begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/*  * Copyright 2011 The Apache Software Foundation  *  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|hfile
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|BufferedInputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|ByteArrayInputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|ByteArrayOutputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|DataInputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|DataOutput
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|DataOutputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|InputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|OutputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|nio
operator|.
name|ByteBuffer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FSDataInputStream
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FSDataOutputStream
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|DoubleOutputStream
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|HeapSize
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|hfile
operator|.
name|Compression
operator|.
name|Algorithm
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|Bytes
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|ClassSize
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|CompoundBloomFilter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|Writables
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|IOUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|Writable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|compress
operator|.
name|Compressor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|compress
operator|.
name|Decompressor
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Preconditions
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|hfile
operator|.
name|BlockType
operator|.
name|MAGIC_LENGTH
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|hfile
operator|.
name|Compression
operator|.
name|Algorithm
operator|.
name|NONE
import|;
end_import

begin_comment
comment|/**  * Reading {@link HFile} version 1 and 2 blocks, and writing version 2 blocks.  *<ul>  *<li>In version 1 all blocks are always compressed or uncompressed, as  * specified by the {@link HFile}'s compression algorithm, with a type-specific  * magic record stored in the beginning of the compressed data (i.e. one needs  * to uncompress the compressed block to determine the block type). There is  * only a single compression algorithm setting for all blocks. Offset and size  * information from the block index are required to read a block.  *<li>In version 2 a block is structured as follows:  *<ul>  *<li>Magic record identifying the block type (8 bytes)  *<li>Compressed block size, header not included (4 bytes)  *<li>Uncompressed block size, header not included (4 bytes)  *<li>The offset of the previous block of the same type (8 bytes). This is  * used to be able to navigate to the previous block without going to the block  * index.  *<li>Compressed data (or uncompressed data if compression is disabled). The  * compression algorithm is the same for all the blocks in the {@link HFile},  * similarly to what was done in version 1.  *</ul>  *</ul>  * The version 2 block representation in the block cache is the same as above,  * except that the data section is always uncompressed in the cache.  */
end_comment

begin_class
specifier|public
class|class
name|HFileBlock
implements|implements
name|HeapSize
block|{
comment|/** The size of a version 2 {@link HFile} block header */
specifier|public
specifier|static
specifier|final
name|int
name|HEADER_SIZE
init|=
name|MAGIC_LENGTH
operator|+
literal|2
operator|*
name|Bytes
operator|.
name|SIZEOF_INT
operator|+
name|Bytes
operator|.
name|SIZEOF_LONG
decl_stmt|;
comment|/** Just an array of bytes of the right size. */
specifier|public
specifier|static
specifier|final
name|byte
index|[]
name|DUMMY_HEADER
init|=
operator|new
name|byte
index|[
name|HEADER_SIZE
index|]
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|int
name|BYTE_BUFFER_HEAP_SIZE
init|=
operator|(
name|int
operator|)
name|ClassSize
operator|.
name|estimateBase
argument_list|(
name|ByteBuffer
operator|.
name|wrap
argument_list|(
operator|new
name|byte
index|[
literal|0
index|]
argument_list|,
literal|0
argument_list|,
literal|0
argument_list|)
operator|.
name|getClass
argument_list|()
argument_list|,
literal|false
argument_list|)
decl_stmt|;
specifier|private
name|BlockType
name|blockType
decl_stmt|;
specifier|private
specifier|final
name|int
name|onDiskSizeWithoutHeader
decl_stmt|;
specifier|private
specifier|final
name|int
name|uncompressedSizeWithoutHeader
decl_stmt|;
specifier|private
specifier|final
name|long
name|prevBlockOffset
decl_stmt|;
specifier|private
name|ByteBuffer
name|buf
decl_stmt|;
comment|/**    * The offset of this block in the file. Populated by the reader for    * convenience of access. This offset is not part of the block header.    */
specifier|private
name|long
name|offset
init|=
operator|-
literal|1
decl_stmt|;
comment|/**    * The on-disk size of the next block, including the header, obtained by    * peeking into the first {@link HEADER_SIZE} bytes of the next block's    * header, or -1 if unknown.    */
specifier|private
name|int
name|nextBlockOnDiskSizeWithHeader
init|=
operator|-
literal|1
decl_stmt|;
comment|/**    * Creates a new {@link HFile} block from the given fields. This constructor    * is mostly used when the block data has already been read and uncompressed,    * and is sitting in a byte buffer.    *    * @param blockType the type of this block, see {@link BlockType}    * @param onDiskSizeWithoutHeader compressed size of the block if compression    *          is used, otherwise uncompressed size, header size not included    * @param uncompressedSizeWithoutHeader uncompressed size of the block,    *          header size not included. Equals onDiskSizeWithoutHeader if    *          compression is disabled.    * @param prevBlockOffset the offset of the previous block in the    *          {@link HFile}    * @param buf block header ({@link #HEADER_SIZE} bytes) followed by    *          uncompressed data. This    * @param fillHeader true to fill in the first {@link #HEADER_SIZE} bytes of    *          the buffer based on the header fields provided    * @param offset the file offset the block was read from    */
specifier|public
name|HFileBlock
parameter_list|(
name|BlockType
name|blockType
parameter_list|,
name|int
name|onDiskSizeWithoutHeader
parameter_list|,
name|int
name|uncompressedSizeWithoutHeader
parameter_list|,
name|long
name|prevBlockOffset
parameter_list|,
name|ByteBuffer
name|buf
parameter_list|,
name|boolean
name|fillHeader
parameter_list|,
name|long
name|offset
parameter_list|)
block|{
name|this
operator|.
name|blockType
operator|=
name|blockType
expr_stmt|;
name|this
operator|.
name|onDiskSizeWithoutHeader
operator|=
name|onDiskSizeWithoutHeader
expr_stmt|;
name|this
operator|.
name|uncompressedSizeWithoutHeader
operator|=
name|uncompressedSizeWithoutHeader
expr_stmt|;
name|this
operator|.
name|prevBlockOffset
operator|=
name|prevBlockOffset
expr_stmt|;
name|this
operator|.
name|buf
operator|=
name|buf
expr_stmt|;
if|if
condition|(
name|fillHeader
condition|)
name|overwriteHeader
argument_list|()
expr_stmt|;
name|this
operator|.
name|offset
operator|=
name|offset
expr_stmt|;
block|}
comment|/**    * Creates a block from an existing buffer starting with a header. Rewinds    * and takes ownership of the buffer. By definition of rewind, ignores the    * buffer position, but if you slice the buffer beforehand, it will rewind    * to that point.    */
specifier|private
name|HFileBlock
parameter_list|(
name|ByteBuffer
name|b
parameter_list|)
throws|throws
name|IOException
block|{
name|b
operator|.
name|rewind
argument_list|()
expr_stmt|;
name|blockType
operator|=
name|BlockType
operator|.
name|read
argument_list|(
name|b
argument_list|)
expr_stmt|;
name|onDiskSizeWithoutHeader
operator|=
name|b
operator|.
name|getInt
argument_list|()
expr_stmt|;
name|uncompressedSizeWithoutHeader
operator|=
name|b
operator|.
name|getInt
argument_list|()
expr_stmt|;
name|prevBlockOffset
operator|=
name|b
operator|.
name|getLong
argument_list|()
expr_stmt|;
name|buf
operator|=
name|b
expr_stmt|;
name|buf
operator|.
name|rewind
argument_list|()
expr_stmt|;
block|}
specifier|public
name|BlockType
name|getBlockType
parameter_list|()
block|{
return|return
name|blockType
return|;
block|}
comment|/**    * @return the on-disk size of the block with header size included    */
specifier|public
name|int
name|getOnDiskSizeWithHeader
parameter_list|()
block|{
return|return
name|onDiskSizeWithoutHeader
operator|+
name|HEADER_SIZE
return|;
block|}
comment|/**    * Returns the size of the compressed part of the block in case compression    * is used, or the uncompressed size of the data part otherwise. Header size    * is not included.    *    * @return the on-disk size of the data part of the block, header not    *         included    */
specifier|public
name|int
name|getOnDiskSizeWithoutHeader
parameter_list|()
block|{
return|return
name|onDiskSizeWithoutHeader
return|;
block|}
comment|/**    * @return the uncompressed size of the data part of the block, header not    *         included    */
specifier|public
name|int
name|getUncompressedSizeWithoutHeader
parameter_list|()
block|{
return|return
name|uncompressedSizeWithoutHeader
return|;
block|}
comment|/**    * @return the offset of the previous block of the same type in the file, or    *         -1 if unknown    */
specifier|public
name|long
name|getPrevBlockOffset
parameter_list|()
block|{
return|return
name|prevBlockOffset
return|;
block|}
comment|/**    * Writes header fields into the first {@link HEADER_SIZE} bytes of the    * buffer. Resets the buffer position to the end of header as side effect.    */
specifier|private
name|void
name|overwriteHeader
parameter_list|()
block|{
name|buf
operator|.
name|rewind
argument_list|()
expr_stmt|;
name|blockType
operator|.
name|write
argument_list|(
name|buf
argument_list|)
expr_stmt|;
name|buf
operator|.
name|putInt
argument_list|(
name|onDiskSizeWithoutHeader
argument_list|)
expr_stmt|;
name|buf
operator|.
name|putInt
argument_list|(
name|uncompressedSizeWithoutHeader
argument_list|)
expr_stmt|;
name|buf
operator|.
name|putLong
argument_list|(
name|prevBlockOffset
argument_list|)
expr_stmt|;
block|}
comment|/**    * Returns a buffer that does not include the header. The array offset points    * to the start of the block data right after the header. The underlying data    * array is not copied.    *    * @return the buffer with header skipped    */
specifier|public
name|ByteBuffer
name|getBufferWithoutHeader
parameter_list|()
block|{
return|return
name|ByteBuffer
operator|.
name|wrap
argument_list|(
name|buf
operator|.
name|array
argument_list|()
argument_list|,
name|buf
operator|.
name|arrayOffset
argument_list|()
operator|+
name|HEADER_SIZE
argument_list|,
name|buf
operator|.
name|limit
argument_list|()
operator|-
name|HEADER_SIZE
argument_list|)
operator|.
name|slice
argument_list|()
return|;
block|}
comment|/**    * Returns the buffer this block stores internally. The clients must not    * modify the buffer object. This method has to be public because it is    * used in {@link CompoundBloomFilter} to avoid object creation on every    * Bloom filter lookup, but has to be used with caution.    *    * @return the buffer of this block for read-only operations    */
specifier|public
name|ByteBuffer
name|getBufferReadOnly
parameter_list|()
block|{
return|return
name|buf
return|;
block|}
comment|/**    * Returns a byte buffer of this block, including header data, positioned at    * the beginning of header. The underlying data array is not copied.    *    * @return the byte buffer with header included    */
specifier|public
name|ByteBuffer
name|getBufferWithHeader
parameter_list|()
block|{
name|ByteBuffer
name|dupBuf
init|=
name|buf
operator|.
name|duplicate
argument_list|()
decl_stmt|;
name|dupBuf
operator|.
name|rewind
argument_list|()
expr_stmt|;
return|return
name|dupBuf
return|;
block|}
comment|/**    * Deserializes fields of the given writable using the data portion of this    * block. Does not check that all the block data has been read.    */
specifier|public
name|void
name|readInto
parameter_list|(
name|Writable
name|w
parameter_list|)
throws|throws
name|IOException
block|{
name|Preconditions
operator|.
name|checkNotNull
argument_list|(
name|w
argument_list|)
expr_stmt|;
if|if
condition|(
name|Writables
operator|.
name|getWritable
argument_list|(
name|buf
operator|.
name|array
argument_list|()
argument_list|,
name|buf
operator|.
name|arrayOffset
argument_list|()
operator|+
name|HEADER_SIZE
argument_list|,
name|buf
operator|.
name|limit
argument_list|()
operator|-
name|HEADER_SIZE
argument_list|,
name|w
argument_list|)
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Failed to deserialize block "
operator|+
name|this
operator|+
literal|" into a "
operator|+
name|w
operator|.
name|getClass
argument_list|()
operator|.
name|getSimpleName
argument_list|()
argument_list|)
throw|;
block|}
block|}
specifier|private
name|void
name|sanityCheckAssertion
parameter_list|(
name|long
name|valueFromBuf
parameter_list|,
name|long
name|valueFromField
parameter_list|,
name|String
name|fieldName
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|valueFromBuf
operator|!=
name|valueFromField
condition|)
block|{
throw|throw
operator|new
name|AssertionError
argument_list|(
name|fieldName
operator|+
literal|" in the buffer ("
operator|+
name|valueFromBuf
operator|+
literal|") is different from that in the field ("
operator|+
name|valueFromField
operator|+
literal|")"
argument_list|)
throw|;
block|}
block|}
comment|/**    * Checks if the block is internally consistent, i.e. the first    * {@link #HEADER_SIZE} bytes of the buffer contain a valid header consistent    * with the fields. This function is primary for testing and debugging, and    * is not thread-safe, because it alters the internal buffer pointer.    */
name|void
name|sanityCheck
parameter_list|()
throws|throws
name|IOException
block|{
name|buf
operator|.
name|rewind
argument_list|()
expr_stmt|;
block|{
name|BlockType
name|blockTypeFromBuf
init|=
name|BlockType
operator|.
name|read
argument_list|(
name|buf
argument_list|)
decl_stmt|;
if|if
condition|(
name|blockTypeFromBuf
operator|!=
name|blockType
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Block type stored in the buffer: "
operator|+
name|blockTypeFromBuf
operator|+
literal|", block type field: "
operator|+
name|blockType
argument_list|)
throw|;
block|}
block|}
name|sanityCheckAssertion
argument_list|(
name|buf
operator|.
name|getInt
argument_list|()
argument_list|,
name|onDiskSizeWithoutHeader
argument_list|,
literal|"onDiskSizeWithoutHeader"
argument_list|)
expr_stmt|;
name|sanityCheckAssertion
argument_list|(
name|buf
operator|.
name|getInt
argument_list|()
argument_list|,
name|uncompressedSizeWithoutHeader
argument_list|,
literal|"uncompressedSizeWithoutHeader"
argument_list|)
expr_stmt|;
name|sanityCheckAssertion
argument_list|(
name|buf
operator|.
name|getLong
argument_list|()
argument_list|,
name|prevBlockOffset
argument_list|,
literal|"prevBlocKOffset"
argument_list|)
expr_stmt|;
name|int
name|expectedBufLimit
init|=
name|uncompressedSizeWithoutHeader
operator|+
name|HEADER_SIZE
decl_stmt|;
if|if
condition|(
name|buf
operator|.
name|limit
argument_list|()
operator|!=
name|expectedBufLimit
condition|)
block|{
throw|throw
operator|new
name|AssertionError
argument_list|(
literal|"Expected buffer limit "
operator|+
name|expectedBufLimit
operator|+
literal|", got "
operator|+
name|buf
operator|.
name|limit
argument_list|()
argument_list|)
throw|;
block|}
comment|// We might optionally allocate HEADER_SIZE more bytes to read the next
comment|// block's, header, so there are two sensible values for buffer capacity.
if|if
condition|(
name|buf
operator|.
name|capacity
argument_list|()
operator|!=
name|uncompressedSizeWithoutHeader
operator|+
name|HEADER_SIZE
operator|&&
name|buf
operator|.
name|capacity
argument_list|()
operator|!=
name|uncompressedSizeWithoutHeader
operator|+
literal|2
operator|*
name|HEADER_SIZE
condition|)
block|{
throw|throw
operator|new
name|AssertionError
argument_list|(
literal|"Invalid buffer capacity: "
operator|+
name|buf
operator|.
name|capacity
argument_list|()
operator|+
literal|", expected "
operator|+
operator|(
name|uncompressedSizeWithoutHeader
operator|+
name|HEADER_SIZE
operator|)
operator|+
literal|" or "
operator|+
operator|(
name|uncompressedSizeWithoutHeader
operator|+
literal|2
operator|*
name|HEADER_SIZE
operator|)
argument_list|)
throw|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|String
name|toString
parameter_list|()
block|{
return|return
literal|"blockType="
operator|+
name|blockType
operator|+
literal|", onDiskSizeWithoutHeader="
operator|+
name|onDiskSizeWithoutHeader
operator|+
literal|", uncompressedSizeWithoutHeader="
operator|+
name|uncompressedSizeWithoutHeader
operator|+
literal|", prevBlockOffset="
operator|+
name|prevBlockOffset
operator|+
literal|", dataBeginsWith="
operator|+
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|buf
operator|.
name|array
argument_list|()
argument_list|,
name|buf
operator|.
name|arrayOffset
argument_list|()
operator|+
name|HEADER_SIZE
argument_list|,
name|Math
operator|.
name|min
argument_list|(
literal|32
argument_list|,
name|buf
operator|.
name|limit
argument_list|()
operator|-
name|buf
operator|.
name|arrayOffset
argument_list|()
operator|-
name|HEADER_SIZE
argument_list|)
argument_list|)
operator|+
literal|", fileOffset="
operator|+
name|offset
return|;
block|}
specifier|private
name|void
name|validateOnDiskSizeWithoutHeader
parameter_list|(
name|int
name|expectedOnDiskSizeWithoutHeader
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|onDiskSizeWithoutHeader
operator|!=
name|expectedOnDiskSizeWithoutHeader
condition|)
block|{
name|String
name|blockInfoMsg
init|=
literal|"Block offset: "
operator|+
name|offset
operator|+
literal|", data starts with: "
operator|+
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|buf
operator|.
name|array
argument_list|()
argument_list|,
name|buf
operator|.
name|arrayOffset
argument_list|()
argument_list|,
name|buf
operator|.
name|arrayOffset
argument_list|()
operator|+
name|Math
operator|.
name|min
argument_list|(
literal|32
argument_list|,
name|buf
operator|.
name|limit
argument_list|()
argument_list|)
argument_list|)
decl_stmt|;
throw|throw
operator|new
name|IOException
argument_list|(
literal|"On-disk size without header provided is "
operator|+
name|expectedOnDiskSizeWithoutHeader
operator|+
literal|", but block "
operator|+
literal|"header contains "
operator|+
name|onDiskSizeWithoutHeader
operator|+
literal|". "
operator|+
name|blockInfoMsg
argument_list|)
throw|;
block|}
block|}
comment|/**    * Always allocates a new buffer of the correct size. Copies header bytes    * from the existing buffer. Does not change header fields.    *    * @param extraBytes whether to reserve room in the buffer to read the next    *          block's header    */
specifier|private
name|void
name|allocateBuffer
parameter_list|(
name|boolean
name|extraBytes
parameter_list|)
block|{
name|int
name|capacityNeeded
init|=
name|HEADER_SIZE
operator|+
name|uncompressedSizeWithoutHeader
operator|+
operator|(
name|extraBytes
condition|?
name|HEADER_SIZE
else|:
literal|0
operator|)
decl_stmt|;
name|ByteBuffer
name|newBuf
init|=
name|ByteBuffer
operator|.
name|allocate
argument_list|(
name|capacityNeeded
argument_list|)
decl_stmt|;
comment|// Copy header bytes.
name|System
operator|.
name|arraycopy
argument_list|(
name|buf
operator|.
name|array
argument_list|()
argument_list|,
name|buf
operator|.
name|arrayOffset
argument_list|()
argument_list|,
name|newBuf
operator|.
name|array
argument_list|()
argument_list|,
name|newBuf
operator|.
name|arrayOffset
argument_list|()
argument_list|,
name|HEADER_SIZE
argument_list|)
expr_stmt|;
name|buf
operator|=
name|newBuf
expr_stmt|;
name|buf
operator|.
name|limit
argument_list|(
name|HEADER_SIZE
operator|+
name|uncompressedSizeWithoutHeader
argument_list|)
expr_stmt|;
block|}
comment|/** An additional sanity-check in case no compression is being used. */
specifier|public
name|void
name|assumeUncompressed
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|onDiskSizeWithoutHeader
operator|!=
name|uncompressedSizeWithoutHeader
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Using no compression but "
operator|+
literal|"onDiskSizeWithoutHeader="
operator|+
name|onDiskSizeWithoutHeader
operator|+
literal|", "
operator|+
literal|"uncompressedSizeWithoutHeader="
operator|+
name|uncompressedSizeWithoutHeader
argument_list|)
throw|;
block|}
block|}
comment|/**    * @param expectedType the expected type of this block    * @throws IOException if this block's type is different than expected    */
specifier|public
name|void
name|expectType
parameter_list|(
name|BlockType
name|expectedType
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|blockType
operator|!=
name|expectedType
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Invalid block type: expected="
operator|+
name|expectedType
operator|+
literal|", actual="
operator|+
name|blockType
argument_list|)
throw|;
block|}
block|}
comment|/** @return the offset of this block in the file it was read from */
specifier|public
name|long
name|getOffset
parameter_list|()
block|{
if|if
condition|(
name|offset
operator|<
literal|0
condition|)
block|{
throw|throw
operator|new
name|IllegalStateException
argument_list|(
literal|"HFile block offset not initialized properly"
argument_list|)
throw|;
block|}
return|return
name|offset
return|;
block|}
comment|/**    * @return a byte stream reading the data section of this block    */
specifier|public
name|DataInputStream
name|getByteStream
parameter_list|()
block|{
return|return
operator|new
name|DataInputStream
argument_list|(
operator|new
name|ByteArrayInputStream
argument_list|(
name|buf
operator|.
name|array
argument_list|()
argument_list|,
name|buf
operator|.
name|arrayOffset
argument_list|()
operator|+
name|HEADER_SIZE
argument_list|,
name|buf
operator|.
name|limit
argument_list|()
operator|-
name|HEADER_SIZE
argument_list|)
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|heapSize
parameter_list|()
block|{
comment|// This object, block type and byte buffer reference, on-disk and
comment|// uncompressed size, next block's on-disk size, offset and previous
comment|// offset, byte buffer object, and its byte array. Might also need to add
comment|// some fields inside the byte buffer.
return|return
name|ClassSize
operator|.
name|align
argument_list|(
name|ClassSize
operator|.
name|OBJECT
operator|+
literal|2
operator|*
name|ClassSize
operator|.
name|REFERENCE
operator|+
literal|3
operator|*
name|Bytes
operator|.
name|SIZEOF_INT
operator|+
literal|2
operator|*
name|Bytes
operator|.
name|SIZEOF_LONG
operator|+
name|BYTE_BUFFER_HEAP_SIZE
argument_list|)
operator|+
name|ClassSize
operator|.
name|align
argument_list|(
name|buf
operator|.
name|capacity
argument_list|()
argument_list|)
return|;
block|}
comment|/**    * Read from an input stream. Analogous to    * {@link IOUtils#readFully(InputStream, byte[], int, int)}, but specifies a    * number of "extra" bytes that would be desirable but not absolutely    * necessary to read.    *    * @param in the input stream to read from    * @param buf the buffer to read into    * @param bufOffset the destination offset in the buffer    * @param necessaryLen the number of bytes that are absolutely necessary to    *          read    * @param extraLen the number of extra bytes that would be nice to read    * @return true if succeeded reading the extra bytes    * @throws IOException if failed to read the necessary bytes    */
specifier|public
specifier|static
name|boolean
name|readWithExtra
parameter_list|(
name|InputStream
name|in
parameter_list|,
name|byte
name|buf
index|[]
parameter_list|,
name|int
name|bufOffset
parameter_list|,
name|int
name|necessaryLen
parameter_list|,
name|int
name|extraLen
parameter_list|)
throws|throws
name|IOException
block|{
name|int
name|bytesRemaining
init|=
name|necessaryLen
operator|+
name|extraLen
decl_stmt|;
while|while
condition|(
name|bytesRemaining
operator|>
literal|0
condition|)
block|{
name|int
name|ret
init|=
name|in
operator|.
name|read
argument_list|(
name|buf
argument_list|,
name|bufOffset
argument_list|,
name|bytesRemaining
argument_list|)
decl_stmt|;
if|if
condition|(
name|ret
operator|==
operator|-
literal|1
operator|&&
name|bytesRemaining
operator|<=
name|extraLen
condition|)
block|{
comment|// We could not read the "extra data", but that is OK.
break|break;
block|}
if|if
condition|(
name|ret
operator|<
literal|0
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Premature EOF from inputStream (read "
operator|+
literal|"returned "
operator|+
name|ret
operator|+
literal|", was trying to read "
operator|+
name|necessaryLen
operator|+
literal|" necessary bytes and "
operator|+
name|extraLen
operator|+
literal|" extra bytes, "
operator|+
literal|"successfully read "
operator|+
operator|(
name|necessaryLen
operator|+
name|extraLen
operator|-
name|bytesRemaining
operator|)
argument_list|)
throw|;
block|}
name|bufOffset
operator|+=
name|ret
expr_stmt|;
name|bytesRemaining
operator|-=
name|ret
expr_stmt|;
block|}
return|return
name|bytesRemaining
operator|<=
literal|0
return|;
block|}
comment|/**    * @return the on-disk size of the next block (including the header size)    *         that was read by peeking into the next block's header    */
specifier|public
name|int
name|getNextBlockOnDiskSizeWithHeader
parameter_list|()
block|{
return|return
name|nextBlockOnDiskSizeWithHeader
return|;
block|}
comment|/**    * Unified version 2 {@link HFile} block writer. The intended usage pattern    * is as follows:    *<ul>    *<li>Construct an {@link HFileBlock.Writer}, providing a compression    * algorithm    *<li>Call {@link Writer#startWriting(BlockType)} and get a data stream to    * write to    *<li>Write your data into the stream    *<li>Call {@link Writer#writeHeaderAndData()} as many times as you need to    * store the serialized block into an external stream, or call    * {@link Writer#getHeaderAndData()} to get it as a byte array.    *<li>Repeat to write more blocks    *</ul>    *<p>    */
specifier|public
specifier|static
class|class
name|Writer
block|{
specifier|private
enum|enum
name|State
block|{
name|INIT
block|,
name|WRITING
block|,
name|BLOCK_READY
block|}
empty_stmt|;
comment|/** Writer state. Used to ensure the correct usage protocol. */
specifier|private
name|State
name|state
init|=
name|State
operator|.
name|INIT
decl_stmt|;
comment|/** Compression algorithm for all blocks this instance writes. */
specifier|private
specifier|final
name|Compression
operator|.
name|Algorithm
name|compressAlgo
decl_stmt|;
comment|/**      * The stream we use to accumulate data in the on-disk format for each      * block (i.e. compressed data, or uncompressed if using no compression).      * We reset this stream at the end of each block and reuse it. The header      * is written as the first {@link #HEADER_SIZE} bytes into this stream.      */
specifier|private
name|ByteArrayOutputStream
name|baosOnDisk
decl_stmt|;
comment|/**      * The stream we use to accumulate uncompressed block data for      * cache-on-write. Null when cache-on-write is turned off.      */
specifier|private
name|ByteArrayOutputStream
name|baosInMemory
decl_stmt|;
comment|/** Compressor, which is also reused between consecutive blocks. */
specifier|private
name|Compressor
name|compressor
decl_stmt|;
comment|/** Current block type. Set in {@link #startWriting(BlockType)}. */
specifier|private
name|BlockType
name|blockType
decl_stmt|;
comment|/**      * A stream that we write uncompressed bytes to, which compresses them and      * writes them to {@link #baosOnDisk}.      */
specifier|private
name|DataOutputStream
name|userDataStream
decl_stmt|;
comment|/**      * Bytes to be written to the file system, including the header. Compressed      * if compression is turned on.      */
specifier|private
name|byte
index|[]
name|onDiskBytesWithHeader
decl_stmt|;
comment|/**      * The total number of uncompressed bytes written into the current block,      * with header size not included. Valid in the READY state.      */
specifier|private
name|int
name|uncompressedSizeWithoutHeader
decl_stmt|;
comment|/**      * Only used when we are using cache-on-write. Valid in the READY state.      * Contains the header and the uncompressed bytes, so the length is      * {@link #uncompressedSizeWithoutHeader} + {@link HFileBlock#HEADER_SIZE}.      */
specifier|private
name|byte
index|[]
name|uncompressedBytesWithHeader
decl_stmt|;
comment|/**      * Current block's start offset in the {@link HFile}. Set in      * {@link #writeHeaderAndData(FSDataOutputStream)}.      */
specifier|private
name|long
name|startOffset
decl_stmt|;
comment|/**      * Offset of previous block by block type. Updated when the next block is      * started.      */
specifier|private
name|long
index|[]
name|prevOffsetByType
decl_stmt|;
comment|/**      * Whether we are accumulating uncompressed bytes for the purpose of      * caching on write.      */
specifier|private
name|boolean
name|cacheOnWrite
decl_stmt|;
comment|/** The offset of the previous block of the same type */
specifier|private
name|long
name|prevOffset
decl_stmt|;
comment|/**      * @param blockType      *          block type to create      * @param compressionAlgorithm      *          compression algorithm to use      */
specifier|public
name|Writer
parameter_list|(
name|Compression
operator|.
name|Algorithm
name|compressionAlgorithm
parameter_list|)
block|{
name|compressAlgo
operator|=
name|compressionAlgorithm
operator|==
literal|null
condition|?
name|NONE
else|:
name|compressionAlgorithm
expr_stmt|;
name|baosOnDisk
operator|=
operator|new
name|ByteArrayOutputStream
argument_list|()
expr_stmt|;
if|if
condition|(
name|compressAlgo
operator|!=
name|NONE
condition|)
name|compressor
operator|=
name|compressionAlgorithm
operator|.
name|getCompressor
argument_list|()
expr_stmt|;
name|prevOffsetByType
operator|=
operator|new
name|long
index|[
name|BlockType
operator|.
name|values
argument_list|()
operator|.
name|length
index|]
expr_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|prevOffsetByType
operator|.
name|length
condition|;
operator|++
name|i
control|)
name|prevOffsetByType
index|[
name|i
index|]
operator|=
operator|-
literal|1
expr_stmt|;
block|}
comment|/**      * Starts writing into the block. The previous block's data is discarded.      *      * @return the stream the user can write their data into      * @throws IOException      */
specifier|public
name|DataOutputStream
name|startWriting
parameter_list|(
name|BlockType
name|newBlockType
parameter_list|,
name|boolean
name|cacheOnWrite
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|state
operator|==
name|State
operator|.
name|BLOCK_READY
operator|&&
name|startOffset
operator|!=
operator|-
literal|1
condition|)
block|{
comment|// We had a previous block that was written to a stream at a specific
comment|// offset. Save that offset as the last offset of a block of that type.
name|prevOffsetByType
index|[
name|blockType
operator|.
name|ordinal
argument_list|()
index|]
operator|=
name|startOffset
expr_stmt|;
block|}
name|this
operator|.
name|cacheOnWrite
operator|=
name|cacheOnWrite
expr_stmt|;
name|startOffset
operator|=
operator|-
literal|1
expr_stmt|;
name|blockType
operator|=
name|newBlockType
expr_stmt|;
name|baosOnDisk
operator|.
name|reset
argument_list|()
expr_stmt|;
name|baosOnDisk
operator|.
name|write
argument_list|(
name|DUMMY_HEADER
argument_list|)
expr_stmt|;
name|state
operator|=
name|State
operator|.
name|WRITING
expr_stmt|;
if|if
condition|(
name|compressAlgo
operator|==
name|NONE
condition|)
block|{
comment|// We do not need a compression stream or a second uncompressed stream
comment|// for cache-on-write.
name|userDataStream
operator|=
operator|new
name|DataOutputStream
argument_list|(
name|baosOnDisk
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|OutputStream
name|compressingOutputStream
init|=
name|compressAlgo
operator|.
name|createCompressionStream
argument_list|(
name|baosOnDisk
argument_list|,
name|compressor
argument_list|,
literal|0
argument_list|)
decl_stmt|;
if|if
condition|(
name|cacheOnWrite
condition|)
block|{
comment|// We save uncompressed data in a cache-on-write mode.
if|if
condition|(
name|baosInMemory
operator|==
literal|null
condition|)
name|baosInMemory
operator|=
operator|new
name|ByteArrayOutputStream
argument_list|()
expr_stmt|;
name|baosInMemory
operator|.
name|reset
argument_list|()
expr_stmt|;
name|baosInMemory
operator|.
name|write
argument_list|(
name|DUMMY_HEADER
argument_list|)
expr_stmt|;
name|userDataStream
operator|=
operator|new
name|DataOutputStream
argument_list|(
operator|new
name|DoubleOutputStream
argument_list|(
name|compressingOutputStream
argument_list|,
name|baosInMemory
argument_list|)
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|userDataStream
operator|=
operator|new
name|DataOutputStream
argument_list|(
name|compressingOutputStream
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|userDataStream
return|;
block|}
comment|/**      * Returns the stream for the user to write to. The block writer takes care      * of handling compression and buffering for caching on write. Can only be      * called in the "writing" state.      *      * @return the data output stream for the user to write to      */
name|DataOutputStream
name|getUserDataStream
parameter_list|()
block|{
name|expectState
argument_list|(
name|State
operator|.
name|WRITING
argument_list|)
expr_stmt|;
return|return
name|userDataStream
return|;
block|}
comment|/**      * Transitions the block writer from the "writing" state to the "block      * ready" state.  Does nothing if a block is already finished.      */
specifier|private
name|void
name|ensureBlockReady
parameter_list|()
throws|throws
name|IOException
block|{
name|Preconditions
operator|.
name|checkState
argument_list|(
name|state
operator|!=
name|State
operator|.
name|INIT
argument_list|,
literal|"Unexpected state: "
operator|+
name|state
argument_list|)
expr_stmt|;
if|if
condition|(
name|state
operator|==
name|State
operator|.
name|BLOCK_READY
condition|)
return|return;
name|finishBlock
argument_list|()
expr_stmt|;
name|state
operator|=
name|State
operator|.
name|BLOCK_READY
expr_stmt|;
block|}
comment|/**      * An internal method that flushes the compressing stream (if using      * compression), serializes the header, and takes care of the separate      * uncompressed stream for caching on write, if applicable. Block writer      * state transitions must be managed by the caller.      */
specifier|private
name|void
name|finishBlock
parameter_list|()
throws|throws
name|IOException
block|{
name|userDataStream
operator|.
name|flush
argument_list|()
expr_stmt|;
name|uncompressedSizeWithoutHeader
operator|=
name|userDataStream
operator|.
name|size
argument_list|()
expr_stmt|;
name|onDiskBytesWithHeader
operator|=
name|baosOnDisk
operator|.
name|toByteArray
argument_list|()
expr_stmt|;
name|prevOffset
operator|=
name|prevOffsetByType
index|[
name|blockType
operator|.
name|ordinal
argument_list|()
index|]
expr_stmt|;
name|putHeader
argument_list|(
name|onDiskBytesWithHeader
argument_list|,
literal|0
argument_list|)
expr_stmt|;
if|if
condition|(
name|cacheOnWrite
operator|&&
name|compressAlgo
operator|!=
name|NONE
condition|)
block|{
name|uncompressedBytesWithHeader
operator|=
name|baosInMemory
operator|.
name|toByteArray
argument_list|()
expr_stmt|;
if|if
condition|(
name|uncompressedSizeWithoutHeader
operator|!=
name|uncompressedBytesWithHeader
operator|.
name|length
operator|-
name|HEADER_SIZE
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Uncompressed size mismatch: "
operator|+
name|uncompressedSizeWithoutHeader
operator|+
literal|" vs. "
operator|+
operator|(
name|uncompressedBytesWithHeader
operator|.
name|length
operator|-
name|HEADER_SIZE
operator|)
argument_list|)
throw|;
block|}
comment|// Write the header into the beginning of the uncompressed byte array.
name|putHeader
argument_list|(
name|uncompressedBytesWithHeader
argument_list|,
literal|0
argument_list|)
expr_stmt|;
block|}
block|}
comment|/** Put the header into the given byte array at the given offset. */
specifier|private
name|void
name|putHeader
parameter_list|(
name|byte
index|[]
name|dest
parameter_list|,
name|int
name|offset
parameter_list|)
block|{
name|offset
operator|=
name|blockType
operator|.
name|put
argument_list|(
name|dest
argument_list|,
name|offset
argument_list|)
expr_stmt|;
name|offset
operator|=
name|Bytes
operator|.
name|putInt
argument_list|(
name|dest
argument_list|,
name|offset
argument_list|,
name|onDiskBytesWithHeader
operator|.
name|length
operator|-
name|HEADER_SIZE
argument_list|)
expr_stmt|;
name|offset
operator|=
name|Bytes
operator|.
name|putInt
argument_list|(
name|dest
argument_list|,
name|offset
argument_list|,
name|uncompressedSizeWithoutHeader
argument_list|)
expr_stmt|;
name|Bytes
operator|.
name|putLong
argument_list|(
name|dest
argument_list|,
name|offset
argument_list|,
name|prevOffset
argument_list|)
expr_stmt|;
block|}
comment|/**      * Similar to {@link #writeHeaderAndData(DataOutputStream)}, but records      * the offset of this block so that it can be referenced in the next block      * of the same type.      *      * @param out      * @throws IOException      */
specifier|public
name|void
name|writeHeaderAndData
parameter_list|(
name|FSDataOutputStream
name|out
parameter_list|)
throws|throws
name|IOException
block|{
name|long
name|offset
init|=
name|out
operator|.
name|getPos
argument_list|()
decl_stmt|;
if|if
condition|(
name|startOffset
operator|!=
operator|-
literal|1
operator|&&
name|offset
operator|!=
name|startOffset
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"A "
operator|+
name|blockType
operator|+
literal|" block written to a "
operator|+
literal|"stream twice, first at offset "
operator|+
name|startOffset
operator|+
literal|", then at "
operator|+
name|offset
argument_list|)
throw|;
block|}
name|startOffset
operator|=
name|offset
expr_stmt|;
name|writeHeaderAndData
argument_list|(
operator|(
name|DataOutputStream
operator|)
name|out
argument_list|)
expr_stmt|;
block|}
comment|/**      * Writes the header and the compressed data of this block (or uncompressed      * data when not using compression) into the given stream. Can be called in      * the "writing" state or in the "block ready" state. If called in the      * "writing" state, transitions the writer to the "block ready" state.      *      * @param out the output stream to write the      * @throws IOException      */
specifier|private
name|void
name|writeHeaderAndData
parameter_list|(
name|DataOutputStream
name|out
parameter_list|)
throws|throws
name|IOException
block|{
name|ensureBlockReady
argument_list|()
expr_stmt|;
name|out
operator|.
name|write
argument_list|(
name|onDiskBytesWithHeader
argument_list|)
expr_stmt|;
block|}
comment|/**      * Returns the header or the compressed data (or uncompressed data when not      * using compression) as a byte array. Can be called in the "writing" state      * or in the "block ready" state. If called in the "writing" state,      * transitions the writer to the "block ready" state.      *      * @return header and data as they would be stored on disk in a byte array      * @throws IOException      */
specifier|public
name|byte
index|[]
name|getHeaderAndData
parameter_list|()
throws|throws
name|IOException
block|{
name|ensureBlockReady
argument_list|()
expr_stmt|;
return|return
name|onDiskBytesWithHeader
return|;
block|}
comment|/**      * Releases the compressor this writer uses to compress blocks into the      * compressor pool. Needs to be called before the writer is discarded.      */
specifier|public
name|void
name|releaseCompressor
parameter_list|()
block|{
if|if
condition|(
name|compressor
operator|!=
literal|null
condition|)
block|{
name|compressAlgo
operator|.
name|returnCompressor
argument_list|(
name|compressor
argument_list|)
expr_stmt|;
name|compressor
operator|=
literal|null
expr_stmt|;
block|}
block|}
comment|/**      * Returns the on-disk size of the data portion of the block. This is the      * compressed size if compression is enabled. Can only be called in the      * "block ready" state. Header is not compressed, and its size is not      * included in the return value.      *      * @return the on-disk size of the block, not including the header.      */
specifier|public
name|int
name|getOnDiskSizeWithoutHeader
parameter_list|()
block|{
name|expectState
argument_list|(
name|State
operator|.
name|BLOCK_READY
argument_list|)
expr_stmt|;
return|return
name|onDiskBytesWithHeader
operator|.
name|length
operator|-
name|HEADER_SIZE
return|;
block|}
comment|/**      * Returns the on-disk size of the block. Can only be called in the      * "block ready" state.      *      * @return the on-disk size of the block ready to be written, including the      *         header size      */
specifier|public
name|int
name|getOnDiskSizeWithHeader
parameter_list|()
block|{
name|expectState
argument_list|(
name|State
operator|.
name|BLOCK_READY
argument_list|)
expr_stmt|;
return|return
name|onDiskBytesWithHeader
operator|.
name|length
return|;
block|}
comment|/**      * The uncompressed size of the block data. Does not include header size.      */
specifier|public
name|int
name|getUncompressedSizeWithoutHeader
parameter_list|()
block|{
name|expectState
argument_list|(
name|State
operator|.
name|BLOCK_READY
argument_list|)
expr_stmt|;
return|return
name|uncompressedSizeWithoutHeader
return|;
block|}
comment|/**      * The uncompressed size of the block data, including header size.      */
specifier|public
name|int
name|getUncompressedSizeWithHeader
parameter_list|()
block|{
name|expectState
argument_list|(
name|State
operator|.
name|BLOCK_READY
argument_list|)
expr_stmt|;
return|return
name|uncompressedSizeWithoutHeader
operator|+
name|HEADER_SIZE
return|;
block|}
comment|/** @return true if a block is being written  */
specifier|public
name|boolean
name|isWriting
parameter_list|()
block|{
return|return
name|state
operator|==
name|State
operator|.
name|WRITING
return|;
block|}
comment|/**      * Returns the number of bytes written into the current block so far, or      * zero if not writing the block at the moment. Note that this will return      * zero in the "block ready" state as well.      *      * @return the number of bytes written      */
specifier|public
name|int
name|blockSizeWritten
parameter_list|()
block|{
if|if
condition|(
name|state
operator|!=
name|State
operator|.
name|WRITING
condition|)
return|return
literal|0
return|;
return|return
name|userDataStream
operator|.
name|size
argument_list|()
return|;
block|}
comment|/**      * Returns the header followed by the uncompressed data, even if using      * compression. This is needed for storing uncompressed blocks in the block      * cache. Can be called in the "writing" state or the "block ready" state.      *      * @return uncompressed block bytes for caching on write      */
specifier|private
name|byte
index|[]
name|getUncompressedDataWithHeader
parameter_list|()
block|{
name|expectState
argument_list|(
name|State
operator|.
name|BLOCK_READY
argument_list|)
expr_stmt|;
if|if
condition|(
name|compressAlgo
operator|==
name|NONE
condition|)
return|return
name|onDiskBytesWithHeader
return|;
if|if
condition|(
operator|!
name|cacheOnWrite
condition|)
throw|throw
operator|new
name|IllegalStateException
argument_list|(
literal|"Cache-on-write is turned off"
argument_list|)
throw|;
if|if
condition|(
name|uncompressedBytesWithHeader
operator|==
literal|null
condition|)
throw|throw
operator|new
name|NullPointerException
argument_list|()
throw|;
return|return
name|uncompressedBytesWithHeader
return|;
block|}
specifier|private
name|void
name|expectState
parameter_list|(
name|State
name|expectedState
parameter_list|)
block|{
if|if
condition|(
name|state
operator|!=
name|expectedState
condition|)
block|{
throw|throw
operator|new
name|IllegalStateException
argument_list|(
literal|"Expected state: "
operator|+
name|expectedState
operator|+
literal|", actual state: "
operator|+
name|state
argument_list|)
throw|;
block|}
block|}
comment|/**      * Similar to {@link #getUncompressedDataWithHeader()} but returns a byte      * buffer.      *      * @return uncompressed block for caching on write in the form of a buffer      */
specifier|public
name|ByteBuffer
name|getUncompressedBufferWithHeader
parameter_list|()
block|{
name|byte
index|[]
name|b
init|=
name|getUncompressedDataWithHeader
argument_list|()
decl_stmt|;
return|return
name|ByteBuffer
operator|.
name|wrap
argument_list|(
name|b
argument_list|,
literal|0
argument_list|,
name|b
operator|.
name|length
argument_list|)
return|;
block|}
comment|/**      * Takes the given {@link BlockWritable} instance, creates a new block of      * its appropriate type, writes the writable into this block, and flushes      * the block into the output stream. The writer is instructed not to buffer      * uncompressed bytes for cache-on-write.      *      * @param bw the block-writable object to write as a block      * @param out the file system output stream      * @throws IOException      */
specifier|public
name|void
name|writeBlock
parameter_list|(
name|BlockWritable
name|bw
parameter_list|,
name|FSDataOutputStream
name|out
parameter_list|)
throws|throws
name|IOException
block|{
name|bw
operator|.
name|writeToBlock
argument_list|(
name|startWriting
argument_list|(
name|bw
operator|.
name|getBlockType
argument_list|()
argument_list|,
literal|false
argument_list|)
argument_list|)
expr_stmt|;
name|writeHeaderAndData
argument_list|(
name|out
argument_list|)
expr_stmt|;
block|}
specifier|public
name|HFileBlock
name|getBlockForCaching
parameter_list|()
block|{
return|return
operator|new
name|HFileBlock
argument_list|(
name|blockType
argument_list|,
name|onDiskBytesWithHeader
operator|.
name|length
operator|-
name|HEADER_SIZE
argument_list|,
name|uncompressedSizeWithoutHeader
argument_list|,
name|prevOffset
argument_list|,
name|getUncompressedBufferWithHeader
argument_list|()
argument_list|,
literal|false
argument_list|,
name|startOffset
argument_list|)
return|;
block|}
block|}
comment|/** Something that can be written into a block. */
specifier|public
interface|interface
name|BlockWritable
block|{
comment|/** The type of block this data should use. */
name|BlockType
name|getBlockType
parameter_list|()
function_decl|;
comment|/**      * Writes the block to the provided stream. Must not write any magic      * records.      *      * @param out a stream to write uncompressed data into      */
name|void
name|writeToBlock
parameter_list|(
name|DataOutput
name|out
parameter_list|)
throws|throws
name|IOException
function_decl|;
block|}
comment|// Block readers and writers
comment|/** An interface allowing to iterate {@link HFileBlock}s. */
specifier|public
interface|interface
name|BlockIterator
block|{
comment|/**      * Get the next block, or null if there are no more blocks to iterate.      */
name|HFileBlock
name|nextBlock
parameter_list|()
throws|throws
name|IOException
function_decl|;
comment|/**      * Similar to {@link #nextBlock()} but checks block type, throws an      * exception if incorrect, and returns the data portion of the block as      * an input stream.      */
name|DataInputStream
name|nextBlockAsStream
parameter_list|(
name|BlockType
name|blockType
parameter_list|)
throws|throws
name|IOException
function_decl|;
block|}
comment|/**    * Just the basic ability to read blocks, providing optional hints of    * on-disk-size and/or uncompressed size.    */
specifier|public
interface|interface
name|BasicReader
block|{
comment|/**      * Reads the block at the given offset in the file with the given on-disk      * size and uncompressed size.      *      * @param offset      * @param onDiskSize the on-disk size of the entire block, including all      *          applicable headers, or -1 if unknown      * @param uncompressedSize the uncompressed size of the compressed part of      *          the block, or -1 if unknown      * @return the newly read block      */
name|HFileBlock
name|readBlockData
parameter_list|(
name|long
name|offset
parameter_list|,
name|long
name|onDiskSize
parameter_list|,
name|int
name|uncompressedSize
parameter_list|,
name|boolean
name|pread
parameter_list|)
throws|throws
name|IOException
function_decl|;
block|}
comment|/** A full-fledged reader with an iteration ability. */
specifier|public
interface|interface
name|FSReader
extends|extends
name|BasicReader
block|{
comment|/**      * Creates a block iterator over the given portion of the {@link HFile}.      * The iterator returns blocks starting with offset such that offset<=      * startOffset< endOffset.      *      * @param startOffset the offset of the block to start iteration with      * @param endOffset the offset to end iteration at (exclusive)      * @return an iterator of blocks between the two given offsets      */
name|BlockIterator
name|blockRange
parameter_list|(
name|long
name|startOffset
parameter_list|,
name|long
name|endOffset
parameter_list|)
function_decl|;
block|}
comment|/**    * A common implementation of some methods of {@link FSReader} and some    * tools for implementing HFile format version-specific block readers.    */
specifier|public
specifier|abstract
specifier|static
class|class
name|AbstractFSReader
implements|implements
name|FSReader
block|{
comment|/** The file system stream of the underlying {@link HFile} */
specifier|protected
name|FSDataInputStream
name|istream
decl_stmt|;
comment|/** Compression algorithm used by the {@link HFile} */
specifier|protected
name|Compression
operator|.
name|Algorithm
name|compressAlgo
decl_stmt|;
comment|/** The size of the file we are reading from, or -1 if unknown. */
specifier|protected
name|long
name|fileSize
decl_stmt|;
comment|/** The default buffer size for our buffered streams */
specifier|public
specifier|static
specifier|final
name|int
name|DEFAULT_BUFFER_SIZE
init|=
literal|1
operator|<<
literal|20
decl_stmt|;
specifier|public
name|AbstractFSReader
parameter_list|(
name|FSDataInputStream
name|istream
parameter_list|,
name|Algorithm
name|compressAlgo
parameter_list|,
name|long
name|fileSize
parameter_list|)
block|{
name|this
operator|.
name|istream
operator|=
name|istream
expr_stmt|;
name|this
operator|.
name|compressAlgo
operator|=
name|compressAlgo
expr_stmt|;
name|this
operator|.
name|fileSize
operator|=
name|fileSize
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|BlockIterator
name|blockRange
parameter_list|(
specifier|final
name|long
name|startOffset
parameter_list|,
specifier|final
name|long
name|endOffset
parameter_list|)
block|{
return|return
operator|new
name|BlockIterator
argument_list|()
block|{
specifier|private
name|long
name|offset
init|=
name|startOffset
decl_stmt|;
annotation|@
name|Override
specifier|public
name|HFileBlock
name|nextBlock
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|offset
operator|>=
name|endOffset
condition|)
return|return
literal|null
return|;
name|HFileBlock
name|b
init|=
name|readBlockData
argument_list|(
name|offset
argument_list|,
operator|-
literal|1
argument_list|,
operator|-
literal|1
argument_list|,
literal|false
argument_list|)
decl_stmt|;
name|offset
operator|+=
name|b
operator|.
name|getOnDiskSizeWithHeader
argument_list|()
expr_stmt|;
return|return
name|b
return|;
block|}
annotation|@
name|Override
specifier|public
name|DataInputStream
name|nextBlockAsStream
parameter_list|(
name|BlockType
name|blockType
parameter_list|)
throws|throws
name|IOException
block|{
name|HFileBlock
name|blk
init|=
name|nextBlock
argument_list|()
decl_stmt|;
if|if
condition|(
name|blk
operator|.
name|getBlockType
argument_list|()
operator|!=
name|blockType
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Expected block of type "
operator|+
name|blockType
operator|+
literal|" but found "
operator|+
name|blk
operator|.
name|getBlockType
argument_list|()
argument_list|)
throw|;
block|}
return|return
name|blk
operator|.
name|getByteStream
argument_list|()
return|;
block|}
block|}
return|;
block|}
comment|/**      * Does a positional read or a seek and read into the given buffer. Returns      * the on-disk size of the next block, or -1 if it could not be determined.      *      * @param dest destination buffer      * @param destOffset offset in the destination buffer      * @param size size of the block to be read      * @param peekIntoNextBlock whether to read the next block's on-disk size      * @param fileOffset position in the stream to read at      * @param pread whether we should do a positional read      * @return the on-disk size of the next block with header size included, or      *         -1 if it could not be determined      * @throws IOException      */
specifier|protected
name|int
name|readAtOffset
parameter_list|(
name|byte
index|[]
name|dest
parameter_list|,
name|int
name|destOffset
parameter_list|,
name|int
name|size
parameter_list|,
name|boolean
name|peekIntoNextBlock
parameter_list|,
name|long
name|fileOffset
parameter_list|,
name|boolean
name|pread
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|peekIntoNextBlock
operator|&&
name|destOffset
operator|+
name|size
operator|+
name|HEADER_SIZE
operator|>
name|dest
operator|.
name|length
condition|)
block|{
comment|// We are asked to read the next block's header as well, but there is
comment|// not enough room in the array.
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Attempted to read "
operator|+
name|size
operator|+
literal|" bytes and "
operator|+
name|HEADER_SIZE
operator|+
literal|" bytes of next header into a "
operator|+
name|dest
operator|.
name|length
operator|+
literal|"-byte array at offset "
operator|+
name|destOffset
argument_list|)
throw|;
block|}
if|if
condition|(
name|pread
condition|)
block|{
comment|// Positional read. Better for random reads.
name|int
name|extraSize
init|=
name|peekIntoNextBlock
condition|?
name|HEADER_SIZE
else|:
literal|0
decl_stmt|;
name|int
name|ret
init|=
name|istream
operator|.
name|read
argument_list|(
name|fileOffset
argument_list|,
name|dest
argument_list|,
name|destOffset
argument_list|,
name|size
operator|+
name|extraSize
argument_list|)
decl_stmt|;
if|if
condition|(
name|ret
operator|<
name|size
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Positional read of "
operator|+
name|size
operator|+
literal|" bytes "
operator|+
literal|"failed at offset "
operator|+
name|fileOffset
operator|+
literal|" (returned "
operator|+
name|ret
operator|+
literal|")"
argument_list|)
throw|;
block|}
if|if
condition|(
name|ret
operator|==
name|size
operator|||
name|ret
operator|<
name|size
operator|+
name|extraSize
condition|)
block|{
comment|// Could not read the next block's header, or did not try.
return|return
operator|-
literal|1
return|;
block|}
block|}
else|else
block|{
comment|// Seek + read. Better for scanning.
synchronized|synchronized
init|(
name|istream
init|)
block|{
name|istream
operator|.
name|seek
argument_list|(
name|fileOffset
argument_list|)
expr_stmt|;
name|long
name|realOffset
init|=
name|istream
operator|.
name|getPos
argument_list|()
decl_stmt|;
if|if
condition|(
name|realOffset
operator|!=
name|fileOffset
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Tried to seek to "
operator|+
name|fileOffset
operator|+
literal|" to "
operator|+
literal|"read "
operator|+
name|size
operator|+
literal|" bytes, but pos="
operator|+
name|realOffset
operator|+
literal|" after seek"
argument_list|)
throw|;
block|}
if|if
condition|(
operator|!
name|peekIntoNextBlock
condition|)
block|{
name|IOUtils
operator|.
name|readFully
argument_list|(
name|istream
argument_list|,
name|dest
argument_list|,
name|destOffset
argument_list|,
name|size
argument_list|)
expr_stmt|;
return|return
operator|-
literal|1
return|;
block|}
comment|// Try to read the next block header.
if|if
condition|(
operator|!
name|readWithExtra
argument_list|(
name|istream
argument_list|,
name|dest
argument_list|,
name|destOffset
argument_list|,
name|size
argument_list|,
name|HEADER_SIZE
argument_list|)
condition|)
return|return
operator|-
literal|1
return|;
block|}
block|}
assert|assert
name|peekIntoNextBlock
assert|;
return|return
name|Bytes
operator|.
name|toInt
argument_list|(
name|dest
argument_list|,
name|destOffset
operator|+
name|size
operator|+
name|BlockType
operator|.
name|MAGIC_LENGTH
argument_list|)
operator|+
name|HEADER_SIZE
return|;
block|}
comment|/**      * Decompresses data from the given stream using the configured compression      * algorithm.      *      * @param boundedStream      *          a stream to read compressed data from, bounded to the exact      *          amount of compressed data      * @param compressedSize      *          compressed data size, header not included      * @param uncompressedSize      *          uncompressed data size, header not included      * @param header      *          the header to include before the decompressed data, or null.      *          Only the first {@link HFileBlock#HEADER_SIZE} bytes of the      *          buffer are included.      * @return the byte buffer containing the given header (optionally) and the      *         decompressed data      * @throws IOException      */
specifier|protected
name|void
name|decompress
parameter_list|(
name|byte
index|[]
name|dest
parameter_list|,
name|int
name|destOffset
parameter_list|,
name|InputStream
name|bufferedBoundedStream
parameter_list|,
name|int
name|compressedSize
parameter_list|,
name|int
name|uncompressedSize
parameter_list|)
throws|throws
name|IOException
block|{
name|Decompressor
name|decompressor
init|=
literal|null
decl_stmt|;
try|try
block|{
name|decompressor
operator|=
name|compressAlgo
operator|.
name|getDecompressor
argument_list|()
expr_stmt|;
name|InputStream
name|is
init|=
name|compressAlgo
operator|.
name|createDecompressionStream
argument_list|(
name|bufferedBoundedStream
argument_list|,
name|decompressor
argument_list|,
literal|0
argument_list|)
decl_stmt|;
name|IOUtils
operator|.
name|readFully
argument_list|(
name|is
argument_list|,
name|dest
argument_list|,
name|destOffset
argument_list|,
name|uncompressedSize
argument_list|)
expr_stmt|;
name|is
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
finally|finally
block|{
if|if
condition|(
name|decompressor
operator|!=
literal|null
condition|)
block|{
name|compressAlgo
operator|.
name|returnDecompressor
argument_list|(
name|decompressor
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|/**      * Creates a buffered stream reading a certain slice of the file system      * input stream. We need this because the decompression we use seems to      * expect the input stream to be bounded.      *      * @param offset the starting file offset the bounded stream reads from      * @param size the size of the segment of the file the stream should read      * @param pread whether to use position reads      * @return a stream restricted to the given portion of the file      */
specifier|protected
name|InputStream
name|createBufferedBoundedStream
parameter_list|(
name|long
name|offset
parameter_list|,
name|int
name|size
parameter_list|,
name|boolean
name|pread
parameter_list|)
block|{
return|return
operator|new
name|BufferedInputStream
argument_list|(
operator|new
name|BoundedRangeFileInputStream
argument_list|(
name|istream
argument_list|,
name|offset
argument_list|,
name|size
argument_list|,
name|pread
argument_list|)
argument_list|,
name|Math
operator|.
name|min
argument_list|(
name|DEFAULT_BUFFER_SIZE
argument_list|,
name|size
argument_list|)
argument_list|)
return|;
block|}
block|}
comment|/**    * Reads version 1 blocks from the file system. In version 1 blocks,    * everything is compressed, including the magic record, if compression is    * enabled. Everything might be uncompressed if no compression is used. This    * reader returns blocks represented in the uniform version 2 format in    * memory.    */
specifier|public
specifier|static
class|class
name|FSReaderV1
extends|extends
name|AbstractFSReader
block|{
comment|/** Header size difference between version 1 and 2 */
specifier|private
specifier|static
specifier|final
name|int
name|HEADER_DELTA
init|=
name|HEADER_SIZE
operator|-
name|MAGIC_LENGTH
decl_stmt|;
specifier|public
name|FSReaderV1
parameter_list|(
name|FSDataInputStream
name|istream
parameter_list|,
name|Algorithm
name|compressAlgo
parameter_list|,
name|long
name|fileSize
parameter_list|)
block|{
name|super
argument_list|(
name|istream
argument_list|,
name|compressAlgo
argument_list|,
name|fileSize
argument_list|)
expr_stmt|;
block|}
comment|/**      * Read a version 1 block. There is no uncompressed header, and the block      * type (the magic record) is part of the compressed data. This      * implementation assumes that the bounded range file input stream is      * needed to stop the decompressor reading into next block, because the      * decompressor just grabs a bunch of data without regard to whether it is      * coming to end of the compressed section.      *      * The block returned is still a version 2 block, and in particular, its      * first {@link #HEADER_SIZE} bytes contain a valid version 2 header.      *      * @param offset the offset of the block to read in the file      * @param onDiskSizeWithMagic the on-disk size of the version 1 block,      *          including the magic record, which is the part of compressed      *          data if using compression      * @param uncompressedSizeWithMagic uncompressed size of the version 1      *          block, including the magic record      */
annotation|@
name|Override
specifier|public
name|HFileBlock
name|readBlockData
parameter_list|(
name|long
name|offset
parameter_list|,
name|long
name|onDiskSizeWithMagic
parameter_list|,
name|int
name|uncompressedSizeWithMagic
parameter_list|,
name|boolean
name|pread
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|uncompressedSizeWithMagic
operator|<=
literal|0
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Invalid uncompressedSize="
operator|+
name|uncompressedSizeWithMagic
operator|+
literal|" for a version 1 block"
argument_list|)
throw|;
block|}
if|if
condition|(
name|onDiskSizeWithMagic
operator|<=
literal|0
operator|||
name|onDiskSizeWithMagic
operator|>=
name|Integer
operator|.
name|MAX_VALUE
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Invalid onDiskSize="
operator|+
name|onDiskSizeWithMagic
operator|+
literal|" (maximum allowed: "
operator|+
name|Integer
operator|.
name|MAX_VALUE
operator|+
literal|")"
argument_list|)
throw|;
block|}
name|int
name|onDiskSize
init|=
operator|(
name|int
operator|)
name|onDiskSizeWithMagic
decl_stmt|;
if|if
condition|(
name|uncompressedSizeWithMagic
operator|<
name|MAGIC_LENGTH
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Uncompressed size for a version 1 block is "
operator|+
name|uncompressedSizeWithMagic
operator|+
literal|" but must be at least "
operator|+
name|MAGIC_LENGTH
argument_list|)
throw|;
block|}
comment|// The existing size already includes magic size, and we are inserting
comment|// a version 2 header.
name|ByteBuffer
name|buf
init|=
name|ByteBuffer
operator|.
name|allocate
argument_list|(
name|uncompressedSizeWithMagic
operator|+
name|HEADER_DELTA
argument_list|)
decl_stmt|;
name|int
name|onDiskSizeWithoutHeader
decl_stmt|;
if|if
condition|(
name|compressAlgo
operator|==
name|Compression
operator|.
name|Algorithm
operator|.
name|NONE
condition|)
block|{
comment|// A special case when there is no compression.
if|if
condition|(
name|onDiskSize
operator|!=
name|uncompressedSizeWithMagic
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"onDiskSize="
operator|+
name|onDiskSize
operator|+
literal|" and uncompressedSize="
operator|+
name|uncompressedSizeWithMagic
operator|+
literal|" must be equal for version 1 with no compression"
argument_list|)
throw|;
block|}
comment|// The first MAGIC_LENGTH bytes of what this will read will be
comment|// overwritten.
name|readAtOffset
argument_list|(
name|buf
operator|.
name|array
argument_list|()
argument_list|,
name|buf
operator|.
name|arrayOffset
argument_list|()
operator|+
name|HEADER_DELTA
argument_list|,
name|onDiskSize
argument_list|,
literal|false
argument_list|,
name|offset
argument_list|,
name|pread
argument_list|)
expr_stmt|;
name|onDiskSizeWithoutHeader
operator|=
name|uncompressedSizeWithMagic
operator|-
name|MAGIC_LENGTH
expr_stmt|;
block|}
else|else
block|{
name|InputStream
name|bufferedBoundedStream
init|=
name|createBufferedBoundedStream
argument_list|(
name|offset
argument_list|,
name|onDiskSize
argument_list|,
name|pread
argument_list|)
decl_stmt|;
name|decompress
argument_list|(
name|buf
operator|.
name|array
argument_list|()
argument_list|,
name|buf
operator|.
name|arrayOffset
argument_list|()
operator|+
name|HEADER_DELTA
argument_list|,
name|bufferedBoundedStream
argument_list|,
name|onDiskSize
argument_list|,
name|uncompressedSizeWithMagic
argument_list|)
expr_stmt|;
comment|// We don't really have a good way to exclude the "magic record" size
comment|// from the compressed block's size, since it is compressed as well.
name|onDiskSizeWithoutHeader
operator|=
name|onDiskSize
expr_stmt|;
block|}
name|BlockType
name|newBlockType
init|=
name|BlockType
operator|.
name|parse
argument_list|(
name|buf
operator|.
name|array
argument_list|()
argument_list|,
name|buf
operator|.
name|arrayOffset
argument_list|()
operator|+
name|HEADER_DELTA
argument_list|,
name|MAGIC_LENGTH
argument_list|)
decl_stmt|;
comment|// We set the uncompressed size of the new HFile block we are creating
comment|// to the size of the data portion of the block without the magic record,
comment|// since the magic record gets moved to the header.
name|HFileBlock
name|b
init|=
operator|new
name|HFileBlock
argument_list|(
name|newBlockType
argument_list|,
name|onDiskSizeWithoutHeader
argument_list|,
name|uncompressedSizeWithMagic
operator|-
name|MAGIC_LENGTH
argument_list|,
operator|-
literal|1L
argument_list|,
name|buf
argument_list|,
literal|true
argument_list|,
name|offset
argument_list|)
decl_stmt|;
return|return
name|b
return|;
block|}
block|}
comment|/**    * We always prefetch the header of the next block, so that we know its    * on-disk size in advance and can read it in one operation.    */
specifier|private
specifier|static
class|class
name|PrefetchedHeader
block|{
name|long
name|offset
init|=
operator|-
literal|1
decl_stmt|;
name|byte
index|[]
name|header
init|=
operator|new
name|byte
index|[
name|HEADER_SIZE
index|]
decl_stmt|;
name|ByteBuffer
name|buf
init|=
name|ByteBuffer
operator|.
name|wrap
argument_list|(
name|header
argument_list|,
literal|0
argument_list|,
name|HEADER_SIZE
argument_list|)
decl_stmt|;
block|}
comment|/** Reads version 2 blocks from the filesystem. */
specifier|public
specifier|static
class|class
name|FSReaderV2
extends|extends
name|AbstractFSReader
block|{
specifier|private
name|ThreadLocal
argument_list|<
name|PrefetchedHeader
argument_list|>
name|prefetchedHeaderForThread
init|=
operator|new
name|ThreadLocal
argument_list|<
name|PrefetchedHeader
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|PrefetchedHeader
name|initialValue
parameter_list|()
block|{
return|return
operator|new
name|PrefetchedHeader
argument_list|()
return|;
block|}
block|}
decl_stmt|;
specifier|public
name|FSReaderV2
parameter_list|(
name|FSDataInputStream
name|istream
parameter_list|,
name|Algorithm
name|compressAlgo
parameter_list|,
name|long
name|fileSize
parameter_list|)
block|{
name|super
argument_list|(
name|istream
argument_list|,
name|compressAlgo
argument_list|,
name|fileSize
argument_list|)
expr_stmt|;
block|}
comment|/**      * Reads a version 2 block. Tries to do as little memory allocation as      * possible, using the provided on-disk size.      *      * @param offset the offset in the stream to read at      * @param onDiskSizeWithHeaderL the on-disk size of the block, including      *          the header, or -1 if unknown      * @param uncompressedSize the uncompressed size of the the block. Always      *          expected to be -1. This parameter is only used in version 1.      * @param pread whether to use a positional read      */
annotation|@
name|Override
specifier|public
name|HFileBlock
name|readBlockData
parameter_list|(
name|long
name|offset
parameter_list|,
name|long
name|onDiskSizeWithHeaderL
parameter_list|,
name|int
name|uncompressedSize
parameter_list|,
name|boolean
name|pread
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|offset
operator|<
literal|0
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Invalid offset="
operator|+
name|offset
operator|+
literal|" trying to read "
operator|+
literal|"block (onDiskSize="
operator|+
name|onDiskSizeWithHeaderL
operator|+
literal|", uncompressedSize="
operator|+
name|uncompressedSize
operator|+
literal|")"
argument_list|)
throw|;
block|}
if|if
condition|(
name|uncompressedSize
operator|!=
operator|-
literal|1
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Version 2 block reader API does not need "
operator|+
literal|"the uncompressed size parameter"
argument_list|)
throw|;
block|}
if|if
condition|(
operator|(
name|onDiskSizeWithHeaderL
operator|<
name|HEADER_SIZE
operator|&&
name|onDiskSizeWithHeaderL
operator|!=
operator|-
literal|1
operator|)
operator|||
name|onDiskSizeWithHeaderL
operator|>=
name|Integer
operator|.
name|MAX_VALUE
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Invalid onDisksize="
operator|+
name|onDiskSizeWithHeaderL
operator|+
literal|": expected to be at least "
operator|+
name|HEADER_SIZE
operator|+
literal|" and at most "
operator|+
name|Integer
operator|.
name|MAX_VALUE
operator|+
literal|", or -1 (offset="
operator|+
name|offset
operator|+
literal|", uncompressedSize="
operator|+
name|uncompressedSize
operator|+
literal|")"
argument_list|)
throw|;
block|}
name|int
name|onDiskSizeWithHeader
init|=
operator|(
name|int
operator|)
name|onDiskSizeWithHeaderL
decl_stmt|;
name|HFileBlock
name|b
decl_stmt|;
if|if
condition|(
name|onDiskSizeWithHeader
operator|>
literal|0
condition|)
block|{
comment|// We know the total on-disk size but not the uncompressed size. Read
comment|// the entire block into memory, then parse the header and decompress
comment|// from memory if using compression. This code path is used when
comment|// doing a random read operation relying on the block index, as well as
comment|// when the client knows the on-disk size from peeking into the next
comment|// block's header (e.g. this block's header) when reading the previous
comment|// block. This is the faster and more preferable case.
name|int
name|onDiskSizeWithoutHeader
init|=
name|onDiskSizeWithHeader
operator|-
name|HEADER_SIZE
decl_stmt|;
assert|assert
name|onDiskSizeWithoutHeader
operator|>=
literal|0
assert|;
comment|// See if we can avoid reading the header. This is desirable, because
comment|// we will not incur a seek operation to seek back if we have already
comment|// read this block's header as part of the previous read's look-ahead.
name|PrefetchedHeader
name|prefetchedHeader
init|=
name|prefetchedHeaderForThread
operator|.
name|get
argument_list|()
decl_stmt|;
name|byte
index|[]
name|header
init|=
name|prefetchedHeader
operator|.
name|offset
operator|==
name|offset
condition|?
name|prefetchedHeader
operator|.
name|header
else|:
literal|null
decl_stmt|;
comment|// Size that we have to skip in case we have already read the header.
name|int
name|preReadHeaderSize
init|=
name|header
operator|==
literal|null
condition|?
literal|0
else|:
name|HEADER_SIZE
decl_stmt|;
if|if
condition|(
name|compressAlgo
operator|==
name|Compression
operator|.
name|Algorithm
operator|.
name|NONE
condition|)
block|{
comment|// Just read the whole thing. Allocate enough space to read the
comment|// next block's header too.
name|ByteBuffer
name|headerAndData
init|=
name|ByteBuffer
operator|.
name|allocate
argument_list|(
name|onDiskSizeWithHeader
operator|+
name|HEADER_SIZE
argument_list|)
decl_stmt|;
name|headerAndData
operator|.
name|limit
argument_list|(
name|onDiskSizeWithHeader
argument_list|)
expr_stmt|;
if|if
condition|(
name|header
operator|!=
literal|null
condition|)
block|{
name|System
operator|.
name|arraycopy
argument_list|(
name|header
argument_list|,
literal|0
argument_list|,
name|headerAndData
operator|.
name|array
argument_list|()
argument_list|,
literal|0
argument_list|,
name|HEADER_SIZE
argument_list|)
expr_stmt|;
block|}
name|int
name|nextBlockOnDiskSizeWithHeader
init|=
name|readAtOffset
argument_list|(
name|headerAndData
operator|.
name|array
argument_list|()
argument_list|,
name|headerAndData
operator|.
name|arrayOffset
argument_list|()
operator|+
name|preReadHeaderSize
argument_list|,
name|onDiskSizeWithHeader
operator|-
name|preReadHeaderSize
argument_list|,
literal|true
argument_list|,
name|offset
operator|+
name|preReadHeaderSize
argument_list|,
name|pread
argument_list|)
decl_stmt|;
name|b
operator|=
operator|new
name|HFileBlock
argument_list|(
name|headerAndData
argument_list|)
expr_stmt|;
name|b
operator|.
name|assumeUncompressed
argument_list|()
expr_stmt|;
name|b
operator|.
name|validateOnDiskSizeWithoutHeader
argument_list|(
name|onDiskSizeWithoutHeader
argument_list|)
expr_stmt|;
name|b
operator|.
name|nextBlockOnDiskSizeWithHeader
operator|=
name|nextBlockOnDiskSizeWithHeader
expr_stmt|;
if|if
condition|(
name|b
operator|.
name|nextBlockOnDiskSizeWithHeader
operator|>
literal|0
condition|)
name|setNextBlockHeader
argument_list|(
name|offset
argument_list|,
name|b
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// Allocate enough space to fit the next block's header too.
name|byte
index|[]
name|onDiskBlock
init|=
operator|new
name|byte
index|[
name|onDiskSizeWithHeader
operator|+
name|HEADER_SIZE
index|]
decl_stmt|;
name|int
name|nextBlockOnDiskSize
init|=
name|readAtOffset
argument_list|(
name|onDiskBlock
argument_list|,
name|preReadHeaderSize
argument_list|,
name|onDiskSizeWithHeader
operator|-
name|preReadHeaderSize
argument_list|,
literal|true
argument_list|,
name|offset
operator|+
name|preReadHeaderSize
argument_list|,
name|pread
argument_list|)
decl_stmt|;
if|if
condition|(
name|header
operator|==
literal|null
condition|)
name|header
operator|=
name|onDiskBlock
expr_stmt|;
try|try
block|{
name|b
operator|=
operator|new
name|HFileBlock
argument_list|(
name|ByteBuffer
operator|.
name|wrap
argument_list|(
name|header
argument_list|,
literal|0
argument_list|,
name|HEADER_SIZE
argument_list|)
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ex
parameter_list|)
block|{
comment|// Seen in load testing. Provide comprehensive debug info.
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Failed to read compressed block at "
operator|+
name|offset
operator|+
literal|", onDiskSizeWithoutHeader="
operator|+
name|onDiskSizeWithHeader
operator|+
literal|", preReadHeaderSize="
operator|+
name|preReadHeaderSize
operator|+
literal|", header.length="
operator|+
name|header
operator|.
name|length
operator|+
literal|", header bytes: "
operator|+
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|header
argument_list|,
literal|0
argument_list|,
name|HEADER_SIZE
argument_list|)
argument_list|,
name|ex
argument_list|)
throw|;
block|}
name|b
operator|.
name|validateOnDiskSizeWithoutHeader
argument_list|(
name|onDiskSizeWithoutHeader
argument_list|)
expr_stmt|;
name|b
operator|.
name|nextBlockOnDiskSizeWithHeader
operator|=
name|nextBlockOnDiskSize
expr_stmt|;
name|DataInputStream
name|dis
init|=
operator|new
name|DataInputStream
argument_list|(
operator|new
name|ByteArrayInputStream
argument_list|(
name|onDiskBlock
argument_list|,
name|HEADER_SIZE
argument_list|,
name|onDiskSizeWithoutHeader
argument_list|)
argument_list|)
decl_stmt|;
comment|// This will allocate a new buffer but keep header bytes.
name|b
operator|.
name|allocateBuffer
argument_list|(
name|b
operator|.
name|nextBlockOnDiskSizeWithHeader
operator|>
literal|0
argument_list|)
expr_stmt|;
name|decompress
argument_list|(
name|b
operator|.
name|buf
operator|.
name|array
argument_list|()
argument_list|,
name|b
operator|.
name|buf
operator|.
name|arrayOffset
argument_list|()
operator|+
name|HEADER_SIZE
argument_list|,
name|dis
argument_list|,
name|onDiskSizeWithoutHeader
argument_list|,
name|b
operator|.
name|uncompressedSizeWithoutHeader
argument_list|)
expr_stmt|;
comment|// Copy next block's header bytes into the new block if we have them.
if|if
condition|(
name|nextBlockOnDiskSize
operator|>
literal|0
condition|)
block|{
name|System
operator|.
name|arraycopy
argument_list|(
name|onDiskBlock
argument_list|,
name|onDiskSizeWithHeader
argument_list|,
name|b
operator|.
name|buf
operator|.
name|array
argument_list|()
argument_list|,
name|b
operator|.
name|buf
operator|.
name|arrayOffset
argument_list|()
operator|+
name|HEADER_SIZE
operator|+
name|b
operator|.
name|uncompressedSizeWithoutHeader
argument_list|,
name|HEADER_SIZE
argument_list|)
expr_stmt|;
name|setNextBlockHeader
argument_list|(
name|offset
argument_list|,
name|b
argument_list|)
expr_stmt|;
block|}
block|}
block|}
else|else
block|{
comment|// We don't know the on-disk size. Read the header first, determine the
comment|// on-disk size from it, and read the remaining data, thereby incurring
comment|// two read operations. This might happen when we are doing the first
comment|// read in a series of reads or a random read, and we don't have access
comment|// to the block index. This is costly and should happen very rarely.
comment|// Check if we have read this block's header as part of reading the
comment|// previous block. If so, don't read the header again.
name|PrefetchedHeader
name|prefetchedHeader
init|=
name|prefetchedHeaderForThread
operator|.
name|get
argument_list|()
decl_stmt|;
name|ByteBuffer
name|headerBuf
init|=
name|prefetchedHeader
operator|.
name|offset
operator|==
name|offset
condition|?
name|prefetchedHeader
operator|.
name|buf
else|:
literal|null
decl_stmt|;
if|if
condition|(
name|headerBuf
operator|==
literal|null
condition|)
block|{
comment|// Unfortunately, we still have to do a separate read operation to
comment|// read the header.
name|headerBuf
operator|=
name|ByteBuffer
operator|.
name|allocate
argument_list|(
name|HEADER_SIZE
argument_list|)
expr_stmt|;
empty_stmt|;
name|readAtOffset
argument_list|(
name|headerBuf
operator|.
name|array
argument_list|()
argument_list|,
name|headerBuf
operator|.
name|arrayOffset
argument_list|()
argument_list|,
name|HEADER_SIZE
argument_list|,
literal|false
argument_list|,
name|offset
argument_list|,
name|pread
argument_list|)
expr_stmt|;
block|}
name|b
operator|=
operator|new
name|HFileBlock
argument_list|(
name|headerBuf
argument_list|)
expr_stmt|;
comment|// This will also allocate enough room for the next block's header.
name|b
operator|.
name|allocateBuffer
argument_list|(
literal|true
argument_list|)
expr_stmt|;
if|if
condition|(
name|compressAlgo
operator|==
name|Compression
operator|.
name|Algorithm
operator|.
name|NONE
condition|)
block|{
comment|// Avoid creating bounded streams and using a "codec" that does
comment|// nothing.
name|b
operator|.
name|assumeUncompressed
argument_list|()
expr_stmt|;
name|b
operator|.
name|nextBlockOnDiskSizeWithHeader
operator|=
name|readAtOffset
argument_list|(
name|b
operator|.
name|buf
operator|.
name|array
argument_list|()
argument_list|,
name|b
operator|.
name|buf
operator|.
name|arrayOffset
argument_list|()
operator|+
name|HEADER_SIZE
argument_list|,
name|b
operator|.
name|uncompressedSizeWithoutHeader
argument_list|,
literal|true
argument_list|,
name|offset
operator|+
name|HEADER_SIZE
argument_list|,
name|pread
argument_list|)
expr_stmt|;
if|if
condition|(
name|b
operator|.
name|nextBlockOnDiskSizeWithHeader
operator|>
literal|0
condition|)
block|{
name|setNextBlockHeader
argument_list|(
name|offset
argument_list|,
name|b
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
comment|// Allocate enough space for the block's header and compressed data.
name|byte
index|[]
name|compressedBytes
init|=
operator|new
name|byte
index|[
name|b
operator|.
name|getOnDiskSizeWithHeader
argument_list|()
operator|+
name|HEADER_SIZE
index|]
decl_stmt|;
name|b
operator|.
name|nextBlockOnDiskSizeWithHeader
operator|=
name|readAtOffset
argument_list|(
name|compressedBytes
argument_list|,
name|HEADER_SIZE
argument_list|,
name|b
operator|.
name|onDiskSizeWithoutHeader
argument_list|,
literal|true
argument_list|,
name|offset
operator|+
name|HEADER_SIZE
argument_list|,
name|pread
argument_list|)
expr_stmt|;
name|DataInputStream
name|dis
init|=
operator|new
name|DataInputStream
argument_list|(
operator|new
name|ByteArrayInputStream
argument_list|(
name|compressedBytes
argument_list|,
name|HEADER_SIZE
argument_list|,
name|b
operator|.
name|onDiskSizeWithoutHeader
argument_list|)
argument_list|)
decl_stmt|;
name|decompress
argument_list|(
name|b
operator|.
name|buf
operator|.
name|array
argument_list|()
argument_list|,
name|b
operator|.
name|buf
operator|.
name|arrayOffset
argument_list|()
operator|+
name|HEADER_SIZE
argument_list|,
name|dis
argument_list|,
name|b
operator|.
name|onDiskSizeWithoutHeader
argument_list|,
name|b
operator|.
name|uncompressedSizeWithoutHeader
argument_list|)
expr_stmt|;
if|if
condition|(
name|b
operator|.
name|nextBlockOnDiskSizeWithHeader
operator|>
literal|0
condition|)
block|{
comment|// Copy the next block's header into the new block.
name|int
name|nextHeaderOffset
init|=
name|b
operator|.
name|buf
operator|.
name|arrayOffset
argument_list|()
operator|+
name|HEADER_SIZE
operator|+
name|b
operator|.
name|uncompressedSizeWithoutHeader
decl_stmt|;
name|System
operator|.
name|arraycopy
argument_list|(
name|compressedBytes
argument_list|,
name|compressedBytes
operator|.
name|length
operator|-
name|HEADER_SIZE
argument_list|,
name|b
operator|.
name|buf
operator|.
name|array
argument_list|()
argument_list|,
name|nextHeaderOffset
argument_list|,
name|HEADER_SIZE
argument_list|)
expr_stmt|;
name|setNextBlockHeader
argument_list|(
name|offset
argument_list|,
name|b
argument_list|)
expr_stmt|;
block|}
block|}
block|}
name|b
operator|.
name|offset
operator|=
name|offset
expr_stmt|;
return|return
name|b
return|;
block|}
specifier|private
name|void
name|setNextBlockHeader
parameter_list|(
name|long
name|offset
parameter_list|,
name|HFileBlock
name|b
parameter_list|)
block|{
name|PrefetchedHeader
name|prefetchedHeader
init|=
name|prefetchedHeaderForThread
operator|.
name|get
argument_list|()
decl_stmt|;
name|prefetchedHeader
operator|.
name|offset
operator|=
name|offset
operator|+
name|b
operator|.
name|getOnDiskSizeWithHeader
argument_list|()
expr_stmt|;
name|int
name|nextHeaderOffset
init|=
name|b
operator|.
name|buf
operator|.
name|arrayOffset
argument_list|()
operator|+
name|HEADER_SIZE
operator|+
name|b
operator|.
name|uncompressedSizeWithoutHeader
decl_stmt|;
name|System
operator|.
name|arraycopy
argument_list|(
name|b
operator|.
name|buf
operator|.
name|array
argument_list|()
argument_list|,
name|nextHeaderOffset
argument_list|,
name|prefetchedHeader
operator|.
name|header
argument_list|,
literal|0
argument_list|,
name|HEADER_SIZE
argument_list|)
expr_stmt|;
block|}
block|}
block|}
end_class

end_unit

