begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Copyright 2010 The Apache Software Foundation  *  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|wal
package|;
end_package

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|FSUtils
operator|.
name|recoverFileLease
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|DataInput
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|DataOutput
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|EOFException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|FileNotFoundException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|OutputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|UnsupportedEncodingException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|lang
operator|.
name|reflect
operator|.
name|InvocationTargetException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|lang
operator|.
name|reflect
operator|.
name|Method
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|URLEncoder
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collections
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|LinkedList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|NavigableSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|SortedMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|TreeMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|TreeSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|Callable
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ConcurrentSkipListMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|CopyOnWriteArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ExecutionException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|Executors
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|Future
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ThreadFactory
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ThreadPoolExecutor
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|TimeUnit
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|atomic
operator|.
name|AtomicInteger
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|atomic
operator|.
name|AtomicLong
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|locks
operator|.
name|Condition
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|locks
operator|.
name|Lock
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|locks
operator|.
name|ReentrantLock
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|regex
operator|.
name|Matcher
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|regex
operator|.
name|Pattern
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|Log
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|LogFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileStatus
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|PathFilter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Syncable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HBaseConfiguration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HConstants
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HRegionInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HServerInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HTableDescriptor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|KeyValue
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|RemoteExceptionHandler
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|HRegion
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|Bytes
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|ClassSize
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|FSUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|Threads
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|Writable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|StringUtils
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ThreadFactoryBuilder
import|;
end_import

begin_comment
comment|/**  * HLog stores all the edits to the HStore.  Its the hbase write-ahead-log  * implementation.  *  * It performs logfile-rolling, so external callers are not aware that the  * underlying file is being rolled.  *  *<p>  * There is one HLog per RegionServer.  All edits for all Regions carried by  * a particular RegionServer are entered first in the HLog.  *  *<p>  * Each HRegion is identified by a unique long<code>int</code>. HRegions do  * not need to declare themselves before using the HLog; they simply include  * their HRegion-id in the<code>append</code> or  *<code>completeCacheFlush</code> calls.  *  *<p>  * An HLog consists of multiple on-disk files, which have a chronological order.  * As data is flushed to other (better) on-disk structures, the log becomes  * obsolete. We can destroy all the log messages for a given HRegion-id up to  * the most-recent CACHEFLUSH message from that HRegion.  *  *<p>  * It's only practical to delete entire files. Thus, we delete an entire on-disk  * file F when all of the messages in F have a log-sequence-id that's older  * (smaller) than the most-recent CACHEFLUSH message for every HRegion that has  * a message in F.  *  *<p>  * Synchronized methods can never execute in parallel. However, between the  * start of a cache flush and the completion point, appends are allowed but log  * rolling is not. To prevent log rolling taking place during this period, a  * separate reentrant lock is used.  *  *<p>To read an HLog, call {@link #getReader(org.apache.hadoop.fs.FileSystem,  * org.apache.hadoop.fs.Path, org.apache.hadoop.conf.Configuration)}.  *  */
end_comment

begin_class
specifier|public
class|class
name|HLog
implements|implements
name|Syncable
block|{
specifier|static
specifier|final
name|Log
name|LOG
init|=
name|LogFactory
operator|.
name|getLog
argument_list|(
name|HLog
operator|.
name|class
argument_list|)
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|byte
index|[]
name|METAFAMILY
init|=
name|Bytes
operator|.
name|toBytes
argument_list|(
literal|"METAFAMILY"
argument_list|)
decl_stmt|;
specifier|static
specifier|final
name|byte
index|[]
name|METAROW
init|=
name|Bytes
operator|.
name|toBytes
argument_list|(
literal|"METAROW"
argument_list|)
decl_stmt|;
comment|/*    * Name of directory that holds recovered edits written by the wal log    * splitting code, one per region    */
specifier|private
specifier|static
specifier|final
name|String
name|RECOVERED_EDITS_DIR
init|=
literal|"recovered.edits"
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|Pattern
name|EDITFILES_NAME_PATTERN
init|=
name|Pattern
operator|.
name|compile
argument_list|(
literal|"-?[0-9]+"
argument_list|)
decl_stmt|;
specifier|private
specifier|final
name|FileSystem
name|fs
decl_stmt|;
specifier|private
specifier|final
name|Path
name|dir
decl_stmt|;
specifier|private
specifier|final
name|Configuration
name|conf
decl_stmt|;
comment|// Listeners that are called on WAL events.
specifier|private
name|List
argument_list|<
name|WALObserver
argument_list|>
name|listeners
init|=
operator|new
name|CopyOnWriteArrayList
argument_list|<
name|WALObserver
argument_list|>
argument_list|()
decl_stmt|;
specifier|private
specifier|final
name|long
name|optionalFlushInterval
decl_stmt|;
specifier|private
specifier|final
name|long
name|blocksize
decl_stmt|;
specifier|private
specifier|final
name|int
name|flushlogentries
decl_stmt|;
specifier|private
specifier|final
name|String
name|prefix
decl_stmt|;
specifier|private
specifier|final
name|AtomicInteger
name|unflushedEntries
init|=
operator|new
name|AtomicInteger
argument_list|(
literal|0
argument_list|)
decl_stmt|;
specifier|private
specifier|final
name|Path
name|oldLogDir
decl_stmt|;
specifier|private
specifier|static
name|Class
argument_list|<
name|?
extends|extends
name|Writer
argument_list|>
name|logWriterClass
decl_stmt|;
specifier|private
specifier|static
name|Class
argument_list|<
name|?
extends|extends
name|Reader
argument_list|>
name|logReaderClass
decl_stmt|;
specifier|private
name|OutputStream
name|hdfs_out
decl_stmt|;
comment|// OutputStream associated with the current SequenceFile.writer
specifier|private
name|int
name|initialReplication
decl_stmt|;
comment|// initial replication factor of SequenceFile.writer
specifier|private
name|Method
name|getNumCurrentReplicas
decl_stmt|;
comment|// refers to DFSOutputStream.getNumCurrentReplicas
specifier|final
specifier|static
name|Object
index|[]
name|NO_ARGS
init|=
operator|new
name|Object
index|[]
block|{}
decl_stmt|;
comment|// used to indirectly tell syncFs to force the sync
specifier|private
name|boolean
name|forceSync
init|=
literal|false
decl_stmt|;
specifier|public
interface|interface
name|Reader
block|{
name|void
name|init
parameter_list|(
name|FileSystem
name|fs
parameter_list|,
name|Path
name|path
parameter_list|,
name|Configuration
name|c
parameter_list|)
throws|throws
name|IOException
function_decl|;
name|void
name|close
parameter_list|()
throws|throws
name|IOException
function_decl|;
name|Entry
name|next
parameter_list|()
throws|throws
name|IOException
function_decl|;
name|Entry
name|next
parameter_list|(
name|Entry
name|reuse
parameter_list|)
throws|throws
name|IOException
function_decl|;
name|void
name|seek
parameter_list|(
name|long
name|pos
parameter_list|)
throws|throws
name|IOException
function_decl|;
name|long
name|getPosition
parameter_list|()
throws|throws
name|IOException
function_decl|;
block|}
specifier|public
interface|interface
name|Writer
block|{
name|void
name|init
parameter_list|(
name|FileSystem
name|fs
parameter_list|,
name|Path
name|path
parameter_list|,
name|Configuration
name|c
parameter_list|)
throws|throws
name|IOException
function_decl|;
name|void
name|close
parameter_list|()
throws|throws
name|IOException
function_decl|;
name|void
name|sync
parameter_list|()
throws|throws
name|IOException
function_decl|;
name|void
name|append
parameter_list|(
name|Entry
name|entry
parameter_list|)
throws|throws
name|IOException
function_decl|;
name|long
name|getLength
parameter_list|()
throws|throws
name|IOException
function_decl|;
block|}
comment|/*    * Current log file.    */
name|Writer
name|writer
decl_stmt|;
comment|/*    * Map of all log files but the current one.    */
specifier|final
name|SortedMap
argument_list|<
name|Long
argument_list|,
name|Path
argument_list|>
name|outputfiles
init|=
name|Collections
operator|.
name|synchronizedSortedMap
argument_list|(
operator|new
name|TreeMap
argument_list|<
name|Long
argument_list|,
name|Path
argument_list|>
argument_list|()
argument_list|)
decl_stmt|;
comment|/*    * Map of regions to most recent sequence/edit id in their memstore.    * Key is encoded region name.    */
specifier|private
specifier|final
name|ConcurrentSkipListMap
argument_list|<
name|byte
index|[]
argument_list|,
name|Long
argument_list|>
name|lastSeqWritten
init|=
operator|new
name|ConcurrentSkipListMap
argument_list|<
name|byte
index|[]
argument_list|,
name|Long
argument_list|>
argument_list|(
name|Bytes
operator|.
name|BYTES_COMPARATOR
argument_list|)
decl_stmt|;
specifier|private
specifier|volatile
name|boolean
name|closed
init|=
literal|false
decl_stmt|;
specifier|private
specifier|final
name|AtomicLong
name|logSeqNum
init|=
operator|new
name|AtomicLong
argument_list|(
literal|0
argument_list|)
decl_stmt|;
comment|// The timestamp (in ms) when the log file was created.
specifier|private
specifier|volatile
name|long
name|filenum
init|=
operator|-
literal|1
decl_stmt|;
comment|//number of transactions in the current Hlog.
specifier|private
specifier|final
name|AtomicInteger
name|numEntries
init|=
operator|new
name|AtomicInteger
argument_list|(
literal|0
argument_list|)
decl_stmt|;
comment|// If> than this size, roll the log. This is typically 0.95 times the size
comment|// of the default Hdfs block size.
specifier|private
specifier|final
name|long
name|logrollsize
decl_stmt|;
comment|// This lock prevents starting a log roll during a cache flush.
comment|// synchronized is insufficient because a cache flush spans two method calls.
specifier|private
specifier|final
name|Lock
name|cacheFlushLock
init|=
operator|new
name|ReentrantLock
argument_list|()
decl_stmt|;
comment|// We synchronize on updateLock to prevent updates and to prevent a log roll
comment|// during an update
specifier|private
specifier|final
name|Object
name|updateLock
init|=
operator|new
name|Object
argument_list|()
decl_stmt|;
specifier|private
specifier|final
name|boolean
name|enabled
decl_stmt|;
comment|/*    * If more than this many logs, force flush of oldest region to oldest edit    * goes to disk.  If too many and we crash, then will take forever replaying.    * Keep the number of logs tidy.    */
specifier|private
specifier|final
name|int
name|maxLogs
decl_stmt|;
comment|/**    * Thread that handles group commit    */
specifier|private
specifier|final
name|LogSyncer
name|logSyncerThread
decl_stmt|;
comment|/**    * Pattern used to validate a HLog file name    */
specifier|private
specifier|static
specifier|final
name|Pattern
name|pattern
init|=
name|Pattern
operator|.
name|compile
argument_list|(
literal|".*\\.\\d*"
argument_list|)
decl_stmt|;
specifier|static
name|byte
index|[]
name|COMPLETE_CACHE_FLUSH
decl_stmt|;
static|static
block|{
try|try
block|{
name|COMPLETE_CACHE_FLUSH
operator|=
literal|"HBASE::CACHEFLUSH"
operator|.
name|getBytes
argument_list|(
name|HConstants
operator|.
name|UTF8_ENCODING
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|UnsupportedEncodingException
name|e
parameter_list|)
block|{
assert|assert
operator|(
literal|false
operator|)
assert|;
block|}
block|}
comment|// For measuring latency of writes
specifier|private
specifier|static
specifier|volatile
name|long
name|writeOps
decl_stmt|;
specifier|private
specifier|static
specifier|volatile
name|long
name|writeTime
decl_stmt|;
comment|// For measuring latency of syncs
specifier|private
specifier|static
specifier|volatile
name|long
name|syncOps
decl_stmt|;
specifier|private
specifier|static
specifier|volatile
name|long
name|syncTime
decl_stmt|;
specifier|public
specifier|static
name|long
name|getWriteOps
parameter_list|()
block|{
name|long
name|ret
init|=
name|writeOps
decl_stmt|;
name|writeOps
operator|=
literal|0
expr_stmt|;
return|return
name|ret
return|;
block|}
specifier|public
specifier|static
name|long
name|getWriteTime
parameter_list|()
block|{
name|long
name|ret
init|=
name|writeTime
decl_stmt|;
name|writeTime
operator|=
literal|0
expr_stmt|;
return|return
name|ret
return|;
block|}
specifier|public
specifier|static
name|long
name|getSyncOps
parameter_list|()
block|{
name|long
name|ret
init|=
name|syncOps
decl_stmt|;
name|syncOps
operator|=
literal|0
expr_stmt|;
return|return
name|ret
return|;
block|}
specifier|public
specifier|static
name|long
name|getSyncTime
parameter_list|()
block|{
name|long
name|ret
init|=
name|syncTime
decl_stmt|;
name|syncTime
operator|=
literal|0
expr_stmt|;
return|return
name|ret
return|;
block|}
comment|/**    * Constructor.    *    * @param fs filesystem handle    * @param dir path to where hlogs are stored    * @param oldLogDir path to where hlogs are archived    * @param conf configuration to use    * @throws IOException    */
specifier|public
name|HLog
parameter_list|(
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Path
name|dir
parameter_list|,
specifier|final
name|Path
name|oldLogDir
parameter_list|,
specifier|final
name|Configuration
name|conf
parameter_list|)
throws|throws
name|IOException
block|{
name|this
argument_list|(
name|fs
argument_list|,
name|dir
argument_list|,
name|oldLogDir
argument_list|,
name|conf
argument_list|,
literal|null
argument_list|,
literal|null
argument_list|)
expr_stmt|;
block|}
comment|/**    * Create an edit log at the given<code>dir</code> location.    *    * You should never have to load an existing log. If there is a log at    * startup, it should have already been processed and deleted by the time the    * HLog object is started up.    *    * @param fs filesystem handle    * @param dir path to where hlogs are stored    * @param oldLogDir path to where hlogs are archived    * @param conf configuration to use    * @param listeners Listeners on WAL events. Listeners passed here will    * be registered before we do anything else; e.g. the    * Constructor {@link #rollWriter().    * @param prefix should always be hostname and port in distributed env and    *        it will be URL encoded before being used.    *        If prefix is null, "hlog" will be used    * @throws IOException    */
specifier|public
name|HLog
parameter_list|(
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Path
name|dir
parameter_list|,
specifier|final
name|Path
name|oldLogDir
parameter_list|,
specifier|final
name|Configuration
name|conf
parameter_list|,
specifier|final
name|List
argument_list|<
name|WALObserver
argument_list|>
name|listeners
parameter_list|,
specifier|final
name|String
name|prefix
parameter_list|)
throws|throws
name|IOException
block|{
name|super
argument_list|()
expr_stmt|;
name|this
operator|.
name|fs
operator|=
name|fs
expr_stmt|;
name|this
operator|.
name|dir
operator|=
name|dir
expr_stmt|;
name|this
operator|.
name|conf
operator|=
name|conf
expr_stmt|;
if|if
condition|(
name|listeners
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|WALObserver
name|i
range|:
name|listeners
control|)
block|{
name|registerWALActionsListener
argument_list|(
name|i
argument_list|)
expr_stmt|;
block|}
block|}
name|this
operator|.
name|flushlogentries
operator|=
name|conf
operator|.
name|getInt
argument_list|(
literal|"hbase.regionserver.flushlogentries"
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|this
operator|.
name|blocksize
operator|=
name|conf
operator|.
name|getLong
argument_list|(
literal|"hbase.regionserver.hlog.blocksize"
argument_list|,
name|this
operator|.
name|fs
operator|.
name|getDefaultBlockSize
argument_list|()
argument_list|)
expr_stmt|;
comment|// Roll at 95% of block size.
name|float
name|multi
init|=
name|conf
operator|.
name|getFloat
argument_list|(
literal|"hbase.regionserver.logroll.multiplier"
argument_list|,
literal|0.95f
argument_list|)
decl_stmt|;
name|this
operator|.
name|logrollsize
operator|=
call|(
name|long
call|)
argument_list|(
name|this
operator|.
name|blocksize
operator|*
name|multi
argument_list|)
expr_stmt|;
name|this
operator|.
name|optionalFlushInterval
operator|=
name|conf
operator|.
name|getLong
argument_list|(
literal|"hbase.regionserver.optionallogflushinterval"
argument_list|,
literal|1
operator|*
literal|1000
argument_list|)
expr_stmt|;
if|if
condition|(
name|fs
operator|.
name|exists
argument_list|(
name|dir
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Target HLog directory already exists: "
operator|+
name|dir
argument_list|)
throw|;
block|}
name|fs
operator|.
name|mkdirs
argument_list|(
name|dir
argument_list|)
expr_stmt|;
name|this
operator|.
name|oldLogDir
operator|=
name|oldLogDir
expr_stmt|;
if|if
condition|(
operator|!
name|fs
operator|.
name|exists
argument_list|(
name|oldLogDir
argument_list|)
condition|)
block|{
name|fs
operator|.
name|mkdirs
argument_list|(
name|this
operator|.
name|oldLogDir
argument_list|)
expr_stmt|;
block|}
name|this
operator|.
name|maxLogs
operator|=
name|conf
operator|.
name|getInt
argument_list|(
literal|"hbase.regionserver.maxlogs"
argument_list|,
literal|32
argument_list|)
expr_stmt|;
name|this
operator|.
name|enabled
operator|=
name|conf
operator|.
name|getBoolean
argument_list|(
literal|"hbase.regionserver.hlog.enabled"
argument_list|,
literal|true
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"HLog configuration: blocksize="
operator|+
name|StringUtils
operator|.
name|byteDesc
argument_list|(
name|this
operator|.
name|blocksize
argument_list|)
operator|+
literal|", rollsize="
operator|+
name|StringUtils
operator|.
name|byteDesc
argument_list|(
name|this
operator|.
name|logrollsize
argument_list|)
operator|+
literal|", enabled="
operator|+
name|this
operator|.
name|enabled
operator|+
literal|", flushlogentries="
operator|+
name|this
operator|.
name|flushlogentries
operator|+
literal|", optionallogflushinternal="
operator|+
name|this
operator|.
name|optionalFlushInterval
operator|+
literal|"ms"
argument_list|)
expr_stmt|;
comment|// If prefix is null||empty then just name it hlog
name|this
operator|.
name|prefix
operator|=
name|prefix
operator|==
literal|null
operator|||
name|prefix
operator|.
name|isEmpty
argument_list|()
condition|?
literal|"hlog"
else|:
name|URLEncoder
operator|.
name|encode
argument_list|(
name|prefix
argument_list|,
literal|"UTF8"
argument_list|)
expr_stmt|;
comment|// rollWriter sets this.hdfs_out if it can.
name|rollWriter
argument_list|()
expr_stmt|;
comment|// handle the reflection necessary to call getNumCurrentReplicas()
name|this
operator|.
name|getNumCurrentReplicas
operator|=
literal|null
expr_stmt|;
name|Exception
name|exception
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|this
operator|.
name|hdfs_out
operator|!=
literal|null
condition|)
block|{
try|try
block|{
name|this
operator|.
name|getNumCurrentReplicas
operator|=
name|this
operator|.
name|hdfs_out
operator|.
name|getClass
argument_list|()
operator|.
name|getMethod
argument_list|(
literal|"getNumCurrentReplicas"
argument_list|,
operator|new
name|Class
argument_list|<
name|?
argument_list|>
index|[]
block|{}
block|)
empty_stmt|;
name|this
operator|.
name|getNumCurrentReplicas
operator|.
name|setAccessible
argument_list|(
literal|true
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|NoSuchMethodException
name|e
parameter_list|)
block|{
comment|// Thrown if getNumCurrentReplicas() function isn't available
name|exception
operator|=
name|e
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|SecurityException
name|e
parameter_list|)
block|{
comment|// Thrown if we can't get access to getNumCurrentReplicas()
name|exception
operator|=
name|e
expr_stmt|;
name|this
operator|.
name|getNumCurrentReplicas
operator|=
literal|null
expr_stmt|;
comment|// could happen on setAccessible()
block|}
block|}
if|if
condition|(
name|this
operator|.
name|getNumCurrentReplicas
operator|!=
literal|null
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Using getNumCurrentReplicas--HDFS-826"
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"getNumCurrentReplicas--HDFS-826 not available; hdfs_out="
operator|+
name|this
operator|.
name|hdfs_out
operator|+
literal|", exception="
operator|+
name|exception
operator|.
name|getMessage
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|logSyncerThread
operator|=
operator|new
name|LogSyncer
argument_list|(
name|this
operator|.
name|optionalFlushInterval
argument_list|)
expr_stmt|;
name|Threads
operator|.
name|setDaemonThreadRunning
argument_list|(
name|logSyncerThread
argument_list|,
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|".logSyncer"
argument_list|)
expr_stmt|;
block|}
end_class

begin_function
specifier|public
name|void
name|registerWALActionsListener
parameter_list|(
specifier|final
name|WALObserver
name|listener
parameter_list|)
block|{
name|this
operator|.
name|listeners
operator|.
name|add
argument_list|(
name|listener
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|public
name|boolean
name|unregisterWALActionsListener
parameter_list|(
specifier|final
name|WALObserver
name|listener
parameter_list|)
block|{
return|return
name|this
operator|.
name|listeners
operator|.
name|remove
argument_list|(
name|listener
argument_list|)
return|;
block|}
end_function

begin_comment
comment|/**    * @return Current state of the monotonically increasing file id.    */
end_comment

begin_function
specifier|public
name|long
name|getFilenum
parameter_list|()
block|{
return|return
name|this
operator|.
name|filenum
return|;
block|}
end_function

begin_comment
comment|/**    * Called by HRegionServer when it opens a new region to ensure that log    * sequence numbers are always greater than the latest sequence number of the    * region being brought on-line.    *    * @param newvalue We'll set log edit/sequence number to this value if it    * is greater than the current value.    */
end_comment

begin_function
specifier|public
name|void
name|setSequenceNumber
parameter_list|(
specifier|final
name|long
name|newvalue
parameter_list|)
block|{
for|for
control|(
name|long
name|id
init|=
name|this
operator|.
name|logSeqNum
operator|.
name|get
argument_list|()
init|;
name|id
operator|<
name|newvalue
operator|&&
operator|!
name|this
operator|.
name|logSeqNum
operator|.
name|compareAndSet
argument_list|(
name|id
argument_list|,
name|newvalue
argument_list|)
condition|;
name|id
operator|=
name|this
operator|.
name|logSeqNum
operator|.
name|get
argument_list|()
control|)
block|{
comment|// This could spin on occasion but better the occasional spin than locking
comment|// every increment of sequence number.
name|LOG
operator|.
name|debug
argument_list|(
literal|"Changed sequenceid from "
operator|+
name|logSeqNum
operator|+
literal|" to "
operator|+
name|newvalue
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/**    * @return log sequence number    */
end_comment

begin_function
specifier|public
name|long
name|getSequenceNumber
parameter_list|()
block|{
return|return
name|logSeqNum
operator|.
name|get
argument_list|()
return|;
block|}
end_function

begin_comment
comment|// usage: see TestLogRolling.java
end_comment

begin_function
name|OutputStream
name|getOutputStream
parameter_list|()
block|{
return|return
name|this
operator|.
name|hdfs_out
return|;
block|}
end_function

begin_comment
comment|/**    * Roll the log writer. That is, start writing log messages to a new file.    *    * Because a log cannot be rolled during a cache flush, and a cache flush    * spans two method calls, a special lock needs to be obtained so that a cache    * flush cannot start when the log is being rolled and the log cannot be    * rolled during a cache flush.    *    *<p>Note that this method cannot be synchronized because it is possible that    * startCacheFlush runs, obtaining the cacheFlushLock, then this method could    * start which would obtain the lock on this but block on obtaining the    * cacheFlushLock and then completeCacheFlush could be called which would wait    * for the lock on this and consequently never release the cacheFlushLock    *    * @return If lots of logs, flush the returned regions so next time through    * we can clean logs. Returns null if nothing to flush.  Names are actual    * region names as returned by {@link HRegionInfo#getEncodedName()}    * @throws org.apache.hadoop.hbase.regionserver.wal.FailedLogCloseException    * @throws IOException    */
end_comment

begin_function
specifier|public
name|byte
index|[]
index|[]
name|rollWriter
parameter_list|()
throws|throws
name|FailedLogCloseException
throws|,
name|IOException
block|{
comment|// Return if nothing to flush.
if|if
condition|(
name|this
operator|.
name|writer
operator|!=
literal|null
operator|&&
name|this
operator|.
name|numEntries
operator|.
name|get
argument_list|()
operator|<=
literal|0
condition|)
block|{
return|return
literal|null
return|;
block|}
name|byte
index|[]
index|[]
name|regionsToFlush
init|=
literal|null
decl_stmt|;
name|this
operator|.
name|cacheFlushLock
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
if|if
condition|(
name|closed
condition|)
block|{
return|return
name|regionsToFlush
return|;
block|}
comment|// Do all the preparation outside of the updateLock to block
comment|// as less as possible the incoming writes
name|long
name|currentFilenum
init|=
name|this
operator|.
name|filenum
decl_stmt|;
name|this
operator|.
name|filenum
operator|=
name|System
operator|.
name|currentTimeMillis
argument_list|()
expr_stmt|;
name|Path
name|newPath
init|=
name|computeFilename
argument_list|()
decl_stmt|;
name|HLog
operator|.
name|Writer
name|nextWriter
init|=
name|createWriter
argument_list|(
name|fs
argument_list|,
name|newPath
argument_list|,
name|HBaseConfiguration
operator|.
name|create
argument_list|(
name|conf
argument_list|)
argument_list|)
decl_stmt|;
name|int
name|nextInitialReplication
init|=
name|fs
operator|.
name|getFileStatus
argument_list|(
name|newPath
argument_list|)
operator|.
name|getReplication
argument_list|()
decl_stmt|;
comment|// Can we get at the dfsclient outputstream?  If an instance of
comment|// SFLW, it'll have done the necessary reflection to get at the
comment|// protected field name.
name|OutputStream
name|nextHdfsOut
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|nextWriter
operator|instanceof
name|SequenceFileLogWriter
condition|)
block|{
name|nextHdfsOut
operator|=
operator|(
operator|(
name|SequenceFileLogWriter
operator|)
name|nextWriter
operator|)
operator|.
name|getDFSCOutputStream
argument_list|()
expr_stmt|;
block|}
synchronized|synchronized
init|(
name|updateLock
init|)
block|{
comment|// Clean up current writer.
name|Path
name|oldFile
init|=
name|cleanupCurrentWriter
argument_list|(
name|currentFilenum
argument_list|)
decl_stmt|;
name|this
operator|.
name|writer
operator|=
name|nextWriter
expr_stmt|;
name|this
operator|.
name|initialReplication
operator|=
name|nextInitialReplication
expr_stmt|;
name|this
operator|.
name|hdfs_out
operator|=
name|nextHdfsOut
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
operator|(
name|oldFile
operator|!=
literal|null
condition|?
literal|"Roll "
operator|+
name|FSUtils
operator|.
name|getPath
argument_list|(
name|oldFile
argument_list|)
operator|+
literal|", entries="
operator|+
name|this
operator|.
name|numEntries
operator|.
name|get
argument_list|()
operator|+
literal|", filesize="
operator|+
name|this
operator|.
name|fs
operator|.
name|getFileStatus
argument_list|(
name|oldFile
argument_list|)
operator|.
name|getLen
argument_list|()
operator|+
literal|". "
else|:
literal|""
operator|)
operator|+
literal|"New hlog "
operator|+
name|FSUtils
operator|.
name|getPath
argument_list|(
name|newPath
argument_list|)
argument_list|)
expr_stmt|;
name|this
operator|.
name|numEntries
operator|.
name|set
argument_list|(
literal|0
argument_list|)
expr_stmt|;
block|}
comment|// Tell our listeners that a new log was created
if|if
condition|(
operator|!
name|this
operator|.
name|listeners
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
for|for
control|(
name|WALObserver
name|i
range|:
name|this
operator|.
name|listeners
control|)
block|{
name|i
operator|.
name|logRolled
argument_list|(
name|newPath
argument_list|)
expr_stmt|;
block|}
block|}
comment|// Can we delete any of the old log files?
if|if
condition|(
name|this
operator|.
name|outputfiles
operator|.
name|size
argument_list|()
operator|>
literal|0
condition|)
block|{
if|if
condition|(
name|this
operator|.
name|lastSeqWritten
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Last sequenceid written is empty. Deleting all old hlogs"
argument_list|)
expr_stmt|;
comment|// If so, then no new writes have come in since all regions were
comment|// flushed (and removed from the lastSeqWritten map). Means can
comment|// remove all but currently open log file.
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|Long
argument_list|,
name|Path
argument_list|>
name|e
range|:
name|this
operator|.
name|outputfiles
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|archiveLogFile
argument_list|(
name|e
operator|.
name|getValue
argument_list|()
argument_list|,
name|e
operator|.
name|getKey
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|this
operator|.
name|outputfiles
operator|.
name|clear
argument_list|()
expr_stmt|;
block|}
else|else
block|{
name|regionsToFlush
operator|=
name|cleanOldLogs
argument_list|()
expr_stmt|;
block|}
block|}
block|}
finally|finally
block|{
name|this
operator|.
name|cacheFlushLock
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
return|return
name|regionsToFlush
return|;
block|}
end_function

begin_comment
comment|/**    * Get a reader for the WAL.    * @param fs    * @param path    * @param conf    * @return A WAL reader.  Close when done with it.    * @throws IOException    */
end_comment

begin_function
specifier|public
specifier|static
name|Reader
name|getReader
parameter_list|(
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Path
name|path
parameter_list|,
name|Configuration
name|conf
parameter_list|)
throws|throws
name|IOException
block|{
try|try
block|{
if|if
condition|(
name|logReaderClass
operator|==
literal|null
condition|)
block|{
name|logReaderClass
operator|=
name|conf
operator|.
name|getClass
argument_list|(
literal|"hbase.regionserver.hlog.reader.impl"
argument_list|,
name|SequenceFileLogReader
operator|.
name|class
argument_list|,
name|Reader
operator|.
name|class
argument_list|)
expr_stmt|;
block|}
name|HLog
operator|.
name|Reader
name|reader
init|=
name|logReaderClass
operator|.
name|newInstance
argument_list|()
decl_stmt|;
name|reader
operator|.
name|init
argument_list|(
name|fs
argument_list|,
name|path
argument_list|,
name|conf
argument_list|)
expr_stmt|;
return|return
name|reader
return|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
throw|throw
name|e
throw|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Cannot get log reader"
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
end_function

begin_comment
comment|/**    * Get a writer for the WAL.    * @param path    * @param conf    * @return A WAL writer.  Close when done with it.    * @throws IOException    */
end_comment

begin_function
specifier|public
specifier|static
name|Writer
name|createWriter
parameter_list|(
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Path
name|path
parameter_list|,
name|Configuration
name|conf
parameter_list|)
throws|throws
name|IOException
block|{
try|try
block|{
if|if
condition|(
name|logWriterClass
operator|==
literal|null
condition|)
block|{
name|logWriterClass
operator|=
name|conf
operator|.
name|getClass
argument_list|(
literal|"hbase.regionserver.hlog.writer.impl"
argument_list|,
name|SequenceFileLogWriter
operator|.
name|class
argument_list|,
name|Writer
operator|.
name|class
argument_list|)
expr_stmt|;
block|}
name|HLog
operator|.
name|Writer
name|writer
init|=
operator|(
name|HLog
operator|.
name|Writer
operator|)
name|logWriterClass
operator|.
name|newInstance
argument_list|()
decl_stmt|;
name|writer
operator|.
name|init
argument_list|(
name|fs
argument_list|,
name|path
argument_list|,
name|conf
argument_list|)
expr_stmt|;
return|return
name|writer
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|IOException
name|ie
init|=
operator|new
name|IOException
argument_list|(
literal|"cannot get log writer"
argument_list|)
decl_stmt|;
name|ie
operator|.
name|initCause
argument_list|(
name|e
argument_list|)
expr_stmt|;
throw|throw
name|ie
throw|;
block|}
block|}
end_function

begin_comment
comment|/*    * Clean up old commit logs.    * @return If lots of logs, flush the returned region so next time through    * we can clean logs. Returns null if nothing to flush.  Returns array of    * encoded region names to flush.    * @throws IOException    */
end_comment

begin_function
specifier|private
name|byte
index|[]
index|[]
name|cleanOldLogs
parameter_list|()
throws|throws
name|IOException
block|{
name|Long
name|oldestOutstandingSeqNum
init|=
name|getOldestOutstandingSeqNum
argument_list|()
decl_stmt|;
comment|// Get the set of all log files whose final ID is older than or
comment|// equal to the oldest pending region operation
name|TreeSet
argument_list|<
name|Long
argument_list|>
name|sequenceNumbers
init|=
operator|new
name|TreeSet
argument_list|<
name|Long
argument_list|>
argument_list|(
name|this
operator|.
name|outputfiles
operator|.
name|headMap
argument_list|(
operator|(
name|Long
operator|.
name|valueOf
argument_list|(
name|oldestOutstandingSeqNum
operator|.
name|longValue
argument_list|()
operator|+
literal|1L
argument_list|)
operator|)
argument_list|)
operator|.
name|keySet
argument_list|()
argument_list|)
decl_stmt|;
comment|// Now remove old log files (if any)
name|int
name|logsToRemove
init|=
name|sequenceNumbers
operator|.
name|size
argument_list|()
decl_stmt|;
if|if
condition|(
name|logsToRemove
operator|>
literal|0
condition|)
block|{
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
comment|// Find associated region; helps debugging.
name|byte
index|[]
name|oldestRegion
init|=
name|getOldestRegion
argument_list|(
name|oldestOutstandingSeqNum
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Found "
operator|+
name|logsToRemove
operator|+
literal|" hlogs to remove "
operator|+
literal|" out of total "
operator|+
name|this
operator|.
name|outputfiles
operator|.
name|size
argument_list|()
operator|+
literal|"; "
operator|+
literal|"oldest outstanding sequenceid is "
operator|+
name|oldestOutstandingSeqNum
operator|+
literal|" from region "
operator|+
name|Bytes
operator|.
name|toString
argument_list|(
name|oldestRegion
argument_list|)
argument_list|)
expr_stmt|;
block|}
for|for
control|(
name|Long
name|seq
range|:
name|sequenceNumbers
control|)
block|{
name|archiveLogFile
argument_list|(
name|this
operator|.
name|outputfiles
operator|.
name|remove
argument_list|(
name|seq
argument_list|)
argument_list|,
name|seq
argument_list|)
expr_stmt|;
block|}
block|}
comment|// If too many log files, figure which regions we need to flush.
comment|// Array is an array of encoded region names.
name|byte
index|[]
index|[]
name|regions
init|=
literal|null
decl_stmt|;
name|int
name|logCount
init|=
name|this
operator|.
name|outputfiles
operator|.
name|size
argument_list|()
operator|-
name|logsToRemove
decl_stmt|;
if|if
condition|(
name|logCount
operator|>
name|this
operator|.
name|maxLogs
operator|&&
name|this
operator|.
name|outputfiles
operator|!=
literal|null
operator|&&
name|this
operator|.
name|outputfiles
operator|.
name|size
argument_list|()
operator|>
literal|0
condition|)
block|{
comment|// This is an array of encoded region names.
name|regions
operator|=
name|findMemstoresWithEditsOlderThan
argument_list|(
name|this
operator|.
name|outputfiles
operator|.
name|firstKey
argument_list|()
argument_list|,
name|this
operator|.
name|lastSeqWritten
argument_list|)
expr_stmt|;
name|StringBuilder
name|sb
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|regions
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|i
operator|>
literal|0
condition|)
name|sb
operator|.
name|append
argument_list|(
literal|", "
argument_list|)
expr_stmt|;
name|sb
operator|.
name|append
argument_list|(
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|regions
index|[
name|i
index|]
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|LOG
operator|.
name|info
argument_list|(
literal|"Too many hlogs: logs="
operator|+
name|logCount
operator|+
literal|", maxlogs="
operator|+
name|this
operator|.
name|maxLogs
operator|+
literal|"; forcing flush of "
operator|+
name|regions
operator|.
name|length
operator|+
literal|" regions(s): "
operator|+
name|sb
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
name|regions
return|;
block|}
end_function

begin_comment
comment|/**    * Return regions (memstores) that have edits that are less than the passed    *<code>oldestWALseqid</code>.    * @param oldestWALseqid    * @param regionsToSeqids    * @return All regions whose seqid is< than<code>oldestWALseqid</code> (Not    * necessarily in order).  Null if no regions found.    */
end_comment

begin_function
specifier|static
name|byte
index|[]
index|[]
name|findMemstoresWithEditsOlderThan
parameter_list|(
specifier|final
name|long
name|oldestWALseqid
parameter_list|,
specifier|final
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|Long
argument_list|>
name|regionsToSeqids
parameter_list|)
block|{
comment|//  This method is static so it can be unit tested the easier.
name|List
argument_list|<
name|byte
index|[]
argument_list|>
name|regions
init|=
literal|null
decl_stmt|;
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|byte
index|[]
argument_list|,
name|Long
argument_list|>
name|e
range|:
name|regionsToSeqids
operator|.
name|entrySet
argument_list|()
control|)
block|{
if|if
condition|(
name|e
operator|.
name|getValue
argument_list|()
operator|.
name|longValue
argument_list|()
operator|<
name|oldestWALseqid
condition|)
block|{
if|if
condition|(
name|regions
operator|==
literal|null
condition|)
name|regions
operator|=
operator|new
name|ArrayList
argument_list|<
name|byte
index|[]
argument_list|>
argument_list|()
expr_stmt|;
name|regions
operator|.
name|add
argument_list|(
name|e
operator|.
name|getKey
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|regions
operator|==
literal|null
condition|?
literal|null
else|:
name|regions
operator|.
name|toArray
argument_list|(
operator|new
name|byte
index|[]
index|[]
block|{
name|HConstants
operator|.
name|EMPTY_BYTE_ARRAY
block|}
argument_list|)
return|;
block|}
end_function

begin_comment
comment|/*    * @return Logs older than this id are safe to remove.    */
end_comment

begin_function
specifier|private
name|Long
name|getOldestOutstandingSeqNum
parameter_list|()
block|{
return|return
name|Collections
operator|.
name|min
argument_list|(
name|this
operator|.
name|lastSeqWritten
operator|.
name|values
argument_list|()
argument_list|)
return|;
block|}
end_function

begin_comment
comment|/**    * @param oldestOutstandingSeqNum    * @return (Encoded) name of oldest outstanding region.    */
end_comment

begin_function
specifier|private
name|byte
index|[]
name|getOldestRegion
parameter_list|(
specifier|final
name|Long
name|oldestOutstandingSeqNum
parameter_list|)
block|{
name|byte
index|[]
name|oldestRegion
init|=
literal|null
decl_stmt|;
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|byte
index|[]
argument_list|,
name|Long
argument_list|>
name|e
range|:
name|this
operator|.
name|lastSeqWritten
operator|.
name|entrySet
argument_list|()
control|)
block|{
if|if
condition|(
name|e
operator|.
name|getValue
argument_list|()
operator|.
name|longValue
argument_list|()
operator|==
name|oldestOutstandingSeqNum
operator|.
name|longValue
argument_list|()
condition|)
block|{
name|oldestRegion
operator|=
name|e
operator|.
name|getKey
argument_list|()
expr_stmt|;
break|break;
block|}
block|}
return|return
name|oldestRegion
return|;
block|}
end_function

begin_comment
comment|/*    * Cleans up current writer closing and adding to outputfiles.    * Presumes we're operating inside an updateLock scope.    * @return Path to current writer or null if none.    * @throws IOException    */
end_comment

begin_function
specifier|private
name|Path
name|cleanupCurrentWriter
parameter_list|(
specifier|final
name|long
name|currentfilenum
parameter_list|)
throws|throws
name|IOException
block|{
name|Path
name|oldFile
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|this
operator|.
name|writer
operator|!=
literal|null
condition|)
block|{
comment|// Close the current writer, get a new one.
try|try
block|{
name|this
operator|.
name|writer
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
comment|// Failed close of log file.  Means we're losing edits.  For now,
comment|// shut ourselves down to minimize loss.  Alternative is to try and
comment|// keep going.  See HBASE-930.
name|FailedLogCloseException
name|flce
init|=
operator|new
name|FailedLogCloseException
argument_list|(
literal|"#"
operator|+
name|currentfilenum
argument_list|)
decl_stmt|;
name|flce
operator|.
name|initCause
argument_list|(
name|e
argument_list|)
expr_stmt|;
throw|throw
name|e
throw|;
block|}
if|if
condition|(
name|currentfilenum
operator|>=
literal|0
condition|)
block|{
name|oldFile
operator|=
name|computeFilename
argument_list|(
name|currentfilenum
argument_list|)
expr_stmt|;
name|this
operator|.
name|outputfiles
operator|.
name|put
argument_list|(
name|Long
operator|.
name|valueOf
argument_list|(
name|this
operator|.
name|logSeqNum
operator|.
name|get
argument_list|()
operator|-
literal|1
argument_list|)
argument_list|,
name|oldFile
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|oldFile
return|;
block|}
end_function

begin_function
specifier|private
name|void
name|archiveLogFile
parameter_list|(
specifier|final
name|Path
name|p
parameter_list|,
specifier|final
name|Long
name|seqno
parameter_list|)
throws|throws
name|IOException
block|{
name|Path
name|newPath
init|=
name|getHLogArchivePath
argument_list|(
name|this
operator|.
name|oldLogDir
argument_list|,
name|p
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"moving old hlog file "
operator|+
name|FSUtils
operator|.
name|getPath
argument_list|(
name|p
argument_list|)
operator|+
literal|" whose highest sequenceid is "
operator|+
name|seqno
operator|+
literal|" to "
operator|+
name|FSUtils
operator|.
name|getPath
argument_list|(
name|newPath
argument_list|)
argument_list|)
expr_stmt|;
name|this
operator|.
name|fs
operator|.
name|rename
argument_list|(
name|p
argument_list|,
name|newPath
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/**    * This is a convenience method that computes a new filename with a given    * using the current HLog file-number    * @return Path    */
end_comment

begin_function
specifier|protected
name|Path
name|computeFilename
parameter_list|()
block|{
return|return
name|computeFilename
argument_list|(
name|this
operator|.
name|filenum
argument_list|)
return|;
block|}
end_function

begin_comment
comment|/**    * This is a convenience method that computes a new filename with a given    * file-number.    * @param file-number to use    * @return Path    */
end_comment

begin_function
specifier|protected
name|Path
name|computeFilename
parameter_list|(
name|long
name|filenum
parameter_list|)
block|{
if|if
condition|(
name|filenum
operator|<
literal|0
condition|)
block|{
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"hlog file number can't be< 0"
argument_list|)
throw|;
block|}
return|return
operator|new
name|Path
argument_list|(
name|dir
argument_list|,
name|prefix
operator|+
literal|"."
operator|+
name|filenum
argument_list|)
return|;
block|}
end_function

begin_comment
comment|/**    * Shut down the log and delete the log directory    *    * @throws IOException    */
end_comment

begin_function
specifier|public
name|void
name|closeAndDelete
parameter_list|()
throws|throws
name|IOException
block|{
name|close
argument_list|()
expr_stmt|;
name|FileStatus
index|[]
name|files
init|=
name|fs
operator|.
name|listStatus
argument_list|(
name|this
operator|.
name|dir
argument_list|)
decl_stmt|;
for|for
control|(
name|FileStatus
name|file
range|:
name|files
control|)
block|{
name|fs
operator|.
name|rename
argument_list|(
name|file
operator|.
name|getPath
argument_list|()
argument_list|,
name|getHLogArchivePath
argument_list|(
name|this
operator|.
name|oldLogDir
argument_list|,
name|file
operator|.
name|getPath
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|LOG
operator|.
name|debug
argument_list|(
literal|"Moved "
operator|+
name|files
operator|.
name|length
operator|+
literal|" log files to "
operator|+
name|FSUtils
operator|.
name|getPath
argument_list|(
name|this
operator|.
name|oldLogDir
argument_list|)
argument_list|)
expr_stmt|;
name|fs
operator|.
name|delete
argument_list|(
name|dir
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/**    * Shut down the log.    *    * @throws IOException    */
end_comment

begin_function
specifier|public
name|void
name|close
parameter_list|()
throws|throws
name|IOException
block|{
try|try
block|{
name|logSyncerThread
operator|.
name|interrupt
argument_list|()
expr_stmt|;
comment|// Make sure we synced everything
name|logSyncerThread
operator|.
name|join
argument_list|(
name|this
operator|.
name|optionalFlushInterval
operator|*
literal|2
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Exception while waiting for syncer thread to die"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
name|cacheFlushLock
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
synchronized|synchronized
init|(
name|updateLock
init|)
block|{
name|this
operator|.
name|closed
operator|=
literal|true
expr_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"closing hlog writer in "
operator|+
name|this
operator|.
name|dir
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|this
operator|.
name|writer
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
block|}
finally|finally
block|{
name|cacheFlushLock
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/** Append an entry to the log.    *    * @param regionInfo    * @param logEdit    * @param now Time of this edit write.    * @throws IOException    */
end_comment

begin_function
specifier|public
name|void
name|append
parameter_list|(
name|HRegionInfo
name|regionInfo
parameter_list|,
name|WALEdit
name|logEdit
parameter_list|,
specifier|final
name|long
name|now
parameter_list|,
specifier|final
name|boolean
name|isMetaRegion
parameter_list|)
throws|throws
name|IOException
block|{
name|byte
index|[]
name|regionName
init|=
name|regionInfo
operator|.
name|getEncodedNameAsBytes
argument_list|()
decl_stmt|;
name|byte
index|[]
name|tableName
init|=
name|regionInfo
operator|.
name|getTableDesc
argument_list|()
operator|.
name|getName
argument_list|()
decl_stmt|;
name|this
operator|.
name|append
argument_list|(
name|regionInfo
argument_list|,
name|makeKey
argument_list|(
name|regionName
argument_list|,
name|tableName
argument_list|,
operator|-
literal|1
argument_list|,
name|now
argument_list|)
argument_list|,
name|logEdit
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/**    * @param now    * @param regionName    * @param tableName    * @return New log key.    */
end_comment

begin_function
specifier|protected
name|HLogKey
name|makeKey
parameter_list|(
name|byte
index|[]
name|regionName
parameter_list|,
name|byte
index|[]
name|tableName
parameter_list|,
name|long
name|seqnum
parameter_list|,
name|long
name|now
parameter_list|)
block|{
return|return
operator|new
name|HLogKey
argument_list|(
name|regionName
argument_list|,
name|tableName
argument_list|,
name|seqnum
argument_list|,
name|now
argument_list|)
return|;
block|}
end_function

begin_comment
comment|/** Append an entry to the log.    *    * @param regionInfo    * @param logEdit    * @param logKey    * @throws IOException    */
end_comment

begin_function
specifier|public
name|void
name|append
parameter_list|(
name|HRegionInfo
name|regionInfo
parameter_list|,
name|HLogKey
name|logKey
parameter_list|,
name|WALEdit
name|logEdit
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|this
operator|.
name|closed
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Cannot append; log is closed"
argument_list|)
throw|;
block|}
synchronized|synchronized
init|(
name|updateLock
init|)
block|{
name|long
name|seqNum
init|=
name|obtainSeqNum
argument_list|()
decl_stmt|;
name|logKey
operator|.
name|setLogSeqNum
argument_list|(
name|seqNum
argument_list|)
expr_stmt|;
comment|// The 'lastSeqWritten' map holds the sequence number of the oldest
comment|// write for each region (i.e. the first edit added to the particular
comment|// memstore). When the cache is flushed, the entry for the
comment|// region being flushed is removed if the sequence number of the flush
comment|// is greater than or equal to the value in lastSeqWritten.
name|this
operator|.
name|lastSeqWritten
operator|.
name|putIfAbsent
argument_list|(
name|regionInfo
operator|.
name|getEncodedNameAsBytes
argument_list|()
argument_list|,
name|Long
operator|.
name|valueOf
argument_list|(
name|seqNum
argument_list|)
argument_list|)
expr_stmt|;
name|doWrite
argument_list|(
name|regionInfo
argument_list|,
name|logKey
argument_list|,
name|logEdit
argument_list|)
expr_stmt|;
name|this
operator|.
name|unflushedEntries
operator|.
name|incrementAndGet
argument_list|()
expr_stmt|;
name|this
operator|.
name|numEntries
operator|.
name|incrementAndGet
argument_list|()
expr_stmt|;
block|}
comment|// sync txn to file system
name|this
operator|.
name|sync
argument_list|(
name|regionInfo
operator|.
name|isMetaRegion
argument_list|()
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/**    * Append a set of edits to the log. Log edits are keyed by (encoded)    * regionName, rowname, and log-sequence-id.    *    * Later, if we sort by these keys, we obtain all the relevant edits for a    * given key-range of the HRegion (TODO). Any edits that do not have a    * matching COMPLETE_CACHEFLUSH message can be discarded.    *    *<p>    * Logs cannot be restarted once closed, or once the HLog process dies. Each    * time the HLog starts, it must create a new log. This means that other    * systems should process the log appropriately upon each startup (and prior    * to initializing HLog).    *    * synchronized prevents appends during the completion of a cache flush or for    * the duration of a log roll.    *    * @param info    * @param tableName    * @param edits    * @param now    * @throws IOException    */
end_comment

begin_function
specifier|public
name|void
name|append
parameter_list|(
name|HRegionInfo
name|info
parameter_list|,
name|byte
index|[]
name|tableName
parameter_list|,
name|WALEdit
name|edits
parameter_list|,
specifier|final
name|long
name|now
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|edits
operator|.
name|isEmpty
argument_list|()
condition|)
return|return;
if|if
condition|(
name|this
operator|.
name|closed
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Cannot append; log is closed"
argument_list|)
throw|;
block|}
synchronized|synchronized
init|(
name|this
operator|.
name|updateLock
init|)
block|{
name|long
name|seqNum
init|=
name|obtainSeqNum
argument_list|()
decl_stmt|;
comment|// The 'lastSeqWritten' map holds the sequence number of the oldest
comment|// write for each region (i.e. the first edit added to the particular
comment|// memstore). . When the cache is flushed, the entry for the
comment|// region being flushed is removed if the sequence number of the flush
comment|// is greater than or equal to the value in lastSeqWritten.
comment|// Use encoded name.  Its shorter, guaranteed unique and a subset of
comment|// actual  name.
name|byte
index|[]
name|hriKey
init|=
name|info
operator|.
name|getEncodedNameAsBytes
argument_list|()
decl_stmt|;
name|this
operator|.
name|lastSeqWritten
operator|.
name|putIfAbsent
argument_list|(
name|hriKey
argument_list|,
name|seqNum
argument_list|)
expr_stmt|;
name|HLogKey
name|logKey
init|=
name|makeKey
argument_list|(
name|hriKey
argument_list|,
name|tableName
argument_list|,
name|seqNum
argument_list|,
name|now
argument_list|)
decl_stmt|;
name|doWrite
argument_list|(
name|info
argument_list|,
name|logKey
argument_list|,
name|edits
argument_list|)
expr_stmt|;
name|this
operator|.
name|numEntries
operator|.
name|incrementAndGet
argument_list|()
expr_stmt|;
comment|// Only count 1 row as an unflushed entry.
name|this
operator|.
name|unflushedEntries
operator|.
name|incrementAndGet
argument_list|()
expr_stmt|;
block|}
comment|// sync txn to file system
name|this
operator|.
name|sync
argument_list|(
name|info
operator|.
name|isMetaRegion
argument_list|()
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/**    * This thread is responsible to call syncFs and buffer up the writers while    * it happens.    */
end_comment

begin_class
class|class
name|LogSyncer
extends|extends
name|Thread
block|{
comment|// Using fairness to make sure locks are given in order
specifier|private
specifier|final
name|ReentrantLock
name|lock
init|=
operator|new
name|ReentrantLock
argument_list|(
literal|true
argument_list|)
decl_stmt|;
comment|// Condition used to wait until we have something to sync
specifier|private
specifier|final
name|Condition
name|queueEmpty
init|=
name|lock
operator|.
name|newCondition
argument_list|()
decl_stmt|;
comment|// Condition used to signal that the sync is done
specifier|private
specifier|final
name|Condition
name|syncDone
init|=
name|lock
operator|.
name|newCondition
argument_list|()
decl_stmt|;
specifier|private
specifier|final
name|long
name|optionalFlushInterval
decl_stmt|;
specifier|private
name|boolean
name|syncerShuttingDown
init|=
literal|false
decl_stmt|;
name|LogSyncer
parameter_list|(
name|long
name|optionalFlushInterval
parameter_list|)
block|{
name|this
operator|.
name|optionalFlushInterval
operator|=
name|optionalFlushInterval
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|run
parameter_list|()
block|{
try|try
block|{
name|lock
operator|.
name|lock
argument_list|()
expr_stmt|;
comment|// awaiting with a timeout doesn't always
comment|// throw exceptions on interrupt
while|while
condition|(
operator|!
name|this
operator|.
name|isInterrupted
argument_list|()
condition|)
block|{
comment|// Wait until something has to be hflushed or do it if we waited
comment|// enough time (useful if something appends but does not hflush).
comment|// 0 or less means that it timed out and maybe waited a bit more.
if|if
condition|(
operator|!
operator|(
name|queueEmpty
operator|.
name|awaitNanos
argument_list|(
name|this
operator|.
name|optionalFlushInterval
operator|*
literal|1000000
argument_list|)
operator|<=
literal|0
operator|)
condition|)
block|{
name|forceSync
operator|=
literal|true
expr_stmt|;
block|}
comment|// We got the signal, let's hflush. We currently own the lock so new
comment|// writes are waiting to acquire it in addToSyncQueue while the ones
comment|// we hflush are waiting on await()
name|hflush
argument_list|()
expr_stmt|;
comment|// Release all the clients waiting on the hflush. Notice that we still
comment|// own the lock until we get back to await at which point all the
comment|// other threads waiting will first acquire and release locks
name|syncDone
operator|.
name|signalAll
argument_list|()
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Error while syncing, requesting close of hlog "
argument_list|,
name|e
argument_list|)
expr_stmt|;
name|requestLogRoll
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
name|getName
argument_list|()
operator|+
literal|" interrupted while waiting for sync requests"
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|syncerShuttingDown
operator|=
literal|true
expr_stmt|;
name|syncDone
operator|.
name|signalAll
argument_list|()
expr_stmt|;
name|lock
operator|.
name|unlock
argument_list|()
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
name|getName
argument_list|()
operator|+
literal|" exiting"
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**      * This method first signals the thread that there's a sync needed      * and then waits for it to happen before returning.      */
specifier|public
name|void
name|addToSyncQueue
parameter_list|(
name|boolean
name|force
parameter_list|)
block|{
comment|// Don't bother if somehow our append was already hflushed
if|if
condition|(
name|unflushedEntries
operator|.
name|get
argument_list|()
operator|==
literal|0
condition|)
block|{
return|return;
block|}
name|lock
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
if|if
condition|(
name|syncerShuttingDown
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
name|getName
argument_list|()
operator|+
literal|" was shut down while waiting for sync"
argument_list|)
expr_stmt|;
return|return;
block|}
if|if
condition|(
name|force
condition|)
block|{
name|forceSync
operator|=
literal|true
expr_stmt|;
block|}
comment|// Wake the thread
name|queueEmpty
operator|.
name|signal
argument_list|()
expr_stmt|;
comment|// Wait for it to hflush
name|syncDone
operator|.
name|await
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
name|getName
argument_list|()
operator|+
literal|" was interrupted while waiting for sync"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|lock
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
block|}
end_class

begin_function
specifier|public
name|void
name|sync
parameter_list|()
block|{
name|sync
argument_list|(
literal|false
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/**    * This method calls the LogSyncer in order to group commit the sync    * with other threads.    * @param force For catalog regions, force the sync to happen    */
end_comment

begin_function
specifier|public
name|void
name|sync
parameter_list|(
name|boolean
name|force
parameter_list|)
block|{
name|logSyncerThread
operator|.
name|addToSyncQueue
argument_list|(
name|force
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|public
name|void
name|hflush
parameter_list|()
throws|throws
name|IOException
block|{
synchronized|synchronized
init|(
name|this
operator|.
name|updateLock
init|)
block|{
if|if
condition|(
name|this
operator|.
name|closed
condition|)
block|{
return|return;
block|}
name|boolean
name|logRollRequested
init|=
literal|false
decl_stmt|;
if|if
condition|(
name|this
operator|.
name|forceSync
operator|||
name|this
operator|.
name|unflushedEntries
operator|.
name|get
argument_list|()
operator|>=
name|this
operator|.
name|flushlogentries
condition|)
block|{
try|try
block|{
name|long
name|now
init|=
name|System
operator|.
name|currentTimeMillis
argument_list|()
decl_stmt|;
name|this
operator|.
name|writer
operator|.
name|sync
argument_list|()
expr_stmt|;
name|syncTime
operator|+=
name|System
operator|.
name|currentTimeMillis
argument_list|()
operator|-
name|now
expr_stmt|;
name|syncOps
operator|++
expr_stmt|;
name|this
operator|.
name|forceSync
operator|=
literal|false
expr_stmt|;
name|this
operator|.
name|unflushedEntries
operator|.
name|set
argument_list|(
literal|0
argument_list|)
expr_stmt|;
comment|// if the number of replicas in HDFS has fallen below the initial
comment|// value, then roll logs.
try|try
block|{
name|int
name|numCurrentReplicas
init|=
name|getLogReplication
argument_list|()
decl_stmt|;
if|if
condition|(
name|numCurrentReplicas
operator|!=
literal|0
operator|&&
name|numCurrentReplicas
operator|<
name|this
operator|.
name|initialReplication
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"HDFS pipeline error detected. "
operator|+
literal|"Found "
operator|+
name|numCurrentReplicas
operator|+
literal|" replicas but expecting "
operator|+
name|this
operator|.
name|initialReplication
operator|+
literal|" replicas. "
operator|+
literal|" Requesting close of hlog."
argument_list|)
expr_stmt|;
name|requestLogRoll
argument_list|()
expr_stmt|;
name|logRollRequested
operator|=
literal|true
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Unable to invoke DFSOutputStream.getNumCurrentReplicas"
operator|+
name|e
operator|+
literal|" still proceeding ahead..."
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|fatal
argument_list|(
literal|"Could not append. Requesting close of hlog"
argument_list|,
name|e
argument_list|)
expr_stmt|;
name|requestLogRoll
argument_list|()
expr_stmt|;
throw|throw
name|e
throw|;
block|}
block|}
if|if
condition|(
operator|!
name|logRollRequested
operator|&&
operator|(
name|this
operator|.
name|writer
operator|.
name|getLength
argument_list|()
operator|>
name|this
operator|.
name|logrollsize
operator|)
condition|)
block|{
name|requestLogRoll
argument_list|()
expr_stmt|;
block|}
block|}
block|}
end_function

begin_comment
comment|/**    * This method gets the datanode replication count for the current HLog.    *    * If the pipeline isn't started yet or is empty, you will get the default    * replication factor.  Therefore, if this function returns 0, it means you    * are not properly running with the HDFS-826 patch.    * @throws InvocationTargetException    * @throws IllegalAccessException    * @throws IllegalArgumentException    *    * @throws Exception    */
end_comment

begin_function
name|int
name|getLogReplication
parameter_list|()
throws|throws
name|IllegalArgumentException
throws|,
name|IllegalAccessException
throws|,
name|InvocationTargetException
block|{
if|if
condition|(
name|this
operator|.
name|getNumCurrentReplicas
operator|!=
literal|null
operator|&&
name|this
operator|.
name|hdfs_out
operator|!=
literal|null
condition|)
block|{
name|Object
name|repl
init|=
name|this
operator|.
name|getNumCurrentReplicas
operator|.
name|invoke
argument_list|(
name|this
operator|.
name|hdfs_out
argument_list|,
name|NO_ARGS
argument_list|)
decl_stmt|;
if|if
condition|(
name|repl
operator|instanceof
name|Integer
condition|)
block|{
return|return
operator|(
operator|(
name|Integer
operator|)
name|repl
operator|)
operator|.
name|intValue
argument_list|()
return|;
block|}
block|}
return|return
literal|0
return|;
block|}
end_function

begin_function
name|boolean
name|canGetCurReplicas
parameter_list|()
block|{
return|return
name|this
operator|.
name|getNumCurrentReplicas
operator|!=
literal|null
return|;
block|}
end_function

begin_function
specifier|public
name|void
name|hsync
parameter_list|()
throws|throws
name|IOException
block|{
comment|// Not yet implemented up in hdfs so just call hflush.
name|hflush
argument_list|()
expr_stmt|;
block|}
end_function

begin_function
specifier|private
name|void
name|requestLogRoll
parameter_list|()
block|{
if|if
condition|(
operator|!
name|this
operator|.
name|listeners
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
for|for
control|(
name|WALObserver
name|i
range|:
name|this
operator|.
name|listeners
control|)
block|{
name|i
operator|.
name|logRollRequested
argument_list|()
expr_stmt|;
block|}
block|}
block|}
end_function

begin_function
specifier|protected
name|void
name|doWrite
parameter_list|(
name|HRegionInfo
name|info
parameter_list|,
name|HLogKey
name|logKey
parameter_list|,
name|WALEdit
name|logEdit
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
operator|!
name|this
operator|.
name|enabled
condition|)
block|{
return|return;
block|}
if|if
condition|(
operator|!
name|this
operator|.
name|listeners
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
for|for
control|(
name|WALObserver
name|i
range|:
name|this
operator|.
name|listeners
control|)
block|{
name|i
operator|.
name|visitLogEntryBeforeWrite
argument_list|(
name|info
argument_list|,
name|logKey
argument_list|,
name|logEdit
argument_list|)
expr_stmt|;
block|}
block|}
try|try
block|{
name|long
name|now
init|=
name|System
operator|.
name|currentTimeMillis
argument_list|()
decl_stmt|;
name|this
operator|.
name|writer
operator|.
name|append
argument_list|(
operator|new
name|HLog
operator|.
name|Entry
argument_list|(
name|logKey
argument_list|,
name|logEdit
argument_list|)
argument_list|)
expr_stmt|;
name|long
name|took
init|=
name|System
operator|.
name|currentTimeMillis
argument_list|()
operator|-
name|now
decl_stmt|;
name|writeTime
operator|+=
name|took
expr_stmt|;
name|writeOps
operator|++
expr_stmt|;
if|if
condition|(
name|took
operator|>
literal|1000
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|" took "
operator|+
name|took
operator|+
literal|"ms appending an edit to hlog; editcount="
operator|+
name|this
operator|.
name|numEntries
operator|.
name|get
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|fatal
argument_list|(
literal|"Could not append. Requesting close of hlog"
argument_list|,
name|e
argument_list|)
expr_stmt|;
name|requestLogRoll
argument_list|()
expr_stmt|;
throw|throw
name|e
throw|;
block|}
block|}
end_function

begin_comment
comment|/** @return How many items have been added to the log */
end_comment

begin_function
name|int
name|getNumEntries
parameter_list|()
block|{
return|return
name|numEntries
operator|.
name|get
argument_list|()
return|;
block|}
end_function

begin_comment
comment|/**    * Obtain a log sequence number.    */
end_comment

begin_function
specifier|private
name|long
name|obtainSeqNum
parameter_list|()
block|{
return|return
name|this
operator|.
name|logSeqNum
operator|.
name|incrementAndGet
argument_list|()
return|;
block|}
end_function

begin_comment
comment|/** @return the number of log files in use */
end_comment

begin_function
name|int
name|getNumLogFiles
parameter_list|()
block|{
return|return
name|outputfiles
operator|.
name|size
argument_list|()
return|;
block|}
end_function

begin_comment
comment|/**    * By acquiring a log sequence ID, we can allow log messages to continue while    * we flush the cache.    *    * Acquire a lock so that we do not roll the log between the start and    * completion of a cache-flush. Otherwise the log-seq-id for the flush will    * not appear in the correct logfile.    *    * @return sequence ID to pass {@link #completeCacheFlush(byte[], byte[], long, boolean)}    * (byte[], byte[], long)}    * @see #completeCacheFlush(byte[], byte[], long, boolean)    * @see #abortCacheFlush()    */
end_comment

begin_function
specifier|public
name|long
name|startCacheFlush
parameter_list|()
block|{
name|this
operator|.
name|cacheFlushLock
operator|.
name|lock
argument_list|()
expr_stmt|;
return|return
name|obtainSeqNum
argument_list|()
return|;
block|}
end_function

begin_comment
comment|/**    * Complete the cache flush    *    * Protected by cacheFlushLock    *    * @param encodedRegionName    * @param tableName    * @param logSeqId    * @throws IOException    */
end_comment

begin_function
specifier|public
name|void
name|completeCacheFlush
parameter_list|(
specifier|final
name|byte
index|[]
name|encodedRegionName
parameter_list|,
specifier|final
name|byte
index|[]
name|tableName
parameter_list|,
specifier|final
name|long
name|logSeqId
parameter_list|,
specifier|final
name|boolean
name|isMetaRegion
parameter_list|)
throws|throws
name|IOException
block|{
try|try
block|{
if|if
condition|(
name|this
operator|.
name|closed
condition|)
block|{
return|return;
block|}
synchronized|synchronized
init|(
name|updateLock
init|)
block|{
name|long
name|now
init|=
name|System
operator|.
name|currentTimeMillis
argument_list|()
decl_stmt|;
name|WALEdit
name|edit
init|=
name|completeCacheFlushLogEdit
argument_list|()
decl_stmt|;
name|HLogKey
name|key
init|=
name|makeKey
argument_list|(
name|encodedRegionName
argument_list|,
name|tableName
argument_list|,
name|logSeqId
argument_list|,
name|System
operator|.
name|currentTimeMillis
argument_list|()
argument_list|)
decl_stmt|;
name|this
operator|.
name|writer
operator|.
name|append
argument_list|(
operator|new
name|Entry
argument_list|(
name|key
argument_list|,
name|edit
argument_list|)
argument_list|)
expr_stmt|;
name|writeTime
operator|+=
name|System
operator|.
name|currentTimeMillis
argument_list|()
operator|-
name|now
expr_stmt|;
name|writeOps
operator|++
expr_stmt|;
name|this
operator|.
name|numEntries
operator|.
name|incrementAndGet
argument_list|()
expr_stmt|;
name|Long
name|seq
init|=
name|this
operator|.
name|lastSeqWritten
operator|.
name|get
argument_list|(
name|encodedRegionName
argument_list|)
decl_stmt|;
if|if
condition|(
name|seq
operator|!=
literal|null
operator|&&
name|logSeqId
operator|>=
name|seq
operator|.
name|longValue
argument_list|()
condition|)
block|{
name|this
operator|.
name|lastSeqWritten
operator|.
name|remove
argument_list|(
name|encodedRegionName
argument_list|)
expr_stmt|;
block|}
block|}
comment|// sync txn to file system
name|this
operator|.
name|sync
argument_list|(
name|isMetaRegion
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|this
operator|.
name|cacheFlushLock
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
end_function

begin_function
specifier|private
name|WALEdit
name|completeCacheFlushLogEdit
parameter_list|()
block|{
name|KeyValue
name|kv
init|=
operator|new
name|KeyValue
argument_list|(
name|METAROW
argument_list|,
name|METAFAMILY
argument_list|,
literal|null
argument_list|,
name|System
operator|.
name|currentTimeMillis
argument_list|()
argument_list|,
name|COMPLETE_CACHE_FLUSH
argument_list|)
decl_stmt|;
name|WALEdit
name|e
init|=
operator|new
name|WALEdit
argument_list|()
decl_stmt|;
name|e
operator|.
name|add
argument_list|(
name|kv
argument_list|)
expr_stmt|;
return|return
name|e
return|;
block|}
end_function

begin_comment
comment|/**    * Abort a cache flush.    * Call if the flush fails. Note that the only recovery for an aborted flush    * currently is a restart of the regionserver so the snapshot content dropped    * by the failure gets restored to the memstore.    */
end_comment

begin_function
specifier|public
name|void
name|abortCacheFlush
parameter_list|()
block|{
name|this
operator|.
name|cacheFlushLock
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
end_function

begin_comment
comment|/**    * @param family    * @return true if the column is a meta column    */
end_comment

begin_function
specifier|public
specifier|static
name|boolean
name|isMetaFamily
parameter_list|(
name|byte
index|[]
name|family
parameter_list|)
block|{
return|return
name|Bytes
operator|.
name|equals
argument_list|(
name|METAFAMILY
argument_list|,
name|family
argument_list|)
return|;
block|}
end_function

begin_comment
comment|/**    * Split up a bunch of regionserver commit log files that are no longer    * being written to, into new files, one per region for region to replay on    * startup. Delete the old log files when finished.    *    * @param rootDir qualified root directory of the HBase instance    * @param srcDir Directory of log files to split: e.g.    *<code>${ROOTDIR}/log_HOST_PORT</code>    * @param oldLogDir directory where processed (split) logs will be archived to    * @param fs FileSystem    * @param conf Configuration    * @throws IOException will throw if corrupted hlogs aren't tolerated    * @return the list of splits    */
end_comment

begin_function
specifier|public
specifier|static
name|List
argument_list|<
name|Path
argument_list|>
name|splitLog
parameter_list|(
specifier|final
name|Path
name|rootDir
parameter_list|,
specifier|final
name|Path
name|srcDir
parameter_list|,
name|Path
name|oldLogDir
parameter_list|,
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Configuration
name|conf
parameter_list|)
throws|throws
name|IOException
block|{
name|long
name|millis
init|=
name|System
operator|.
name|currentTimeMillis
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|Path
argument_list|>
name|splits
init|=
literal|null
decl_stmt|;
if|if
condition|(
operator|!
name|fs
operator|.
name|exists
argument_list|(
name|srcDir
argument_list|)
condition|)
block|{
comment|// Nothing to do
return|return
name|splits
return|;
block|}
name|FileStatus
index|[]
name|logfiles
init|=
name|fs
operator|.
name|listStatus
argument_list|(
name|srcDir
argument_list|)
decl_stmt|;
if|if
condition|(
name|logfiles
operator|==
literal|null
operator|||
name|logfiles
operator|.
name|length
operator|==
literal|0
condition|)
block|{
comment|// Nothing to do
return|return
name|splits
return|;
block|}
name|LOG
operator|.
name|info
argument_list|(
literal|"Splitting "
operator|+
name|logfiles
operator|.
name|length
operator|+
literal|" hlog(s) in "
operator|+
name|srcDir
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
name|splits
operator|=
name|splitLog
argument_list|(
name|rootDir
argument_list|,
name|srcDir
argument_list|,
name|oldLogDir
argument_list|,
name|logfiles
argument_list|,
name|fs
argument_list|,
name|conf
argument_list|)
expr_stmt|;
try|try
block|{
name|FileStatus
index|[]
name|files
init|=
name|fs
operator|.
name|listStatus
argument_list|(
name|srcDir
argument_list|)
decl_stmt|;
for|for
control|(
name|FileStatus
name|file
range|:
name|files
control|)
block|{
name|Path
name|newPath
init|=
name|getHLogArchivePath
argument_list|(
name|oldLogDir
argument_list|,
name|file
operator|.
name|getPath
argument_list|()
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Moving "
operator|+
name|FSUtils
operator|.
name|getPath
argument_list|(
name|file
operator|.
name|getPath
argument_list|()
argument_list|)
operator|+
literal|" to "
operator|+
name|FSUtils
operator|.
name|getPath
argument_list|(
name|newPath
argument_list|)
argument_list|)
expr_stmt|;
name|fs
operator|.
name|rename
argument_list|(
name|file
operator|.
name|getPath
argument_list|()
argument_list|,
name|newPath
argument_list|)
expr_stmt|;
block|}
name|LOG
operator|.
name|debug
argument_list|(
literal|"Moved "
operator|+
name|files
operator|.
name|length
operator|+
literal|" log files to "
operator|+
name|FSUtils
operator|.
name|getPath
argument_list|(
name|oldLogDir
argument_list|)
argument_list|)
expr_stmt|;
name|fs
operator|.
name|delete
argument_list|(
name|srcDir
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|e
operator|=
name|RemoteExceptionHandler
operator|.
name|checkIOException
argument_list|(
name|e
argument_list|)
expr_stmt|;
name|IOException
name|io
init|=
operator|new
name|IOException
argument_list|(
literal|"Cannot delete: "
operator|+
name|srcDir
argument_list|)
decl_stmt|;
name|io
operator|.
name|initCause
argument_list|(
name|e
argument_list|)
expr_stmt|;
throw|throw
name|io
throw|;
block|}
name|long
name|endMillis
init|=
name|System
operator|.
name|currentTimeMillis
argument_list|()
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"hlog file splitting completed in "
operator|+
operator|(
name|endMillis
operator|-
name|millis
operator|)
operator|+
literal|" millis for "
operator|+
name|srcDir
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
return|return
name|splits
return|;
block|}
end_function

begin_comment
comment|// Private immutable datastructure to hold Writer and its Path.
end_comment

begin_class
specifier|private
specifier|final
specifier|static
class|class
name|WriterAndPath
block|{
specifier|final
name|Path
name|p
decl_stmt|;
specifier|final
name|Writer
name|w
decl_stmt|;
name|WriterAndPath
parameter_list|(
specifier|final
name|Path
name|p
parameter_list|,
specifier|final
name|Writer
name|w
parameter_list|)
block|{
name|this
operator|.
name|p
operator|=
name|p
expr_stmt|;
name|this
operator|.
name|w
operator|=
name|w
expr_stmt|;
block|}
block|}
end_class

begin_function
annotation|@
name|SuppressWarnings
argument_list|(
literal|"unchecked"
argument_list|)
specifier|public
specifier|static
name|Class
argument_list|<
name|?
extends|extends
name|HLogKey
argument_list|>
name|getKeyClass
parameter_list|(
name|Configuration
name|conf
parameter_list|)
block|{
return|return
operator|(
name|Class
argument_list|<
name|?
extends|extends
name|HLogKey
argument_list|>
operator|)
name|conf
operator|.
name|getClass
argument_list|(
literal|"hbase.regionserver.hlog.keyclass"
argument_list|,
name|HLogKey
operator|.
name|class
argument_list|)
return|;
block|}
end_function

begin_function
specifier|public
specifier|static
name|HLogKey
name|newKey
parameter_list|(
name|Configuration
name|conf
parameter_list|)
throws|throws
name|IOException
block|{
name|Class
argument_list|<
name|?
extends|extends
name|HLogKey
argument_list|>
name|keyClass
init|=
name|getKeyClass
argument_list|(
name|conf
argument_list|)
decl_stmt|;
try|try
block|{
return|return
name|keyClass
operator|.
name|newInstance
argument_list|()
return|;
block|}
catch|catch
parameter_list|(
name|InstantiationException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"cannot create hlog key"
argument_list|)
throw|;
block|}
catch|catch
parameter_list|(
name|IllegalAccessException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"cannot create hlog key"
argument_list|)
throw|;
block|}
block|}
end_function

begin_comment
comment|/**    * Sorts the HLog edits in the given list of logfiles (that are a mix of edits on multiple regions)    * by region and then splits them per region directories, in batches of (hbase.hlog.split.batch.size)    *    * A batch consists of a set of log files that will be sorted in a single map of edits indexed by region    * the resulting map will be concurrently written by multiple threads to their corresponding regions    *    * Each batch consists of more more log files that are    *  - recovered (files is opened for append then closed to ensure no process is writing into it)    *  - parsed (each edit in the log is appended to a list of edits indexed by region    *    see {@link #parseHLog} for more details)    *  - marked as either processed or corrupt depending on parsing outcome    *  - the resulting edits indexed by region are concurrently written to their corresponding region    *    region directories    *  - original files are then archived to a different directory    *    *    *    * @param rootDir  hbase directory    * @param srcDir   logs directory    * @param oldLogDir directory where processed logs are archived to    * @param logfiles the list of log files to split    * @param fs    * @param conf    * @return    * @throws IOException    */
end_comment

begin_function
specifier|private
specifier|static
name|List
argument_list|<
name|Path
argument_list|>
name|splitLog
parameter_list|(
specifier|final
name|Path
name|rootDir
parameter_list|,
specifier|final
name|Path
name|srcDir
parameter_list|,
name|Path
name|oldLogDir
parameter_list|,
specifier|final
name|FileStatus
index|[]
name|logfiles
parameter_list|,
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Configuration
name|conf
parameter_list|)
throws|throws
name|IOException
block|{
name|List
argument_list|<
name|Path
argument_list|>
name|processedLogs
init|=
operator|new
name|ArrayList
argument_list|<
name|Path
argument_list|>
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|Path
argument_list|>
name|corruptedLogs
init|=
operator|new
name|ArrayList
argument_list|<
name|Path
argument_list|>
argument_list|()
decl_stmt|;
specifier|final
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|WriterAndPath
argument_list|>
name|logWriters
init|=
name|Collections
operator|.
name|synchronizedMap
argument_list|(
operator|new
name|TreeMap
argument_list|<
name|byte
index|[]
argument_list|,
name|WriterAndPath
argument_list|>
argument_list|(
name|Bytes
operator|.
name|BYTES_COMPARATOR
argument_list|)
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|Path
argument_list|>
name|splits
init|=
literal|null
decl_stmt|;
comment|// Number of logs in a read batch
comment|// More means faster but bigger mem consumption
comment|//TODO make a note on the conf rename and update hbase-site.xml if needed
name|int
name|logFilesPerStep
init|=
name|conf
operator|.
name|getInt
argument_list|(
literal|"hbase.hlog.split.batch.size"
argument_list|,
literal|3
argument_list|)
decl_stmt|;
name|boolean
name|skipErrors
init|=
name|conf
operator|.
name|getBoolean
argument_list|(
literal|"hbase.hlog.split.skip.errors"
argument_list|,
literal|false
argument_list|)
decl_stmt|;
try|try
block|{
name|int
name|i
init|=
operator|-
literal|1
decl_stmt|;
while|while
condition|(
name|i
operator|<
name|logfiles
operator|.
name|length
condition|)
block|{
specifier|final
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|LinkedList
argument_list|<
name|Entry
argument_list|>
argument_list|>
name|editsByRegion
init|=
operator|new
name|TreeMap
argument_list|<
name|byte
index|[]
argument_list|,
name|LinkedList
argument_list|<
name|Entry
argument_list|>
argument_list|>
argument_list|(
name|Bytes
operator|.
name|BYTES_COMPARATOR
argument_list|)
decl_stmt|;
for|for
control|(
name|int
name|j
init|=
literal|0
init|;
name|j
operator|<
name|logFilesPerStep
condition|;
name|j
operator|++
control|)
block|{
name|i
operator|++
expr_stmt|;
if|if
condition|(
name|i
operator|==
name|logfiles
operator|.
name|length
condition|)
block|{
break|break;
block|}
name|FileStatus
name|log
init|=
name|logfiles
index|[
name|i
index|]
decl_stmt|;
name|Path
name|logPath
init|=
name|log
operator|.
name|getPath
argument_list|()
decl_stmt|;
name|long
name|logLength
init|=
name|log
operator|.
name|getLen
argument_list|()
decl_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Splitting hlog "
operator|+
operator|(
name|i
operator|+
literal|1
operator|)
operator|+
literal|" of "
operator|+
name|logfiles
operator|.
name|length
operator|+
literal|": "
operator|+
name|logPath
operator|+
literal|", length="
operator|+
name|logLength
argument_list|)
expr_stmt|;
try|try
block|{
name|recoverFileLease
argument_list|(
name|fs
argument_list|,
name|logPath
argument_list|,
name|conf
argument_list|)
expr_stmt|;
name|parseHLog
argument_list|(
name|log
argument_list|,
name|editsByRegion
argument_list|,
name|fs
argument_list|,
name|conf
argument_list|)
expr_stmt|;
name|processedLogs
operator|.
name|add
argument_list|(
name|logPath
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|EOFException
name|eof
parameter_list|)
block|{
comment|// truncated files are expected if a RS crashes (see HBASE-2643)
name|LOG
operator|.
name|info
argument_list|(
literal|"EOF from hlog "
operator|+
name|logPath
operator|+
literal|".  continuing"
argument_list|)
expr_stmt|;
name|processedLogs
operator|.
name|add
argument_list|(
name|logPath
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
if|if
condition|(
name|skipErrors
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Got while parsing hlog "
operator|+
name|logPath
operator|+
literal|". Marking as corrupted"
argument_list|,
name|e
argument_list|)
expr_stmt|;
name|corruptedLogs
operator|.
name|add
argument_list|(
name|logPath
argument_list|)
expr_stmt|;
block|}
else|else
block|{
throw|throw
name|e
throw|;
block|}
block|}
block|}
name|writeEditsBatchToRegions
argument_list|(
name|editsByRegion
argument_list|,
name|logWriters
argument_list|,
name|rootDir
argument_list|,
name|fs
argument_list|,
name|conf
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|fs
operator|.
name|listStatus
argument_list|(
name|srcDir
argument_list|)
operator|.
name|length
operator|>
name|processedLogs
operator|.
name|size
argument_list|()
operator|+
name|corruptedLogs
operator|.
name|size
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Discovered orphan hlog after split. Maybe "
operator|+
literal|"HRegionServer was not dead when we started"
argument_list|)
throw|;
block|}
name|archiveLogs
argument_list|(
name|corruptedLogs
argument_list|,
name|processedLogs
argument_list|,
name|oldLogDir
argument_list|,
name|fs
argument_list|,
name|conf
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|splits
operator|=
operator|new
name|ArrayList
argument_list|<
name|Path
argument_list|>
argument_list|(
name|logWriters
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
for|for
control|(
name|WriterAndPath
name|wap
range|:
name|logWriters
operator|.
name|values
argument_list|()
control|)
block|{
name|wap
operator|.
name|w
operator|.
name|close
argument_list|()
expr_stmt|;
name|splits
operator|.
name|add
argument_list|(
name|wap
operator|.
name|p
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Closed "
operator|+
name|wap
operator|.
name|p
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|splits
return|;
block|}
end_function

begin_comment
comment|/**    * Utility class that lets us keep track of the edit with it's key    * Only used when splitting logs    */
end_comment

begin_class
specifier|public
specifier|static
class|class
name|Entry
implements|implements
name|Writable
block|{
specifier|private
name|WALEdit
name|edit
decl_stmt|;
specifier|private
name|HLogKey
name|key
decl_stmt|;
specifier|public
name|Entry
parameter_list|()
block|{
name|edit
operator|=
operator|new
name|WALEdit
argument_list|()
expr_stmt|;
name|key
operator|=
operator|new
name|HLogKey
argument_list|()
expr_stmt|;
block|}
comment|/**      * Constructor for both params      * @param edit log's edit      * @param key log's key      */
specifier|public
name|Entry
parameter_list|(
name|HLogKey
name|key
parameter_list|,
name|WALEdit
name|edit
parameter_list|)
block|{
name|super
argument_list|()
expr_stmt|;
name|this
operator|.
name|key
operator|=
name|key
expr_stmt|;
name|this
operator|.
name|edit
operator|=
name|edit
expr_stmt|;
block|}
comment|/**      * Gets the edit      * @return edit      */
specifier|public
name|WALEdit
name|getEdit
parameter_list|()
block|{
return|return
name|edit
return|;
block|}
comment|/**      * Gets the key      * @return key      */
specifier|public
name|HLogKey
name|getKey
parameter_list|()
block|{
return|return
name|key
return|;
block|}
annotation|@
name|Override
specifier|public
name|String
name|toString
parameter_list|()
block|{
return|return
name|this
operator|.
name|key
operator|+
literal|"="
operator|+
name|this
operator|.
name|edit
return|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|write
parameter_list|(
name|DataOutput
name|dataOutput
parameter_list|)
throws|throws
name|IOException
block|{
name|this
operator|.
name|key
operator|.
name|write
argument_list|(
name|dataOutput
argument_list|)
expr_stmt|;
name|this
operator|.
name|edit
operator|.
name|write
argument_list|(
name|dataOutput
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|readFields
parameter_list|(
name|DataInput
name|dataInput
parameter_list|)
throws|throws
name|IOException
block|{
name|this
operator|.
name|key
operator|.
name|readFields
argument_list|(
name|dataInput
argument_list|)
expr_stmt|;
name|this
operator|.
name|edit
operator|.
name|readFields
argument_list|(
name|dataInput
argument_list|)
expr_stmt|;
block|}
block|}
end_class

begin_comment
comment|/**    * Construct the HLog directory name    *    * @param info HServerInfo for server    * @return the HLog directory name    */
end_comment

begin_function
specifier|public
specifier|static
name|String
name|getHLogDirectoryName
parameter_list|(
name|HServerInfo
name|info
parameter_list|)
block|{
return|return
name|getHLogDirectoryName
argument_list|(
name|info
operator|.
name|getServerName
argument_list|()
argument_list|)
return|;
block|}
end_function

begin_comment
comment|/**    * Construct the HLog directory name    *    * @param serverAddress    * @param startCode    * @return the HLog directory name    */
end_comment

begin_function
specifier|public
specifier|static
name|String
name|getHLogDirectoryName
parameter_list|(
name|String
name|serverAddress
parameter_list|,
name|long
name|startCode
parameter_list|)
block|{
if|if
condition|(
name|serverAddress
operator|==
literal|null
operator|||
name|serverAddress
operator|.
name|length
argument_list|()
operator|==
literal|0
condition|)
block|{
return|return
literal|null
return|;
block|}
return|return
name|getHLogDirectoryName
argument_list|(
name|HServerInfo
operator|.
name|getServerName
argument_list|(
name|serverAddress
argument_list|,
name|startCode
argument_list|)
argument_list|)
return|;
block|}
end_function

begin_comment
comment|/**    * Construct the HLog directory name    *    * @param serverName    * @return the HLog directory name    */
end_comment

begin_function
specifier|public
specifier|static
name|String
name|getHLogDirectoryName
parameter_list|(
name|String
name|serverName
parameter_list|)
block|{
name|StringBuilder
name|dirName
init|=
operator|new
name|StringBuilder
argument_list|(
name|HConstants
operator|.
name|HREGION_LOGDIR_NAME
argument_list|)
decl_stmt|;
name|dirName
operator|.
name|append
argument_list|(
literal|"/"
argument_list|)
expr_stmt|;
name|dirName
operator|.
name|append
argument_list|(
name|serverName
argument_list|)
expr_stmt|;
return|return
name|dirName
operator|.
name|toString
argument_list|()
return|;
block|}
end_function

begin_function
specifier|public
specifier|static
name|boolean
name|validateHLogFilename
parameter_list|(
name|String
name|filename
parameter_list|)
block|{
return|return
name|pattern
operator|.
name|matcher
argument_list|(
name|filename
argument_list|)
operator|.
name|matches
argument_list|()
return|;
block|}
end_function

begin_function
specifier|private
specifier|static
name|Path
name|getHLogArchivePath
parameter_list|(
name|Path
name|oldLogDir
parameter_list|,
name|Path
name|p
parameter_list|)
block|{
return|return
operator|new
name|Path
argument_list|(
name|oldLogDir
argument_list|,
name|p
operator|.
name|getName
argument_list|()
argument_list|)
return|;
block|}
end_function

begin_comment
comment|/**    * Takes splitLogsMap and concurrently writes them to region directories using a thread pool    *    * @param splitLogsMap map that contains the log splitting result indexed by region    * @param logWriters map that contains a writer per region    * @param rootDir hbase root dir    * @param fs    * @param conf    * @throws IOException    */
end_comment

begin_function
specifier|private
specifier|static
name|void
name|writeEditsBatchToRegions
parameter_list|(
specifier|final
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|LinkedList
argument_list|<
name|Entry
argument_list|>
argument_list|>
name|splitLogsMap
parameter_list|,
specifier|final
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|WriterAndPath
argument_list|>
name|logWriters
parameter_list|,
specifier|final
name|Path
name|rootDir
parameter_list|,
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Configuration
name|conf
parameter_list|)
throws|throws
name|IOException
block|{
comment|// Number of threads to use when log splitting to rewrite the logs.
comment|// More means faster but bigger mem consumption.
name|int
name|logWriterThreads
init|=
name|conf
operator|.
name|getInt
argument_list|(
literal|"hbase.regionserver.hlog.splitlog.writer.threads"
argument_list|,
literal|3
argument_list|)
decl_stmt|;
name|boolean
name|skipErrors
init|=
name|conf
operator|.
name|getBoolean
argument_list|(
literal|"hbase.skip.errors"
argument_list|,
literal|false
argument_list|)
decl_stmt|;
name|HashMap
argument_list|<
name|byte
index|[]
argument_list|,
name|Future
argument_list|>
name|writeFutureResult
init|=
operator|new
name|HashMap
argument_list|<
name|byte
index|[]
argument_list|,
name|Future
argument_list|>
argument_list|()
decl_stmt|;
name|ThreadFactoryBuilder
name|builder
init|=
operator|new
name|ThreadFactoryBuilder
argument_list|()
decl_stmt|;
name|builder
operator|.
name|setNameFormat
argument_list|(
literal|"SplitWriter-%1$d"
argument_list|)
expr_stmt|;
name|ThreadFactory
name|factory
init|=
name|builder
operator|.
name|build
argument_list|()
decl_stmt|;
name|ThreadPoolExecutor
name|threadPool
init|=
operator|(
name|ThreadPoolExecutor
operator|)
name|Executors
operator|.
name|newFixedThreadPool
argument_list|(
name|logWriterThreads
argument_list|,
name|factory
argument_list|)
decl_stmt|;
for|for
control|(
specifier|final
name|byte
index|[]
name|region
range|:
name|splitLogsMap
operator|.
name|keySet
argument_list|()
control|)
block|{
name|Callable
name|splitter
init|=
name|createNewSplitter
argument_list|(
name|rootDir
argument_list|,
name|logWriters
argument_list|,
name|splitLogsMap
argument_list|,
name|region
argument_list|,
name|fs
argument_list|,
name|conf
argument_list|)
decl_stmt|;
name|writeFutureResult
operator|.
name|put
argument_list|(
name|region
argument_list|,
name|threadPool
operator|.
name|submit
argument_list|(
name|splitter
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|threadPool
operator|.
name|shutdown
argument_list|()
expr_stmt|;
comment|// Wait for all threads to terminate
try|try
block|{
for|for
control|(
name|int
name|j
init|=
literal|0
init|;
operator|!
name|threadPool
operator|.
name|awaitTermination
argument_list|(
literal|5
argument_list|,
name|TimeUnit
operator|.
name|SECONDS
argument_list|)
condition|;
name|j
operator|++
control|)
block|{
name|String
name|message
init|=
literal|"Waiting for hlog writers to terminate, elapsed "
operator|+
name|j
operator|*
literal|5
operator|+
literal|" seconds"
decl_stmt|;
if|if
condition|(
name|j
operator|<
literal|30
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
name|message
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|LOG
operator|.
name|info
argument_list|(
name|message
argument_list|)
expr_stmt|;
block|}
block|}
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|ex
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Hlog writers were interrupted, possible data loss!"
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|skipErrors
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Could not finish writing log entries"
argument_list|,
name|ex
argument_list|)
throw|;
comment|//TODO  maybe we should fail here regardless if skipErrors is active or not
block|}
block|}
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|byte
index|[]
argument_list|,
name|Future
argument_list|>
name|entry
range|:
name|writeFutureResult
operator|.
name|entrySet
argument_list|()
control|)
block|{
try|try
block|{
name|entry
operator|.
name|getValue
argument_list|()
operator|.
name|get
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|ExecutionException
name|e
parameter_list|)
block|{
throw|throw
operator|(
operator|new
name|IOException
argument_list|(
name|e
operator|.
name|getCause
argument_list|()
argument_list|)
operator|)
throw|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e1
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Writer for region "
operator|+
name|Bytes
operator|.
name|toString
argument_list|(
name|entry
operator|.
name|getKey
argument_list|()
argument_list|)
operator|+
literal|" was interrupted, however the write process should have "
operator|+
literal|"finished. Throwing up "
argument_list|,
name|e1
argument_list|)
expr_stmt|;
throw|throw
operator|(
operator|new
name|IOException
argument_list|(
name|e1
operator|.
name|getCause
argument_list|()
argument_list|)
operator|)
throw|;
block|}
block|}
block|}
end_function

begin_comment
comment|/*    * Parse a single hlog and put the edits in @splitLogsMap    *    * @param logfile to split    * @param splitLogsMap output parameter: a map with region names as keys and a    * list of edits as values    * @param fs the filesystem    * @param conf the configuration    * @throws IOException if hlog is corrupted, or can't be open    */
end_comment

begin_function
specifier|private
specifier|static
name|void
name|parseHLog
parameter_list|(
specifier|final
name|FileStatus
name|logfile
parameter_list|,
specifier|final
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|LinkedList
argument_list|<
name|Entry
argument_list|>
argument_list|>
name|splitLogsMap
parameter_list|,
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Configuration
name|conf
parameter_list|)
throws|throws
name|IOException
block|{
comment|// Check for possibly empty file. With appends, currently Hadoop reports a
comment|// zero length even if the file has been sync'd. Revisit if HDFS-376 or
comment|// HDFS-878 is committed.
name|long
name|length
init|=
name|logfile
operator|.
name|getLen
argument_list|()
decl_stmt|;
if|if
condition|(
name|length
operator|<=
literal|0
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"File "
operator|+
name|logfile
operator|.
name|getPath
argument_list|()
operator|+
literal|" might be still open, length is 0"
argument_list|)
expr_stmt|;
block|}
name|Path
name|path
init|=
name|logfile
operator|.
name|getPath
argument_list|()
decl_stmt|;
name|Reader
name|in
decl_stmt|;
name|int
name|editsCount
init|=
literal|0
decl_stmt|;
try|try
block|{
name|in
operator|=
name|HLog
operator|.
name|getReader
argument_list|(
name|fs
argument_list|,
name|path
argument_list|,
name|conf
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|EOFException
name|e
parameter_list|)
block|{
if|if
condition|(
name|length
operator|<=
literal|0
condition|)
block|{
comment|//TODO should we ignore an empty, not-last log file if skip.errors is false?
comment|//Either way, the caller should decide what to do. E.g. ignore if this is the last
comment|//log in sequence.
comment|//TODO is this scenario still possible if the log has been recovered (i.e. closed)
name|LOG
operator|.
name|warn
argument_list|(
literal|"Could not open "
operator|+
name|path
operator|+
literal|" for reading. File is empty"
operator|+
name|e
argument_list|)
expr_stmt|;
return|return;
block|}
else|else
block|{
throw|throw
name|e
throw|;
block|}
block|}
try|try
block|{
name|Entry
name|entry
decl_stmt|;
while|while
condition|(
operator|(
name|entry
operator|=
name|in
operator|.
name|next
argument_list|()
operator|)
operator|!=
literal|null
condition|)
block|{
name|byte
index|[]
name|region
init|=
name|entry
operator|.
name|getKey
argument_list|()
operator|.
name|getEncodedRegionName
argument_list|()
decl_stmt|;
name|LinkedList
argument_list|<
name|Entry
argument_list|>
name|queue
init|=
name|splitLogsMap
operator|.
name|get
argument_list|(
name|region
argument_list|)
decl_stmt|;
if|if
condition|(
name|queue
operator|==
literal|null
condition|)
block|{
name|queue
operator|=
operator|new
name|LinkedList
argument_list|<
name|Entry
argument_list|>
argument_list|()
expr_stmt|;
name|splitLogsMap
operator|.
name|put
argument_list|(
name|region
argument_list|,
name|queue
argument_list|)
expr_stmt|;
block|}
name|queue
operator|.
name|addLast
argument_list|(
name|entry
argument_list|)
expr_stmt|;
name|editsCount
operator|++
expr_stmt|;
block|}
block|}
finally|finally
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Pushed="
operator|+
name|editsCount
operator|+
literal|" entries from "
operator|+
name|path
argument_list|)
expr_stmt|;
try|try
block|{
if|if
condition|(
name|in
operator|!=
literal|null
condition|)
block|{
name|in
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Close log reader in finally threw exception -- continuing"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
block|}
block|}
end_function

begin_function
specifier|private
specifier|static
name|Callable
argument_list|<
name|Void
argument_list|>
name|createNewSplitter
parameter_list|(
specifier|final
name|Path
name|rootDir
parameter_list|,
specifier|final
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|WriterAndPath
argument_list|>
name|logWriters
parameter_list|,
specifier|final
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|LinkedList
argument_list|<
name|Entry
argument_list|>
argument_list|>
name|logEntries
parameter_list|,
specifier|final
name|byte
index|[]
name|region
parameter_list|,
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Configuration
name|conf
parameter_list|)
block|{
return|return
operator|new
name|Callable
argument_list|<
name|Void
argument_list|>
argument_list|()
block|{
specifier|public
name|String
name|getName
parameter_list|()
block|{
return|return
literal|"Split writer thread for region "
operator|+
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|region
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|Void
name|call
parameter_list|()
throws|throws
name|IOException
block|{
name|LinkedList
argument_list|<
name|Entry
argument_list|>
name|entries
init|=
name|logEntries
operator|.
name|get
argument_list|(
name|region
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
name|this
operator|.
name|getName
argument_list|()
operator|+
literal|" got "
operator|+
name|entries
operator|.
name|size
argument_list|()
operator|+
literal|" to process"
argument_list|)
expr_stmt|;
name|long
name|threadTime
init|=
name|System
operator|.
name|currentTimeMillis
argument_list|()
decl_stmt|;
try|try
block|{
name|int
name|editsCount
init|=
literal|0
decl_stmt|;
name|WriterAndPath
name|wap
init|=
name|logWriters
operator|.
name|get
argument_list|(
name|region
argument_list|)
decl_stmt|;
for|for
control|(
name|Entry
name|logEntry
range|:
name|entries
control|)
block|{
if|if
condition|(
name|wap
operator|==
literal|null
condition|)
block|{
name|Path
name|regionedits
init|=
name|getRegionSplitEditsPath
argument_list|(
name|fs
argument_list|,
name|logEntry
argument_list|,
name|rootDir
argument_list|)
decl_stmt|;
if|if
condition|(
name|fs
operator|.
name|exists
argument_list|(
name|regionedits
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Found existing old edits file. It could be the "
operator|+
literal|"result of a previous failed split attempt. Deleting "
operator|+
name|regionedits
operator|+
literal|", length="
operator|+
name|fs
operator|.
name|getFileStatus
argument_list|(
name|regionedits
argument_list|)
operator|.
name|getLen
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|fs
operator|.
name|delete
argument_list|(
name|regionedits
argument_list|,
literal|false
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failed delete of old "
operator|+
name|regionedits
argument_list|)
expr_stmt|;
block|}
block|}
name|Writer
name|w
init|=
name|createWriter
argument_list|(
name|fs
argument_list|,
name|regionedits
argument_list|,
name|conf
argument_list|)
decl_stmt|;
name|wap
operator|=
operator|new
name|WriterAndPath
argument_list|(
name|regionedits
argument_list|,
name|w
argument_list|)
expr_stmt|;
name|logWriters
operator|.
name|put
argument_list|(
name|region
argument_list|,
name|wap
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Creating writer path="
operator|+
name|regionedits
operator|+
literal|" region="
operator|+
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|region
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|wap
operator|.
name|w
operator|.
name|append
argument_list|(
name|logEntry
argument_list|)
expr_stmt|;
name|editsCount
operator|++
expr_stmt|;
block|}
name|LOG
operator|.
name|debug
argument_list|(
name|this
operator|.
name|getName
argument_list|()
operator|+
literal|" Applied "
operator|+
name|editsCount
operator|+
literal|" total edits to "
operator|+
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|region
argument_list|)
operator|+
literal|" in "
operator|+
operator|(
name|System
operator|.
name|currentTimeMillis
argument_list|()
operator|-
name|threadTime
operator|)
operator|+
literal|"ms"
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|e
operator|=
name|RemoteExceptionHandler
operator|.
name|checkIOException
argument_list|(
name|e
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|fatal
argument_list|(
name|this
operator|.
name|getName
argument_list|()
operator|+
literal|" Got while writing log entry to log"
argument_list|,
name|e
argument_list|)
expr_stmt|;
throw|throw
name|e
throw|;
block|}
return|return
literal|null
return|;
block|}
block|}
return|;
block|}
end_function

begin_comment
comment|/**    * Moves processed logs to a oldLogDir after successful processing    * Moves corrupted logs (any log that couldn't be successfully parsed    * to corruptDir (.corrupt) for later investigation    *    * @param corruptedLogs    * @param processedLogs    * @param oldLogDir    * @param fs    * @param conf    * @throws IOException    */
end_comment

begin_function
specifier|private
specifier|static
name|void
name|archiveLogs
parameter_list|(
specifier|final
name|List
argument_list|<
name|Path
argument_list|>
name|corruptedLogs
parameter_list|,
specifier|final
name|List
argument_list|<
name|Path
argument_list|>
name|processedLogs
parameter_list|,
specifier|final
name|Path
name|oldLogDir
parameter_list|,
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Configuration
name|conf
parameter_list|)
throws|throws
name|IOException
block|{
specifier|final
name|Path
name|corruptDir
init|=
operator|new
name|Path
argument_list|(
name|conf
operator|.
name|get
argument_list|(
name|HConstants
operator|.
name|HBASE_DIR
argument_list|)
argument_list|,
name|conf
operator|.
name|get
argument_list|(
literal|"hbase.regionserver.hlog.splitlog.corrupt.dir"
argument_list|,
literal|".corrupt"
argument_list|)
argument_list|)
decl_stmt|;
name|fs
operator|.
name|mkdirs
argument_list|(
name|corruptDir
argument_list|)
expr_stmt|;
name|fs
operator|.
name|mkdirs
argument_list|(
name|oldLogDir
argument_list|)
expr_stmt|;
for|for
control|(
name|Path
name|corrupted
range|:
name|corruptedLogs
control|)
block|{
name|Path
name|p
init|=
operator|new
name|Path
argument_list|(
name|corruptDir
argument_list|,
name|corrupted
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Moving corrupted log "
operator|+
name|corrupted
operator|+
literal|" to "
operator|+
name|p
argument_list|)
expr_stmt|;
name|fs
operator|.
name|rename
argument_list|(
name|corrupted
argument_list|,
name|p
argument_list|)
expr_stmt|;
block|}
for|for
control|(
name|Path
name|p
range|:
name|processedLogs
control|)
block|{
name|Path
name|newPath
init|=
name|getHLogArchivePath
argument_list|(
name|oldLogDir
argument_list|,
name|p
argument_list|)
decl_stmt|;
name|fs
operator|.
name|rename
argument_list|(
name|p
argument_list|,
name|newPath
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Archived processed log "
operator|+
name|p
operator|+
literal|" to "
operator|+
name|newPath
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/*    * Path to a file under RECOVERED_EDITS_DIR directory of the region found in    *<code>logEntry</code> named for the sequenceid in the passed    *<code>logEntry</code>: e.g. /hbase/some_table/2323432434/recovered.edits/2332.    * This method also ensures existence of RECOVERED_EDITS_DIR under the region    * creating it if necessary.    * @param fs    * @param logEntry    * @param rootDir HBase root dir.    * @return Path to file into which to dump split log edits.    * @throws IOException    */
end_comment

begin_function
specifier|private
specifier|static
name|Path
name|getRegionSplitEditsPath
parameter_list|(
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Entry
name|logEntry
parameter_list|,
specifier|final
name|Path
name|rootDir
parameter_list|)
throws|throws
name|IOException
block|{
name|Path
name|tableDir
init|=
name|HTableDescriptor
operator|.
name|getTableDir
argument_list|(
name|rootDir
argument_list|,
name|logEntry
operator|.
name|getKey
argument_list|()
operator|.
name|getTablename
argument_list|()
argument_list|)
decl_stmt|;
name|Path
name|regiondir
init|=
name|HRegion
operator|.
name|getRegionDir
argument_list|(
name|tableDir
argument_list|,
name|Bytes
operator|.
name|toString
argument_list|(
name|logEntry
operator|.
name|getKey
argument_list|()
operator|.
name|getEncodedRegionName
argument_list|()
argument_list|)
argument_list|)
decl_stmt|;
name|Path
name|dir
init|=
name|getRegionDirRecoveredEditsDir
argument_list|(
name|regiondir
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|fs
operator|.
name|exists
argument_list|(
name|dir
argument_list|)
condition|)
block|{
if|if
condition|(
operator|!
name|fs
operator|.
name|mkdirs
argument_list|(
name|dir
argument_list|)
condition|)
name|LOG
operator|.
name|warn
argument_list|(
literal|"mkdir failed on "
operator|+
name|dir
argument_list|)
expr_stmt|;
block|}
return|return
operator|new
name|Path
argument_list|(
name|dir
argument_list|,
name|formatRecoveredEditsFileName
argument_list|(
name|logEntry
operator|.
name|getKey
argument_list|()
operator|.
name|getLogSeqNum
argument_list|()
argument_list|)
argument_list|)
return|;
block|}
end_function

begin_function
specifier|static
name|String
name|formatRecoveredEditsFileName
parameter_list|(
specifier|final
name|long
name|seqid
parameter_list|)
block|{
return|return
name|String
operator|.
name|format
argument_list|(
literal|"%019d"
argument_list|,
name|seqid
argument_list|)
return|;
block|}
end_function

begin_comment
comment|/**    * Returns sorted set of edit files made by wal-log splitter.    * @param fs    * @param regiondir    * @return Files in passed<code>regiondir</code> as a sorted set.    * @throws IOException    */
end_comment

begin_function
specifier|public
specifier|static
name|NavigableSet
argument_list|<
name|Path
argument_list|>
name|getSplitEditFilesSorted
parameter_list|(
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Path
name|regiondir
parameter_list|)
throws|throws
name|IOException
block|{
name|Path
name|editsdir
init|=
name|getRegionDirRecoveredEditsDir
argument_list|(
name|regiondir
argument_list|)
decl_stmt|;
name|FileStatus
index|[]
name|files
init|=
name|fs
operator|.
name|listStatus
argument_list|(
name|editsdir
argument_list|,
operator|new
name|PathFilter
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|boolean
name|accept
parameter_list|(
name|Path
name|p
parameter_list|)
block|{
name|boolean
name|result
init|=
literal|false
decl_stmt|;
try|try
block|{
comment|// Return files and only files that match the editfile names pattern.
comment|// There can be other files in this directory other than edit files.
comment|// In particular, on error, we'll move aside the bad edit file giving
comment|// it a timestamp suffix.  See moveAsideBadEditsFile.
name|Matcher
name|m
init|=
name|EDITFILES_NAME_PATTERN
operator|.
name|matcher
argument_list|(
name|p
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
name|result
operator|=
name|fs
operator|.
name|isFile
argument_list|(
name|p
argument_list|)
operator|&&
name|m
operator|.
name|matches
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failed isFile check on "
operator|+
name|p
argument_list|)
expr_stmt|;
block|}
return|return
name|result
return|;
block|}
block|}
argument_list|)
decl_stmt|;
name|NavigableSet
argument_list|<
name|Path
argument_list|>
name|filesSorted
init|=
operator|new
name|TreeSet
argument_list|<
name|Path
argument_list|>
argument_list|()
decl_stmt|;
if|if
condition|(
name|files
operator|==
literal|null
condition|)
return|return
name|filesSorted
return|;
for|for
control|(
name|FileStatus
name|status
range|:
name|files
control|)
block|{
name|filesSorted
operator|.
name|add
argument_list|(
name|status
operator|.
name|getPath
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
name|filesSorted
return|;
block|}
end_function

begin_comment
comment|/**    * Move aside a bad edits file.    * @param fs    * @param edits Edits file to move aside.    * @return The name of the moved aside file.    * @throws IOException    */
end_comment

begin_function
specifier|public
specifier|static
name|Path
name|moveAsideBadEditsFile
parameter_list|(
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Path
name|edits
parameter_list|)
throws|throws
name|IOException
block|{
name|Path
name|moveAsideName
init|=
operator|new
name|Path
argument_list|(
name|edits
operator|.
name|getParent
argument_list|()
argument_list|,
name|edits
operator|.
name|getName
argument_list|()
operator|+
literal|"."
operator|+
name|System
operator|.
name|currentTimeMillis
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|fs
operator|.
name|rename
argument_list|(
name|edits
argument_list|,
name|moveAsideName
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Rename failed from "
operator|+
name|edits
operator|+
literal|" to "
operator|+
name|moveAsideName
argument_list|)
expr_stmt|;
block|}
return|return
name|moveAsideName
return|;
block|}
end_function

begin_comment
comment|/**    * @param regiondir This regions directory in the filesystem.    * @return The directory that holds recovered edits files for the region    *<code>regiondir</code>    */
end_comment

begin_function
specifier|public
specifier|static
name|Path
name|getRegionDirRecoveredEditsDir
parameter_list|(
specifier|final
name|Path
name|regiondir
parameter_list|)
block|{
return|return
operator|new
name|Path
argument_list|(
name|regiondir
argument_list|,
name|RECOVERED_EDITS_DIR
argument_list|)
return|;
block|}
end_function

begin_decl_stmt
specifier|public
specifier|static
specifier|final
name|long
name|FIXED_OVERHEAD
init|=
name|ClassSize
operator|.
name|align
argument_list|(
name|ClassSize
operator|.
name|OBJECT
operator|+
operator|(
literal|5
operator|*
name|ClassSize
operator|.
name|REFERENCE
operator|)
operator|+
name|ClassSize
operator|.
name|ATOMIC_INTEGER
operator|+
name|Bytes
operator|.
name|SIZEOF_INT
operator|+
operator|(
literal|3
operator|*
name|Bytes
operator|.
name|SIZEOF_LONG
operator|)
argument_list|)
decl_stmt|;
end_decl_stmt

begin_function
specifier|private
specifier|static
name|void
name|usage
parameter_list|()
block|{
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|"Usage: HLog<ARGS>"
argument_list|)
expr_stmt|;
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|"Arguments:"
argument_list|)
expr_stmt|;
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|" --dump  Dump textual representation of passed one or more files"
argument_list|)
expr_stmt|;
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|"         For example: HLog --dump hdfs://example.com:9000/hbase/.logs/MACHINE/LOGFILE"
argument_list|)
expr_stmt|;
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|" --split Split the passed directory of WAL logs"
argument_list|)
expr_stmt|;
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|"         For example: HLog --split hdfs://example.com:9000/hbase/.logs/DIR"
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|private
specifier|static
name|void
name|dump
parameter_list|(
specifier|final
name|Configuration
name|conf
parameter_list|,
specifier|final
name|Path
name|p
parameter_list|)
throws|throws
name|IOException
block|{
name|FileSystem
name|fs
init|=
name|FileSystem
operator|.
name|get
argument_list|(
name|conf
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|fs
operator|.
name|exists
argument_list|(
name|p
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|FileNotFoundException
argument_list|(
name|p
operator|.
name|toString
argument_list|()
argument_list|)
throw|;
block|}
if|if
condition|(
operator|!
name|fs
operator|.
name|isFile
argument_list|(
name|p
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|p
operator|+
literal|" is not a file"
argument_list|)
throw|;
block|}
name|Reader
name|log
init|=
name|getReader
argument_list|(
name|fs
argument_list|,
name|p
argument_list|,
name|conf
argument_list|)
decl_stmt|;
try|try
block|{
name|int
name|count
init|=
literal|0
decl_stmt|;
name|HLog
operator|.
name|Entry
name|entry
decl_stmt|;
while|while
condition|(
operator|(
name|entry
operator|=
name|log
operator|.
name|next
argument_list|()
operator|)
operator|!=
literal|null
condition|)
block|{
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"#"
operator|+
name|count
operator|+
literal|", pos="
operator|+
name|log
operator|.
name|getPosition
argument_list|()
operator|+
literal|" "
operator|+
name|entry
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
name|count
operator|++
expr_stmt|;
block|}
block|}
finally|finally
block|{
name|log
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
block|}
end_function

begin_function
specifier|private
specifier|static
name|void
name|split
parameter_list|(
specifier|final
name|Configuration
name|conf
parameter_list|,
specifier|final
name|Path
name|p
parameter_list|)
throws|throws
name|IOException
block|{
name|FileSystem
name|fs
init|=
name|FileSystem
operator|.
name|get
argument_list|(
name|conf
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|fs
operator|.
name|exists
argument_list|(
name|p
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|FileNotFoundException
argument_list|(
name|p
operator|.
name|toString
argument_list|()
argument_list|)
throw|;
block|}
specifier|final
name|Path
name|baseDir
init|=
operator|new
name|Path
argument_list|(
name|conf
operator|.
name|get
argument_list|(
name|HConstants
operator|.
name|HBASE_DIR
argument_list|)
argument_list|)
decl_stmt|;
specifier|final
name|Path
name|oldLogDir
init|=
operator|new
name|Path
argument_list|(
name|baseDir
argument_list|,
name|HConstants
operator|.
name|HREGION_OLDLOGDIR_NAME
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|fs
operator|.
name|getFileStatus
argument_list|(
name|p
argument_list|)
operator|.
name|isDir
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|p
operator|+
literal|" is not a directory"
argument_list|)
throw|;
block|}
name|splitLog
argument_list|(
name|baseDir
argument_list|,
name|p
argument_list|,
name|oldLogDir
argument_list|,
name|fs
argument_list|,
name|conf
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/**    * Pass one or more log file names and it will either dump out a text version    * on<code>stdout</code> or split the specified log files.    *    * @param args    * @throws IOException    */
end_comment

begin_function
specifier|public
specifier|static
name|void
name|main
parameter_list|(
name|String
index|[]
name|args
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|args
operator|.
name|length
operator|<
literal|2
condition|)
block|{
name|usage
argument_list|()
expr_stmt|;
name|System
operator|.
name|exit
argument_list|(
operator|-
literal|1
argument_list|)
expr_stmt|;
block|}
name|boolean
name|dump
init|=
literal|true
decl_stmt|;
if|if
condition|(
name|args
index|[
literal|0
index|]
operator|.
name|compareTo
argument_list|(
literal|"--dump"
argument_list|)
operator|!=
literal|0
condition|)
block|{
if|if
condition|(
name|args
index|[
literal|0
index|]
operator|.
name|compareTo
argument_list|(
literal|"--split"
argument_list|)
operator|==
literal|0
condition|)
block|{
name|dump
operator|=
literal|false
expr_stmt|;
block|}
else|else
block|{
name|usage
argument_list|()
expr_stmt|;
name|System
operator|.
name|exit
argument_list|(
operator|-
literal|1
argument_list|)
expr_stmt|;
block|}
block|}
name|Configuration
name|conf
init|=
name|HBaseConfiguration
operator|.
name|create
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|1
init|;
name|i
operator|<
name|args
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
try|try
block|{
name|Path
name|logPath
init|=
operator|new
name|Path
argument_list|(
name|args
index|[
name|i
index|]
argument_list|)
decl_stmt|;
if|if
condition|(
name|dump
condition|)
block|{
name|dump
argument_list|(
name|conf
argument_list|,
name|logPath
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|split
argument_list|(
name|conf
argument_list|,
name|logPath
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|Throwable
name|t
parameter_list|)
block|{
name|t
operator|.
name|printStackTrace
argument_list|()
expr_stmt|;
name|System
operator|.
name|exit
argument_list|(
operator|-
literal|1
argument_list|)
expr_stmt|;
block|}
block|}
block|}
end_function

unit|}
end_unit

