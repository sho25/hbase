begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Copyright 2010 The Apache Software Foundation  *  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|DataInput
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|FileNotFoundException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|nio
operator|.
name|ByteBuffer
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Arrays
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collection
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collections
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Comparator
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Random
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|SortedSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|atomic
operator|.
name|AtomicBoolean
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|regex
operator|.
name|Matcher
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|regex
operator|.
name|Pattern
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|Log
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|LogFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileStatus
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HDFSBlocksDistribution
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|KeyValue
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|KeyValue
operator|.
name|KVComparator
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|Scan
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|HalfStoreFileReader
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|Reference
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|hfile
operator|.
name|CacheConfig
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|hfile
operator|.
name|Compression
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|hfile
operator|.
name|HFile
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|hfile
operator|.
name|HFileScanner
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|hfile
operator|.
name|HFileWriterV1
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|BloomFilter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|BloomFilterFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|BloomFilterWriter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|Bytes
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|FSUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|Writables
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|RawComparator
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|WritableUtils
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Function
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|ImmutableList
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|Ordering
import|;
end_import

begin_comment
comment|/**  * A Store data file.  Stores usually have one or more of these files.  They  * are produced by flushing the memstore to disk.  To  * create, call {@link #createWriter(FileSystem, Path, int, Configuration)}  * and append data. Be sure to add any metadata before calling close on the  * Writer (Use the appendMetadata convenience methods). On close, a StoreFile  * is sitting in the Filesystem.  To refer to it, create a StoreFile instance  * passing filesystem and path.  To read, call {@link #createReader()}.  *<p>StoreFiles may also reference store files in another Store.  *  * The reason for this weird pattern where you use a different instance for the  * writer and a reader is that we write once but read a lot more.  */
end_comment

begin_class
specifier|public
class|class
name|StoreFile
block|{
specifier|static
specifier|final
name|Log
name|LOG
init|=
name|LogFactory
operator|.
name|getLog
argument_list|(
name|StoreFile
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
specifier|static
specifier|final
name|String
name|HFILE_BLOCK_CACHE_SIZE_KEY
init|=
literal|"hfile.block.cache.size"
decl_stmt|;
specifier|public
specifier|static
enum|enum
name|BloomType
block|{
comment|/**      * Bloomfilters disabled      */
name|NONE
block|,
comment|/**      * Bloom enabled with Table row as Key      */
name|ROW
block|,
comment|/**      * Bloom enabled with Table row& column (family+qualifier) as Key      */
name|ROWCOL
block|}
comment|// Keys for fileinfo values in HFile
comment|/** Max Sequence ID in FileInfo */
specifier|public
specifier|static
specifier|final
name|byte
index|[]
name|MAX_SEQ_ID_KEY
init|=
name|Bytes
operator|.
name|toBytes
argument_list|(
literal|"MAX_SEQ_ID_KEY"
argument_list|)
decl_stmt|;
comment|/** Major compaction flag in FileInfo */
specifier|public
specifier|static
specifier|final
name|byte
index|[]
name|MAJOR_COMPACTION_KEY
init|=
name|Bytes
operator|.
name|toBytes
argument_list|(
literal|"MAJOR_COMPACTION_KEY"
argument_list|)
decl_stmt|;
comment|/** Bloom filter Type in FileInfo */
specifier|static
specifier|final
name|byte
index|[]
name|BLOOM_FILTER_TYPE_KEY
init|=
name|Bytes
operator|.
name|toBytes
argument_list|(
literal|"BLOOM_FILTER_TYPE"
argument_list|)
decl_stmt|;
comment|/** Last Bloom filter key in FileInfo */
specifier|private
specifier|static
specifier|final
name|byte
index|[]
name|LAST_BLOOM_KEY
init|=
name|Bytes
operator|.
name|toBytes
argument_list|(
literal|"LAST_BLOOM_KEY"
argument_list|)
decl_stmt|;
comment|/** Key for Timerange information in metadata*/
specifier|public
specifier|static
specifier|final
name|byte
index|[]
name|TIMERANGE_KEY
init|=
name|Bytes
operator|.
name|toBytes
argument_list|(
literal|"TIMERANGE"
argument_list|)
decl_stmt|;
comment|// Make default block size for StoreFiles 8k while testing.  TODO: FIX!
comment|// Need to make it 8k for testing.
specifier|public
specifier|static
specifier|final
name|int
name|DEFAULT_BLOCKSIZE_SMALL
init|=
literal|8
operator|*
literal|1024
decl_stmt|;
specifier|private
specifier|final
name|FileSystem
name|fs
decl_stmt|;
comment|// This file's path.
specifier|private
specifier|final
name|Path
name|path
decl_stmt|;
comment|// If this storefile references another, this is the reference instance.
specifier|private
name|Reference
name|reference
decl_stmt|;
comment|// If this StoreFile references another, this is the other files path.
specifier|private
name|Path
name|referencePath
decl_stmt|;
comment|// Block cache configuration and reference.
specifier|private
specifier|final
name|CacheConfig
name|cacheConf
decl_stmt|;
comment|// HDFS blocks distribuion information
specifier|private
name|HDFSBlocksDistribution
name|hdfsBlocksDistribution
decl_stmt|;
comment|// Keys for metadata stored in backing HFile.
comment|// Set when we obtain a Reader.
specifier|private
name|long
name|sequenceid
init|=
operator|-
literal|1
decl_stmt|;
comment|// If true, this file was product of a major compaction.  Its then set
comment|// whenever you get a Reader.
specifier|private
name|AtomicBoolean
name|majorCompaction
init|=
literal|null
decl_stmt|;
comment|/** Meta key set when store file is a result of a bulk load */
specifier|public
specifier|static
specifier|final
name|byte
index|[]
name|BULKLOAD_TASK_KEY
init|=
name|Bytes
operator|.
name|toBytes
argument_list|(
literal|"BULKLOAD_SOURCE_TASK"
argument_list|)
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|byte
index|[]
name|BULKLOAD_TIME_KEY
init|=
name|Bytes
operator|.
name|toBytes
argument_list|(
literal|"BULKLOAD_TIMESTAMP"
argument_list|)
decl_stmt|;
comment|/**    * Map of the metadata entries in the corresponding HFile    */
specifier|private
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|byte
index|[]
argument_list|>
name|metadataMap
decl_stmt|;
comment|/*    * Regex that will work for straight filenames and for reference names.    * If reference, then the regex has more than just one group.  Group 1 is    * this files id.  Group 2 the referenced region name, etc.    */
specifier|private
specifier|static
specifier|final
name|Pattern
name|REF_NAME_PARSER
init|=
name|Pattern
operator|.
name|compile
argument_list|(
literal|"^(\\d+)(?:\\.(.+))?$"
argument_list|)
decl_stmt|;
comment|// StoreFile.Reader
specifier|private
specifier|volatile
name|Reader
name|reader
decl_stmt|;
comment|// Used making file ids.
specifier|private
specifier|final
specifier|static
name|Random
name|rand
init|=
operator|new
name|Random
argument_list|()
decl_stmt|;
comment|/**    * Bloom filter type specified in column family configuration. Does not    * necessarily correspond to the Bloom filter type present in the HFile.    */
specifier|private
specifier|final
name|BloomType
name|cfBloomType
decl_stmt|;
comment|// the last modification time stamp
specifier|private
name|long
name|modificationTimeStamp
init|=
literal|0L
decl_stmt|;
comment|/**    * Constructor, loads a reader and it's indices, etc. May allocate a    * substantial amount of ram depending on the underlying files (10-20MB?).    *    * @param fs  The current file system to use.    * @param p  The path of the file.    * @param blockcache<code>true</code> if the block cache is enabled.    * @param conf  The current configuration.    * @param cacheConf  The cache configuration and block cache reference.    * @param cfBloomType The bloom type to use for this store file as specified    *          by column family configuration. This may or may not be the same    *          as the Bloom filter type actually present in the HFile, because    *          column family configuration might change. If this is    *          {@link BloomType#NONE}, the existing Bloom filter is ignored.    * @throws IOException When opening the reader fails.    */
name|StoreFile
parameter_list|(
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Path
name|p
parameter_list|,
specifier|final
name|Configuration
name|conf
parameter_list|,
specifier|final
name|CacheConfig
name|cacheConf
parameter_list|,
specifier|final
name|BloomType
name|cfBloomType
parameter_list|)
throws|throws
name|IOException
block|{
name|this
operator|.
name|fs
operator|=
name|fs
expr_stmt|;
name|this
operator|.
name|path
operator|=
name|p
expr_stmt|;
name|this
operator|.
name|cacheConf
operator|=
name|cacheConf
expr_stmt|;
if|if
condition|(
name|isReference
argument_list|(
name|p
argument_list|)
condition|)
block|{
name|this
operator|.
name|reference
operator|=
name|Reference
operator|.
name|read
argument_list|(
name|fs
argument_list|,
name|p
argument_list|)
expr_stmt|;
name|this
operator|.
name|referencePath
operator|=
name|getReferredToFile
argument_list|(
name|this
operator|.
name|path
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|BloomFilterFactory
operator|.
name|isBloomEnabled
argument_list|(
name|conf
argument_list|)
condition|)
block|{
name|this
operator|.
name|cfBloomType
operator|=
name|cfBloomType
expr_stmt|;
block|}
else|else
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Ignoring bloom filter check for file "
operator|+
name|path
operator|+
literal|": "
operator|+
literal|"cfBloomType="
operator|+
name|cfBloomType
operator|+
literal|" (disabled in config)"
argument_list|)
expr_stmt|;
name|this
operator|.
name|cfBloomType
operator|=
name|BloomType
operator|.
name|NONE
expr_stmt|;
block|}
comment|// cache the modification time stamp of this store file
name|FileStatus
index|[]
name|stats
init|=
name|fs
operator|.
name|listStatus
argument_list|(
name|p
argument_list|)
decl_stmt|;
if|if
condition|(
name|stats
operator|!=
literal|null
operator|&&
name|stats
operator|.
name|length
operator|==
literal|1
condition|)
block|{
name|this
operator|.
name|modificationTimeStamp
operator|=
name|stats
index|[
literal|0
index|]
operator|.
name|getModificationTime
argument_list|()
expr_stmt|;
block|}
else|else
block|{
name|this
operator|.
name|modificationTimeStamp
operator|=
literal|0
expr_stmt|;
block|}
block|}
comment|/**    * @return Path or null if this StoreFile was made with a Stream.    */
name|Path
name|getPath
parameter_list|()
block|{
return|return
name|this
operator|.
name|path
return|;
block|}
comment|/**    * @return The Store/ColumnFamily this file belongs to.    */
name|byte
index|[]
name|getFamily
parameter_list|()
block|{
return|return
name|Bytes
operator|.
name|toBytes
argument_list|(
name|this
operator|.
name|path
operator|.
name|getParent
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|)
return|;
block|}
comment|/**    * @return True if this is a StoreFile Reference; call after {@link #open()}    * else may get wrong answer.    */
name|boolean
name|isReference
parameter_list|()
block|{
return|return
name|this
operator|.
name|reference
operator|!=
literal|null
return|;
block|}
comment|/**    * @param p Path to check.    * @return True if the path has format of a HStoreFile reference.    */
specifier|public
specifier|static
name|boolean
name|isReference
parameter_list|(
specifier|final
name|Path
name|p
parameter_list|)
block|{
return|return
operator|!
name|p
operator|.
name|getName
argument_list|()
operator|.
name|startsWith
argument_list|(
literal|"_"
argument_list|)
operator|&&
name|isReference
argument_list|(
name|p
argument_list|,
name|REF_NAME_PARSER
operator|.
name|matcher
argument_list|(
name|p
operator|.
name|getName
argument_list|()
argument_list|)
argument_list|)
return|;
block|}
comment|/**    * @param p Path to check.    * @param m Matcher to use.    * @return True if the path has format of a HStoreFile reference.    */
specifier|public
specifier|static
name|boolean
name|isReference
parameter_list|(
specifier|final
name|Path
name|p
parameter_list|,
specifier|final
name|Matcher
name|m
parameter_list|)
block|{
if|if
condition|(
name|m
operator|==
literal|null
operator|||
operator|!
name|m
operator|.
name|matches
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failed match of store file name "
operator|+
name|p
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"Failed match of store file name "
operator|+
name|p
operator|.
name|toString
argument_list|()
argument_list|)
throw|;
block|}
return|return
name|m
operator|.
name|groupCount
argument_list|()
operator|>
literal|1
operator|&&
name|m
operator|.
name|group
argument_list|(
literal|2
argument_list|)
operator|!=
literal|null
return|;
block|}
comment|/*    * Return path to the file referred to by a Reference.  Presumes a directory    * hierarchy of<code>${hbase.rootdir}/tablename/regionname/familyname</code>.    * @param p Path to a Reference file.    * @return Calculated path to parent region file.    * @throws IOException    */
specifier|static
name|Path
name|getReferredToFile
parameter_list|(
specifier|final
name|Path
name|p
parameter_list|)
block|{
name|Matcher
name|m
init|=
name|REF_NAME_PARSER
operator|.
name|matcher
argument_list|(
name|p
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|m
operator|==
literal|null
operator|||
operator|!
name|m
operator|.
name|matches
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failed match of store file name "
operator|+
name|p
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"Failed match of store file name "
operator|+
name|p
operator|.
name|toString
argument_list|()
argument_list|)
throw|;
block|}
comment|// Other region name is suffix on the passed Reference file name
name|String
name|otherRegion
init|=
name|m
operator|.
name|group
argument_list|(
literal|2
argument_list|)
decl_stmt|;
comment|// Tabledir is up two directories from where Reference was written.
name|Path
name|tableDir
init|=
name|p
operator|.
name|getParent
argument_list|()
operator|.
name|getParent
argument_list|()
operator|.
name|getParent
argument_list|()
decl_stmt|;
name|String
name|nameStrippedOfSuffix
init|=
name|m
operator|.
name|group
argument_list|(
literal|1
argument_list|)
decl_stmt|;
comment|// Build up new path with the referenced region in place of our current
comment|// region in the reference path.  Also strip regionname suffix from name.
return|return
operator|new
name|Path
argument_list|(
operator|new
name|Path
argument_list|(
operator|new
name|Path
argument_list|(
name|tableDir
argument_list|,
name|otherRegion
argument_list|)
argument_list|,
name|p
operator|.
name|getParent
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|)
argument_list|,
name|nameStrippedOfSuffix
argument_list|)
return|;
block|}
comment|/**    * @return True if this file was made by a major compaction.    */
name|boolean
name|isMajorCompaction
parameter_list|()
block|{
if|if
condition|(
name|this
operator|.
name|majorCompaction
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|NullPointerException
argument_list|(
literal|"This has not been set yet"
argument_list|)
throw|;
block|}
return|return
name|this
operator|.
name|majorCompaction
operator|.
name|get
argument_list|()
return|;
block|}
comment|/**    * @return This files maximum edit sequence id.    */
specifier|public
name|long
name|getMaxSequenceId
parameter_list|()
block|{
return|return
name|this
operator|.
name|sequenceid
return|;
block|}
specifier|public
name|long
name|getModificationTimeStamp
parameter_list|()
block|{
return|return
name|modificationTimeStamp
return|;
block|}
comment|/**    * Return the highest sequence ID found across all storefiles in    * the given list. Store files that were created by a mapreduce    * bulk load are ignored, as they do not correspond to any edit    * log items.    * @return 0 if no non-bulk-load files are provided or, this is Store that    * does not yet have any store files.    */
specifier|public
specifier|static
name|long
name|getMaxSequenceIdInList
parameter_list|(
name|Collection
argument_list|<
name|StoreFile
argument_list|>
name|sfs
parameter_list|)
block|{
name|long
name|max
init|=
literal|0
decl_stmt|;
for|for
control|(
name|StoreFile
name|sf
range|:
name|sfs
control|)
block|{
if|if
condition|(
operator|!
name|sf
operator|.
name|isBulkLoadResult
argument_list|()
condition|)
block|{
name|max
operator|=
name|Math
operator|.
name|max
argument_list|(
name|max
argument_list|,
name|sf
operator|.
name|getMaxSequenceId
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|max
return|;
block|}
comment|/**    * @return true if this storefile was created by HFileOutputFormat    * for a bulk load.    */
name|boolean
name|isBulkLoadResult
parameter_list|()
block|{
return|return
name|metadataMap
operator|.
name|containsKey
argument_list|(
name|BULKLOAD_TIME_KEY
argument_list|)
return|;
block|}
comment|/**    * Return the timestamp at which this bulk load file was generated.    */
specifier|public
name|long
name|getBulkLoadTimestamp
parameter_list|()
block|{
return|return
name|Bytes
operator|.
name|toLong
argument_list|(
name|metadataMap
operator|.
name|get
argument_list|(
name|BULKLOAD_TIME_KEY
argument_list|)
argument_list|)
return|;
block|}
comment|/**    * @return the cached value of HDFS blocks distribution. The cached value is    * calculated when store file is opened.    */
specifier|public
name|HDFSBlocksDistribution
name|getHDFSBlockDistribution
parameter_list|()
block|{
return|return
name|this
operator|.
name|hdfsBlocksDistribution
return|;
block|}
comment|/**    * helper function to compute HDFS blocks distribution of a given reference    * file.For reference file, we don't compute the exact value. We use some    * estimate instead given it might be good enough. we assume bottom part    * takes the first half of reference file, top part takes the second half    * of the reference file. This is just estimate, given    * midkey ofregion != midkey of HFile, also the number and size of keys vary.    * If this estimate isn't good enough, we can improve it later.    * @param fs  The FileSystem    * @param reference  The reference    * @param reference  The referencePath    * @return HDFS blocks distribution    */
specifier|static
specifier|private
name|HDFSBlocksDistribution
name|computeRefFileHDFSBlockDistribution
parameter_list|(
name|FileSystem
name|fs
parameter_list|,
name|Reference
name|reference
parameter_list|,
name|Path
name|referencePath
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|referencePath
operator|==
literal|null
condition|)
block|{
return|return
literal|null
return|;
block|}
name|FileStatus
name|status
init|=
name|fs
operator|.
name|getFileStatus
argument_list|(
name|referencePath
argument_list|)
decl_stmt|;
name|long
name|start
init|=
literal|0
decl_stmt|;
name|long
name|length
init|=
literal|0
decl_stmt|;
if|if
condition|(
name|Reference
operator|.
name|isTopFileRegion
argument_list|(
name|reference
operator|.
name|getFileRegion
argument_list|()
argument_list|)
condition|)
block|{
name|start
operator|=
name|status
operator|.
name|getLen
argument_list|()
operator|/
literal|2
expr_stmt|;
name|length
operator|=
name|status
operator|.
name|getLen
argument_list|()
operator|-
name|status
operator|.
name|getLen
argument_list|()
operator|/
literal|2
expr_stmt|;
block|}
else|else
block|{
name|start
operator|=
literal|0
expr_stmt|;
name|length
operator|=
name|status
operator|.
name|getLen
argument_list|()
operator|/
literal|2
expr_stmt|;
block|}
return|return
name|FSUtils
operator|.
name|computeHDFSBlocksDistribution
argument_list|(
name|fs
argument_list|,
name|status
argument_list|,
name|start
argument_list|,
name|length
argument_list|)
return|;
block|}
comment|/**    * helper function to compute HDFS blocks distribution of a given file.    * For reference file, it is an estimate    * @param fs  The FileSystem    * @param o  The path of the file    * @return HDFS blocks distribution    */
specifier|static
specifier|public
name|HDFSBlocksDistribution
name|computeHDFSBlockDistribution
parameter_list|(
name|FileSystem
name|fs
parameter_list|,
name|Path
name|p
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|isReference
argument_list|(
name|p
argument_list|)
condition|)
block|{
name|Reference
name|reference
init|=
name|Reference
operator|.
name|read
argument_list|(
name|fs
argument_list|,
name|p
argument_list|)
decl_stmt|;
name|Path
name|referencePath
init|=
name|getReferredToFile
argument_list|(
name|p
argument_list|)
decl_stmt|;
return|return
name|computeRefFileHDFSBlockDistribution
argument_list|(
name|fs
argument_list|,
name|reference
argument_list|,
name|referencePath
argument_list|)
return|;
block|}
else|else
block|{
name|FileStatus
name|status
init|=
name|fs
operator|.
name|getFileStatus
argument_list|(
name|p
argument_list|)
decl_stmt|;
name|long
name|length
init|=
name|status
operator|.
name|getLen
argument_list|()
decl_stmt|;
return|return
name|FSUtils
operator|.
name|computeHDFSBlocksDistribution
argument_list|(
name|fs
argument_list|,
name|status
argument_list|,
literal|0
argument_list|,
name|length
argument_list|)
return|;
block|}
block|}
comment|/**    * compute HDFS block distribution, for reference file, it is an estimate    */
specifier|private
name|void
name|computeHDFSBlockDistribution
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|isReference
argument_list|()
condition|)
block|{
name|this
operator|.
name|hdfsBlocksDistribution
operator|=
name|computeRefFileHDFSBlockDistribution
argument_list|(
name|this
operator|.
name|fs
argument_list|,
name|this
operator|.
name|reference
argument_list|,
name|this
operator|.
name|referencePath
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|FileStatus
name|status
init|=
name|this
operator|.
name|fs
operator|.
name|getFileStatus
argument_list|(
name|this
operator|.
name|path
argument_list|)
decl_stmt|;
name|long
name|length
init|=
name|status
operator|.
name|getLen
argument_list|()
decl_stmt|;
name|this
operator|.
name|hdfsBlocksDistribution
operator|=
name|FSUtils
operator|.
name|computeHDFSBlocksDistribution
argument_list|(
name|this
operator|.
name|fs
argument_list|,
name|status
argument_list|,
literal|0
argument_list|,
name|length
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Opens reader on this store file.  Called by Constructor.    * @return Reader for the store file.    * @throws IOException    * @see #closeReader()    */
specifier|private
name|Reader
name|open
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|this
operator|.
name|reader
operator|!=
literal|null
condition|)
block|{
throw|throw
operator|new
name|IllegalAccessError
argument_list|(
literal|"Already open"
argument_list|)
throw|;
block|}
if|if
condition|(
name|isReference
argument_list|()
condition|)
block|{
name|this
operator|.
name|reader
operator|=
operator|new
name|HalfStoreFileReader
argument_list|(
name|this
operator|.
name|fs
argument_list|,
name|this
operator|.
name|referencePath
argument_list|,
name|this
operator|.
name|cacheConf
argument_list|,
name|this
operator|.
name|reference
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|this
operator|.
name|reader
operator|=
operator|new
name|Reader
argument_list|(
name|this
operator|.
name|fs
argument_list|,
name|this
operator|.
name|path
argument_list|,
name|this
operator|.
name|cacheConf
argument_list|)
expr_stmt|;
block|}
name|computeHDFSBlockDistribution
argument_list|()
expr_stmt|;
comment|// Load up indices and fileinfo. This also loads Bloom filter type.
name|metadataMap
operator|=
name|Collections
operator|.
name|unmodifiableMap
argument_list|(
name|this
operator|.
name|reader
operator|.
name|loadFileInfo
argument_list|()
argument_list|)
expr_stmt|;
comment|// Read in our metadata.
name|byte
index|[]
name|b
init|=
name|metadataMap
operator|.
name|get
argument_list|(
name|MAX_SEQ_ID_KEY
argument_list|)
decl_stmt|;
if|if
condition|(
name|b
operator|!=
literal|null
condition|)
block|{
comment|// By convention, if halfhfile, top half has a sequence number> bottom
comment|// half. Thats why we add one in below. Its done for case the two halves
comment|// are ever merged back together --rare.  Without it, on open of store,
comment|// since store files are distingushed by sequence id, the one half would
comment|// subsume the other.
name|this
operator|.
name|sequenceid
operator|=
name|Bytes
operator|.
name|toLong
argument_list|(
name|b
argument_list|)
expr_stmt|;
if|if
condition|(
name|isReference
argument_list|()
condition|)
block|{
if|if
condition|(
name|Reference
operator|.
name|isTopFileRegion
argument_list|(
name|this
operator|.
name|reference
operator|.
name|getFileRegion
argument_list|()
argument_list|)
condition|)
block|{
name|this
operator|.
name|sequenceid
operator|+=
literal|1
expr_stmt|;
block|}
block|}
block|}
name|this
operator|.
name|reader
operator|.
name|setSequenceID
argument_list|(
name|this
operator|.
name|sequenceid
argument_list|)
expr_stmt|;
name|b
operator|=
name|metadataMap
operator|.
name|get
argument_list|(
name|MAJOR_COMPACTION_KEY
argument_list|)
expr_stmt|;
if|if
condition|(
name|b
operator|!=
literal|null
condition|)
block|{
name|boolean
name|mc
init|=
name|Bytes
operator|.
name|toBoolean
argument_list|(
name|b
argument_list|)
decl_stmt|;
if|if
condition|(
name|this
operator|.
name|majorCompaction
operator|==
literal|null
condition|)
block|{
name|this
operator|.
name|majorCompaction
operator|=
operator|new
name|AtomicBoolean
argument_list|(
name|mc
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|this
operator|.
name|majorCompaction
operator|.
name|set
argument_list|(
name|mc
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
comment|// Presume it is not major compacted if it doesn't explicity say so
comment|// HFileOutputFormat explicitly sets the major compacted key.
name|this
operator|.
name|majorCompaction
operator|=
operator|new
name|AtomicBoolean
argument_list|(
literal|false
argument_list|)
expr_stmt|;
block|}
name|BloomType
name|hfileBloomType
init|=
name|reader
operator|.
name|getBloomFilterType
argument_list|()
decl_stmt|;
if|if
condition|(
name|cfBloomType
operator|!=
name|BloomType
operator|.
name|NONE
condition|)
block|{
name|reader
operator|.
name|loadBloomfilter
argument_list|()
expr_stmt|;
if|if
condition|(
name|hfileBloomType
operator|!=
name|cfBloomType
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"HFile Bloom filter type for "
operator|+
name|reader
operator|.
name|getHFileReader
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|": "
operator|+
name|hfileBloomType
operator|+
literal|", but "
operator|+
name|cfBloomType
operator|+
literal|" specified in column family "
operator|+
literal|"configuration"
argument_list|)
expr_stmt|;
block|}
block|}
elseif|else
if|if
condition|(
name|hfileBloomType
operator|!=
name|BloomType
operator|.
name|NONE
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Bloom filter turned off by CF config for "
operator|+
name|reader
operator|.
name|getHFileReader
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
block|}
try|try
block|{
name|byte
index|[]
name|timerangeBytes
init|=
name|metadataMap
operator|.
name|get
argument_list|(
name|TIMERANGE_KEY
argument_list|)
decl_stmt|;
if|if
condition|(
name|timerangeBytes
operator|!=
literal|null
condition|)
block|{
name|this
operator|.
name|reader
operator|.
name|timeRangeTracker
operator|=
operator|new
name|TimeRangeTracker
argument_list|()
expr_stmt|;
name|Writables
operator|.
name|copyWritable
argument_list|(
name|timerangeBytes
argument_list|,
name|this
operator|.
name|reader
operator|.
name|timeRangeTracker
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|IllegalArgumentException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Error reading timestamp range data from meta -- "
operator|+
literal|"proceeding without"
argument_list|,
name|e
argument_list|)
expr_stmt|;
name|this
operator|.
name|reader
operator|.
name|timeRangeTracker
operator|=
literal|null
expr_stmt|;
block|}
return|return
name|this
operator|.
name|reader
return|;
block|}
comment|/**    * @return Reader for StoreFile. creates if necessary    * @throws IOException    */
specifier|public
name|Reader
name|createReader
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|this
operator|.
name|reader
operator|==
literal|null
condition|)
block|{
name|this
operator|.
name|reader
operator|=
name|open
argument_list|()
expr_stmt|;
block|}
return|return
name|this
operator|.
name|reader
return|;
block|}
comment|/**    * @return Current reader.  Must call createReader first else returns null.    * @throws IOException    * @see #createReader()    */
specifier|public
name|Reader
name|getReader
parameter_list|()
block|{
return|return
name|this
operator|.
name|reader
return|;
block|}
comment|/**    * @throws IOException    */
specifier|public
specifier|synchronized
name|void
name|closeReader
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|this
operator|.
name|reader
operator|!=
literal|null
condition|)
block|{
name|this
operator|.
name|reader
operator|.
name|close
argument_list|()
expr_stmt|;
name|this
operator|.
name|reader
operator|=
literal|null
expr_stmt|;
block|}
block|}
comment|/**    * Delete this file    * @throws IOException    */
specifier|public
name|void
name|deleteReader
parameter_list|()
throws|throws
name|IOException
block|{
name|closeReader
argument_list|()
expr_stmt|;
name|this
operator|.
name|fs
operator|.
name|delete
argument_list|(
name|getPath
argument_list|()
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|String
name|toString
parameter_list|()
block|{
return|return
name|this
operator|.
name|path
operator|.
name|toString
argument_list|()
operator|+
operator|(
name|isReference
argument_list|()
condition|?
literal|"-"
operator|+
name|this
operator|.
name|referencePath
operator|+
literal|"-"
operator|+
name|reference
operator|.
name|toString
argument_list|()
else|:
literal|""
operator|)
return|;
block|}
comment|/**    * @return a length description of this StoreFile, suitable for debug output    */
specifier|public
name|String
name|toStringDetailed
parameter_list|()
block|{
name|StringBuilder
name|sb
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
name|sb
operator|.
name|append
argument_list|(
name|this
operator|.
name|path
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
name|sb
operator|.
name|append
argument_list|(
literal|", isReference="
argument_list|)
operator|.
name|append
argument_list|(
name|isReference
argument_list|()
argument_list|)
expr_stmt|;
name|sb
operator|.
name|append
argument_list|(
literal|", isBulkLoadResult="
argument_list|)
operator|.
name|append
argument_list|(
name|isBulkLoadResult
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|isBulkLoadResult
argument_list|()
condition|)
block|{
name|sb
operator|.
name|append
argument_list|(
literal|", bulkLoadTS="
argument_list|)
operator|.
name|append
argument_list|(
name|getBulkLoadTimestamp
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|sb
operator|.
name|append
argument_list|(
literal|", seqid="
argument_list|)
operator|.
name|append
argument_list|(
name|getMaxSequenceId
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|sb
operator|.
name|append
argument_list|(
literal|", majorCompaction="
argument_list|)
operator|.
name|append
argument_list|(
name|isMajorCompaction
argument_list|()
argument_list|)
expr_stmt|;
return|return
name|sb
operator|.
name|toString
argument_list|()
return|;
block|}
comment|/**    * Utility to help with rename.    * @param fs    * @param src    * @param tgt    * @return True if succeeded.    * @throws IOException    */
specifier|public
specifier|static
name|Path
name|rename
parameter_list|(
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Path
name|src
parameter_list|,
specifier|final
name|Path
name|tgt
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
operator|!
name|fs
operator|.
name|exists
argument_list|(
name|src
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|FileNotFoundException
argument_list|(
name|src
operator|.
name|toString
argument_list|()
argument_list|)
throw|;
block|}
if|if
condition|(
operator|!
name|fs
operator|.
name|rename
argument_list|(
name|src
argument_list|,
name|tgt
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Failed rename of "
operator|+
name|src
operator|+
literal|" to "
operator|+
name|tgt
argument_list|)
throw|;
block|}
return|return
name|tgt
return|;
block|}
comment|/**    * Get a store file writer. Client is responsible for closing file when done.    *    * @param fs    * @param dir Path to family directory.  Makes the directory if doesn't exist.    * Creates a file with a unique name in this directory.    * @param blocksize size per filesystem block    * @return StoreFile.Writer    * @throws IOException    */
specifier|public
specifier|static
name|Writer
name|createWriter
parameter_list|(
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Path
name|dir
parameter_list|,
specifier|final
name|int
name|blocksize
parameter_list|,
name|Configuration
name|conf
parameter_list|,
name|CacheConfig
name|cacheConf
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|createWriter
argument_list|(
name|fs
argument_list|,
name|dir
argument_list|,
name|blocksize
argument_list|,
literal|null
argument_list|,
literal|null
argument_list|,
name|conf
argument_list|,
name|cacheConf
argument_list|,
name|BloomType
operator|.
name|NONE
argument_list|,
literal|0
argument_list|)
return|;
block|}
comment|/**    * Create a store file writer. Client is responsible for closing file when done.    * If metadata, add BEFORE closing using appendMetadata()    * @param fs    * @param dir Path to family directory.  Makes the directory if doesn't exist.    * Creates a file with a unique name in this directory.    * @param blocksize    * @param algorithm Pass null to get default.    * @param c Pass null to get default.    * @param conf HBase system configuration. used with bloom filters    * @param cacheConf Cache configuration and reference.    * @param bloomType column family setting for bloom filters    * @param maxKeyCount estimated maximum number of keys we expect to add    * @return HFile.Writer    * @throws IOException    */
specifier|public
specifier|static
name|StoreFile
operator|.
name|Writer
name|createWriter
parameter_list|(
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Path
name|dir
parameter_list|,
specifier|final
name|int
name|blocksize
parameter_list|,
specifier|final
name|Compression
operator|.
name|Algorithm
name|algorithm
parameter_list|,
specifier|final
name|KeyValue
operator|.
name|KVComparator
name|c
parameter_list|,
specifier|final
name|Configuration
name|conf
parameter_list|,
specifier|final
name|CacheConfig
name|cacheConf
parameter_list|,
name|BloomType
name|bloomType
parameter_list|,
name|long
name|maxKeyCount
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
operator|!
name|fs
operator|.
name|exists
argument_list|(
name|dir
argument_list|)
condition|)
block|{
name|fs
operator|.
name|mkdirs
argument_list|(
name|dir
argument_list|)
expr_stmt|;
block|}
name|Path
name|path
init|=
name|getUniqueFile
argument_list|(
name|fs
argument_list|,
name|dir
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|BloomFilterFactory
operator|.
name|isBloomEnabled
argument_list|(
name|conf
argument_list|)
condition|)
block|{
name|bloomType
operator|=
name|BloomType
operator|.
name|NONE
expr_stmt|;
block|}
return|return
operator|new
name|Writer
argument_list|(
name|fs
argument_list|,
name|path
argument_list|,
name|blocksize
argument_list|,
name|algorithm
operator|==
literal|null
condition|?
name|HFile
operator|.
name|DEFAULT_COMPRESSION_ALGORITHM
else|:
name|algorithm
argument_list|,
name|conf
argument_list|,
name|cacheConf
argument_list|,
name|c
operator|==
literal|null
condition|?
name|KeyValue
operator|.
name|COMPARATOR
else|:
name|c
argument_list|,
name|bloomType
argument_list|,
name|maxKeyCount
argument_list|)
return|;
block|}
comment|/**    * @param fs    * @param dir Directory to create file in.    * @return random filename inside passed<code>dir</code>    */
specifier|public
specifier|static
name|Path
name|getUniqueFile
parameter_list|(
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Path
name|dir
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
operator|!
name|fs
operator|.
name|getFileStatus
argument_list|(
name|dir
argument_list|)
operator|.
name|isDir
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Expecting "
operator|+
name|dir
operator|.
name|toString
argument_list|()
operator|+
literal|" to be a directory"
argument_list|)
throw|;
block|}
return|return
name|fs
operator|.
name|getFileStatus
argument_list|(
name|dir
argument_list|)
operator|.
name|isDir
argument_list|()
condition|?
name|getRandomFilename
argument_list|(
name|fs
argument_list|,
name|dir
argument_list|)
else|:
name|dir
return|;
block|}
comment|/**    *    * @param fs    * @param dir    * @return Path to a file that doesn't exist at time of this invocation.    * @throws IOException    */
specifier|static
name|Path
name|getRandomFilename
parameter_list|(
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Path
name|dir
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|getRandomFilename
argument_list|(
name|fs
argument_list|,
name|dir
argument_list|,
literal|null
argument_list|)
return|;
block|}
comment|/**    *    * @param fs    * @param dir    * @param suffix    * @return Path to a file that doesn't exist at time of this invocation.    * @throws IOException    */
specifier|static
name|Path
name|getRandomFilename
parameter_list|(
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Path
name|dir
parameter_list|,
specifier|final
name|String
name|suffix
parameter_list|)
throws|throws
name|IOException
block|{
name|long
name|id
init|=
operator|-
literal|1
decl_stmt|;
name|Path
name|p
init|=
literal|null
decl_stmt|;
do|do
block|{
name|id
operator|=
name|Math
operator|.
name|abs
argument_list|(
name|rand
operator|.
name|nextLong
argument_list|()
argument_list|)
expr_stmt|;
name|p
operator|=
operator|new
name|Path
argument_list|(
name|dir
argument_list|,
name|Long
operator|.
name|toString
argument_list|(
name|id
argument_list|)
operator|+
operator|(
operator|(
name|suffix
operator|==
literal|null
operator|||
name|suffix
operator|.
name|length
argument_list|()
operator|<=
literal|0
operator|)
condition|?
literal|""
else|:
name|suffix
operator|)
argument_list|)
expr_stmt|;
block|}
do|while
condition|(
name|fs
operator|.
name|exists
argument_list|(
name|p
argument_list|)
condition|)
do|;
return|return
name|p
return|;
block|}
comment|/**    * Write out a split reference.    *    * Package local so it doesnt leak out of regionserver.    *    * @param fs    * @param splitDir Presumes path format is actually    *<code>SOME_DIRECTORY/REGIONNAME/FAMILY</code>.    * @param f File to split.    * @param splitRow    * @param range    * @return Path to created reference.    * @throws IOException    */
specifier|static
name|Path
name|split
parameter_list|(
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Path
name|splitDir
parameter_list|,
specifier|final
name|StoreFile
name|f
parameter_list|,
specifier|final
name|byte
index|[]
name|splitRow
parameter_list|,
specifier|final
name|Reference
operator|.
name|Range
name|range
parameter_list|)
throws|throws
name|IOException
block|{
comment|// A reference to the bottom half of the hsf store file.
name|Reference
name|r
init|=
operator|new
name|Reference
argument_list|(
name|splitRow
argument_list|,
name|range
argument_list|)
decl_stmt|;
comment|// Add the referred-to regions name as a dot separated suffix.
comment|// See REF_NAME_PARSER regex above.  The referred-to regions name is
comment|// up in the path of the passed in<code>f</code> -- parentdir is family,
comment|// then the directory above is the region name.
name|String
name|parentRegionName
init|=
name|f
operator|.
name|getPath
argument_list|()
operator|.
name|getParent
argument_list|()
operator|.
name|getParent
argument_list|()
operator|.
name|getName
argument_list|()
decl_stmt|;
comment|// Write reference with same file id only with the other region name as
comment|// suffix and into the new region location (under same family).
name|Path
name|p
init|=
operator|new
name|Path
argument_list|(
name|splitDir
argument_list|,
name|f
operator|.
name|getPath
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|"."
operator|+
name|parentRegionName
argument_list|)
decl_stmt|;
return|return
name|r
operator|.
name|write
argument_list|(
name|fs
argument_list|,
name|p
argument_list|)
return|;
block|}
comment|/**    * A StoreFile writer.  Use this to read/write HBase Store Files. It is package    * local because it is an implementation detail of the HBase regionserver.    */
specifier|public
specifier|static
class|class
name|Writer
block|{
specifier|private
specifier|final
name|BloomFilterWriter
name|bloomFilterWriter
decl_stmt|;
specifier|private
specifier|final
name|BloomType
name|bloomType
decl_stmt|;
specifier|private
name|byte
index|[]
name|lastBloomKey
decl_stmt|;
specifier|private
name|int
name|lastBloomKeyOffset
decl_stmt|,
name|lastBloomKeyLen
decl_stmt|;
specifier|private
name|KVComparator
name|kvComparator
decl_stmt|;
specifier|private
name|KeyValue
name|lastKv
init|=
literal|null
decl_stmt|;
name|TimeRangeTracker
name|timeRangeTracker
init|=
operator|new
name|TimeRangeTracker
argument_list|()
decl_stmt|;
comment|/* isTimeRangeTrackerSet keeps track if the timeRange has already been set      * When flushing a memstore, we set TimeRange and use this variable to      * indicate that it doesn't need to be calculated again while      * appending KeyValues.      * It is not set in cases of compactions when it is recalculated using only      * the appended KeyValues*/
name|boolean
name|isTimeRangeTrackerSet
init|=
literal|false
decl_stmt|;
specifier|protected
name|HFile
operator|.
name|Writer
name|writer
decl_stmt|;
comment|/**      * Creates an HFile.Writer that also write helpful meta data.      * @param fs file system to write to      * @param path file name to create      * @param blocksize HDFS block size      * @param compress HDFS block compression      * @param conf user configuration      * @param comparator key comparator      * @param bloomType bloom filter setting      * @param maxKeys the expected maximum number of keys to be added. Was used      *        for Bloom filter size in {@link HFile} format version 1.      * @throws IOException problem writing to FS      */
specifier|public
name|Writer
parameter_list|(
name|FileSystem
name|fs
parameter_list|,
name|Path
name|path
parameter_list|,
name|int
name|blocksize
parameter_list|,
name|Compression
operator|.
name|Algorithm
name|compress
parameter_list|,
specifier|final
name|Configuration
name|conf
parameter_list|,
name|CacheConfig
name|cacheConf
parameter_list|,
specifier|final
name|KVComparator
name|comparator
parameter_list|,
name|BloomType
name|bloomType
parameter_list|,
name|long
name|maxKeys
parameter_list|)
throws|throws
name|IOException
block|{
name|writer
operator|=
name|HFile
operator|.
name|getWriterFactory
argument_list|(
name|conf
argument_list|)
operator|.
name|createWriter
argument_list|(
name|fs
argument_list|,
name|path
argument_list|,
name|blocksize
argument_list|,
name|compress
argument_list|,
name|comparator
operator|.
name|getRawComparator
argument_list|()
argument_list|)
expr_stmt|;
name|this
operator|.
name|kvComparator
operator|=
name|comparator
expr_stmt|;
name|bloomFilterWriter
operator|=
name|BloomFilterFactory
operator|.
name|createBloomAtWrite
argument_list|(
name|conf
argument_list|,
name|cacheConf
argument_list|,
name|bloomType
argument_list|,
operator|(
name|int
operator|)
name|Math
operator|.
name|min
argument_list|(
name|maxKeys
argument_list|,
name|Integer
operator|.
name|MAX_VALUE
argument_list|)
argument_list|,
name|writer
argument_list|)
expr_stmt|;
if|if
condition|(
name|bloomFilterWriter
operator|!=
literal|null
condition|)
block|{
name|this
operator|.
name|bloomType
operator|=
name|bloomType
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Bloom filter type for "
operator|+
name|path
operator|+
literal|": "
operator|+
name|this
operator|.
name|bloomType
operator|+
literal|", "
operator|+
name|bloomFilterWriter
operator|.
name|getClass
argument_list|()
operator|.
name|getSimpleName
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// Not using Bloom filters.
name|this
operator|.
name|bloomType
operator|=
name|BloomType
operator|.
name|NONE
expr_stmt|;
block|}
block|}
comment|/**      * Writes meta data.      * Call before {@link #close()} since its written as meta data to this file.      * @param maxSequenceId Maximum sequence id.      * @param majorCompaction True if this file is product of a major compaction      * @throws IOException problem writing to FS      */
specifier|public
name|void
name|appendMetadata
parameter_list|(
specifier|final
name|long
name|maxSequenceId
parameter_list|,
specifier|final
name|boolean
name|majorCompaction
parameter_list|)
throws|throws
name|IOException
block|{
name|writer
operator|.
name|appendFileInfo
argument_list|(
name|MAX_SEQ_ID_KEY
argument_list|,
name|Bytes
operator|.
name|toBytes
argument_list|(
name|maxSequenceId
argument_list|)
argument_list|)
expr_stmt|;
name|writer
operator|.
name|appendFileInfo
argument_list|(
name|MAJOR_COMPACTION_KEY
argument_list|,
name|Bytes
operator|.
name|toBytes
argument_list|(
name|majorCompaction
argument_list|)
argument_list|)
expr_stmt|;
name|appendTimeRangeMetadata
argument_list|()
expr_stmt|;
block|}
comment|/**      * Add TimestampRange to Metadata      */
specifier|public
name|void
name|appendTimeRangeMetadata
parameter_list|()
throws|throws
name|IOException
block|{
name|appendFileInfo
argument_list|(
name|TIMERANGE_KEY
argument_list|,
name|WritableUtils
operator|.
name|toByteArray
argument_list|(
name|timeRangeTracker
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|/**      * Set TimeRangeTracker      * @param trt      */
specifier|public
name|void
name|setTimeRangeTracker
parameter_list|(
specifier|final
name|TimeRangeTracker
name|trt
parameter_list|)
block|{
name|this
operator|.
name|timeRangeTracker
operator|=
name|trt
expr_stmt|;
name|isTimeRangeTrackerSet
operator|=
literal|true
expr_stmt|;
block|}
comment|/**      * If the timeRangeTracker is not set,      * update TimeRangeTracker to include the timestamp of this key      * @param kv      * @throws IOException      */
specifier|public
name|void
name|includeInTimeRangeTracker
parameter_list|(
specifier|final
name|KeyValue
name|kv
parameter_list|)
block|{
if|if
condition|(
operator|!
name|isTimeRangeTrackerSet
condition|)
block|{
name|timeRangeTracker
operator|.
name|includeTimestamp
argument_list|(
name|kv
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**      * If the timeRangeTracker is not set,      * update TimeRangeTracker to include the timestamp of this key      * @param key      * @throws IOException      */
specifier|public
name|void
name|includeInTimeRangeTracker
parameter_list|(
specifier|final
name|byte
index|[]
name|key
parameter_list|)
block|{
if|if
condition|(
operator|!
name|isTimeRangeTrackerSet
condition|)
block|{
name|timeRangeTracker
operator|.
name|includeTimestamp
argument_list|(
name|key
argument_list|)
expr_stmt|;
block|}
block|}
specifier|public
name|void
name|append
parameter_list|(
specifier|final
name|KeyValue
name|kv
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|this
operator|.
name|bloomFilterWriter
operator|!=
literal|null
condition|)
block|{
comment|// only add to the bloom filter on a new, unique key
name|boolean
name|newKey
init|=
literal|true
decl_stmt|;
if|if
condition|(
name|this
operator|.
name|lastKv
operator|!=
literal|null
condition|)
block|{
switch|switch
condition|(
name|bloomType
condition|)
block|{
case|case
name|ROW
case|:
name|newKey
operator|=
operator|!
name|kvComparator
operator|.
name|matchingRows
argument_list|(
name|kv
argument_list|,
name|lastKv
argument_list|)
expr_stmt|;
break|break;
case|case
name|ROWCOL
case|:
name|newKey
operator|=
operator|!
name|kvComparator
operator|.
name|matchingRowColumn
argument_list|(
name|kv
argument_list|,
name|lastKv
argument_list|)
expr_stmt|;
break|break;
case|case
name|NONE
case|:
name|newKey
operator|=
literal|false
expr_stmt|;
break|break;
default|default:
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Invalid Bloom filter type: "
operator|+
name|bloomType
argument_list|)
throw|;
block|}
block|}
if|if
condition|(
name|newKey
condition|)
block|{
comment|/*            * http://2.bp.blogspot.com/_Cib_A77V54U/StZMrzaKufI/AAAAAAAAADo/ZhK7bGoJdMQ/s400/KeyValue.png            * Key = RowLen + Row + FamilyLen + Column [Family + Qualifier] + TimeStamp            *            * 2 Types of Filtering:            *  1. Row = Row            *  2. RowCol = Row + Qualifier            */
name|byte
index|[]
name|bloomKey
decl_stmt|;
name|int
name|bloomKeyOffset
decl_stmt|,
name|bloomKeyLen
decl_stmt|;
switch|switch
condition|(
name|bloomType
condition|)
block|{
case|case
name|ROW
case|:
name|bloomKey
operator|=
name|kv
operator|.
name|getBuffer
argument_list|()
expr_stmt|;
name|bloomKeyOffset
operator|=
name|kv
operator|.
name|getRowOffset
argument_list|()
expr_stmt|;
name|bloomKeyLen
operator|=
name|kv
operator|.
name|getRowLength
argument_list|()
expr_stmt|;
break|break;
case|case
name|ROWCOL
case|:
comment|// merge(row, qualifier)
comment|// TODO: could save one buffer copy in case of compound Bloom
comment|// filters when this involves creating a KeyValue
name|bloomKey
operator|=
name|bloomFilterWriter
operator|.
name|createBloomKey
argument_list|(
name|kv
operator|.
name|getBuffer
argument_list|()
argument_list|,
name|kv
operator|.
name|getRowOffset
argument_list|()
argument_list|,
name|kv
operator|.
name|getRowLength
argument_list|()
argument_list|,
name|kv
operator|.
name|getBuffer
argument_list|()
argument_list|,
name|kv
operator|.
name|getQualifierOffset
argument_list|()
argument_list|,
name|kv
operator|.
name|getQualifierLength
argument_list|()
argument_list|)
expr_stmt|;
name|bloomKeyOffset
operator|=
literal|0
expr_stmt|;
name|bloomKeyLen
operator|=
name|bloomKey
operator|.
name|length
expr_stmt|;
break|break;
default|default:
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Invalid Bloom filter type: "
operator|+
name|bloomType
operator|+
literal|" (ROW or ROWCOL expected)"
argument_list|)
throw|;
block|}
name|bloomFilterWriter
operator|.
name|add
argument_list|(
name|bloomKey
argument_list|,
name|bloomKeyOffset
argument_list|,
name|bloomKeyLen
argument_list|)
expr_stmt|;
if|if
condition|(
name|lastBloomKey
operator|!=
literal|null
operator|&&
name|bloomFilterWriter
operator|.
name|getComparator
argument_list|()
operator|.
name|compare
argument_list|(
name|bloomKey
argument_list|,
name|bloomKeyOffset
argument_list|,
name|bloomKeyLen
argument_list|,
name|lastBloomKey
argument_list|,
name|lastBloomKeyOffset
argument_list|,
name|lastBloomKeyLen
argument_list|)
operator|<=
literal|0
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Non-increasing Bloom keys: "
operator|+
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|bloomKey
argument_list|,
name|bloomKeyOffset
argument_list|,
name|bloomKeyLen
argument_list|)
operator|+
literal|" after "
operator|+
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|lastBloomKey
argument_list|,
name|lastBloomKeyOffset
argument_list|,
name|lastBloomKeyLen
argument_list|)
argument_list|)
throw|;
block|}
name|lastBloomKey
operator|=
name|bloomKey
expr_stmt|;
name|lastBloomKeyOffset
operator|=
name|bloomKeyOffset
expr_stmt|;
name|lastBloomKeyLen
operator|=
name|bloomKeyLen
expr_stmt|;
name|this
operator|.
name|lastKv
operator|=
name|kv
expr_stmt|;
block|}
block|}
name|writer
operator|.
name|append
argument_list|(
name|kv
argument_list|)
expr_stmt|;
name|includeInTimeRangeTracker
argument_list|(
name|kv
argument_list|)
expr_stmt|;
block|}
specifier|public
name|Path
name|getPath
parameter_list|()
block|{
return|return
name|this
operator|.
name|writer
operator|.
name|getPath
argument_list|()
return|;
block|}
name|boolean
name|hasBloom
parameter_list|()
block|{
return|return
name|this
operator|.
name|bloomFilterWriter
operator|!=
literal|null
return|;
block|}
comment|/**      * For unit testing only.      * @return the Bloom filter used by this writer.      */
name|BloomFilterWriter
name|getBloomWriter
parameter_list|()
block|{
return|return
name|bloomFilterWriter
return|;
block|}
specifier|public
name|void
name|close
parameter_list|()
throws|throws
name|IOException
block|{
comment|// Make sure we wrote something to the Bloom filter before adding it.
name|boolean
name|haveBloom
init|=
name|bloomFilterWriter
operator|!=
literal|null
operator|&&
name|bloomFilterWriter
operator|.
name|getKeyCount
argument_list|()
operator|>
literal|0
decl_stmt|;
if|if
condition|(
name|haveBloom
condition|)
block|{
name|bloomFilterWriter
operator|.
name|compactBloom
argument_list|()
expr_stmt|;
name|writer
operator|.
name|addBloomFilter
argument_list|(
name|bloomFilterWriter
argument_list|)
expr_stmt|;
name|writer
operator|.
name|appendFileInfo
argument_list|(
name|BLOOM_FILTER_TYPE_KEY
argument_list|,
name|Bytes
operator|.
name|toBytes
argument_list|(
name|bloomType
operator|.
name|toString
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|lastBloomKey
operator|!=
literal|null
condition|)
block|{
name|writer
operator|.
name|appendFileInfo
argument_list|(
name|LAST_BLOOM_KEY
argument_list|,
name|Arrays
operator|.
name|copyOfRange
argument_list|(
name|lastBloomKey
argument_list|,
name|lastBloomKeyOffset
argument_list|,
name|lastBloomKeyOffset
operator|+
name|lastBloomKeyLen
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
name|writer
operator|.
name|close
argument_list|()
expr_stmt|;
comment|// Log final Bloom filter statistics. This needs to be done after close()
comment|// because compound Bloom filters might be finalized as part of closing.
if|if
condition|(
name|haveBloom
operator|&&
name|bloomFilterWriter
operator|.
name|getMaxKeys
argument_list|()
operator|>
literal|0
condition|)
block|{
name|StoreFile
operator|.
name|LOG
operator|.
name|info
argument_list|(
literal|"Bloom added to HFile ("
operator|+
name|getPath
argument_list|()
operator|+
literal|"): "
operator|+
name|bloomFilterWriter
operator|.
name|toString
argument_list|()
operator|.
name|replace
argument_list|(
literal|"\n"
argument_list|,
literal|"; "
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
specifier|public
name|void
name|appendFileInfo
parameter_list|(
name|byte
index|[]
name|key
parameter_list|,
name|byte
index|[]
name|value
parameter_list|)
throws|throws
name|IOException
block|{
name|writer
operator|.
name|appendFileInfo
argument_list|(
name|key
argument_list|,
name|value
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Reader for a StoreFile.    */
specifier|public
specifier|static
class|class
name|Reader
block|{
specifier|static
specifier|final
name|Log
name|LOG
init|=
name|LogFactory
operator|.
name|getLog
argument_list|(
name|Reader
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
specifier|protected
name|BloomFilter
name|bloomFilter
init|=
literal|null
decl_stmt|;
specifier|protected
name|BloomType
name|bloomFilterType
decl_stmt|;
specifier|private
specifier|final
name|HFile
operator|.
name|Reader
name|reader
decl_stmt|;
specifier|protected
name|TimeRangeTracker
name|timeRangeTracker
init|=
literal|null
decl_stmt|;
specifier|protected
name|long
name|sequenceID
init|=
operator|-
literal|1
decl_stmt|;
specifier|private
name|byte
index|[]
name|lastBloomKey
decl_stmt|;
specifier|public
name|Reader
parameter_list|(
name|FileSystem
name|fs
parameter_list|,
name|Path
name|path
parameter_list|,
name|CacheConfig
name|cacheConf
parameter_list|)
throws|throws
name|IOException
block|{
name|reader
operator|=
name|HFile
operator|.
name|createReader
argument_list|(
name|fs
argument_list|,
name|path
argument_list|,
name|cacheConf
argument_list|)
expr_stmt|;
name|bloomFilterType
operator|=
name|BloomType
operator|.
name|NONE
expr_stmt|;
block|}
comment|/**      * ONLY USE DEFAULT CONSTRUCTOR FOR UNIT TESTS      */
name|Reader
parameter_list|()
block|{
name|this
operator|.
name|reader
operator|=
literal|null
expr_stmt|;
block|}
specifier|public
name|RawComparator
argument_list|<
name|byte
index|[]
argument_list|>
name|getComparator
parameter_list|()
block|{
return|return
name|reader
operator|.
name|getComparator
argument_list|()
return|;
block|}
comment|/**      * Get a scanner to scan over this StoreFile.      *      * @param cacheBlocks should this scanner cache blocks?      * @param pread use pread (for highly concurrent small readers)      * @return a scanner      */
specifier|public
name|StoreFileScanner
name|getStoreFileScanner
parameter_list|(
name|boolean
name|cacheBlocks
parameter_list|,
name|boolean
name|pread
parameter_list|)
block|{
return|return
operator|new
name|StoreFileScanner
argument_list|(
name|this
argument_list|,
name|getScanner
argument_list|(
name|cacheBlocks
argument_list|,
name|pread
argument_list|)
argument_list|)
return|;
block|}
comment|/**      * Warning: Do not write further code which depends on this call. Instead      * use getStoreFileScanner() which uses the StoreFileScanner class/interface      * which is the preferred way to scan a store with higher level concepts.      *      * @param cacheBlocks should we cache the blocks?      * @param pread use pread (for concurrent small readers)      * @return the underlying HFileScanner      */
annotation|@
name|Deprecated
specifier|public
name|HFileScanner
name|getScanner
parameter_list|(
name|boolean
name|cacheBlocks
parameter_list|,
name|boolean
name|pread
parameter_list|)
block|{
return|return
name|reader
operator|.
name|getScanner
argument_list|(
name|cacheBlocks
argument_list|,
name|pread
argument_list|)
return|;
block|}
specifier|public
name|void
name|close
parameter_list|()
throws|throws
name|IOException
block|{
name|reader
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
specifier|public
name|boolean
name|shouldSeek
parameter_list|(
name|Scan
name|scan
parameter_list|,
specifier|final
name|SortedSet
argument_list|<
name|byte
index|[]
argument_list|>
name|columns
parameter_list|)
block|{
return|return
operator|(
name|passesTimerangeFilter
argument_list|(
name|scan
argument_list|)
operator|&&
name|passesBloomFilter
argument_list|(
name|scan
argument_list|,
name|columns
argument_list|)
operator|)
return|;
block|}
comment|/**      * Check if this storeFile may contain keys within the TimeRange      * @param scan      * @return False if it definitely does not exist in this StoreFile      */
specifier|private
name|boolean
name|passesTimerangeFilter
parameter_list|(
name|Scan
name|scan
parameter_list|)
block|{
if|if
condition|(
name|timeRangeTracker
operator|==
literal|null
condition|)
block|{
return|return
literal|true
return|;
block|}
else|else
block|{
return|return
name|timeRangeTracker
operator|.
name|includesTimeRange
argument_list|(
name|scan
operator|.
name|getTimeRange
argument_list|()
argument_list|)
return|;
block|}
block|}
comment|/**      * Checks whether the given scan passes the Bloom filter (if present). Only      * checks Bloom filters for single-row or single-row-column scans. Bloom      * filter checking for multi-gets is implemented as part of the store      * scanner system (see {@link StoreFileScanner#seekExactly}) and uses      * the lower-level API {@link #passesBloomFilter(byte[], int, int, byte[],      * int, int)}.      *      * @param scan the scan specification. Used to determine the row, and to      *          check whether this is a single-row ("get") scan.      * @param columns the set of columns. Only used for row-column Bloom      *          filters.      * @return true if the scan with the given column set passes the Bloom      *         filter, or if the Bloom filter is not applicable for the scan.      *         False if the Bloom filter is applicable and the scan fails it.      */
specifier|private
name|boolean
name|passesBloomFilter
parameter_list|(
name|Scan
name|scan
parameter_list|,
specifier|final
name|SortedSet
argument_list|<
name|byte
index|[]
argument_list|>
name|columns
parameter_list|)
block|{
comment|// Multi-column non-get scans will use Bloom filters through the
comment|// lower-level API function that this function calls.
if|if
condition|(
operator|!
name|scan
operator|.
name|isGetScan
argument_list|()
condition|)
block|{
return|return
literal|true
return|;
block|}
name|byte
index|[]
name|row
init|=
name|scan
operator|.
name|getStartRow
argument_list|()
decl_stmt|;
switch|switch
condition|(
name|this
operator|.
name|bloomFilterType
condition|)
block|{
case|case
name|ROW
case|:
return|return
name|passesBloomFilter
argument_list|(
name|row
argument_list|,
literal|0
argument_list|,
name|row
operator|.
name|length
argument_list|,
literal|null
argument_list|,
literal|0
argument_list|,
literal|0
argument_list|)
return|;
case|case
name|ROWCOL
case|:
if|if
condition|(
name|columns
operator|!=
literal|null
operator|&&
name|columns
operator|.
name|size
argument_list|()
operator|==
literal|1
condition|)
block|{
name|byte
index|[]
name|column
init|=
name|columns
operator|.
name|first
argument_list|()
decl_stmt|;
return|return
name|passesBloomFilter
argument_list|(
name|row
argument_list|,
literal|0
argument_list|,
name|row
operator|.
name|length
argument_list|,
name|column
argument_list|,
literal|0
argument_list|,
name|column
operator|.
name|length
argument_list|)
return|;
block|}
comment|// For multi-column queries the Bloom filter is checked from the
comment|// seekExact operation.
return|return
literal|true
return|;
default|default:
return|return
literal|true
return|;
block|}
block|}
comment|/**      * A method for checking Bloom filters. Called directly from      * {@link StoreFileScanner} in case of a multi-column query.      *      * @param row      * @param rowOffset      * @param rowLen      * @param col      * @param colOffset      * @param colLen      * @return      */
specifier|public
name|boolean
name|passesBloomFilter
parameter_list|(
name|byte
index|[]
name|row
parameter_list|,
name|int
name|rowOffset
parameter_list|,
name|int
name|rowLen
parameter_list|,
name|byte
index|[]
name|col
parameter_list|,
name|int
name|colOffset
parameter_list|,
name|int
name|colLen
parameter_list|)
block|{
if|if
condition|(
name|bloomFilter
operator|==
literal|null
condition|)
return|return
literal|true
return|;
name|byte
index|[]
name|key
decl_stmt|;
switch|switch
condition|(
name|bloomFilterType
condition|)
block|{
case|case
name|ROW
case|:
if|if
condition|(
name|col
operator|!=
literal|null
condition|)
block|{
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"Row-only Bloom filter called with "
operator|+
literal|"column specified"
argument_list|)
throw|;
block|}
if|if
condition|(
name|rowOffset
operator|!=
literal|0
operator|||
name|rowLen
operator|!=
name|row
operator|.
name|length
condition|)
block|{
throw|throw
operator|new
name|AssertionError
argument_list|(
literal|"For row-only Bloom filters the row "
operator|+
literal|"must occupy the whole array"
argument_list|)
throw|;
block|}
name|key
operator|=
name|row
expr_stmt|;
break|break;
case|case
name|ROWCOL
case|:
name|key
operator|=
name|bloomFilter
operator|.
name|createBloomKey
argument_list|(
name|row
argument_list|,
name|rowOffset
argument_list|,
name|rowLen
argument_list|,
name|col
argument_list|,
name|colOffset
argument_list|,
name|colLen
argument_list|)
expr_stmt|;
break|break;
default|default:
return|return
literal|true
return|;
block|}
comment|// Cache Bloom filter as a local variable in case it is set to null by
comment|// another thread on an IO error.
name|BloomFilter
name|bloomFilter
init|=
name|this
operator|.
name|bloomFilter
decl_stmt|;
if|if
condition|(
name|bloomFilter
operator|==
literal|null
condition|)
block|{
return|return
literal|true
return|;
block|}
comment|// Empty file?
if|if
condition|(
name|reader
operator|.
name|getTrailer
argument_list|()
operator|.
name|getEntryCount
argument_list|()
operator|==
literal|0
condition|)
return|return
literal|false
return|;
try|try
block|{
name|boolean
name|shouldCheckBloom
decl_stmt|;
name|ByteBuffer
name|bloom
decl_stmt|;
if|if
condition|(
name|bloomFilter
operator|.
name|supportsAutoLoading
argument_list|()
condition|)
block|{
name|bloom
operator|=
literal|null
expr_stmt|;
name|shouldCheckBloom
operator|=
literal|true
expr_stmt|;
block|}
else|else
block|{
name|bloom
operator|=
name|reader
operator|.
name|getMetaBlock
argument_list|(
name|HFileWriterV1
operator|.
name|BLOOM_FILTER_DATA_KEY
argument_list|,
literal|true
argument_list|)
expr_stmt|;
name|shouldCheckBloom
operator|=
name|bloom
operator|!=
literal|null
expr_stmt|;
block|}
if|if
condition|(
name|shouldCheckBloom
condition|)
block|{
name|boolean
name|exists
decl_stmt|;
comment|// Whether the primary Bloom key is greater than the last Bloom key
comment|// from the file info. For row-column Bloom filters this is not yet
comment|// a sufficient condition to return false.
name|boolean
name|keyIsAfterLast
init|=
name|lastBloomKey
operator|!=
literal|null
operator|&&
name|bloomFilter
operator|.
name|getComparator
argument_list|()
operator|.
name|compare
argument_list|(
name|key
argument_list|,
name|lastBloomKey
argument_list|)
operator|>
literal|0
decl_stmt|;
if|if
condition|(
name|bloomFilterType
operator|==
name|BloomType
operator|.
name|ROWCOL
condition|)
block|{
comment|// Since a Row Delete is essentially a DeleteFamily applied to all
comment|// columns, a file might be skipped if using row+col Bloom filter.
comment|// In order to ensure this file is included an additional check is
comment|// required looking only for a row bloom.
name|byte
index|[]
name|rowBloomKey
init|=
name|bloomFilter
operator|.
name|createBloomKey
argument_list|(
name|row
argument_list|,
literal|0
argument_list|,
name|row
operator|.
name|length
argument_list|,
literal|null
argument_list|,
literal|0
argument_list|,
literal|0
argument_list|)
decl_stmt|;
if|if
condition|(
name|keyIsAfterLast
operator|&&
name|bloomFilter
operator|.
name|getComparator
argument_list|()
operator|.
name|compare
argument_list|(
name|rowBloomKey
argument_list|,
name|lastBloomKey
argument_list|)
operator|>
literal|0
condition|)
block|{
name|exists
operator|=
literal|false
expr_stmt|;
block|}
else|else
block|{
name|exists
operator|=
name|this
operator|.
name|bloomFilter
operator|.
name|contains
argument_list|(
name|key
argument_list|,
literal|0
argument_list|,
name|key
operator|.
name|length
argument_list|,
name|bloom
argument_list|)
operator|||
name|this
operator|.
name|bloomFilter
operator|.
name|contains
argument_list|(
name|rowBloomKey
argument_list|,
literal|0
argument_list|,
name|rowBloomKey
operator|.
name|length
argument_list|,
name|bloom
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
name|exists
operator|=
operator|!
name|keyIsAfterLast
operator|&&
name|this
operator|.
name|bloomFilter
operator|.
name|contains
argument_list|(
name|key
argument_list|,
literal|0
argument_list|,
name|key
operator|.
name|length
argument_list|,
name|bloom
argument_list|)
expr_stmt|;
block|}
return|return
name|exists
return|;
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Error reading bloom filter data -- proceeding without"
argument_list|,
name|e
argument_list|)
expr_stmt|;
name|setBloomFilterFaulty
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IllegalArgumentException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Bad bloom filter data -- proceeding without"
argument_list|,
name|e
argument_list|)
expr_stmt|;
name|setBloomFilterFaulty
argument_list|()
expr_stmt|;
block|}
return|return
literal|true
return|;
block|}
specifier|public
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|byte
index|[]
argument_list|>
name|loadFileInfo
parameter_list|()
throws|throws
name|IOException
block|{
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|byte
index|[]
argument_list|>
name|fi
init|=
name|reader
operator|.
name|loadFileInfo
argument_list|()
decl_stmt|;
name|byte
index|[]
name|b
init|=
name|fi
operator|.
name|get
argument_list|(
name|BLOOM_FILTER_TYPE_KEY
argument_list|)
decl_stmt|;
if|if
condition|(
name|b
operator|!=
literal|null
condition|)
block|{
name|bloomFilterType
operator|=
name|BloomType
operator|.
name|valueOf
argument_list|(
name|Bytes
operator|.
name|toString
argument_list|(
name|b
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|lastBloomKey
operator|=
name|fi
operator|.
name|get
argument_list|(
name|LAST_BLOOM_KEY
argument_list|)
expr_stmt|;
return|return
name|fi
return|;
block|}
specifier|public
name|void
name|loadBloomfilter
parameter_list|()
block|{
if|if
condition|(
name|this
operator|.
name|bloomFilter
operator|!=
literal|null
condition|)
block|{
return|return;
comment|// already loaded
block|}
try|try
block|{
name|DataInput
name|bloomMeta
init|=
name|reader
operator|.
name|getBloomFilterMetadata
argument_list|()
decl_stmt|;
if|if
condition|(
name|bloomMeta
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
name|bloomFilterType
operator|==
name|BloomType
operator|.
name|NONE
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"valid bloom filter type not found in FileInfo"
argument_list|)
throw|;
block|}
name|bloomFilter
operator|=
name|BloomFilterFactory
operator|.
name|createFromMeta
argument_list|(
name|bloomMeta
argument_list|,
name|reader
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Loaded "
operator|+
name|bloomFilterType
operator|+
literal|" "
operator|+
name|bloomFilter
operator|.
name|getClass
argument_list|()
operator|.
name|getSimpleName
argument_list|()
operator|+
literal|" metadata for "
operator|+
name|reader
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Error reading bloom filter meta -- proceeding without"
argument_list|,
name|e
argument_list|)
expr_stmt|;
name|this
operator|.
name|bloomFilter
operator|=
literal|null
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IllegalArgumentException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Bad bloom filter meta -- proceeding without"
argument_list|,
name|e
argument_list|)
expr_stmt|;
name|this
operator|.
name|bloomFilter
operator|=
literal|null
expr_stmt|;
block|}
block|}
comment|/**      * The number of Bloom filter entries in this store file, or an estimate      * thereof, if the Bloom filter is not loaded. This always returns an upper      * bound of the number of Bloom filter entries.      *      * @return an estimate of the number of Bloom filter entries in this file      */
specifier|public
name|long
name|getFilterEntries
parameter_list|()
block|{
return|return
name|bloomFilter
operator|!=
literal|null
condition|?
name|bloomFilter
operator|.
name|getKeyCount
argument_list|()
else|:
name|reader
operator|.
name|getEntries
argument_list|()
return|;
block|}
specifier|public
name|void
name|setBloomFilterFaulty
parameter_list|()
block|{
name|bloomFilter
operator|=
literal|null
expr_stmt|;
block|}
specifier|public
name|byte
index|[]
name|getLastKey
parameter_list|()
block|{
return|return
name|reader
operator|.
name|getLastKey
argument_list|()
return|;
block|}
specifier|public
name|byte
index|[]
name|midkey
parameter_list|()
throws|throws
name|IOException
block|{
return|return
name|reader
operator|.
name|midkey
argument_list|()
return|;
block|}
specifier|public
name|long
name|length
parameter_list|()
block|{
return|return
name|reader
operator|.
name|length
argument_list|()
return|;
block|}
specifier|public
name|long
name|getTotalUncompressedBytes
parameter_list|()
block|{
return|return
name|reader
operator|.
name|getTrailer
argument_list|()
operator|.
name|getTotalUncompressedBytes
argument_list|()
return|;
block|}
specifier|public
name|long
name|getEntries
parameter_list|()
block|{
return|return
name|reader
operator|.
name|getEntries
argument_list|()
return|;
block|}
specifier|public
name|byte
index|[]
name|getFirstKey
parameter_list|()
block|{
return|return
name|reader
operator|.
name|getFirstKey
argument_list|()
return|;
block|}
specifier|public
name|long
name|indexSize
parameter_list|()
block|{
return|return
name|reader
operator|.
name|indexSize
argument_list|()
return|;
block|}
specifier|public
name|BloomType
name|getBloomFilterType
parameter_list|()
block|{
return|return
name|this
operator|.
name|bloomFilterType
return|;
block|}
specifier|public
name|long
name|getSequenceID
parameter_list|()
block|{
return|return
name|sequenceID
return|;
block|}
specifier|public
name|void
name|setSequenceID
parameter_list|(
name|long
name|sequenceID
parameter_list|)
block|{
name|this
operator|.
name|sequenceID
operator|=
name|sequenceID
expr_stmt|;
block|}
name|BloomFilter
name|getBloomFilter
parameter_list|()
block|{
return|return
name|bloomFilter
return|;
block|}
name|long
name|getUncompressedDataIndexSize
parameter_list|()
block|{
return|return
name|reader
operator|.
name|getTrailer
argument_list|()
operator|.
name|getUncompressedDataIndexSize
argument_list|()
return|;
block|}
specifier|public
name|long
name|getTotalBloomSize
parameter_list|()
block|{
if|if
condition|(
name|bloomFilter
operator|==
literal|null
condition|)
return|return
literal|0
return|;
return|return
name|bloomFilter
operator|.
name|getByteSize
argument_list|()
return|;
block|}
specifier|public
name|int
name|getHFileVersion
parameter_list|()
block|{
return|return
name|reader
operator|.
name|getTrailer
argument_list|()
operator|.
name|getVersion
argument_list|()
return|;
block|}
name|HFile
operator|.
name|Reader
name|getHFileReader
parameter_list|()
block|{
return|return
name|reader
return|;
block|}
name|void
name|disableBloomFilterForTesting
parameter_list|()
block|{
name|bloomFilter
operator|=
literal|null
expr_stmt|;
block|}
specifier|public
name|long
name|getMaxTimestamp
parameter_list|()
block|{
return|return
name|timeRangeTracker
operator|.
name|maximumTimestamp
return|;
block|}
block|}
comment|/**    * Useful comparators for comparing StoreFiles.    */
specifier|abstract
specifier|static
class|class
name|Comparators
block|{
comment|/**      * Comparator that compares based on the flush time of      * the StoreFiles. All bulk loads are placed before all non-      * bulk loads, and then all files are sorted by sequence ID.      * If there are ties, the path name is used as a tie-breaker.      */
specifier|static
specifier|final
name|Comparator
argument_list|<
name|StoreFile
argument_list|>
name|FLUSH_TIME
init|=
name|Ordering
operator|.
name|compound
argument_list|(
name|ImmutableList
operator|.
name|of
argument_list|(
name|Ordering
operator|.
name|natural
argument_list|()
operator|.
name|onResultOf
argument_list|(
operator|new
name|GetBulkTime
argument_list|()
argument_list|)
argument_list|,
name|Ordering
operator|.
name|natural
argument_list|()
operator|.
name|onResultOf
argument_list|(
operator|new
name|GetSeqId
argument_list|()
argument_list|)
argument_list|,
name|Ordering
operator|.
name|natural
argument_list|()
operator|.
name|onResultOf
argument_list|(
operator|new
name|GetPathName
argument_list|()
argument_list|)
argument_list|)
argument_list|)
decl_stmt|;
specifier|private
specifier|static
class|class
name|GetBulkTime
implements|implements
name|Function
argument_list|<
name|StoreFile
argument_list|,
name|Long
argument_list|>
block|{
annotation|@
name|Override
specifier|public
name|Long
name|apply
parameter_list|(
name|StoreFile
name|sf
parameter_list|)
block|{
if|if
condition|(
operator|!
name|sf
operator|.
name|isBulkLoadResult
argument_list|()
condition|)
return|return
name|Long
operator|.
name|MAX_VALUE
return|;
return|return
name|sf
operator|.
name|getBulkLoadTimestamp
argument_list|()
return|;
block|}
block|}
specifier|private
specifier|static
class|class
name|GetSeqId
implements|implements
name|Function
argument_list|<
name|StoreFile
argument_list|,
name|Long
argument_list|>
block|{
annotation|@
name|Override
specifier|public
name|Long
name|apply
parameter_list|(
name|StoreFile
name|sf
parameter_list|)
block|{
if|if
condition|(
name|sf
operator|.
name|isBulkLoadResult
argument_list|()
condition|)
return|return
operator|-
literal|1L
return|;
return|return
name|sf
operator|.
name|getMaxSequenceId
argument_list|()
return|;
block|}
block|}
specifier|private
specifier|static
class|class
name|GetPathName
implements|implements
name|Function
argument_list|<
name|StoreFile
argument_list|,
name|String
argument_list|>
block|{
annotation|@
name|Override
specifier|public
name|String
name|apply
parameter_list|(
name|StoreFile
name|sf
parameter_list|)
block|{
return|return
name|sf
operator|.
name|getPath
argument_list|()
operator|.
name|getName
argument_list|()
return|;
block|}
block|}
comment|/**      * FILE_SIZE = descending sort StoreFiles (largest --> smallest in size)      */
specifier|static
specifier|final
name|Comparator
argument_list|<
name|StoreFile
argument_list|>
name|FILE_SIZE
init|=
name|Ordering
operator|.
name|natural
argument_list|()
operator|.
name|reverse
argument_list|()
operator|.
name|onResultOf
argument_list|(
operator|new
name|Function
argument_list|<
name|StoreFile
argument_list|,
name|Long
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|Long
name|apply
parameter_list|(
name|StoreFile
name|sf
parameter_list|)
block|{
return|return
name|sf
operator|.
name|getReader
argument_list|()
operator|.
name|length
argument_list|()
return|;
block|}
block|}
argument_list|)
decl_stmt|;
block|}
block|}
end_class

end_unit

