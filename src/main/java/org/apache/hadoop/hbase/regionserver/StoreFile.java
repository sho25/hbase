begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Copyright 2010 The Apache Software Foundation  *  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
package|;
end_package

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|Log
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|LogFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FSDataInputStream
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HConstants
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|KeyValue
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|KeyValue
operator|.
name|KVComparator
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|HalfStoreFileReader
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|Reference
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|hfile
operator|.
name|BlockCache
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|hfile
operator|.
name|Compression
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|hfile
operator|.
name|HFile
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|hfile
operator|.
name|HFileScanner
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|hfile
operator|.
name|LruBlockCache
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|BloomFilter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|ByteBloomFilter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|Bytes
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|Hash
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|StringUtils
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Function
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|ImmutableList
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|Ordering
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|FileNotFoundException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|lang
operator|.
name|management
operator|.
name|ManagementFactory
import|;
end_import

begin_import
import|import
name|java
operator|.
name|lang
operator|.
name|management
operator|.
name|MemoryUsage
import|;
end_import

begin_import
import|import
name|java
operator|.
name|nio
operator|.
name|ByteBuffer
import|;
end_import

begin_import
import|import
name|java
operator|.
name|text
operator|.
name|NumberFormat
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Arrays
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collections
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Comparator
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|SortedSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Random
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|atomic
operator|.
name|AtomicBoolean
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|regex
operator|.
name|Matcher
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|regex
operator|.
name|Pattern
import|;
end_import

begin_comment
comment|/**  * A Store data file.  Stores usually have one or more of these files.  They  * are produced by flushing the memstore to disk.  To  * create, call {@link #createWriter(FileSystem, Path, int)} and append data.  Be  * sure to add any metadata before calling close on the Writer  * (Use the appendMetadata convenience methods). On close, a StoreFile is  * sitting in the Filesystem.  To refer to it, create a StoreFile instance  * passing filesystem and path.  To read, call {@link #createReader()}.  *<p>StoreFiles may also reference store files in another Store.  */
end_comment

begin_class
specifier|public
class|class
name|StoreFile
block|{
specifier|static
specifier|final
name|Log
name|LOG
init|=
name|LogFactory
operator|.
name|getLog
argument_list|(
name|StoreFile
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|String
name|HFILE_CACHE_SIZE_KEY
init|=
literal|"hfile.block.cache.size"
decl_stmt|;
specifier|private
specifier|static
name|BlockCache
name|hfileBlockCache
init|=
literal|null
decl_stmt|;
comment|// Make default block size for StoreFiles 8k while testing.  TODO: FIX!
comment|// Need to make it 8k for testing.
specifier|public
specifier|static
specifier|final
name|int
name|DEFAULT_BLOCKSIZE_SMALL
init|=
literal|8
operator|*
literal|1024
decl_stmt|;
specifier|private
specifier|final
name|FileSystem
name|fs
decl_stmt|;
comment|// This file's path.
specifier|private
specifier|final
name|Path
name|path
decl_stmt|;
comment|// If this storefile references another, this is the reference instance.
specifier|private
name|Reference
name|reference
decl_stmt|;
comment|// If this StoreFile references another, this is the other files path.
specifier|private
name|Path
name|referencePath
decl_stmt|;
comment|// Should the block cache be used or not.
specifier|private
name|boolean
name|blockcache
decl_stmt|;
comment|// Is this from an in-memory store
specifier|private
name|boolean
name|inMemory
decl_stmt|;
comment|// Keys for metadata stored in backing HFile.
comment|/** Constant for the max sequence ID meta */
specifier|public
specifier|static
specifier|final
name|byte
index|[]
name|MAX_SEQ_ID_KEY
init|=
name|Bytes
operator|.
name|toBytes
argument_list|(
literal|"MAX_SEQ_ID_KEY"
argument_list|)
decl_stmt|;
comment|// Set when we obtain a Reader.
specifier|private
name|long
name|sequenceid
init|=
operator|-
literal|1
decl_stmt|;
comment|/** Constant for major compaction meta */
specifier|public
specifier|static
specifier|final
name|byte
index|[]
name|MAJOR_COMPACTION_KEY
init|=
name|Bytes
operator|.
name|toBytes
argument_list|(
literal|"MAJOR_COMPACTION_KEY"
argument_list|)
decl_stmt|;
comment|// If true, this file was product of a major compaction.  Its then set
comment|// whenever you get a Reader.
specifier|private
name|AtomicBoolean
name|majorCompaction
init|=
literal|null
decl_stmt|;
comment|/** Meta key set when store file is a result of a bulk load */
specifier|public
specifier|static
specifier|final
name|byte
index|[]
name|BULKLOAD_TASK_KEY
init|=
name|Bytes
operator|.
name|toBytes
argument_list|(
literal|"BULKLOAD_SOURCE_TASK"
argument_list|)
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|byte
index|[]
name|BULKLOAD_TIME_KEY
init|=
name|Bytes
operator|.
name|toBytes
argument_list|(
literal|"BULKLOAD_TIMESTAMP"
argument_list|)
decl_stmt|;
specifier|static
specifier|final
name|String
name|BLOOM_FILTER_META_KEY
init|=
literal|"BLOOM_FILTER_META"
decl_stmt|;
specifier|static
specifier|final
name|String
name|BLOOM_FILTER_DATA_KEY
init|=
literal|"BLOOM_FILTER_DATA"
decl_stmt|;
specifier|static
specifier|final
name|byte
index|[]
name|BLOOM_FILTER_TYPE_KEY
init|=
name|Bytes
operator|.
name|toBytes
argument_list|(
literal|"BLOOM_FILTER_TYPE"
argument_list|)
decl_stmt|;
comment|/**    * Map of the metadata entries in the corresponding HFile    */
specifier|private
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|byte
index|[]
argument_list|>
name|metadataMap
decl_stmt|;
comment|/*    * Regex that will work for straight filenames and for reference names.    * If reference, then the regex has more than just one group.  Group 1 is    * this files id.  Group 2 the referenced region name, etc.    */
specifier|private
specifier|static
specifier|final
name|Pattern
name|REF_NAME_PARSER
init|=
name|Pattern
operator|.
name|compile
argument_list|(
literal|"^(\\d+)(?:\\.(.+))?$"
argument_list|)
decl_stmt|;
specifier|private
specifier|volatile
name|StoreFile
operator|.
name|Reader
name|reader
decl_stmt|;
comment|// Used making file ids.
specifier|private
specifier|final
specifier|static
name|Random
name|rand
init|=
operator|new
name|Random
argument_list|()
decl_stmt|;
specifier|private
specifier|final
name|Configuration
name|conf
decl_stmt|;
specifier|private
specifier|final
name|BloomType
name|bloomType
decl_stmt|;
comment|/**    * Constructor, loads a reader and it's indices, etc. May allocate a    * substantial amount of ram depending on the underlying files (10-20MB?).    *    * @param fs  The current file system to use.    * @param p  The path of the file.    * @param blockcache<code>true</code> if the block cache is enabled.    * @param conf  The current configuration.    * @param bt The bloom type to use for this store file    * @throws IOException When opening the reader fails.    */
name|StoreFile
parameter_list|(
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Path
name|p
parameter_list|,
specifier|final
name|boolean
name|blockcache
parameter_list|,
specifier|final
name|Configuration
name|conf
parameter_list|,
specifier|final
name|BloomType
name|bt
parameter_list|,
specifier|final
name|boolean
name|inMemory
parameter_list|)
throws|throws
name|IOException
block|{
name|this
operator|.
name|conf
operator|=
name|conf
expr_stmt|;
name|this
operator|.
name|fs
operator|=
name|fs
expr_stmt|;
name|this
operator|.
name|path
operator|=
name|p
expr_stmt|;
name|this
operator|.
name|blockcache
operator|=
name|blockcache
expr_stmt|;
name|this
operator|.
name|inMemory
operator|=
name|inMemory
expr_stmt|;
if|if
condition|(
name|isReference
argument_list|(
name|p
argument_list|)
condition|)
block|{
name|this
operator|.
name|reference
operator|=
name|Reference
operator|.
name|read
argument_list|(
name|fs
argument_list|,
name|p
argument_list|)
expr_stmt|;
name|this
operator|.
name|referencePath
operator|=
name|getReferredToFile
argument_list|(
name|this
operator|.
name|path
argument_list|)
expr_stmt|;
block|}
comment|// ignore if the column family config says "no bloom filter"
comment|// even if there is one in the hfile.
if|if
condition|(
name|conf
operator|.
name|getBoolean
argument_list|(
literal|"io.hfile.bloom.enabled"
argument_list|,
literal|true
argument_list|)
condition|)
block|{
name|this
operator|.
name|bloomType
operator|=
name|bt
expr_stmt|;
block|}
else|else
block|{
name|this
operator|.
name|bloomType
operator|=
name|BloomType
operator|.
name|NONE
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Ignoring bloom filter check for file (disabled in config)"
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * @return Path or null if this StoreFile was made with a Stream.    */
name|Path
name|getPath
parameter_list|()
block|{
return|return
name|this
operator|.
name|path
return|;
block|}
comment|/**    * @return The Store/ColumnFamily this file belongs to.    */
name|byte
index|[]
name|getFamily
parameter_list|()
block|{
return|return
name|Bytes
operator|.
name|toBytes
argument_list|(
name|this
operator|.
name|path
operator|.
name|getParent
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|)
return|;
block|}
comment|/**    * @return True if this is a StoreFile Reference; call after {@link #open()}    * else may get wrong answer.    */
name|boolean
name|isReference
parameter_list|()
block|{
return|return
name|this
operator|.
name|reference
operator|!=
literal|null
return|;
block|}
comment|/**    * @param p Path to check.    * @return True if the path has format of a HStoreFile reference.    */
specifier|public
specifier|static
name|boolean
name|isReference
parameter_list|(
specifier|final
name|Path
name|p
parameter_list|)
block|{
return|return
operator|!
name|p
operator|.
name|getName
argument_list|()
operator|.
name|startsWith
argument_list|(
literal|"_"
argument_list|)
operator|&&
name|isReference
argument_list|(
name|p
argument_list|,
name|REF_NAME_PARSER
operator|.
name|matcher
argument_list|(
name|p
operator|.
name|getName
argument_list|()
argument_list|)
argument_list|)
return|;
block|}
comment|/**    * @param p Path to check.    * @param m Matcher to use.    * @return True if the path has format of a HStoreFile reference.    */
specifier|public
specifier|static
name|boolean
name|isReference
parameter_list|(
specifier|final
name|Path
name|p
parameter_list|,
specifier|final
name|Matcher
name|m
parameter_list|)
block|{
if|if
condition|(
name|m
operator|==
literal|null
operator|||
operator|!
name|m
operator|.
name|matches
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failed match of store file name "
operator|+
name|p
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"Failed match of store file name "
operator|+
name|p
operator|.
name|toString
argument_list|()
argument_list|)
throw|;
block|}
return|return
name|m
operator|.
name|groupCount
argument_list|()
operator|>
literal|1
operator|&&
name|m
operator|.
name|group
argument_list|(
literal|2
argument_list|)
operator|!=
literal|null
return|;
block|}
comment|/*    * Return path to the file referred to by a Reference.  Presumes a directory    * hierarchy of<code>${hbase.rootdir}/tablename/regionname/familyname</code>.    * @param p Path to a Reference file.    * @return Calculated path to parent region file.    * @throws IOException    */
specifier|static
name|Path
name|getReferredToFile
parameter_list|(
specifier|final
name|Path
name|p
parameter_list|)
block|{
name|Matcher
name|m
init|=
name|REF_NAME_PARSER
operator|.
name|matcher
argument_list|(
name|p
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|m
operator|==
literal|null
operator|||
operator|!
name|m
operator|.
name|matches
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failed match of store file name "
operator|+
name|p
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"Failed match of store file name "
operator|+
name|p
operator|.
name|toString
argument_list|()
argument_list|)
throw|;
block|}
comment|// Other region name is suffix on the passed Reference file name
name|String
name|otherRegion
init|=
name|m
operator|.
name|group
argument_list|(
literal|2
argument_list|)
decl_stmt|;
comment|// Tabledir is up two directories from where Reference was written.
name|Path
name|tableDir
init|=
name|p
operator|.
name|getParent
argument_list|()
operator|.
name|getParent
argument_list|()
operator|.
name|getParent
argument_list|()
decl_stmt|;
name|String
name|nameStrippedOfSuffix
init|=
name|m
operator|.
name|group
argument_list|(
literal|1
argument_list|)
decl_stmt|;
comment|// Build up new path with the referenced region in place of our current
comment|// region in the reference path.  Also strip regionname suffix from name.
return|return
operator|new
name|Path
argument_list|(
operator|new
name|Path
argument_list|(
operator|new
name|Path
argument_list|(
name|tableDir
argument_list|,
name|otherRegion
argument_list|)
argument_list|,
name|p
operator|.
name|getParent
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|)
argument_list|,
name|nameStrippedOfSuffix
argument_list|)
return|;
block|}
comment|/**    * @return True if this file was made by a major compaction.    */
name|boolean
name|isMajorCompaction
parameter_list|()
block|{
if|if
condition|(
name|this
operator|.
name|majorCompaction
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|NullPointerException
argument_list|(
literal|"This has not been set yet"
argument_list|)
throw|;
block|}
return|return
name|this
operator|.
name|majorCompaction
operator|.
name|get
argument_list|()
return|;
block|}
comment|/**    * @return This files maximum edit sequence id.    */
specifier|public
name|long
name|getMaxSequenceId
parameter_list|()
block|{
if|if
condition|(
name|this
operator|.
name|sequenceid
operator|==
operator|-
literal|1
condition|)
block|{
throw|throw
operator|new
name|IllegalAccessError
argument_list|(
literal|"Has not been initialized"
argument_list|)
throw|;
block|}
return|return
name|this
operator|.
name|sequenceid
return|;
block|}
comment|/**    * Return the highest sequence ID found across all storefiles in    * the given list. Store files that were created by a mapreduce    * bulk load are ignored, as they do not correspond to any edit    * log items.    * @return 0 if no non-bulk-load files are provided    */
specifier|public
specifier|static
name|long
name|getMaxSequenceIdInList
parameter_list|(
name|List
argument_list|<
name|StoreFile
argument_list|>
name|sfs
parameter_list|)
block|{
name|long
name|max
init|=
literal|0
decl_stmt|;
for|for
control|(
name|StoreFile
name|sf
range|:
name|sfs
control|)
block|{
if|if
condition|(
operator|!
name|sf
operator|.
name|isBulkLoadResult
argument_list|()
condition|)
block|{
name|max
operator|=
name|Math
operator|.
name|max
argument_list|(
name|max
argument_list|,
name|sf
operator|.
name|getMaxSequenceId
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|max
return|;
block|}
comment|/**    * @return true if this storefile was created by HFileOutputFormat    * for a bulk load.    */
name|boolean
name|isBulkLoadResult
parameter_list|()
block|{
return|return
name|metadataMap
operator|.
name|containsKey
argument_list|(
name|BULKLOAD_TIME_KEY
argument_list|)
return|;
block|}
comment|/**    * Return the timestamp at which this bulk load file was generated.    */
specifier|public
name|long
name|getBulkLoadTimestamp
parameter_list|()
block|{
return|return
name|Bytes
operator|.
name|toLong
argument_list|(
name|metadataMap
operator|.
name|get
argument_list|(
name|BULKLOAD_TIME_KEY
argument_list|)
argument_list|)
return|;
block|}
comment|/**    * Returns the block cache or<code>null</code> in case none should be used.    *    * @param conf  The current configuration.    * @return The block cache or<code>null</code>.    */
specifier|public
specifier|static
specifier|synchronized
name|BlockCache
name|getBlockCache
parameter_list|(
name|Configuration
name|conf
parameter_list|)
block|{
if|if
condition|(
name|hfileBlockCache
operator|!=
literal|null
condition|)
return|return
name|hfileBlockCache
return|;
name|float
name|cachePercentage
init|=
name|conf
operator|.
name|getFloat
argument_list|(
name|HFILE_CACHE_SIZE_KEY
argument_list|,
literal|0.0f
argument_list|)
decl_stmt|;
comment|// There should be a better way to optimize this. But oh well.
if|if
condition|(
name|cachePercentage
operator|==
literal|0L
condition|)
return|return
literal|null
return|;
if|if
condition|(
name|cachePercentage
operator|>
literal|1.0
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
name|HFILE_CACHE_SIZE_KEY
operator|+
literal|" must be between 0.0 and 1.0, not> 1.0"
argument_list|)
throw|;
block|}
comment|// Calculate the amount of heap to give the heap.
name|MemoryUsage
name|mu
init|=
name|ManagementFactory
operator|.
name|getMemoryMXBean
argument_list|()
operator|.
name|getHeapMemoryUsage
argument_list|()
decl_stmt|;
name|long
name|cacheSize
init|=
call|(
name|long
call|)
argument_list|(
name|mu
operator|.
name|getMax
argument_list|()
operator|*
name|cachePercentage
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Allocating LruBlockCache with maximum size "
operator|+
name|StringUtils
operator|.
name|humanReadableInt
argument_list|(
name|cacheSize
argument_list|)
argument_list|)
expr_stmt|;
name|hfileBlockCache
operator|=
operator|new
name|LruBlockCache
argument_list|(
name|cacheSize
argument_list|,
name|DEFAULT_BLOCKSIZE_SMALL
argument_list|)
expr_stmt|;
return|return
name|hfileBlockCache
return|;
block|}
comment|/**    * @return the blockcache    */
specifier|public
name|BlockCache
name|getBlockCache
parameter_list|()
block|{
return|return
name|blockcache
condition|?
name|getBlockCache
argument_list|(
name|conf
argument_list|)
else|:
literal|null
return|;
block|}
comment|/**    * Opens reader on this store file.  Called by Constructor.    * @return Reader for the store file.    * @throws IOException    * @see #closeReader()    */
specifier|private
name|StoreFile
operator|.
name|Reader
name|open
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|this
operator|.
name|reader
operator|!=
literal|null
condition|)
block|{
throw|throw
operator|new
name|IllegalAccessError
argument_list|(
literal|"Already open"
argument_list|)
throw|;
block|}
if|if
condition|(
name|isReference
argument_list|()
condition|)
block|{
name|this
operator|.
name|reader
operator|=
operator|new
name|HalfStoreFileReader
argument_list|(
name|this
operator|.
name|fs
argument_list|,
name|this
operator|.
name|referencePath
argument_list|,
name|getBlockCache
argument_list|()
argument_list|,
name|this
operator|.
name|reference
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|this
operator|.
name|reader
operator|=
operator|new
name|StoreFile
operator|.
name|Reader
argument_list|(
name|this
operator|.
name|fs
argument_list|,
name|this
operator|.
name|path
argument_list|,
name|getBlockCache
argument_list|()
argument_list|,
name|this
operator|.
name|inMemory
argument_list|)
expr_stmt|;
block|}
comment|// Load up indices and fileinfo.
name|metadataMap
operator|=
name|Collections
operator|.
name|unmodifiableMap
argument_list|(
name|this
operator|.
name|reader
operator|.
name|loadFileInfo
argument_list|()
argument_list|)
expr_stmt|;
comment|// Read in our metadata.
name|byte
index|[]
name|b
init|=
name|metadataMap
operator|.
name|get
argument_list|(
name|MAX_SEQ_ID_KEY
argument_list|)
decl_stmt|;
if|if
condition|(
name|b
operator|!=
literal|null
condition|)
block|{
comment|// By convention, if halfhfile, top half has a sequence number> bottom
comment|// half. Thats why we add one in below. Its done for case the two halves
comment|// are ever merged back together --rare.  Without it, on open of store,
comment|// since store files are distingushed by sequence id, the one half would
comment|// subsume the other.
name|this
operator|.
name|sequenceid
operator|=
name|Bytes
operator|.
name|toLong
argument_list|(
name|b
argument_list|)
expr_stmt|;
if|if
condition|(
name|isReference
argument_list|()
condition|)
block|{
if|if
condition|(
name|Reference
operator|.
name|isTopFileRegion
argument_list|(
name|this
operator|.
name|reference
operator|.
name|getFileRegion
argument_list|()
argument_list|)
condition|)
block|{
name|this
operator|.
name|sequenceid
operator|+=
literal|1
expr_stmt|;
block|}
block|}
block|}
name|b
operator|=
name|metadataMap
operator|.
name|get
argument_list|(
name|MAJOR_COMPACTION_KEY
argument_list|)
expr_stmt|;
if|if
condition|(
name|b
operator|!=
literal|null
condition|)
block|{
name|boolean
name|mc
init|=
name|Bytes
operator|.
name|toBoolean
argument_list|(
name|b
argument_list|)
decl_stmt|;
if|if
condition|(
name|this
operator|.
name|majorCompaction
operator|==
literal|null
condition|)
block|{
name|this
operator|.
name|majorCompaction
operator|=
operator|new
name|AtomicBoolean
argument_list|(
name|mc
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|this
operator|.
name|majorCompaction
operator|.
name|set
argument_list|(
name|mc
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|this
operator|.
name|bloomType
operator|!=
name|BloomType
operator|.
name|NONE
condition|)
block|{
name|this
operator|.
name|reader
operator|.
name|loadBloomfilter
argument_list|()
expr_stmt|;
block|}
return|return
name|this
operator|.
name|reader
return|;
block|}
comment|/**    * @return Reader for StoreFile. creates if necessary    * @throws IOException    */
specifier|public
name|StoreFile
operator|.
name|Reader
name|createReader
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|this
operator|.
name|reader
operator|==
literal|null
condition|)
block|{
name|this
operator|.
name|reader
operator|=
name|open
argument_list|()
expr_stmt|;
block|}
return|return
name|this
operator|.
name|reader
return|;
block|}
comment|/**    * @return Current reader.  Must call createReader first else returns null.    * @throws IOException    * @see {@link #createReader()}    */
specifier|public
name|StoreFile
operator|.
name|Reader
name|getReader
parameter_list|()
block|{
return|return
name|this
operator|.
name|reader
return|;
block|}
comment|/**    * @throws IOException    */
specifier|public
specifier|synchronized
name|void
name|closeReader
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|this
operator|.
name|reader
operator|!=
literal|null
condition|)
block|{
name|this
operator|.
name|reader
operator|.
name|close
argument_list|()
expr_stmt|;
name|this
operator|.
name|reader
operator|=
literal|null
expr_stmt|;
block|}
block|}
comment|/**    * Delete this file    * @throws IOException    */
specifier|public
name|void
name|deleteReader
parameter_list|()
throws|throws
name|IOException
block|{
name|closeReader
argument_list|()
expr_stmt|;
name|this
operator|.
name|fs
operator|.
name|delete
argument_list|(
name|getPath
argument_list|()
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|String
name|toString
parameter_list|()
block|{
return|return
name|this
operator|.
name|path
operator|.
name|toString
argument_list|()
operator|+
operator|(
name|isReference
argument_list|()
condition|?
literal|"-"
operator|+
name|this
operator|.
name|referencePath
operator|+
literal|"-"
operator|+
name|reference
operator|.
name|toString
argument_list|()
else|:
literal|""
operator|)
return|;
block|}
comment|/**    * @return a length description of this StoreFile, suitable for debug output    */
specifier|public
name|String
name|toStringDetailed
parameter_list|()
block|{
name|StringBuilder
name|sb
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
name|sb
operator|.
name|append
argument_list|(
name|this
operator|.
name|path
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
name|sb
operator|.
name|append
argument_list|(
literal|", isReference="
argument_list|)
operator|.
name|append
argument_list|(
name|isReference
argument_list|()
argument_list|)
expr_stmt|;
name|sb
operator|.
name|append
argument_list|(
literal|", isBulkLoadResult="
argument_list|)
operator|.
name|append
argument_list|(
name|isBulkLoadResult
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|isBulkLoadResult
argument_list|()
condition|)
block|{
name|sb
operator|.
name|append
argument_list|(
literal|", bulkLoadTS="
argument_list|)
operator|.
name|append
argument_list|(
name|getBulkLoadTimestamp
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|sb
operator|.
name|append
argument_list|(
literal|", seqid="
argument_list|)
operator|.
name|append
argument_list|(
name|getMaxSequenceId
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|sb
operator|.
name|append
argument_list|(
literal|", majorCompaction="
argument_list|)
operator|.
name|append
argument_list|(
name|isMajorCompaction
argument_list|()
argument_list|)
expr_stmt|;
return|return
name|sb
operator|.
name|toString
argument_list|()
return|;
block|}
comment|/**    * Utility to help with rename.    * @param fs    * @param src    * @param tgt    * @return True if succeeded.    * @throws IOException    */
specifier|public
specifier|static
name|Path
name|rename
parameter_list|(
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Path
name|src
parameter_list|,
specifier|final
name|Path
name|tgt
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
operator|!
name|fs
operator|.
name|exists
argument_list|(
name|src
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|FileNotFoundException
argument_list|(
name|src
operator|.
name|toString
argument_list|()
argument_list|)
throw|;
block|}
if|if
condition|(
operator|!
name|fs
operator|.
name|rename
argument_list|(
name|src
argument_list|,
name|tgt
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Failed rename of "
operator|+
name|src
operator|+
literal|" to "
operator|+
name|tgt
argument_list|)
throw|;
block|}
return|return
name|tgt
return|;
block|}
comment|/**    * Get a store file writer. Client is responsible for closing file when done.    * If metadata, add BEFORE closing using    * {@link #appendMetadata(org.apache.hadoop.hbase.io.hfile.HFile.Writer, long)}.    * @param fs    * @param dir Path to family directory.  Makes the directory if doesn't exist.    * Creates a file with a unique name in this directory.    * @param blocksize size per filesystem block    * @return HFile.Writer    * @throws IOException    */
specifier|public
specifier|static
name|StoreFile
operator|.
name|Writer
name|createWriter
parameter_list|(
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Path
name|dir
parameter_list|,
specifier|final
name|int
name|blocksize
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|createWriter
argument_list|(
name|fs
argument_list|,
name|dir
argument_list|,
name|blocksize
argument_list|,
literal|null
argument_list|,
literal|null
argument_list|,
literal|null
argument_list|,
name|BloomType
operator|.
name|NONE
argument_list|,
literal|0
argument_list|)
return|;
block|}
comment|/**    * Create a store file writer. Client is responsible for closing file when done.    * If metadata, add BEFORE closing using appendMetadata()    * @param fs    * @param dir Path to family directory.  Makes the directory if doesn't exist.    * Creates a file with a unique name in this directory.    * @param blocksize    * @param algorithm Pass null to get default.    * @param conf HBase system configuration. used with bloom filters    * @param bloomType column family setting for bloom filters    * @param c Pass null to get default.    * @param maxKeySize peak theoretical entry size (maintains error rate)    * @return HFile.Writer    * @throws IOException    */
specifier|public
specifier|static
name|StoreFile
operator|.
name|Writer
name|createWriter
parameter_list|(
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Path
name|dir
parameter_list|,
specifier|final
name|int
name|blocksize
parameter_list|,
specifier|final
name|Compression
operator|.
name|Algorithm
name|algorithm
parameter_list|,
specifier|final
name|KeyValue
operator|.
name|KVComparator
name|c
parameter_list|,
specifier|final
name|Configuration
name|conf
parameter_list|,
name|BloomType
name|bloomType
parameter_list|,
name|int
name|maxKeySize
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
operator|!
name|fs
operator|.
name|exists
argument_list|(
name|dir
argument_list|)
condition|)
block|{
name|fs
operator|.
name|mkdirs
argument_list|(
name|dir
argument_list|)
expr_stmt|;
block|}
name|Path
name|path
init|=
name|getUniqueFile
argument_list|(
name|fs
argument_list|,
name|dir
argument_list|)
decl_stmt|;
if|if
condition|(
name|conf
operator|==
literal|null
operator|||
operator|!
name|conf
operator|.
name|getBoolean
argument_list|(
literal|"io.hfile.bloom.enabled"
argument_list|,
literal|true
argument_list|)
condition|)
block|{
name|bloomType
operator|=
name|BloomType
operator|.
name|NONE
expr_stmt|;
block|}
return|return
operator|new
name|StoreFile
operator|.
name|Writer
argument_list|(
name|fs
argument_list|,
name|path
argument_list|,
name|blocksize
argument_list|,
name|algorithm
operator|==
literal|null
condition|?
name|HFile
operator|.
name|DEFAULT_COMPRESSION_ALGORITHM
else|:
name|algorithm
argument_list|,
name|conf
argument_list|,
name|c
operator|==
literal|null
condition|?
name|KeyValue
operator|.
name|COMPARATOR
else|:
name|c
argument_list|,
name|bloomType
argument_list|,
name|maxKeySize
argument_list|)
return|;
block|}
comment|/**    * @param fs    * @param dir Directory to create file in.    * @return random filename inside passed<code>dir</code>    */
specifier|public
specifier|static
name|Path
name|getUniqueFile
parameter_list|(
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Path
name|dir
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
operator|!
name|fs
operator|.
name|getFileStatus
argument_list|(
name|dir
argument_list|)
operator|.
name|isDir
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Expecting "
operator|+
name|dir
operator|.
name|toString
argument_list|()
operator|+
literal|" to be a directory"
argument_list|)
throw|;
block|}
return|return
name|fs
operator|.
name|getFileStatus
argument_list|(
name|dir
argument_list|)
operator|.
name|isDir
argument_list|()
condition|?
name|getRandomFilename
argument_list|(
name|fs
argument_list|,
name|dir
argument_list|)
else|:
name|dir
return|;
block|}
comment|/**    *    * @param fs    * @param dir    * @return Path to a file that doesn't exist at time of this invocation.    * @throws IOException    */
specifier|static
name|Path
name|getRandomFilename
parameter_list|(
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Path
name|dir
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|getRandomFilename
argument_list|(
name|fs
argument_list|,
name|dir
argument_list|,
literal|null
argument_list|)
return|;
block|}
comment|/**    *    * @param fs    * @param dir    * @param suffix    * @return Path to a file that doesn't exist at time of this invocation.    * @throws IOException    */
specifier|static
name|Path
name|getRandomFilename
parameter_list|(
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Path
name|dir
parameter_list|,
specifier|final
name|String
name|suffix
parameter_list|)
throws|throws
name|IOException
block|{
name|long
name|id
init|=
operator|-
literal|1
decl_stmt|;
name|Path
name|p
init|=
literal|null
decl_stmt|;
do|do
block|{
name|id
operator|=
name|Math
operator|.
name|abs
argument_list|(
name|rand
operator|.
name|nextLong
argument_list|()
argument_list|)
expr_stmt|;
name|p
operator|=
operator|new
name|Path
argument_list|(
name|dir
argument_list|,
name|Long
operator|.
name|toString
argument_list|(
name|id
argument_list|)
operator|+
operator|(
operator|(
name|suffix
operator|==
literal|null
operator|||
name|suffix
operator|.
name|length
argument_list|()
operator|<=
literal|0
operator|)
condition|?
literal|""
else|:
name|suffix
operator|)
argument_list|)
expr_stmt|;
block|}
do|while
condition|(
name|fs
operator|.
name|exists
argument_list|(
name|p
argument_list|)
condition|)
do|;
return|return
name|p
return|;
block|}
comment|/*    * Write out a split reference.    * @param fs    * @param splitDir Presumes path format is actually    *<code>SOME_DIRECTORY/REGIONNAME/FAMILY</code>.    * @param f File to split.    * @param splitRow    * @param range    * @return Path to created reference.    * @throws IOException    */
specifier|static
name|Path
name|split
parameter_list|(
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Path
name|splitDir
parameter_list|,
specifier|final
name|StoreFile
name|f
parameter_list|,
specifier|final
name|byte
index|[]
name|splitRow
parameter_list|,
specifier|final
name|Reference
operator|.
name|Range
name|range
parameter_list|)
throws|throws
name|IOException
block|{
comment|// A reference to the bottom half of the hsf store file.
name|Reference
name|r
init|=
operator|new
name|Reference
argument_list|(
name|splitRow
argument_list|,
name|range
argument_list|)
decl_stmt|;
comment|// Add the referred-to regions name as a dot separated suffix.
comment|// See REF_NAME_PARSER regex above.  The referred-to regions name is
comment|// up in the path of the passed in<code>f</code> -- parentdir is family,
comment|// then the directory above is the region name.
name|String
name|parentRegionName
init|=
name|f
operator|.
name|getPath
argument_list|()
operator|.
name|getParent
argument_list|()
operator|.
name|getParent
argument_list|()
operator|.
name|getName
argument_list|()
decl_stmt|;
comment|// Write reference with same file id only with the other region name as
comment|// suffix and into the new region location (under same family).
name|Path
name|p
init|=
operator|new
name|Path
argument_list|(
name|splitDir
argument_list|,
name|f
operator|.
name|getPath
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|"."
operator|+
name|parentRegionName
argument_list|)
decl_stmt|;
return|return
name|r
operator|.
name|write
argument_list|(
name|fs
argument_list|,
name|p
argument_list|)
return|;
block|}
specifier|public
specifier|static
enum|enum
name|BloomType
block|{
comment|/**      * Bloomfilters disabled      */
name|NONE
block|,
comment|/**      * Bloom enabled with Table row as Key      */
name|ROW
block|,
comment|/**      * Bloom enabled with Table row& column (family+qualifier) as Key      */
name|ROWCOL
block|}
comment|/**    *    */
specifier|public
specifier|static
class|class
name|Reader
extends|extends
name|HFile
operator|.
name|Reader
block|{
comment|/** Bloom Filter class.  Caches only meta, pass in data */
specifier|protected
name|BloomFilter
name|bloomFilter
init|=
literal|null
decl_stmt|;
comment|/** Type of bloom filter (e.g. ROW vs ROWCOL) */
specifier|protected
name|BloomType
name|bloomFilterType
decl_stmt|;
specifier|public
name|Reader
parameter_list|(
name|FileSystem
name|fs
parameter_list|,
name|Path
name|path
parameter_list|,
name|BlockCache
name|cache
parameter_list|,
name|boolean
name|inMemory
parameter_list|)
throws|throws
name|IOException
block|{
name|super
argument_list|(
name|fs
argument_list|,
name|path
argument_list|,
name|cache
argument_list|,
name|inMemory
argument_list|)
expr_stmt|;
block|}
specifier|public
name|Reader
parameter_list|(
specifier|final
name|FSDataInputStream
name|fsdis
parameter_list|,
specifier|final
name|long
name|size
parameter_list|,
specifier|final
name|BlockCache
name|cache
parameter_list|,
specifier|final
name|boolean
name|inMemory
parameter_list|)
block|{
name|super
argument_list|(
name|fsdis
argument_list|,
name|size
argument_list|,
name|cache
argument_list|,
name|inMemory
argument_list|)
expr_stmt|;
name|bloomFilterType
operator|=
name|BloomType
operator|.
name|NONE
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|byte
index|[]
argument_list|>
name|loadFileInfo
parameter_list|()
throws|throws
name|IOException
block|{
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|byte
index|[]
argument_list|>
name|fi
init|=
name|super
operator|.
name|loadFileInfo
argument_list|()
decl_stmt|;
name|byte
index|[]
name|b
init|=
name|fi
operator|.
name|get
argument_list|(
name|BLOOM_FILTER_TYPE_KEY
argument_list|)
decl_stmt|;
if|if
condition|(
name|b
operator|!=
literal|null
condition|)
block|{
name|bloomFilterType
operator|=
name|BloomType
operator|.
name|valueOf
argument_list|(
name|Bytes
operator|.
name|toString
argument_list|(
name|b
argument_list|)
argument_list|)
expr_stmt|;
block|}
return|return
name|fi
return|;
block|}
comment|/**      * Load the bloom filter for this HFile into memory.      * Assumes the HFile has already been loaded      */
specifier|public
name|void
name|loadBloomfilter
parameter_list|()
block|{
if|if
condition|(
name|this
operator|.
name|bloomFilter
operator|!=
literal|null
condition|)
block|{
return|return;
comment|// already loaded
block|}
comment|// see if bloom filter information is in the metadata
try|try
block|{
name|ByteBuffer
name|b
init|=
name|getMetaBlock
argument_list|(
name|BLOOM_FILTER_META_KEY
argument_list|,
literal|false
argument_list|)
decl_stmt|;
if|if
condition|(
name|b
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
name|bloomFilterType
operator|==
name|BloomType
operator|.
name|NONE
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"valid bloom filter type not found in FileInfo"
argument_list|)
throw|;
block|}
name|this
operator|.
name|bloomFilter
operator|=
operator|new
name|ByteBloomFilter
argument_list|(
name|b
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Loaded "
operator|+
operator|(
name|bloomFilterType
operator|==
name|BloomType
operator|.
name|ROW
condition|?
literal|"row"
else|:
literal|"col"
operator|)
operator|+
literal|" bloom filter metadata for "
operator|+
name|name
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Error reading bloom filter meta -- proceeding without"
argument_list|,
name|e
argument_list|)
expr_stmt|;
name|this
operator|.
name|bloomFilter
operator|=
literal|null
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IllegalArgumentException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Bad bloom filter meta -- proceeding without"
argument_list|,
name|e
argument_list|)
expr_stmt|;
name|this
operator|.
name|bloomFilter
operator|=
literal|null
expr_stmt|;
block|}
block|}
name|BloomFilter
name|getBloomFilter
parameter_list|()
block|{
return|return
name|this
operator|.
name|bloomFilter
return|;
block|}
comment|/**      * @return bloom type information associated with this store file      */
specifier|public
name|BloomType
name|getBloomFilterType
parameter_list|()
block|{
return|return
name|this
operator|.
name|bloomFilterType
return|;
block|}
annotation|@
name|Override
specifier|public
name|int
name|getFilterEntries
parameter_list|()
block|{
return|return
operator|(
name|this
operator|.
name|bloomFilter
operator|!=
literal|null
operator|)
condition|?
name|this
operator|.
name|bloomFilter
operator|.
name|getKeyCount
argument_list|()
else|:
name|super
operator|.
name|getFilterEntries
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|HFileScanner
name|getScanner
parameter_list|(
name|boolean
name|cacheBlocks
parameter_list|,
specifier|final
name|boolean
name|pread
parameter_list|)
block|{
return|return
operator|new
name|Scanner
argument_list|(
name|this
argument_list|,
name|cacheBlocks
argument_list|,
name|pread
argument_list|)
return|;
block|}
specifier|protected
class|class
name|Scanner
extends|extends
name|HFile
operator|.
name|Reader
operator|.
name|Scanner
block|{
specifier|public
name|Scanner
parameter_list|(
name|Reader
name|r
parameter_list|,
name|boolean
name|cacheBlocks
parameter_list|,
specifier|final
name|boolean
name|pread
parameter_list|)
block|{
name|super
argument_list|(
name|r
argument_list|,
name|cacheBlocks
argument_list|,
name|pread
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|shouldSeek
parameter_list|(
specifier|final
name|byte
index|[]
name|row
parameter_list|,
specifier|final
name|SortedSet
argument_list|<
name|byte
index|[]
argument_list|>
name|columns
parameter_list|)
block|{
if|if
condition|(
name|bloomFilter
operator|==
literal|null
condition|)
block|{
return|return
literal|true
return|;
block|}
name|byte
index|[]
name|key
decl_stmt|;
switch|switch
condition|(
name|bloomFilterType
condition|)
block|{
case|case
name|ROW
case|:
name|key
operator|=
name|row
expr_stmt|;
break|break;
case|case
name|ROWCOL
case|:
if|if
condition|(
name|columns
operator|.
name|size
argument_list|()
operator|==
literal|1
condition|)
block|{
name|byte
index|[]
name|col
init|=
name|columns
operator|.
name|first
argument_list|()
decl_stmt|;
name|key
operator|=
name|Bytes
operator|.
name|add
argument_list|(
name|row
argument_list|,
name|col
argument_list|)
expr_stmt|;
break|break;
block|}
comment|//$FALL-THROUGH$
default|default:
return|return
literal|true
return|;
block|}
try|try
block|{
name|ByteBuffer
name|bloom
init|=
name|getMetaBlock
argument_list|(
name|BLOOM_FILTER_DATA_KEY
argument_list|,
literal|true
argument_list|)
decl_stmt|;
if|if
condition|(
name|bloom
operator|!=
literal|null
condition|)
block|{
return|return
name|bloomFilter
operator|.
name|contains
argument_list|(
name|key
argument_list|,
name|bloom
argument_list|)
return|;
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Error reading bloom filter data -- proceeding without"
argument_list|,
name|e
argument_list|)
expr_stmt|;
name|bloomFilter
operator|=
literal|null
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IllegalArgumentException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Bad bloom filter data -- proceeding without"
argument_list|,
name|e
argument_list|)
expr_stmt|;
name|bloomFilter
operator|=
literal|null
expr_stmt|;
block|}
return|return
literal|true
return|;
block|}
block|}
block|}
comment|/**    *    */
specifier|public
specifier|static
class|class
name|Writer
extends|extends
name|HFile
operator|.
name|Writer
block|{
specifier|private
specifier|final
name|BloomFilter
name|bloomFilter
decl_stmt|;
specifier|private
specifier|final
name|BloomType
name|bloomType
decl_stmt|;
specifier|private
name|KVComparator
name|kvComparator
decl_stmt|;
specifier|private
name|KeyValue
name|lastKv
init|=
literal|null
decl_stmt|;
specifier|private
name|byte
index|[]
name|lastByteArray
init|=
literal|null
decl_stmt|;
comment|/**      * Creates an HFile.Writer that also write helpful meta data.      * @param fs file system to write to      * @param path file name to create      * @param blocksize HDFS block size      * @param compress HDFS block compression      * @param conf user configuration      * @param comparator key comparator      * @param bloomType bloom filter setting      * @param maxKeys maximum amount of keys to add (for blooms)      * @throws IOException problem writing to FS      */
specifier|public
name|Writer
parameter_list|(
name|FileSystem
name|fs
parameter_list|,
name|Path
name|path
parameter_list|,
name|int
name|blocksize
parameter_list|,
name|Compression
operator|.
name|Algorithm
name|compress
parameter_list|,
specifier|final
name|Configuration
name|conf
parameter_list|,
specifier|final
name|KVComparator
name|comparator
parameter_list|,
name|BloomType
name|bloomType
parameter_list|,
name|int
name|maxKeys
parameter_list|)
throws|throws
name|IOException
block|{
name|super
argument_list|(
name|fs
argument_list|,
name|path
argument_list|,
name|blocksize
argument_list|,
name|compress
argument_list|,
name|comparator
operator|.
name|getRawComparator
argument_list|()
argument_list|)
expr_stmt|;
name|this
operator|.
name|kvComparator
operator|=
name|comparator
expr_stmt|;
if|if
condition|(
name|bloomType
operator|!=
name|BloomType
operator|.
name|NONE
operator|&&
name|conf
operator|!=
literal|null
condition|)
block|{
name|float
name|err
init|=
name|conf
operator|.
name|getFloat
argument_list|(
literal|"io.hfile.bloom.error.rate"
argument_list|,
operator|(
name|float
operator|)
literal|0.01
argument_list|)
decl_stmt|;
name|int
name|maxFold
init|=
name|conf
operator|.
name|getInt
argument_list|(
literal|"io.hfile.bloom.max.fold"
argument_list|,
literal|7
argument_list|)
decl_stmt|;
name|this
operator|.
name|bloomFilter
operator|=
operator|new
name|ByteBloomFilter
argument_list|(
name|maxKeys
argument_list|,
name|err
argument_list|,
name|Hash
operator|.
name|getHashType
argument_list|(
name|conf
argument_list|)
argument_list|,
name|maxFold
argument_list|)
expr_stmt|;
name|this
operator|.
name|bloomFilter
operator|.
name|allocBloom
argument_list|()
expr_stmt|;
name|this
operator|.
name|bloomType
operator|=
name|bloomType
expr_stmt|;
block|}
else|else
block|{
name|this
operator|.
name|bloomFilter
operator|=
literal|null
expr_stmt|;
name|this
operator|.
name|bloomType
operator|=
name|BloomType
operator|.
name|NONE
expr_stmt|;
block|}
block|}
comment|/**      * Writes meta data.      * Call before {@link #close()} since its written as meta data to this file.      * @param maxSequenceId Maximum sequence id.      * @param majorCompaction True if this file is product of a major compaction      * @throws IOException problem writing to FS      */
specifier|public
name|void
name|appendMetadata
parameter_list|(
specifier|final
name|long
name|maxSequenceId
parameter_list|,
specifier|final
name|boolean
name|majorCompaction
parameter_list|)
throws|throws
name|IOException
block|{
name|appendFileInfo
argument_list|(
name|MAX_SEQ_ID_KEY
argument_list|,
name|Bytes
operator|.
name|toBytes
argument_list|(
name|maxSequenceId
argument_list|)
argument_list|)
expr_stmt|;
name|appendFileInfo
argument_list|(
name|MAJOR_COMPACTION_KEY
argument_list|,
name|Bytes
operator|.
name|toBytes
argument_list|(
name|majorCompaction
argument_list|)
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|append
parameter_list|(
specifier|final
name|KeyValue
name|kv
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|this
operator|.
name|bloomFilter
operator|!=
literal|null
condition|)
block|{
comment|// only add to the bloom filter on a new, unique key
name|boolean
name|newKey
init|=
literal|true
decl_stmt|;
if|if
condition|(
name|this
operator|.
name|lastKv
operator|!=
literal|null
condition|)
block|{
switch|switch
condition|(
name|bloomType
condition|)
block|{
case|case
name|ROW
case|:
name|newKey
operator|=
operator|!
name|kvComparator
operator|.
name|matchingRows
argument_list|(
name|kv
argument_list|,
name|lastKv
argument_list|)
expr_stmt|;
break|break;
case|case
name|ROWCOL
case|:
name|newKey
operator|=
operator|!
name|kvComparator
operator|.
name|matchingRowColumn
argument_list|(
name|kv
argument_list|,
name|lastKv
argument_list|)
expr_stmt|;
break|break;
case|case
name|NONE
case|:
name|newKey
operator|=
literal|false
expr_stmt|;
block|}
block|}
if|if
condition|(
name|newKey
condition|)
block|{
comment|/*            * http://2.bp.blogspot.com/_Cib_A77V54U/StZMrzaKufI/AAAAAAAAADo/ZhK7bGoJdMQ/s400/KeyValue.png            * Key = RowLen + Row + FamilyLen + Column [Family + Qualifier] + TimeStamp            *            * 2 Types of Filtering:            *  1. Row = Row            *  2. RowCol = Row + Qualifier            */
switch|switch
condition|(
name|bloomType
condition|)
block|{
case|case
name|ROW
case|:
name|this
operator|.
name|bloomFilter
operator|.
name|add
argument_list|(
name|kv
operator|.
name|getBuffer
argument_list|()
argument_list|,
name|kv
operator|.
name|getRowOffset
argument_list|()
argument_list|,
name|kv
operator|.
name|getRowLength
argument_list|()
argument_list|)
expr_stmt|;
break|break;
case|case
name|ROWCOL
case|:
comment|// merge(row, qualifier)
name|int
name|ro
init|=
name|kv
operator|.
name|getRowOffset
argument_list|()
decl_stmt|;
name|int
name|rl
init|=
name|kv
operator|.
name|getRowLength
argument_list|()
decl_stmt|;
name|int
name|qo
init|=
name|kv
operator|.
name|getQualifierOffset
argument_list|()
decl_stmt|;
name|int
name|ql
init|=
name|kv
operator|.
name|getQualifierLength
argument_list|()
decl_stmt|;
name|byte
index|[]
name|result
init|=
operator|new
name|byte
index|[
name|rl
operator|+
name|ql
index|]
decl_stmt|;
name|System
operator|.
name|arraycopy
argument_list|(
name|kv
operator|.
name|getBuffer
argument_list|()
argument_list|,
name|ro
argument_list|,
name|result
argument_list|,
literal|0
argument_list|,
name|rl
argument_list|)
expr_stmt|;
name|System
operator|.
name|arraycopy
argument_list|(
name|kv
operator|.
name|getBuffer
argument_list|()
argument_list|,
name|qo
argument_list|,
name|result
argument_list|,
name|rl
argument_list|,
name|ql
argument_list|)
expr_stmt|;
name|this
operator|.
name|bloomFilter
operator|.
name|add
argument_list|(
name|result
argument_list|)
expr_stmt|;
break|break;
default|default:
block|}
name|this
operator|.
name|lastKv
operator|=
name|kv
expr_stmt|;
block|}
block|}
name|super
operator|.
name|append
argument_list|(
name|kv
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|append
parameter_list|(
specifier|final
name|byte
index|[]
name|key
parameter_list|,
specifier|final
name|byte
index|[]
name|value
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|this
operator|.
name|bloomFilter
operator|!=
literal|null
condition|)
block|{
comment|// only add to the bloom filter on a new row
if|if
condition|(
name|this
operator|.
name|lastByteArray
operator|==
literal|null
operator|||
operator|!
name|Arrays
operator|.
name|equals
argument_list|(
name|key
argument_list|,
name|lastByteArray
argument_list|)
condition|)
block|{
name|this
operator|.
name|bloomFilter
operator|.
name|add
argument_list|(
name|key
argument_list|)
expr_stmt|;
name|this
operator|.
name|lastByteArray
operator|=
name|key
expr_stmt|;
block|}
block|}
name|super
operator|.
name|append
argument_list|(
name|key
argument_list|,
name|value
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|close
parameter_list|()
throws|throws
name|IOException
block|{
comment|// make sure we wrote something to the bloom before adding it
if|if
condition|(
name|this
operator|.
name|bloomFilter
operator|!=
literal|null
operator|&&
name|this
operator|.
name|bloomFilter
operator|.
name|getKeyCount
argument_list|()
operator|>
literal|0
condition|)
block|{
name|bloomFilter
operator|.
name|finalize
argument_list|()
expr_stmt|;
if|if
condition|(
name|this
operator|.
name|bloomFilter
operator|.
name|getMaxKeys
argument_list|()
operator|>
literal|0
condition|)
block|{
name|int
name|b
init|=
name|this
operator|.
name|bloomFilter
operator|.
name|getByteSize
argument_list|()
decl_stmt|;
name|int
name|k
init|=
name|this
operator|.
name|bloomFilter
operator|.
name|getKeyCount
argument_list|()
decl_stmt|;
name|int
name|m
init|=
name|this
operator|.
name|bloomFilter
operator|.
name|getMaxKeys
argument_list|()
decl_stmt|;
name|StoreFile
operator|.
name|LOG
operator|.
name|info
argument_list|(
literal|"Bloom added to HFile.  "
operator|+
name|b
operator|+
literal|"B, "
operator|+
name|k
operator|+
literal|"/"
operator|+
name|m
operator|+
literal|" ("
operator|+
name|NumberFormat
operator|.
name|getPercentInstance
argument_list|()
operator|.
name|format
argument_list|(
operator|(
operator|(
name|double
operator|)
name|k
operator|)
operator|/
operator|(
operator|(
name|double
operator|)
name|m
operator|)
argument_list|)
operator|+
literal|")"
argument_list|)
expr_stmt|;
block|}
name|appendMetaBlock
argument_list|(
name|BLOOM_FILTER_META_KEY
argument_list|,
name|bloomFilter
operator|.
name|getMetaWriter
argument_list|()
argument_list|)
expr_stmt|;
name|appendMetaBlock
argument_list|(
name|BLOOM_FILTER_DATA_KEY
argument_list|,
name|bloomFilter
operator|.
name|getDataWriter
argument_list|()
argument_list|)
expr_stmt|;
name|appendFileInfo
argument_list|(
name|BLOOM_FILTER_TYPE_KEY
argument_list|,
name|Bytes
operator|.
name|toBytes
argument_list|(
name|bloomType
operator|.
name|toString
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|super
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**    * Useful comparators for comparing StoreFiles.    */
specifier|abstract
specifier|static
class|class
name|Comparators
block|{
comment|/**      * Comparator that compares based on the flush time of      * the StoreFiles. All bulk loads are placed before all non-      * bulk loads, and then all files are sorted by sequence ID.      * If there are ties, the path name is used as a tie-breaker.      */
specifier|static
specifier|final
name|Comparator
argument_list|<
name|StoreFile
argument_list|>
name|FLUSH_TIME
init|=
name|Ordering
operator|.
name|compound
argument_list|(
name|ImmutableList
operator|.
name|of
argument_list|(
name|Ordering
operator|.
name|natural
argument_list|()
operator|.
name|onResultOf
argument_list|(
operator|new
name|GetBulkTime
argument_list|()
argument_list|)
argument_list|,
name|Ordering
operator|.
name|natural
argument_list|()
operator|.
name|onResultOf
argument_list|(
operator|new
name|GetSeqId
argument_list|()
argument_list|)
argument_list|,
name|Ordering
operator|.
name|natural
argument_list|()
operator|.
name|onResultOf
argument_list|(
operator|new
name|GetPathName
argument_list|()
argument_list|)
argument_list|)
argument_list|)
decl_stmt|;
specifier|private
specifier|static
class|class
name|GetBulkTime
implements|implements
name|Function
argument_list|<
name|StoreFile
argument_list|,
name|Long
argument_list|>
block|{
annotation|@
name|Override
specifier|public
name|Long
name|apply
parameter_list|(
name|StoreFile
name|sf
parameter_list|)
block|{
if|if
condition|(
operator|!
name|sf
operator|.
name|isBulkLoadResult
argument_list|()
condition|)
return|return
name|Long
operator|.
name|MAX_VALUE
return|;
return|return
name|sf
operator|.
name|getBulkLoadTimestamp
argument_list|()
return|;
block|}
block|}
specifier|private
specifier|static
class|class
name|GetSeqId
implements|implements
name|Function
argument_list|<
name|StoreFile
argument_list|,
name|Long
argument_list|>
block|{
annotation|@
name|Override
specifier|public
name|Long
name|apply
parameter_list|(
name|StoreFile
name|sf
parameter_list|)
block|{
if|if
condition|(
name|sf
operator|.
name|isBulkLoadResult
argument_list|()
condition|)
return|return
operator|-
literal|1L
return|;
return|return
name|sf
operator|.
name|getMaxSequenceId
argument_list|()
return|;
block|}
block|}
specifier|private
specifier|static
class|class
name|GetPathName
implements|implements
name|Function
argument_list|<
name|StoreFile
argument_list|,
name|String
argument_list|>
block|{
annotation|@
name|Override
specifier|public
name|String
name|apply
parameter_list|(
name|StoreFile
name|sf
parameter_list|)
block|{
return|return
name|sf
operator|.
name|getPath
argument_list|()
operator|.
name|getName
argument_list|()
return|;
block|}
block|}
block|}
block|}
end_class

end_unit

