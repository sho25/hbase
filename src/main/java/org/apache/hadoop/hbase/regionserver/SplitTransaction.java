begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Copyright 2010 The Apache Software Foundation  *  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ListIterator
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|Callable
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ExecutionException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|Executors
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|Future
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ThreadFactory
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ThreadPoolExecutor
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|TimeUnit
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|Log
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|LogFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileStatus
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HRegionInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|Server
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|ServerName
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|catalog
operator|.
name|MetaEditor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|executor
operator|.
name|RegionTransitionData
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|executor
operator|.
name|EventHandler
operator|.
name|EventType
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|Reference
operator|.
name|Range
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|Bytes
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|CancelableProgressable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|EnvironmentEdgeManager
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|FSUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|PairOfSameType
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|Writables
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|zookeeper
operator|.
name|ZKAssign
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|zookeeper
operator|.
name|ZKUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|zookeeper
operator|.
name|ZooKeeperWatcher
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|zookeeper
operator|.
name|KeeperException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|zookeeper
operator|.
name|KeeperException
operator|.
name|NodeExistsException
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ThreadFactoryBuilder
import|;
end_import

begin_comment
comment|/**  * Executes region split as a "transaction".  Call {@link #prepare()} to setup  * the transaction, {@link #execute(OnlineRegions)} to run the transaction and  * {@link #rollback(OnlineRegions)} to cleanup if execute fails.  *  *<p>Here is an example of how you would use this class:  *<pre>  *  SplitTransaction st = new SplitTransaction(this.conf, parent, midKey)  *  if (!st.prepare()) return;  *  try {  *    st.execute(myOnlineRegions);  *  } catch (IOException ioe) {  *    try {  *      st.rollback(myOnlineRegions);  *      return;  *    } catch (RuntimeException e) {  *      myAbortable.abort("Failed split, abort");  *    }  *  }  *</Pre>  *<p>This class is not thread safe.  Caller needs ensure split is run by  * one thread only.  */
end_comment

begin_class
specifier|public
class|class
name|SplitTransaction
block|{
specifier|private
specifier|static
specifier|final
name|Log
name|LOG
init|=
name|LogFactory
operator|.
name|getLog
argument_list|(
name|SplitTransaction
operator|.
name|class
argument_list|)
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|String
name|SPLITDIR
init|=
literal|"splits"
decl_stmt|;
comment|/*    * Region to split    */
specifier|private
specifier|final
name|HRegion
name|parent
decl_stmt|;
specifier|private
name|HRegionInfo
name|hri_a
decl_stmt|;
specifier|private
name|HRegionInfo
name|hri_b
decl_stmt|;
specifier|private
name|Path
name|splitdir
decl_stmt|;
specifier|private
name|long
name|fileSplitTimeout
init|=
literal|30000
decl_stmt|;
specifier|private
name|int
name|znodeVersion
init|=
operator|-
literal|1
decl_stmt|;
comment|/*    * Row to split around    */
specifier|private
specifier|final
name|byte
index|[]
name|splitrow
decl_stmt|;
comment|/**    * Types to add to the transaction journal    */
enum|enum
name|JournalEntry
block|{
comment|/**      * Set region as in transition, set it into SPLITTING state.      */
name|SET_SPLITTING_IN_ZK
block|,
comment|/**      * We created the temporary split data directory.      */
name|CREATE_SPLIT_DIR
block|,
comment|/**      * Closed the parent region.      */
name|CLOSED_PARENT_REGION
block|,
comment|/**      * The parent has been taken out of the server's online regions list.      */
name|OFFLINED_PARENT
block|,
comment|/**      * Started in on creation of the first daughter region.      */
name|STARTED_REGION_A_CREATION
block|,
comment|/**      * Started in on the creation of the second daughter region.      */
name|STARTED_REGION_B_CREATION
block|}
comment|/*    * Journal of how far the split transaction has progressed.    */
specifier|private
specifier|final
name|List
argument_list|<
name|JournalEntry
argument_list|>
name|journal
init|=
operator|new
name|ArrayList
argument_list|<
name|JournalEntry
argument_list|>
argument_list|()
decl_stmt|;
comment|/**    * Constructor    * @param services So we can online new servces.  If null, we'll skip onlining    * (Useful testing).    * @param c Configuration to use running split    * @param r Region to split    * @param splitrow Row to split around    */
specifier|public
name|SplitTransaction
parameter_list|(
specifier|final
name|HRegion
name|r
parameter_list|,
specifier|final
name|byte
index|[]
name|splitrow
parameter_list|)
block|{
name|this
operator|.
name|parent
operator|=
name|r
expr_stmt|;
name|this
operator|.
name|splitrow
operator|=
name|splitrow
expr_stmt|;
name|this
operator|.
name|splitdir
operator|=
name|getSplitDir
argument_list|(
name|this
operator|.
name|parent
argument_list|)
expr_stmt|;
block|}
comment|/**    * Does checks on split inputs.    * @return<code>true</code> if the region is splittable else    *<code>false</code> if it is not (e.g. its already closed, etc.).    */
specifier|public
name|boolean
name|prepare
parameter_list|()
block|{
if|if
condition|(
name|this
operator|.
name|parent
operator|.
name|isClosed
argument_list|()
operator|||
name|this
operator|.
name|parent
operator|.
name|isClosing
argument_list|()
condition|)
return|return
literal|false
return|;
name|HRegionInfo
name|hri
init|=
name|this
operator|.
name|parent
operator|.
name|getRegionInfo
argument_list|()
decl_stmt|;
name|parent
operator|.
name|prepareToSplit
argument_list|()
expr_stmt|;
comment|// Check splitrow.
name|byte
index|[]
name|startKey
init|=
name|hri
operator|.
name|getStartKey
argument_list|()
decl_stmt|;
name|byte
index|[]
name|endKey
init|=
name|hri
operator|.
name|getEndKey
argument_list|()
decl_stmt|;
if|if
condition|(
name|Bytes
operator|.
name|equals
argument_list|(
name|startKey
argument_list|,
name|splitrow
argument_list|)
operator|||
operator|!
name|this
operator|.
name|parent
operator|.
name|getRegionInfo
argument_list|()
operator|.
name|containsRow
argument_list|(
name|splitrow
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Split row is not inside region key range or is equal to "
operator|+
literal|"startkey: "
operator|+
name|Bytes
operator|.
name|toString
argument_list|(
name|this
operator|.
name|splitrow
argument_list|)
argument_list|)
expr_stmt|;
return|return
literal|false
return|;
block|}
name|long
name|rid
init|=
name|getDaughterRegionIdTimestamp
argument_list|(
name|hri
argument_list|)
decl_stmt|;
name|this
operator|.
name|hri_a
operator|=
operator|new
name|HRegionInfo
argument_list|(
name|hri
operator|.
name|getTableDesc
argument_list|()
argument_list|,
name|startKey
argument_list|,
name|this
operator|.
name|splitrow
argument_list|,
literal|false
argument_list|,
name|rid
argument_list|)
expr_stmt|;
name|this
operator|.
name|hri_b
operator|=
operator|new
name|HRegionInfo
argument_list|(
name|hri
operator|.
name|getTableDesc
argument_list|()
argument_list|,
name|this
operator|.
name|splitrow
argument_list|,
name|endKey
argument_list|,
literal|false
argument_list|,
name|rid
argument_list|)
expr_stmt|;
return|return
literal|true
return|;
block|}
comment|/**    * Calculate daughter regionid to use.    * @param hri Parent {@link HRegionInfo}    * @return Daughter region id (timestamp) to use.    */
specifier|private
specifier|static
name|long
name|getDaughterRegionIdTimestamp
parameter_list|(
specifier|final
name|HRegionInfo
name|hri
parameter_list|)
block|{
name|long
name|rid
init|=
name|EnvironmentEdgeManager
operator|.
name|currentTimeMillis
argument_list|()
decl_stmt|;
comment|// Regionid is timestamp.  Can't be less than that of parent else will insert
comment|// at wrong location in .META. (See HBASE-710).
if|if
condition|(
name|rid
operator|<
name|hri
operator|.
name|getRegionId
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Clock skew; parent regions id is "
operator|+
name|hri
operator|.
name|getRegionId
argument_list|()
operator|+
literal|" but current time here is "
operator|+
name|rid
argument_list|)
expr_stmt|;
name|rid
operator|=
name|hri
operator|.
name|getRegionId
argument_list|()
operator|+
literal|1
expr_stmt|;
block|}
return|return
name|rid
return|;
block|}
comment|/**    * Run the transaction.    * @param server Hosting server instance.    * @param services Used to online/offline regions.    * @throws IOException If thrown, transaction failed. Call {@link #rollback(OnlineRegions)}    * @return Regions created    * @throws KeeperException    * @throws NodeExistsException     * @see #rollback(OnlineRegions)    */
specifier|public
name|PairOfSameType
argument_list|<
name|HRegion
argument_list|>
name|execute
parameter_list|(
specifier|final
name|Server
name|server
parameter_list|,
specifier|final
name|RegionServerServices
name|services
parameter_list|)
throws|throws
name|IOException
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Starting split of region "
operator|+
name|this
operator|.
name|parent
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|server
operator|!=
literal|null
operator|&&
name|server
operator|.
name|isStopped
argument_list|()
operator|)
operator|||
operator|(
name|services
operator|!=
literal|null
operator|&&
name|services
operator|.
name|isStopping
argument_list|()
operator|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Server is stopped or stopping"
argument_list|)
throw|;
block|}
assert|assert
operator|!
name|this
operator|.
name|parent
operator|.
name|lock
operator|.
name|writeLock
argument_list|()
operator|.
name|isHeldByCurrentThread
argument_list|()
operator|:
literal|"Unsafe to hold write lock while performing RPCs"
assert|;
comment|// Coprocessor callback
if|if
condition|(
name|this
operator|.
name|parent
operator|.
name|getCoprocessorHost
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|this
operator|.
name|parent
operator|.
name|getCoprocessorHost
argument_list|()
operator|.
name|preSplit
argument_list|()
expr_stmt|;
block|}
comment|// If true, no cluster to write meta edits to or to update znodes in.
name|boolean
name|testing
init|=
name|server
operator|==
literal|null
condition|?
literal|true
else|:
name|server
operator|.
name|getConfiguration
argument_list|()
operator|.
name|getBoolean
argument_list|(
literal|"hbase.testing.nocluster"
argument_list|,
literal|false
argument_list|)
decl_stmt|;
name|this
operator|.
name|fileSplitTimeout
operator|=
name|testing
condition|?
name|this
operator|.
name|fileSplitTimeout
else|:
name|server
operator|.
name|getConfiguration
argument_list|()
operator|.
name|getLong
argument_list|(
literal|"hbase.regionserver.fileSplitTimeout"
argument_list|,
name|this
operator|.
name|fileSplitTimeout
argument_list|)
expr_stmt|;
comment|// Set ephemeral SPLITTING znode up in zk.  Mocked servers sometimes don't
comment|// have zookeeper so don't do zk stuff if zookeeper is null
if|if
condition|(
name|server
operator|!=
literal|null
operator|&&
name|server
operator|.
name|getZooKeeper
argument_list|()
operator|!=
literal|null
condition|)
block|{
try|try
block|{
name|this
operator|.
name|znodeVersion
operator|=
name|createNodeSplitting
argument_list|(
name|server
operator|.
name|getZooKeeper
argument_list|()
argument_list|,
name|this
operator|.
name|parent
operator|.
name|getRegionInfo
argument_list|()
argument_list|,
name|server
operator|.
name|getServerName
argument_list|()
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|KeeperException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Failed setting SPLITTING znode on "
operator|+
name|this
operator|.
name|parent
operator|.
name|getRegionNameAsString
argument_list|()
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
name|this
operator|.
name|journal
operator|.
name|add
argument_list|(
name|JournalEntry
operator|.
name|SET_SPLITTING_IN_ZK
argument_list|)
expr_stmt|;
name|createSplitDir
argument_list|(
name|this
operator|.
name|parent
operator|.
name|getFilesystem
argument_list|()
argument_list|,
name|this
operator|.
name|splitdir
argument_list|)
expr_stmt|;
name|this
operator|.
name|journal
operator|.
name|add
argument_list|(
name|JournalEntry
operator|.
name|CREATE_SPLIT_DIR
argument_list|)
expr_stmt|;
name|List
argument_list|<
name|StoreFile
argument_list|>
name|hstoreFilesToSplit
init|=
name|this
operator|.
name|parent
operator|.
name|close
argument_list|(
literal|false
argument_list|)
decl_stmt|;
if|if
condition|(
name|hstoreFilesToSplit
operator|==
literal|null
condition|)
block|{
comment|// The region was closed by a concurrent thread.  We can't continue
comment|// with the split, instead we must just abandon the split.  If we
comment|// reopen or split this could cause problems because the region has
comment|// probably already been moved to a different server, or is in the
comment|// process of moving to a different server.
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Failed to close region: already closed by "
operator|+
literal|"another thread"
argument_list|)
throw|;
block|}
name|this
operator|.
name|journal
operator|.
name|add
argument_list|(
name|JournalEntry
operator|.
name|CLOSED_PARENT_REGION
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|testing
condition|)
block|{
name|services
operator|.
name|removeFromOnlineRegions
argument_list|(
name|this
operator|.
name|parent
operator|.
name|getRegionInfo
argument_list|()
operator|.
name|getEncodedName
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|this
operator|.
name|journal
operator|.
name|add
argument_list|(
name|JournalEntry
operator|.
name|OFFLINED_PARENT
argument_list|)
expr_stmt|;
comment|// TODO: If the below were multithreaded would we complete steps in less
comment|// elapsed time?  St.Ack 20100920
name|splitStoreFiles
argument_list|(
name|this
operator|.
name|splitdir
argument_list|,
name|hstoreFilesToSplit
argument_list|)
expr_stmt|;
comment|// splitStoreFiles creates daughter region dirs under the parent splits dir
comment|// Nothing to unroll here if failure -- clean up of CREATE_SPLIT_DIR will
comment|// clean this up.
comment|// Log to the journal that we are creating region A, the first daughter
comment|// region.  We could fail halfway through.  If we do, we could have left
comment|// stuff in fs that needs cleanup -- a storefile or two.  Thats why we
comment|// add entry to journal BEFORE rather than AFTER the change.
name|this
operator|.
name|journal
operator|.
name|add
argument_list|(
name|JournalEntry
operator|.
name|STARTED_REGION_A_CREATION
argument_list|)
expr_stmt|;
name|HRegion
name|a
init|=
name|createDaughterRegion
argument_list|(
name|this
operator|.
name|hri_a
argument_list|,
name|this
operator|.
name|parent
operator|.
name|rsServices
argument_list|)
decl_stmt|;
comment|// Ditto
name|this
operator|.
name|journal
operator|.
name|add
argument_list|(
name|JournalEntry
operator|.
name|STARTED_REGION_B_CREATION
argument_list|)
expr_stmt|;
name|HRegion
name|b
init|=
name|createDaughterRegion
argument_list|(
name|this
operator|.
name|hri_b
argument_list|,
name|this
operator|.
name|parent
operator|.
name|rsServices
argument_list|)
decl_stmt|;
comment|// Edit parent in meta
if|if
condition|(
operator|!
name|testing
condition|)
block|{
name|MetaEditor
operator|.
name|offlineParentInMeta
argument_list|(
name|server
operator|.
name|getCatalogTracker
argument_list|()
argument_list|,
name|this
operator|.
name|parent
operator|.
name|getRegionInfo
argument_list|()
argument_list|,
name|a
operator|.
name|getRegionInfo
argument_list|()
argument_list|,
name|b
operator|.
name|getRegionInfo
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|// This is the point of no return.  We are committed to the split now.  We
comment|// have still the daughter regions to open but meta has been changed.
comment|// If we fail from here on out, we cannot rollback so, we'll just abort.
if|if
condition|(
operator|!
name|testing
condition|)
block|{
comment|// Open daughters in parallel.
name|DaughterOpener
name|aOpener
init|=
operator|new
name|DaughterOpener
argument_list|(
name|server
argument_list|,
name|services
argument_list|,
name|a
argument_list|)
decl_stmt|;
name|DaughterOpener
name|bOpener
init|=
operator|new
name|DaughterOpener
argument_list|(
name|server
argument_list|,
name|services
argument_list|,
name|b
argument_list|)
decl_stmt|;
name|aOpener
operator|.
name|start
argument_list|()
expr_stmt|;
name|bOpener
operator|.
name|start
argument_list|()
expr_stmt|;
try|try
block|{
name|aOpener
operator|.
name|join
argument_list|()
expr_stmt|;
name|bOpener
operator|.
name|join
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
name|server
operator|.
name|abort
argument_list|(
literal|"Exception running daughter opens"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
block|}
comment|// Tell master about split by updating zk.  If we fail, abort.
if|if
condition|(
name|server
operator|!=
literal|null
operator|&&
name|server
operator|.
name|getZooKeeper
argument_list|()
operator|!=
literal|null
condition|)
block|{
try|try
block|{
name|transitionNodeSplit
argument_list|(
name|server
operator|.
name|getZooKeeper
argument_list|()
argument_list|,
name|parent
operator|.
name|getRegionInfo
argument_list|()
argument_list|,
name|a
operator|.
name|getRegionInfo
argument_list|()
argument_list|,
name|b
operator|.
name|getRegionInfo
argument_list|()
argument_list|,
name|server
operator|.
name|getServerName
argument_list|()
argument_list|,
name|this
operator|.
name|znodeVersion
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|server
operator|.
name|abort
argument_list|(
literal|"Failed telling master about split"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
block|}
comment|// Coprocessor callback
if|if
condition|(
name|this
operator|.
name|parent
operator|.
name|getCoprocessorHost
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|this
operator|.
name|parent
operator|.
name|getCoprocessorHost
argument_list|()
operator|.
name|postSplit
argument_list|(
name|a
argument_list|,
name|b
argument_list|)
expr_stmt|;
block|}
comment|// Leaving here, the splitdir with its dross will be in place but since the
comment|// split was successful, just leave it; it'll be cleaned when parent is
comment|// deleted and cleaned up.
return|return
operator|new
name|PairOfSameType
argument_list|<
name|HRegion
argument_list|>
argument_list|(
name|a
argument_list|,
name|b
argument_list|)
return|;
block|}
class|class
name|DaughterOpener
extends|extends
name|Thread
block|{
specifier|private
specifier|final
name|RegionServerServices
name|services
decl_stmt|;
specifier|private
specifier|final
name|Server
name|server
decl_stmt|;
specifier|private
specifier|final
name|HRegion
name|r
decl_stmt|;
name|DaughterOpener
parameter_list|(
specifier|final
name|Server
name|s
parameter_list|,
specifier|final
name|RegionServerServices
name|services
parameter_list|,
specifier|final
name|HRegion
name|r
parameter_list|)
block|{
name|super
argument_list|(
name|s
operator|.
name|getServerName
argument_list|()
operator|+
literal|"-daughterOpener="
operator|+
name|r
operator|.
name|getRegionInfo
argument_list|()
operator|.
name|getEncodedName
argument_list|()
argument_list|)
expr_stmt|;
name|setDaemon
argument_list|(
literal|true
argument_list|)
expr_stmt|;
name|this
operator|.
name|services
operator|=
name|services
expr_stmt|;
name|this
operator|.
name|server
operator|=
name|s
expr_stmt|;
name|this
operator|.
name|r
operator|=
name|r
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|run
parameter_list|()
block|{
try|try
block|{
name|openDaughterRegion
argument_list|(
name|this
operator|.
name|server
argument_list|,
name|this
operator|.
name|services
argument_list|,
name|r
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Throwable
name|t
parameter_list|)
block|{
name|this
operator|.
name|server
operator|.
name|abort
argument_list|(
literal|"Failed open of daughter "
operator|+
name|this
operator|.
name|r
operator|.
name|getRegionInfo
argument_list|()
operator|.
name|getRegionNameAsString
argument_list|()
argument_list|,
name|t
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|/**    * Open daughter regions, add them to online list and update meta.    * @param server    * @param services    * @param daughter    * @throws IOException    * @throws KeeperException    */
name|void
name|openDaughterRegion
parameter_list|(
specifier|final
name|Server
name|server
parameter_list|,
specifier|final
name|RegionServerServices
name|services
parameter_list|,
specifier|final
name|HRegion
name|daughter
parameter_list|)
throws|throws
name|IOException
throws|,
name|KeeperException
block|{
if|if
condition|(
name|server
operator|.
name|isStopped
argument_list|()
operator|||
name|services
operator|.
name|isStopping
argument_list|()
condition|)
block|{
name|MetaEditor
operator|.
name|addDaughter
argument_list|(
name|server
operator|.
name|getCatalogTracker
argument_list|()
argument_list|,
name|daughter
operator|.
name|getRegionInfo
argument_list|()
argument_list|,
literal|null
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Not opening daughter "
operator|+
name|daughter
operator|.
name|getRegionInfo
argument_list|()
operator|.
name|getRegionNameAsString
argument_list|()
operator|+
literal|" because stopping="
operator|+
name|services
operator|.
name|isStopping
argument_list|()
operator|+
literal|", stopped="
operator|+
name|server
operator|.
name|isStopped
argument_list|()
argument_list|)
expr_stmt|;
return|return;
block|}
name|HRegionInfo
name|hri
init|=
name|daughter
operator|.
name|getRegionInfo
argument_list|()
decl_stmt|;
name|LoggingProgressable
name|reporter
init|=
operator|new
name|LoggingProgressable
argument_list|(
name|hri
argument_list|,
name|server
operator|.
name|getConfiguration
argument_list|()
argument_list|)
decl_stmt|;
name|HRegion
name|r
init|=
name|daughter
operator|.
name|openHRegion
argument_list|(
name|reporter
argument_list|)
decl_stmt|;
name|services
operator|.
name|postOpenDeployTasks
argument_list|(
name|r
argument_list|,
name|server
operator|.
name|getCatalogTracker
argument_list|()
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
specifier|static
class|class
name|LoggingProgressable
implements|implements
name|CancelableProgressable
block|{
specifier|private
specifier|final
name|HRegionInfo
name|hri
decl_stmt|;
specifier|private
name|long
name|lastLog
init|=
operator|-
literal|1
decl_stmt|;
specifier|private
specifier|final
name|long
name|interval
decl_stmt|;
name|LoggingProgressable
parameter_list|(
specifier|final
name|HRegionInfo
name|hri
parameter_list|,
specifier|final
name|Configuration
name|c
parameter_list|)
block|{
name|this
operator|.
name|hri
operator|=
name|hri
expr_stmt|;
name|this
operator|.
name|interval
operator|=
name|c
operator|.
name|getLong
argument_list|(
literal|"hbase.regionserver.split.daughter.open.log.interval"
argument_list|,
literal|10000
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|progress
parameter_list|()
block|{
name|long
name|now
init|=
name|System
operator|.
name|currentTimeMillis
argument_list|()
decl_stmt|;
if|if
condition|(
name|now
operator|-
name|lastLog
operator|>
name|this
operator|.
name|interval
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Opening "
operator|+
name|this
operator|.
name|hri
operator|.
name|getRegionNameAsString
argument_list|()
argument_list|)
expr_stmt|;
name|this
operator|.
name|lastLog
operator|=
name|now
expr_stmt|;
block|}
return|return
literal|true
return|;
block|}
block|}
specifier|private
specifier|static
name|Path
name|getSplitDir
parameter_list|(
specifier|final
name|HRegion
name|r
parameter_list|)
block|{
return|return
operator|new
name|Path
argument_list|(
name|r
operator|.
name|getRegionDir
argument_list|()
argument_list|,
name|SPLITDIR
argument_list|)
return|;
block|}
comment|/**    * @param fs Filesystem to use    * @param splitdir Directory to store temporary split data in    * @throws IOException If<code>splitdir</code> already exists or we fail    * to create it.    * @see #cleanupSplitDir(FileSystem, Path)    */
specifier|private
specifier|static
name|void
name|createSplitDir
parameter_list|(
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Path
name|splitdir
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|fs
operator|.
name|exists
argument_list|(
name|splitdir
argument_list|)
condition|)
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Splitdir already exits? "
operator|+
name|splitdir
argument_list|)
throw|;
if|if
condition|(
operator|!
name|fs
operator|.
name|mkdirs
argument_list|(
name|splitdir
argument_list|)
condition|)
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Failed create of "
operator|+
name|splitdir
argument_list|)
throw|;
block|}
specifier|private
specifier|static
name|void
name|cleanupSplitDir
parameter_list|(
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Path
name|splitdir
parameter_list|)
throws|throws
name|IOException
block|{
comment|// Splitdir may have been cleaned up by reopen of the parent dir.
name|deleteDir
argument_list|(
name|fs
argument_list|,
name|splitdir
argument_list|,
literal|false
argument_list|)
expr_stmt|;
block|}
comment|/**    * @param fs Filesystem to use    * @param dir Directory to delete    * @param mustPreExist If true, we'll throw exception if<code>dir</code>    * does not preexist, else we'll just pass.    * @throws IOException Thrown if we fail to delete passed<code>dir</code>    */
specifier|private
specifier|static
name|void
name|deleteDir
parameter_list|(
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Path
name|dir
parameter_list|,
specifier|final
name|boolean
name|mustPreExist
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
operator|!
name|fs
operator|.
name|exists
argument_list|(
name|dir
argument_list|)
condition|)
block|{
if|if
condition|(
name|mustPreExist
condition|)
throw|throw
operator|new
name|IOException
argument_list|(
name|dir
operator|.
name|toString
argument_list|()
operator|+
literal|" does not exist!"
argument_list|)
throw|;
block|}
elseif|else
if|if
condition|(
operator|!
name|fs
operator|.
name|delete
argument_list|(
name|dir
argument_list|,
literal|true
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Failed delete of "
operator|+
name|dir
argument_list|)
throw|;
block|}
block|}
specifier|private
name|void
name|splitStoreFiles
parameter_list|(
specifier|final
name|Path
name|splitdir
parameter_list|,
specifier|final
name|List
argument_list|<
name|StoreFile
argument_list|>
name|hstoreFilesToSplit
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|hstoreFilesToSplit
operator|==
literal|null
condition|)
block|{
comment|// Could be null because close didn't succeed -- for now consider it fatal
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Close returned empty list of StoreFiles"
argument_list|)
throw|;
block|}
comment|// The following code sets up a thread pool executor with as many slots as
comment|// there's files to split. It then fires up everything, waits for
comment|// completion and finally checks for any exception
name|int
name|nbFiles
init|=
name|hstoreFilesToSplit
operator|.
name|size
argument_list|()
decl_stmt|;
name|ThreadFactoryBuilder
name|builder
init|=
operator|new
name|ThreadFactoryBuilder
argument_list|()
decl_stmt|;
name|builder
operator|.
name|setNameFormat
argument_list|(
literal|"StoreFileSplitter-%1$d"
argument_list|)
expr_stmt|;
name|ThreadFactory
name|factory
init|=
name|builder
operator|.
name|build
argument_list|()
decl_stmt|;
name|ThreadPoolExecutor
name|threadPool
init|=
operator|(
name|ThreadPoolExecutor
operator|)
name|Executors
operator|.
name|newFixedThreadPool
argument_list|(
name|nbFiles
argument_list|,
name|factory
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|Future
argument_list|<
name|Void
argument_list|>
argument_list|>
name|futures
init|=
operator|new
name|ArrayList
argument_list|<
name|Future
argument_list|<
name|Void
argument_list|>
argument_list|>
argument_list|(
name|nbFiles
argument_list|)
decl_stmt|;
comment|// Split each store file.
for|for
control|(
name|StoreFile
name|sf
range|:
name|hstoreFilesToSplit
control|)
block|{
comment|//splitStoreFile(sf, splitdir);
name|StoreFileSplitter
name|sfs
init|=
operator|new
name|StoreFileSplitter
argument_list|(
name|sf
argument_list|,
name|splitdir
argument_list|)
decl_stmt|;
name|futures
operator|.
name|add
argument_list|(
name|threadPool
operator|.
name|submit
argument_list|(
name|sfs
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|// Shutdown the pool
name|threadPool
operator|.
name|shutdown
argument_list|()
expr_stmt|;
comment|// Wait for all the tasks to finish
try|try
block|{
name|boolean
name|stillRunning
init|=
operator|!
name|threadPool
operator|.
name|awaitTermination
argument_list|(
name|this
operator|.
name|fileSplitTimeout
argument_list|,
name|TimeUnit
operator|.
name|MILLISECONDS
argument_list|)
decl_stmt|;
if|if
condition|(
name|stillRunning
condition|)
block|{
name|threadPool
operator|.
name|shutdownNow
argument_list|()
expr_stmt|;
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Took too long to split the"
operator|+
literal|" files and create the references, aborting split"
argument_list|)
throw|;
block|}
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|interrupt
argument_list|()
expr_stmt|;
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Interrupted while waiting for file splitters"
argument_list|,
name|e
argument_list|)
throw|;
block|}
comment|// Look for any exception
for|for
control|(
name|Future
argument_list|<
name|Void
argument_list|>
name|future
range|:
name|futures
control|)
block|{
try|try
block|{
name|future
operator|.
name|get
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|interrupt
argument_list|()
expr_stmt|;
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Interrupted while trying to get the results of file splitters"
argument_list|,
name|e
argument_list|)
throw|;
block|}
catch|catch
parameter_list|(
name|ExecutionException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
block|}
specifier|private
name|void
name|splitStoreFile
parameter_list|(
specifier|final
name|StoreFile
name|sf
parameter_list|,
specifier|final
name|Path
name|splitdir
parameter_list|)
throws|throws
name|IOException
block|{
name|FileSystem
name|fs
init|=
name|this
operator|.
name|parent
operator|.
name|getFilesystem
argument_list|()
decl_stmt|;
name|byte
index|[]
name|family
init|=
name|sf
operator|.
name|getFamily
argument_list|()
decl_stmt|;
name|String
name|encoded
init|=
name|this
operator|.
name|hri_a
operator|.
name|getEncodedName
argument_list|()
decl_stmt|;
name|Path
name|storedir
init|=
name|Store
operator|.
name|getStoreHomedir
argument_list|(
name|splitdir
argument_list|,
name|encoded
argument_list|,
name|family
argument_list|)
decl_stmt|;
name|StoreFile
operator|.
name|split
argument_list|(
name|fs
argument_list|,
name|storedir
argument_list|,
name|sf
argument_list|,
name|this
operator|.
name|splitrow
argument_list|,
name|Range
operator|.
name|bottom
argument_list|)
expr_stmt|;
name|encoded
operator|=
name|this
operator|.
name|hri_b
operator|.
name|getEncodedName
argument_list|()
expr_stmt|;
name|storedir
operator|=
name|Store
operator|.
name|getStoreHomedir
argument_list|(
name|splitdir
argument_list|,
name|encoded
argument_list|,
name|family
argument_list|)
expr_stmt|;
name|StoreFile
operator|.
name|split
argument_list|(
name|fs
argument_list|,
name|storedir
argument_list|,
name|sf
argument_list|,
name|this
operator|.
name|splitrow
argument_list|,
name|Range
operator|.
name|top
argument_list|)
expr_stmt|;
block|}
comment|/**    * Utility class used to do the file splitting / reference writing    * in parallel instead of sequentially.    */
class|class
name|StoreFileSplitter
implements|implements
name|Callable
argument_list|<
name|Void
argument_list|>
block|{
specifier|private
specifier|final
name|StoreFile
name|sf
decl_stmt|;
specifier|private
specifier|final
name|Path
name|splitdir
decl_stmt|;
comment|/**      * Constructor that takes what it needs to split      * @param sf which file      * @param splitdir where the splitting is done      */
specifier|public
name|StoreFileSplitter
parameter_list|(
specifier|final
name|StoreFile
name|sf
parameter_list|,
specifier|final
name|Path
name|splitdir
parameter_list|)
block|{
name|this
operator|.
name|sf
operator|=
name|sf
expr_stmt|;
name|this
operator|.
name|splitdir
operator|=
name|splitdir
expr_stmt|;
block|}
specifier|public
name|Void
name|call
parameter_list|()
throws|throws
name|IOException
block|{
name|splitStoreFile
argument_list|(
name|sf
argument_list|,
name|splitdir
argument_list|)
expr_stmt|;
return|return
literal|null
return|;
block|}
block|}
comment|/**    * @param hri Spec. for daughter region to open.    * @param flusher Flusher this region should use.    * @return Created daughter HRegion.    * @throws IOException    * @see #cleanupDaughterRegion(FileSystem, Path, HRegionInfo)    */
name|HRegion
name|createDaughterRegion
parameter_list|(
specifier|final
name|HRegionInfo
name|hri
parameter_list|,
specifier|final
name|RegionServerServices
name|rsServices
parameter_list|)
throws|throws
name|IOException
block|{
comment|// Package private so unit tests have access.
name|FileSystem
name|fs
init|=
name|this
operator|.
name|parent
operator|.
name|getFilesystem
argument_list|()
decl_stmt|;
name|Path
name|regionDir
init|=
name|getSplitDirForDaughter
argument_list|(
name|this
operator|.
name|parent
operator|.
name|getFilesystem
argument_list|()
argument_list|,
name|this
operator|.
name|splitdir
argument_list|,
name|hri
argument_list|)
decl_stmt|;
name|HRegion
name|r
init|=
name|HRegion
operator|.
name|newHRegion
argument_list|(
name|this
operator|.
name|parent
operator|.
name|getTableDir
argument_list|()
argument_list|,
name|this
operator|.
name|parent
operator|.
name|getLog
argument_list|()
argument_list|,
name|fs
argument_list|,
name|this
operator|.
name|parent
operator|.
name|getConf
argument_list|()
argument_list|,
name|hri
argument_list|,
name|rsServices
argument_list|)
decl_stmt|;
name|r
operator|.
name|readRequestsCount
operator|.
name|set
argument_list|(
name|this
operator|.
name|parent
operator|.
name|getReadRequestsCount
argument_list|()
operator|/
literal|2
argument_list|)
expr_stmt|;
name|r
operator|.
name|writeRequestsCount
operator|.
name|set
argument_list|(
name|this
operator|.
name|parent
operator|.
name|getWriteRequestsCount
argument_list|()
operator|/
literal|2
argument_list|)
expr_stmt|;
name|HRegion
operator|.
name|moveInitialFilesIntoPlace
argument_list|(
name|fs
argument_list|,
name|regionDir
argument_list|,
name|r
operator|.
name|getRegionDir
argument_list|()
argument_list|)
expr_stmt|;
return|return
name|r
return|;
block|}
specifier|private
specifier|static
name|void
name|cleanupDaughterRegion
parameter_list|(
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Path
name|tabledir
parameter_list|,
specifier|final
name|String
name|encodedName
parameter_list|)
throws|throws
name|IOException
block|{
name|Path
name|regiondir
init|=
name|HRegion
operator|.
name|getRegionDir
argument_list|(
name|tabledir
argument_list|,
name|encodedName
argument_list|)
decl_stmt|;
comment|// Dir may not preexist.
name|deleteDir
argument_list|(
name|fs
argument_list|,
name|regiondir
argument_list|,
literal|false
argument_list|)
expr_stmt|;
block|}
comment|/*    * Get the daughter directories in the splits dir.  The splits dir is under    * the parent regions' directory.    * @param fs    * @param splitdir    * @param hri    * @return Path to daughter split dir.    * @throws IOException    */
specifier|private
specifier|static
name|Path
name|getSplitDirForDaughter
parameter_list|(
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Path
name|splitdir
parameter_list|,
specifier|final
name|HRegionInfo
name|hri
parameter_list|)
throws|throws
name|IOException
block|{
return|return
operator|new
name|Path
argument_list|(
name|splitdir
argument_list|,
name|hri
operator|.
name|getEncodedName
argument_list|()
argument_list|)
return|;
block|}
comment|/**    * @param or Object that can online/offline parent region.  Can be passed null    * by unit tests.    * @return The region we were splitting    * @throws IOException If thrown, rollback failed.  Take drastic action.    */
specifier|public
name|void
name|rollback
parameter_list|(
specifier|final
name|Server
name|server
parameter_list|,
specifier|final
name|OnlineRegions
name|or
parameter_list|)
throws|throws
name|IOException
block|{
name|FileSystem
name|fs
init|=
name|this
operator|.
name|parent
operator|.
name|getFilesystem
argument_list|()
decl_stmt|;
name|ListIterator
argument_list|<
name|JournalEntry
argument_list|>
name|iterator
init|=
name|this
operator|.
name|journal
operator|.
name|listIterator
argument_list|(
name|this
operator|.
name|journal
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
while|while
condition|(
name|iterator
operator|.
name|hasPrevious
argument_list|()
condition|)
block|{
name|JournalEntry
name|je
init|=
name|iterator
operator|.
name|previous
argument_list|()
decl_stmt|;
switch|switch
condition|(
name|je
condition|)
block|{
case|case
name|SET_SPLITTING_IN_ZK
case|:
if|if
condition|(
name|server
operator|!=
literal|null
operator|&&
name|server
operator|.
name|getZooKeeper
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|cleanZK
argument_list|(
name|server
argument_list|,
name|this
operator|.
name|parent
operator|.
name|getRegionInfo
argument_list|()
argument_list|)
expr_stmt|;
block|}
break|break;
case|case
name|CREATE_SPLIT_DIR
case|:
name|this
operator|.
name|parent
operator|.
name|writestate
operator|.
name|writesEnabled
operator|=
literal|true
expr_stmt|;
name|cleanupSplitDir
argument_list|(
name|fs
argument_list|,
name|this
operator|.
name|splitdir
argument_list|)
expr_stmt|;
break|break;
case|case
name|CLOSED_PARENT_REGION
case|:
comment|// So, this returns a seqid but if we just closed and then reopened, we
comment|// should be ok. On close, we flushed using sequenceid obtained from
comment|// hosting regionserver so no need to propagate the sequenceid returned
comment|// out of initialize below up into regionserver as we normally do.
comment|// TODO: Verify.
name|this
operator|.
name|parent
operator|.
name|initialize
argument_list|()
expr_stmt|;
break|break;
case|case
name|STARTED_REGION_A_CREATION
case|:
name|cleanupDaughterRegion
argument_list|(
name|fs
argument_list|,
name|this
operator|.
name|parent
operator|.
name|getTableDir
argument_list|()
argument_list|,
name|this
operator|.
name|hri_a
operator|.
name|getEncodedName
argument_list|()
argument_list|)
expr_stmt|;
break|break;
case|case
name|STARTED_REGION_B_CREATION
case|:
name|cleanupDaughterRegion
argument_list|(
name|fs
argument_list|,
name|this
operator|.
name|parent
operator|.
name|getTableDir
argument_list|()
argument_list|,
name|this
operator|.
name|hri_b
operator|.
name|getEncodedName
argument_list|()
argument_list|)
expr_stmt|;
break|break;
case|case
name|OFFLINED_PARENT
case|:
if|if
condition|(
name|or
operator|!=
literal|null
condition|)
name|or
operator|.
name|addToOnlineRegions
argument_list|(
name|this
operator|.
name|parent
argument_list|)
expr_stmt|;
break|break;
default|default:
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"Unhandled journal entry: "
operator|+
name|je
argument_list|)
throw|;
block|}
block|}
block|}
name|HRegionInfo
name|getFirstDaughter
parameter_list|()
block|{
return|return
name|hri_a
return|;
block|}
name|HRegionInfo
name|getSecondDaughter
parameter_list|()
block|{
return|return
name|hri_b
return|;
block|}
comment|// For unit testing.
name|Path
name|getSplitDir
parameter_list|()
block|{
return|return
name|this
operator|.
name|splitdir
return|;
block|}
comment|/**    * Clean up any split detritus that may have been left around from previous    * split attempts.    * Call this method on initial region deploy.  Cleans up any mess    * left by previous deploys of passed<code>r</code> region.    * @param r    * @throws IOException    */
specifier|static
name|void
name|cleanupAnySplitDetritus
parameter_list|(
specifier|final
name|HRegion
name|r
parameter_list|)
throws|throws
name|IOException
block|{
name|Path
name|splitdir
init|=
name|getSplitDir
argument_list|(
name|r
argument_list|)
decl_stmt|;
name|FileSystem
name|fs
init|=
name|r
operator|.
name|getFilesystem
argument_list|()
decl_stmt|;
if|if
condition|(
operator|!
name|fs
operator|.
name|exists
argument_list|(
name|splitdir
argument_list|)
condition|)
return|return;
comment|// Look at the splitdir.  It could have the encoded names of the daughter
comment|// regions we tried to make.  See if the daughter regions actually got made
comment|// out under the tabledir.  If here under splitdir still, then the split did
comment|// not complete.  Try and do cleanup.  This code WILL NOT catch the case
comment|// where we successfully created daughter a but regionserver crashed during
comment|// the creation of region b.  In this case, there'll be an orphan daughter
comment|// dir in the filesystem.  TOOD: Fix.
name|FileStatus
index|[]
name|daughters
init|=
name|fs
operator|.
name|listStatus
argument_list|(
name|splitdir
argument_list|,
operator|new
name|FSUtils
operator|.
name|DirFilter
argument_list|(
name|fs
argument_list|)
argument_list|)
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|daughters
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|cleanupDaughterRegion
argument_list|(
name|fs
argument_list|,
name|r
operator|.
name|getTableDir
argument_list|()
argument_list|,
name|daughters
index|[
name|i
index|]
operator|.
name|getPath
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|cleanupSplitDir
argument_list|(
name|r
operator|.
name|getFilesystem
argument_list|()
argument_list|,
name|splitdir
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Cleaned up old failed split transaction detritus: "
operator|+
name|splitdir
argument_list|)
expr_stmt|;
block|}
specifier|private
specifier|static
name|void
name|cleanZK
parameter_list|(
specifier|final
name|Server
name|server
parameter_list|,
specifier|final
name|HRegionInfo
name|hri
parameter_list|)
block|{
try|try
block|{
comment|// Only delete if its in expected state; could have been hijacked.
name|ZKAssign
operator|.
name|deleteNode
argument_list|(
name|server
operator|.
name|getZooKeeper
argument_list|()
argument_list|,
name|hri
operator|.
name|getEncodedName
argument_list|()
argument_list|,
name|EventType
operator|.
name|RS_ZK_REGION_SPLITTING
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|KeeperException
name|e
parameter_list|)
block|{
name|server
operator|.
name|abort
argument_list|(
literal|"Failed cleanup of "
operator|+
name|hri
operator|.
name|getRegionNameAsString
argument_list|()
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Creates a new ephemeral node in the SPLITTING state for the specified region.    * Create it ephemeral in case regionserver dies mid-split.    *    *<p>Does not transition nodes from other states.  If a node already exists    * for this region, a {@link NodeExistsException} will be thrown.    *    * @param zkw zk reference    * @param region region to be created as offline    * @param serverName server event originates from    * @return Version of znode created.    * @throws IOException     */
specifier|private
specifier|static
name|int
name|createNodeSplitting
parameter_list|(
specifier|final
name|ZooKeeperWatcher
name|zkw
parameter_list|,
specifier|final
name|HRegionInfo
name|region
parameter_list|,
specifier|final
name|ServerName
name|serverName
parameter_list|)
throws|throws
name|KeeperException
throws|,
name|IOException
block|{
name|LOG
operator|.
name|debug
argument_list|(
name|zkw
operator|.
name|prefix
argument_list|(
literal|"Creating ephemeral node for "
operator|+
name|region
operator|.
name|getEncodedName
argument_list|()
operator|+
literal|" in SPLITTING state"
argument_list|)
argument_list|)
expr_stmt|;
name|RegionTransitionData
name|data
init|=
operator|new
name|RegionTransitionData
argument_list|(
name|EventType
operator|.
name|RS_ZK_REGION_SPLITTING
argument_list|,
name|region
operator|.
name|getRegionName
argument_list|()
argument_list|,
name|serverName
argument_list|)
decl_stmt|;
comment|// This synchronization is copied from ZKAssign.
synchronized|synchronized
init|(
name|zkw
operator|.
name|getNodes
argument_list|()
init|)
block|{
name|String
name|node
init|=
name|ZKAssign
operator|.
name|getNodeName
argument_list|(
name|zkw
argument_list|,
name|region
operator|.
name|getEncodedName
argument_list|()
argument_list|)
decl_stmt|;
name|zkw
operator|.
name|getNodes
argument_list|()
operator|.
name|add
argument_list|(
name|node
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|ZKUtil
operator|.
name|createEphemeralNodeAndWatch
argument_list|(
name|zkw
argument_list|,
name|node
argument_list|,
name|data
operator|.
name|getBytes
argument_list|()
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Failed create of ephemeral "
operator|+
name|node
argument_list|)
throw|;
block|}
block|}
comment|// Transition node from SPLITTING to SPLITTING and pick up version so we
comment|// can be sure this znode is ours; version is needed deleting.
return|return
name|transitionNodeSplitting
argument_list|(
name|zkw
argument_list|,
name|region
argument_list|,
name|serverName
argument_list|,
operator|-
literal|1
argument_list|)
return|;
block|}
comment|/**    * Transitions an existing node for the specified region which is    * currently in the SPLITTING state to be in the SPLIT state.  Converts the    * ephemeral SPLITTING znode to an ephemeral SPLIT node.  Master cleans up    * SPLIT znode when it reads it (or if we crash, zk will clean it up).    *    *<p>Does not transition nodes from other states.  If for some reason the    * node could not be transitioned, the method returns -1.  If the transition    * is successful, the version of the node after transition is returned.    *    *<p>This method can fail and return false for three different reasons:    *<ul><li>Node for this region does not exist</li>    *<li>Node for this region is not in SPLITTING state</li>    *<li>After verifying SPLITTING state, update fails because of wrong version    * (this should never actually happen since an RS only does this transition    * following a transition to SPLITTING.  if two RS are conflicting, one would    * fail the original transition to SPLITTING and not this transition)</li>    *</ul>    *    *<p>Does not set any watches.    *    *<p>This method should only be used by a RegionServer when completing the    * open of a region.    *    * @param zkw zk reference    * @param parent region to be transitioned to opened    * @param a Daughter a of split    * @param b Daughter b of split    * @param serverName server event originates from    * @return version of node after transition, -1 if unsuccessful transition    * @throws KeeperException if unexpected zookeeper exception    * @throws IOException     */
specifier|private
specifier|static
name|int
name|transitionNodeSplit
parameter_list|(
name|ZooKeeperWatcher
name|zkw
parameter_list|,
name|HRegionInfo
name|parent
parameter_list|,
name|HRegionInfo
name|a
parameter_list|,
name|HRegionInfo
name|b
parameter_list|,
name|ServerName
name|serverName
parameter_list|,
specifier|final
name|int
name|znodeVersion
parameter_list|)
throws|throws
name|KeeperException
throws|,
name|IOException
block|{
name|byte
index|[]
name|payload
init|=
name|Writables
operator|.
name|getBytes
argument_list|(
name|a
argument_list|,
name|b
argument_list|)
decl_stmt|;
return|return
name|ZKAssign
operator|.
name|transitionNode
argument_list|(
name|zkw
argument_list|,
name|parent
argument_list|,
name|serverName
argument_list|,
name|EventType
operator|.
name|RS_ZK_REGION_SPLITTING
argument_list|,
name|EventType
operator|.
name|RS_ZK_REGION_SPLIT
argument_list|,
name|znodeVersion
argument_list|,
name|payload
argument_list|)
return|;
block|}
specifier|private
specifier|static
name|int
name|transitionNodeSplitting
parameter_list|(
specifier|final
name|ZooKeeperWatcher
name|zkw
parameter_list|,
specifier|final
name|HRegionInfo
name|parent
parameter_list|,
specifier|final
name|ServerName
name|serverName
parameter_list|,
specifier|final
name|int
name|version
parameter_list|)
throws|throws
name|KeeperException
throws|,
name|IOException
block|{
return|return
name|ZKAssign
operator|.
name|transitionNode
argument_list|(
name|zkw
argument_list|,
name|parent
argument_list|,
name|serverName
argument_list|,
name|EventType
operator|.
name|RS_ZK_REGION_SPLITTING
argument_list|,
name|EventType
operator|.
name|RS_ZK_REGION_SPLITTING
argument_list|,
name|version
argument_list|)
return|;
block|}
block|}
end_class

end_unit

