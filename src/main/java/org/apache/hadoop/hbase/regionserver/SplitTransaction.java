begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Copyright 2010 The Apache Software Foundation  *  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ListIterator
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|Log
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|LogFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileStatus
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HConstants
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HRegionInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|KeyValue
operator|.
name|KVComparator
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|HTable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|Put
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|Reference
operator|.
name|Range
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|Bytes
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|EnvironmentEdgeManager
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|FSUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|PairOfSameType
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|Writables
import|;
end_import

begin_comment
comment|/**  * Executes region split as a "transaction".  Call {@link #prepare()} to setup  * the transaction, {@link #execute(OnlineRegions)} to run the transaction and  * {@link #rollback(OnlineRegions)} to cleanup if execute fails.  *  *<p>Here is an example of how you would use this class:  *<pre>  *  SplitTransaction st = new SplitTransaction(this.conf, parent, midKey)  *  if (!st.prepare()) return;  *  try {  *    st.execute(myOnlineRegions);  *  } catch (IOException ioe) {  *    try {  *      st.rollback(myOnlineRegions);  *      return;  *    } catch (RuntimeException e) {  *      myAbortable.abort("Failed split, abort");  *    }  *  }  *</Pre>  */
end_comment

begin_class
class|class
name|SplitTransaction
block|{
specifier|private
specifier|static
specifier|final
name|Log
name|LOG
init|=
name|LogFactory
operator|.
name|getLog
argument_list|(
name|SplitTransaction
operator|.
name|class
argument_list|)
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|String
name|SPLITDIR
init|=
literal|"splits"
decl_stmt|;
comment|/*    * Region to split    */
specifier|private
specifier|final
name|HRegion
name|parent
decl_stmt|;
specifier|private
name|HRegionInfo
name|hri_a
decl_stmt|;
specifier|private
name|HRegionInfo
name|hri_b
decl_stmt|;
specifier|private
name|Path
name|splitdir
decl_stmt|;
comment|/*    * Row to split around    */
specifier|private
specifier|final
name|byte
index|[]
name|splitrow
decl_stmt|;
comment|/**    * Types to add to the transaction journal    */
enum|enum
name|JournalEntry
block|{
comment|/**      * We created the temporary split data directory.      */
name|CREATE_SPLIT_DIR
block|,
comment|/**      * Closed the parent region.      */
name|CLOSED_PARENT_REGION
block|,
comment|/**      * The parent has been taken out of the server's online regions list.      */
name|OFFLINED_PARENT
block|,
comment|/**      * Started in on creation of the first daughter region.      */
name|STARTED_REGION_A_CREATION
block|,
comment|/**      * Started in on the creation of the second daughter region.      */
name|STARTED_REGION_B_CREATION
block|}
comment|/*    * Journal of how far the split transaction has progressed.    */
specifier|private
specifier|final
name|List
argument_list|<
name|JournalEntry
argument_list|>
name|journal
init|=
operator|new
name|ArrayList
argument_list|<
name|JournalEntry
argument_list|>
argument_list|()
decl_stmt|;
comment|/**    * Constructor    * @param c Configuration to use running split    * @param r Region to split    * @param splitrow Row to split around    */
name|SplitTransaction
parameter_list|(
specifier|final
name|HRegion
name|r
parameter_list|,
specifier|final
name|byte
index|[]
name|splitrow
parameter_list|)
block|{
name|this
operator|.
name|parent
operator|=
name|r
expr_stmt|;
name|this
operator|.
name|splitrow
operator|=
name|splitrow
expr_stmt|;
name|this
operator|.
name|splitdir
operator|=
name|getSplitDir
argument_list|(
name|this
operator|.
name|parent
argument_list|)
expr_stmt|;
block|}
comment|/**    * Does checks on split inputs.    * @return<code>true</code> if the region is splittable else    *<code>false</code> if it is not (e.g. its already closed, etc.). If we    * return<code>true</code>, we'll have taken out the parent's    *<code>splitsAndClosesLock</code> and only way to unlock is successful    * {@link #execute(OnlineRegions)} or {@link #rollback(OnlineRegions)}    */
specifier|public
name|boolean
name|prepare
parameter_list|()
block|{
name|boolean
name|prepared
init|=
literal|false
decl_stmt|;
name|this
operator|.
name|parent
operator|.
name|splitsAndClosesLock
operator|.
name|writeLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
if|if
condition|(
name|this
operator|.
name|parent
operator|.
name|isClosed
argument_list|()
operator|||
name|this
operator|.
name|parent
operator|.
name|isClosing
argument_list|()
condition|)
return|return
name|prepared
return|;
name|HRegionInfo
name|hri
init|=
name|this
operator|.
name|parent
operator|.
name|getRegionInfo
argument_list|()
decl_stmt|;
comment|// Check splitrow.
name|byte
index|[]
name|startKey
init|=
name|hri
operator|.
name|getStartKey
argument_list|()
decl_stmt|;
name|byte
index|[]
name|endKey
init|=
name|hri
operator|.
name|getEndKey
argument_list|()
decl_stmt|;
if|if
condition|(
name|Bytes
operator|.
name|equals
argument_list|(
name|startKey
argument_list|,
name|splitrow
argument_list|)
operator|||
operator|!
name|this
operator|.
name|parent
operator|.
name|getRegionInfo
argument_list|()
operator|.
name|containsRow
argument_list|(
name|splitrow
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Split row is not inside region key range or is equal to "
operator|+
literal|"startkey: "
operator|+
name|Bytes
operator|.
name|toString
argument_list|(
name|this
operator|.
name|splitrow
argument_list|)
argument_list|)
expr_stmt|;
return|return
name|prepared
return|;
block|}
name|long
name|rid
init|=
name|getDaughterRegionIdTimestamp
argument_list|(
name|hri
argument_list|)
decl_stmt|;
name|this
operator|.
name|hri_a
operator|=
operator|new
name|HRegionInfo
argument_list|(
name|hri
operator|.
name|getTableDesc
argument_list|()
argument_list|,
name|startKey
argument_list|,
name|this
operator|.
name|splitrow
argument_list|,
literal|false
argument_list|,
name|rid
argument_list|)
expr_stmt|;
name|this
operator|.
name|hri_b
operator|=
operator|new
name|HRegionInfo
argument_list|(
name|hri
operator|.
name|getTableDesc
argument_list|()
argument_list|,
name|this
operator|.
name|splitrow
argument_list|,
name|endKey
argument_list|,
literal|false
argument_list|,
name|rid
argument_list|)
expr_stmt|;
name|prepared
operator|=
literal|true
expr_stmt|;
block|}
finally|finally
block|{
if|if
condition|(
operator|!
name|prepared
condition|)
name|this
operator|.
name|parent
operator|.
name|splitsAndClosesLock
operator|.
name|writeLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
return|return
name|prepared
return|;
block|}
comment|/**    * Calculate daughter regionid to use.    * @param hri Parent {@link HRegionInfo}    * @return Daughter region id (timestamp) to use.    */
specifier|private
specifier|static
name|long
name|getDaughterRegionIdTimestamp
parameter_list|(
specifier|final
name|HRegionInfo
name|hri
parameter_list|)
block|{
name|long
name|rid
init|=
name|EnvironmentEdgeManager
operator|.
name|currentTimeMillis
argument_list|()
decl_stmt|;
comment|// Regionid is timestamp.  Can't be less than that of parent else will insert
comment|// at wrong location in .META. (See HBASE-710).
if|if
condition|(
name|rid
operator|<
name|hri
operator|.
name|getRegionId
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Clock skew; parent regions id is "
operator|+
name|hri
operator|.
name|getRegionId
argument_list|()
operator|+
literal|" but current time here is "
operator|+
name|rid
argument_list|)
expr_stmt|;
name|rid
operator|=
name|hri
operator|.
name|getRegionId
argument_list|()
operator|+
literal|1
expr_stmt|;
block|}
return|return
name|rid
return|;
block|}
comment|/**    * Run the transaction.    * @param or Object that can online/offline parent region.    * @throws IOException If thrown, transaction failed. Call {@link #rollback(OnlineRegions)}    * @return Regions created    * @see #rollback(OnlineRegions)    */
specifier|public
name|PairOfSameType
argument_list|<
name|HRegion
argument_list|>
name|execute
parameter_list|(
specifier|final
name|OnlineRegions
name|or
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|execute
argument_list|(
name|or
argument_list|,
name|or
operator|!=
literal|null
argument_list|)
return|;
block|}
comment|/**    * Run the transaction.    * @param or Object that can online/offline parent region.  Can be null (Tests    * will pass null).    * @param If<code>true</code>, update meta (set to false when testing).    * @throws IOException If thrown, transaction failed. Call {@link #rollback(OnlineRegions)}    * @return Regions created    * @see #rollback(OnlineRegions)    */
name|PairOfSameType
argument_list|<
name|HRegion
argument_list|>
name|execute
parameter_list|(
specifier|final
name|OnlineRegions
name|or
parameter_list|,
specifier|final
name|boolean
name|updateMeta
parameter_list|)
throws|throws
name|IOException
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Starting split of region "
operator|+
name|this
operator|.
name|parent
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|this
operator|.
name|parent
operator|.
name|splitsAndClosesLock
operator|.
name|writeLock
argument_list|()
operator|.
name|isHeldByCurrentThread
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|SplitAndCloseWriteLockNotHeld
argument_list|()
throw|;
block|}
comment|// We'll need one of these later but get it now because if we fail there
comment|// is nothing to undo.
name|HTable
name|t
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|updateMeta
condition|)
name|t
operator|=
name|getTable
argument_list|(
name|this
operator|.
name|parent
operator|.
name|getConf
argument_list|()
argument_list|)
expr_stmt|;
name|createSplitDir
argument_list|(
name|this
operator|.
name|parent
operator|.
name|getFilesystem
argument_list|()
argument_list|,
name|this
operator|.
name|splitdir
argument_list|)
expr_stmt|;
name|this
operator|.
name|journal
operator|.
name|add
argument_list|(
name|JournalEntry
operator|.
name|CREATE_SPLIT_DIR
argument_list|)
expr_stmt|;
name|List
argument_list|<
name|StoreFile
argument_list|>
name|hstoreFilesToSplit
init|=
name|this
operator|.
name|parent
operator|.
name|close
argument_list|(
literal|false
argument_list|)
decl_stmt|;
name|this
operator|.
name|journal
operator|.
name|add
argument_list|(
name|JournalEntry
operator|.
name|CLOSED_PARENT_REGION
argument_list|)
expr_stmt|;
if|if
condition|(
name|or
operator|!=
literal|null
condition|)
name|or
operator|.
name|removeFromOnlineRegions
argument_list|(
name|this
operator|.
name|parent
operator|.
name|getRegionInfo
argument_list|()
argument_list|)
expr_stmt|;
name|this
operator|.
name|journal
operator|.
name|add
argument_list|(
name|JournalEntry
operator|.
name|OFFLINED_PARENT
argument_list|)
expr_stmt|;
name|splitStoreFiles
argument_list|(
name|this
operator|.
name|splitdir
argument_list|,
name|hstoreFilesToSplit
argument_list|)
expr_stmt|;
comment|// splitStoreFiles creates daughter region dirs under the parent splits dir
comment|// Nothing to unroll here if failure -- clean up of CREATE_SPLIT_DIR will
comment|// clean this up.
comment|// Log to the journal that we are creating region A, the first daughter
comment|// region.  We could fail halfway through.  If we do, we could have left
comment|// stuff in fs that needs cleanup -- a storefile or two.  Thats why we
comment|// add entry to journal BEFORE rather than AFTER the change.
name|this
operator|.
name|journal
operator|.
name|add
argument_list|(
name|JournalEntry
operator|.
name|STARTED_REGION_A_CREATION
argument_list|)
expr_stmt|;
name|HRegion
name|a
init|=
name|createDaughterRegion
argument_list|(
name|this
operator|.
name|hri_a
argument_list|)
decl_stmt|;
comment|// Ditto
name|this
operator|.
name|journal
operator|.
name|add
argument_list|(
name|JournalEntry
operator|.
name|STARTED_REGION_B_CREATION
argument_list|)
expr_stmt|;
name|HRegion
name|b
init|=
name|createDaughterRegion
argument_list|(
name|this
operator|.
name|hri_b
argument_list|)
decl_stmt|;
name|Put
name|editParentPut
init|=
name|createOfflineParentPut
argument_list|()
decl_stmt|;
if|if
condition|(
name|t
operator|!=
literal|null
condition|)
name|t
operator|.
name|put
argument_list|(
name|editParentPut
argument_list|)
expr_stmt|;
comment|// The is the point of no return.  We are committed to the split now.  Up to
comment|// a failure editing parent in meta or a crash of the hosting regionserver,
comment|// we could rollback (or, if crash, we could cleanup on redeploy) but now
comment|// meta has been changed, we can only go forward.  If the below last steps
comment|// do not complete, repair has to be done by another agent.  For example,
comment|// basescanner, at least up till master rewrite, would add daughter rows if
comment|// missing from meta.  It could do this because the parent edit includes the
comment|// daughter specs.  In Bigtable paper, they have another mechanism where
comment|// some feedback to the master somehow flags it that split is incomplete and
comment|// needs fixup.  Whatever the mechanism, its a TODO that we have some fixup.
comment|// I looked at writing the put of the parent edit above out to the WAL log
comment|// before changing meta with the notion that should we fail, then on replay
comment|// the offlining of the parent and addition of daughters up into meta could
comment|// be reinserted.  The edits would have to be 'special' and given how our
comment|// splits work, splitting by region, I think the replay would have to happen
comment|// inside in the split code -- as soon as it saw one of these special edits,
comment|// rather than write the edit out a file for the .META. region to replay or
comment|// somehow, write it out to this regions edits file for it to handle on
comment|// redeploy -- this'd be whacky, we'd be telling meta about a split during
comment|// the deploy of the parent -- instead we'd have to play the edit inside
comment|// in the split code somehow; this would involve a stop-the-splitting till
comment|// meta had been edited which might hold up splitting a good while.
comment|// Finish up the meta edits.  If these fail, another agent needs to do fixup
name|HRegionInfo
name|hri
init|=
name|this
operator|.
name|hri_a
decl_stmt|;
try|try
block|{
if|if
condition|(
name|t
operator|!=
literal|null
condition|)
name|t
operator|.
name|put
argument_list|(
name|createDaughterPut
argument_list|(
name|hri
argument_list|)
argument_list|)
expr_stmt|;
name|hri
operator|=
name|this
operator|.
name|hri_b
expr_stmt|;
if|if
condition|(
name|t
operator|!=
literal|null
condition|)
name|t
operator|.
name|put
argument_list|(
name|createDaughterPut
argument_list|(
name|hri
argument_list|)
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
comment|// Don't let this out or we'll run rollback.
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failed adding daughter "
operator|+
name|hri
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|// This should not fail because the HTable instance we are using is not
comment|// running a buffer -- its immediately flushing its puts.
if|if
condition|(
name|t
operator|!=
literal|null
condition|)
name|t
operator|.
name|close
argument_list|()
expr_stmt|;
comment|// Unlock if successful split.
name|this
operator|.
name|parent
operator|.
name|splitsAndClosesLock
operator|.
name|writeLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
comment|// Leaving here, the splitdir with its dross will be in place but since the
comment|// split was successful, just leave it; it'll be cleaned when parent is
comment|// deleted and cleaned up.
return|return
operator|new
name|PairOfSameType
argument_list|<
name|HRegion
argument_list|>
argument_list|(
name|a
argument_list|,
name|b
argument_list|)
return|;
block|}
specifier|private
specifier|static
name|Path
name|getSplitDir
parameter_list|(
specifier|final
name|HRegion
name|r
parameter_list|)
block|{
return|return
operator|new
name|Path
argument_list|(
name|r
operator|.
name|getRegionDir
argument_list|()
argument_list|,
name|SPLITDIR
argument_list|)
return|;
block|}
comment|/**    * @param fs Filesystem to use    * @param splitdir Directory to store temporary split data in    * @throws IOException If<code>splitdir</code> already exists or we fail    * to create it.    * @see #cleanupSplitDir(FileSystem, Path)    */
specifier|private
specifier|static
name|void
name|createSplitDir
parameter_list|(
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Path
name|splitdir
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|fs
operator|.
name|exists
argument_list|(
name|splitdir
argument_list|)
condition|)
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Splitdir already exits? "
operator|+
name|splitdir
argument_list|)
throw|;
if|if
condition|(
operator|!
name|fs
operator|.
name|mkdirs
argument_list|(
name|splitdir
argument_list|)
condition|)
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Failed create of "
operator|+
name|splitdir
argument_list|)
throw|;
block|}
specifier|private
specifier|static
name|void
name|cleanupSplitDir
parameter_list|(
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Path
name|splitdir
parameter_list|)
throws|throws
name|IOException
block|{
comment|// Splitdir may have been cleaned up by reopen of the parent dir.
name|deleteDir
argument_list|(
name|fs
argument_list|,
name|splitdir
argument_list|,
literal|false
argument_list|)
expr_stmt|;
block|}
comment|/**    * @param fs Filesystem to use    * @param dir Directory to delete    * @param mustPreExist If true, we'll throw exception if<code>dir</code>    * does not preexist, else we'll just pass.    * @throws IOException Thrown if we fail to delete passed<code>dir</code>    */
specifier|private
specifier|static
name|void
name|deleteDir
parameter_list|(
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Path
name|dir
parameter_list|,
specifier|final
name|boolean
name|mustPreExist
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
operator|!
name|fs
operator|.
name|exists
argument_list|(
name|dir
argument_list|)
condition|)
block|{
if|if
condition|(
name|mustPreExist
condition|)
throw|throw
operator|new
name|IOException
argument_list|(
name|dir
operator|.
name|toString
argument_list|()
operator|+
literal|" does not exist!"
argument_list|)
throw|;
block|}
elseif|else
if|if
condition|(
operator|!
name|fs
operator|.
name|delete
argument_list|(
name|dir
argument_list|,
literal|true
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Failed delete of "
operator|+
name|dir
argument_list|)
throw|;
block|}
block|}
specifier|private
name|void
name|splitStoreFiles
parameter_list|(
specifier|final
name|Path
name|splitdir
parameter_list|,
specifier|final
name|List
argument_list|<
name|StoreFile
argument_list|>
name|hstoreFilesToSplit
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|hstoreFilesToSplit
operator|==
literal|null
condition|)
block|{
comment|// Could be null because close didn't succeed -- for now consider it fatal
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Close returned empty list of StoreFiles"
argument_list|)
throw|;
block|}
comment|// Split each store file.
for|for
control|(
name|StoreFile
name|sf
range|:
name|hstoreFilesToSplit
control|)
block|{
name|splitStoreFile
argument_list|(
name|sf
argument_list|,
name|splitdir
argument_list|)
expr_stmt|;
block|}
block|}
specifier|private
name|void
name|splitStoreFile
parameter_list|(
specifier|final
name|StoreFile
name|sf
parameter_list|,
specifier|final
name|Path
name|splitdir
parameter_list|)
throws|throws
name|IOException
block|{
name|FileSystem
name|fs
init|=
name|this
operator|.
name|parent
operator|.
name|getFilesystem
argument_list|()
decl_stmt|;
name|byte
index|[]
name|family
init|=
name|sf
operator|.
name|getFamily
argument_list|()
decl_stmt|;
name|String
name|encoded
init|=
name|this
operator|.
name|hri_a
operator|.
name|getEncodedName
argument_list|()
decl_stmt|;
name|Path
name|storedir
init|=
name|Store
operator|.
name|getStoreHomedir
argument_list|(
name|splitdir
argument_list|,
name|encoded
argument_list|,
name|family
argument_list|)
decl_stmt|;
name|StoreFile
operator|.
name|split
argument_list|(
name|fs
argument_list|,
name|storedir
argument_list|,
name|sf
argument_list|,
name|this
operator|.
name|splitrow
argument_list|,
name|Range
operator|.
name|bottom
argument_list|)
expr_stmt|;
name|encoded
operator|=
name|this
operator|.
name|hri_b
operator|.
name|getEncodedName
argument_list|()
expr_stmt|;
name|storedir
operator|=
name|Store
operator|.
name|getStoreHomedir
argument_list|(
name|splitdir
argument_list|,
name|encoded
argument_list|,
name|family
argument_list|)
expr_stmt|;
name|StoreFile
operator|.
name|split
argument_list|(
name|fs
argument_list|,
name|storedir
argument_list|,
name|sf
argument_list|,
name|this
operator|.
name|splitrow
argument_list|,
name|Range
operator|.
name|top
argument_list|)
expr_stmt|;
block|}
comment|/**    * @param hri    * @return Created daughter HRegion.    * @throws IOException    * @see #cleanupDaughterRegion(FileSystem, Path, HRegionInfo)    */
name|HRegion
name|createDaughterRegion
parameter_list|(
specifier|final
name|HRegionInfo
name|hri
parameter_list|)
throws|throws
name|IOException
block|{
comment|// Package private so unit tests have access.
name|FileSystem
name|fs
init|=
name|this
operator|.
name|parent
operator|.
name|getFilesystem
argument_list|()
decl_stmt|;
name|Path
name|regionDir
init|=
name|getSplitDirForDaughter
argument_list|(
name|this
operator|.
name|parent
operator|.
name|getFilesystem
argument_list|()
argument_list|,
name|this
operator|.
name|splitdir
argument_list|,
name|hri
argument_list|)
decl_stmt|;
name|HRegion
name|r
init|=
name|HRegion
operator|.
name|newHRegion
argument_list|(
name|this
operator|.
name|parent
operator|.
name|getTableDir
argument_list|()
argument_list|,
name|this
operator|.
name|parent
operator|.
name|getLog
argument_list|()
argument_list|,
name|fs
argument_list|,
name|this
operator|.
name|parent
operator|.
name|getConf
argument_list|()
argument_list|,
name|hri
argument_list|,
literal|null
argument_list|)
decl_stmt|;
name|HRegion
operator|.
name|moveInitialFilesIntoPlace
argument_list|(
name|fs
argument_list|,
name|regionDir
argument_list|,
name|r
operator|.
name|getRegionDir
argument_list|()
argument_list|)
expr_stmt|;
return|return
name|r
return|;
block|}
specifier|private
specifier|static
name|void
name|cleanupDaughterRegion
parameter_list|(
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Path
name|tabledir
parameter_list|,
specifier|final
name|String
name|encodedName
parameter_list|)
throws|throws
name|IOException
block|{
name|Path
name|regiondir
init|=
name|HRegion
operator|.
name|getRegionDir
argument_list|(
name|tabledir
argument_list|,
name|encodedName
argument_list|)
decl_stmt|;
comment|// Dir may not preexist.
name|deleteDir
argument_list|(
name|fs
argument_list|,
name|regiondir
argument_list|,
literal|false
argument_list|)
expr_stmt|;
block|}
comment|/*    * Get the daughter directories in the splits dir.  The splits dir is under    * the parent regions' directory.    * @param fs    * @param splitdir    * @param hri    * @return Path to daughter split dir.    * @throws IOException    */
specifier|private
specifier|static
name|Path
name|getSplitDirForDaughter
parameter_list|(
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Path
name|splitdir
parameter_list|,
specifier|final
name|HRegionInfo
name|hri
parameter_list|)
throws|throws
name|IOException
block|{
return|return
operator|new
name|Path
argument_list|(
name|splitdir
argument_list|,
name|hri
operator|.
name|getEncodedName
argument_list|()
argument_list|)
return|;
block|}
comment|/*    * @param r Parent region we want to edit.    * @return An HTable instance against the meta table that holds passed    *<code>r</code>; it has autoFlush enabled so we immediately send puts (No    * buffering enabled).    * @throws IOException    */
specifier|private
name|HTable
name|getTable
parameter_list|(
specifier|final
name|Configuration
name|conf
parameter_list|)
throws|throws
name|IOException
block|{
comment|// When a region is split, the META table needs to updated if we're
comment|// splitting a 'normal' region, and the ROOT table needs to be
comment|// updated if we are splitting a META region.
name|HTable
name|t
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|this
operator|.
name|parent
operator|.
name|getRegionInfo
argument_list|()
operator|.
name|isMetaTable
argument_list|()
condition|)
block|{
name|t
operator|=
operator|new
name|HTable
argument_list|(
name|conf
argument_list|,
name|HConstants
operator|.
name|ROOT_TABLE_NAME
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|t
operator|=
operator|new
name|HTable
argument_list|(
name|conf
argument_list|,
name|HConstants
operator|.
name|META_TABLE_NAME
argument_list|)
expr_stmt|;
block|}
comment|// Flush puts as we send them -- no buffering.
name|t
operator|.
name|setAutoFlush
argument_list|(
literal|true
argument_list|)
expr_stmt|;
return|return
name|t
return|;
block|}
specifier|private
name|Put
name|createOfflineParentPut
parameter_list|()
throws|throws
name|IOException
block|{
name|HRegionInfo
name|editedParentRegionInfo
init|=
operator|new
name|HRegionInfo
argument_list|(
name|this
operator|.
name|parent
operator|.
name|getRegionInfo
argument_list|()
argument_list|)
decl_stmt|;
name|editedParentRegionInfo
operator|.
name|setOffline
argument_list|(
literal|true
argument_list|)
expr_stmt|;
name|editedParentRegionInfo
operator|.
name|setSplit
argument_list|(
literal|true
argument_list|)
expr_stmt|;
name|Put
name|put
init|=
operator|new
name|Put
argument_list|(
name|editedParentRegionInfo
operator|.
name|getRegionName
argument_list|()
argument_list|)
decl_stmt|;
name|put
operator|.
name|add
argument_list|(
name|HConstants
operator|.
name|CATALOG_FAMILY
argument_list|,
name|HConstants
operator|.
name|REGIONINFO_QUALIFIER
argument_list|,
name|Writables
operator|.
name|getBytes
argument_list|(
name|editedParentRegionInfo
argument_list|)
argument_list|)
expr_stmt|;
name|put
operator|.
name|add
argument_list|(
name|HConstants
operator|.
name|CATALOG_FAMILY
argument_list|,
name|HConstants
operator|.
name|SERVER_QUALIFIER
argument_list|,
name|HConstants
operator|.
name|EMPTY_BYTE_ARRAY
argument_list|)
expr_stmt|;
name|put
operator|.
name|add
argument_list|(
name|HConstants
operator|.
name|CATALOG_FAMILY
argument_list|,
name|HConstants
operator|.
name|STARTCODE_QUALIFIER
argument_list|,
name|HConstants
operator|.
name|EMPTY_BYTE_ARRAY
argument_list|)
expr_stmt|;
name|put
operator|.
name|add
argument_list|(
name|HConstants
operator|.
name|CATALOG_FAMILY
argument_list|,
name|HConstants
operator|.
name|SPLITA_QUALIFIER
argument_list|,
name|Writables
operator|.
name|getBytes
argument_list|(
name|this
operator|.
name|hri_a
argument_list|)
argument_list|)
expr_stmt|;
name|put
operator|.
name|add
argument_list|(
name|HConstants
operator|.
name|CATALOG_FAMILY
argument_list|,
name|HConstants
operator|.
name|SPLITB_QUALIFIER
argument_list|,
name|Writables
operator|.
name|getBytes
argument_list|(
name|this
operator|.
name|hri_b
argument_list|)
argument_list|)
expr_stmt|;
return|return
name|put
return|;
block|}
specifier|private
name|Put
name|createDaughterPut
parameter_list|(
specifier|final
name|HRegionInfo
name|daughter
parameter_list|)
throws|throws
name|IOException
block|{
name|Put
name|p
init|=
operator|new
name|Put
argument_list|(
name|daughter
operator|.
name|getRegionName
argument_list|()
argument_list|)
decl_stmt|;
name|p
operator|.
name|add
argument_list|(
name|HConstants
operator|.
name|CATALOG_FAMILY
argument_list|,
name|HConstants
operator|.
name|REGIONINFO_QUALIFIER
argument_list|,
name|Writables
operator|.
name|getBytes
argument_list|(
name|daughter
argument_list|)
argument_list|)
expr_stmt|;
return|return
name|p
return|;
block|}
comment|/**    * @param or Object that can online/offline parent region.  Can be passed null    * by unit tests.    * @return The region we were splitting    * @throws IOException If thrown, rollback failed.  Take drastic action.    */
specifier|public
name|void
name|rollback
parameter_list|(
specifier|final
name|OnlineRegions
name|or
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
operator|!
name|this
operator|.
name|parent
operator|.
name|splitsAndClosesLock
operator|.
name|writeLock
argument_list|()
operator|.
name|isHeldByCurrentThread
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|SplitAndCloseWriteLockNotHeld
argument_list|()
throw|;
block|}
name|FileSystem
name|fs
init|=
name|this
operator|.
name|parent
operator|.
name|getFilesystem
argument_list|()
decl_stmt|;
name|ListIterator
argument_list|<
name|JournalEntry
argument_list|>
name|iterator
init|=
name|this
operator|.
name|journal
operator|.
name|listIterator
argument_list|(
name|this
operator|.
name|journal
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
while|while
condition|(
name|iterator
operator|.
name|hasPrevious
argument_list|()
condition|)
block|{
name|JournalEntry
name|je
init|=
name|iterator
operator|.
name|previous
argument_list|()
decl_stmt|;
switch|switch
condition|(
name|je
condition|)
block|{
case|case
name|CREATE_SPLIT_DIR
case|:
name|cleanupSplitDir
argument_list|(
name|fs
argument_list|,
name|this
operator|.
name|splitdir
argument_list|)
expr_stmt|;
break|break;
case|case
name|CLOSED_PARENT_REGION
case|:
comment|// So, this returns a seqid but if we just closed and then reopened, we
comment|// should be ok. On close, we flushed using sequenceid obtained from
comment|// hosting regionserver so no need to propagate the sequenceid returned
comment|// out of initialize below up into regionserver as we normally do.
comment|// TODO: Verify.
name|this
operator|.
name|parent
operator|.
name|initialize
argument_list|()
expr_stmt|;
break|break;
case|case
name|STARTED_REGION_A_CREATION
case|:
name|cleanupDaughterRegion
argument_list|(
name|fs
argument_list|,
name|this
operator|.
name|parent
operator|.
name|getTableDir
argument_list|()
argument_list|,
name|this
operator|.
name|hri_a
operator|.
name|getEncodedName
argument_list|()
argument_list|)
expr_stmt|;
break|break;
case|case
name|STARTED_REGION_B_CREATION
case|:
name|cleanupDaughterRegion
argument_list|(
name|fs
argument_list|,
name|this
operator|.
name|parent
operator|.
name|getTableDir
argument_list|()
argument_list|,
name|this
operator|.
name|hri_b
operator|.
name|getEncodedName
argument_list|()
argument_list|)
expr_stmt|;
break|break;
case|case
name|OFFLINED_PARENT
case|:
if|if
condition|(
name|or
operator|!=
literal|null
condition|)
name|or
operator|.
name|addToOnlineRegions
argument_list|(
name|this
operator|.
name|parent
argument_list|)
expr_stmt|;
break|break;
default|default:
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"Unhandled journal entry: "
operator|+
name|je
argument_list|)
throw|;
block|}
block|}
if|if
condition|(
name|this
operator|.
name|parent
operator|.
name|splitsAndClosesLock
operator|.
name|writeLock
argument_list|()
operator|.
name|isHeldByCurrentThread
argument_list|()
condition|)
block|{
name|this
operator|.
name|parent
operator|.
name|splitsAndClosesLock
operator|.
name|writeLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**    * Thrown if lock not held.    */
annotation|@
name|SuppressWarnings
argument_list|(
literal|"serial"
argument_list|)
specifier|public
class|class
name|SplitAndCloseWriteLockNotHeld
extends|extends
name|IOException
block|{}
name|HRegionInfo
name|getFirstDaughter
parameter_list|()
block|{
return|return
name|hri_a
return|;
block|}
name|HRegionInfo
name|getSecondDaughter
parameter_list|()
block|{
return|return
name|hri_b
return|;
block|}
comment|// For unit testing.
name|Path
name|getSplitDir
parameter_list|()
block|{
return|return
name|this
operator|.
name|splitdir
return|;
block|}
comment|/**    * Clean up any split detritus that may have been left around from previous    * split attempts.    * Call this method on initial region deploy.  Cleans up any mess    * left by previous deploys of passed<code>r</code> region.    * @param r    * @throws IOException     */
specifier|static
name|void
name|cleanupAnySplitDetritus
parameter_list|(
specifier|final
name|HRegion
name|r
parameter_list|)
throws|throws
name|IOException
block|{
name|Path
name|splitdir
init|=
name|getSplitDir
argument_list|(
name|r
argument_list|)
decl_stmt|;
name|FileSystem
name|fs
init|=
name|r
operator|.
name|getFilesystem
argument_list|()
decl_stmt|;
if|if
condition|(
operator|!
name|fs
operator|.
name|exists
argument_list|(
name|splitdir
argument_list|)
condition|)
return|return;
comment|// Look at the splitdir.  It could have the encoded names of the daughter
comment|// regions we tried to make.  See if the daughter regions actually got made
comment|// out under the tabledir.  If here under splitdir still, then the split did
comment|// not complete.  Try and do cleanup.  This code WILL NOT catch the case
comment|// where we successfully created daughter a but regionserver crashed during
comment|// the creation of region b.  In this case, there'll be an orphan daughter
comment|// dir in the filesystem.  TOOD: Fix.
name|FileStatus
index|[]
name|daughters
init|=
name|fs
operator|.
name|listStatus
argument_list|(
name|splitdir
argument_list|,
operator|new
name|FSUtils
operator|.
name|DirFilter
argument_list|(
name|fs
argument_list|)
argument_list|)
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|daughters
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|cleanupDaughterRegion
argument_list|(
name|fs
argument_list|,
name|r
operator|.
name|getTableDir
argument_list|()
argument_list|,
name|daughters
index|[
name|i
index|]
operator|.
name|getPath
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|cleanupSplitDir
argument_list|(
name|r
operator|.
name|getFilesystem
argument_list|()
argument_list|,
name|splitdir
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Cleaned up old failed split transaction detritus: "
operator|+
name|splitdir
argument_list|)
expr_stmt|;
block|}
block|}
end_class

end_unit

