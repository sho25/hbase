begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Copyright 2007 The Apache Software Foundation  *  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|DataInput
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|DataInputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|DataOutput
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|FileNotFoundException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|UnsupportedEncodingException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Random
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|Log
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|LogFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FSDataOutputStream
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|ImmutableBytesWritable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|Writables
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|MapFile
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|SequenceFile
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|Text
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|Writable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|WritableComparable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|onelab
operator|.
name|filter
operator|.
name|Filter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|onelab
operator|.
name|filter
operator|.
name|Key
import|;
end_import

begin_comment
comment|/**  * A HStore data file.  HStores usually have one or more of these files.  They  * are produced by flushing the memcache to disk.  *  *<p>Each HStore maintains a bunch of different data files. The filename is a  * mix of the parent dir, the region name, the column name, and a file  * identifier. The name may also be a reference to a store file located  * elsewhere. This class handles all that path-building stuff for you.  *   *<p>An HStoreFile usually tracks 4 things: its parent dir, the region  * identifier, the column family, and the file identifier.  If you know those  * four things, you know how to obtain the right HStoreFile.  HStoreFiles may  * also refernce store files in another region serving either from  * the top-half of the remote file or from the bottom-half.  Such references  * are made fast splitting regions.  *   *<p>Plain HStoreFiles are named for a randomly generated id as in:  *<code>1278437856009925445</code>  A file by this name is made in both the  *<code>mapfiles</code> and<code>info</code> subdirectories of a  * HStore columnfamily directoy: E.g. If the column family is 'anchor:', then  * under the region directory there is a subdirectory named 'anchor' within  * which is a 'mapfiles' and 'info' subdirectory.  In each will be found a  * file named something like<code>1278437856009925445</code>, one to hold the  * data in 'mapfiles' and one under 'info' that holds the sequence id for this  * store file.  *   *<p>References to store files located over in some other region look like  * this:  *<code>1278437856009925445.hbaserepository,qAReLZD-OyQORZWq_vqR1k==,959247014679548184</code>:  * i.e. an id followed by the name of the referenced region.  The data  * ('mapfiles') of HStoreFile references are empty. The accompanying  *<code>info</code> file contains the  * midkey, the id of the remote store we're referencing and whether we're  * to serve the top or bottom region of the remote store file.  Note, a region  * is not splitable if it has instances of store file references (References  * are cleaned up by compactions).  *   *<p>When merging or splitting HRegions, we might want to modify one of the   * params for an HStoreFile (effectively moving it elsewhere).  */
end_comment

begin_class
specifier|public
class|class
name|HStoreFile
implements|implements
name|HConstants
block|{
specifier|static
specifier|final
name|Log
name|LOG
init|=
name|LogFactory
operator|.
name|getLog
argument_list|(
name|HStoreFile
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
specifier|static
specifier|final
name|byte
name|INFO_SEQ_NUM
init|=
literal|0
decl_stmt|;
specifier|static
specifier|final
name|String
name|HSTORE_DATFILE_DIR
init|=
literal|"mapfiles"
decl_stmt|;
specifier|static
specifier|final
name|String
name|HSTORE_INFO_DIR
init|=
literal|"info"
decl_stmt|;
specifier|static
specifier|final
name|String
name|HSTORE_FILTER_DIR
init|=
literal|"filter"
decl_stmt|;
comment|/**     * For split HStoreFiles, specifies if the file covers the lower half or    * the upper half of the key range    */
specifier|public
specifier|static
enum|enum
name|Range
block|{
comment|/** HStoreFile contains upper half of key range */
name|top
block|,
comment|/** HStoreFile contains lower half of key range */
name|bottom
block|}
specifier|private
specifier|final
specifier|static
name|Random
name|rand
init|=
operator|new
name|Random
argument_list|()
decl_stmt|;
specifier|private
specifier|final
name|Path
name|basedir
decl_stmt|;
specifier|private
specifier|final
name|String
name|encodedRegionName
decl_stmt|;
specifier|private
specifier|final
name|Text
name|colFamily
decl_stmt|;
specifier|private
specifier|final
name|long
name|fileId
decl_stmt|;
specifier|private
specifier|final
name|HBaseConfiguration
name|conf
decl_stmt|;
specifier|private
specifier|final
name|FileSystem
name|fs
decl_stmt|;
specifier|private
specifier|final
name|Reference
name|reference
decl_stmt|;
comment|/**    * Constructor that fully initializes the object    * @param conf Configuration object    * @param basedir qualified path that is parent of region directory    * @param encodedRegionName file name friendly name of the region    * @param colFamily name of the column family    * @param fileId file identifier    * @param ref Reference to another HStoreFile.    * @throws IOException    */
name|HStoreFile
parameter_list|(
name|HBaseConfiguration
name|conf
parameter_list|,
name|FileSystem
name|fs
parameter_list|,
name|Path
name|basedir
parameter_list|,
name|String
name|encodedRegionName
parameter_list|,
name|Text
name|colFamily
parameter_list|,
name|long
name|fileId
parameter_list|,
specifier|final
name|Reference
name|ref
parameter_list|)
throws|throws
name|IOException
block|{
name|this
operator|.
name|conf
operator|=
name|conf
expr_stmt|;
name|this
operator|.
name|fs
operator|=
name|fs
expr_stmt|;
name|this
operator|.
name|basedir
operator|=
name|basedir
expr_stmt|;
name|this
operator|.
name|encodedRegionName
operator|=
name|encodedRegionName
expr_stmt|;
name|this
operator|.
name|colFamily
operator|=
operator|new
name|Text
argument_list|(
name|colFamily
argument_list|)
expr_stmt|;
name|long
name|id
init|=
name|fileId
decl_stmt|;
if|if
condition|(
name|id
operator|==
operator|-
literal|1
condition|)
block|{
name|Path
name|mapdir
init|=
name|HStoreFile
operator|.
name|getMapDir
argument_list|(
name|basedir
argument_list|,
name|encodedRegionName
argument_list|,
name|colFamily
argument_list|)
decl_stmt|;
name|Path
name|testpath
init|=
literal|null
decl_stmt|;
do|do
block|{
name|id
operator|=
name|Math
operator|.
name|abs
argument_list|(
name|rand
operator|.
name|nextLong
argument_list|()
argument_list|)
expr_stmt|;
name|testpath
operator|=
operator|new
name|Path
argument_list|(
name|mapdir
argument_list|,
name|createHStoreFilename
argument_list|(
name|id
argument_list|,
literal|null
argument_list|)
argument_list|)
expr_stmt|;
block|}
do|while
condition|(
name|fs
operator|.
name|exists
argument_list|(
name|testpath
argument_list|)
condition|)
do|;
block|}
name|this
operator|.
name|fileId
operator|=
name|id
expr_stmt|;
comment|// If a reference, construction does not write the pointer files.  Thats
comment|// done by invocations of writeReferenceFiles(hsf, fs).  Happens at fast
comment|// split time.
name|this
operator|.
name|reference
operator|=
name|ref
expr_stmt|;
block|}
comment|/** @return the region name */
name|boolean
name|isReference
parameter_list|()
block|{
return|return
name|reference
operator|!=
literal|null
return|;
block|}
name|Reference
name|getReference
parameter_list|()
block|{
return|return
name|reference
return|;
block|}
name|String
name|getEncodedRegionName
parameter_list|()
block|{
return|return
name|encodedRegionName
return|;
block|}
comment|/** @return the column family */
name|Text
name|getColFamily
parameter_list|()
block|{
return|return
name|colFamily
return|;
block|}
comment|/** @return the file identifier */
name|long
name|getFileId
parameter_list|()
block|{
return|return
name|fileId
return|;
block|}
comment|// Build full filenames from those components
comment|/** @return path for MapFile */
name|Path
name|getMapFilePath
parameter_list|()
block|{
if|if
condition|(
name|isReference
argument_list|()
condition|)
block|{
return|return
name|getMapFilePath
argument_list|(
name|encodedRegionName
argument_list|,
name|fileId
argument_list|,
name|reference
operator|.
name|getEncodedRegionName
argument_list|()
argument_list|)
return|;
block|}
return|return
name|getMapFilePath
argument_list|(
name|encodedRegionName
argument_list|,
name|fileId
argument_list|,
literal|null
argument_list|)
return|;
block|}
specifier|private
name|Path
name|getMapFilePath
parameter_list|(
specifier|final
name|Reference
name|r
parameter_list|)
block|{
if|if
condition|(
name|r
operator|==
literal|null
condition|)
block|{
return|return
name|getMapFilePath
argument_list|()
return|;
block|}
return|return
name|getMapFilePath
argument_list|(
name|r
operator|.
name|getEncodedRegionName
argument_list|()
argument_list|,
name|r
operator|.
name|getFileId
argument_list|()
argument_list|,
literal|null
argument_list|)
return|;
block|}
specifier|private
name|Path
name|getMapFilePath
parameter_list|(
specifier|final
name|String
name|encodedName
parameter_list|,
specifier|final
name|long
name|fid
parameter_list|,
specifier|final
name|String
name|ern
parameter_list|)
block|{
return|return
operator|new
name|Path
argument_list|(
name|HStoreFile
operator|.
name|getMapDir
argument_list|(
name|basedir
argument_list|,
name|encodedName
argument_list|,
name|colFamily
argument_list|)
argument_list|,
name|createHStoreFilename
argument_list|(
name|fid
argument_list|,
name|ern
argument_list|)
argument_list|)
return|;
block|}
comment|/** @return path for info file */
name|Path
name|getInfoFilePath
parameter_list|()
block|{
if|if
condition|(
name|isReference
argument_list|()
condition|)
block|{
return|return
name|getInfoFilePath
argument_list|(
name|encodedRegionName
argument_list|,
name|fileId
argument_list|,
name|reference
operator|.
name|getEncodedRegionName
argument_list|()
argument_list|)
return|;
block|}
return|return
name|getInfoFilePath
argument_list|(
name|encodedRegionName
argument_list|,
name|fileId
argument_list|,
literal|null
argument_list|)
return|;
block|}
specifier|private
name|Path
name|getInfoFilePath
parameter_list|(
specifier|final
name|String
name|encodedName
parameter_list|,
specifier|final
name|long
name|fid
parameter_list|,
specifier|final
name|String
name|ern
parameter_list|)
block|{
return|return
operator|new
name|Path
argument_list|(
name|HStoreFile
operator|.
name|getInfoDir
argument_list|(
name|basedir
argument_list|,
name|encodedName
argument_list|,
name|colFamily
argument_list|)
argument_list|,
name|createHStoreFilename
argument_list|(
name|fid
argument_list|,
name|ern
argument_list|)
argument_list|)
return|;
block|}
comment|// File handling
comment|/*    * Split by making two new store files that reference top and bottom regions    * of original store file.    * @param midKey    * @param dstA    * @param dstB    * @param fs    * @param c    * @throws IOException    *    * @param midKey the key which will be the starting key of the second region    * @param dstA the file which will contain keys from the start of the source    * @param dstB the file which will contain keys from midKey to end of source    * @param fs file system    * @param c configuration    * @throws IOException    */
name|void
name|splitStoreFile
parameter_list|(
specifier|final
name|HStoreFile
name|dstA
parameter_list|,
specifier|final
name|HStoreFile
name|dstB
parameter_list|,
specifier|final
name|FileSystem
name|fs
parameter_list|)
throws|throws
name|IOException
block|{
name|dstA
operator|.
name|writeReferenceFiles
argument_list|(
name|fs
argument_list|)
expr_stmt|;
name|dstB
operator|.
name|writeReferenceFiles
argument_list|(
name|fs
argument_list|)
expr_stmt|;
block|}
name|void
name|writeReferenceFiles
parameter_list|(
specifier|final
name|FileSystem
name|fs
parameter_list|)
throws|throws
name|IOException
block|{
name|createOrFail
argument_list|(
name|fs
argument_list|,
name|getMapFilePath
argument_list|()
argument_list|)
expr_stmt|;
name|writeSplitInfo
argument_list|(
name|fs
argument_list|)
expr_stmt|;
block|}
comment|/*    * If reference, create and write the remote store file id, the midkey and    * whether we're going against the top file region of the referent out to    * the info file.     * @param p Path to info file.    * @param hsf    * @param fs    * @throws IOException    */
specifier|private
name|void
name|writeSplitInfo
parameter_list|(
specifier|final
name|FileSystem
name|fs
parameter_list|)
throws|throws
name|IOException
block|{
name|Path
name|p
init|=
name|getInfoFilePath
argument_list|()
decl_stmt|;
if|if
condition|(
name|fs
operator|.
name|exists
argument_list|(
name|p
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"File already exists "
operator|+
name|p
operator|.
name|toString
argument_list|()
argument_list|)
throw|;
block|}
name|FSDataOutputStream
name|out
init|=
name|fs
operator|.
name|create
argument_list|(
name|p
argument_list|)
decl_stmt|;
try|try
block|{
name|reference
operator|.
name|write
argument_list|(
name|out
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|out
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
block|}
specifier|private
name|void
name|createOrFail
parameter_list|(
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Path
name|p
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|fs
operator|.
name|exists
argument_list|(
name|p
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"File already exists "
operator|+
name|p
operator|.
name|toString
argument_list|()
argument_list|)
throw|;
block|}
if|if
condition|(
operator|!
name|fs
operator|.
name|createNewFile
argument_list|(
name|p
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Failed create of "
operator|+
name|p
argument_list|)
throw|;
block|}
block|}
comment|/**    * Merges the contents of the given source HStoreFiles into a single new one.    *    * @param srcFiles files to be merged    * @param fs file system    * @param conf configuration object    * @throws IOException    */
name|void
name|mergeStoreFiles
parameter_list|(
name|List
argument_list|<
name|HStoreFile
argument_list|>
name|srcFiles
parameter_list|,
name|FileSystem
name|fs
parameter_list|,
annotation|@
name|SuppressWarnings
argument_list|(
literal|"hiding"
argument_list|)
name|Configuration
name|conf
parameter_list|)
throws|throws
name|IOException
block|{
comment|// Copy all the source MapFile tuples into this HSF's MapFile
name|MapFile
operator|.
name|Writer
name|out
init|=
operator|new
name|MapFile
operator|.
name|Writer
argument_list|(
name|conf
argument_list|,
name|fs
argument_list|,
name|getMapFilePath
argument_list|()
operator|.
name|toString
argument_list|()
argument_list|,
name|HStoreKey
operator|.
name|class
argument_list|,
name|ImmutableBytesWritable
operator|.
name|class
argument_list|)
decl_stmt|;
try|try
block|{
for|for
control|(
name|HStoreFile
name|src
range|:
name|srcFiles
control|)
block|{
name|MapFile
operator|.
name|Reader
name|in
init|=
name|src
operator|.
name|getReader
argument_list|(
name|fs
argument_list|,
literal|null
argument_list|)
decl_stmt|;
try|try
block|{
name|HStoreKey
name|readkey
init|=
operator|new
name|HStoreKey
argument_list|()
decl_stmt|;
name|ImmutableBytesWritable
name|readval
init|=
operator|new
name|ImmutableBytesWritable
argument_list|()
decl_stmt|;
while|while
condition|(
name|in
operator|.
name|next
argument_list|(
name|readkey
argument_list|,
name|readval
argument_list|)
condition|)
block|{
name|out
operator|.
name|append
argument_list|(
name|readkey
argument_list|,
name|readval
argument_list|)
expr_stmt|;
block|}
block|}
finally|finally
block|{
name|in
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
block|}
block|}
finally|finally
block|{
name|out
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
comment|// Build a unified InfoFile from the source InfoFiles.
name|long
name|unifiedSeqId
init|=
operator|-
literal|1
decl_stmt|;
for|for
control|(
name|HStoreFile
name|hsf
range|:
name|srcFiles
control|)
block|{
name|long
name|curSeqId
init|=
name|hsf
operator|.
name|loadInfo
argument_list|(
name|fs
argument_list|)
decl_stmt|;
if|if
condition|(
name|curSeqId
operator|>
name|unifiedSeqId
condition|)
block|{
name|unifiedSeqId
operator|=
name|curSeqId
expr_stmt|;
block|}
block|}
name|writeInfo
argument_list|(
name|fs
argument_list|,
name|unifiedSeqId
argument_list|)
expr_stmt|;
block|}
comment|/**     * Reads in an info file    *    * @param fs file system    * @return The sequence id contained in the info file    * @throws IOException    */
name|long
name|loadInfo
parameter_list|(
name|FileSystem
name|fs
parameter_list|)
throws|throws
name|IOException
block|{
name|Path
name|p
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|isReference
argument_list|()
condition|)
block|{
name|p
operator|=
name|getInfoFilePath
argument_list|(
name|reference
operator|.
name|getEncodedRegionName
argument_list|()
argument_list|,
name|reference
operator|.
name|getFileId
argument_list|()
argument_list|,
literal|null
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|p
operator|=
name|getInfoFilePath
argument_list|()
expr_stmt|;
block|}
name|DataInputStream
name|in
init|=
operator|new
name|DataInputStream
argument_list|(
name|fs
operator|.
name|open
argument_list|(
name|p
argument_list|)
argument_list|)
decl_stmt|;
try|try
block|{
name|byte
name|flag
init|=
name|in
operator|.
name|readByte
argument_list|()
decl_stmt|;
if|if
condition|(
name|flag
operator|==
name|INFO_SEQ_NUM
condition|)
block|{
return|return
name|in
operator|.
name|readLong
argument_list|()
return|;
block|}
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Cannot process log file: "
operator|+
name|p
argument_list|)
throw|;
block|}
finally|finally
block|{
name|in
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**    * Writes the file-identifier to disk    *     * @param fs file system    * @param infonum file id    * @throws IOException    */
name|void
name|writeInfo
parameter_list|(
name|FileSystem
name|fs
parameter_list|,
name|long
name|infonum
parameter_list|)
throws|throws
name|IOException
block|{
name|Path
name|p
init|=
name|getInfoFilePath
argument_list|()
decl_stmt|;
name|FSDataOutputStream
name|out
init|=
name|fs
operator|.
name|create
argument_list|(
name|p
argument_list|)
decl_stmt|;
try|try
block|{
name|out
operator|.
name|writeByte
argument_list|(
name|INFO_SEQ_NUM
argument_list|)
expr_stmt|;
name|out
operator|.
name|writeLong
argument_list|(
name|infonum
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|out
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**    * Delete store map files.    * @throws IOException     */
specifier|public
name|void
name|delete
parameter_list|()
throws|throws
name|IOException
block|{
name|fs
operator|.
name|delete
argument_list|(
name|getMapFilePath
argument_list|()
argument_list|)
expr_stmt|;
name|fs
operator|.
name|delete
argument_list|(
name|getInfoFilePath
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|/**    * Renames the mapfiles and info directories under the passed    *<code>hsf</code> directory.    * @param fs    * @param hsf    * @return True if succeeded.    * @throws IOException    */
specifier|public
name|boolean
name|rename
parameter_list|(
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|HStoreFile
name|hsf
parameter_list|)
throws|throws
name|IOException
block|{
name|Path
name|src
init|=
name|getMapFilePath
argument_list|()
decl_stmt|;
if|if
condition|(
operator|!
name|fs
operator|.
name|exists
argument_list|(
name|src
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|FileNotFoundException
argument_list|(
name|src
operator|.
name|toString
argument_list|()
argument_list|)
throw|;
block|}
name|boolean
name|success
init|=
name|fs
operator|.
name|rename
argument_list|(
name|src
argument_list|,
name|hsf
operator|.
name|getMapFilePath
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|success
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failed rename of "
operator|+
name|src
operator|+
literal|" to "
operator|+
name|hsf
operator|.
name|getMapFilePath
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|src
operator|=
name|getInfoFilePath
argument_list|()
expr_stmt|;
if|if
condition|(
operator|!
name|fs
operator|.
name|exists
argument_list|(
name|src
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|FileNotFoundException
argument_list|(
name|src
operator|.
name|toString
argument_list|()
argument_list|)
throw|;
block|}
name|success
operator|=
name|fs
operator|.
name|rename
argument_list|(
name|src
argument_list|,
name|hsf
operator|.
name|getInfoFilePath
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|success
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failed rename of "
operator|+
name|src
operator|+
literal|" to "
operator|+
name|hsf
operator|.
name|getInfoFilePath
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|success
return|;
block|}
comment|/**    * Get reader for the store file map file.    * Client is responsible for closing file when done.    * @param fs    * @param bloomFilter If null, no filtering is done.    * @return MapFile.Reader    * @throws IOException    */
specifier|public
specifier|synchronized
name|MapFile
operator|.
name|Reader
name|getReader
parameter_list|(
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Filter
name|bloomFilter
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|isReference
argument_list|()
condition|)
block|{
return|return
operator|new
name|HStoreFile
operator|.
name|HalfMapFileReader
argument_list|(
name|fs
argument_list|,
name|getMapFilePath
argument_list|(
name|reference
argument_list|)
operator|.
name|toString
argument_list|()
argument_list|,
name|conf
argument_list|,
name|reference
operator|.
name|getFileRegion
argument_list|()
argument_list|,
name|reference
operator|.
name|getMidkey
argument_list|()
argument_list|,
name|bloomFilter
argument_list|)
return|;
block|}
return|return
operator|new
name|BloomFilterMapFile
operator|.
name|Reader
argument_list|(
name|fs
argument_list|,
name|getMapFilePath
argument_list|()
operator|.
name|toString
argument_list|()
argument_list|,
name|conf
argument_list|,
name|bloomFilter
argument_list|)
return|;
block|}
comment|/**    * Get a store file writer.    * Client is responsible for closing file when done.    * @param fs    * @param compression Pass<code>SequenceFile.CompressionType.NONE</code>    * for none.    * @param bloomFilter If null, no filtering is done.    * @return MapFile.Writer    * @throws IOException    */
specifier|public
name|MapFile
operator|.
name|Writer
name|getWriter
parameter_list|(
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|SequenceFile
operator|.
name|CompressionType
name|compression
parameter_list|,
specifier|final
name|Filter
name|bloomFilter
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|isReference
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Illegal Access: Cannot get a writer on a"
operator|+
literal|"HStoreFile reference"
argument_list|)
throw|;
block|}
return|return
operator|new
name|BloomFilterMapFile
operator|.
name|Writer
argument_list|(
name|conf
argument_list|,
name|fs
argument_list|,
name|getMapFilePath
argument_list|()
operator|.
name|toString
argument_list|()
argument_list|,
name|HStoreKey
operator|.
name|class
argument_list|,
name|ImmutableBytesWritable
operator|.
name|class
argument_list|,
name|compression
argument_list|,
name|bloomFilter
argument_list|)
return|;
block|}
comment|/**    * @return Length of the store map file.  If a reference, size is    * approximation.    * @throws IOException    */
specifier|public
name|long
name|length
parameter_list|()
throws|throws
name|IOException
block|{
name|Path
name|p
init|=
operator|new
name|Path
argument_list|(
name|getMapFilePath
argument_list|(
name|reference
argument_list|)
argument_list|,
name|MapFile
operator|.
name|DATA_FILE_NAME
argument_list|)
decl_stmt|;
name|long
name|l
init|=
name|p
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
operator|.
name|getFileStatus
argument_list|(
name|p
argument_list|)
operator|.
name|getLen
argument_list|()
decl_stmt|;
return|return
operator|(
name|isReference
argument_list|()
operator|)
condition|?
name|l
operator|/
literal|2
else|:
name|l
return|;
block|}
comment|/** {@inheritDoc} */
annotation|@
name|Override
specifier|public
name|String
name|toString
parameter_list|()
block|{
return|return
name|encodedRegionName
operator|+
literal|"/"
operator|+
name|colFamily
operator|+
literal|"/"
operator|+
name|fileId
operator|+
operator|(
name|isReference
argument_list|()
condition|?
literal|"/"
operator|+
name|reference
operator|.
name|toString
argument_list|()
else|:
literal|""
operator|)
return|;
block|}
comment|/**    * Custom bloom filter key maker.    * @param key    * @return Key made of bytes of row and column only.    * @throws IOException    */
specifier|static
name|Key
name|getBloomFilterKey
parameter_list|(
name|WritableComparable
name|key
parameter_list|)
throws|throws
name|IOException
block|{
name|HStoreKey
name|hsk
init|=
operator|(
name|HStoreKey
operator|)
name|key
decl_stmt|;
name|byte
index|[]
name|bytes
init|=
literal|null
decl_stmt|;
try|try
block|{
name|bytes
operator|=
operator|(
name|hsk
operator|.
name|getRow
argument_list|()
operator|.
name|toString
argument_list|()
operator|+
name|hsk
operator|.
name|getColumn
argument_list|()
operator|.
name|toString
argument_list|()
operator|)
operator|.
name|getBytes
argument_list|(
name|UTF8_ENCODING
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|UnsupportedEncodingException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|e
operator|.
name|toString
argument_list|()
argument_list|)
throw|;
block|}
return|return
operator|new
name|Key
argument_list|(
name|bytes
argument_list|)
return|;
block|}
specifier|static
name|boolean
name|isTopFileRegion
parameter_list|(
specifier|final
name|Range
name|r
parameter_list|)
block|{
return|return
name|r
operator|.
name|equals
argument_list|(
name|Range
operator|.
name|top
argument_list|)
return|;
block|}
specifier|private
specifier|static
name|String
name|createHStoreFilename
parameter_list|(
specifier|final
name|long
name|fid
parameter_list|,
specifier|final
name|String
name|encodedRegionName
parameter_list|)
block|{
return|return
name|Long
operator|.
name|toString
argument_list|(
name|fid
argument_list|)
operator|+
operator|(
operator|(
name|encodedRegionName
operator|!=
literal|null
operator|)
condition|?
literal|"."
operator|+
name|encodedRegionName
else|:
literal|""
operator|)
return|;
block|}
specifier|static
name|Path
name|getMapDir
parameter_list|(
name|Path
name|dir
parameter_list|,
name|String
name|encodedRegionName
parameter_list|,
name|Text
name|colFamily
parameter_list|)
block|{
return|return
operator|new
name|Path
argument_list|(
name|dir
argument_list|,
operator|new
name|Path
argument_list|(
name|encodedRegionName
argument_list|,
operator|new
name|Path
argument_list|(
name|colFamily
operator|.
name|toString
argument_list|()
argument_list|,
name|HSTORE_DATFILE_DIR
argument_list|)
argument_list|)
argument_list|)
return|;
block|}
comment|/** @return the info directory path */
specifier|static
name|Path
name|getInfoDir
parameter_list|(
name|Path
name|dir
parameter_list|,
name|String
name|encodedRegionName
parameter_list|,
name|Text
name|colFamily
parameter_list|)
block|{
return|return
operator|new
name|Path
argument_list|(
name|dir
argument_list|,
operator|new
name|Path
argument_list|(
name|encodedRegionName
argument_list|,
operator|new
name|Path
argument_list|(
name|colFamily
operator|.
name|toString
argument_list|()
argument_list|,
name|HSTORE_INFO_DIR
argument_list|)
argument_list|)
argument_list|)
return|;
block|}
comment|/** @return the bloom filter directory path */
specifier|static
name|Path
name|getFilterDir
parameter_list|(
name|Path
name|dir
parameter_list|,
name|String
name|encodedRegionName
parameter_list|,
name|Text
name|colFamily
parameter_list|)
block|{
return|return
operator|new
name|Path
argument_list|(
name|dir
argument_list|,
operator|new
name|Path
argument_list|(
name|encodedRegionName
argument_list|,
operator|new
name|Path
argument_list|(
name|colFamily
operator|.
name|toString
argument_list|()
argument_list|,
name|HSTORE_FILTER_DIR
argument_list|)
argument_list|)
argument_list|)
return|;
block|}
comment|/*    * Data structure to hold reference to a store file over in another region.    */
specifier|static
class|class
name|Reference
implements|implements
name|Writable
block|{
specifier|private
name|String
name|encodedRegionName
decl_stmt|;
specifier|private
name|long
name|fileid
decl_stmt|;
specifier|private
name|Range
name|region
decl_stmt|;
specifier|private
name|HStoreKey
name|midkey
decl_stmt|;
name|Reference
parameter_list|(
specifier|final
name|String
name|ern
parameter_list|,
specifier|final
name|long
name|fid
parameter_list|,
specifier|final
name|HStoreKey
name|m
parameter_list|,
specifier|final
name|Range
name|fr
parameter_list|)
block|{
name|this
operator|.
name|encodedRegionName
operator|=
name|ern
expr_stmt|;
name|this
operator|.
name|fileid
operator|=
name|fid
expr_stmt|;
name|this
operator|.
name|region
operator|=
name|fr
expr_stmt|;
name|this
operator|.
name|midkey
operator|=
name|m
expr_stmt|;
block|}
name|Reference
parameter_list|()
block|{
name|this
argument_list|(
literal|null
argument_list|,
operator|-
literal|1
argument_list|,
literal|null
argument_list|,
name|Range
operator|.
name|bottom
argument_list|)
expr_stmt|;
block|}
name|long
name|getFileId
parameter_list|()
block|{
return|return
name|fileid
return|;
block|}
name|Range
name|getFileRegion
parameter_list|()
block|{
return|return
name|region
return|;
block|}
name|HStoreKey
name|getMidkey
parameter_list|()
block|{
return|return
name|midkey
return|;
block|}
name|String
name|getEncodedRegionName
parameter_list|()
block|{
return|return
name|encodedRegionName
return|;
block|}
comment|/** {@inheritDoc} */
annotation|@
name|Override
specifier|public
name|String
name|toString
parameter_list|()
block|{
return|return
name|encodedRegionName
operator|+
literal|"/"
operator|+
name|fileid
operator|+
literal|"/"
operator|+
name|region
return|;
block|}
comment|// Make it serializable.
comment|/** {@inheritDoc} */
specifier|public
name|void
name|write
parameter_list|(
name|DataOutput
name|out
parameter_list|)
throws|throws
name|IOException
block|{
name|out
operator|.
name|writeUTF
argument_list|(
name|encodedRegionName
argument_list|)
expr_stmt|;
name|out
operator|.
name|writeLong
argument_list|(
name|fileid
argument_list|)
expr_stmt|;
comment|// Write true if we're doing top of the file.
name|out
operator|.
name|writeBoolean
argument_list|(
name|isTopFileRegion
argument_list|(
name|region
argument_list|)
argument_list|)
expr_stmt|;
name|midkey
operator|.
name|write
argument_list|(
name|out
argument_list|)
expr_stmt|;
block|}
comment|/** {@inheritDoc} */
specifier|public
name|void
name|readFields
parameter_list|(
name|DataInput
name|in
parameter_list|)
throws|throws
name|IOException
block|{
name|encodedRegionName
operator|=
name|in
operator|.
name|readUTF
argument_list|()
expr_stmt|;
name|fileid
operator|=
name|in
operator|.
name|readLong
argument_list|()
expr_stmt|;
name|boolean
name|tmp
init|=
name|in
operator|.
name|readBoolean
argument_list|()
decl_stmt|;
comment|// If true, set region to top.
name|region
operator|=
name|tmp
condition|?
name|Range
operator|.
name|top
else|:
name|Range
operator|.
name|bottom
expr_stmt|;
name|midkey
operator|=
operator|new
name|HStoreKey
argument_list|()
expr_stmt|;
name|midkey
operator|.
name|readFields
argument_list|(
name|in
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Hbase customizations of MapFile.    */
specifier|static
class|class
name|HbaseMapFile
extends|extends
name|MapFile
block|{
specifier|static
class|class
name|HbaseReader
extends|extends
name|MapFile
operator|.
name|Reader
block|{
comment|/**        * @param fs        * @param dirName        * @param conf        * @throws IOException        */
specifier|public
name|HbaseReader
parameter_list|(
name|FileSystem
name|fs
parameter_list|,
name|String
name|dirName
parameter_list|,
name|Configuration
name|conf
parameter_list|)
throws|throws
name|IOException
block|{
name|super
argument_list|(
name|fs
argument_list|,
name|dirName
argument_list|,
name|conf
argument_list|)
expr_stmt|;
comment|// Force reading of the mapfile index by calling midKey.
comment|// Reading the index will bring the index into memory over
comment|// here on the client and then close the index file freeing
comment|// up socket connection and resources in the datanode.
comment|// Usually, the first access on a MapFile.Reader will load the
comment|// index force the issue in HStoreFile MapFiles because an
comment|// access may not happen for some time; meantime we're
comment|// using up datanode resources.  See HADOOP-2341.
name|midKey
argument_list|()
expr_stmt|;
block|}
block|}
specifier|static
class|class
name|HbaseWriter
extends|extends
name|MapFile
operator|.
name|Writer
block|{
comment|/**        * @param conf        * @param fs        * @param dirName        * @param keyClass        * @param valClass        * @param compression        * @throws IOException        */
specifier|public
name|HbaseWriter
parameter_list|(
name|Configuration
name|conf
parameter_list|,
name|FileSystem
name|fs
parameter_list|,
name|String
name|dirName
parameter_list|,
name|Class
argument_list|<
name|Writable
argument_list|>
name|keyClass
parameter_list|,
name|Class
argument_list|<
name|Writable
argument_list|>
name|valClass
parameter_list|,
name|SequenceFile
operator|.
name|CompressionType
name|compression
parameter_list|)
throws|throws
name|IOException
block|{
name|super
argument_list|(
name|conf
argument_list|,
name|fs
argument_list|,
name|dirName
argument_list|,
name|keyClass
argument_list|,
name|valClass
argument_list|,
name|compression
argument_list|)
expr_stmt|;
comment|// Default for mapfiles is 128.  Makes random reads faster if we
comment|// have more keys indexed and we're not 'next'-ing around in the
comment|// mapfile.
name|setIndexInterval
argument_list|(
name|conf
operator|.
name|getInt
argument_list|(
literal|"hbase.index.interval"
argument_list|,
literal|128
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|/**    * On write, all keys are added to a bloom filter.  On read, all keys are    * tested first against bloom filter. Keys are HStoreKey.  If passed bloom    * filter is null, just passes invocation to parent.    */
specifier|static
class|class
name|BloomFilterMapFile
extends|extends
name|HbaseMapFile
block|{
specifier|static
class|class
name|Reader
extends|extends
name|HbaseReader
block|{
specifier|private
specifier|final
name|Filter
name|bloomFilter
decl_stmt|;
comment|/**        * @param fs        * @param dirName        * @param conf        * @param filter        * @throws IOException        */
specifier|public
name|Reader
parameter_list|(
name|FileSystem
name|fs
parameter_list|,
name|String
name|dirName
parameter_list|,
name|Configuration
name|conf
parameter_list|,
specifier|final
name|Filter
name|filter
parameter_list|)
throws|throws
name|IOException
block|{
name|super
argument_list|(
name|fs
argument_list|,
name|dirName
argument_list|,
name|conf
argument_list|)
expr_stmt|;
name|bloomFilter
operator|=
name|filter
expr_stmt|;
block|}
comment|/** {@inheritDoc} */
annotation|@
name|Override
specifier|public
name|Writable
name|get
parameter_list|(
name|WritableComparable
name|key
parameter_list|,
name|Writable
name|val
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|bloomFilter
operator|==
literal|null
condition|)
block|{
return|return
name|super
operator|.
name|get
argument_list|(
name|key
argument_list|,
name|val
argument_list|)
return|;
block|}
if|if
condition|(
name|bloomFilter
operator|.
name|membershipTest
argument_list|(
name|getBloomFilterKey
argument_list|(
name|key
argument_list|)
argument_list|)
condition|)
block|{
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"bloom filter reported that key exists"
argument_list|)
expr_stmt|;
block|}
return|return
name|super
operator|.
name|get
argument_list|(
name|key
argument_list|,
name|val
argument_list|)
return|;
block|}
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"bloom filter reported that key does not exist"
argument_list|)
expr_stmt|;
block|}
return|return
literal|null
return|;
block|}
comment|/** {@inheritDoc} */
annotation|@
name|Override
specifier|public
name|WritableComparable
name|getClosest
parameter_list|(
name|WritableComparable
name|key
parameter_list|,
name|Writable
name|val
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|bloomFilter
operator|==
literal|null
condition|)
block|{
return|return
name|super
operator|.
name|getClosest
argument_list|(
name|key
argument_list|,
name|val
argument_list|)
return|;
block|}
comment|// Note - the key being passed to us is always a HStoreKey
if|if
condition|(
name|bloomFilter
operator|.
name|membershipTest
argument_list|(
name|getBloomFilterKey
argument_list|(
name|key
argument_list|)
argument_list|)
condition|)
block|{
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"bloom filter reported that key exists"
argument_list|)
expr_stmt|;
block|}
return|return
name|super
operator|.
name|getClosest
argument_list|(
name|key
argument_list|,
name|val
argument_list|)
return|;
block|}
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"bloom filter reported that key does not exist"
argument_list|)
expr_stmt|;
block|}
return|return
literal|null
return|;
block|}
block|}
specifier|static
class|class
name|Writer
extends|extends
name|HbaseWriter
block|{
specifier|private
specifier|final
name|Filter
name|bloomFilter
decl_stmt|;
comment|/**        * @param conf        * @param fs        * @param dirName        * @param keyClass        * @param valClass        * @param compression        * @param filter        * @throws IOException        */
annotation|@
name|SuppressWarnings
argument_list|(
literal|"unchecked"
argument_list|)
specifier|public
name|Writer
parameter_list|(
name|Configuration
name|conf
parameter_list|,
name|FileSystem
name|fs
parameter_list|,
name|String
name|dirName
parameter_list|,
name|Class
name|keyClass
parameter_list|,
name|Class
name|valClass
parameter_list|,
name|SequenceFile
operator|.
name|CompressionType
name|compression
parameter_list|,
specifier|final
name|Filter
name|filter
parameter_list|)
throws|throws
name|IOException
block|{
name|super
argument_list|(
name|conf
argument_list|,
name|fs
argument_list|,
name|dirName
argument_list|,
name|keyClass
argument_list|,
name|valClass
argument_list|,
name|compression
argument_list|)
expr_stmt|;
name|bloomFilter
operator|=
name|filter
expr_stmt|;
block|}
comment|/** {@inheritDoc} */
annotation|@
name|Override
specifier|public
name|void
name|append
parameter_list|(
name|WritableComparable
name|key
parameter_list|,
name|Writable
name|val
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|bloomFilter
operator|!=
literal|null
condition|)
block|{
name|bloomFilter
operator|.
name|add
argument_list|(
name|getBloomFilterKey
argument_list|(
name|key
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|super
operator|.
name|append
argument_list|(
name|key
argument_list|,
name|val
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|/**    * A facade for a {@link MapFile.Reader} that serves up either the top or    * bottom half of a MapFile (where 'bottom' is the first half of the file    * containing the keys that sort lowest and 'top' is the second half of the    * file with keys that sort greater than those of the bottom half).    * Subclasses BloomFilterMapFile.Reader in case     *     *<p>This file is not splitable.  Calls to {@link #midKey()} return null.    */
specifier|static
class|class
name|HalfMapFileReader
extends|extends
name|BloomFilterMapFile
operator|.
name|Reader
block|{
specifier|private
specifier|final
name|boolean
name|top
decl_stmt|;
specifier|private
specifier|final
name|WritableComparable
name|midkey
decl_stmt|;
specifier|private
name|boolean
name|firstNextCall
init|=
literal|true
decl_stmt|;
name|HalfMapFileReader
parameter_list|(
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|String
name|dirName
parameter_list|,
specifier|final
name|Configuration
name|conf
parameter_list|,
specifier|final
name|Range
name|r
parameter_list|,
specifier|final
name|WritableComparable
name|midKey
parameter_list|)
throws|throws
name|IOException
block|{
name|this
argument_list|(
name|fs
argument_list|,
name|dirName
argument_list|,
name|conf
argument_list|,
name|r
argument_list|,
name|midKey
argument_list|,
literal|null
argument_list|)
expr_stmt|;
block|}
name|HalfMapFileReader
parameter_list|(
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|String
name|dirName
parameter_list|,
specifier|final
name|Configuration
name|conf
parameter_list|,
specifier|final
name|Range
name|r
parameter_list|,
specifier|final
name|WritableComparable
name|midKey
parameter_list|,
specifier|final
name|Filter
name|filter
parameter_list|)
throws|throws
name|IOException
block|{
name|super
argument_list|(
name|fs
argument_list|,
name|dirName
argument_list|,
name|conf
argument_list|,
name|filter
argument_list|)
expr_stmt|;
name|top
operator|=
name|isTopFileRegion
argument_list|(
name|r
argument_list|)
expr_stmt|;
name|midkey
operator|=
name|midKey
expr_stmt|;
block|}
annotation|@
name|SuppressWarnings
argument_list|(
literal|"unchecked"
argument_list|)
specifier|private
name|void
name|checkKey
parameter_list|(
specifier|final
name|WritableComparable
name|key
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|top
condition|)
block|{
if|if
condition|(
name|key
operator|.
name|compareTo
argument_list|(
name|midkey
argument_list|)
operator|<
literal|0
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Illegal Access: Key is less than midKey of "
operator|+
literal|"backing mapfile"
argument_list|)
throw|;
block|}
block|}
elseif|else
if|if
condition|(
name|key
operator|.
name|compareTo
argument_list|(
name|midkey
argument_list|)
operator|>=
literal|0
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Illegal Access: Key is greater than or equal "
operator|+
literal|"to midKey of backing mapfile"
argument_list|)
throw|;
block|}
block|}
comment|/** {@inheritDoc} */
annotation|@
name|Override
specifier|public
specifier|synchronized
name|void
name|finalKey
parameter_list|(
name|WritableComparable
name|key
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|top
condition|)
block|{
name|checkKey
argument_list|(
name|key
argument_list|)
expr_stmt|;
name|super
operator|.
name|finalKey
argument_list|(
name|key
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|reset
argument_list|()
expr_stmt|;
name|Writable
name|value
init|=
operator|new
name|ImmutableBytesWritable
argument_list|()
decl_stmt|;
name|key
operator|=
name|super
operator|.
name|getClosest
argument_list|(
name|midkey
argument_list|,
name|value
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
block|}
comment|/** {@inheritDoc} */
annotation|@
name|Override
specifier|public
specifier|synchronized
name|Writable
name|get
parameter_list|(
name|WritableComparable
name|key
parameter_list|,
name|Writable
name|val
parameter_list|)
throws|throws
name|IOException
block|{
name|checkKey
argument_list|(
name|key
argument_list|)
expr_stmt|;
return|return
name|super
operator|.
name|get
argument_list|(
name|key
argument_list|,
name|val
argument_list|)
return|;
block|}
comment|/** {@inheritDoc} */
annotation|@
name|SuppressWarnings
argument_list|(
literal|"unchecked"
argument_list|)
annotation|@
name|Override
specifier|public
specifier|synchronized
name|WritableComparable
name|getClosest
parameter_list|(
name|WritableComparable
name|key
parameter_list|,
name|Writable
name|val
parameter_list|)
throws|throws
name|IOException
block|{
name|WritableComparable
name|closest
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|top
condition|)
block|{
comment|// If top, the lowest possible key is midkey.  Do not have to check
comment|// what comes back from super getClosest.  Will return exact match or
comment|// greater.
name|closest
operator|=
operator|(
name|key
operator|.
name|compareTo
argument_list|(
name|this
operator|.
name|midkey
argument_list|)
operator|<
literal|0
operator|)
condition|?
name|this
operator|.
name|midkey
else|:
name|super
operator|.
name|getClosest
argument_list|(
name|key
argument_list|,
name|val
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// We're serving bottom of the file.
if|if
condition|(
name|key
operator|.
name|compareTo
argument_list|(
name|this
operator|.
name|midkey
argument_list|)
operator|<
literal|0
condition|)
block|{
comment|// Check key is within range for bottom.
name|closest
operator|=
name|super
operator|.
name|getClosest
argument_list|(
name|key
argument_list|,
name|val
argument_list|)
expr_stmt|;
comment|// midkey was made against largest store file at time of split. Smaller
comment|// store files could have anything in them.  Check return value is
comment|// not beyond the midkey (getClosest returns exact match or next
comment|// after).
if|if
condition|(
name|closest
operator|!=
literal|null
operator|&&
name|closest
operator|.
name|compareTo
argument_list|(
name|this
operator|.
name|midkey
argument_list|)
operator|>=
literal|0
condition|)
block|{
comment|// Don't let this value out.
name|closest
operator|=
literal|null
expr_stmt|;
block|}
block|}
comment|// Else, key is> midkey so let out closest = null.
block|}
return|return
name|closest
return|;
block|}
comment|/** {@inheritDoc} */
annotation|@
name|SuppressWarnings
argument_list|(
literal|"unused"
argument_list|)
annotation|@
name|Override
specifier|public
specifier|synchronized
name|WritableComparable
name|midKey
parameter_list|()
throws|throws
name|IOException
block|{
comment|// Returns null to indicate file is not splitable.
return|return
literal|null
return|;
block|}
comment|/** {@inheritDoc} */
annotation|@
name|SuppressWarnings
argument_list|(
literal|"unchecked"
argument_list|)
annotation|@
name|Override
specifier|public
specifier|synchronized
name|boolean
name|next
parameter_list|(
name|WritableComparable
name|key
parameter_list|,
name|Writable
name|val
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|firstNextCall
condition|)
block|{
name|firstNextCall
operator|=
literal|false
expr_stmt|;
if|if
condition|(
name|this
operator|.
name|top
condition|)
block|{
comment|// Seek to midkey.  Midkey may not exist in this file.  That should be
comment|// fine.  Then we'll either be positioned at end or start of file.
name|WritableComparable
name|nearest
init|=
name|getClosest
argument_list|(
name|midkey
argument_list|,
name|val
argument_list|)
decl_stmt|;
comment|// Now copy the mid key into the passed key.
if|if
condition|(
name|nearest
operator|!=
literal|null
condition|)
block|{
name|Writables
operator|.
name|copyWritable
argument_list|(
name|nearest
argument_list|,
name|key
argument_list|)
expr_stmt|;
return|return
literal|true
return|;
block|}
return|return
literal|false
return|;
block|}
block|}
name|boolean
name|result
init|=
name|super
operator|.
name|next
argument_list|(
name|key
argument_list|,
name|val
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|top
operator|&&
name|key
operator|.
name|compareTo
argument_list|(
name|midkey
argument_list|)
operator|>=
literal|0
condition|)
block|{
name|result
operator|=
literal|false
expr_stmt|;
block|}
return|return
name|result
return|;
block|}
comment|/** {@inheritDoc} */
annotation|@
name|Override
specifier|public
specifier|synchronized
name|void
name|reset
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|top
condition|)
block|{
name|firstNextCall
operator|=
literal|true
expr_stmt|;
name|seek
argument_list|(
name|midkey
argument_list|)
expr_stmt|;
return|return;
block|}
name|super
operator|.
name|reset
argument_list|()
expr_stmt|;
block|}
comment|/** {@inheritDoc} */
annotation|@
name|Override
specifier|public
specifier|synchronized
name|boolean
name|seek
parameter_list|(
name|WritableComparable
name|key
parameter_list|)
throws|throws
name|IOException
block|{
name|checkKey
argument_list|(
name|key
argument_list|)
expr_stmt|;
return|return
name|super
operator|.
name|seek
argument_list|(
name|key
argument_list|)
return|;
block|}
block|}
block|}
end_class

end_unit

