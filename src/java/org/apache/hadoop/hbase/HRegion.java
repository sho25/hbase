begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Copyright 2007 The Apache Software Foundation  *  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Iterator
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Random
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|SortedMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|TreeMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|TreeSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Vector
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
operator|.
name|Entry
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|atomic
operator|.
name|AtomicBoolean
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|atomic
operator|.
name|AtomicInteger
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|atomic
operator|.
name|AtomicLong
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|locks
operator|.
name|ReentrantReadWriteLock
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|Log
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|LogFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|filter
operator|.
name|RowFilterInterface
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|BatchOperation
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|BatchUpdate
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|Writables
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|Text
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|StringUtils
import|;
end_import

begin_comment
comment|/**  * HRegion stores data for a certain region of a table.  It stores all columns  * for each row. A given table consists of one or more HRegions.  *  *<p>We maintain multiple HStores for a single HRegion.  *   *<p>An HStore is a set of rows with some column data; together,  * they make up all the data for the rows.    *  *<p>Each HRegion has a 'startKey' and 'endKey'.  *     *<p>The first is inclusive, the second is exclusive (except for  * the final region)  The endKey of region 0 is the same as  * startKey for region 1 (if it exists).  The startKey for the  * first region is null. The endKey for the final region is null.  *  *<p>Locking at the HRegion level serves only one purpose: preventing the  * region from being closed (and consequently split) while other operations  * are ongoing. Each row level operation obtains both a row lock and a region  * read lock for the duration of the operation. While a scanner is being  * constructed, getScanner holds a read lock. If the scanner is successfully  * constructed, it holds a read lock until it is closed. A close takes out a  * write lock and consequently will block for ongoing operations and will block  * new operations from starting while the close is in progress.  *   *<p>An HRegion is defined by its table and its key extent.  *   *<p>It consists of at least one HStore.  The number of HStores should be   * configurable, so that data which is accessed together is stored in the same  * HStore.  Right now, we approximate that by building a single HStore for   * each column family.  (This config info will be communicated via the   * tabledesc.)  *   *<p>The HTableDescriptor contains metainfo about the HRegion's table.  * regionName is a unique identifier for this HRegion. (startKey, endKey]  * defines the keyspace for this HRegion.  */
end_comment

begin_class
specifier|public
class|class
name|HRegion
implements|implements
name|HConstants
block|{
specifier|static
specifier|final
name|String
name|SPLITDIR
init|=
literal|"splits"
decl_stmt|;
specifier|static
specifier|final
name|String
name|MERGEDIR
init|=
literal|"merges"
decl_stmt|;
specifier|static
specifier|final
name|Random
name|rand
init|=
operator|new
name|Random
argument_list|()
decl_stmt|;
specifier|static
specifier|final
name|Log
name|LOG
init|=
name|LogFactory
operator|.
name|getLog
argument_list|(
name|HRegion
operator|.
name|class
argument_list|)
decl_stmt|;
specifier|final
name|AtomicBoolean
name|closed
init|=
operator|new
name|AtomicBoolean
argument_list|(
literal|false
argument_list|)
decl_stmt|;
comment|/**    * Merge two HRegions.  They must be available on the current    * HRegionServer. Returns a brand-new active HRegion, also    * running on the current HRegionServer.    */
specifier|static
name|HRegion
name|closeAndMerge
parameter_list|(
specifier|final
name|HRegion
name|srcA
parameter_list|,
specifier|final
name|HRegion
name|srcB
parameter_list|)
throws|throws
name|IOException
block|{
name|HRegion
name|a
init|=
name|srcA
decl_stmt|;
name|HRegion
name|b
init|=
name|srcB
decl_stmt|;
comment|// Make sure that srcA comes first; important for key-ordering during
comment|// write of the merged file.
name|FileSystem
name|fs
init|=
name|srcA
operator|.
name|getFilesystem
argument_list|()
decl_stmt|;
if|if
condition|(
name|srcA
operator|.
name|getStartKey
argument_list|()
operator|==
literal|null
condition|)
block|{
if|if
condition|(
name|srcB
operator|.
name|getStartKey
argument_list|()
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Cannot merge two regions with null start key"
argument_list|)
throw|;
block|}
comment|// A's start key is null but B's isn't. Assume A comes before B
block|}
elseif|else
if|if
condition|(
operator|(
name|srcB
operator|.
name|getStartKey
argument_list|()
operator|==
literal|null
operator|)
comment|// A is not null but B is
operator|||
operator|(
name|srcA
operator|.
name|getStartKey
argument_list|()
operator|.
name|compareTo
argument_list|(
name|srcB
operator|.
name|getStartKey
argument_list|()
argument_list|)
operator|>
literal|0
operator|)
condition|)
block|{
comment|// A> B
name|a
operator|=
name|srcB
expr_stmt|;
name|b
operator|=
name|srcA
expr_stmt|;
block|}
if|if
condition|(
operator|!
name|a
operator|.
name|getEndKey
argument_list|()
operator|.
name|equals
argument_list|(
name|b
operator|.
name|getStartKey
argument_list|()
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Cannot merge non-adjacent regions"
argument_list|)
throw|;
block|}
name|HBaseConfiguration
name|conf
init|=
name|a
operator|.
name|getConf
argument_list|()
decl_stmt|;
name|HTableDescriptor
name|tabledesc
init|=
name|a
operator|.
name|getTableDesc
argument_list|()
decl_stmt|;
name|HLog
name|log
init|=
name|a
operator|.
name|getLog
argument_list|()
decl_stmt|;
name|Path
name|rootDir
init|=
name|a
operator|.
name|getRootDir
argument_list|()
decl_stmt|;
name|Text
name|startKey
init|=
name|a
operator|.
name|getStartKey
argument_list|()
decl_stmt|;
name|Text
name|endKey
init|=
name|b
operator|.
name|getEndKey
argument_list|()
decl_stmt|;
name|Path
name|merges
init|=
operator|new
name|Path
argument_list|(
name|a
operator|.
name|getRegionDir
argument_list|()
argument_list|,
name|MERGEDIR
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|fs
operator|.
name|exists
argument_list|(
name|merges
argument_list|)
condition|)
block|{
name|fs
operator|.
name|mkdirs
argument_list|(
name|merges
argument_list|)
expr_stmt|;
block|}
name|HRegionInfo
name|newRegionInfo
init|=
operator|new
name|HRegionInfo
argument_list|(
name|tabledesc
argument_list|,
name|startKey
argument_list|,
name|endKey
argument_list|)
decl_stmt|;
name|Path
name|newRegionDir
init|=
name|HRegion
operator|.
name|getRegionDir
argument_list|(
name|merges
argument_list|,
name|HRegionInfo
operator|.
name|encodeRegionName
argument_list|(
name|newRegionInfo
operator|.
name|getRegionName
argument_list|()
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|fs
operator|.
name|exists
argument_list|(
name|newRegionDir
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Cannot merge; target file collision at "
operator|+
name|newRegionDir
argument_list|)
throw|;
block|}
name|LOG
operator|.
name|info
argument_list|(
literal|"starting merge of regions: "
operator|+
name|a
operator|.
name|getRegionName
argument_list|()
operator|+
literal|" and "
operator|+
name|b
operator|.
name|getRegionName
argument_list|()
operator|+
literal|" into new region "
operator|+
name|newRegionInfo
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
name|Map
argument_list|<
name|Text
argument_list|,
name|Vector
argument_list|<
name|HStoreFile
argument_list|>
argument_list|>
name|byFamily
init|=
operator|new
name|TreeMap
argument_list|<
name|Text
argument_list|,
name|Vector
argument_list|<
name|HStoreFile
argument_list|>
argument_list|>
argument_list|()
decl_stmt|;
name|byFamily
operator|=
name|filesByFamily
argument_list|(
name|byFamily
argument_list|,
name|a
operator|.
name|close
argument_list|()
argument_list|)
expr_stmt|;
name|byFamily
operator|=
name|filesByFamily
argument_list|(
name|byFamily
argument_list|,
name|b
operator|.
name|close
argument_list|()
argument_list|)
expr_stmt|;
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|Text
argument_list|,
name|Vector
argument_list|<
name|HStoreFile
argument_list|>
argument_list|>
name|es
range|:
name|byFamily
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|Text
name|colFamily
init|=
name|es
operator|.
name|getKey
argument_list|()
decl_stmt|;
name|Vector
argument_list|<
name|HStoreFile
argument_list|>
name|srcFiles
init|=
name|es
operator|.
name|getValue
argument_list|()
decl_stmt|;
name|HStoreFile
name|dst
init|=
operator|new
name|HStoreFile
argument_list|(
name|conf
argument_list|,
name|merges
argument_list|,
name|HRegionInfo
operator|.
name|encodeRegionName
argument_list|(
name|newRegionInfo
operator|.
name|getRegionName
argument_list|()
argument_list|)
argument_list|,
name|colFamily
argument_list|,
name|Math
operator|.
name|abs
argument_list|(
name|rand
operator|.
name|nextLong
argument_list|()
argument_list|)
argument_list|)
decl_stmt|;
name|dst
operator|.
name|mergeStoreFiles
argument_list|(
name|srcFiles
argument_list|,
name|fs
argument_list|,
name|conf
argument_list|)
expr_stmt|;
block|}
comment|// Done
comment|// Construction moves the merge files into place under region.
name|HRegion
name|dstRegion
init|=
operator|new
name|HRegion
argument_list|(
name|rootDir
argument_list|,
name|log
argument_list|,
name|fs
argument_list|,
name|conf
argument_list|,
name|newRegionInfo
argument_list|,
name|newRegionDir
argument_list|,
literal|null
argument_list|)
decl_stmt|;
comment|// Get rid of merges directory
name|fs
operator|.
name|delete
argument_list|(
name|merges
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"merge completed. New region is "
operator|+
name|dstRegion
operator|.
name|getRegionName
argument_list|()
argument_list|)
expr_stmt|;
return|return
name|dstRegion
return|;
block|}
comment|/*    * Fills a map with a vector of store files keyed by column family.     * @param byFamily Map to fill.    * @param storeFiles Store files to process.    * @return Returns<code>byFamily</code>    */
specifier|private
specifier|static
name|Map
argument_list|<
name|Text
argument_list|,
name|Vector
argument_list|<
name|HStoreFile
argument_list|>
argument_list|>
name|filesByFamily
parameter_list|(
name|Map
argument_list|<
name|Text
argument_list|,
name|Vector
argument_list|<
name|HStoreFile
argument_list|>
argument_list|>
name|byFamily
parameter_list|,
name|Vector
argument_list|<
name|HStoreFile
argument_list|>
name|storeFiles
parameter_list|)
block|{
for|for
control|(
name|HStoreFile
name|src
range|:
name|storeFiles
control|)
block|{
name|Vector
argument_list|<
name|HStoreFile
argument_list|>
name|v
init|=
name|byFamily
operator|.
name|get
argument_list|(
name|src
operator|.
name|getColFamily
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|v
operator|==
literal|null
condition|)
block|{
name|v
operator|=
operator|new
name|Vector
argument_list|<
name|HStoreFile
argument_list|>
argument_list|()
expr_stmt|;
name|byFamily
operator|.
name|put
argument_list|(
name|src
operator|.
name|getColFamily
argument_list|()
argument_list|,
name|v
argument_list|)
expr_stmt|;
block|}
name|v
operator|.
name|add
argument_list|(
name|src
argument_list|)
expr_stmt|;
block|}
return|return
name|byFamily
return|;
block|}
comment|//////////////////////////////////////////////////////////////////////////////
comment|// Members
comment|//////////////////////////////////////////////////////////////////////////////
specifier|volatile
name|Map
argument_list|<
name|Text
argument_list|,
name|Long
argument_list|>
name|rowsToLocks
init|=
operator|new
name|HashMap
argument_list|<
name|Text
argument_list|,
name|Long
argument_list|>
argument_list|()
decl_stmt|;
specifier|volatile
name|Map
argument_list|<
name|Long
argument_list|,
name|Text
argument_list|>
name|locksToRows
init|=
operator|new
name|HashMap
argument_list|<
name|Long
argument_list|,
name|Text
argument_list|>
argument_list|()
decl_stmt|;
specifier|volatile
name|Map
argument_list|<
name|Text
argument_list|,
name|HStore
argument_list|>
name|stores
init|=
operator|new
name|HashMap
argument_list|<
name|Text
argument_list|,
name|HStore
argument_list|>
argument_list|()
decl_stmt|;
specifier|volatile
name|Map
argument_list|<
name|Long
argument_list|,
name|TreeMap
argument_list|<
name|HStoreKey
argument_list|,
name|byte
index|[]
argument_list|>
argument_list|>
name|targetColumns
init|=
operator|new
name|HashMap
argument_list|<
name|Long
argument_list|,
name|TreeMap
argument_list|<
name|HStoreKey
argument_list|,
name|byte
index|[]
argument_list|>
argument_list|>
argument_list|()
decl_stmt|;
specifier|final
name|AtomicLong
name|memcacheSize
init|=
operator|new
name|AtomicLong
argument_list|(
literal|0
argument_list|)
decl_stmt|;
specifier|final
name|Path
name|rootDir
decl_stmt|;
specifier|final
name|HLog
name|log
decl_stmt|;
specifier|final
name|FileSystem
name|fs
decl_stmt|;
specifier|final
name|HBaseConfiguration
name|conf
decl_stmt|;
specifier|final
name|HRegionInfo
name|regionInfo
decl_stmt|;
specifier|final
name|Path
name|regiondir
decl_stmt|;
specifier|static
class|class
name|WriteState
block|{
comment|// Set while a memcache flush is happening.
specifier|volatile
name|boolean
name|flushing
init|=
literal|false
decl_stmt|;
comment|// Set while a compaction is running.
specifier|volatile
name|boolean
name|compacting
init|=
literal|false
decl_stmt|;
comment|// Gets set by last flush before close.  If set, cannot compact or flush
comment|// again.
specifier|volatile
name|boolean
name|writesEnabled
init|=
literal|true
decl_stmt|;
block|}
specifier|volatile
name|WriteState
name|writestate
init|=
operator|new
name|WriteState
argument_list|()
decl_stmt|;
specifier|final
name|int
name|memcacheFlushSize
decl_stmt|;
specifier|private
specifier|volatile
name|long
name|lastFlushTime
decl_stmt|;
specifier|final
name|CacheFlushListener
name|flushListener
decl_stmt|;
specifier|final
name|int
name|blockingMemcacheSize
decl_stmt|;
specifier|protected
specifier|final
name|long
name|threadWakeFrequency
decl_stmt|;
specifier|private
specifier|final
name|ReentrantReadWriteLock
name|lock
init|=
operator|new
name|ReentrantReadWriteLock
argument_list|()
decl_stmt|;
specifier|private
specifier|final
name|Integer
name|updateLock
init|=
operator|new
name|Integer
argument_list|(
literal|0
argument_list|)
decl_stmt|;
specifier|private
specifier|final
name|long
name|desiredMaxFileSize
decl_stmt|;
specifier|private
specifier|final
name|long
name|minSequenceId
decl_stmt|;
specifier|private
specifier|final
name|String
name|encodedRegionName
decl_stmt|;
specifier|final
name|AtomicInteger
name|activeScannerCount
init|=
operator|new
name|AtomicInteger
argument_list|(
literal|0
argument_list|)
decl_stmt|;
comment|//////////////////////////////////////////////////////////////////////////////
comment|// Constructor
comment|//////////////////////////////////////////////////////////////////////////////
comment|/**    * HRegion constructor.    *    * @param log The HLog is the outbound log for any updates to the HRegion    * (There's a single HLog for all the HRegions on a single HRegionServer.)    * The log file is a logfile from the previous execution that's    * custom-computed for this HRegion. The HRegionServer computes and sorts the    * appropriate log info for this HRegion. If there is a previous log file    * (implying that the HRegion has been written-to before), then read it from    * the supplied path.    * @param rootDir root directory for HBase instance    * @param fs is the filesystem.      * @param conf is global configuration settings.    * @param regionInfo - HRegionInfo that describes the region    * @param initialFiles If there are initial files (implying that the HRegion    * is new), then read them from the supplied path.    * @param listener an object that implements CacheFlushListener or null    *     * @throws IOException    */
specifier|public
name|HRegion
parameter_list|(
name|Path
name|rootDir
parameter_list|,
name|HLog
name|log
parameter_list|,
name|FileSystem
name|fs
parameter_list|,
name|HBaseConfiguration
name|conf
parameter_list|,
name|HRegionInfo
name|regionInfo
parameter_list|,
name|Path
name|initialFiles
parameter_list|,
name|CacheFlushListener
name|listener
parameter_list|)
throws|throws
name|IOException
block|{
name|this
operator|.
name|rootDir
operator|=
name|rootDir
expr_stmt|;
name|this
operator|.
name|log
operator|=
name|log
expr_stmt|;
name|this
operator|.
name|fs
operator|=
name|fs
expr_stmt|;
name|this
operator|.
name|conf
operator|=
name|conf
expr_stmt|;
name|this
operator|.
name|regionInfo
operator|=
name|regionInfo
expr_stmt|;
name|this
operator|.
name|encodedRegionName
operator|=
name|HRegionInfo
operator|.
name|encodeRegionName
argument_list|(
name|this
operator|.
name|regionInfo
operator|.
name|getRegionName
argument_list|()
argument_list|)
expr_stmt|;
name|this
operator|.
name|threadWakeFrequency
operator|=
name|conf
operator|.
name|getLong
argument_list|(
name|THREAD_WAKE_FREQUENCY
argument_list|,
literal|10
operator|*
literal|1000
argument_list|)
expr_stmt|;
comment|// Declare the regionName.  This is a unique string for the region, used to
comment|// build a unique filename.
name|this
operator|.
name|regiondir
operator|=
name|HRegion
operator|.
name|getRegionDir
argument_list|(
name|rootDir
argument_list|,
name|this
operator|.
name|encodedRegionName
argument_list|)
expr_stmt|;
name|Path
name|oldLogFile
init|=
operator|new
name|Path
argument_list|(
name|regiondir
argument_list|,
name|HREGION_OLDLOGFILE_NAME
argument_list|)
decl_stmt|;
comment|// Move prefab HStore files into place (if any).  This picks up split files
comment|// and any merges from splits and merges dirs.
if|if
condition|(
name|initialFiles
operator|!=
literal|null
operator|&&
name|fs
operator|.
name|exists
argument_list|(
name|initialFiles
argument_list|)
condition|)
block|{
name|fs
operator|.
name|rename
argument_list|(
name|initialFiles
argument_list|,
name|this
operator|.
name|regiondir
argument_list|)
expr_stmt|;
block|}
comment|// Load in all the HStores.
name|long
name|maxSeqId
init|=
operator|-
literal|1
decl_stmt|;
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|Text
argument_list|,
name|HColumnDescriptor
argument_list|>
name|e
range|:
name|this
operator|.
name|regionInfo
operator|.
name|getTableDesc
argument_list|()
operator|.
name|families
argument_list|()
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|Text
name|colFamily
init|=
name|HStoreKey
operator|.
name|extractFamily
argument_list|(
name|e
operator|.
name|getKey
argument_list|()
argument_list|)
decl_stmt|;
name|HStore
name|store
init|=
operator|new
name|HStore
argument_list|(
name|rootDir
argument_list|,
name|this
operator|.
name|regionInfo
operator|.
name|getRegionName
argument_list|()
argument_list|,
name|this
operator|.
name|encodedRegionName
argument_list|,
name|e
operator|.
name|getValue
argument_list|()
argument_list|,
name|fs
argument_list|,
name|oldLogFile
argument_list|,
name|conf
argument_list|)
decl_stmt|;
name|stores
operator|.
name|put
argument_list|(
name|colFamily
argument_list|,
name|store
argument_list|)
expr_stmt|;
name|long
name|storeSeqId
init|=
name|store
operator|.
name|getMaxSequenceId
argument_list|()
decl_stmt|;
if|if
condition|(
name|storeSeqId
operator|>
name|maxSeqId
condition|)
block|{
name|maxSeqId
operator|=
name|storeSeqId
expr_stmt|;
block|}
block|}
name|this
operator|.
name|minSequenceId
operator|=
name|maxSeqId
expr_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Next sequence id for region "
operator|+
name|regionInfo
operator|.
name|getRegionName
argument_list|()
operator|+
literal|" is "
operator|+
name|this
operator|.
name|minSequenceId
argument_list|)
expr_stmt|;
block|}
comment|// Get rid of any splits or merges that were lost in-progress
name|Path
name|splits
init|=
operator|new
name|Path
argument_list|(
name|regiondir
argument_list|,
name|SPLITDIR
argument_list|)
decl_stmt|;
if|if
condition|(
name|fs
operator|.
name|exists
argument_list|(
name|splits
argument_list|)
condition|)
block|{
name|fs
operator|.
name|delete
argument_list|(
name|splits
argument_list|)
expr_stmt|;
block|}
name|Path
name|merges
init|=
operator|new
name|Path
argument_list|(
name|regiondir
argument_list|,
name|MERGEDIR
argument_list|)
decl_stmt|;
if|if
condition|(
name|fs
operator|.
name|exists
argument_list|(
name|merges
argument_list|)
condition|)
block|{
name|fs
operator|.
name|delete
argument_list|(
name|merges
argument_list|)
expr_stmt|;
block|}
comment|// By default, we flush the cache when 16M.
name|this
operator|.
name|memcacheFlushSize
operator|=
name|conf
operator|.
name|getInt
argument_list|(
literal|"hbase.hregion.memcache.flush.size"
argument_list|,
literal|1024
operator|*
literal|1024
operator|*
literal|16
argument_list|)
expr_stmt|;
name|this
operator|.
name|flushListener
operator|=
name|listener
expr_stmt|;
name|this
operator|.
name|blockingMemcacheSize
operator|=
name|this
operator|.
name|memcacheFlushSize
operator|*
name|conf
operator|.
name|getInt
argument_list|(
literal|"hbase.hregion.memcache.block.multiplier"
argument_list|,
literal|2
argument_list|)
expr_stmt|;
comment|// By default we split region if a file> DEFAULT_MAX_FILE_SIZE.
name|this
operator|.
name|desiredMaxFileSize
operator|=
name|conf
operator|.
name|getLong
argument_list|(
literal|"hbase.hregion.max.filesize"
argument_list|,
name|DEFAULT_MAX_FILE_SIZE
argument_list|)
expr_stmt|;
comment|// HRegion is ready to go!
name|this
operator|.
name|writestate
operator|.
name|compacting
operator|=
literal|false
expr_stmt|;
name|this
operator|.
name|lastFlushTime
operator|=
name|System
operator|.
name|currentTimeMillis
argument_list|()
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"region "
operator|+
name|this
operator|.
name|regionInfo
operator|.
name|getRegionName
argument_list|()
operator|+
literal|" available"
argument_list|)
expr_stmt|;
block|}
comment|/**    * @return Updates to this region need to have a sequence id that is>= to    * the this number.    */
name|long
name|getMinSequenceId
parameter_list|()
block|{
return|return
name|this
operator|.
name|minSequenceId
return|;
block|}
comment|/** @return a HRegionInfo object for this region */
specifier|public
name|HRegionInfo
name|getRegionInfo
parameter_list|()
block|{
return|return
name|this
operator|.
name|regionInfo
return|;
block|}
comment|/** returns true if region is closed */
name|boolean
name|isClosed
parameter_list|()
block|{
return|return
name|this
operator|.
name|closed
operator|.
name|get
argument_list|()
return|;
block|}
comment|/**    * Close down this HRegion.  Flush the cache, shut down each HStore, don't     * service any more calls.    *    *<p>This method could take some time to execute, so don't call it from a     * time-sensitive thread.    *     * @return Vector of all the storage files that the HRegion's component     * HStores make use of.  It's a list of all HStoreFile objects. Returns empty    * vector if already closed and null if judged that it should not close.    *     * @throws IOException    */
specifier|public
name|Vector
argument_list|<
name|HStoreFile
argument_list|>
name|close
parameter_list|()
throws|throws
name|IOException
block|{
return|return
name|close
argument_list|(
literal|false
argument_list|)
return|;
block|}
comment|/**    * Close down this HRegion.  Flush the cache unless abort parameter is true,    * Shut down each HStore, don't service any more calls.    *    * This method could take some time to execute, so don't call it from a     * time-sensitive thread.    *     * @param abort true if server is aborting (only during testing)    * @return Vector of all the storage files that the HRegion's component     * HStores make use of.  It's a list of HStoreFile objects.  Can be null if    * we are not to close at this time or we are already closed.    *     * @throws IOException    */
name|Vector
argument_list|<
name|HStoreFile
argument_list|>
name|close
parameter_list|(
name|boolean
name|abort
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|isClosed
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"region "
operator|+
name|this
operator|.
name|regionInfo
operator|.
name|getRegionName
argument_list|()
operator|+
literal|" already closed"
argument_list|)
expr_stmt|;
return|return
literal|null
return|;
block|}
name|lock
operator|.
name|writeLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
synchronized|synchronized
init|(
name|writestate
init|)
block|{
while|while
condition|(
name|writestate
operator|.
name|compacting
operator|||
name|writestate
operator|.
name|flushing
condition|)
block|{
try|try
block|{
name|writestate
operator|.
name|wait
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|iex
parameter_list|)
block|{
comment|// continue
block|}
block|}
comment|// Disable compacting and flushing by background threads for this
comment|// region.
name|writestate
operator|.
name|writesEnabled
operator|=
literal|false
expr_stmt|;
block|}
comment|// Wait for active scanners to finish. The write lock we hold will prevent
comment|// new scanners from being created.
synchronized|synchronized
init|(
name|activeScannerCount
init|)
block|{
while|while
condition|(
name|activeScannerCount
operator|.
name|get
argument_list|()
operator|!=
literal|0
condition|)
block|{
try|try
block|{
name|activeScannerCount
operator|.
name|wait
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
comment|// continue
block|}
block|}
block|}
comment|// Write lock means no more row locks can be given out.  Wait on
comment|// outstanding row locks to come in before we close so we do not drop
comment|// outstanding updates.
name|waitOnRowLocks
argument_list|()
expr_stmt|;
comment|// Don't flush the cache if we are aborting
if|if
condition|(
operator|!
name|abort
condition|)
block|{
name|internalFlushcache
argument_list|(
name|snapshotMemcaches
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|Vector
argument_list|<
name|HStoreFile
argument_list|>
name|result
init|=
operator|new
name|Vector
argument_list|<
name|HStoreFile
argument_list|>
argument_list|()
decl_stmt|;
for|for
control|(
name|HStore
name|store
range|:
name|stores
operator|.
name|values
argument_list|()
control|)
block|{
name|result
operator|.
name|addAll
argument_list|(
name|store
operator|.
name|close
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|this
operator|.
name|closed
operator|.
name|set
argument_list|(
literal|true
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"closed "
operator|+
name|this
operator|.
name|regionInfo
operator|.
name|getRegionName
argument_list|()
argument_list|)
expr_stmt|;
return|return
name|result
return|;
block|}
finally|finally
block|{
name|lock
operator|.
name|writeLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
comment|//////////////////////////////////////////////////////////////////////////////
comment|// HRegion accessors
comment|//////////////////////////////////////////////////////////////////////////////
comment|/** @return start key for region */
specifier|public
name|Text
name|getStartKey
parameter_list|()
block|{
return|return
name|this
operator|.
name|regionInfo
operator|.
name|getStartKey
argument_list|()
return|;
block|}
comment|/** @return end key for region */
specifier|public
name|Text
name|getEndKey
parameter_list|()
block|{
return|return
name|this
operator|.
name|regionInfo
operator|.
name|getEndKey
argument_list|()
return|;
block|}
comment|/** @return region id */
specifier|public
name|long
name|getRegionId
parameter_list|()
block|{
return|return
name|this
operator|.
name|regionInfo
operator|.
name|getRegionId
argument_list|()
return|;
block|}
comment|/** @return region name */
specifier|public
name|Text
name|getRegionName
parameter_list|()
block|{
return|return
name|this
operator|.
name|regionInfo
operator|.
name|getRegionName
argument_list|()
return|;
block|}
comment|/** @return root directory path */
specifier|public
name|Path
name|getRootDir
parameter_list|()
block|{
return|return
name|rootDir
return|;
block|}
comment|/** @return HTableDescriptor for this region */
specifier|public
name|HTableDescriptor
name|getTableDesc
parameter_list|()
block|{
return|return
name|this
operator|.
name|regionInfo
operator|.
name|getTableDesc
argument_list|()
return|;
block|}
comment|/** @return HLog in use for this region */
specifier|public
name|HLog
name|getLog
parameter_list|()
block|{
return|return
name|this
operator|.
name|log
return|;
block|}
comment|/** @return Configuration object */
specifier|public
name|HBaseConfiguration
name|getConf
parameter_list|()
block|{
return|return
name|this
operator|.
name|conf
return|;
block|}
comment|/** @return region directory Path */
specifier|public
name|Path
name|getRegionDir
parameter_list|()
block|{
return|return
name|this
operator|.
name|regiondir
return|;
block|}
comment|/** @return FileSystem being used by this region */
specifier|public
name|FileSystem
name|getFilesystem
parameter_list|()
block|{
return|return
name|this
operator|.
name|fs
return|;
block|}
comment|/** @return the last time the region was flushed */
specifier|public
name|long
name|getLastFlushTime
parameter_list|()
block|{
return|return
name|this
operator|.
name|lastFlushTime
return|;
block|}
comment|//////////////////////////////////////////////////////////////////////////////
comment|// HRegion maintenance.
comment|//
comment|// These methods are meant to be called periodically by the HRegionServer for
comment|// upkeep.
comment|//////////////////////////////////////////////////////////////////////////////
comment|/**    * @return returns size of largest HStore.  Also returns whether store is    * splitable or not (Its not splitable if region has a store that has a    * reference store file).    */
name|HStore
operator|.
name|HStoreSize
name|largestHStore
parameter_list|(
name|Text
name|midkey
parameter_list|)
block|{
name|HStore
operator|.
name|HStoreSize
name|biggest
init|=
literal|null
decl_stmt|;
name|boolean
name|splitable
init|=
literal|true
decl_stmt|;
for|for
control|(
name|HStore
name|h
range|:
name|stores
operator|.
name|values
argument_list|()
control|)
block|{
name|HStore
operator|.
name|HStoreSize
name|size
init|=
name|h
operator|.
name|size
argument_list|(
name|midkey
argument_list|)
decl_stmt|;
comment|// If we came across a reference down in the store, then propagate
comment|// fact that region is not splitable.
if|if
condition|(
name|splitable
condition|)
block|{
name|splitable
operator|=
name|size
operator|.
name|splitable
expr_stmt|;
block|}
if|if
condition|(
name|biggest
operator|==
literal|null
condition|)
block|{
name|biggest
operator|=
name|size
expr_stmt|;
continue|continue;
block|}
if|if
condition|(
name|size
operator|.
name|getAggregate
argument_list|()
operator|>
name|biggest
operator|.
name|getAggregate
argument_list|()
condition|)
block|{
comment|// Largest so far
name|biggest
operator|=
name|size
expr_stmt|;
block|}
block|}
if|if
condition|(
name|biggest
operator|!=
literal|null
condition|)
block|{
name|biggest
operator|.
name|setSplitable
argument_list|(
name|splitable
argument_list|)
expr_stmt|;
block|}
return|return
name|biggest
return|;
block|}
comment|/*    * Split the HRegion to create two brand-new ones.  This also closes    * current HRegion.  Split should be fast since we don't rewrite store files    * but instead create new 'reference' store files that read off the top and    * bottom ranges of parent store files.    * @param listener May be null.    * @return two brand-new (and open) HRegions or null if a split is not needed    * @throws IOException    */
name|HRegion
index|[]
name|splitRegion
parameter_list|(
specifier|final
name|RegionUnavailableListener
name|listener
parameter_list|)
throws|throws
name|IOException
block|{
name|Text
name|midKey
init|=
operator|new
name|Text
argument_list|()
decl_stmt|;
if|if
condition|(
operator|!
name|needsSplit
argument_list|(
name|midKey
argument_list|)
condition|)
block|{
return|return
literal|null
return|;
block|}
name|long
name|startTime
init|=
name|System
operator|.
name|currentTimeMillis
argument_list|()
decl_stmt|;
name|Path
name|splits
init|=
name|getSplitsDir
argument_list|()
decl_stmt|;
name|HRegionInfo
name|regionAInfo
init|=
operator|new
name|HRegionInfo
argument_list|(
name|this
operator|.
name|regionInfo
operator|.
name|getTableDesc
argument_list|()
argument_list|,
name|this
operator|.
name|regionInfo
operator|.
name|getStartKey
argument_list|()
argument_list|,
name|midKey
argument_list|)
decl_stmt|;
name|Path
name|dirA
init|=
name|getSplitRegionDir
argument_list|(
name|splits
argument_list|,
name|HRegionInfo
operator|.
name|encodeRegionName
argument_list|(
name|regionAInfo
operator|.
name|getRegionName
argument_list|()
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|fs
operator|.
name|exists
argument_list|(
name|dirA
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Cannot split; target file collision at "
operator|+
name|dirA
argument_list|)
throw|;
block|}
name|HRegionInfo
name|regionBInfo
init|=
operator|new
name|HRegionInfo
argument_list|(
name|this
operator|.
name|regionInfo
operator|.
name|getTableDesc
argument_list|()
argument_list|,
name|midKey
argument_list|,
literal|null
argument_list|)
decl_stmt|;
name|Path
name|dirB
init|=
name|getSplitRegionDir
argument_list|(
name|splits
argument_list|,
name|HRegionInfo
operator|.
name|encodeRegionName
argument_list|(
name|regionBInfo
operator|.
name|getRegionName
argument_list|()
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|this
operator|.
name|fs
operator|.
name|exists
argument_list|(
name|dirB
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Cannot split; target file collision at "
operator|+
name|dirB
argument_list|)
throw|;
block|}
comment|// Notify the caller that we are about to close the region. This moves
comment|// us to the 'retiring' queue. Means no more updates coming in -- just
comment|// whatever is outstanding.
if|if
condition|(
name|listener
operator|!=
literal|null
condition|)
block|{
name|listener
operator|.
name|closing
argument_list|(
name|getRegionName
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|// Now close the HRegion.  Close returns all store files or null if not
comment|// supposed to close (? What to do in this case? Implement abort of close?)
comment|// Close also does wait on outstanding rows and calls a flush just-in-case.
name|Vector
argument_list|<
name|HStoreFile
argument_list|>
name|hstoreFilesToSplit
init|=
name|close
argument_list|()
decl_stmt|;
if|if
condition|(
name|hstoreFilesToSplit
operator|==
literal|null
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Close came back null (Implement abort of close?)"
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"close returned empty vector of HStoreFiles"
argument_list|)
throw|;
block|}
comment|// Tell listener that region is now closed and that they can therefore
comment|// clean up any outstanding references.
if|if
condition|(
name|listener
operator|!=
literal|null
condition|)
block|{
name|listener
operator|.
name|closed
argument_list|(
name|this
operator|.
name|getRegionName
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|// Split each store file.
for|for
control|(
name|HStoreFile
name|h
range|:
name|hstoreFilesToSplit
control|)
block|{
comment|// A reference to the bottom half of the hsf store file.
name|HStoreFile
operator|.
name|Reference
name|aReference
init|=
operator|new
name|HStoreFile
operator|.
name|Reference
argument_list|(
name|this
operator|.
name|encodedRegionName
argument_list|,
name|h
operator|.
name|getFileId
argument_list|()
argument_list|,
operator|new
name|HStoreKey
argument_list|(
name|midKey
argument_list|)
argument_list|,
name|HStoreFile
operator|.
name|Range
operator|.
name|bottom
argument_list|)
decl_stmt|;
name|HStoreFile
name|a
init|=
operator|new
name|HStoreFile
argument_list|(
name|this
operator|.
name|conf
argument_list|,
name|splits
argument_list|,
name|HRegionInfo
operator|.
name|encodeRegionName
argument_list|(
name|regionAInfo
operator|.
name|getRegionName
argument_list|()
argument_list|)
argument_list|,
name|h
operator|.
name|getColFamily
argument_list|()
argument_list|,
name|Math
operator|.
name|abs
argument_list|(
name|rand
operator|.
name|nextLong
argument_list|()
argument_list|)
argument_list|,
name|aReference
argument_list|)
decl_stmt|;
comment|// Reference to top half of the hsf store file.
name|HStoreFile
operator|.
name|Reference
name|bReference
init|=
operator|new
name|HStoreFile
operator|.
name|Reference
argument_list|(
name|this
operator|.
name|encodedRegionName
argument_list|,
name|h
operator|.
name|getFileId
argument_list|()
argument_list|,
operator|new
name|HStoreKey
argument_list|(
name|midKey
argument_list|)
argument_list|,
name|HStoreFile
operator|.
name|Range
operator|.
name|top
argument_list|)
decl_stmt|;
name|HStoreFile
name|b
init|=
operator|new
name|HStoreFile
argument_list|(
name|this
operator|.
name|conf
argument_list|,
name|splits
argument_list|,
name|HRegionInfo
operator|.
name|encodeRegionName
argument_list|(
name|regionBInfo
operator|.
name|getRegionName
argument_list|()
argument_list|)
argument_list|,
name|h
operator|.
name|getColFamily
argument_list|()
argument_list|,
name|Math
operator|.
name|abs
argument_list|(
name|rand
operator|.
name|nextLong
argument_list|()
argument_list|)
argument_list|,
name|bReference
argument_list|)
decl_stmt|;
name|h
operator|.
name|splitStoreFile
argument_list|(
name|a
argument_list|,
name|b
argument_list|,
name|this
operator|.
name|fs
argument_list|)
expr_stmt|;
block|}
comment|// Done!
comment|// Opening the region copies the splits files from the splits directory
comment|// under each region.
name|HRegion
name|regionA
init|=
operator|new
name|HRegion
argument_list|(
name|rootDir
argument_list|,
name|log
argument_list|,
name|fs
argument_list|,
name|conf
argument_list|,
name|regionAInfo
argument_list|,
name|dirA
argument_list|,
literal|null
argument_list|)
decl_stmt|;
name|HRegion
name|regionB
init|=
operator|new
name|HRegion
argument_list|(
name|rootDir
argument_list|,
name|log
argument_list|,
name|fs
argument_list|,
name|conf
argument_list|,
name|regionBInfo
argument_list|,
name|dirB
argument_list|,
literal|null
argument_list|)
decl_stmt|;
comment|// Cleanup
name|boolean
name|deleted
init|=
name|fs
operator|.
name|delete
argument_list|(
name|splits
argument_list|)
decl_stmt|;
comment|// Get rid of splits directory
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Cleaned up "
operator|+
name|splits
operator|.
name|toString
argument_list|()
operator|+
literal|" "
operator|+
name|deleted
argument_list|)
expr_stmt|;
block|}
name|HRegion
name|regions
index|[]
init|=
operator|new
name|HRegion
index|[]
block|{
name|regionA
block|,
name|regionB
block|}
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Region split of "
operator|+
name|this
operator|.
name|regionInfo
operator|.
name|getRegionName
argument_list|()
operator|+
literal|" complete; "
operator|+
literal|"new regions: "
operator|+
name|regions
index|[
literal|0
index|]
operator|.
name|getRegionName
argument_list|()
operator|+
literal|", "
operator|+
name|regions
index|[
literal|1
index|]
operator|.
name|getRegionName
argument_list|()
operator|+
literal|". Split took "
operator|+
name|StringUtils
operator|.
name|formatTimeDiff
argument_list|(
name|System
operator|.
name|currentTimeMillis
argument_list|()
argument_list|,
name|startTime
argument_list|)
argument_list|)
expr_stmt|;
return|return
name|regions
return|;
block|}
comment|/*    * Iterates through all the HStores and finds the one with the largest    * MapFile size. If the size is greater than the (currently hard-coded)    * threshold, returns true indicating that the region should be split. The    * midKey for the largest MapFile is returned through the midKey parameter.    * It is possible for us to rule the region non-splitable even in excess of    * configured size.  This happens if region contains a reference file.  If    * a reference file, the region can not be split.    *     * Note that there is no need to do locking in this method because it calls    * largestHStore which does the necessary locking.    *     * @param midKey midKey of the largest MapFile    * @return true if the region should be split. midKey is set by this method.    * Check it for a midKey value on return.    */
name|boolean
name|needsSplit
parameter_list|(
name|Text
name|midKey
parameter_list|)
block|{
name|HStore
operator|.
name|HStoreSize
name|biggest
init|=
name|largestHStore
argument_list|(
name|midKey
argument_list|)
decl_stmt|;
if|if
condition|(
name|biggest
operator|==
literal|null
condition|)
block|{
return|return
literal|false
return|;
block|}
name|long
name|triggerSize
init|=
name|this
operator|.
name|desiredMaxFileSize
operator|+
operator|(
name|this
operator|.
name|desiredMaxFileSize
operator|/
literal|2
operator|)
decl_stmt|;
name|boolean
name|split
init|=
operator|(
name|biggest
operator|.
name|getAggregate
argument_list|()
operator|>=
name|triggerSize
operator|)
decl_stmt|;
if|if
condition|(
name|split
condition|)
block|{
if|if
condition|(
operator|!
name|biggest
operator|.
name|isSplitable
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Region "
operator|+
name|getRegionName
argument_list|()
operator|.
name|toString
argument_list|()
operator|+
literal|" is NOT splitable though its aggregate size is "
operator|+
name|StringUtils
operator|.
name|humanReadableInt
argument_list|(
name|biggest
operator|.
name|getAggregate
argument_list|()
argument_list|)
operator|+
literal|" and desired size is "
operator|+
name|StringUtils
operator|.
name|humanReadableInt
argument_list|(
name|this
operator|.
name|desiredMaxFileSize
argument_list|)
argument_list|)
expr_stmt|;
name|split
operator|=
literal|false
expr_stmt|;
block|}
else|else
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Splitting "
operator|+
name|getRegionName
argument_list|()
operator|.
name|toString
argument_list|()
operator|+
literal|" because largest aggregate size is "
operator|+
name|StringUtils
operator|.
name|humanReadableInt
argument_list|(
name|biggest
operator|.
name|getAggregate
argument_list|()
argument_list|)
operator|+
literal|" and desired size is "
operator|+
name|StringUtils
operator|.
name|humanReadableInt
argument_list|(
name|this
operator|.
name|desiredMaxFileSize
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|split
return|;
block|}
specifier|private
name|Path
name|getSplitRegionDir
parameter_list|(
specifier|final
name|Path
name|splits
parameter_list|,
specifier|final
name|String
name|region
parameter_list|)
block|{
return|return
name|HRegion
operator|.
name|getRegionDir
argument_list|(
name|splits
argument_list|,
name|region
argument_list|)
return|;
block|}
specifier|private
name|Path
name|getSplitsDir
parameter_list|()
throws|throws
name|IOException
block|{
name|Path
name|splits
init|=
operator|new
name|Path
argument_list|(
name|this
operator|.
name|regiondir
argument_list|,
name|SPLITDIR
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|this
operator|.
name|fs
operator|.
name|exists
argument_list|(
name|splits
argument_list|)
condition|)
block|{
name|this
operator|.
name|fs
operator|.
name|mkdirs
argument_list|(
name|splits
argument_list|)
expr_stmt|;
block|}
return|return
name|splits
return|;
block|}
comment|/**    * Only do a compaction if it is necessary    *     * @return    * @throws IOException    */
name|boolean
name|compactIfNeeded
parameter_list|()
throws|throws
name|IOException
block|{
name|boolean
name|needsCompaction
init|=
literal|false
decl_stmt|;
for|for
control|(
name|HStore
name|store
range|:
name|stores
operator|.
name|values
argument_list|()
control|)
block|{
if|if
condition|(
name|store
operator|.
name|needsCompaction
argument_list|()
condition|)
block|{
name|needsCompaction
operator|=
literal|true
expr_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
name|store
operator|.
name|toString
argument_list|()
operator|+
literal|" needs compaction"
argument_list|)
expr_stmt|;
block|}
break|break;
block|}
block|}
if|if
condition|(
operator|!
name|needsCompaction
condition|)
block|{
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"region "
operator|+
name|regionInfo
operator|.
name|getRegionName
argument_list|()
operator|+
literal|" does not need compaction"
argument_list|)
expr_stmt|;
block|}
return|return
literal|false
return|;
block|}
return|return
name|compactStores
argument_list|()
return|;
block|}
comment|/**    * Compact all the stores.  This should be called periodically to make sure     * the stores are kept manageable.      *    *<p>This operation could block for a long time, so don't call it from a     * time-sensitive thread.    *    * @return Returns TRUE if the compaction has completed.  FALSE, if the    * compaction was not carried out, because the HRegion is busy doing    * something else storage-intensive (like flushing the cache). The caller    * should check back later.    *     * Note that no locking is necessary at this level because compaction only    * conflicts with a region split, and that cannot happen because the region    * server does them sequentially and not in parallel.    */
name|boolean
name|compactStores
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|this
operator|.
name|closed
operator|.
name|get
argument_list|()
condition|)
block|{
return|return
literal|false
return|;
block|}
try|try
block|{
synchronized|synchronized
init|(
name|writestate
init|)
block|{
if|if
condition|(
operator|!
name|writestate
operator|.
name|compacting
operator|&&
name|writestate
operator|.
name|writesEnabled
condition|)
block|{
name|writestate
operator|.
name|compacting
operator|=
literal|true
expr_stmt|;
block|}
else|else
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"NOT compacting region "
operator|+
name|this
operator|.
name|regionInfo
operator|.
name|getRegionName
argument_list|()
operator|.
name|toString
argument_list|()
operator|+
literal|": compacting="
operator|+
name|writestate
operator|.
name|compacting
operator|+
literal|", writesEnabled="
operator|+
name|writestate
operator|.
name|writesEnabled
argument_list|)
expr_stmt|;
return|return
literal|false
return|;
block|}
block|}
name|long
name|startTime
init|=
name|System
operator|.
name|currentTimeMillis
argument_list|()
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"starting compaction on region "
operator|+
name|this
operator|.
name|regionInfo
operator|.
name|getRegionName
argument_list|()
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
name|boolean
name|status
init|=
literal|true
decl_stmt|;
for|for
control|(
name|HStore
name|store
range|:
name|stores
operator|.
name|values
argument_list|()
control|)
block|{
if|if
condition|(
operator|!
name|store
operator|.
name|compact
argument_list|()
condition|)
block|{
name|status
operator|=
literal|false
expr_stmt|;
block|}
block|}
name|LOG
operator|.
name|info
argument_list|(
literal|"compaction completed on region "
operator|+
name|this
operator|.
name|regionInfo
operator|.
name|getRegionName
argument_list|()
operator|.
name|toString
argument_list|()
operator|+
literal|". Took "
operator|+
name|StringUtils
operator|.
name|formatTimeDiff
argument_list|(
name|System
operator|.
name|currentTimeMillis
argument_list|()
argument_list|,
name|startTime
argument_list|)
argument_list|)
expr_stmt|;
return|return
name|status
return|;
block|}
finally|finally
block|{
synchronized|synchronized
init|(
name|writestate
init|)
block|{
name|writestate
operator|.
name|compacting
operator|=
literal|false
expr_stmt|;
name|writestate
operator|.
name|notifyAll
argument_list|()
expr_stmt|;
block|}
block|}
block|}
comment|/**    * Flush the cache.    *     * When this method is called the cache will be flushed unless:    *<ol>    *<li>the cache is empty</li>    *<li>the region is closed.</li>    *<li>a flush is already in progress</li>    *<li>writes are disabled</li>    *</ol>    *    *<p>This method may block for some time, so it should not be called from a     * time-sensitive thread.    *     * @return true if cache was flushed    *     * @throws IOException    * @throws DroppedSnapshotException Thrown when replay of hlog is required    * because a Snapshot was not properly persisted.    */
name|boolean
name|flushcache
parameter_list|()
throws|throws
name|IOException
block|{
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
comment|// Prevent splits and closes
try|try
block|{
if|if
condition|(
name|this
operator|.
name|closed
operator|.
name|get
argument_list|()
condition|)
block|{
return|return
literal|false
return|;
block|}
synchronized|synchronized
init|(
name|writestate
init|)
block|{
if|if
condition|(
operator|(
operator|!
name|writestate
operator|.
name|flushing
operator|)
operator|&&
name|writestate
operator|.
name|writesEnabled
condition|)
block|{
name|writestate
operator|.
name|flushing
operator|=
literal|true
expr_stmt|;
block|}
else|else
block|{
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"NOT flushing memcache for region "
operator|+
name|this
operator|.
name|regionInfo
operator|.
name|getRegionName
argument_list|()
operator|+
literal|", flushing="
operator|+
name|writestate
operator|.
name|flushing
operator|+
literal|", writesEnabled="
operator|+
name|writestate
operator|.
name|writesEnabled
argument_list|)
expr_stmt|;
block|}
return|return
literal|false
return|;
block|}
block|}
name|long
name|startTime
init|=
operator|-
literal|1
decl_stmt|;
synchronized|synchronized
init|(
name|updateLock
init|)
block|{
comment|// Stop updates while we snapshot the memcaches
name|startTime
operator|=
name|snapshotMemcaches
argument_list|()
expr_stmt|;
block|}
try|try
block|{
return|return
name|internalFlushcache
argument_list|(
name|startTime
argument_list|)
return|;
block|}
finally|finally
block|{
synchronized|synchronized
init|(
name|writestate
init|)
block|{
name|writestate
operator|.
name|flushing
operator|=
literal|false
expr_stmt|;
name|writestate
operator|.
name|notifyAll
argument_list|()
expr_stmt|;
block|}
block|}
block|}
finally|finally
block|{
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
comment|/*    * It is assumed that updates are blocked for the duration of this method    */
specifier|private
name|long
name|snapshotMemcaches
parameter_list|()
block|{
if|if
condition|(
name|this
operator|.
name|memcacheSize
operator|.
name|get
argument_list|()
operator|==
literal|0
condition|)
block|{
return|return
operator|-
literal|1
return|;
block|}
name|long
name|startTime
init|=
name|System
operator|.
name|currentTimeMillis
argument_list|()
decl_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Started memcache flush for region "
operator|+
name|this
operator|.
name|regionInfo
operator|.
name|getRegionName
argument_list|()
operator|+
literal|". Size "
operator|+
name|StringUtils
operator|.
name|humanReadableInt
argument_list|(
name|this
operator|.
name|memcacheSize
operator|.
name|get
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|// We reset the aggregate memcache size here so that subsequent updates
comment|// will add to the unflushed size
name|this
operator|.
name|memcacheSize
operator|.
name|set
argument_list|(
literal|0L
argument_list|)
expr_stmt|;
for|for
control|(
name|HStore
name|hstore
range|:
name|stores
operator|.
name|values
argument_list|()
control|)
block|{
name|hstore
operator|.
name|snapshotMemcache
argument_list|()
expr_stmt|;
block|}
return|return
name|startTime
return|;
block|}
comment|/**    * Flushing the cache is a little tricky. We have a lot of updates in the    * HMemcache, all of which have also been written to the log. We need to    * write those updates in the HMemcache out to disk, while being able to    * process reads/writes as much as possible during the flush operation. Also,    * the log has to state clearly the point in time at which the HMemcache was    * flushed. (That way, during recovery, we know when we can rely on the    * on-disk flushed structures and when we have to recover the HMemcache from    * the log.)    *     *<p>So, we have a three-step process:    *     *<ul><li>A. Flush the memcache to the on-disk stores, noting the current    * sequence ID for the log.<li>    *     *<li>B. Write a FLUSHCACHE-COMPLETE message to the log, using the sequence    * ID that was current at the time of memcache-flush.</li>    *     *<li>C. Get rid of the memcache structures that are now redundant, as    * they've been flushed to the on-disk HStores.</li>    *</ul>    *<p>This method is protected, but can be accessed via several public    * routes.    *     *<p> This method may block for some time.    *     * @param startTime the time the cache was snapshotted or -1 if a flush is    * not needed    *     * @return true if the cache was flushed    *     * @throws IOException    * @throws DroppedSnapshotException Thrown when replay of hlog is required    * because a Snapshot was not properly persisted.    */
specifier|private
name|boolean
name|internalFlushcache
parameter_list|(
name|long
name|startTime
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|startTime
operator|==
operator|-
literal|1
condition|)
block|{
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Not flushing cache for region "
operator|+
name|regionInfo
operator|.
name|getRegionName
argument_list|()
operator|+
literal|": snapshotMemcaches() determined that there was nothing to do"
argument_list|)
expr_stmt|;
block|}
return|return
literal|false
return|;
block|}
comment|// We pass the log to the HMemcache, so we can lock down both
comment|// simultaneously.  We only have to do this for a moment: we need the
comment|// HMemcache state at the time of a known log sequence number. Since
comment|// multiple HRegions may write to a single HLog, the sequence numbers may
comment|// zoom past unless we lock it.
comment|//
comment|// When execution returns from snapshotMemcacheForLog() with a non-NULL
comment|// value, the HMemcache will have a snapshot object stored that must be
comment|// explicitly cleaned up using a call to deleteSnapshot() or by calling
comment|// abort.
comment|//
name|long
name|sequenceId
init|=
name|log
operator|.
name|startCacheFlush
argument_list|()
decl_stmt|;
comment|// Any failure from here on out will be catastrophic requiring server
comment|// restart so hlog content can be replayed and put back into the memcache.
comment|// Otherwise, the snapshot content while backed up in the hlog, it will not
comment|// be part of the current running servers state.
try|try
block|{
comment|// A.  Flush memcache to all the HStores.
comment|// Keep running vector of all store files that includes both old and the
comment|// just-made new flush store file.
for|for
control|(
name|HStore
name|hstore
range|:
name|stores
operator|.
name|values
argument_list|()
control|)
block|{
name|hstore
operator|.
name|flushCache
argument_list|(
name|sequenceId
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
comment|// An exception here means that the snapshot was not persisted.
comment|// The hlog needs to be replayed so its content is restored to memcache.
comment|// Currently, only a server restart will do this.
name|this
operator|.
name|log
operator|.
name|abortCacheFlush
argument_list|()
expr_stmt|;
throw|throw
operator|new
name|DroppedSnapshotException
argument_list|(
name|e
operator|.
name|getMessage
argument_list|()
argument_list|)
throw|;
block|}
comment|// If we get to here, the HStores have been written. If we get an
comment|// error in completeCacheFlush it will release the lock it is holding
comment|// B.  Write a FLUSHCACHE-COMPLETE message to the log.
comment|//     This tells future readers that the HStores were emitted correctly,
comment|//     and that all updates to the log for this regionName that have lower
comment|//     log-sequence-ids can be safely ignored.
name|this
operator|.
name|log
operator|.
name|completeCacheFlush
argument_list|(
name|this
operator|.
name|regionInfo
operator|.
name|getRegionName
argument_list|()
argument_list|,
name|regionInfo
operator|.
name|getTableDesc
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|,
name|sequenceId
argument_list|)
expr_stmt|;
comment|// D. Finally notify anyone waiting on memcache to clear:
comment|// e.g. checkResources().
synchronized|synchronized
init|(
name|this
init|)
block|{
name|notifyAll
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Finished memcache flush for region "
operator|+
name|this
operator|.
name|regionInfo
operator|.
name|getRegionName
argument_list|()
operator|+
literal|" in "
operator|+
operator|(
name|System
operator|.
name|currentTimeMillis
argument_list|()
operator|-
name|startTime
operator|)
operator|+
literal|"ms, sequenceid="
operator|+
name|sequenceId
argument_list|)
expr_stmt|;
block|}
return|return
literal|true
return|;
block|}
comment|//////////////////////////////////////////////////////////////////////////////
comment|// get() methods for client use.
comment|//////////////////////////////////////////////////////////////////////////////
comment|/**    * Fetch a single data item.    * @param row    * @param column    * @return column value    * @throws IOException    */
specifier|public
name|byte
index|[]
name|get
parameter_list|(
name|Text
name|row
parameter_list|,
name|Text
name|column
parameter_list|)
throws|throws
name|IOException
block|{
name|byte
index|[]
index|[]
name|results
init|=
name|get
argument_list|(
name|row
argument_list|,
name|column
argument_list|,
name|Long
operator|.
name|MAX_VALUE
argument_list|,
literal|1
argument_list|)
decl_stmt|;
return|return
operator|(
name|results
operator|==
literal|null
operator|||
name|results
operator|.
name|length
operator|==
literal|0
operator|)
condition|?
literal|null
else|:
name|results
index|[
literal|0
index|]
return|;
block|}
comment|/**    * Fetch multiple versions of a single data item    *     * @param row    * @param column    * @param numVersions    * @return array of values one element per version    * @throws IOException    */
specifier|public
name|byte
index|[]
index|[]
name|get
parameter_list|(
name|Text
name|row
parameter_list|,
name|Text
name|column
parameter_list|,
name|int
name|numVersions
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|get
argument_list|(
name|row
argument_list|,
name|column
argument_list|,
name|Long
operator|.
name|MAX_VALUE
argument_list|,
name|numVersions
argument_list|)
return|;
block|}
comment|/**    * Fetch multiple versions of a single data item, with timestamp.    *    * @param row    * @param column    * @param timestamp    * @param numVersions    * @return array of values one element per version that matches the timestamp    * @throws IOException    */
specifier|public
name|byte
index|[]
index|[]
name|get
parameter_list|(
name|Text
name|row
parameter_list|,
name|Text
name|column
parameter_list|,
name|long
name|timestamp
parameter_list|,
name|int
name|numVersions
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|this
operator|.
name|closed
operator|.
name|get
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Region "
operator|+
name|this
operator|.
name|getRegionName
argument_list|()
operator|.
name|toString
argument_list|()
operator|+
literal|" closed"
argument_list|)
throw|;
block|}
comment|// Make sure this is a valid row and valid column
name|checkRow
argument_list|(
name|row
argument_list|)
expr_stmt|;
name|checkColumn
argument_list|(
name|column
argument_list|)
expr_stmt|;
comment|// Don't need a row lock for a simple get
name|HStoreKey
name|key
init|=
operator|new
name|HStoreKey
argument_list|(
name|row
argument_list|,
name|column
argument_list|,
name|timestamp
argument_list|)
decl_stmt|;
name|HStore
name|targetStore
init|=
name|stores
operator|.
name|get
argument_list|(
name|HStoreKey
operator|.
name|extractFamily
argument_list|(
name|column
argument_list|)
argument_list|)
decl_stmt|;
return|return
name|targetStore
operator|.
name|get
argument_list|(
name|key
argument_list|,
name|numVersions
argument_list|)
return|;
block|}
comment|/**    * Fetch all the columns for the indicated row.    * Returns a TreeMap that maps column names to values.    *    * We should eventually use Bloom filters here, to reduce running time.  If     * the database has many column families and is very sparse, then we could be     * checking many files needlessly.  A small Bloom for each row would help us     * determine which column groups are useful for that row.  That would let us     * avoid a bunch of disk activity.    *    * @param row    * @return Map<columnName, byte[]> values    * @throws IOException    */
specifier|public
name|Map
argument_list|<
name|Text
argument_list|,
name|byte
index|[]
argument_list|>
name|getFull
parameter_list|(
name|Text
name|row
parameter_list|)
throws|throws
name|IOException
block|{
name|HStoreKey
name|key
init|=
operator|new
name|HStoreKey
argument_list|(
name|row
argument_list|,
name|System
operator|.
name|currentTimeMillis
argument_list|()
argument_list|)
decl_stmt|;
name|obtainRowLock
argument_list|(
name|row
argument_list|)
expr_stmt|;
try|try
block|{
name|TreeMap
argument_list|<
name|Text
argument_list|,
name|byte
index|[]
argument_list|>
name|result
init|=
operator|new
name|TreeMap
argument_list|<
name|Text
argument_list|,
name|byte
index|[]
argument_list|>
argument_list|()
decl_stmt|;
for|for
control|(
name|Text
name|colFamily
range|:
name|stores
operator|.
name|keySet
argument_list|()
control|)
block|{
name|HStore
name|targetStore
init|=
name|stores
operator|.
name|get
argument_list|(
name|colFamily
argument_list|)
decl_stmt|;
name|targetStore
operator|.
name|getFull
argument_list|(
name|key
argument_list|,
name|result
argument_list|)
expr_stmt|;
block|}
return|return
name|result
return|;
block|}
finally|finally
block|{
name|releaseRowLock
argument_list|(
name|row
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Get<code>versions</code> keys matching the origin key's    * row/column/timestamp and those of an older vintage    * Default access so can be accessed out of {@link HRegionServer}.    * @param origin Where to start searching.    * @param versions How many versions to return. Pass    * {@link HConstants.ALL_VERSIONS} to retrieve all.    * @return Ordered list of<code>versions</code> keys going from newest back.    * @throws IOException    */
specifier|private
name|List
argument_list|<
name|HStoreKey
argument_list|>
name|getKeys
parameter_list|(
specifier|final
name|HStoreKey
name|origin
parameter_list|,
specifier|final
name|int
name|versions
parameter_list|)
throws|throws
name|IOException
block|{
name|List
argument_list|<
name|HStoreKey
argument_list|>
name|keys
init|=
literal|null
decl_stmt|;
name|Text
name|colFamily
init|=
name|HStoreKey
operator|.
name|extractFamily
argument_list|(
name|origin
operator|.
name|getColumn
argument_list|()
argument_list|)
decl_stmt|;
name|HStore
name|targetStore
init|=
name|stores
operator|.
name|get
argument_list|(
name|colFamily
argument_list|)
decl_stmt|;
if|if
condition|(
name|targetStore
operator|!=
literal|null
condition|)
block|{
comment|// Pass versions without modification since in the store getKeys, it
comment|// includes the size of the passed<code>keys</code> array when counting.
name|keys
operator|=
name|targetStore
operator|.
name|getKeys
argument_list|(
name|origin
argument_list|,
name|versions
argument_list|)
expr_stmt|;
block|}
return|return
name|keys
return|;
block|}
comment|/**    * Return an iterator that scans over the HRegion, returning the indicated     * columns for only the rows that match the data filter.  This Iterator must    * be closed by the caller.    *    * @param cols columns to scan. If column name is a column family, all    * columns of the specified column family are returned.  Its also possible    * to pass a regex in the column qualifier. A column qualifier is judged to    * be a regex if it contains at least one of the following characters:    *<code>\+|^&*$[]]}{)(</code>.    * @param firstRow row which is the starting point of the scan    * @param timestamp only return rows whose timestamp is<= this value    * @param filter row filter    * @return HScannerInterface    * @throws IOException    */
specifier|public
name|HInternalScannerInterface
name|getScanner
parameter_list|(
name|Text
index|[]
name|cols
parameter_list|,
name|Text
name|firstRow
parameter_list|,
name|long
name|timestamp
parameter_list|,
name|RowFilterInterface
name|filter
parameter_list|)
throws|throws
name|IOException
block|{
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
if|if
condition|(
name|this
operator|.
name|closed
operator|.
name|get
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Region "
operator|+
name|this
operator|.
name|getRegionName
argument_list|()
operator|.
name|toString
argument_list|()
operator|+
literal|" closed"
argument_list|)
throw|;
block|}
name|TreeSet
argument_list|<
name|Text
argument_list|>
name|families
init|=
operator|new
name|TreeSet
argument_list|<
name|Text
argument_list|>
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|cols
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|families
operator|.
name|add
argument_list|(
name|HStoreKey
operator|.
name|extractFamily
argument_list|(
name|cols
index|[
name|i
index|]
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|List
argument_list|<
name|HStore
argument_list|>
name|storelist
init|=
operator|new
name|ArrayList
argument_list|<
name|HStore
argument_list|>
argument_list|()
decl_stmt|;
for|for
control|(
name|Text
name|family
range|:
name|families
control|)
block|{
name|HStore
name|s
init|=
name|stores
operator|.
name|get
argument_list|(
name|family
argument_list|)
decl_stmt|;
if|if
condition|(
name|s
operator|==
literal|null
condition|)
block|{
continue|continue;
block|}
name|storelist
operator|.
name|add
argument_list|(
name|stores
operator|.
name|get
argument_list|(
name|family
argument_list|)
argument_list|)
expr_stmt|;
block|}
return|return
operator|new
name|HScanner
argument_list|(
name|cols
argument_list|,
name|firstRow
argument_list|,
name|timestamp
argument_list|,
name|storelist
operator|.
name|toArray
argument_list|(
operator|new
name|HStore
index|[
name|storelist
operator|.
name|size
argument_list|()
index|]
argument_list|)
argument_list|,
name|filter
argument_list|)
return|;
block|}
finally|finally
block|{
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
comment|//////////////////////////////////////////////////////////////////////////////
comment|// set() methods for client use.
comment|//////////////////////////////////////////////////////////////////////////////
comment|/**    * @param timestamp    * @param b    * @throws IOException    */
specifier|public
name|void
name|batchUpdate
parameter_list|(
name|long
name|timestamp
parameter_list|,
name|BatchUpdate
name|b
parameter_list|)
throws|throws
name|IOException
block|{
comment|// Do a rough check that we have resources to accept a write.  The check is
comment|// 'rough' in that between the resource check and the call to obtain a
comment|// read lock, resources may run out.  For now, the thought is that this
comment|// will be extremely rare; we'll deal with it when it happens.
name|checkResources
argument_list|()
expr_stmt|;
comment|// We obtain a per-row lock, so other clients will block while one client
comment|// performs an update. The read lock is released by the client calling
comment|// #commit or #abort or if the HRegionServer lease on the lock expires.
comment|// See HRegionServer#RegionListener for how the expire on HRegionServer
comment|// invokes a HRegion#abort.
name|Text
name|row
init|=
name|b
operator|.
name|getRow
argument_list|()
decl_stmt|;
name|long
name|lockid
init|=
name|obtainRowLock
argument_list|(
name|row
argument_list|)
decl_stmt|;
name|long
name|commitTime
init|=
operator|(
name|timestamp
operator|==
name|LATEST_TIMESTAMP
operator|)
condition|?
name|System
operator|.
name|currentTimeMillis
argument_list|()
else|:
name|timestamp
decl_stmt|;
try|try
block|{
name|List
argument_list|<
name|Text
argument_list|>
name|deletes
init|=
literal|null
decl_stmt|;
for|for
control|(
name|BatchOperation
name|op
range|:
name|b
control|)
block|{
name|HStoreKey
name|key
init|=
operator|new
name|HStoreKey
argument_list|(
name|row
argument_list|,
name|op
operator|.
name|getColumn
argument_list|()
argument_list|,
name|commitTime
argument_list|)
decl_stmt|;
name|byte
index|[]
name|val
init|=
literal|null
decl_stmt|;
switch|switch
condition|(
name|op
operator|.
name|getOp
argument_list|()
condition|)
block|{
case|case
name|PUT
case|:
name|val
operator|=
name|op
operator|.
name|getValue
argument_list|()
expr_stmt|;
if|if
condition|(
name|HLogEdit
operator|.
name|isDeleted
argument_list|(
name|val
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Cannot insert value: "
operator|+
name|val
argument_list|)
throw|;
block|}
break|break;
case|case
name|DELETE
case|:
if|if
condition|(
name|timestamp
operator|==
name|LATEST_TIMESTAMP
condition|)
block|{
comment|// Save off these deletes
if|if
condition|(
name|deletes
operator|==
literal|null
condition|)
block|{
name|deletes
operator|=
operator|new
name|ArrayList
argument_list|<
name|Text
argument_list|>
argument_list|()
expr_stmt|;
block|}
name|deletes
operator|.
name|add
argument_list|(
name|op
operator|.
name|getColumn
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|val
operator|=
name|HLogEdit
operator|.
name|deleteBytes
operator|.
name|get
argument_list|()
expr_stmt|;
block|}
break|break;
block|}
if|if
condition|(
name|val
operator|!=
literal|null
condition|)
block|{
name|localput
argument_list|(
name|lockid
argument_list|,
name|key
argument_list|,
name|val
argument_list|)
expr_stmt|;
block|}
block|}
name|TreeMap
argument_list|<
name|HStoreKey
argument_list|,
name|byte
index|[]
argument_list|>
name|edits
init|=
name|this
operator|.
name|targetColumns
operator|.
name|remove
argument_list|(
name|Long
operator|.
name|valueOf
argument_list|(
name|lockid
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|edits
operator|!=
literal|null
operator|&&
name|edits
operator|.
name|size
argument_list|()
operator|>
literal|0
condition|)
block|{
name|update
argument_list|(
name|edits
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|deletes
operator|!=
literal|null
operator|&&
name|deletes
operator|.
name|size
argument_list|()
operator|>
literal|0
condition|)
block|{
comment|// We have some LATEST_TIMESTAMP deletes to run.
for|for
control|(
name|Text
name|column
range|:
name|deletes
control|)
block|{
name|deleteMultiple
argument_list|(
name|row
argument_list|,
name|column
argument_list|,
name|LATEST_TIMESTAMP
argument_list|,
literal|1
argument_list|)
expr_stmt|;
block|}
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|this
operator|.
name|targetColumns
operator|.
name|remove
argument_list|(
name|Long
operator|.
name|valueOf
argument_list|(
name|lockid
argument_list|)
argument_list|)
expr_stmt|;
throw|throw
name|e
throw|;
block|}
finally|finally
block|{
name|releaseRowLock
argument_list|(
name|row
argument_list|)
expr_stmt|;
block|}
block|}
comment|/*    * Check if resources to support an update.    *     * For now, just checks memcache saturation.    *     * Here we synchronize on HRegion, a broad scoped lock.  Its appropriate    * given we're figuring in here whether this region is able to take on    * writes.  This is only method with a synchronize (at time of writing),    * this and the synchronize on 'this' inside in internalFlushCache to send    * the notify.    */
specifier|private
specifier|synchronized
name|void
name|checkResources
parameter_list|()
block|{
name|boolean
name|blocked
init|=
literal|false
decl_stmt|;
while|while
condition|(
name|this
operator|.
name|memcacheSize
operator|.
name|get
argument_list|()
operator|>=
name|this
operator|.
name|blockingMemcacheSize
condition|)
block|{
if|if
condition|(
operator|!
name|blocked
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Blocking updates for '"
operator|+
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|"': Memcache size "
operator|+
name|StringUtils
operator|.
name|humanReadableInt
argument_list|(
name|this
operator|.
name|memcacheSize
operator|.
name|get
argument_list|()
argument_list|)
operator|+
literal|" is>= than blocking "
operator|+
name|StringUtils
operator|.
name|humanReadableInt
argument_list|(
name|this
operator|.
name|blockingMemcacheSize
argument_list|)
operator|+
literal|" size"
argument_list|)
expr_stmt|;
block|}
name|blocked
operator|=
literal|true
expr_stmt|;
try|try
block|{
name|wait
argument_list|(
name|threadWakeFrequency
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
comment|// continue;
block|}
block|}
if|if
condition|(
name|blocked
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Unblocking updates for region "
operator|+
name|getRegionName
argument_list|()
operator|+
literal|" '"
operator|+
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|"'"
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Delete all cells of the same age as the passed timestamp or older.    * @param row    * @param column    * @param ts Delete all entries that have this timestamp or older    * @throws IOException    */
specifier|public
name|void
name|deleteAll
parameter_list|(
specifier|final
name|Text
name|row
parameter_list|,
specifier|final
name|Text
name|column
parameter_list|,
specifier|final
name|long
name|ts
parameter_list|)
throws|throws
name|IOException
block|{
name|checkColumn
argument_list|(
name|column
argument_list|)
expr_stmt|;
name|obtainRowLock
argument_list|(
name|row
argument_list|)
expr_stmt|;
try|try
block|{
name|deleteMultiple
argument_list|(
name|row
argument_list|,
name|column
argument_list|,
name|ts
argument_list|,
name|ALL_VERSIONS
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|releaseRowLock
argument_list|(
name|row
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Delete one or many cells.    * Used to support {@link #deleteAll(Text, Text, long)} and deletion of    * latest cell.    *     * @param row    * @param column    * @param ts Timestamp to start search on.    * @param versions How many versions to delete. Pass    * {@link HConstants#ALL_VERSIONS} to delete all.    * @throws IOException    */
specifier|private
name|void
name|deleteMultiple
parameter_list|(
specifier|final
name|Text
name|row
parameter_list|,
specifier|final
name|Text
name|column
parameter_list|,
specifier|final
name|long
name|ts
parameter_list|,
specifier|final
name|int
name|versions
parameter_list|)
throws|throws
name|IOException
block|{
name|HStoreKey
name|origin
init|=
operator|new
name|HStoreKey
argument_list|(
name|row
argument_list|,
name|column
argument_list|,
name|ts
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|HStoreKey
argument_list|>
name|keys
init|=
name|getKeys
argument_list|(
name|origin
argument_list|,
name|versions
argument_list|)
decl_stmt|;
if|if
condition|(
name|keys
operator|.
name|size
argument_list|()
operator|>
literal|0
condition|)
block|{
name|TreeMap
argument_list|<
name|HStoreKey
argument_list|,
name|byte
index|[]
argument_list|>
name|edits
init|=
operator|new
name|TreeMap
argument_list|<
name|HStoreKey
argument_list|,
name|byte
index|[]
argument_list|>
argument_list|()
decl_stmt|;
for|for
control|(
name|HStoreKey
name|key
range|:
name|keys
control|)
block|{
name|edits
operator|.
name|put
argument_list|(
name|key
argument_list|,
name|HLogEdit
operator|.
name|deleteBytes
operator|.
name|get
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|update
argument_list|(
name|edits
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Private implementation.    *     * localput() is used for both puts and deletes. We just place the values    * into a per-row pending area, until a commit() or abort() call is received.    * (Or until the user's write-lock expires.)    *     * @param lockid    * @param key     * @param val Value to enter into cell    * @throws IOException    */
specifier|private
name|void
name|localput
parameter_list|(
specifier|final
name|long
name|lockid
parameter_list|,
specifier|final
name|HStoreKey
name|key
parameter_list|,
specifier|final
name|byte
index|[]
name|val
parameter_list|)
throws|throws
name|IOException
block|{
name|checkColumn
argument_list|(
name|key
operator|.
name|getColumn
argument_list|()
argument_list|)
expr_stmt|;
name|Long
name|lid
init|=
name|Long
operator|.
name|valueOf
argument_list|(
name|lockid
argument_list|)
decl_stmt|;
name|TreeMap
argument_list|<
name|HStoreKey
argument_list|,
name|byte
index|[]
argument_list|>
name|targets
init|=
name|this
operator|.
name|targetColumns
operator|.
name|get
argument_list|(
name|lid
argument_list|)
decl_stmt|;
if|if
condition|(
name|targets
operator|==
literal|null
condition|)
block|{
name|targets
operator|=
operator|new
name|TreeMap
argument_list|<
name|HStoreKey
argument_list|,
name|byte
index|[]
argument_list|>
argument_list|()
expr_stmt|;
name|this
operator|.
name|targetColumns
operator|.
name|put
argument_list|(
name|lid
argument_list|,
name|targets
argument_list|)
expr_stmt|;
block|}
name|targets
operator|.
name|put
argument_list|(
name|key
argument_list|,
name|val
argument_list|)
expr_stmt|;
block|}
comment|/*     * Add updates first to the hlog and then add values to memcache.    * Warning: Assumption is caller has lock on passed in row.    * @param row Row to update.    * @param timestamp Timestamp to record the updates against    * @param updatesByColumn Cell updates by column    * @throws IOException    */
specifier|private
name|void
name|update
parameter_list|(
specifier|final
name|TreeMap
argument_list|<
name|HStoreKey
argument_list|,
name|byte
index|[]
argument_list|>
name|updatesByColumn
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|updatesByColumn
operator|==
literal|null
operator|||
name|updatesByColumn
operator|.
name|size
argument_list|()
operator|<=
literal|0
condition|)
block|{
return|return;
block|}
synchronized|synchronized
init|(
name|updateLock
init|)
block|{
comment|// prevent a cache flush
name|this
operator|.
name|log
operator|.
name|append
argument_list|(
name|regionInfo
operator|.
name|getRegionName
argument_list|()
argument_list|,
name|regionInfo
operator|.
name|getTableDesc
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|,
name|updatesByColumn
argument_list|)
expr_stmt|;
name|long
name|memcacheSize
init|=
literal|0
decl_stmt|;
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|HStoreKey
argument_list|,
name|byte
index|[]
argument_list|>
name|e
range|:
name|updatesByColumn
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|HStoreKey
name|key
init|=
name|e
operator|.
name|getKey
argument_list|()
decl_stmt|;
name|byte
index|[]
name|val
init|=
name|e
operator|.
name|getValue
argument_list|()
decl_stmt|;
name|memcacheSize
operator|=
name|this
operator|.
name|memcacheSize
operator|.
name|addAndGet
argument_list|(
name|key
operator|.
name|getSize
argument_list|()
operator|+
operator|(
name|val
operator|==
literal|null
condition|?
literal|0
else|:
name|val
operator|.
name|length
operator|)
argument_list|)
expr_stmt|;
name|stores
operator|.
name|get
argument_list|(
name|HStoreKey
operator|.
name|extractFamily
argument_list|(
name|key
operator|.
name|getColumn
argument_list|()
argument_list|)
argument_list|)
operator|.
name|add
argument_list|(
name|key
argument_list|,
name|val
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|this
operator|.
name|flushListener
operator|!=
literal|null
operator|&&
name|memcacheSize
operator|>
name|this
operator|.
name|memcacheFlushSize
condition|)
block|{
comment|// Request a cache flush
name|this
operator|.
name|flushListener
operator|.
name|flushRequested
argument_list|(
name|this
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|//////////////////////////////////////////////////////////////////////////////
comment|// Support code
comment|//////////////////////////////////////////////////////////////////////////////
comment|/** Make sure this is a valid row for the HRegion */
specifier|private
name|void
name|checkRow
parameter_list|(
name|Text
name|row
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
operator|(
operator|(
name|regionInfo
operator|.
name|getStartKey
argument_list|()
operator|.
name|getLength
argument_list|()
operator|==
literal|0
operator|)
operator|||
operator|(
name|regionInfo
operator|.
name|getStartKey
argument_list|()
operator|.
name|compareTo
argument_list|(
name|row
argument_list|)
operator|<=
literal|0
operator|)
operator|)
operator|&&
operator|(
operator|(
name|regionInfo
operator|.
name|getEndKey
argument_list|()
operator|.
name|getLength
argument_list|()
operator|==
literal|0
operator|)
operator|||
operator|(
name|regionInfo
operator|.
name|getEndKey
argument_list|()
operator|.
name|compareTo
argument_list|(
name|row
argument_list|)
operator|>
literal|0
operator|)
operator|)
condition|)
block|{
comment|// all's well
block|}
else|else
block|{
throw|throw
operator|new
name|WrongRegionException
argument_list|(
literal|"Requested row out of range for "
operator|+
literal|"HRegion "
operator|+
name|regionInfo
operator|.
name|getRegionName
argument_list|()
operator|+
literal|", startKey='"
operator|+
name|regionInfo
operator|.
name|getStartKey
argument_list|()
operator|+
literal|"', getEndKey()='"
operator|+
name|regionInfo
operator|.
name|getEndKey
argument_list|()
operator|+
literal|"', row='"
operator|+
name|row
operator|+
literal|"'"
argument_list|)
throw|;
block|}
block|}
comment|/**    * Make sure this is a valid column for the current table    * @param columnName    * @throws IOException    */
specifier|private
name|void
name|checkColumn
parameter_list|(
name|Text
name|columnName
parameter_list|)
throws|throws
name|IOException
block|{
name|Text
name|family
init|=
operator|new
name|Text
argument_list|(
name|HStoreKey
operator|.
name|extractFamily
argument_list|(
name|columnName
argument_list|)
operator|+
literal|":"
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|regionInfo
operator|.
name|getTableDesc
argument_list|()
operator|.
name|hasFamily
argument_list|(
name|family
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Requested column family "
operator|+
name|family
operator|+
literal|" does not exist in HRegion "
operator|+
name|regionInfo
operator|.
name|getRegionName
argument_list|()
operator|+
literal|" for table "
operator|+
name|regionInfo
operator|.
name|getTableDesc
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|)
throw|;
block|}
block|}
comment|/**    * Obtain a lock on the given row.  Blocks until success.    *    * I know it's strange to have two mappings:    *<pre>    *   ROWS  ==> LOCKS    *</pre>    * as well as    *<pre>    *   LOCKS ==> ROWS    *</pre>    *    * But it acts as a guard on the client; a miswritten client just can't    * submit the name of a row and start writing to it; it must know the correct    * lockid, which matches the lock list in memory.    *     *<p>It would be more memory-efficient to assume a correctly-written client,     * which maybe we'll do in the future.    *     * @param row Name of row to lock.    * @throws IOException    * @return The id of the held lock.    */
name|long
name|obtainRowLock
parameter_list|(
name|Text
name|row
parameter_list|)
throws|throws
name|IOException
block|{
name|checkRow
argument_list|(
name|row
argument_list|)
expr_stmt|;
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
if|if
condition|(
name|this
operator|.
name|closed
operator|.
name|get
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Region "
operator|+
name|this
operator|.
name|getRegionName
argument_list|()
operator|.
name|toString
argument_list|()
operator|+
literal|" closed"
argument_list|)
throw|;
block|}
synchronized|synchronized
init|(
name|rowsToLocks
init|)
block|{
while|while
condition|(
name|rowsToLocks
operator|.
name|get
argument_list|(
name|row
argument_list|)
operator|!=
literal|null
condition|)
block|{
try|try
block|{
name|rowsToLocks
operator|.
name|wait
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|ie
parameter_list|)
block|{
comment|// Empty
block|}
block|}
name|Long
name|lid
init|=
name|Long
operator|.
name|valueOf
argument_list|(
name|Math
operator|.
name|abs
argument_list|(
name|rand
operator|.
name|nextLong
argument_list|()
argument_list|)
argument_list|)
decl_stmt|;
name|rowsToLocks
operator|.
name|put
argument_list|(
name|row
argument_list|,
name|lid
argument_list|)
expr_stmt|;
name|locksToRows
operator|.
name|put
argument_list|(
name|lid
argument_list|,
name|row
argument_list|)
expr_stmt|;
name|rowsToLocks
operator|.
name|notifyAll
argument_list|()
expr_stmt|;
return|return
name|lid
operator|.
name|longValue
argument_list|()
return|;
block|}
block|}
finally|finally
block|{
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
name|Text
name|getRowFromLock
parameter_list|(
name|long
name|lockid
parameter_list|)
block|{
comment|// Pattern is that all access to rowsToLocks and/or to
comment|// locksToRows is via a lock on rowsToLocks.
synchronized|synchronized
init|(
name|rowsToLocks
init|)
block|{
return|return
name|locksToRows
operator|.
name|get
argument_list|(
name|Long
operator|.
name|valueOf
argument_list|(
name|lockid
argument_list|)
argument_list|)
return|;
block|}
block|}
comment|/**     * Release the row lock!    * @param row Name of row whose lock we are to release    */
name|void
name|releaseRowLock
parameter_list|(
name|Text
name|row
parameter_list|)
block|{
synchronized|synchronized
init|(
name|rowsToLocks
init|)
block|{
name|long
name|lockid
init|=
name|rowsToLocks
operator|.
name|remove
argument_list|(
name|row
argument_list|)
operator|.
name|longValue
argument_list|()
decl_stmt|;
name|locksToRows
operator|.
name|remove
argument_list|(
name|Long
operator|.
name|valueOf
argument_list|(
name|lockid
argument_list|)
argument_list|)
expr_stmt|;
name|rowsToLocks
operator|.
name|notifyAll
argument_list|()
expr_stmt|;
block|}
block|}
specifier|private
name|void
name|waitOnRowLocks
parameter_list|()
block|{
synchronized|synchronized
init|(
name|rowsToLocks
init|)
block|{
while|while
condition|(
name|this
operator|.
name|rowsToLocks
operator|.
name|size
argument_list|()
operator|>
literal|0
condition|)
block|{
try|try
block|{
name|this
operator|.
name|rowsToLocks
operator|.
name|wait
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
comment|// Catch. Let while test determine loop-end.
block|}
block|}
block|}
block|}
comment|/** {@inheritDoc} */
annotation|@
name|Override
specifier|public
name|String
name|toString
parameter_list|()
block|{
return|return
name|getRegionName
argument_list|()
operator|.
name|toString
argument_list|()
return|;
block|}
comment|/**    * HScanner is an iterator through a bunch of rows in an HRegion.    */
specifier|private
class|class
name|HScanner
implements|implements
name|HInternalScannerInterface
block|{
specifier|private
name|HInternalScannerInterface
index|[]
name|scanners
decl_stmt|;
specifier|private
name|boolean
name|wildcardMatch
init|=
literal|false
decl_stmt|;
specifier|private
name|boolean
name|multipleMatchers
init|=
literal|false
decl_stmt|;
comment|/** Create an HScanner with a handle on many HStores. */
annotation|@
name|SuppressWarnings
argument_list|(
literal|"unchecked"
argument_list|)
name|HScanner
parameter_list|(
name|Text
index|[]
name|cols
parameter_list|,
name|Text
name|firstRow
parameter_list|,
name|long
name|timestamp
parameter_list|,
name|HStore
index|[]
name|stores
parameter_list|,
name|RowFilterInterface
name|filter
parameter_list|)
throws|throws
name|IOException
block|{
name|this
operator|.
name|scanners
operator|=
operator|new
name|HInternalScannerInterface
index|[
name|stores
operator|.
name|length
index|]
expr_stmt|;
comment|//       Advance to the first key in each store.
comment|//       All results will match the required column-set and scanTime.
try|try
block|{
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|stores
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|HInternalScannerInterface
name|scanner
init|=
name|scanners
index|[
name|i
index|]
operator|=
name|stores
index|[
name|i
index|]
operator|.
name|getScanner
argument_list|(
name|timestamp
argument_list|,
name|cols
argument_list|,
name|firstRow
argument_list|,
name|filter
argument_list|)
decl_stmt|;
if|if
condition|(
name|scanner
operator|.
name|isWildcardScanner
argument_list|()
condition|)
block|{
name|this
operator|.
name|wildcardMatch
operator|=
literal|true
expr_stmt|;
block|}
if|if
condition|(
name|scanner
operator|.
name|isMultipleMatchScanner
argument_list|()
condition|)
block|{
name|this
operator|.
name|multipleMatchers
operator|=
literal|true
expr_stmt|;
block|}
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|this
operator|.
name|scanners
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|scanners
index|[
name|i
index|]
operator|!=
literal|null
condition|)
block|{
name|closeScanner
argument_list|(
name|i
argument_list|)
expr_stmt|;
block|}
block|}
throw|throw
name|e
throw|;
block|}
comment|// As we have now successfully completed initialization, increment the
comment|// activeScanner count.
name|activeScannerCount
operator|.
name|incrementAndGet
argument_list|()
expr_stmt|;
block|}
comment|/** @return true if the scanner is a wild card scanner */
specifier|public
name|boolean
name|isWildcardScanner
parameter_list|()
block|{
return|return
name|wildcardMatch
return|;
block|}
comment|/** @return true if the scanner is a multiple match scanner */
specifier|public
name|boolean
name|isMultipleMatchScanner
parameter_list|()
block|{
return|return
name|multipleMatchers
return|;
block|}
comment|/** {@inheritDoc} */
specifier|public
name|boolean
name|next
parameter_list|(
name|HStoreKey
name|key
parameter_list|,
name|SortedMap
argument_list|<
name|Text
argument_list|,
name|byte
index|[]
argument_list|>
name|results
parameter_list|)
throws|throws
name|IOException
block|{
name|boolean
name|haveResults
init|=
literal|false
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|scanners
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|scanners
index|[
name|i
index|]
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
name|scanners
index|[
name|i
index|]
operator|.
name|next
argument_list|(
name|key
argument_list|,
name|results
argument_list|)
condition|)
block|{
name|haveResults
operator|=
literal|true
expr_stmt|;
block|}
else|else
block|{
name|closeScanner
argument_list|(
name|i
argument_list|)
expr_stmt|;
block|}
block|}
block|}
return|return
name|haveResults
return|;
block|}
comment|/** Shut down a single scanner */
name|void
name|closeScanner
parameter_list|(
name|int
name|i
parameter_list|)
block|{
try|try
block|{
try|try
block|{
name|scanners
index|[
name|i
index|]
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failed closeing scanner "
operator|+
name|i
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
block|}
finally|finally
block|{
name|scanners
index|[
name|i
index|]
operator|=
literal|null
expr_stmt|;
block|}
block|}
comment|/**      * {@inheritDoc}      */
specifier|public
name|void
name|close
parameter_list|()
block|{
try|try
block|{
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|scanners
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|scanners
index|[
name|i
index|]
operator|!=
literal|null
condition|)
block|{
name|closeScanner
argument_list|(
name|i
argument_list|)
expr_stmt|;
block|}
block|}
block|}
finally|finally
block|{
synchronized|synchronized
init|(
name|activeScannerCount
init|)
block|{
name|int
name|scanners
init|=
name|activeScannerCount
operator|.
name|decrementAndGet
argument_list|()
decl_stmt|;
if|if
condition|(
name|scanners
operator|<
literal|0
condition|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"active scanner count less than zero: "
operator|+
name|scanners
operator|+
literal|" resetting to zero"
argument_list|)
expr_stmt|;
name|activeScannerCount
operator|.
name|set
argument_list|(
literal|0
argument_list|)
expr_stmt|;
name|scanners
operator|=
literal|0
expr_stmt|;
block|}
if|if
condition|(
name|scanners
operator|==
literal|0
condition|)
block|{
name|activeScannerCount
operator|.
name|notifyAll
argument_list|()
expr_stmt|;
block|}
block|}
block|}
block|}
comment|/** {@inheritDoc} */
specifier|public
name|Iterator
argument_list|<
name|Entry
argument_list|<
name|HStoreKey
argument_list|,
name|SortedMap
argument_list|<
name|Text
argument_list|,
name|byte
index|[]
argument_list|>
argument_list|>
argument_list|>
name|iterator
parameter_list|()
block|{
throw|throw
operator|new
name|UnsupportedOperationException
argument_list|(
literal|"Unimplemented serverside. "
operator|+
literal|"next(HStoreKey, StortedMap(...) is more efficient"
argument_list|)
throw|;
block|}
block|}
comment|// Utility methods
comment|/**    * Convenience method creating new HRegions. Used by createTable and by the    * bootstrap code in the HMaster constructor.    * Note, this method creates an {@link HLog} for the created region. It    * needs to be closed explicitly.  Use {@link HRegion#getLog()} to get    * access.    * @param info Info for region to create.    * @param rootDir Root directory for HBase instance    * @param conf    * @param initialFiles InitialFiles to pass new HRegion. Pass null if none.    * @return new HRegion    *     * @throws IOException    */
specifier|static
name|HRegion
name|createHRegion
parameter_list|(
specifier|final
name|HRegionInfo
name|info
parameter_list|,
specifier|final
name|Path
name|rootDir
parameter_list|,
specifier|final
name|HBaseConfiguration
name|conf
parameter_list|,
specifier|final
name|Path
name|initialFiles
parameter_list|)
throws|throws
name|IOException
block|{
name|Path
name|regionDir
init|=
name|HRegion
operator|.
name|getRegionDir
argument_list|(
name|rootDir
argument_list|,
name|HRegionInfo
operator|.
name|encodeRegionName
argument_list|(
name|info
operator|.
name|getRegionName
argument_list|()
argument_list|)
argument_list|)
decl_stmt|;
name|FileSystem
name|fs
init|=
name|FileSystem
operator|.
name|get
argument_list|(
name|conf
argument_list|)
decl_stmt|;
name|fs
operator|.
name|mkdirs
argument_list|(
name|regionDir
argument_list|)
expr_stmt|;
return|return
operator|new
name|HRegion
argument_list|(
name|rootDir
argument_list|,
operator|new
name|HLog
argument_list|(
name|fs
argument_list|,
operator|new
name|Path
argument_list|(
name|regionDir
argument_list|,
name|HREGION_LOGDIR_NAME
argument_list|)
argument_list|,
name|conf
argument_list|,
literal|null
argument_list|)
argument_list|,
name|fs
argument_list|,
name|conf
argument_list|,
name|info
argument_list|,
name|initialFiles
argument_list|,
literal|null
argument_list|)
return|;
block|}
comment|/**    * Inserts a new region's meta information into the passed    *<code>meta</code> region. Used by the HMaster bootstrap code adding    * new table to ROOT table.    *     * @param meta META HRegion to be updated    * @param r HRegion to add to<code>meta</code>    *    * @throws IOException    */
specifier|static
name|void
name|addRegionToMETA
parameter_list|(
name|HRegion
name|meta
parameter_list|,
name|HRegion
name|r
parameter_list|)
throws|throws
name|IOException
block|{
name|meta
operator|.
name|checkResources
argument_list|()
expr_stmt|;
comment|// The row key is the region name
name|Text
name|row
init|=
name|r
operator|.
name|getRegionName
argument_list|()
decl_stmt|;
name|meta
operator|.
name|obtainRowLock
argument_list|(
name|row
argument_list|)
expr_stmt|;
try|try
block|{
name|HStoreKey
name|key
init|=
operator|new
name|HStoreKey
argument_list|(
name|row
argument_list|,
name|COL_REGIONINFO
argument_list|,
name|System
operator|.
name|currentTimeMillis
argument_list|()
argument_list|)
decl_stmt|;
name|TreeMap
argument_list|<
name|HStoreKey
argument_list|,
name|byte
index|[]
argument_list|>
name|edits
init|=
operator|new
name|TreeMap
argument_list|<
name|HStoreKey
argument_list|,
name|byte
index|[]
argument_list|>
argument_list|()
decl_stmt|;
name|edits
operator|.
name|put
argument_list|(
name|key
argument_list|,
name|Writables
operator|.
name|getBytes
argument_list|(
name|r
operator|.
name|getRegionInfo
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
name|meta
operator|.
name|update
argument_list|(
name|edits
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|meta
operator|.
name|releaseRowLock
argument_list|(
name|row
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Deletes all the files for a HRegion    *     * @param fs the file system object    * @param baseDirectory base directory for HBase    * @param name region file name    * @throws IOException    * @return True if deleted.    */
specifier|static
name|boolean
name|deleteRegion
parameter_list|(
name|FileSystem
name|fs
parameter_list|,
name|Path
name|baseDirectory
parameter_list|,
name|String
name|name
parameter_list|)
throws|throws
name|IOException
block|{
name|Path
name|p
init|=
name|HRegion
operator|.
name|getRegionDir
argument_list|(
name|fs
operator|.
name|makeQualified
argument_list|(
name|baseDirectory
argument_list|)
argument_list|,
name|name
argument_list|)
decl_stmt|;
return|return
name|fs
operator|.
name|delete
argument_list|(
name|p
argument_list|)
return|;
block|}
comment|/**    * Computes the Path of the HRegion    *     * @param dir hbase home directory    * @param name region file name    * @return Path of HRegion directory    */
specifier|public
specifier|static
name|Path
name|getRegionDir
parameter_list|(
specifier|final
name|Path
name|dir
parameter_list|,
specifier|final
name|String
name|name
parameter_list|)
block|{
return|return
operator|new
name|Path
argument_list|(
name|dir
argument_list|,
operator|new
name|Path
argument_list|(
name|HREGIONDIR_PREFIX
operator|+
name|name
argument_list|)
argument_list|)
return|;
block|}
block|}
end_class

end_unit

