begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Copyright 2007 The Apache Software Foundation  *  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Iterator
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Random
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|SortedMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|TreeMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|TreeSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Vector
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
operator|.
name|Entry
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|atomic
operator|.
name|AtomicBoolean
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|Log
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|LogFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|filter
operator|.
name|RowFilterInterface
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|Writables
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|Text
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|StringUtils
import|;
end_import

begin_comment
comment|/**  * HRegion stores data for a certain region of a table.  It stores all columns  * for each row. A given table consists of one or more HRegions.  *  *<p>We maintain multiple HStores for a single HRegion.  *   *<p>An HStore is a set of rows with some column data; together,  * they make up all the data for the rows.    *  *<p>Each HRegion has a 'startKey' and 'endKey'.  *     *<p>The first is inclusive, the second is exclusive (except for  * the final region)  The endKey of region 0 is the same as  * startKey for region 1 (if it exists).  The startKey for the  * first region is null. The endKey for the final region is null.  *  *<p>The HStores have no locking built-in.  All row-level locking  * and row-level atomicity is provided by the HRegion.  *   *<p>An HRegion is defined by its table and its key extent.  *   *<p>It consists of at least one HStore.  The number of HStores should be   * configurable, so that data which is accessed together is stored in the same  * HStore.  Right now, we approximate that by building a single HStore for   * each column family.  (This config info will be communicated via the   * tabledesc.)  *   *<p>The HTableDescriptor contains metainfo about the HRegion's table.  * regionName is a unique identifier for this HRegion. (startKey, endKey]  * defines the keyspace for this HRegion.  */
end_comment

begin_class
specifier|public
class|class
name|HRegion
implements|implements
name|HConstants
block|{
specifier|static
name|String
name|SPLITDIR
init|=
literal|"splits"
decl_stmt|;
specifier|static
name|String
name|MERGEDIR
init|=
literal|"merges"
decl_stmt|;
specifier|static
specifier|final
name|Random
name|rand
init|=
operator|new
name|Random
argument_list|()
decl_stmt|;
specifier|static
specifier|final
name|Log
name|LOG
init|=
name|LogFactory
operator|.
name|getLog
argument_list|(
name|HRegion
operator|.
name|class
argument_list|)
decl_stmt|;
specifier|final
name|AtomicBoolean
name|closed
init|=
operator|new
name|AtomicBoolean
argument_list|(
literal|false
argument_list|)
decl_stmt|;
specifier|private
name|long
name|noFlushCount
init|=
literal|0
decl_stmt|;
comment|/**    * Merge two HRegions.  They must be available on the current    * HRegionServer. Returns a brand-new active HRegion, also    * running on the current HRegionServer.    */
specifier|static
name|HRegion
name|closeAndMerge
parameter_list|(
specifier|final
name|HRegion
name|srcA
parameter_list|,
specifier|final
name|HRegion
name|srcB
parameter_list|)
throws|throws
name|IOException
block|{
name|HRegion
name|a
init|=
name|srcA
decl_stmt|;
name|HRegion
name|b
init|=
name|srcB
decl_stmt|;
comment|// Make sure that srcA comes first; important for key-ordering during
comment|// write of the merged file.
name|FileSystem
name|fs
init|=
name|srcA
operator|.
name|getFilesystem
argument_list|()
decl_stmt|;
if|if
condition|(
name|srcA
operator|.
name|getStartKey
argument_list|()
operator|==
literal|null
condition|)
block|{
if|if
condition|(
name|srcB
operator|.
name|getStartKey
argument_list|()
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Cannot merge two regions with null start key"
argument_list|)
throw|;
block|}
comment|// A's start key is null but B's isn't. Assume A comes before B
block|}
elseif|else
if|if
condition|(
operator|(
name|srcB
operator|.
name|getStartKey
argument_list|()
operator|==
literal|null
operator|)
comment|// A is not null but B is
operator|||
operator|(
name|srcA
operator|.
name|getStartKey
argument_list|()
operator|.
name|compareTo
argument_list|(
name|srcB
operator|.
name|getStartKey
argument_list|()
argument_list|)
operator|>
literal|0
operator|)
condition|)
block|{
comment|// A> B
name|a
operator|=
name|srcB
expr_stmt|;
name|b
operator|=
name|srcA
expr_stmt|;
block|}
if|if
condition|(
operator|!
name|a
operator|.
name|getEndKey
argument_list|()
operator|.
name|equals
argument_list|(
name|b
operator|.
name|getStartKey
argument_list|()
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Cannot merge non-adjacent regions"
argument_list|)
throw|;
block|}
name|Configuration
name|conf
init|=
name|a
operator|.
name|getConf
argument_list|()
decl_stmt|;
name|HTableDescriptor
name|tabledesc
init|=
name|a
operator|.
name|getTableDesc
argument_list|()
decl_stmt|;
name|HLog
name|log
init|=
name|a
operator|.
name|getLog
argument_list|()
decl_stmt|;
name|Path
name|rootDir
init|=
name|a
operator|.
name|getRootDir
argument_list|()
decl_stmt|;
name|Text
name|startKey
init|=
name|a
operator|.
name|getStartKey
argument_list|()
decl_stmt|;
name|Text
name|endKey
init|=
name|b
operator|.
name|getEndKey
argument_list|()
decl_stmt|;
name|Path
name|merges
init|=
operator|new
name|Path
argument_list|(
name|a
operator|.
name|getRegionDir
argument_list|()
argument_list|,
name|MERGEDIR
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|fs
operator|.
name|exists
argument_list|(
name|merges
argument_list|)
condition|)
block|{
name|fs
operator|.
name|mkdirs
argument_list|(
name|merges
argument_list|)
expr_stmt|;
block|}
name|HRegionInfo
name|newRegionInfo
init|=
operator|new
name|HRegionInfo
argument_list|(
name|tabledesc
argument_list|,
name|startKey
argument_list|,
name|endKey
argument_list|)
decl_stmt|;
name|Path
name|newRegionDir
init|=
name|HRegion
operator|.
name|getRegionDir
argument_list|(
name|merges
argument_list|,
name|HRegionInfo
operator|.
name|encodeRegionName
argument_list|(
name|newRegionInfo
operator|.
name|getRegionName
argument_list|()
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|fs
operator|.
name|exists
argument_list|(
name|newRegionDir
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Cannot merge; target file collision at "
operator|+
name|newRegionDir
argument_list|)
throw|;
block|}
name|LOG
operator|.
name|info
argument_list|(
literal|"starting merge of regions: "
operator|+
name|a
operator|.
name|getRegionName
argument_list|()
operator|+
literal|" and "
operator|+
name|b
operator|.
name|getRegionName
argument_list|()
operator|+
literal|" into new region "
operator|+
name|newRegionInfo
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
name|Map
argument_list|<
name|Text
argument_list|,
name|Vector
argument_list|<
name|HStoreFile
argument_list|>
argument_list|>
name|byFamily
init|=
operator|new
name|TreeMap
argument_list|<
name|Text
argument_list|,
name|Vector
argument_list|<
name|HStoreFile
argument_list|>
argument_list|>
argument_list|()
decl_stmt|;
name|byFamily
operator|=
name|filesByFamily
argument_list|(
name|byFamily
argument_list|,
name|a
operator|.
name|close
argument_list|()
argument_list|)
expr_stmt|;
name|byFamily
operator|=
name|filesByFamily
argument_list|(
name|byFamily
argument_list|,
name|b
operator|.
name|close
argument_list|()
argument_list|)
expr_stmt|;
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|Text
argument_list|,
name|Vector
argument_list|<
name|HStoreFile
argument_list|>
argument_list|>
name|es
range|:
name|byFamily
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|Text
name|colFamily
init|=
name|es
operator|.
name|getKey
argument_list|()
decl_stmt|;
name|Vector
argument_list|<
name|HStoreFile
argument_list|>
name|srcFiles
init|=
name|es
operator|.
name|getValue
argument_list|()
decl_stmt|;
name|HStoreFile
name|dst
init|=
operator|new
name|HStoreFile
argument_list|(
name|conf
argument_list|,
name|merges
argument_list|,
name|HRegionInfo
operator|.
name|encodeRegionName
argument_list|(
name|newRegionInfo
operator|.
name|getRegionName
argument_list|()
argument_list|)
argument_list|,
name|colFamily
argument_list|,
name|Math
operator|.
name|abs
argument_list|(
name|rand
operator|.
name|nextLong
argument_list|()
argument_list|)
argument_list|)
decl_stmt|;
name|dst
operator|.
name|mergeStoreFiles
argument_list|(
name|srcFiles
argument_list|,
name|fs
argument_list|,
name|conf
argument_list|)
expr_stmt|;
block|}
comment|// Done
comment|// Construction moves the merge files into place under region.
name|HRegion
name|dstRegion
init|=
operator|new
name|HRegion
argument_list|(
name|rootDir
argument_list|,
name|log
argument_list|,
name|fs
argument_list|,
name|conf
argument_list|,
name|newRegionInfo
argument_list|,
name|newRegionDir
argument_list|)
decl_stmt|;
comment|// Get rid of merges directory
name|fs
operator|.
name|delete
argument_list|(
name|merges
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"merge completed. New region is "
operator|+
name|dstRegion
operator|.
name|getRegionName
argument_list|()
argument_list|)
expr_stmt|;
return|return
name|dstRegion
return|;
block|}
comment|/*    * Fills a map with a vector of store files keyed by column family.     * @param byFamily Map to fill.    * @param storeFiles Store files to process.    * @return Returns<code>byFamily</code>    */
specifier|private
specifier|static
name|Map
argument_list|<
name|Text
argument_list|,
name|Vector
argument_list|<
name|HStoreFile
argument_list|>
argument_list|>
name|filesByFamily
parameter_list|(
name|Map
argument_list|<
name|Text
argument_list|,
name|Vector
argument_list|<
name|HStoreFile
argument_list|>
argument_list|>
name|byFamily
parameter_list|,
name|Vector
argument_list|<
name|HStoreFile
argument_list|>
name|storeFiles
parameter_list|)
block|{
for|for
control|(
name|HStoreFile
name|src
range|:
name|storeFiles
control|)
block|{
name|Vector
argument_list|<
name|HStoreFile
argument_list|>
name|v
init|=
name|byFamily
operator|.
name|get
argument_list|(
name|src
operator|.
name|getColFamily
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|v
operator|==
literal|null
condition|)
block|{
name|v
operator|=
operator|new
name|Vector
argument_list|<
name|HStoreFile
argument_list|>
argument_list|()
expr_stmt|;
name|byFamily
operator|.
name|put
argument_list|(
name|src
operator|.
name|getColFamily
argument_list|()
argument_list|,
name|v
argument_list|)
expr_stmt|;
block|}
name|v
operator|.
name|add
argument_list|(
name|src
argument_list|)
expr_stmt|;
block|}
return|return
name|byFamily
return|;
block|}
comment|//////////////////////////////////////////////////////////////////////////////
comment|// Members
comment|//////////////////////////////////////////////////////////////////////////////
name|Map
argument_list|<
name|Text
argument_list|,
name|Long
argument_list|>
name|rowsToLocks
init|=
operator|new
name|HashMap
argument_list|<
name|Text
argument_list|,
name|Long
argument_list|>
argument_list|()
decl_stmt|;
name|Map
argument_list|<
name|Long
argument_list|,
name|Text
argument_list|>
name|locksToRows
init|=
operator|new
name|HashMap
argument_list|<
name|Long
argument_list|,
name|Text
argument_list|>
argument_list|()
decl_stmt|;
name|Map
argument_list|<
name|Text
argument_list|,
name|HStore
argument_list|>
name|stores
init|=
operator|new
name|HashMap
argument_list|<
name|Text
argument_list|,
name|HStore
argument_list|>
argument_list|()
decl_stmt|;
name|Map
argument_list|<
name|Long
argument_list|,
name|TreeMap
argument_list|<
name|Text
argument_list|,
name|byte
index|[]
argument_list|>
argument_list|>
name|targetColumns
init|=
operator|new
name|HashMap
argument_list|<
name|Long
argument_list|,
name|TreeMap
argument_list|<
name|Text
argument_list|,
name|byte
index|[]
argument_list|>
argument_list|>
argument_list|()
decl_stmt|;
specifier|final
name|HMemcache
name|memcache
decl_stmt|;
name|Path
name|rootDir
decl_stmt|;
name|HLog
name|log
decl_stmt|;
name|FileSystem
name|fs
decl_stmt|;
name|Configuration
name|conf
decl_stmt|;
name|HRegionInfo
name|regionInfo
decl_stmt|;
name|Path
name|regiondir
decl_stmt|;
specifier|static
class|class
name|WriteState
block|{
comment|// Set while a memcache flush is happening.
specifier|volatile
name|boolean
name|flushing
init|=
literal|false
decl_stmt|;
comment|// Set while a compaction is running.
specifier|volatile
name|boolean
name|compacting
init|=
literal|false
decl_stmt|;
comment|// Gets set by last flush before close.  If set, cannot compact or flush
comment|// again.
specifier|volatile
name|boolean
name|writesEnabled
init|=
literal|true
decl_stmt|;
block|}
specifier|volatile
name|WriteState
name|writestate
init|=
operator|new
name|WriteState
argument_list|()
decl_stmt|;
specifier|final
name|int
name|memcacheFlushSize
decl_stmt|;
specifier|final
name|int
name|blockingMemcacheSize
decl_stmt|;
specifier|protected
specifier|final
name|long
name|threadWakeFrequency
decl_stmt|;
specifier|protected
specifier|final
name|int
name|optionalFlushCount
decl_stmt|;
specifier|private
specifier|final
name|HLocking
name|lock
init|=
operator|new
name|HLocking
argument_list|()
decl_stmt|;
specifier|private
name|long
name|desiredMaxFileSize
decl_stmt|;
specifier|private
specifier|final
name|long
name|minSequenceId
decl_stmt|;
specifier|private
specifier|final
name|String
name|encodedRegionName
decl_stmt|;
comment|//////////////////////////////////////////////////////////////////////////////
comment|// Constructor
comment|//////////////////////////////////////////////////////////////////////////////
comment|/**    * HRegion constructor.    *    * @param log The HLog is the outbound log for any updates to the HRegion    * (There's a single HLog for all the HRegions on a single HRegionServer.)    * The log file is a logfile from the previous execution that's    * custom-computed for this HRegion. The HRegionServer computes and sorts the    * appropriate log info for this HRegion. If there is a previous log file    * (implying that the HRegion has been written-to before), then read it from    * the supplied path.    * @param rootDir root directory for HBase instance    * @param fs is the filesystem.      * @param conf is global configuration settings.    * @param regionInfo - HRegionInfo that describes the region    * @param initialFiles If there are initial files (implying that the HRegion    * is new), then read them from the supplied path.    *     * @throws IOException    */
specifier|public
name|HRegion
parameter_list|(
name|Path
name|rootDir
parameter_list|,
name|HLog
name|log
parameter_list|,
name|FileSystem
name|fs
parameter_list|,
name|Configuration
name|conf
parameter_list|,
name|HRegionInfo
name|regionInfo
parameter_list|,
name|Path
name|initialFiles
parameter_list|)
throws|throws
name|IOException
block|{
name|this
operator|.
name|rootDir
operator|=
name|rootDir
expr_stmt|;
name|this
operator|.
name|log
operator|=
name|log
expr_stmt|;
name|this
operator|.
name|fs
operator|=
name|fs
expr_stmt|;
name|this
operator|.
name|conf
operator|=
name|conf
expr_stmt|;
name|this
operator|.
name|regionInfo
operator|=
name|regionInfo
expr_stmt|;
name|this
operator|.
name|encodedRegionName
operator|=
name|HRegionInfo
operator|.
name|encodeRegionName
argument_list|(
name|this
operator|.
name|regionInfo
operator|.
name|getRegionName
argument_list|()
argument_list|)
expr_stmt|;
name|this
operator|.
name|memcache
operator|=
operator|new
name|HMemcache
argument_list|()
expr_stmt|;
name|this
operator|.
name|threadWakeFrequency
operator|=
name|conf
operator|.
name|getLong
argument_list|(
name|THREAD_WAKE_FREQUENCY
argument_list|,
literal|10
operator|*
literal|1000
argument_list|)
expr_stmt|;
name|this
operator|.
name|optionalFlushCount
operator|=
name|conf
operator|.
name|getInt
argument_list|(
literal|"hbase.hregion.memcache.optionalflushcount"
argument_list|,
literal|10
argument_list|)
expr_stmt|;
comment|// Declare the regionName.  This is a unique string for the region, used to
comment|// build a unique filename.
name|this
operator|.
name|regiondir
operator|=
name|HRegion
operator|.
name|getRegionDir
argument_list|(
name|rootDir
argument_list|,
name|this
operator|.
name|encodedRegionName
argument_list|)
expr_stmt|;
name|Path
name|oldLogFile
init|=
operator|new
name|Path
argument_list|(
name|regiondir
argument_list|,
name|HREGION_OLDLOGFILE_NAME
argument_list|)
decl_stmt|;
comment|// Move prefab HStore files into place (if any).  This picks up split files
comment|// and any merges from splits and merges dirs.
if|if
condition|(
name|initialFiles
operator|!=
literal|null
operator|&&
name|fs
operator|.
name|exists
argument_list|(
name|initialFiles
argument_list|)
condition|)
block|{
name|fs
operator|.
name|rename
argument_list|(
name|initialFiles
argument_list|,
name|this
operator|.
name|regiondir
argument_list|)
expr_stmt|;
block|}
comment|// Load in all the HStores.
name|long
name|maxSeqId
init|=
operator|-
literal|1
decl_stmt|;
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|Text
argument_list|,
name|HColumnDescriptor
argument_list|>
name|e
range|:
name|this
operator|.
name|regionInfo
operator|.
name|getTableDesc
argument_list|()
operator|.
name|families
argument_list|()
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|Text
name|colFamily
init|=
name|HStoreKey
operator|.
name|extractFamily
argument_list|(
name|e
operator|.
name|getKey
argument_list|()
argument_list|)
decl_stmt|;
name|HStore
name|store
init|=
operator|new
name|HStore
argument_list|(
name|rootDir
argument_list|,
name|this
operator|.
name|regionInfo
operator|.
name|getRegionName
argument_list|()
argument_list|,
name|this
operator|.
name|encodedRegionName
argument_list|,
name|e
operator|.
name|getValue
argument_list|()
argument_list|,
name|fs
argument_list|,
name|oldLogFile
argument_list|,
name|conf
argument_list|)
decl_stmt|;
name|stores
operator|.
name|put
argument_list|(
name|colFamily
argument_list|,
name|store
argument_list|)
expr_stmt|;
name|long
name|storeSeqId
init|=
name|store
operator|.
name|getMaxSequenceId
argument_list|()
decl_stmt|;
if|if
condition|(
name|storeSeqId
operator|>
name|maxSeqId
condition|)
block|{
name|maxSeqId
operator|=
name|storeSeqId
expr_stmt|;
block|}
block|}
name|this
operator|.
name|minSequenceId
operator|=
name|maxSeqId
expr_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Next sequence id for region "
operator|+
name|regionInfo
operator|.
name|getRegionName
argument_list|()
operator|+
literal|" is "
operator|+
name|this
operator|.
name|minSequenceId
argument_list|)
expr_stmt|;
block|}
comment|// Get rid of any splits or merges that were lost in-progress
name|Path
name|splits
init|=
operator|new
name|Path
argument_list|(
name|regiondir
argument_list|,
name|SPLITDIR
argument_list|)
decl_stmt|;
if|if
condition|(
name|fs
operator|.
name|exists
argument_list|(
name|splits
argument_list|)
condition|)
block|{
name|fs
operator|.
name|delete
argument_list|(
name|splits
argument_list|)
expr_stmt|;
block|}
name|Path
name|merges
init|=
operator|new
name|Path
argument_list|(
name|regiondir
argument_list|,
name|MERGEDIR
argument_list|)
decl_stmt|;
if|if
condition|(
name|fs
operator|.
name|exists
argument_list|(
name|merges
argument_list|)
condition|)
block|{
name|fs
operator|.
name|delete
argument_list|(
name|merges
argument_list|)
expr_stmt|;
block|}
comment|// By default, we flush the cache when 16M.
name|this
operator|.
name|memcacheFlushSize
operator|=
name|conf
operator|.
name|getInt
argument_list|(
literal|"hbase.hregion.memcache.flush.size"
argument_list|,
literal|1024
operator|*
literal|1024
operator|*
literal|16
argument_list|)
expr_stmt|;
name|this
operator|.
name|blockingMemcacheSize
operator|=
name|this
operator|.
name|memcacheFlushSize
operator|*
name|conf
operator|.
name|getInt
argument_list|(
literal|"hbase.hregion.memcache.block.multiplier"
argument_list|,
literal|2
argument_list|)
expr_stmt|;
comment|// By default we split region if a file> DEFAULT_MAX_FILE_SIZE.
name|this
operator|.
name|desiredMaxFileSize
operator|=
name|conf
operator|.
name|getLong
argument_list|(
literal|"hbase.hregion.max.filesize"
argument_list|,
name|DEFAULT_MAX_FILE_SIZE
argument_list|)
expr_stmt|;
comment|// HRegion is ready to go!
name|this
operator|.
name|writestate
operator|.
name|compacting
operator|=
literal|false
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"region "
operator|+
name|this
operator|.
name|regionInfo
operator|.
name|getRegionName
argument_list|()
operator|+
literal|" available"
argument_list|)
expr_stmt|;
block|}
comment|/**    * @return Updates to this region need to have a sequence id that is>= to    * the this number.    */
name|long
name|getMinSequenceId
parameter_list|()
block|{
return|return
name|this
operator|.
name|minSequenceId
return|;
block|}
comment|/** @return a HRegionInfo object for this region */
specifier|public
name|HRegionInfo
name|getRegionInfo
parameter_list|()
block|{
return|return
name|this
operator|.
name|regionInfo
return|;
block|}
comment|/** returns true if region is closed */
name|boolean
name|isClosed
parameter_list|()
block|{
return|return
name|this
operator|.
name|closed
operator|.
name|get
argument_list|()
return|;
block|}
comment|/**    * Close down this HRegion.  Flush the cache, shut down each HStore, don't     * service any more calls.    *    *<p>This method could take some time to execute, so don't call it from a     * time-sensitive thread.    *     * @return Vector of all the storage files that the HRegion's component     * HStores make use of.  It's a list of all HStoreFile objects. Returns empty    * vector if already closed and null if judged that it should not close.    *     * @throws IOException    */
specifier|public
name|Vector
argument_list|<
name|HStoreFile
argument_list|>
name|close
parameter_list|()
throws|throws
name|IOException
block|{
return|return
name|close
argument_list|(
literal|false
argument_list|)
return|;
block|}
comment|/**    * Close down this HRegion.  Flush the cache unless abort parameter is true,    * Shut down each HStore, don't service any more calls.    *    * This method could take some time to execute, so don't call it from a     * time-sensitive thread.    *     * @param abort true if server is aborting (only during testing)    * @return Vector of all the storage files that the HRegion's component     * HStores make use of.  It's a list of HStoreFile objects.  Can be null if    * we are not to close at this time or we are already closed.    *     * @throws IOException    */
name|Vector
argument_list|<
name|HStoreFile
argument_list|>
name|close
parameter_list|(
name|boolean
name|abort
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|isClosed
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"region "
operator|+
name|this
operator|.
name|regionInfo
operator|.
name|getRegionName
argument_list|()
operator|+
literal|" already closed"
argument_list|)
expr_stmt|;
return|return
literal|null
return|;
block|}
name|lock
operator|.
name|obtainWriteLock
argument_list|()
expr_stmt|;
try|try
block|{
synchronized|synchronized
init|(
name|writestate
init|)
block|{
while|while
condition|(
name|writestate
operator|.
name|compacting
operator|||
name|writestate
operator|.
name|flushing
condition|)
block|{
try|try
block|{
name|writestate
operator|.
name|wait
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|iex
parameter_list|)
block|{
comment|// continue
block|}
block|}
comment|// Disable compacting and flushing by background threads for this
comment|// region.
name|writestate
operator|.
name|writesEnabled
operator|=
literal|false
expr_stmt|;
block|}
comment|// Write lock means no more row locks can be given out.  Wait on
comment|// outstanding row locks to come in before we close so we do not drop
comment|// outstanding updates.
name|waitOnRowLocks
argument_list|()
expr_stmt|;
if|if
condition|(
operator|!
name|abort
condition|)
block|{
comment|// Don't flush the cache if we are aborting during a test.
name|internalFlushcache
argument_list|()
expr_stmt|;
block|}
name|Vector
argument_list|<
name|HStoreFile
argument_list|>
name|result
init|=
operator|new
name|Vector
argument_list|<
name|HStoreFile
argument_list|>
argument_list|()
decl_stmt|;
for|for
control|(
name|HStore
name|store
range|:
name|stores
operator|.
name|values
argument_list|()
control|)
block|{
name|result
operator|.
name|addAll
argument_list|(
name|store
operator|.
name|close
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|this
operator|.
name|closed
operator|.
name|set
argument_list|(
literal|true
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"closed "
operator|+
name|this
operator|.
name|regionInfo
operator|.
name|getRegionName
argument_list|()
argument_list|)
expr_stmt|;
return|return
name|result
return|;
block|}
finally|finally
block|{
name|lock
operator|.
name|releaseWriteLock
argument_list|()
expr_stmt|;
block|}
block|}
comment|/*    * Split the HRegion to create two brand-new ones.  This also closes    * current HRegion.  Split should be fast since we don't rewrite store files    * but instead create new 'reference' store files that read off the top and    * bottom ranges of parent store files.    * @param midKey Row to split on.    * @param listener May be null.    * @return two brand-new (and open) HRegions    * @throws IOException    */
name|HRegion
index|[]
name|closeAndSplit
parameter_list|(
specifier|final
name|Text
name|midKey
parameter_list|,
specifier|final
name|RegionUnavailableListener
name|listener
parameter_list|)
throws|throws
name|IOException
block|{
name|checkMidKey
argument_list|(
name|midKey
argument_list|)
expr_stmt|;
name|long
name|startTime
init|=
name|System
operator|.
name|currentTimeMillis
argument_list|()
decl_stmt|;
name|Path
name|splits
init|=
name|getSplitsDir
argument_list|()
decl_stmt|;
name|HRegionInfo
name|regionAInfo
init|=
operator|new
name|HRegionInfo
argument_list|(
name|this
operator|.
name|regionInfo
operator|.
name|getTableDesc
argument_list|()
argument_list|,
name|this
operator|.
name|regionInfo
operator|.
name|getStartKey
argument_list|()
argument_list|,
name|midKey
argument_list|)
decl_stmt|;
name|Path
name|dirA
init|=
name|getSplitRegionDir
argument_list|(
name|splits
argument_list|,
name|HRegionInfo
operator|.
name|encodeRegionName
argument_list|(
name|regionAInfo
operator|.
name|getRegionName
argument_list|()
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|fs
operator|.
name|exists
argument_list|(
name|dirA
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Cannot split; target file collision at "
operator|+
name|dirA
argument_list|)
throw|;
block|}
name|HRegionInfo
name|regionBInfo
init|=
operator|new
name|HRegionInfo
argument_list|(
name|this
operator|.
name|regionInfo
operator|.
name|getTableDesc
argument_list|()
argument_list|,
name|midKey
argument_list|,
literal|null
argument_list|)
decl_stmt|;
name|Path
name|dirB
init|=
name|getSplitRegionDir
argument_list|(
name|splits
argument_list|,
name|HRegionInfo
operator|.
name|encodeRegionName
argument_list|(
name|regionBInfo
operator|.
name|getRegionName
argument_list|()
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|this
operator|.
name|fs
operator|.
name|exists
argument_list|(
name|dirB
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Cannot split; target file collision at "
operator|+
name|dirB
argument_list|)
throw|;
block|}
comment|// Notify the caller that we are about to close the region. This moves
comment|// us to the 'retiring' queue. Means no more updates coming in -- just
comment|// whatever is outstanding.
if|if
condition|(
name|listener
operator|!=
literal|null
condition|)
block|{
name|listener
operator|.
name|closing
argument_list|(
name|getRegionName
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|// Now close the HRegion.  Close returns all store files or null if not
comment|// supposed to close (? What to do in this case? Implement abort of close?)
comment|// Close also does wait on outstanding rows and calls a flush just-in-case.
name|Vector
argument_list|<
name|HStoreFile
argument_list|>
name|hstoreFilesToSplit
init|=
name|close
argument_list|()
decl_stmt|;
if|if
condition|(
name|hstoreFilesToSplit
operator|==
literal|null
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Close came back null (Implement abort of close?)"
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"close returned empty vector of HStoreFiles"
argument_list|)
throw|;
block|}
comment|// Tell listener that region is now closed and that they can therefore
comment|// clean up any outstanding references.
if|if
condition|(
name|listener
operator|!=
literal|null
condition|)
block|{
name|listener
operator|.
name|closed
argument_list|(
name|this
operator|.
name|getRegionName
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|// Split each store file.
for|for
control|(
name|HStoreFile
name|h
range|:
name|hstoreFilesToSplit
control|)
block|{
comment|// A reference to the bottom half of the hsf store file.
name|HStoreFile
operator|.
name|Reference
name|aReference
init|=
operator|new
name|HStoreFile
operator|.
name|Reference
argument_list|(
name|this
operator|.
name|encodedRegionName
argument_list|,
name|h
operator|.
name|getFileId
argument_list|()
argument_list|,
operator|new
name|HStoreKey
argument_list|(
name|midKey
argument_list|)
argument_list|,
name|HStoreFile
operator|.
name|Range
operator|.
name|bottom
argument_list|)
decl_stmt|;
name|HStoreFile
name|a
init|=
operator|new
name|HStoreFile
argument_list|(
name|this
operator|.
name|conf
argument_list|,
name|splits
argument_list|,
name|HRegionInfo
operator|.
name|encodeRegionName
argument_list|(
name|regionAInfo
operator|.
name|getRegionName
argument_list|()
argument_list|)
argument_list|,
name|h
operator|.
name|getColFamily
argument_list|()
argument_list|,
name|Math
operator|.
name|abs
argument_list|(
name|rand
operator|.
name|nextLong
argument_list|()
argument_list|)
argument_list|,
name|aReference
argument_list|)
decl_stmt|;
comment|// Reference to top half of the hsf store file.
name|HStoreFile
operator|.
name|Reference
name|bReference
init|=
operator|new
name|HStoreFile
operator|.
name|Reference
argument_list|(
name|this
operator|.
name|encodedRegionName
argument_list|,
name|h
operator|.
name|getFileId
argument_list|()
argument_list|,
operator|new
name|HStoreKey
argument_list|(
name|midKey
argument_list|)
argument_list|,
name|HStoreFile
operator|.
name|Range
operator|.
name|top
argument_list|)
decl_stmt|;
name|HStoreFile
name|b
init|=
operator|new
name|HStoreFile
argument_list|(
name|this
operator|.
name|conf
argument_list|,
name|splits
argument_list|,
name|HRegionInfo
operator|.
name|encodeRegionName
argument_list|(
name|regionBInfo
operator|.
name|getRegionName
argument_list|()
argument_list|)
argument_list|,
name|h
operator|.
name|getColFamily
argument_list|()
argument_list|,
name|Math
operator|.
name|abs
argument_list|(
name|rand
operator|.
name|nextLong
argument_list|()
argument_list|)
argument_list|,
name|bReference
argument_list|)
decl_stmt|;
name|h
operator|.
name|splitStoreFile
argument_list|(
name|a
argument_list|,
name|b
argument_list|,
name|this
operator|.
name|fs
argument_list|)
expr_stmt|;
block|}
comment|// Done!
comment|// Opening the region copies the splits files from the splits directory
comment|// under each region.
name|HRegion
name|regionA
init|=
operator|new
name|HRegion
argument_list|(
name|rootDir
argument_list|,
name|log
argument_list|,
name|fs
argument_list|,
name|conf
argument_list|,
name|regionAInfo
argument_list|,
name|dirA
argument_list|)
decl_stmt|;
name|HRegion
name|regionB
init|=
operator|new
name|HRegion
argument_list|(
name|rootDir
argument_list|,
name|log
argument_list|,
name|fs
argument_list|,
name|conf
argument_list|,
name|regionBInfo
argument_list|,
name|dirB
argument_list|)
decl_stmt|;
comment|// Cleanup
name|boolean
name|deleted
init|=
name|fs
operator|.
name|delete
argument_list|(
name|splits
argument_list|)
decl_stmt|;
comment|// Get rid of splits directory
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Cleaned up "
operator|+
name|splits
operator|.
name|toString
argument_list|()
operator|+
literal|" "
operator|+
name|deleted
argument_list|)
expr_stmt|;
block|}
name|HRegion
name|regions
index|[]
init|=
operator|new
name|HRegion
index|[]
block|{
name|regionA
block|,
name|regionB
block|}
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Region split of "
operator|+
name|this
operator|.
name|regionInfo
operator|.
name|getRegionName
argument_list|()
operator|+
literal|" complete; "
operator|+
literal|"new regions: "
operator|+
name|regions
index|[
literal|0
index|]
operator|.
name|getRegionName
argument_list|()
operator|+
literal|", "
operator|+
name|regions
index|[
literal|1
index|]
operator|.
name|getRegionName
argument_list|()
operator|+
literal|". Split took "
operator|+
name|StringUtils
operator|.
name|formatTimeDiff
argument_list|(
name|System
operator|.
name|currentTimeMillis
argument_list|()
argument_list|,
name|startTime
argument_list|)
argument_list|)
expr_stmt|;
return|return
name|regions
return|;
block|}
specifier|private
name|void
name|checkMidKey
parameter_list|(
specifier|final
name|Text
name|midKey
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
operator|(
operator|(
name|this
operator|.
name|regionInfo
operator|.
name|getStartKey
argument_list|()
operator|.
name|getLength
argument_list|()
operator|!=
literal|0
operator|)
operator|&&
operator|(
name|this
operator|.
name|regionInfo
operator|.
name|getStartKey
argument_list|()
operator|.
name|compareTo
argument_list|(
name|midKey
argument_list|)
operator|>
literal|0
operator|)
operator|)
operator|||
operator|(
operator|(
name|this
operator|.
name|regionInfo
operator|.
name|getEndKey
argument_list|()
operator|.
name|getLength
argument_list|()
operator|!=
literal|0
operator|)
operator|&&
operator|(
name|this
operator|.
name|regionInfo
operator|.
name|getEndKey
argument_list|()
operator|.
name|compareTo
argument_list|(
name|midKey
argument_list|)
operator|<
literal|0
operator|)
operator|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Region splitkey must lie within region "
operator|+
literal|"boundaries."
argument_list|)
throw|;
block|}
block|}
specifier|private
name|Path
name|getSplitRegionDir
parameter_list|(
specifier|final
name|Path
name|splits
parameter_list|,
specifier|final
name|String
name|region
parameter_list|)
block|{
return|return
name|HRegion
operator|.
name|getRegionDir
argument_list|(
name|splits
argument_list|,
name|region
argument_list|)
return|;
block|}
specifier|private
name|Path
name|getSplitsDir
parameter_list|()
throws|throws
name|IOException
block|{
name|Path
name|splits
init|=
operator|new
name|Path
argument_list|(
name|this
operator|.
name|regiondir
argument_list|,
name|SPLITDIR
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|this
operator|.
name|fs
operator|.
name|exists
argument_list|(
name|splits
argument_list|)
condition|)
block|{
name|this
operator|.
name|fs
operator|.
name|mkdirs
argument_list|(
name|splits
argument_list|)
expr_stmt|;
block|}
return|return
name|splits
return|;
block|}
comment|//////////////////////////////////////////////////////////////////////////////
comment|// HRegion accessors
comment|//////////////////////////////////////////////////////////////////////////////
comment|/** @return start key for region */
specifier|public
name|Text
name|getStartKey
parameter_list|()
block|{
return|return
name|this
operator|.
name|regionInfo
operator|.
name|getStartKey
argument_list|()
return|;
block|}
comment|/** @return end key for region */
specifier|public
name|Text
name|getEndKey
parameter_list|()
block|{
return|return
name|this
operator|.
name|regionInfo
operator|.
name|getEndKey
argument_list|()
return|;
block|}
comment|/** @return region id */
specifier|public
name|long
name|getRegionId
parameter_list|()
block|{
return|return
name|this
operator|.
name|regionInfo
operator|.
name|getRegionId
argument_list|()
return|;
block|}
comment|/** @return region name */
specifier|public
name|Text
name|getRegionName
parameter_list|()
block|{
return|return
name|this
operator|.
name|regionInfo
operator|.
name|getRegionName
argument_list|()
return|;
block|}
comment|/** @return root directory path */
specifier|public
name|Path
name|getRootDir
parameter_list|()
block|{
return|return
name|rootDir
return|;
block|}
comment|/** @return HTableDescriptor for this region */
specifier|public
name|HTableDescriptor
name|getTableDesc
parameter_list|()
block|{
return|return
name|this
operator|.
name|regionInfo
operator|.
name|getTableDesc
argument_list|()
return|;
block|}
comment|/** @return HLog in use for this region */
specifier|public
name|HLog
name|getLog
parameter_list|()
block|{
return|return
name|this
operator|.
name|log
return|;
block|}
comment|/** @return Configuration object */
specifier|public
name|Configuration
name|getConf
parameter_list|()
block|{
return|return
name|this
operator|.
name|conf
return|;
block|}
comment|/** @return region directory Path */
specifier|public
name|Path
name|getRegionDir
parameter_list|()
block|{
return|return
name|this
operator|.
name|regiondir
return|;
block|}
comment|/** @return FileSystem being used by this region */
specifier|public
name|FileSystem
name|getFilesystem
parameter_list|()
block|{
return|return
name|this
operator|.
name|fs
return|;
block|}
comment|//////////////////////////////////////////////////////////////////////////////
comment|// HRegion maintenance.
comment|//
comment|// These methods are meant to be called periodically by the HRegionServer for
comment|// upkeep.
comment|//////////////////////////////////////////////////////////////////////////////
comment|/*    * Iterates through all the HStores and finds the one with the largest    * MapFile size. If the size is greater than the (currently hard-coded)    * threshold, returns true indicating that the region should be split. The    * midKey for the largest MapFile is returned through the midKey parameter.    * It is possible for us to rule the region non-splitable even in excess of    * configured size.  This happens if region contains a reference file.  If    * a reference file, the region can not be split.    * @param midKey midKey of the largest MapFile    * @return true if the region should be split. midKey is set by this method.    * Check it for a midKey value on return.    */
name|boolean
name|needsSplit
parameter_list|(
name|Text
name|midKey
parameter_list|)
block|{
name|lock
operator|.
name|obtainReadLock
argument_list|()
expr_stmt|;
try|try
block|{
name|HStore
operator|.
name|HStoreSize
name|biggest
init|=
name|largestHStore
argument_list|(
name|midKey
argument_list|)
decl_stmt|;
if|if
condition|(
name|biggest
operator|==
literal|null
condition|)
block|{
return|return
literal|false
return|;
block|}
name|long
name|triggerSize
init|=
name|this
operator|.
name|desiredMaxFileSize
operator|+
operator|(
name|this
operator|.
name|desiredMaxFileSize
operator|/
literal|2
operator|)
decl_stmt|;
name|boolean
name|split
init|=
operator|(
name|biggest
operator|.
name|getAggregate
argument_list|()
operator|>=
name|triggerSize
operator|)
decl_stmt|;
if|if
condition|(
name|split
condition|)
block|{
if|if
condition|(
operator|!
name|biggest
operator|.
name|isSplitable
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Region "
operator|+
name|getRegionName
argument_list|()
operator|.
name|toString
argument_list|()
operator|+
literal|" is NOT splitable though its aggregate size is "
operator|+
name|StringUtils
operator|.
name|humanReadableInt
argument_list|(
name|biggest
operator|.
name|getAggregate
argument_list|()
argument_list|)
operator|+
literal|" and desired size is "
operator|+
name|StringUtils
operator|.
name|humanReadableInt
argument_list|(
name|this
operator|.
name|desiredMaxFileSize
argument_list|)
argument_list|)
expr_stmt|;
name|split
operator|=
literal|false
expr_stmt|;
block|}
else|else
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Splitting "
operator|+
name|getRegionName
argument_list|()
operator|.
name|toString
argument_list|()
operator|+
literal|" because largest aggregate size is "
operator|+
name|StringUtils
operator|.
name|humanReadableInt
argument_list|(
name|biggest
operator|.
name|getAggregate
argument_list|()
argument_list|)
operator|+
literal|" and desired size is "
operator|+
name|StringUtils
operator|.
name|humanReadableInt
argument_list|(
name|this
operator|.
name|desiredMaxFileSize
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|split
return|;
block|}
finally|finally
block|{
name|lock
operator|.
name|releaseReadLock
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**    * @return returns size of largest HStore.  Also returns whether store is    * splitable or not (Its not splitable if region has a store that has a    * reference store file).    */
name|HStore
operator|.
name|HStoreSize
name|largestHStore
parameter_list|(
specifier|final
name|Text
name|midkey
parameter_list|)
block|{
name|HStore
operator|.
name|HStoreSize
name|biggest
init|=
literal|null
decl_stmt|;
name|boolean
name|splitable
init|=
literal|true
decl_stmt|;
name|lock
operator|.
name|obtainReadLock
argument_list|()
expr_stmt|;
try|try
block|{
for|for
control|(
name|HStore
name|h
range|:
name|stores
operator|.
name|values
argument_list|()
control|)
block|{
name|HStore
operator|.
name|HStoreSize
name|size
init|=
name|h
operator|.
name|size
argument_list|(
name|midkey
argument_list|)
decl_stmt|;
comment|// If we came across a reference down in the store, then propagate
comment|// fact that region is not splitable.
if|if
condition|(
name|splitable
condition|)
block|{
name|splitable
operator|=
name|size
operator|.
name|splitable
expr_stmt|;
block|}
if|if
condition|(
name|biggest
operator|==
literal|null
condition|)
block|{
name|biggest
operator|=
name|size
expr_stmt|;
continue|continue;
block|}
if|if
condition|(
name|size
operator|.
name|getAggregate
argument_list|()
operator|>
name|biggest
operator|.
name|getAggregate
argument_list|()
condition|)
block|{
comment|// Largest so far
name|biggest
operator|=
name|size
expr_stmt|;
block|}
block|}
if|if
condition|(
name|biggest
operator|!=
literal|null
condition|)
block|{
name|biggest
operator|.
name|setSplitable
argument_list|(
name|splitable
argument_list|)
expr_stmt|;
block|}
return|return
name|biggest
return|;
block|}
finally|finally
block|{
name|lock
operator|.
name|releaseReadLock
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**    * @return true if the region should be compacted.    */
name|boolean
name|needsCompaction
parameter_list|()
block|{
name|boolean
name|needsCompaction
init|=
literal|false
decl_stmt|;
name|this
operator|.
name|lock
operator|.
name|obtainReadLock
argument_list|()
expr_stmt|;
try|try
block|{
for|for
control|(
name|HStore
name|store
range|:
name|stores
operator|.
name|values
argument_list|()
control|)
block|{
if|if
condition|(
name|store
operator|.
name|needsCompaction
argument_list|()
condition|)
block|{
name|needsCompaction
operator|=
literal|true
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
name|store
operator|.
name|toString
argument_list|()
operator|+
literal|" needs compaction"
argument_list|)
expr_stmt|;
break|break;
block|}
block|}
block|}
finally|finally
block|{
name|this
operator|.
name|lock
operator|.
name|releaseReadLock
argument_list|()
expr_stmt|;
block|}
return|return
name|needsCompaction
return|;
block|}
comment|/**    * Compact all the stores.  This should be called periodically to make sure     * the stores are kept manageable.      *    *<p>This operation could block for a long time, so don't call it from a     * time-sensitive thread.    *    * @return Returns TRUE if the compaction has completed.  FALSE, if the    * compaction was not carried out, because the HRegion is busy doing    * something else storage-intensive (like flushing the cache). The caller    * should check back later.    */
name|boolean
name|compactStores
parameter_list|()
throws|throws
name|IOException
block|{
name|boolean
name|shouldCompact
init|=
literal|false
decl_stmt|;
if|if
condition|(
name|this
operator|.
name|closed
operator|.
name|get
argument_list|()
condition|)
block|{
return|return
name|shouldCompact
return|;
block|}
name|lock
operator|.
name|obtainReadLock
argument_list|()
expr_stmt|;
try|try
block|{
synchronized|synchronized
init|(
name|writestate
init|)
block|{
if|if
condition|(
operator|(
operator|!
name|writestate
operator|.
name|compacting
operator|)
operator|&&
name|writestate
operator|.
name|writesEnabled
condition|)
block|{
name|writestate
operator|.
name|compacting
operator|=
literal|true
expr_stmt|;
name|shouldCompact
operator|=
literal|true
expr_stmt|;
block|}
block|}
if|if
condition|(
operator|!
name|shouldCompact
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"NOT compacting region "
operator|+
name|this
operator|.
name|regionInfo
operator|.
name|getRegionName
argument_list|()
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
return|return
literal|false
return|;
block|}
name|long
name|startTime
init|=
name|System
operator|.
name|currentTimeMillis
argument_list|()
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"starting compaction on region "
operator|+
name|this
operator|.
name|regionInfo
operator|.
name|getRegionName
argument_list|()
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
for|for
control|(
name|HStore
name|store
range|:
name|stores
operator|.
name|values
argument_list|()
control|)
block|{
name|store
operator|.
name|compact
argument_list|()
expr_stmt|;
block|}
name|LOG
operator|.
name|info
argument_list|(
literal|"compaction completed on region "
operator|+
name|this
operator|.
name|regionInfo
operator|.
name|getRegionName
argument_list|()
operator|.
name|toString
argument_list|()
operator|+
literal|". Took "
operator|+
name|StringUtils
operator|.
name|formatTimeDiff
argument_list|(
name|System
operator|.
name|currentTimeMillis
argument_list|()
argument_list|,
name|startTime
argument_list|)
argument_list|)
expr_stmt|;
return|return
literal|true
return|;
block|}
finally|finally
block|{
name|lock
operator|.
name|releaseReadLock
argument_list|()
expr_stmt|;
synchronized|synchronized
init|(
name|writestate
init|)
block|{
name|writestate
operator|.
name|compacting
operator|=
literal|false
expr_stmt|;
name|writestate
operator|.
name|notifyAll
argument_list|()
expr_stmt|;
block|}
block|}
block|}
comment|/**    * Each HRegion is given a periodic chance to flush the cache, which it should    * only take if there have been a lot of uncommitted writes.    * @throws IOException    * @throws DroppedSnapshotException Thrown when replay of hlog is required    * because a Snapshot was not properly persisted.    */
name|void
name|optionallyFlush
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|this
operator|.
name|memcache
operator|.
name|getSize
argument_list|()
operator|>
name|this
operator|.
name|memcacheFlushSize
condition|)
block|{
name|flushcache
argument_list|(
literal|false
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|this
operator|.
name|memcache
operator|.
name|getSize
argument_list|()
operator|>
literal|0
condition|)
block|{
if|if
condition|(
name|this
operator|.
name|noFlushCount
operator|>=
name|this
operator|.
name|optionalFlushCount
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Optional flush called "
operator|+
name|this
operator|.
name|noFlushCount
operator|+
literal|" times when data present without flushing.  Forcing one."
argument_list|)
expr_stmt|;
name|flushcache
argument_list|(
literal|false
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// Only increment if something in the cache.
comment|// Gets zero'd when a flushcache is called.
name|this
operator|.
name|noFlushCount
operator|++
expr_stmt|;
block|}
block|}
block|}
comment|/**    * Flush the cache.  This is called periodically to minimize the amount of    * log processing needed upon startup.    *     *<p>The returned Vector is a list of all the files used by the component    * HStores. It is a list of HStoreFile objects.  If the returned value is    * NULL, then the flush could not be executed, because the HRegion is busy    * doing something else storage-intensive.  The caller should check back    * later.    *    *<p>This method may block for some time, so it should not be called from a     * time-sensitive thread.    *     * @param disableFutureWrites indicates that the caller intends to     * close() the HRegion shortly, so the HRegion should not take on any new and     * potentially long-lasting disk operations. This flush() should be the final    * pre-close() disk operation.    * @throws IOException    * @throws DroppedSnapshotException Thrown when replay of hlog is required    * because a Snapshot was not properly persisted.    */
name|void
name|flushcache
parameter_list|(
name|boolean
name|disableFutureWrites
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|this
operator|.
name|closed
operator|.
name|get
argument_list|()
condition|)
block|{
return|return;
block|}
name|this
operator|.
name|noFlushCount
operator|=
literal|0
expr_stmt|;
name|boolean
name|shouldFlush
init|=
literal|false
decl_stmt|;
synchronized|synchronized
init|(
name|writestate
init|)
block|{
if|if
condition|(
operator|(
operator|!
name|writestate
operator|.
name|flushing
operator|)
operator|&&
name|writestate
operator|.
name|writesEnabled
condition|)
block|{
name|writestate
operator|.
name|flushing
operator|=
literal|true
expr_stmt|;
name|shouldFlush
operator|=
literal|true
expr_stmt|;
if|if
condition|(
name|disableFutureWrites
condition|)
block|{
name|writestate
operator|.
name|writesEnabled
operator|=
literal|false
expr_stmt|;
block|}
block|}
block|}
if|if
condition|(
operator|!
name|shouldFlush
condition|)
block|{
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"NOT flushing memcache for region "
operator|+
name|this
operator|.
name|regionInfo
operator|.
name|getRegionName
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return;
block|}
try|try
block|{
name|internalFlushcache
argument_list|()
expr_stmt|;
block|}
finally|finally
block|{
synchronized|synchronized
init|(
name|writestate
init|)
block|{
name|writestate
operator|.
name|flushing
operator|=
literal|false
expr_stmt|;
name|writestate
operator|.
name|notifyAll
argument_list|()
expr_stmt|;
block|}
block|}
block|}
comment|/**    * Flushing the cache is a little tricky. We have a lot of updates in the    * HMemcache, all of which have also been written to the log. We need to    * write those updates in the HMemcache out to disk, while being able to    * process reads/writes as much as possible during the flush operation. Also,    * the log has to state clearly the point in time at which the HMemcache was    * flushed. (That way, during recovery, we know when we can rely on the    * on-disk flushed structures and when we have to recover the HMemcache from    * the log.)    *     *<p>So, we have a three-step process:    *     *<ul><li>A. Flush the memcache to the on-disk stores, noting the current    * sequence ID for the log.<li>    *     *<li>B. Write a FLUSHCACHE-COMPLETE message to the log, using the sequence    * ID that was current at the time of memcache-flush.</li>    *     *<li>C. Get rid of the memcache structures that are now redundant, as    * they've been flushed to the on-disk HStores.</li>    *</ul>    *<p>This method is protected, but can be accessed via several public    * routes.    *     *<p> This method may block for some time.    * @throws IOException    * @throws DroppedSnapshotException Thrown when replay of hlog is required    * because a Snapshot was not properly persisted.    */
name|void
name|internalFlushcache
parameter_list|()
throws|throws
name|IOException
block|{
name|long
name|startTime
init|=
operator|-
literal|1
decl_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|startTime
operator|=
name|System
operator|.
name|currentTimeMillis
argument_list|()
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Started memcache flush for region "
operator|+
name|this
operator|.
name|regionInfo
operator|.
name|getRegionName
argument_list|()
operator|+
literal|". Size "
operator|+
name|StringUtils
operator|.
name|humanReadableInt
argument_list|(
name|this
operator|.
name|memcache
operator|.
name|getSize
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|// We pass the log to the HMemcache, so we can lock down both
comment|// simultaneously.  We only have to do this for a moment: we need the
comment|// HMemcache state at the time of a known log sequence number. Since
comment|// multiple HRegions may write to a single HLog, the sequence numbers may
comment|// zoom past unless we lock it.
comment|//
comment|// When execution returns from snapshotMemcacheForLog() with a non-NULL
comment|// value, the HMemcache will have a snapshot object stored that must be
comment|// explicitly cleaned up using a call to deleteSnapshot() or by calling
comment|// abort.
comment|//
name|HMemcache
operator|.
name|Snapshot
name|retval
init|=
name|memcache
operator|.
name|snapshotMemcacheForLog
argument_list|(
name|log
argument_list|)
decl_stmt|;
if|if
condition|(
name|retval
operator|==
literal|null
operator|||
name|retval
operator|.
name|memcacheSnapshot
operator|==
literal|null
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Finished memcache flush; empty snapshot"
argument_list|)
expr_stmt|;
return|return;
block|}
comment|// Any failure from here on out will be catastrophic requiring server
comment|// restart so hlog content can be replayed and put back into the memcache.
comment|// Otherwise, the snapshot content while backed up in the hlog, it will not
comment|// be part of the current running servers state.
try|try
block|{
name|long
name|logCacheFlushId
init|=
name|retval
operator|.
name|sequenceId
decl_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Snapshotted memcache for region "
operator|+
name|this
operator|.
name|regionInfo
operator|.
name|getRegionName
argument_list|()
operator|+
literal|" with sequence id "
operator|+
name|retval
operator|.
name|sequenceId
operator|+
literal|" and entries "
operator|+
name|retval
operator|.
name|memcacheSnapshot
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
block|}
try|try
block|{
comment|// A.  Flush memcache to all the HStores.
comment|// Keep running vector of all store files that includes both old and the
comment|// just-made new flush store file.
for|for
control|(
name|HStore
name|hstore
range|:
name|stores
operator|.
name|values
argument_list|()
control|)
block|{
name|hstore
operator|.
name|flushCache
argument_list|(
name|retval
operator|.
name|memcacheSnapshot
argument_list|,
name|retval
operator|.
name|sequenceId
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
comment|// An exception here means that the snapshot was not persisted.
comment|// The hlog needs to be replayed so its content is restored to memcache.
comment|// Currently, only a server restart will do this.
name|this
operator|.
name|log
operator|.
name|abortCacheFlush
argument_list|()
expr_stmt|;
throw|throw
operator|new
name|DroppedSnapshotException
argument_list|(
name|e
operator|.
name|getMessage
argument_list|()
argument_list|)
throw|;
block|}
comment|// If we get to here, the HStores have been written. If we get an
comment|// error in completeCacheFlush it will release the lock it is holding
comment|// B.  Write a FLUSHCACHE-COMPLETE message to the log.
comment|//     This tells future readers that the HStores were emitted correctly,
comment|//     and that all updates to the log for this regionName that have lower
comment|//     log-sequence-ids can be safely ignored.
name|this
operator|.
name|log
operator|.
name|completeCacheFlush
argument_list|(
name|this
operator|.
name|regionInfo
operator|.
name|getRegionName
argument_list|()
argument_list|,
name|regionInfo
operator|.
name|getTableDesc
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|,
name|logCacheFlushId
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
comment|// C. Delete the now-irrelevant memcache snapshot; its contents have been
comment|//    dumped to disk-based HStores or, if error, clear aborted snapshot.
name|this
operator|.
name|memcache
operator|.
name|deleteSnapshot
argument_list|()
expr_stmt|;
block|}
comment|// D. Finally notify anyone waiting on memcache to clear:
comment|// e.g. checkResources().
synchronized|synchronized
init|(
name|this
init|)
block|{
name|notifyAll
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Finished memcache flush for region "
operator|+
name|this
operator|.
name|regionInfo
operator|.
name|getRegionName
argument_list|()
operator|+
literal|" in "
operator|+
operator|(
name|System
operator|.
name|currentTimeMillis
argument_list|()
operator|-
name|startTime
operator|)
operator|+
literal|"ms"
argument_list|)
expr_stmt|;
block|}
block|}
comment|//////////////////////////////////////////////////////////////////////////////
comment|// get() methods for client use.
comment|//////////////////////////////////////////////////////////////////////////////
comment|/** Fetch a single data item. */
name|byte
index|[]
name|get
parameter_list|(
name|Text
name|row
parameter_list|,
name|Text
name|column
parameter_list|)
throws|throws
name|IOException
block|{
name|byte
index|[]
index|[]
name|results
init|=
name|get
argument_list|(
name|row
argument_list|,
name|column
argument_list|,
name|Long
operator|.
name|MAX_VALUE
argument_list|,
literal|1
argument_list|)
decl_stmt|;
return|return
operator|(
name|results
operator|==
literal|null
operator|||
name|results
operator|.
name|length
operator|==
literal|0
operator|)
condition|?
literal|null
else|:
name|results
index|[
literal|0
index|]
return|;
block|}
comment|/** Fetch multiple versions of a single data item */
name|byte
index|[]
index|[]
name|get
parameter_list|(
name|Text
name|row
parameter_list|,
name|Text
name|column
parameter_list|,
name|int
name|numVersions
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|get
argument_list|(
name|row
argument_list|,
name|column
argument_list|,
name|Long
operator|.
name|MAX_VALUE
argument_list|,
name|numVersions
argument_list|)
return|;
block|}
comment|/** Fetch multiple versions of a single data item, with timestamp. */
name|byte
index|[]
index|[]
name|get
parameter_list|(
name|Text
name|row
parameter_list|,
name|Text
name|column
parameter_list|,
name|long
name|timestamp
parameter_list|,
name|int
name|numVersions
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|this
operator|.
name|closed
operator|.
name|get
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Region "
operator|+
name|this
operator|.
name|getRegionName
argument_list|()
operator|.
name|toString
argument_list|()
operator|+
literal|" closed"
argument_list|)
throw|;
block|}
comment|// Make sure this is a valid row and valid column
name|checkRow
argument_list|(
name|row
argument_list|)
expr_stmt|;
name|checkColumn
argument_list|(
name|column
argument_list|)
expr_stmt|;
comment|// Obtain the row-lock
name|obtainRowLock
argument_list|(
name|row
argument_list|)
expr_stmt|;
try|try
block|{
comment|// Obtain the -col results
return|return
name|get
argument_list|(
operator|new
name|HStoreKey
argument_list|(
name|row
argument_list|,
name|column
argument_list|,
name|timestamp
argument_list|)
argument_list|,
name|numVersions
argument_list|)
return|;
block|}
finally|finally
block|{
name|releaseRowLock
argument_list|(
name|row
argument_list|)
expr_stmt|;
block|}
block|}
specifier|private
name|byte
index|[]
index|[]
name|get
parameter_list|(
specifier|final
name|HStoreKey
name|key
parameter_list|,
specifier|final
name|int
name|numVersions
parameter_list|)
throws|throws
name|IOException
block|{
name|lock
operator|.
name|obtainReadLock
argument_list|()
expr_stmt|;
try|try
block|{
comment|// Check the memcache
name|byte
index|[]
index|[]
name|memcacheResult
init|=
name|this
operator|.
name|memcache
operator|.
name|get
argument_list|(
name|key
argument_list|,
name|numVersions
argument_list|)
decl_stmt|;
comment|// If we got sufficient versions from memcache, return.
if|if
condition|(
name|memcacheResult
operator|!=
literal|null
operator|&&
name|memcacheResult
operator|.
name|length
operator|==
name|numVersions
condition|)
block|{
return|return
name|memcacheResult
return|;
block|}
comment|// Check hstore for more versions.
name|Text
name|colFamily
init|=
name|HStoreKey
operator|.
name|extractFamily
argument_list|(
name|key
operator|.
name|getColumn
argument_list|()
argument_list|)
decl_stmt|;
name|HStore
name|targetStore
init|=
name|stores
operator|.
name|get
argument_list|(
name|colFamily
argument_list|)
decl_stmt|;
if|if
condition|(
name|targetStore
operator|==
literal|null
condition|)
block|{
comment|// There are no stores.  Return what we got from memcache.
return|return
name|memcacheResult
return|;
block|}
comment|// Update the number of versions we need to fetch from the store.
name|int
name|amendedNumVersions
init|=
name|numVersions
decl_stmt|;
if|if
condition|(
name|memcacheResult
operator|!=
literal|null
condition|)
block|{
name|amendedNumVersions
operator|-=
name|memcacheResult
operator|.
name|length
expr_stmt|;
block|}
name|byte
index|[]
index|[]
name|result
init|=
name|targetStore
operator|.
name|get
argument_list|(
name|key
argument_list|,
name|amendedNumVersions
argument_list|,
name|this
operator|.
name|memcache
argument_list|)
decl_stmt|;
if|if
condition|(
name|result
operator|==
literal|null
condition|)
block|{
name|result
operator|=
name|memcacheResult
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|memcacheResult
operator|!=
literal|null
condition|)
block|{
comment|// We have results from both memcache and from stores.  Put them
comment|// together in an array in the proper order.
name|byte
index|[]
index|[]
name|storeResult
init|=
name|result
decl_stmt|;
name|result
operator|=
operator|new
name|byte
index|[
name|memcacheResult
operator|.
name|length
operator|+
name|result
operator|.
name|length
index|]
index|[]
expr_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|memcacheResult
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|result
index|[
name|i
index|]
operator|=
name|memcacheResult
index|[
name|i
index|]
expr_stmt|;
block|}
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|storeResult
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|result
index|[
name|i
operator|+
name|memcacheResult
operator|.
name|length
index|]
operator|=
name|storeResult
index|[
name|i
index|]
expr_stmt|;
block|}
block|}
return|return
name|result
return|;
block|}
finally|finally
block|{
name|lock
operator|.
name|releaseReadLock
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**    * Fetch all the columns for the indicated row.    * Returns a TreeMap that maps column names to values.    *    * We should eventually use Bloom filters here, to reduce running time.  If     * the database has many column families and is very sparse, then we could be     * checking many files needlessly.  A small Bloom for each row would help us     * determine which column groups are useful for that row.  That would let us     * avoid a bunch of disk activity.    */
name|TreeMap
argument_list|<
name|Text
argument_list|,
name|byte
index|[]
argument_list|>
name|getFull
parameter_list|(
name|Text
name|row
parameter_list|)
throws|throws
name|IOException
block|{
name|HStoreKey
name|key
init|=
operator|new
name|HStoreKey
argument_list|(
name|row
argument_list|,
name|System
operator|.
name|currentTimeMillis
argument_list|()
argument_list|)
decl_stmt|;
name|lock
operator|.
name|obtainReadLock
argument_list|()
expr_stmt|;
try|try
block|{
name|TreeMap
argument_list|<
name|Text
argument_list|,
name|byte
index|[]
argument_list|>
name|memResult
init|=
name|memcache
operator|.
name|getFull
argument_list|(
name|key
argument_list|)
decl_stmt|;
for|for
control|(
name|Text
name|colFamily
range|:
name|stores
operator|.
name|keySet
argument_list|()
control|)
block|{
name|HStore
name|targetStore
init|=
name|stores
operator|.
name|get
argument_list|(
name|colFamily
argument_list|)
decl_stmt|;
name|targetStore
operator|.
name|getFull
argument_list|(
name|key
argument_list|,
name|memResult
argument_list|)
expr_stmt|;
block|}
return|return
name|memResult
return|;
block|}
finally|finally
block|{
name|lock
operator|.
name|releaseReadLock
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**    * Get all keys matching the origin key's row/column/timestamp and those    * of an older vintage    * Default access so can be accessed out of {@link HRegionServer}.    * @param origin Where to start searching.    * @return Ordered list of keys going from newest on back.    * @throws IOException    */
name|List
argument_list|<
name|HStoreKey
argument_list|>
name|getKeys
parameter_list|(
specifier|final
name|HStoreKey
name|origin
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|getKeys
argument_list|(
name|origin
argument_list|,
name|ALL_VERSIONS
argument_list|)
return|;
block|}
comment|/**    * Get<code>versions</code> keys matching the origin key's    * row/column/timestamp and those of an older vintage    * Default access so can be accessed out of {@link HRegionServer}.    * @param origin Where to start searching.    * @param versions How many versions to return. Pass    * {@link HConstants.ALL_VERSIONS} to retrieve all.    * @return Ordered list of<code>versions</code> keys going from newest back.    * @throws IOException    */
name|List
argument_list|<
name|HStoreKey
argument_list|>
name|getKeys
parameter_list|(
specifier|final
name|HStoreKey
name|origin
parameter_list|,
specifier|final
name|int
name|versions
parameter_list|)
throws|throws
name|IOException
block|{
name|List
argument_list|<
name|HStoreKey
argument_list|>
name|keys
init|=
name|this
operator|.
name|memcache
operator|.
name|getKeys
argument_list|(
name|origin
argument_list|,
name|versions
argument_list|)
decl_stmt|;
if|if
condition|(
name|versions
operator|!=
name|ALL_VERSIONS
operator|&&
name|keys
operator|.
name|size
argument_list|()
operator|>=
name|versions
condition|)
block|{
return|return
name|keys
return|;
block|}
comment|// Check hstore for more versions.
name|Text
name|colFamily
init|=
name|HStoreKey
operator|.
name|extractFamily
argument_list|(
name|origin
operator|.
name|getColumn
argument_list|()
argument_list|)
decl_stmt|;
name|HStore
name|targetStore
init|=
name|stores
operator|.
name|get
argument_list|(
name|colFamily
argument_list|)
decl_stmt|;
if|if
condition|(
name|targetStore
operator|!=
literal|null
condition|)
block|{
comment|// Pass versions without modification since in the store getKeys, it
comment|// includes the size of the passed<code>keys</code> array when counting.
name|keys
operator|=
name|targetStore
operator|.
name|getKeys
argument_list|(
name|origin
argument_list|,
name|keys
argument_list|,
name|versions
argument_list|)
expr_stmt|;
block|}
return|return
name|keys
return|;
block|}
comment|/**    * Return an iterator that scans over the HRegion, returning the indicated     * columns for only the rows that match the data filter.  This Iterator must    * be closed by the caller.    *    * @param cols columns to scan. If column name is a column family, all    * columns of the specified column family are returned.  Its also possible    * to pass a regex in the column qualifier. A column qualifier is judged to    * be a regex if it contains at least one of the following characters:    *<code>\+|^&*$[]]}{)(</code>.    * @param firstRow row which is the starting point of the scan    * @param timestamp only return rows whose timestamp is<= this value    * @param filter row filter    * @return HScannerInterface    * @throws IOException    */
specifier|public
name|HInternalScannerInterface
name|getScanner
parameter_list|(
name|Text
index|[]
name|cols
parameter_list|,
name|Text
name|firstRow
parameter_list|,
name|long
name|timestamp
parameter_list|,
name|RowFilterInterface
name|filter
parameter_list|)
throws|throws
name|IOException
block|{
name|lock
operator|.
name|obtainReadLock
argument_list|()
expr_stmt|;
try|try
block|{
name|TreeSet
argument_list|<
name|Text
argument_list|>
name|families
init|=
operator|new
name|TreeSet
argument_list|<
name|Text
argument_list|>
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|cols
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|families
operator|.
name|add
argument_list|(
name|HStoreKey
operator|.
name|extractFamily
argument_list|(
name|cols
index|[
name|i
index|]
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|List
argument_list|<
name|HStore
argument_list|>
name|storelist
init|=
operator|new
name|ArrayList
argument_list|<
name|HStore
argument_list|>
argument_list|()
decl_stmt|;
for|for
control|(
name|Text
name|family
range|:
name|families
control|)
block|{
name|HStore
name|s
init|=
name|stores
operator|.
name|get
argument_list|(
name|family
argument_list|)
decl_stmt|;
if|if
condition|(
name|s
operator|==
literal|null
condition|)
block|{
continue|continue;
block|}
name|storelist
operator|.
name|add
argument_list|(
name|stores
operator|.
name|get
argument_list|(
name|family
argument_list|)
argument_list|)
expr_stmt|;
block|}
return|return
operator|new
name|HScanner
argument_list|(
name|cols
argument_list|,
name|firstRow
argument_list|,
name|timestamp
argument_list|,
name|memcache
argument_list|,
name|storelist
operator|.
name|toArray
argument_list|(
operator|new
name|HStore
index|[
name|storelist
operator|.
name|size
argument_list|()
index|]
argument_list|)
argument_list|,
name|filter
argument_list|)
return|;
block|}
finally|finally
block|{
name|lock
operator|.
name|releaseReadLock
argument_list|()
expr_stmt|;
block|}
block|}
comment|//////////////////////////////////////////////////////////////////////////////
comment|// set() methods for client use.
comment|//////////////////////////////////////////////////////////////////////////////
comment|/**    * The caller wants to apply a series of writes to a single row in the    * HRegion. The caller will invoke startUpdate(), followed by a series of    * calls to put/delete, then finally either abort() or commit().    *    *<p>Note that we rely on the external caller to properly abort() or    * commit() every transaction.  If the caller is a network client, there    * should be a lease-system in place that automatically aborts() transactions    * after a specified quiet period.    *     * @param row Row to update    * @return lock id    * @throws IOException    * @see #put(long, Text, byte[])    */
specifier|public
name|long
name|startUpdate
parameter_list|(
name|Text
name|row
parameter_list|)
throws|throws
name|IOException
block|{
comment|// Do a rough check that we have resources to accept a write.  The check is
comment|// 'rough' in that between the resource check and the call to obtain a
comment|// read lock, resources may run out.  For now, the thought is that this
comment|// will be extremely rare; we'll deal with it when it happens.
name|checkResources
argument_list|()
expr_stmt|;
comment|// Get a read lock. We will not be able to get one if we are closing or
comment|// if this region is being split.  In neither case should we be allowing
comment|// updates.
name|this
operator|.
name|lock
operator|.
name|obtainReadLock
argument_list|()
expr_stmt|;
if|if
condition|(
name|this
operator|.
name|closed
operator|.
name|get
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Region "
operator|+
name|this
operator|.
name|getRegionName
argument_list|()
operator|.
name|toString
argument_list|()
operator|+
literal|" closed"
argument_list|)
throw|;
block|}
try|try
block|{
comment|// We obtain a per-row lock, so other clients will block while one client
comment|// performs an update. The read lock is released by the client calling
comment|// #commit or #abort or if the HRegionServer lease on the lock expires.
comment|// See HRegionServer#RegionListener for how the expire on HRegionServer
comment|// invokes a HRegion#abort.
return|return
name|obtainRowLock
argument_list|(
name|row
argument_list|)
return|;
block|}
finally|finally
block|{
name|this
operator|.
name|lock
operator|.
name|releaseReadLock
argument_list|()
expr_stmt|;
block|}
block|}
comment|/*    * Check if resources to support an update.    *     * For now, just checks memcache saturation.    *     * Here we synchronize on HRegion, a broad scoped lock.  Its appropriate    * given we're figuring in here whether this region is able to take on    * writes.  This is only method with a synchronize (at time of writing),    * this and the synchronize on 'this' inside in internalFlushCache to send    * the notify.    */
specifier|private
specifier|synchronized
name|void
name|checkResources
parameter_list|()
block|{
name|boolean
name|blocked
init|=
literal|false
decl_stmt|;
while|while
condition|(
operator|!
name|checkCommitsSinceFlush
argument_list|()
condition|)
block|{
if|if
condition|(
operator|!
name|blocked
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Blocking updates for '"
operator|+
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|"': Memcache size "
operator|+
name|StringUtils
operator|.
name|humanReadableInt
argument_list|(
name|this
operator|.
name|memcache
operator|.
name|getSize
argument_list|()
argument_list|)
operator|+
literal|" is>= than blocking "
operator|+
name|StringUtils
operator|.
name|humanReadableInt
argument_list|(
name|this
operator|.
name|blockingMemcacheSize
argument_list|)
operator|+
literal|" size"
argument_list|)
expr_stmt|;
block|}
name|blocked
operator|=
literal|true
expr_stmt|;
try|try
block|{
name|wait
argument_list|(
name|threadWakeFrequency
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
comment|// continue;
block|}
block|}
if|if
condition|(
name|blocked
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Unblocking updates for region "
operator|+
name|getRegionName
argument_list|()
operator|+
literal|" '"
operator|+
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|"'"
argument_list|)
expr_stmt|;
block|}
block|}
comment|/*    * @return True if commits since flush is under the blocking threshold.    */
specifier|private
name|boolean
name|checkCommitsSinceFlush
parameter_list|()
block|{
return|return
name|this
operator|.
name|memcache
operator|.
name|getSize
argument_list|()
operator|<
name|this
operator|.
name|blockingMemcacheSize
return|;
block|}
comment|/**    * Put a cell value into the locked row.  The user indicates the row-lock, the    * target column, and the desired value.  This stuff is set into a temporary     * memory area until the user commits the change, at which point it's logged     * and placed into the memcache.    *    * This method really just tests the input, then calls an internal localput()     * method.    *    * @param lockid lock id obtained from startUpdate    * @param targetCol name of column to be updated    * @param val new value for column    * @throws IOException    */
specifier|public
name|void
name|put
parameter_list|(
name|long
name|lockid
parameter_list|,
name|Text
name|targetCol
parameter_list|,
name|byte
index|[]
name|val
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|HLogEdit
operator|.
name|isDeleted
argument_list|(
name|val
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Cannot insert value: "
operator|+
name|val
argument_list|)
throw|;
block|}
name|localput
argument_list|(
name|lockid
argument_list|,
name|targetCol
argument_list|,
name|val
argument_list|)
expr_stmt|;
block|}
comment|/**    * Delete a value or write a value.    * This is a just a convenience method for put().    * @param lockid lock id obtained from startUpdate    * @param targetCol name of column to be deleted    * @throws IOException    */
specifier|public
name|void
name|delete
parameter_list|(
name|long
name|lockid
parameter_list|,
name|Text
name|targetCol
parameter_list|)
throws|throws
name|IOException
block|{
name|localput
argument_list|(
name|lockid
argument_list|,
name|targetCol
argument_list|,
name|HLogEdit
operator|.
name|deleteBytes
operator|.
name|get
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|/**    * Delete all cells of the same age as the passed timestamp or older.    * @param row    * @param column    * @param ts Delete all entries that have this timestamp or older    * @throws IOException    */
specifier|public
name|void
name|deleteAll
parameter_list|(
specifier|final
name|Text
name|row
parameter_list|,
specifier|final
name|Text
name|column
parameter_list|,
specifier|final
name|long
name|ts
parameter_list|)
throws|throws
name|IOException
block|{
name|deleteMultiple
argument_list|(
name|row
argument_list|,
name|column
argument_list|,
name|ts
argument_list|,
name|ALL_VERSIONS
argument_list|)
expr_stmt|;
block|}
comment|/**    * Delete one or many cells.    * Used to support {@link #deleteAll(Text, Text, long)} and deletion of    * latest cell.    * @param row    * @param column    * @param ts Timestamp to start search on.    * @param versions How many versions to delete. Pass    * {@link HConstants.ALL_VERSIONS} to delete all.    * @throws IOException    */
name|void
name|deleteMultiple
parameter_list|(
specifier|final
name|Text
name|row
parameter_list|,
specifier|final
name|Text
name|column
parameter_list|,
specifier|final
name|long
name|ts
parameter_list|,
specifier|final
name|int
name|versions
parameter_list|)
throws|throws
name|IOException
block|{
name|lock
operator|.
name|obtainReadLock
argument_list|()
expr_stmt|;
try|try
block|{
name|checkColumn
argument_list|(
name|column
argument_list|)
expr_stmt|;
name|HStoreKey
name|origin
init|=
operator|new
name|HStoreKey
argument_list|(
name|row
argument_list|,
name|column
argument_list|,
name|ts
argument_list|)
decl_stmt|;
synchronized|synchronized
init|(
name|row
init|)
block|{
name|List
argument_list|<
name|HStoreKey
argument_list|>
name|keys
init|=
name|getKeys
argument_list|(
name|origin
argument_list|,
name|versions
argument_list|)
decl_stmt|;
if|if
condition|(
name|keys
operator|.
name|size
argument_list|()
operator|>
literal|0
condition|)
block|{
name|TreeMap
argument_list|<
name|Text
argument_list|,
name|byte
index|[]
argument_list|>
name|edits
init|=
operator|new
name|TreeMap
argument_list|<
name|Text
argument_list|,
name|byte
index|[]
argument_list|>
argument_list|()
decl_stmt|;
name|edits
operator|.
name|put
argument_list|(
name|column
argument_list|,
name|HLogEdit
operator|.
name|deleteBytes
operator|.
name|get
argument_list|()
argument_list|)
expr_stmt|;
for|for
control|(
name|HStoreKey
name|key
range|:
name|keys
control|)
block|{
name|update
argument_list|(
name|row
argument_list|,
name|key
operator|.
name|getTimestamp
argument_list|()
argument_list|,
name|edits
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
finally|finally
block|{
name|lock
operator|.
name|releaseReadLock
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**    * Private implementation.    *     * localput() is used for both puts and deletes. We just place the values    * into a per-row pending area, until a commit() or abort() call is received.    * (Or until the user's write-lock expires.)    *     * @param lockid    * @param targetCol    * @param val Value to enter into cell    * @throws IOException    */
name|void
name|localput
parameter_list|(
specifier|final
name|long
name|lockid
parameter_list|,
specifier|final
name|Text
name|targetCol
parameter_list|,
specifier|final
name|byte
index|[]
name|val
parameter_list|)
throws|throws
name|IOException
block|{
name|checkColumn
argument_list|(
name|targetCol
argument_list|)
expr_stmt|;
name|Text
name|row
init|=
name|getRowFromLock
argument_list|(
name|lockid
argument_list|)
decl_stmt|;
if|if
condition|(
name|row
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|LockException
argument_list|(
literal|"No write lock for lockid "
operator|+
name|lockid
argument_list|)
throw|;
block|}
comment|// This sync block makes localput() thread-safe when multiple
comment|// threads from the same client attempt an insert on the same
comment|// locked row (via lockid).
synchronized|synchronized
init|(
name|row
init|)
block|{
comment|// This check makes sure that another thread from the client
comment|// hasn't aborted/committed the write-operation.
if|if
condition|(
name|row
operator|!=
name|getRowFromLock
argument_list|(
name|lockid
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|LockException
argument_list|(
literal|"Locking error: put operation on lock "
operator|+
name|lockid
operator|+
literal|" unexpected aborted by another thread"
argument_list|)
throw|;
block|}
name|Long
name|lid
init|=
name|Long
operator|.
name|valueOf
argument_list|(
name|lockid
argument_list|)
decl_stmt|;
name|TreeMap
argument_list|<
name|Text
argument_list|,
name|byte
index|[]
argument_list|>
name|targets
init|=
name|this
operator|.
name|targetColumns
operator|.
name|get
argument_list|(
name|lid
argument_list|)
decl_stmt|;
if|if
condition|(
name|targets
operator|==
literal|null
condition|)
block|{
name|targets
operator|=
operator|new
name|TreeMap
argument_list|<
name|Text
argument_list|,
name|byte
index|[]
argument_list|>
argument_list|()
expr_stmt|;
name|this
operator|.
name|targetColumns
operator|.
name|put
argument_list|(
name|lid
argument_list|,
name|targets
argument_list|)
expr_stmt|;
block|}
name|targets
operator|.
name|put
argument_list|(
name|targetCol
argument_list|,
name|val
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Abort a pending set of writes. This dumps from memory all in-progress    * writes associated with the given row-lock.  These values have not yet    * been placed in memcache or written to the log.    *    * @param lockid lock id obtained from startUpdate    * @throws IOException    */
specifier|public
name|void
name|abort
parameter_list|(
name|long
name|lockid
parameter_list|)
throws|throws
name|IOException
block|{
name|Text
name|row
init|=
name|getRowFromLock
argument_list|(
name|lockid
argument_list|)
decl_stmt|;
if|if
condition|(
name|row
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|LockException
argument_list|(
literal|"No write lock for lockid "
operator|+
name|lockid
argument_list|)
throw|;
block|}
comment|// This sync block makes abort() thread-safe when multiple
comment|// threads from the same client attempt to operate on the same
comment|// locked row (via lockid).
synchronized|synchronized
init|(
name|row
init|)
block|{
comment|// This check makes sure another thread from the client
comment|// hasn't aborted/committed the write-operation.
if|if
condition|(
name|row
operator|!=
name|getRowFromLock
argument_list|(
name|lockid
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|LockException
argument_list|(
literal|"Locking error: abort() operation on lock "
operator|+
name|lockid
operator|+
literal|" unexpected aborted by another thread"
argument_list|)
throw|;
block|}
name|this
operator|.
name|targetColumns
operator|.
name|remove
argument_list|(
name|Long
operator|.
name|valueOf
argument_list|(
name|lockid
argument_list|)
argument_list|)
expr_stmt|;
name|releaseRowLock
argument_list|(
name|row
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Commit a pending set of writes to the memcache. This also results in    * writing to the change log.    *    * Once updates hit the change log, they are safe.  They will either be moved     * into an HStore in the future, or they will be recovered from the log.    * @param lockid Lock for row we're to commit.    * @param timestamp the time to associate with this change.    * @throws IOException    */
specifier|public
name|void
name|commit
parameter_list|(
specifier|final
name|long
name|lockid
parameter_list|,
specifier|final
name|long
name|timestamp
parameter_list|)
throws|throws
name|IOException
block|{
comment|// Remove the row from the pendingWrites list so
comment|// that repeated executions won't screw this up.
name|Text
name|row
init|=
name|getRowFromLock
argument_list|(
name|lockid
argument_list|)
decl_stmt|;
if|if
condition|(
name|row
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|LockException
argument_list|(
literal|"No write lock for lockid "
operator|+
name|lockid
argument_list|)
throw|;
block|}
comment|// This check makes sure that another thread from the client
comment|// hasn't aborted/committed the write-operation
synchronized|synchronized
init|(
name|row
init|)
block|{
name|Long
name|lid
init|=
name|Long
operator|.
name|valueOf
argument_list|(
name|lockid
argument_list|)
decl_stmt|;
name|update
argument_list|(
name|row
argument_list|,
name|timestamp
argument_list|,
name|this
operator|.
name|targetColumns
operator|.
name|get
argument_list|(
name|lid
argument_list|)
argument_list|)
expr_stmt|;
name|targetColumns
operator|.
name|remove
argument_list|(
name|lid
argument_list|)
expr_stmt|;
name|releaseRowLock
argument_list|(
name|row
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * This method for unit testing only.    * Does each operation individually so can do appropriate    * {@link HConstants#LATEST_TIMESTAMP} action.  Tries to mimic how    * {@link HRegionServer#batchUpdate(Text, long, org.apache.hadoop.hbase.io.BatchUpdate)}    * works when passed a timestamp of LATEST_TIMESTAMP.    * @param lockid Lock for row we're to commit.    * @throws IOException     * @throws IOException    * @see {@link #commit(long, long)}    */
name|void
name|commit
parameter_list|(
specifier|final
name|long
name|lockid
parameter_list|)
throws|throws
name|IOException
block|{
comment|// Remove the row from the pendingWrites list so
comment|// that repeated executions won't screw this up.
name|Text
name|row
init|=
name|getRowFromLock
argument_list|(
name|lockid
argument_list|)
decl_stmt|;
if|if
condition|(
name|row
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|LockException
argument_list|(
literal|"No write lock for lockid "
operator|+
name|lockid
argument_list|)
throw|;
block|}
comment|// This check makes sure that another thread from the client
comment|// hasn't aborted/committed the write-operation
synchronized|synchronized
init|(
name|row
init|)
block|{
name|Long
name|lid
init|=
name|Long
operator|.
name|valueOf
argument_list|(
name|lockid
argument_list|)
decl_stmt|;
name|TreeMap
argument_list|<
name|Text
argument_list|,
name|byte
index|[]
argument_list|>
name|updatesByColumn
init|=
name|this
operator|.
name|targetColumns
operator|.
name|get
argument_list|(
name|lid
argument_list|)
decl_stmt|;
comment|// Run updates one at a time so we can supply appropriate timestamp
name|long
name|now
init|=
name|System
operator|.
name|currentTimeMillis
argument_list|()
decl_stmt|;
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|Text
argument_list|,
name|byte
index|[]
argument_list|>
name|e
range|:
name|updatesByColumn
operator|.
name|entrySet
argument_list|()
control|)
block|{
if|if
condition|(
name|HLogEdit
operator|.
name|isDeleted
argument_list|(
name|e
operator|.
name|getValue
argument_list|()
argument_list|)
condition|)
block|{
comment|// Its a delete.  Delete latest.  deleteMultiple calls update for us.
comment|// Actually regets the row lock but since we already have it, should
comment|// be fine.
name|deleteMultiple
argument_list|(
name|row
argument_list|,
name|e
operator|.
name|getKey
argument_list|()
argument_list|,
name|LATEST_TIMESTAMP
argument_list|,
literal|1
argument_list|)
expr_stmt|;
continue|continue;
block|}
comment|// Must be a 'put'.
name|TreeMap
argument_list|<
name|Text
argument_list|,
name|byte
index|[]
argument_list|>
name|putEdit
init|=
operator|new
name|TreeMap
argument_list|<
name|Text
argument_list|,
name|byte
index|[]
argument_list|>
argument_list|()
decl_stmt|;
name|putEdit
operator|.
name|put
argument_list|(
name|e
operator|.
name|getKey
argument_list|()
argument_list|,
name|e
operator|.
name|getValue
argument_list|()
argument_list|)
expr_stmt|;
name|update
argument_list|(
name|row
argument_list|,
name|now
argument_list|,
name|putEdit
argument_list|)
expr_stmt|;
block|}
name|this
operator|.
name|targetColumns
operator|.
name|remove
argument_list|(
name|lid
argument_list|)
expr_stmt|;
name|releaseRowLock
argument_list|(
name|row
argument_list|)
expr_stmt|;
block|}
block|}
comment|/*     * Add updates first to the hlog and then add values to memcache.    * Warning: Assumption is caller has lock on passed in row.    * @param row Row to update.    * @param timestamp Timestamp to record the updates against    * @param updatesByColumn Cell updates by column    * @throws IOException    */
specifier|private
name|void
name|update
parameter_list|(
specifier|final
name|Text
name|row
parameter_list|,
specifier|final
name|long
name|timestamp
parameter_list|,
specifier|final
name|TreeMap
argument_list|<
name|Text
argument_list|,
name|byte
index|[]
argument_list|>
name|updatesByColumn
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|updatesByColumn
operator|==
literal|null
operator|||
name|updatesByColumn
operator|.
name|size
argument_list|()
operator|<=
literal|0
condition|)
block|{
return|return;
block|}
name|this
operator|.
name|log
operator|.
name|append
argument_list|(
name|regionInfo
operator|.
name|getRegionName
argument_list|()
argument_list|,
name|regionInfo
operator|.
name|getTableDesc
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|,
name|row
argument_list|,
name|updatesByColumn
argument_list|,
name|timestamp
argument_list|)
expr_stmt|;
name|this
operator|.
name|memcache
operator|.
name|add
argument_list|(
name|row
argument_list|,
name|updatesByColumn
argument_list|,
name|timestamp
argument_list|)
expr_stmt|;
block|}
comment|//////////////////////////////////////////////////////////////////////////////
comment|// Support code
comment|//////////////////////////////////////////////////////////////////////////////
comment|/** Make sure this is a valid row for the HRegion */
name|void
name|checkRow
parameter_list|(
name|Text
name|row
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
operator|(
operator|(
name|regionInfo
operator|.
name|getStartKey
argument_list|()
operator|.
name|getLength
argument_list|()
operator|==
literal|0
operator|)
operator|||
operator|(
name|regionInfo
operator|.
name|getStartKey
argument_list|()
operator|.
name|compareTo
argument_list|(
name|row
argument_list|)
operator|<=
literal|0
operator|)
operator|)
operator|&&
operator|(
operator|(
name|regionInfo
operator|.
name|getEndKey
argument_list|()
operator|.
name|getLength
argument_list|()
operator|==
literal|0
operator|)
operator|||
operator|(
name|regionInfo
operator|.
name|getEndKey
argument_list|()
operator|.
name|compareTo
argument_list|(
name|row
argument_list|)
operator|>
literal|0
operator|)
operator|)
condition|)
block|{
comment|// all's well
block|}
else|else
block|{
throw|throw
operator|new
name|WrongRegionException
argument_list|(
literal|"Requested row out of range for "
operator|+
literal|"HRegion "
operator|+
name|regionInfo
operator|.
name|getRegionName
argument_list|()
operator|+
literal|", startKey='"
operator|+
name|regionInfo
operator|.
name|getStartKey
argument_list|()
operator|+
literal|"', getEndKey()='"
operator|+
name|regionInfo
operator|.
name|getEndKey
argument_list|()
operator|+
literal|"', row='"
operator|+
name|row
operator|+
literal|"'"
argument_list|)
throw|;
block|}
block|}
comment|/**    * Make sure this is a valid column for the current table    * @param columnName    * @throws IOException    */
name|void
name|checkColumn
parameter_list|(
name|Text
name|columnName
parameter_list|)
throws|throws
name|IOException
block|{
name|Text
name|family
init|=
operator|new
name|Text
argument_list|(
name|HStoreKey
operator|.
name|extractFamily
argument_list|(
name|columnName
argument_list|)
operator|+
literal|":"
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|regionInfo
operator|.
name|getTableDesc
argument_list|()
operator|.
name|hasFamily
argument_list|(
name|family
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Requested column family "
operator|+
name|family
operator|+
literal|" does not exist in HRegion "
operator|+
name|regionInfo
operator|.
name|getRegionName
argument_list|()
operator|+
literal|" for table "
operator|+
name|regionInfo
operator|.
name|getTableDesc
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|)
throw|;
block|}
block|}
comment|/**    * Obtain a lock on the given row.  Blocks until success.    *    * I know it's strange to have two mappings:    *<pre>    *   ROWS  ==> LOCKS    *</pre>    * as well as    *<pre>    *   LOCKS ==> ROWS    *</pre>    *    * But it acts as a guard on the client; a miswritten client just can't    * submit the name of a row and start writing to it; it must know the correct    * lockid, which matches the lock list in memory.    *     *<p>It would be more memory-efficient to assume a correctly-written client,     * which maybe we'll do in the future.    *     * @param row Name of row to lock.    * @return The id of the held lock.    */
name|long
name|obtainRowLock
parameter_list|(
name|Text
name|row
parameter_list|)
throws|throws
name|IOException
block|{
name|checkRow
argument_list|(
name|row
argument_list|)
expr_stmt|;
synchronized|synchronized
init|(
name|rowsToLocks
init|)
block|{
while|while
condition|(
name|rowsToLocks
operator|.
name|get
argument_list|(
name|row
argument_list|)
operator|!=
literal|null
condition|)
block|{
try|try
block|{
name|rowsToLocks
operator|.
name|wait
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|ie
parameter_list|)
block|{
comment|// Empty
block|}
block|}
name|Long
name|lid
init|=
name|Long
operator|.
name|valueOf
argument_list|(
name|Math
operator|.
name|abs
argument_list|(
name|rand
operator|.
name|nextLong
argument_list|()
argument_list|)
argument_list|)
decl_stmt|;
name|rowsToLocks
operator|.
name|put
argument_list|(
name|row
argument_list|,
name|lid
argument_list|)
expr_stmt|;
name|locksToRows
operator|.
name|put
argument_list|(
name|lid
argument_list|,
name|row
argument_list|)
expr_stmt|;
name|rowsToLocks
operator|.
name|notifyAll
argument_list|()
expr_stmt|;
return|return
name|lid
operator|.
name|longValue
argument_list|()
return|;
block|}
block|}
name|Text
name|getRowFromLock
parameter_list|(
name|long
name|lockid
parameter_list|)
block|{
comment|// Pattern is that all access to rowsToLocks and/or to
comment|// locksToRows is via a lock on rowsToLocks.
synchronized|synchronized
init|(
name|rowsToLocks
init|)
block|{
return|return
name|locksToRows
operator|.
name|get
argument_list|(
name|Long
operator|.
name|valueOf
argument_list|(
name|lockid
argument_list|)
argument_list|)
return|;
block|}
block|}
comment|/**     * Release the row lock!    * @param lock Name of row whose lock we are to release    */
name|void
name|releaseRowLock
parameter_list|(
name|Text
name|row
parameter_list|)
block|{
synchronized|synchronized
init|(
name|rowsToLocks
init|)
block|{
name|long
name|lockid
init|=
name|rowsToLocks
operator|.
name|remove
argument_list|(
name|row
argument_list|)
operator|.
name|longValue
argument_list|()
decl_stmt|;
name|locksToRows
operator|.
name|remove
argument_list|(
name|Long
operator|.
name|valueOf
argument_list|(
name|lockid
argument_list|)
argument_list|)
expr_stmt|;
name|rowsToLocks
operator|.
name|notifyAll
argument_list|()
expr_stmt|;
block|}
block|}
specifier|private
name|void
name|waitOnRowLocks
parameter_list|()
block|{
synchronized|synchronized
init|(
name|this
operator|.
name|rowsToLocks
init|)
block|{
while|while
condition|(
name|this
operator|.
name|rowsToLocks
operator|.
name|size
argument_list|()
operator|>
literal|0
condition|)
block|{
try|try
block|{
name|this
operator|.
name|rowsToLocks
operator|.
name|wait
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
comment|// Catch. Let while test determine loop-end.
block|}
block|}
block|}
block|}
comment|/** {@inheritDoc} */
annotation|@
name|Override
specifier|public
name|String
name|toString
parameter_list|()
block|{
return|return
name|getRegionName
argument_list|()
operator|.
name|toString
argument_list|()
return|;
block|}
comment|/**    * HScanner is an iterator through a bunch of rows in an HRegion.    */
specifier|private
specifier|static
class|class
name|HScanner
implements|implements
name|HInternalScannerInterface
block|{
specifier|private
name|HInternalScannerInterface
index|[]
name|scanners
decl_stmt|;
specifier|private
name|TreeMap
argument_list|<
name|Text
argument_list|,
name|byte
index|[]
argument_list|>
index|[]
name|resultSets
decl_stmt|;
specifier|private
name|HStoreKey
index|[]
name|keys
decl_stmt|;
specifier|private
name|boolean
name|wildcardMatch
init|=
literal|false
decl_stmt|;
specifier|private
name|boolean
name|multipleMatchers
init|=
literal|false
decl_stmt|;
specifier|private
name|RowFilterInterface
name|dataFilter
decl_stmt|;
comment|/** Create an HScanner with a handle on many HStores. */
annotation|@
name|SuppressWarnings
argument_list|(
literal|"unchecked"
argument_list|)
name|HScanner
parameter_list|(
name|Text
index|[]
name|cols
parameter_list|,
name|Text
name|firstRow
parameter_list|,
name|long
name|timestamp
parameter_list|,
name|HMemcache
name|memcache
parameter_list|,
name|HStore
index|[]
name|stores
parameter_list|,
name|RowFilterInterface
name|filter
parameter_list|)
throws|throws
name|IOException
block|{
name|this
operator|.
name|dataFilter
operator|=
name|filter
expr_stmt|;
if|if
condition|(
literal|null
operator|!=
name|dataFilter
condition|)
block|{
name|dataFilter
operator|.
name|reset
argument_list|()
expr_stmt|;
block|}
name|this
operator|.
name|scanners
operator|=
operator|new
name|HInternalScannerInterface
index|[
name|stores
operator|.
name|length
operator|+
literal|1
index|]
expr_stmt|;
name|this
operator|.
name|resultSets
operator|=
operator|new
name|TreeMap
index|[
name|scanners
operator|.
name|length
index|]
expr_stmt|;
name|this
operator|.
name|keys
operator|=
operator|new
name|HStoreKey
index|[
name|scanners
operator|.
name|length
index|]
expr_stmt|;
comment|// Advance to the first key in each store.
comment|// All results will match the required column-set and scanTime.
comment|// NOTE: the memcache scanner should be the first scanner
try|try
block|{
name|HInternalScannerInterface
name|scanner
init|=
name|memcache
operator|.
name|getScanner
argument_list|(
name|timestamp
argument_list|,
name|cols
argument_list|,
name|firstRow
argument_list|)
decl_stmt|;
if|if
condition|(
name|scanner
operator|.
name|isWildcardScanner
argument_list|()
condition|)
block|{
name|this
operator|.
name|wildcardMatch
operator|=
literal|true
expr_stmt|;
block|}
if|if
condition|(
name|scanner
operator|.
name|isMultipleMatchScanner
argument_list|()
condition|)
block|{
name|this
operator|.
name|multipleMatchers
operator|=
literal|true
expr_stmt|;
block|}
name|scanners
index|[
literal|0
index|]
operator|=
name|scanner
expr_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|stores
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|scanner
operator|=
name|stores
index|[
name|i
index|]
operator|.
name|getScanner
argument_list|(
name|timestamp
argument_list|,
name|cols
argument_list|,
name|firstRow
argument_list|)
expr_stmt|;
if|if
condition|(
name|scanner
operator|.
name|isWildcardScanner
argument_list|()
condition|)
block|{
name|this
operator|.
name|wildcardMatch
operator|=
literal|true
expr_stmt|;
block|}
if|if
condition|(
name|scanner
operator|.
name|isMultipleMatchScanner
argument_list|()
condition|)
block|{
name|this
operator|.
name|multipleMatchers
operator|=
literal|true
expr_stmt|;
block|}
name|scanners
index|[
name|i
operator|+
literal|1
index|]
operator|=
name|scanner
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|this
operator|.
name|scanners
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|scanners
index|[
name|i
index|]
operator|!=
literal|null
condition|)
block|{
name|closeScanner
argument_list|(
name|i
argument_list|)
expr_stmt|;
block|}
block|}
throw|throw
name|e
throw|;
block|}
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|scanners
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|keys
index|[
name|i
index|]
operator|=
operator|new
name|HStoreKey
argument_list|()
expr_stmt|;
name|resultSets
index|[
name|i
index|]
operator|=
operator|new
name|TreeMap
argument_list|<
name|Text
argument_list|,
name|byte
index|[]
argument_list|>
argument_list|()
expr_stmt|;
if|if
condition|(
name|scanners
index|[
name|i
index|]
operator|!=
literal|null
operator|&&
operator|!
name|scanners
index|[
name|i
index|]
operator|.
name|next
argument_list|(
name|keys
index|[
name|i
index|]
argument_list|,
name|resultSets
index|[
name|i
index|]
argument_list|)
condition|)
block|{
name|closeScanner
argument_list|(
name|i
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|/** @return true if the scanner is a wild card scanner */
specifier|public
name|boolean
name|isWildcardScanner
parameter_list|()
block|{
return|return
name|wildcardMatch
return|;
block|}
comment|/** @return true if the scanner is a multiple match scanner */
specifier|public
name|boolean
name|isMultipleMatchScanner
parameter_list|()
block|{
return|return
name|multipleMatchers
return|;
block|}
comment|/** {@inheritDoc} */
specifier|public
name|boolean
name|next
parameter_list|(
name|HStoreKey
name|key
parameter_list|,
name|SortedMap
argument_list|<
name|Text
argument_list|,
name|byte
index|[]
argument_list|>
name|results
parameter_list|)
throws|throws
name|IOException
block|{
comment|// Filtered flag is set by filters.  If a cell has been 'filtered out'
comment|// -- i.e. it is not to be returned to the caller -- the flag is 'true'.
name|boolean
name|filtered
init|=
literal|true
decl_stmt|;
name|boolean
name|moreToFollow
init|=
literal|true
decl_stmt|;
while|while
condition|(
name|filtered
operator|&&
name|moreToFollow
condition|)
block|{
comment|// Find the lowest-possible key.
name|Text
name|chosenRow
init|=
literal|null
decl_stmt|;
name|long
name|chosenTimestamp
init|=
operator|-
literal|1
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|this
operator|.
name|keys
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|scanners
index|[
name|i
index|]
operator|!=
literal|null
operator|&&
operator|(
name|chosenRow
operator|==
literal|null
operator|||
operator|(
name|keys
index|[
name|i
index|]
operator|.
name|getRow
argument_list|()
operator|.
name|compareTo
argument_list|(
name|chosenRow
argument_list|)
operator|<
literal|0
operator|)
operator|||
operator|(
operator|(
name|keys
index|[
name|i
index|]
operator|.
name|getRow
argument_list|()
operator|.
name|compareTo
argument_list|(
name|chosenRow
argument_list|)
operator|==
literal|0
operator|)
operator|&&
operator|(
name|keys
index|[
name|i
index|]
operator|.
name|getTimestamp
argument_list|()
operator|>
name|chosenTimestamp
operator|)
operator|)
operator|)
condition|)
block|{
name|chosenRow
operator|=
operator|new
name|Text
argument_list|(
name|keys
index|[
name|i
index|]
operator|.
name|getRow
argument_list|()
argument_list|)
expr_stmt|;
name|chosenTimestamp
operator|=
name|keys
index|[
name|i
index|]
operator|.
name|getTimestamp
argument_list|()
expr_stmt|;
block|}
block|}
comment|// Filter whole row by row key?
name|filtered
operator|=
name|dataFilter
operator|!=
literal|null
condition|?
name|dataFilter
operator|.
name|filter
argument_list|(
name|chosenRow
argument_list|)
else|:
literal|false
expr_stmt|;
comment|// Store the key and results for each sub-scanner. Merge them as
comment|// appropriate.
if|if
condition|(
name|chosenTimestamp
operator|>=
literal|0
operator|&&
operator|!
name|filtered
condition|)
block|{
comment|// Here we are setting the passed in key with current row+timestamp
name|key
operator|.
name|setRow
argument_list|(
name|chosenRow
argument_list|)
expr_stmt|;
name|key
operator|.
name|setVersion
argument_list|(
name|chosenTimestamp
argument_list|)
expr_stmt|;
name|key
operator|.
name|setColumn
argument_list|(
name|HConstants
operator|.
name|EMPTY_TEXT
argument_list|)
expr_stmt|;
comment|// Keep list of deleted cell keys within this row.  We need this
comment|// because as we go through scanners, the delete record may be in an
comment|// early scanner and then the same record with a non-delete, non-null
comment|// value in a later. Without history of what we've seen, we'll return
comment|// deleted values. This List should not ever grow too large since we
comment|// are only keeping rows and columns that match those set on the
comment|// scanner and which have delete values.  If memory usage becomes a
comment|// problem, could redo as bloom filter.
name|List
argument_list|<
name|HStoreKey
argument_list|>
name|deletes
init|=
operator|new
name|ArrayList
argument_list|<
name|HStoreKey
argument_list|>
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|scanners
operator|.
name|length
operator|&&
operator|!
name|filtered
condition|;
name|i
operator|++
control|)
block|{
while|while
condition|(
operator|(
name|scanners
index|[
name|i
index|]
operator|!=
literal|null
operator|&&
operator|!
name|filtered
operator|&&
name|moreToFollow
operator|)
operator|&&
operator|(
name|keys
index|[
name|i
index|]
operator|.
name|getRow
argument_list|()
operator|.
name|compareTo
argument_list|(
name|chosenRow
argument_list|)
operator|==
literal|0
operator|)
condition|)
block|{
comment|// If we are doing a wild card match or there are multiple
comment|// matchers per column, we need to scan all the older versions of
comment|// this row to pick up the rest of the family members
if|if
condition|(
operator|!
name|wildcardMatch
operator|&&
operator|!
name|multipleMatchers
operator|&&
operator|(
name|keys
index|[
name|i
index|]
operator|.
name|getTimestamp
argument_list|()
operator|!=
name|chosenTimestamp
operator|)
condition|)
block|{
break|break;
block|}
comment|// Filter out null criteria columns that are not null
if|if
condition|(
name|dataFilter
operator|!=
literal|null
condition|)
block|{
name|filtered
operator|=
name|dataFilter
operator|.
name|filterNotNull
argument_list|(
name|resultSets
index|[
name|i
index|]
argument_list|)
expr_stmt|;
block|}
comment|// NOTE: We used to do results.putAll(resultSets[i]);
comment|// but this had the effect of overwriting newer
comment|// values with older ones. So now we only insert
comment|// a result if the map does not contain the key.
name|HStoreKey
name|hsk
init|=
operator|new
name|HStoreKey
argument_list|(
name|key
operator|.
name|getRow
argument_list|()
argument_list|,
name|EMPTY_TEXT
argument_list|,
name|key
operator|.
name|getTimestamp
argument_list|()
argument_list|)
decl_stmt|;
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|Text
argument_list|,
name|byte
index|[]
argument_list|>
name|e
range|:
name|resultSets
index|[
name|i
index|]
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|hsk
operator|.
name|setColumn
argument_list|(
name|e
operator|.
name|getKey
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|HLogEdit
operator|.
name|isDeleted
argument_list|(
name|e
operator|.
name|getValue
argument_list|()
argument_list|)
condition|)
block|{
if|if
condition|(
operator|!
name|deletes
operator|.
name|contains
argument_list|(
name|hsk
argument_list|)
condition|)
block|{
comment|// Key changes as we cycle the for loop so add a copy to
comment|// the set of deletes.
name|deletes
operator|.
name|add
argument_list|(
operator|new
name|HStoreKey
argument_list|(
name|hsk
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
elseif|else
if|if
condition|(
operator|!
name|deletes
operator|.
name|contains
argument_list|(
name|hsk
argument_list|)
operator|&&
operator|!
name|filtered
operator|&&
name|moreToFollow
operator|&&
operator|!
name|results
operator|.
name|containsKey
argument_list|(
name|e
operator|.
name|getKey
argument_list|()
argument_list|)
condition|)
block|{
if|if
condition|(
name|dataFilter
operator|!=
literal|null
condition|)
block|{
comment|// Filter whole row by column data?
name|filtered
operator|=
name|dataFilter
operator|.
name|filter
argument_list|(
name|chosenRow
argument_list|,
name|e
operator|.
name|getKey
argument_list|()
argument_list|,
name|e
operator|.
name|getValue
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|filtered
condition|)
block|{
name|results
operator|.
name|clear
argument_list|()
expr_stmt|;
break|break;
block|}
block|}
name|results
operator|.
name|put
argument_list|(
name|e
operator|.
name|getKey
argument_list|()
argument_list|,
name|e
operator|.
name|getValue
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
name|resultSets
index|[
name|i
index|]
operator|.
name|clear
argument_list|()
expr_stmt|;
if|if
condition|(
operator|!
name|scanners
index|[
name|i
index|]
operator|.
name|next
argument_list|(
name|keys
index|[
name|i
index|]
argument_list|,
name|resultSets
index|[
name|i
index|]
argument_list|)
condition|)
block|{
name|closeScanner
argument_list|(
name|i
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|scanners
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
comment|// If the current scanner is non-null AND has a lower-or-equal
comment|// row label, then its timestamp is bad. We need to advance it.
while|while
condition|(
operator|(
name|scanners
index|[
name|i
index|]
operator|!=
literal|null
operator|)
operator|&&
operator|(
name|keys
index|[
name|i
index|]
operator|.
name|getRow
argument_list|()
operator|.
name|compareTo
argument_list|(
name|chosenRow
argument_list|)
operator|<=
literal|0
operator|)
condition|)
block|{
name|resultSets
index|[
name|i
index|]
operator|.
name|clear
argument_list|()
expr_stmt|;
if|if
condition|(
operator|!
name|scanners
index|[
name|i
index|]
operator|.
name|next
argument_list|(
name|keys
index|[
name|i
index|]
argument_list|,
name|resultSets
index|[
name|i
index|]
argument_list|)
condition|)
block|{
name|closeScanner
argument_list|(
name|i
argument_list|)
expr_stmt|;
block|}
block|}
block|}
name|moreToFollow
operator|=
name|chosenTimestamp
operator|>=
literal|0
expr_stmt|;
if|if
condition|(
name|dataFilter
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
name|moreToFollow
condition|)
block|{
name|dataFilter
operator|.
name|rowProcessed
argument_list|(
name|filtered
argument_list|,
name|chosenRow
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|dataFilter
operator|.
name|filterAllRemaining
argument_list|()
condition|)
block|{
name|moreToFollow
operator|=
literal|false
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"page limit"
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
if|if
condition|(
name|this
operator|.
name|dataFilter
operator|!=
literal|null
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"ROWKEY = "
operator|+
name|chosenRow
operator|+
literal|", FILTERED = "
operator|+
name|filtered
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|results
operator|.
name|size
argument_list|()
operator|<=
literal|0
operator|&&
operator|!
name|filtered
condition|)
block|{
comment|// There were no results found for this row.  Marked it as
comment|// 'filtered'-out otherwise we will not move on to the next row.
name|filtered
operator|=
literal|true
expr_stmt|;
block|}
block|}
comment|// If we got no results, then there is no more to follow.
if|if
condition|(
name|results
operator|==
literal|null
operator|||
name|results
operator|.
name|size
argument_list|()
operator|<=
literal|0
condition|)
block|{
name|moreToFollow
operator|=
literal|false
expr_stmt|;
block|}
comment|// Make sure scanners closed if no more results
if|if
condition|(
operator|!
name|moreToFollow
condition|)
block|{
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|scanners
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
literal|null
operator|!=
name|scanners
index|[
name|i
index|]
condition|)
block|{
name|closeScanner
argument_list|(
name|i
argument_list|)
expr_stmt|;
block|}
block|}
block|}
return|return
name|moreToFollow
return|;
block|}
comment|/** Shut down a single scanner */
name|void
name|closeScanner
parameter_list|(
name|int
name|i
parameter_list|)
block|{
try|try
block|{
try|try
block|{
name|scanners
index|[
name|i
index|]
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failed closeing scanner "
operator|+
name|i
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
block|}
finally|finally
block|{
name|scanners
index|[
name|i
index|]
operator|=
literal|null
expr_stmt|;
name|keys
index|[
name|i
index|]
operator|=
literal|null
expr_stmt|;
name|resultSets
index|[
name|i
index|]
operator|=
literal|null
expr_stmt|;
block|}
block|}
comment|/**      * {@inheritDoc}      */
specifier|public
name|void
name|close
parameter_list|()
block|{
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|scanners
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|scanners
index|[
name|i
index|]
operator|!=
literal|null
condition|)
block|{
name|closeScanner
argument_list|(
name|i
argument_list|)
expr_stmt|;
block|}
block|}
block|}
specifier|public
name|Iterator
argument_list|<
name|Entry
argument_list|<
name|HStoreKey
argument_list|,
name|SortedMap
argument_list|<
name|Text
argument_list|,
name|byte
index|[]
argument_list|>
argument_list|>
argument_list|>
name|iterator
parameter_list|()
block|{
throw|throw
operator|new
name|UnsupportedOperationException
argument_list|(
literal|"Unimplemented serverside. "
operator|+
literal|"next(HStoreKey, StortedMap(...) is more efficient"
argument_list|)
throw|;
block|}
block|}
comment|// Utility methods
comment|/**    * Convenience method creating new HRegions. Used by createTable and by the    * bootstrap code in the HMaster constructor.    * Note, this method creates an {@link HLog} for the created region. It    * needs to be closed explicitly.  Use {@link HRegion#getLog()} to get    * access.    * @param info Info for region to create.    * @param rootDir Root directory for HBase instance    * @param conf    * @param initialFiles InitialFiles to pass new HRegion. Pass null if none.    * @return new HRegion    *     * @throws IOException    */
specifier|static
name|HRegion
name|createHRegion
parameter_list|(
specifier|final
name|HRegionInfo
name|info
parameter_list|,
specifier|final
name|Path
name|rootDir
parameter_list|,
specifier|final
name|Configuration
name|conf
parameter_list|,
specifier|final
name|Path
name|initialFiles
parameter_list|)
throws|throws
name|IOException
block|{
name|Path
name|regionDir
init|=
name|HRegion
operator|.
name|getRegionDir
argument_list|(
name|rootDir
argument_list|,
name|HRegionInfo
operator|.
name|encodeRegionName
argument_list|(
name|info
operator|.
name|getRegionName
argument_list|()
argument_list|)
argument_list|)
decl_stmt|;
name|FileSystem
name|fs
init|=
name|FileSystem
operator|.
name|get
argument_list|(
name|conf
argument_list|)
decl_stmt|;
name|fs
operator|.
name|mkdirs
argument_list|(
name|regionDir
argument_list|)
expr_stmt|;
return|return
operator|new
name|HRegion
argument_list|(
name|rootDir
argument_list|,
operator|new
name|HLog
argument_list|(
name|fs
argument_list|,
operator|new
name|Path
argument_list|(
name|regionDir
argument_list|,
name|HREGION_LOGDIR_NAME
argument_list|)
argument_list|,
name|conf
argument_list|)
argument_list|,
name|fs
argument_list|,
name|conf
argument_list|,
name|info
argument_list|,
name|initialFiles
argument_list|)
return|;
block|}
comment|/**    * Inserts a new region's meta information into the passed    *<code>meta</code> region. Used by the HMaster bootstrap code adding    * new table to ROOT table.    *     * @param meta META HRegion to be updated    * @param r HRegion to add to<code>meta</code>    *    * @throws IOException    */
specifier|static
name|void
name|addRegionToMETA
parameter_list|(
name|HRegion
name|meta
parameter_list|,
name|HRegion
name|r
parameter_list|)
throws|throws
name|IOException
block|{
comment|// The row key is the region name
name|long
name|writeid
init|=
name|meta
operator|.
name|startUpdate
argument_list|(
name|r
operator|.
name|getRegionName
argument_list|()
argument_list|)
decl_stmt|;
name|meta
operator|.
name|put
argument_list|(
name|writeid
argument_list|,
name|COL_REGIONINFO
argument_list|,
name|Writables
operator|.
name|getBytes
argument_list|(
name|r
operator|.
name|getRegionInfo
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
name|meta
operator|.
name|commit
argument_list|(
name|writeid
argument_list|,
name|System
operator|.
name|currentTimeMillis
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|/**    * Deletes all the files for a HRegion    *     * @param fs the file system object    * @param baseDirectory base directory for HBase    * @param name region file name    * @throws IOException    * @return True if deleted.    */
specifier|static
name|boolean
name|deleteRegion
parameter_list|(
name|FileSystem
name|fs
parameter_list|,
name|Path
name|baseDirectory
parameter_list|,
name|String
name|name
parameter_list|)
throws|throws
name|IOException
block|{
name|Path
name|p
init|=
name|HRegion
operator|.
name|getRegionDir
argument_list|(
name|fs
operator|.
name|makeQualified
argument_list|(
name|baseDirectory
argument_list|)
argument_list|,
name|name
argument_list|)
decl_stmt|;
return|return
name|fs
operator|.
name|delete
argument_list|(
name|p
argument_list|)
return|;
block|}
comment|/**    * Computes the Path of the HRegion    *     * @param dir hbase home directory    * @param name region file name    * @return Path of HRegion directory    */
specifier|public
specifier|static
name|Path
name|getRegionDir
parameter_list|(
specifier|final
name|Path
name|dir
parameter_list|,
specifier|final
name|String
name|name
parameter_list|)
block|{
return|return
operator|new
name|Path
argument_list|(
name|dir
argument_list|,
operator|new
name|Path
argument_list|(
name|HREGIONDIR_PREFIX
operator|+
name|name
argument_list|)
argument_list|)
return|;
block|}
block|}
end_class

end_unit

