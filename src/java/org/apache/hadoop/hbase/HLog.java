begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Copyright 2007 The Apache Software Foundation  *  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
package|;
end_package

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|Log
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|LogFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|*
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|SequenceFile
operator|.
name|Reader
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|*
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|*
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|*
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|*
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|atomic
operator|.
name|AtomicInteger
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|atomic
operator|.
name|AtomicLong
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|locks
operator|.
name|Lock
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|locks
operator|.
name|ReentrantLock
import|;
end_import

begin_comment
comment|/**  * HLog stores all the edits to the HStore.  *   * It performs logfile-rolling, so external callers are not aware that the   * underlying file is being rolled.  *  *<p>A single HLog is used by several HRegions simultaneously.  *   *<p>Each HRegion is identified by a unique long<code>int</code>. HRegions do  * not need to declare themselves before using the HLog; they simply include  * their HRegion-id in the<code>append</code> or   *<code>completeCacheFlush</code> calls.  *  *<p>An HLog consists of multiple on-disk files, which have a chronological  * order. As data is flushed to other (better) on-disk structures, the log  * becomes obsolete.  We can destroy all the log messages for a given  * HRegion-id up to the most-recent CACHEFLUSH message from that HRegion.  *  *<p>It's only practical to delete entire files.  Thus, we delete an entire   * on-disk file F when all of the messages in F have a log-sequence-id that's   * older (smaller) than the most-recent CACHEFLUSH message for every HRegion   * that has a message in F.  *   *<p>synchronized methods can never execute in parallel. However, between the  * start of a cache flush and the completion point, appends are allowed but log  * rolling is not. To prevent log rolling taking place during this period, a  * separate reentrant lock is used.  *   *<p>TODO: Vuk Ercegovac also pointed out that keeping HBase HRegion edit logs  * in HDFS is currently flawed. HBase writes edits to logs and to a memcache.  * The 'atomic' write to the log is meant to serve as insurance against  * abnormal RegionServer exit: on startup, the log is rerun to reconstruct an  * HRegion's last wholesome state. But files in HDFS do not 'exist' until they  * are cleanly closed -- something that will not happen if RegionServer exits  * without running its 'close'.  */
end_comment

begin_class
specifier|public
class|class
name|HLog
implements|implements
name|HConstants
block|{
specifier|private
specifier|static
specifier|final
name|Log
name|LOG
init|=
name|LogFactory
operator|.
name|getLog
argument_list|(
name|HLog
operator|.
name|class
argument_list|)
decl_stmt|;
specifier|static
specifier|final
name|String
name|HLOG_DATFILE
init|=
literal|"hlog.dat."
decl_stmt|;
specifier|static
specifier|final
name|Text
name|METACOLUMN
init|=
operator|new
name|Text
argument_list|(
literal|"METACOLUMN:"
argument_list|)
decl_stmt|;
specifier|static
specifier|final
name|Text
name|METAROW
init|=
operator|new
name|Text
argument_list|(
literal|"METAROW"
argument_list|)
decl_stmt|;
name|FileSystem
name|fs
decl_stmt|;
name|Path
name|dir
decl_stmt|;
name|Configuration
name|conf
decl_stmt|;
name|SequenceFile
operator|.
name|Writer
name|writer
decl_stmt|;
name|TreeMap
argument_list|<
name|Long
argument_list|,
name|Path
argument_list|>
name|outputfiles
init|=
operator|new
name|TreeMap
argument_list|<
name|Long
argument_list|,
name|Path
argument_list|>
argument_list|()
decl_stmt|;
name|HashMap
argument_list|<
name|Text
argument_list|,
name|Long
argument_list|>
name|lastSeqWritten
init|=
operator|new
name|HashMap
argument_list|<
name|Text
argument_list|,
name|Long
argument_list|>
argument_list|()
decl_stmt|;
specifier|volatile
name|boolean
name|closed
init|=
literal|false
decl_stmt|;
name|AtomicLong
name|logSeqNum
init|=
operator|new
name|AtomicLong
argument_list|(
literal|0
argument_list|)
decl_stmt|;
specifier|volatile
name|long
name|filenum
init|=
literal|0
decl_stmt|;
name|AtomicInteger
name|numEntries
init|=
operator|new
name|AtomicInteger
argument_list|(
literal|0
argument_list|)
decl_stmt|;
comment|// This lock prevents starting a log roll during a cache flush.
comment|// synchronized is insufficient because a cache flush spans two method calls.
specifier|private
specifier|final
name|Lock
name|cacheFlushLock
init|=
operator|new
name|ReentrantLock
argument_list|()
decl_stmt|;
comment|/**    * Split up a bunch of log files, that are no longer being written to,    * into new files, one per region.  Delete the old log files when finished.    *     * @param rootDir Root directory of the HBase instance    * @param srcDir Directory of log files to split:    * e.g.<code>${ROOTDIR}/log_HOST_PORT</code>    * @param fs FileSystem    * @param conf HBaseConfiguration    * @throws IOException    */
specifier|static
name|void
name|splitLog
parameter_list|(
name|Path
name|rootDir
parameter_list|,
name|Path
name|srcDir
parameter_list|,
name|FileSystem
name|fs
parameter_list|,
name|Configuration
name|conf
parameter_list|)
throws|throws
name|IOException
block|{
name|Path
name|logfiles
index|[]
init|=
name|fs
operator|.
name|listPaths
argument_list|(
operator|new
name|Path
index|[]
block|{
name|srcDir
block|}
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"splitting "
operator|+
name|logfiles
operator|.
name|length
operator|+
literal|" log(s) in "
operator|+
name|srcDir
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
name|HashMap
argument_list|<
name|Text
argument_list|,
name|SequenceFile
operator|.
name|Writer
argument_list|>
name|logWriters
init|=
operator|new
name|HashMap
argument_list|<
name|Text
argument_list|,
name|SequenceFile
operator|.
name|Writer
argument_list|>
argument_list|()
decl_stmt|;
try|try
block|{
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|logfiles
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Splitting "
operator|+
name|logfiles
index|[
name|i
index|]
argument_list|)
expr_stmt|;
block|}
comment|// Check for empty file.
if|if
condition|(
name|fs
operator|.
name|getFileStatus
argument_list|(
name|logfiles
index|[
name|i
index|]
argument_list|)
operator|.
name|getLen
argument_list|()
operator|<=
literal|0
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Skipping "
operator|+
name|logfiles
index|[
name|i
index|]
operator|.
name|toString
argument_list|()
operator|+
literal|" because zero length"
argument_list|)
expr_stmt|;
continue|continue;
block|}
name|SequenceFile
operator|.
name|Reader
name|in
init|=
operator|new
name|SequenceFile
operator|.
name|Reader
argument_list|(
name|fs
argument_list|,
name|logfiles
index|[
name|i
index|]
argument_list|,
name|conf
argument_list|)
decl_stmt|;
try|try
block|{
name|HLogKey
name|key
init|=
operator|new
name|HLogKey
argument_list|()
decl_stmt|;
name|HLogEdit
name|val
init|=
operator|new
name|HLogEdit
argument_list|()
decl_stmt|;
while|while
condition|(
name|in
operator|.
name|next
argument_list|(
name|key
argument_list|,
name|val
argument_list|)
condition|)
block|{
name|Text
name|regionName
init|=
name|key
operator|.
name|getRegionName
argument_list|()
decl_stmt|;
name|SequenceFile
operator|.
name|Writer
name|w
init|=
name|logWriters
operator|.
name|get
argument_list|(
name|regionName
argument_list|)
decl_stmt|;
if|if
condition|(
name|w
operator|==
literal|null
condition|)
block|{
name|Path
name|logfile
init|=
operator|new
name|Path
argument_list|(
name|HRegion
operator|.
name|getRegionDir
argument_list|(
name|rootDir
argument_list|,
name|regionName
argument_list|)
argument_list|,
name|HREGION_OLDLOGFILE_NAME
argument_list|)
decl_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"getting new log file writer for path "
operator|+
name|logfile
argument_list|)
expr_stmt|;
block|}
name|w
operator|=
name|SequenceFile
operator|.
name|createWriter
argument_list|(
name|fs
argument_list|,
name|conf
argument_list|,
name|logfile
argument_list|,
name|HLogKey
operator|.
name|class
argument_list|,
name|HLogEdit
operator|.
name|class
argument_list|)
expr_stmt|;
name|logWriters
operator|.
name|put
argument_list|(
name|regionName
argument_list|,
name|w
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Edit "
operator|+
name|key
operator|.
name|toString
argument_list|()
operator|+
literal|"="
operator|+
name|val
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|w
operator|.
name|append
argument_list|(
name|key
argument_list|,
name|val
argument_list|)
expr_stmt|;
block|}
block|}
finally|finally
block|{
name|in
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
block|}
block|}
finally|finally
block|{
for|for
control|(
name|SequenceFile
operator|.
name|Writer
name|w
range|:
name|logWriters
operator|.
name|values
argument_list|()
control|)
block|{
name|w
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
block|}
if|if
condition|(
name|fs
operator|.
name|exists
argument_list|(
name|srcDir
argument_list|)
condition|)
block|{
if|if
condition|(
operator|!
name|fs
operator|.
name|delete
argument_list|(
name|srcDir
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Cannot delete: "
operator|+
name|srcDir
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|FileUtil
operator|.
name|fullyDelete
argument_list|(
operator|new
name|File
argument_list|(
name|srcDir
operator|.
name|toString
argument_list|()
argument_list|)
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Cannot delete: "
operator|+
name|srcDir
argument_list|)
throw|;
block|}
block|}
block|}
name|LOG
operator|.
name|info
argument_list|(
literal|"log file splitting completed for "
operator|+
name|srcDir
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|/**    * Create an edit log at the given<code>dir</code> location.    *    * You should never have to load an existing log.  If there is a log    * at startup, it should have already been processed and deleted by     * the time the HLog object is started up.    *     * @param fs    * @param dir    * @param conf    * @throws IOException    */
name|HLog
parameter_list|(
name|FileSystem
name|fs
parameter_list|,
name|Path
name|dir
parameter_list|,
name|Configuration
name|conf
parameter_list|)
throws|throws
name|IOException
block|{
name|this
operator|.
name|fs
operator|=
name|fs
expr_stmt|;
name|this
operator|.
name|dir
operator|=
name|dir
expr_stmt|;
name|this
operator|.
name|conf
operator|=
name|conf
expr_stmt|;
if|if
condition|(
name|fs
operator|.
name|exists
argument_list|(
name|dir
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Target HLog directory already exists: "
operator|+
name|dir
argument_list|)
throw|;
block|}
name|fs
operator|.
name|mkdirs
argument_list|(
name|dir
argument_list|)
expr_stmt|;
name|rollWriter
argument_list|()
expr_stmt|;
block|}
comment|/**    * Called by HRegionServer when it opens a new region to ensure that log    * sequence numbers are always greater than the latest sequence number of    * the region being brought on-line.    *     * @param newvalue    */
specifier|synchronized
name|void
name|setSequenceNumber
parameter_list|(
name|long
name|newvalue
parameter_list|)
block|{
if|if
condition|(
name|newvalue
operator|>
name|logSeqNum
operator|.
name|get
argument_list|()
condition|)
block|{
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"changing sequence number from "
operator|+
name|logSeqNum
operator|+
literal|" to "
operator|+
name|newvalue
argument_list|)
expr_stmt|;
block|}
name|logSeqNum
operator|.
name|set
argument_list|(
name|newvalue
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Roll the log writer.  That is, start writing log messages to a new file.    *     * Because a log cannot be rolled during a cache flush, and a cache flush    * spans two method calls, a special lock needs to be obtained so that a    * cache flush cannot start when the log is being rolled and the log cannot    * be rolled during a cache flush.    *     * Note that this method cannot be synchronized because it is possible that    * startCacheFlush runs, obtaining the cacheFlushLock, then this method could    * start which would obtain the lock on this but block on obtaining the     * cacheFlushLock and then completeCacheFlush could be called which would     * wait for the lock on this and consequently never release the cacheFlushLock    *     * @throws IOException    */
name|void
name|rollWriter
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|closed
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Cannot roll log; log is closed"
argument_list|)
throw|;
block|}
name|cacheFlushLock
operator|.
name|lock
argument_list|()
expr_stmt|;
comment|// prevent cache flushes
try|try
block|{
comment|// Now that we have locked out cache flushes, lock this to prevent other
comment|// changes.
synchronized|synchronized
init|(
name|this
init|)
block|{
if|if
condition|(
name|writer
operator|!=
literal|null
condition|)
block|{
comment|// Close the current writer (if any), get a new one.
name|writer
operator|.
name|close
argument_list|()
expr_stmt|;
name|Path
name|p
init|=
name|computeFilename
argument_list|(
name|filenum
operator|-
literal|1
argument_list|)
decl_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Closing current log writer "
operator|+
name|p
operator|.
name|toString
argument_list|()
operator|+
literal|" to get a new one"
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|filenum
operator|>
literal|0
condition|)
block|{
name|outputfiles
operator|.
name|put
argument_list|(
name|logSeqNum
operator|.
name|get
argument_list|()
operator|-
literal|1
argument_list|,
name|p
argument_list|)
expr_stmt|;
block|}
block|}
name|Path
name|newPath
init|=
name|computeFilename
argument_list|(
name|filenum
operator|++
argument_list|)
decl_stmt|;
name|this
operator|.
name|writer
operator|=
name|SequenceFile
operator|.
name|createWriter
argument_list|(
name|fs
argument_list|,
name|conf
argument_list|,
name|newPath
argument_list|,
name|HLogKey
operator|.
name|class
argument_list|,
name|HLogEdit
operator|.
name|class
argument_list|)
expr_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"new log writer created at "
operator|+
name|newPath
argument_list|)
expr_stmt|;
block|}
comment|// Can we delete any of the old log files?
comment|// First, compute the oldest relevant log operation
comment|// over all the regions.
name|long
name|oldestOutstandingSeqNum
init|=
name|Long
operator|.
name|MAX_VALUE
decl_stmt|;
for|for
control|(
name|Long
name|l
range|:
name|lastSeqWritten
operator|.
name|values
argument_list|()
control|)
block|{
name|long
name|curSeqNum
init|=
name|l
operator|.
name|longValue
argument_list|()
decl_stmt|;
if|if
condition|(
name|curSeqNum
operator|<
name|oldestOutstandingSeqNum
condition|)
block|{
name|oldestOutstandingSeqNum
operator|=
name|curSeqNum
expr_stmt|;
block|}
block|}
comment|// Get the set of all sequence numbers that are older than the oldest
comment|// pending region operation
name|TreeSet
argument_list|<
name|Long
argument_list|>
name|sequenceNumbers
init|=
operator|new
name|TreeSet
argument_list|<
name|Long
argument_list|>
argument_list|()
decl_stmt|;
name|sequenceNumbers
operator|.
name|addAll
argument_list|(
name|outputfiles
operator|.
name|headMap
argument_list|(
name|oldestOutstandingSeqNum
argument_list|)
operator|.
name|keySet
argument_list|()
argument_list|)
expr_stmt|;
comment|// Remove all files with a final ID that's older than the oldest
comment|// pending region-operation.
for|for
control|(
name|Long
name|seq
range|:
name|sequenceNumbers
control|)
block|{
name|Path
name|p
init|=
name|outputfiles
operator|.
name|remove
argument_list|(
name|seq
argument_list|)
decl_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"removing old log file "
operator|+
name|p
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|fs
operator|.
name|delete
argument_list|(
name|p
argument_list|)
expr_stmt|;
block|}
name|this
operator|.
name|numEntries
operator|.
name|set
argument_list|(
literal|0
argument_list|)
expr_stmt|;
block|}
block|}
finally|finally
block|{
name|cacheFlushLock
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**    * This is a convenience method that computes a new filename with    * a given file-number.    */
name|Path
name|computeFilename
parameter_list|(
specifier|final
name|long
name|fn
parameter_list|)
block|{
return|return
operator|new
name|Path
argument_list|(
name|dir
argument_list|,
name|HLOG_DATFILE
operator|+
name|String
operator|.
name|format
argument_list|(
literal|"%1$03d"
argument_list|,
name|fn
argument_list|)
argument_list|)
return|;
block|}
comment|/**    * Shut down the log and delete the log directory    * @throws IOException    */
specifier|synchronized
name|void
name|closeAndDelete
parameter_list|()
throws|throws
name|IOException
block|{
name|close
argument_list|()
expr_stmt|;
name|fs
operator|.
name|delete
argument_list|(
name|dir
argument_list|)
expr_stmt|;
block|}
comment|/**    * Shut down the log.    * @throws IOException    */
specifier|synchronized
name|void
name|close
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"closing log writer in "
operator|+
name|this
operator|.
name|dir
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|this
operator|.
name|writer
operator|.
name|close
argument_list|()
expr_stmt|;
name|this
operator|.
name|closed
operator|=
literal|true
expr_stmt|;
block|}
comment|/**    * Append a set of edits to the log. Log edits are keyed by regionName,    * rowname, and log-sequence-id.    *    * Later, if we sort by these keys, we obtain all the relevant edits for    * a given key-range of the HRegion (TODO).  Any edits that do not have a    * matching {@link HConstants#COMPLETE_CACHEFLUSH} message can be discarded.    *    *<p>Logs cannot be restarted once closed, or once the HLog process dies.    * Each time the HLog starts, it must create a new log.  This means that    * other systems should process the log appropriately upon each startup    * (and prior to initializing HLog).    *    * synchronized prevents appends during the completion of a cache flush or    * for the duration of a log roll.    *     * @param regionName    * @param tableName    * @param row    * @param columns    * @param timestamp    * @throws IOException    */
specifier|synchronized
name|void
name|append
parameter_list|(
name|Text
name|regionName
parameter_list|,
name|Text
name|tableName
parameter_list|,
name|Text
name|row
parameter_list|,
name|TreeMap
argument_list|<
name|Text
argument_list|,
name|byte
index|[]
argument_list|>
name|columns
parameter_list|,
name|long
name|timestamp
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|closed
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Cannot append; log is closed"
argument_list|)
throw|;
block|}
name|long
name|seqNum
index|[]
init|=
name|obtainSeqNum
argument_list|(
name|columns
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
comment|// The 'lastSeqWritten' map holds the sequence number of the most recent
comment|// write for each region. When the cache is flushed, the entry for the
comment|// region being flushed is removed if the sequence number of the flush
comment|// is greater than or equal to the value in lastSeqWritten
name|lastSeqWritten
operator|.
name|put
argument_list|(
name|regionName
argument_list|,
name|seqNum
index|[
name|seqNum
operator|.
name|length
operator|-
literal|1
index|]
argument_list|)
expr_stmt|;
name|int
name|counter
init|=
literal|0
decl_stmt|;
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|Text
argument_list|,
name|byte
index|[]
argument_list|>
name|es
range|:
name|columns
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|HLogKey
name|logKey
init|=
operator|new
name|HLogKey
argument_list|(
name|regionName
argument_list|,
name|tableName
argument_list|,
name|row
argument_list|,
name|seqNum
index|[
name|counter
operator|++
index|]
argument_list|)
decl_stmt|;
name|HLogEdit
name|logEdit
init|=
operator|new
name|HLogEdit
argument_list|(
name|es
operator|.
name|getKey
argument_list|()
argument_list|,
name|es
operator|.
name|getValue
argument_list|()
argument_list|,
name|timestamp
argument_list|)
decl_stmt|;
name|writer
operator|.
name|append
argument_list|(
name|logKey
argument_list|,
name|logEdit
argument_list|)
expr_stmt|;
name|numEntries
operator|.
name|getAndIncrement
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**    * @return How many items have been added to the log    *     * Because numEntries is an AtomicInteger, no locking is required.    */
name|int
name|getNumEntries
parameter_list|()
block|{
return|return
name|numEntries
operator|.
name|get
argument_list|()
return|;
block|}
comment|/**    * Obtain a log sequence number.    *     * Because it is only called from a synchronized method, no additional locking    * is required.    */
specifier|private
name|long
name|obtainSeqNum
parameter_list|()
block|{
return|return
name|logSeqNum
operator|.
name|getAndIncrement
argument_list|()
return|;
block|}
comment|/**    * Obtain a specified number of sequence numbers    *     * Because it is only called from a synchronized method, no additional locking    * is required.    *     * @param num - number of sequence numbers to obtain    * @return - array of sequence numbers    */
specifier|private
name|long
index|[]
name|obtainSeqNum
parameter_list|(
name|int
name|num
parameter_list|)
block|{
name|long
name|sequenceNumber
init|=
name|logSeqNum
operator|.
name|getAndAdd
argument_list|(
name|num
argument_list|)
decl_stmt|;
name|long
index|[]
name|results
init|=
operator|new
name|long
index|[
name|num
index|]
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|num
condition|;
name|i
operator|++
control|)
block|{
name|results
index|[
name|i
index|]
operator|=
name|sequenceNumber
operator|++
expr_stmt|;
block|}
return|return
name|results
return|;
block|}
comment|/**    * By acquiring a log sequence ID, we can allow log messages    * to continue while we flush the cache.    *    * Acquire a lock so that we do not roll the log between the start    * and completion of a cache-flush.  Otherwise the log-seq-id for    * the flush will not appear in the correct logfile.    *     * @return sequence ID to pass {@link #completeCacheFlush(Text, Text, long)}    * @see #completeCacheFlush(Text, Text, long)    * @see #abortCacheFlush()    */
specifier|synchronized
name|long
name|startCacheFlush
parameter_list|()
block|{
name|cacheFlushLock
operator|.
name|lock
argument_list|()
expr_stmt|;
return|return
name|obtainSeqNum
argument_list|()
return|;
block|}
comment|/**     * Complete the cache flush    *     * Protected by this.lock()    *     * @param regionName    * @param tableName    * @param logSeqId    * @throws IOException    */
specifier|synchronized
name|void
name|completeCacheFlush
parameter_list|(
specifier|final
name|Text
name|regionName
parameter_list|,
specifier|final
name|Text
name|tableName
parameter_list|,
specifier|final
name|long
name|logSeqId
parameter_list|)
throws|throws
name|IOException
block|{
try|try
block|{
if|if
condition|(
name|this
operator|.
name|closed
condition|)
block|{
return|return;
block|}
name|writer
operator|.
name|append
argument_list|(
operator|new
name|HLogKey
argument_list|(
name|regionName
argument_list|,
name|tableName
argument_list|,
name|HLog
operator|.
name|METAROW
argument_list|,
name|logSeqId
argument_list|)
argument_list|,
operator|new
name|HLogEdit
argument_list|(
name|HLog
operator|.
name|METACOLUMN
argument_list|,
name|HGlobals
operator|.
name|completeCacheFlush
operator|.
name|get
argument_list|()
argument_list|,
name|System
operator|.
name|currentTimeMillis
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
name|numEntries
operator|.
name|getAndIncrement
argument_list|()
expr_stmt|;
name|Long
name|seq
init|=
name|lastSeqWritten
operator|.
name|get
argument_list|(
name|regionName
argument_list|)
decl_stmt|;
if|if
condition|(
name|seq
operator|!=
literal|null
operator|&&
name|logSeqId
operator|>=
name|seq
condition|)
block|{
name|lastSeqWritten
operator|.
name|remove
argument_list|(
name|regionName
argument_list|)
expr_stmt|;
block|}
block|}
finally|finally
block|{
name|cacheFlushLock
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**    * Abort a cache flush.    * This method will clear waits on {@link #insideCacheFlush}.  Call if the    * flush fails.  Note that the only recovery for an aborted flush currently    * is a restart of the regionserver so the snapshot content dropped by the    * failure gets restored to the  memcache.    */
name|void
name|abortCacheFlush
parameter_list|()
block|{
name|this
operator|.
name|cacheFlushLock
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
specifier|private
specifier|static
name|void
name|usage
parameter_list|()
block|{
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|"Usage: java org.apache.hbase.HLog"
operator|+
literal|" {--dump<logfile>... | --split<logdir>...}"
argument_list|)
expr_stmt|;
block|}
comment|/**    * Pass one or more log file names and it will either dump out a text version    * on<code>stdout</code> or split the specified log files.    * @param args    * @throws IOException    */
specifier|public
specifier|static
name|void
name|main
parameter_list|(
name|String
index|[]
name|args
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|args
operator|.
name|length
operator|<
literal|2
condition|)
block|{
name|usage
argument_list|()
expr_stmt|;
name|System
operator|.
name|exit
argument_list|(
operator|-
literal|1
argument_list|)
expr_stmt|;
block|}
name|boolean
name|dump
init|=
literal|true
decl_stmt|;
if|if
condition|(
name|args
index|[
literal|0
index|]
operator|.
name|compareTo
argument_list|(
literal|"--dump"
argument_list|)
operator|!=
literal|0
condition|)
block|{
if|if
condition|(
name|args
index|[
literal|0
index|]
operator|.
name|compareTo
argument_list|(
literal|"--split"
argument_list|)
operator|==
literal|0
condition|)
block|{
name|dump
operator|=
literal|false
expr_stmt|;
block|}
else|else
block|{
name|usage
argument_list|()
expr_stmt|;
name|System
operator|.
name|exit
argument_list|(
operator|-
literal|1
argument_list|)
expr_stmt|;
block|}
block|}
name|Configuration
name|conf
init|=
operator|new
name|HBaseConfiguration
argument_list|()
decl_stmt|;
name|FileSystem
name|fs
init|=
name|FileSystem
operator|.
name|get
argument_list|(
name|conf
argument_list|)
decl_stmt|;
name|Path
name|baseDir
init|=
operator|new
name|Path
argument_list|(
name|conf
operator|.
name|get
argument_list|(
name|HBASE_DIR
argument_list|,
name|DEFAULT_HBASE_DIR
argument_list|)
argument_list|)
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|1
init|;
name|i
operator|<
name|args
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|Path
name|logPath
init|=
operator|new
name|Path
argument_list|(
name|args
index|[
name|i
index|]
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|fs
operator|.
name|exists
argument_list|(
name|logPath
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|FileNotFoundException
argument_list|(
name|args
index|[
name|i
index|]
operator|+
literal|" does not exist"
argument_list|)
throw|;
block|}
if|if
condition|(
name|dump
condition|)
block|{
if|if
condition|(
operator|!
name|fs
operator|.
name|isFile
argument_list|(
name|logPath
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|args
index|[
name|i
index|]
operator|+
literal|" is not a file"
argument_list|)
throw|;
block|}
name|Reader
name|log
init|=
operator|new
name|SequenceFile
operator|.
name|Reader
argument_list|(
name|fs
argument_list|,
name|logPath
argument_list|,
name|conf
argument_list|)
decl_stmt|;
try|try
block|{
name|HLogKey
name|key
init|=
operator|new
name|HLogKey
argument_list|()
decl_stmt|;
name|HLogEdit
name|val
init|=
operator|new
name|HLogEdit
argument_list|()
decl_stmt|;
while|while
condition|(
name|log
operator|.
name|next
argument_list|(
name|key
argument_list|,
name|val
argument_list|)
condition|)
block|{
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
name|key
operator|.
name|toString
argument_list|()
operator|+
literal|" "
operator|+
name|val
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
finally|finally
block|{
name|log
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
block|}
else|else
block|{
if|if
condition|(
operator|!
name|fs
operator|.
name|getFileStatus
argument_list|(
name|logPath
argument_list|)
operator|.
name|isDir
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|args
index|[
name|i
index|]
operator|+
literal|" is not a directory"
argument_list|)
throw|;
block|}
name|splitLog
argument_list|(
name|baseDir
argument_list|,
name|logPath
argument_list|,
name|fs
argument_list|,
name|conf
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
end_class

end_unit

