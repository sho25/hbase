begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Copyright 2009 The Apache Software Foundation  *  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|UnsupportedEncodingException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|NavigableSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|TreeMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|TreeSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ConcurrentHashMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ConcurrentSkipListMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|atomic
operator|.
name|AtomicBoolean
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|atomic
operator|.
name|AtomicLong
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|locks
operator|.
name|ReentrantReadWriteLock
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|Log
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|LogFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FSDataOutputStream
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileStatus
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|DroppedSnapshotException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HBaseConfiguration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HColumnDescriptor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HConstants
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HRegionInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HTableDescriptor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|KeyValue
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|NotServingRegionException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|RegionHistorian
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|Delete
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|Get
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|Put
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|Result
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|Scan
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|filter
operator|.
name|Filter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|HeapSize
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|Reference
operator|.
name|Range
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|hfile
operator|.
name|BlockCache
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|ipc
operator|.
name|HRegionInterface
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|Bytes
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|ClassSize
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|FSUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|Writables
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|Progressable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|StringUtils
import|;
end_import

begin_comment
comment|/**  * HRegion stores data for a certain region of a table.  It stores all columns  * for each row. A given table consists of one or more HRegions.  *  *<p>We maintain multiple HStores for a single HRegion.  *   *<p>An Store is a set of rows with some column data; together,  * they make up all the data for the rows.    *  *<p>Each HRegion has a 'startKey' and 'endKey'.  *<p>The first is inclusive, the second is exclusive (except for  * the final region)  The endKey of region 0 is the same as  * startKey for region 1 (if it exists).  The startKey for the  * first region is null. The endKey for the final region is null.  *  *<p>Locking at the HRegion level serves only one purpose: preventing the  * region from being closed (and consequently split) while other operations  * are ongoing. Each row level operation obtains both a row lock and a region  * read lock for the duration of the operation. While a scanner is being  * constructed, getScanner holds a read lock. If the scanner is successfully  * constructed, it holds a read lock until it is closed. A close takes out a  * write lock and consequently will block for ongoing operations and will block  * new operations from starting while the close is in progress.  *   *<p>An HRegion is defined by its table and its key extent.  *   *<p>It consists of at least one Store.  The number of Stores should be  * configurable, so that data which is accessed together is stored in the same  * Store.  Right now, we approximate that by building a single Store for   * each column family.  (This config info will be communicated via the   * tabledesc.)  *   *<p>The HTableDescriptor contains metainfo about the HRegion's table.  * regionName is a unique identifier for this HRegion. (startKey, endKey]  * defines the keyspace for this HRegion.  */
end_comment

begin_class
specifier|public
class|class
name|HRegion
implements|implements
name|HConstants
implements|,
name|HeapSize
block|{
comment|// , Writable{
specifier|static
specifier|final
name|Log
name|LOG
init|=
name|LogFactory
operator|.
name|getLog
argument_list|(
name|HRegion
operator|.
name|class
argument_list|)
decl_stmt|;
specifier|static
specifier|final
name|String
name|SPLITDIR
init|=
literal|"splits"
decl_stmt|;
specifier|static
specifier|final
name|String
name|MERGEDIR
init|=
literal|"merges"
decl_stmt|;
specifier|final
name|AtomicBoolean
name|closed
init|=
operator|new
name|AtomicBoolean
argument_list|(
literal|false
argument_list|)
decl_stmt|;
comment|/* Closing can take some time; use the closing flag if there is stuff we don't     * want to do while in closing state; e.g. like offer this region up to the     * master as a region to close if the carrying regionserver is overloaded.    * Once set, it is never cleared.    */
specifier|final
name|AtomicBoolean
name|closing
init|=
operator|new
name|AtomicBoolean
argument_list|(
literal|false
argument_list|)
decl_stmt|;
specifier|private
specifier|final
name|RegionHistorian
name|historian
decl_stmt|;
comment|//////////////////////////////////////////////////////////////////////////////
comment|// Members
comment|//////////////////////////////////////////////////////////////////////////////
specifier|private
specifier|final
name|Map
argument_list|<
name|Integer
argument_list|,
name|byte
index|[]
argument_list|>
name|locksToRows
init|=
operator|new
name|ConcurrentHashMap
argument_list|<
name|Integer
argument_list|,
name|byte
index|[]
argument_list|>
argument_list|()
decl_stmt|;
specifier|protected
specifier|final
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|Store
argument_list|>
name|stores
init|=
operator|new
name|ConcurrentSkipListMap
argument_list|<
name|byte
index|[]
argument_list|,
name|Store
argument_list|>
argument_list|(
name|Bytes
operator|.
name|BYTES_RAWCOMPARATOR
argument_list|)
decl_stmt|;
comment|//These variable are just used for getting data out of the region, to test on
comment|//client side
comment|// private int numStores = 0;
comment|// private int [] storeSize = null;
comment|// private byte [] name = null;
specifier|final
name|AtomicLong
name|memstoreSize
init|=
operator|new
name|AtomicLong
argument_list|(
literal|0
argument_list|)
decl_stmt|;
comment|// This is the table subdirectory.
specifier|final
name|Path
name|basedir
decl_stmt|;
specifier|final
name|HLog
name|log
decl_stmt|;
specifier|final
name|FileSystem
name|fs
decl_stmt|;
specifier|final
name|HBaseConfiguration
name|conf
decl_stmt|;
specifier|final
name|HRegionInfo
name|regionInfo
decl_stmt|;
specifier|final
name|Path
name|regiondir
decl_stmt|;
specifier|private
specifier|final
name|Path
name|regionCompactionDir
decl_stmt|;
name|KeyValue
operator|.
name|KVComparator
name|comparator
decl_stmt|;
comment|/*    * Set this when scheduling compaction if want the next compaction to be a    * major compaction.  Cleared each time through compaction code.    */
specifier|private
specifier|volatile
name|boolean
name|forceMajorCompaction
init|=
literal|false
decl_stmt|;
comment|/*    * Data structure of write state flags used coordinating flushes,    * compactions and closes.    */
specifier|static
class|class
name|WriteState
block|{
comment|// Set while a memstore flush is happening.
specifier|volatile
name|boolean
name|flushing
init|=
literal|false
decl_stmt|;
comment|// Set when a flush has been requested.
specifier|volatile
name|boolean
name|flushRequested
init|=
literal|false
decl_stmt|;
comment|// Set while a compaction is running.
specifier|volatile
name|boolean
name|compacting
init|=
literal|false
decl_stmt|;
comment|// Gets set in close. If set, cannot compact or flush again.
specifier|volatile
name|boolean
name|writesEnabled
init|=
literal|true
decl_stmt|;
comment|// Set if region is read-only
specifier|volatile
name|boolean
name|readOnly
init|=
literal|false
decl_stmt|;
comment|/**      * Set flags that make this region read-only.      */
specifier|synchronized
name|void
name|setReadOnly
parameter_list|(
specifier|final
name|boolean
name|onOff
parameter_list|)
block|{
name|this
operator|.
name|writesEnabled
operator|=
operator|!
name|onOff
expr_stmt|;
name|this
operator|.
name|readOnly
operator|=
name|onOff
expr_stmt|;
block|}
name|boolean
name|isReadOnly
parameter_list|()
block|{
return|return
name|this
operator|.
name|readOnly
return|;
block|}
name|boolean
name|isFlushRequested
parameter_list|()
block|{
return|return
name|this
operator|.
name|flushRequested
return|;
block|}
block|}
specifier|private
specifier|volatile
name|WriteState
name|writestate
init|=
operator|new
name|WriteState
argument_list|()
decl_stmt|;
specifier|final
name|int
name|memstoreFlushSize
decl_stmt|;
specifier|private
specifier|volatile
name|long
name|lastFlushTime
decl_stmt|;
specifier|final
name|FlushRequester
name|flushListener
decl_stmt|;
specifier|private
specifier|final
name|int
name|blockingMemStoreSize
decl_stmt|;
specifier|final
name|long
name|threadWakeFrequency
decl_stmt|;
comment|// Used to guard splits and closes
specifier|private
specifier|final
name|ReentrantReadWriteLock
name|splitsAndClosesLock
init|=
operator|new
name|ReentrantReadWriteLock
argument_list|()
decl_stmt|;
specifier|private
specifier|final
name|ReentrantReadWriteLock
name|newScannerLock
init|=
operator|new
name|ReentrantReadWriteLock
argument_list|()
decl_stmt|;
comment|// Stop updates lock
specifier|private
specifier|final
name|ReentrantReadWriteLock
name|updatesLock
init|=
operator|new
name|ReentrantReadWriteLock
argument_list|()
decl_stmt|;
specifier|private
specifier|final
name|Object
name|splitLock
init|=
operator|new
name|Object
argument_list|()
decl_stmt|;
specifier|private
name|long
name|minSequenceId
decl_stmt|;
specifier|private
name|boolean
name|splitRequest
decl_stmt|;
comment|/**    * Name of the region info file that resides just under the region directory.    */
specifier|public
specifier|final
specifier|static
name|String
name|REGIONINFO_FILE
init|=
literal|".regioninfo"
decl_stmt|;
comment|/**    * REGIONINFO_FILE as byte array.    */
specifier|public
specifier|final
specifier|static
name|byte
index|[]
name|REGIONINFO_FILE_BYTES
init|=
name|Bytes
operator|.
name|toBytes
argument_list|(
name|REGIONINFO_FILE
argument_list|)
decl_stmt|;
comment|/**    * Should only be used for testing purposes    */
specifier|public
name|HRegion
parameter_list|()
block|{
name|this
operator|.
name|basedir
operator|=
literal|null
expr_stmt|;
name|this
operator|.
name|blockingMemStoreSize
operator|=
literal|0
expr_stmt|;
name|this
operator|.
name|conf
operator|=
literal|null
expr_stmt|;
name|this
operator|.
name|flushListener
operator|=
literal|null
expr_stmt|;
name|this
operator|.
name|fs
operator|=
literal|null
expr_stmt|;
name|this
operator|.
name|historian
operator|=
literal|null
expr_stmt|;
name|this
operator|.
name|memstoreFlushSize
operator|=
literal|0
expr_stmt|;
name|this
operator|.
name|log
operator|=
literal|null
expr_stmt|;
name|this
operator|.
name|regionCompactionDir
operator|=
literal|null
expr_stmt|;
name|this
operator|.
name|regiondir
operator|=
literal|null
expr_stmt|;
name|this
operator|.
name|regionInfo
operator|=
literal|null
expr_stmt|;
name|this
operator|.
name|threadWakeFrequency
operator|=
literal|0L
expr_stmt|;
block|}
comment|/**    * HRegion constructor.    *    * @param basedir qualified path of directory where region should be located,    * usually the table directory.    * @param log The HLog is the outbound log for any updates to the HRegion    * (There's a single HLog for all the HRegions on a single HRegionServer.)    * The log file is a logfile from the previous execution that's    * custom-computed for this HRegion. The HRegionServer computes and sorts the    * appropriate log info for this HRegion. If there is a previous log file    * (implying that the HRegion has been written-to before), then read it from    * the supplied path.    * @param fs is the filesystem.      * @param conf is global configuration settings.    * @param regionInfo - HRegionInfo that describes the region    * is new), then read them from the supplied path.    * @param flushListener an object that implements CacheFlushListener or null    * making progress to master -- otherwise master might think region deploy    * failed.  Can be null.    */
specifier|public
name|HRegion
parameter_list|(
name|Path
name|basedir
parameter_list|,
name|HLog
name|log
parameter_list|,
name|FileSystem
name|fs
parameter_list|,
name|HBaseConfiguration
name|conf
parameter_list|,
name|HRegionInfo
name|regionInfo
parameter_list|,
name|FlushRequester
name|flushListener
parameter_list|)
block|{
name|this
operator|.
name|basedir
operator|=
name|basedir
expr_stmt|;
name|this
operator|.
name|comparator
operator|=
name|regionInfo
operator|.
name|getComparator
argument_list|()
expr_stmt|;
name|this
operator|.
name|log
operator|=
name|log
expr_stmt|;
name|this
operator|.
name|fs
operator|=
name|fs
expr_stmt|;
name|this
operator|.
name|conf
operator|=
name|conf
expr_stmt|;
name|this
operator|.
name|regionInfo
operator|=
name|regionInfo
expr_stmt|;
name|this
operator|.
name|flushListener
operator|=
name|flushListener
expr_stmt|;
name|this
operator|.
name|threadWakeFrequency
operator|=
name|conf
operator|.
name|getLong
argument_list|(
name|THREAD_WAKE_FREQUENCY
argument_list|,
literal|10
operator|*
literal|1000
argument_list|)
expr_stmt|;
name|String
name|encodedNameStr
init|=
name|Integer
operator|.
name|toString
argument_list|(
name|this
operator|.
name|regionInfo
operator|.
name|getEncodedName
argument_list|()
argument_list|)
decl_stmt|;
name|this
operator|.
name|regiondir
operator|=
operator|new
name|Path
argument_list|(
name|basedir
argument_list|,
name|encodedNameStr
argument_list|)
expr_stmt|;
name|this
operator|.
name|historian
operator|=
name|RegionHistorian
operator|.
name|getInstance
argument_list|()
expr_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
comment|// Write out region name as string and its encoded name.
name|LOG
operator|.
name|debug
argument_list|(
literal|"Opening region "
operator|+
name|this
operator|+
literal|", encoded="
operator|+
name|this
operator|.
name|regionInfo
operator|.
name|getEncodedName
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|this
operator|.
name|regionCompactionDir
operator|=
operator|new
name|Path
argument_list|(
name|getCompactionDir
argument_list|(
name|basedir
argument_list|)
argument_list|,
name|encodedNameStr
argument_list|)
expr_stmt|;
name|int
name|flushSize
init|=
name|regionInfo
operator|.
name|getTableDesc
argument_list|()
operator|.
name|getMemStoreFlushSize
argument_list|()
decl_stmt|;
if|if
condition|(
name|flushSize
operator|==
name|HTableDescriptor
operator|.
name|DEFAULT_MEMSTORE_FLUSH_SIZE
condition|)
block|{
name|flushSize
operator|=
name|conf
operator|.
name|getInt
argument_list|(
literal|"hbase.hregion.memstore.flush.size"
argument_list|,
name|HTableDescriptor
operator|.
name|DEFAULT_MEMSTORE_FLUSH_SIZE
argument_list|)
expr_stmt|;
block|}
name|this
operator|.
name|memstoreFlushSize
operator|=
name|flushSize
expr_stmt|;
name|this
operator|.
name|blockingMemStoreSize
operator|=
name|this
operator|.
name|memstoreFlushSize
operator|*
name|conf
operator|.
name|getInt
argument_list|(
literal|"hbase.hregion.memstore.block.multiplier"
argument_list|,
literal|1
argument_list|)
expr_stmt|;
block|}
comment|/**    * Initialize this region and get it ready to roll.    * Called after construction.    *     * @param initialFiles    * @param reporter    * @throws IOException    */
specifier|public
name|void
name|initialize
parameter_list|(
name|Path
name|initialFiles
parameter_list|,
specifier|final
name|Progressable
name|reporter
parameter_list|)
throws|throws
name|IOException
block|{
name|Path
name|oldLogFile
init|=
operator|new
name|Path
argument_list|(
name|regiondir
argument_list|,
name|HREGION_OLDLOGFILE_NAME
argument_list|)
decl_stmt|;
comment|// Move prefab HStore files into place (if any).  This picks up split files
comment|// and any merges from splits and merges dirs.
if|if
condition|(
name|initialFiles
operator|!=
literal|null
operator|&&
name|fs
operator|.
name|exists
argument_list|(
name|initialFiles
argument_list|)
condition|)
block|{
name|fs
operator|.
name|rename
argument_list|(
name|initialFiles
argument_list|,
name|this
operator|.
name|regiondir
argument_list|)
expr_stmt|;
block|}
comment|// Write HRI to a file in case we need to recover .META.
name|checkRegioninfoOnFilesystem
argument_list|()
expr_stmt|;
comment|// Load in all the HStores.
name|long
name|maxSeqId
init|=
operator|-
literal|1
decl_stmt|;
name|long
name|minSeqId
init|=
name|Integer
operator|.
name|MAX_VALUE
decl_stmt|;
for|for
control|(
name|HColumnDescriptor
name|c
range|:
name|this
operator|.
name|regionInfo
operator|.
name|getTableDesc
argument_list|()
operator|.
name|getFamilies
argument_list|()
control|)
block|{
name|Store
name|store
init|=
name|instantiateHStore
argument_list|(
name|this
operator|.
name|basedir
argument_list|,
name|c
argument_list|,
name|oldLogFile
argument_list|,
name|reporter
argument_list|)
decl_stmt|;
name|this
operator|.
name|stores
operator|.
name|put
argument_list|(
name|c
operator|.
name|getName
argument_list|()
argument_list|,
name|store
argument_list|)
expr_stmt|;
name|long
name|storeSeqId
init|=
name|store
operator|.
name|getMaxSequenceId
argument_list|()
decl_stmt|;
if|if
condition|(
name|storeSeqId
operator|>
name|maxSeqId
condition|)
block|{
name|maxSeqId
operator|=
name|storeSeqId
expr_stmt|;
block|}
if|if
condition|(
name|storeSeqId
operator|<
name|minSeqId
condition|)
block|{
name|minSeqId
operator|=
name|storeSeqId
expr_stmt|;
block|}
block|}
comment|// Play log if one.  Delete when done.
name|doReconstructionLog
argument_list|(
name|oldLogFile
argument_list|,
name|minSeqId
argument_list|,
name|maxSeqId
argument_list|,
name|reporter
argument_list|)
expr_stmt|;
if|if
condition|(
name|fs
operator|.
name|exists
argument_list|(
name|oldLogFile
argument_list|)
condition|)
block|{
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Deleting old log file: "
operator|+
name|oldLogFile
argument_list|)
expr_stmt|;
block|}
name|fs
operator|.
name|delete
argument_list|(
name|oldLogFile
argument_list|,
literal|false
argument_list|)
expr_stmt|;
block|}
comment|// Add one to the current maximum sequence id so new edits are beyond.
name|this
operator|.
name|minSequenceId
operator|=
name|maxSeqId
operator|+
literal|1
expr_stmt|;
comment|// Get rid of any splits or merges that were lost in-progress
name|FSUtils
operator|.
name|deleteDirectory
argument_list|(
name|this
operator|.
name|fs
argument_list|,
operator|new
name|Path
argument_list|(
name|regiondir
argument_list|,
name|SPLITDIR
argument_list|)
argument_list|)
expr_stmt|;
name|FSUtils
operator|.
name|deleteDirectory
argument_list|(
name|this
operator|.
name|fs
argument_list|,
operator|new
name|Path
argument_list|(
name|regiondir
argument_list|,
name|MERGEDIR
argument_list|)
argument_list|)
expr_stmt|;
comment|// See if region is meant to run read-only.
if|if
condition|(
name|this
operator|.
name|regionInfo
operator|.
name|getTableDesc
argument_list|()
operator|.
name|isReadOnly
argument_list|()
condition|)
block|{
name|this
operator|.
name|writestate
operator|.
name|setReadOnly
argument_list|(
literal|true
argument_list|)
expr_stmt|;
block|}
comment|// HRegion is ready to go!
name|this
operator|.
name|writestate
operator|.
name|compacting
operator|=
literal|false
expr_stmt|;
name|this
operator|.
name|lastFlushTime
operator|=
name|System
operator|.
name|currentTimeMillis
argument_list|()
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"region "
operator|+
name|this
operator|+
literal|"/"
operator|+
name|this
operator|.
name|regionInfo
operator|.
name|getEncodedName
argument_list|()
operator|+
literal|" available; sequence id is "
operator|+
name|this
operator|.
name|minSequenceId
argument_list|)
expr_stmt|;
block|}
comment|/**    * @return True if this region has references.    */
name|boolean
name|hasReferences
parameter_list|()
block|{
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|byte
index|[]
argument_list|,
name|Store
argument_list|>
name|e
range|:
name|this
operator|.
name|stores
operator|.
name|entrySet
argument_list|()
control|)
block|{
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|Long
argument_list|,
name|StoreFile
argument_list|>
name|ee
range|:
name|e
operator|.
name|getValue
argument_list|()
operator|.
name|getStorefiles
argument_list|()
operator|.
name|entrySet
argument_list|()
control|)
block|{
comment|// Found a reference, return.
if|if
condition|(
name|ee
operator|.
name|getValue
argument_list|()
operator|.
name|isReference
argument_list|()
condition|)
return|return
literal|true
return|;
block|}
block|}
return|return
literal|false
return|;
block|}
comment|/*    * Write out an info file under the region directory.  Useful recovering    * mangled regions.    * @throws IOException    */
specifier|private
name|void
name|checkRegioninfoOnFilesystem
parameter_list|()
throws|throws
name|IOException
block|{
comment|// Name of this file has two leading and trailing underscores so it doesn't
comment|// clash w/ a store/family name.  There is possibility, but assumption is
comment|// that its slim (don't want to use control character in filename because
comment|//
name|Path
name|regioninfo
init|=
operator|new
name|Path
argument_list|(
name|this
operator|.
name|regiondir
argument_list|,
name|REGIONINFO_FILE
argument_list|)
decl_stmt|;
if|if
condition|(
name|this
operator|.
name|fs
operator|.
name|exists
argument_list|(
name|regioninfo
argument_list|)
operator|&&
name|this
operator|.
name|fs
operator|.
name|getFileStatus
argument_list|(
name|regioninfo
argument_list|)
operator|.
name|getLen
argument_list|()
operator|>
literal|0
condition|)
block|{
return|return;
block|}
name|FSDataOutputStream
name|out
init|=
name|this
operator|.
name|fs
operator|.
name|create
argument_list|(
name|regioninfo
argument_list|,
literal|true
argument_list|)
decl_stmt|;
try|try
block|{
name|this
operator|.
name|regionInfo
operator|.
name|write
argument_list|(
name|out
argument_list|)
expr_stmt|;
name|out
operator|.
name|write
argument_list|(
literal|'\n'
argument_list|)
expr_stmt|;
name|out
operator|.
name|write
argument_list|(
literal|'\n'
argument_list|)
expr_stmt|;
name|out
operator|.
name|write
argument_list|(
name|Bytes
operator|.
name|toBytes
argument_list|(
name|this
operator|.
name|regionInfo
operator|.
name|toString
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|out
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**    * @return Updates to this region need to have a sequence id that is>= to    * the this number.    */
name|long
name|getMinSequenceId
parameter_list|()
block|{
return|return
name|this
operator|.
name|minSequenceId
return|;
block|}
comment|/** @return a HRegionInfo object for this region */
specifier|public
name|HRegionInfo
name|getRegionInfo
parameter_list|()
block|{
return|return
name|this
operator|.
name|regionInfo
return|;
block|}
comment|/** @return true if region is closed */
specifier|public
name|boolean
name|isClosed
parameter_list|()
block|{
return|return
name|this
operator|.
name|closed
operator|.
name|get
argument_list|()
return|;
block|}
comment|/**    * @return True if closing process has started.    */
specifier|public
name|boolean
name|isClosing
parameter_list|()
block|{
return|return
name|this
operator|.
name|closing
operator|.
name|get
argument_list|()
return|;
block|}
comment|/**    * Close down this HRegion.  Flush the cache, shut down each HStore, don't     * service any more calls.    *    *<p>This method could take some time to execute, so don't call it from a     * time-sensitive thread.    *     * @return Vector of all the storage files that the HRegion's component     * HStores make use of.  It's a list of all HStoreFile objects. Returns empty    * vector if already closed and null if judged that it should not close.    *     * @throws IOException    */
specifier|public
name|List
argument_list|<
name|StoreFile
argument_list|>
name|close
parameter_list|()
throws|throws
name|IOException
block|{
return|return
name|close
argument_list|(
literal|false
argument_list|)
return|;
block|}
comment|/**    * Close down this HRegion.  Flush the cache unless abort parameter is true,    * Shut down each HStore, don't service any more calls.    *    * This method could take some time to execute, so don't call it from a     * time-sensitive thread.    *     * @param abort true if server is aborting (only during testing)    * @return Vector of all the storage files that the HRegion's component     * HStores make use of.  It's a list of HStoreFile objects.  Can be null if    * we are not to close at this time or we are already closed.    *     * @throws IOException    */
specifier|public
name|List
argument_list|<
name|StoreFile
argument_list|>
name|close
parameter_list|(
specifier|final
name|boolean
name|abort
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|isClosed
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"region "
operator|+
name|this
operator|+
literal|" already closed"
argument_list|)
expr_stmt|;
return|return
literal|null
return|;
block|}
name|this
operator|.
name|closing
operator|.
name|set
argument_list|(
literal|true
argument_list|)
expr_stmt|;
synchronized|synchronized
init|(
name|splitLock
init|)
block|{
synchronized|synchronized
init|(
name|writestate
init|)
block|{
comment|// Disable compacting and flushing by background threads for this
comment|// region.
name|writestate
operator|.
name|writesEnabled
operator|=
literal|false
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Closing "
operator|+
name|this
operator|+
literal|": compactions& flushes disabled "
argument_list|)
expr_stmt|;
while|while
condition|(
name|writestate
operator|.
name|compacting
operator|||
name|writestate
operator|.
name|flushing
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"waiting for"
operator|+
operator|(
name|writestate
operator|.
name|compacting
condition|?
literal|" compaction"
else|:
literal|""
operator|)
operator|+
operator|(
name|writestate
operator|.
name|flushing
condition|?
operator|(
name|writestate
operator|.
name|compacting
condition|?
literal|","
else|:
literal|""
operator|)
operator|+
literal|" cache flush"
else|:
literal|""
operator|)
operator|+
literal|" to complete for region "
operator|+
name|this
argument_list|)
expr_stmt|;
try|try
block|{
name|writestate
operator|.
name|wait
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|iex
parameter_list|)
block|{
comment|// continue
block|}
block|}
block|}
name|newScannerLock
operator|.
name|writeLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
name|splitsAndClosesLock
operator|.
name|writeLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Updates disabled for region, no outstanding scanners on "
operator|+
name|this
argument_list|)
expr_stmt|;
try|try
block|{
comment|// Write lock means no more row locks can be given out.  Wait on
comment|// outstanding row locks to come in before we close so we do not drop
comment|// outstanding updates.
name|waitOnRowLocks
argument_list|()
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"No more row locks outstanding on region "
operator|+
name|this
argument_list|)
expr_stmt|;
comment|// Don't flush the cache if we are aborting
if|if
condition|(
operator|!
name|abort
condition|)
block|{
name|internalFlushcache
argument_list|()
expr_stmt|;
block|}
name|List
argument_list|<
name|StoreFile
argument_list|>
name|result
init|=
operator|new
name|ArrayList
argument_list|<
name|StoreFile
argument_list|>
argument_list|()
decl_stmt|;
for|for
control|(
name|Store
name|store
range|:
name|stores
operator|.
name|values
argument_list|()
control|)
block|{
name|result
operator|.
name|addAll
argument_list|(
name|store
operator|.
name|close
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|this
operator|.
name|closed
operator|.
name|set
argument_list|(
literal|true
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Closed "
operator|+
name|this
argument_list|)
expr_stmt|;
return|return
name|result
return|;
block|}
finally|finally
block|{
name|splitsAndClosesLock
operator|.
name|writeLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
finally|finally
block|{
name|newScannerLock
operator|.
name|writeLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
block|}
comment|//////////////////////////////////////////////////////////////////////////////
comment|// HRegion accessors
comment|//////////////////////////////////////////////////////////////////////////////
comment|/** @return start key for region */
specifier|public
name|byte
index|[]
name|getStartKey
parameter_list|()
block|{
return|return
name|this
operator|.
name|regionInfo
operator|.
name|getStartKey
argument_list|()
return|;
block|}
comment|/** @return end key for region */
specifier|public
name|byte
index|[]
name|getEndKey
parameter_list|()
block|{
return|return
name|this
operator|.
name|regionInfo
operator|.
name|getEndKey
argument_list|()
return|;
block|}
comment|/** @return region id */
specifier|public
name|long
name|getRegionId
parameter_list|()
block|{
return|return
name|this
operator|.
name|regionInfo
operator|.
name|getRegionId
argument_list|()
return|;
block|}
comment|/** @return region name */
specifier|public
name|byte
index|[]
name|getRegionName
parameter_list|()
block|{
return|return
name|this
operator|.
name|regionInfo
operator|.
name|getRegionName
argument_list|()
return|;
block|}
comment|/** @return region name as string for logging */
specifier|public
name|String
name|getRegionNameAsString
parameter_list|()
block|{
return|return
name|this
operator|.
name|regionInfo
operator|.
name|getRegionNameAsString
argument_list|()
return|;
block|}
comment|/** @return HTableDescriptor for this region */
specifier|public
name|HTableDescriptor
name|getTableDesc
parameter_list|()
block|{
return|return
name|this
operator|.
name|regionInfo
operator|.
name|getTableDesc
argument_list|()
return|;
block|}
comment|/** @return HLog in use for this region */
specifier|public
name|HLog
name|getLog
parameter_list|()
block|{
return|return
name|this
operator|.
name|log
return|;
block|}
comment|/** @return Configuration object */
specifier|public
name|HBaseConfiguration
name|getConf
parameter_list|()
block|{
return|return
name|this
operator|.
name|conf
return|;
block|}
comment|/** @return region directory Path */
specifier|public
name|Path
name|getRegionDir
parameter_list|()
block|{
return|return
name|this
operator|.
name|regiondir
return|;
block|}
comment|/** @return FileSystem being used by this region */
specifier|public
name|FileSystem
name|getFilesystem
parameter_list|()
block|{
return|return
name|this
operator|.
name|fs
return|;
block|}
comment|/** @return the last time the region was flushed */
specifier|public
name|long
name|getLastFlushTime
parameter_list|()
block|{
return|return
name|this
operator|.
name|lastFlushTime
return|;
block|}
comment|//////////////////////////////////////////////////////////////////////////////
comment|// HRegion maintenance.
comment|//
comment|// These methods are meant to be called periodically by the HRegionServer for
comment|// upkeep.
comment|//////////////////////////////////////////////////////////////////////////////
comment|/** @return returns size of largest HStore. */
specifier|public
name|long
name|getLargestHStoreSize
parameter_list|()
block|{
name|long
name|size
init|=
literal|0
decl_stmt|;
for|for
control|(
name|Store
name|h
range|:
name|stores
operator|.
name|values
argument_list|()
control|)
block|{
name|long
name|storeSize
init|=
name|h
operator|.
name|getSize
argument_list|()
decl_stmt|;
if|if
condition|(
name|storeSize
operator|>
name|size
condition|)
block|{
name|size
operator|=
name|storeSize
expr_stmt|;
block|}
block|}
return|return
name|size
return|;
block|}
comment|/*    * Split the HRegion to create two brand-new ones.  This also closes    * current HRegion.  Split should be fast since we don't rewrite store files    * but instead create new 'reference' store files that read off the top and    * bottom ranges of parent store files.    * @param splitRow row on which to split region    * @return two brand-new (and open) HRegions or null if a split is not needed    * @throws IOException    */
name|HRegion
index|[]
name|splitRegion
parameter_list|(
specifier|final
name|byte
index|[]
name|splitRow
parameter_list|)
throws|throws
name|IOException
block|{
name|prepareToSplit
argument_list|()
expr_stmt|;
synchronized|synchronized
init|(
name|splitLock
init|)
block|{
if|if
condition|(
name|closed
operator|.
name|get
argument_list|()
condition|)
block|{
return|return
literal|null
return|;
block|}
comment|// Add start/end key checking: hbase-428.
name|byte
index|[]
name|startKey
init|=
name|this
operator|.
name|regionInfo
operator|.
name|getStartKey
argument_list|()
decl_stmt|;
name|byte
index|[]
name|endKey
init|=
name|this
operator|.
name|regionInfo
operator|.
name|getEndKey
argument_list|()
decl_stmt|;
if|if
condition|(
name|this
operator|.
name|comparator
operator|.
name|matchingRows
argument_list|(
name|startKey
argument_list|,
literal|0
argument_list|,
name|startKey
operator|.
name|length
argument_list|,
name|splitRow
argument_list|,
literal|0
argument_list|,
name|splitRow
operator|.
name|length
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Startkey and midkey are same, not splitting"
argument_list|)
expr_stmt|;
return|return
literal|null
return|;
block|}
if|if
condition|(
name|this
operator|.
name|comparator
operator|.
name|matchingRows
argument_list|(
name|splitRow
argument_list|,
literal|0
argument_list|,
name|splitRow
operator|.
name|length
argument_list|,
name|endKey
argument_list|,
literal|0
argument_list|,
name|endKey
operator|.
name|length
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Endkey and midkey are same, not splitting"
argument_list|)
expr_stmt|;
return|return
literal|null
return|;
block|}
name|LOG
operator|.
name|info
argument_list|(
literal|"Starting split of region "
operator|+
name|this
argument_list|)
expr_stmt|;
name|Path
name|splits
init|=
operator|new
name|Path
argument_list|(
name|this
operator|.
name|regiondir
argument_list|,
name|SPLITDIR
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|this
operator|.
name|fs
operator|.
name|exists
argument_list|(
name|splits
argument_list|)
condition|)
block|{
name|this
operator|.
name|fs
operator|.
name|mkdirs
argument_list|(
name|splits
argument_list|)
expr_stmt|;
block|}
comment|// Calculate regionid to use.  Can't be less than that of parent else
comment|// it'll insert into wrong location over in .META. table: HBASE-710.
name|long
name|rid
init|=
name|System
operator|.
name|currentTimeMillis
argument_list|()
decl_stmt|;
if|if
condition|(
name|rid
operator|<
name|this
operator|.
name|regionInfo
operator|.
name|getRegionId
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Clock skew; parent regions id is "
operator|+
name|this
operator|.
name|regionInfo
operator|.
name|getRegionId
argument_list|()
operator|+
literal|" but current time here is "
operator|+
name|rid
argument_list|)
expr_stmt|;
name|rid
operator|=
name|this
operator|.
name|regionInfo
operator|.
name|getRegionId
argument_list|()
operator|+
literal|1
expr_stmt|;
block|}
name|HRegionInfo
name|regionAInfo
init|=
operator|new
name|HRegionInfo
argument_list|(
name|this
operator|.
name|regionInfo
operator|.
name|getTableDesc
argument_list|()
argument_list|,
name|startKey
argument_list|,
name|splitRow
argument_list|,
literal|false
argument_list|,
name|rid
argument_list|)
decl_stmt|;
name|Path
name|dirA
init|=
operator|new
name|Path
argument_list|(
name|splits
argument_list|,
name|Integer
operator|.
name|toString
argument_list|(
name|regionAInfo
operator|.
name|getEncodedName
argument_list|()
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|fs
operator|.
name|exists
argument_list|(
name|dirA
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Cannot split; target file collision at "
operator|+
name|dirA
argument_list|)
throw|;
block|}
name|HRegionInfo
name|regionBInfo
init|=
operator|new
name|HRegionInfo
argument_list|(
name|this
operator|.
name|regionInfo
operator|.
name|getTableDesc
argument_list|()
argument_list|,
name|splitRow
argument_list|,
name|endKey
argument_list|,
literal|false
argument_list|,
name|rid
argument_list|)
decl_stmt|;
name|Path
name|dirB
init|=
operator|new
name|Path
argument_list|(
name|splits
argument_list|,
name|Integer
operator|.
name|toString
argument_list|(
name|regionBInfo
operator|.
name|getEncodedName
argument_list|()
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|this
operator|.
name|fs
operator|.
name|exists
argument_list|(
name|dirB
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Cannot split; target file collision at "
operator|+
name|dirB
argument_list|)
throw|;
block|}
comment|// Now close the HRegion.  Close returns all store files or null if not
comment|// supposed to close (? What to do in this case? Implement abort of close?)
comment|// Close also does wait on outstanding rows and calls a flush just-in-case.
name|List
argument_list|<
name|StoreFile
argument_list|>
name|hstoreFilesToSplit
init|=
name|close
argument_list|(
literal|false
argument_list|)
decl_stmt|;
if|if
condition|(
name|hstoreFilesToSplit
operator|==
literal|null
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Close came back null (Implement abort of close?)"
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"close returned empty vector of HStoreFiles"
argument_list|)
throw|;
block|}
comment|// Split each store file.
for|for
control|(
name|StoreFile
name|h
range|:
name|hstoreFilesToSplit
control|)
block|{
name|StoreFile
operator|.
name|split
argument_list|(
name|fs
argument_list|,
name|Store
operator|.
name|getStoreHomedir
argument_list|(
name|splits
argument_list|,
name|regionAInfo
operator|.
name|getEncodedName
argument_list|()
argument_list|,
name|h
operator|.
name|getFamily
argument_list|()
argument_list|)
argument_list|,
name|h
argument_list|,
name|splitRow
argument_list|,
name|Range
operator|.
name|bottom
argument_list|)
expr_stmt|;
name|StoreFile
operator|.
name|split
argument_list|(
name|fs
argument_list|,
name|Store
operator|.
name|getStoreHomedir
argument_list|(
name|splits
argument_list|,
name|regionBInfo
operator|.
name|getEncodedName
argument_list|()
argument_list|,
name|h
operator|.
name|getFamily
argument_list|()
argument_list|)
argument_list|,
name|h
argument_list|,
name|splitRow
argument_list|,
name|Range
operator|.
name|top
argument_list|)
expr_stmt|;
block|}
comment|// Done!
comment|// Opening the region copies the splits files from the splits directory
comment|// under each region.
name|HRegion
name|regionA
init|=
operator|new
name|HRegion
argument_list|(
name|basedir
argument_list|,
name|log
argument_list|,
name|fs
argument_list|,
name|conf
argument_list|,
name|regionAInfo
argument_list|,
literal|null
argument_list|)
decl_stmt|;
name|regionA
operator|.
name|initialize
argument_list|(
name|dirA
argument_list|,
literal|null
argument_list|)
expr_stmt|;
name|regionA
operator|.
name|close
argument_list|()
expr_stmt|;
name|HRegion
name|regionB
init|=
operator|new
name|HRegion
argument_list|(
name|basedir
argument_list|,
name|log
argument_list|,
name|fs
argument_list|,
name|conf
argument_list|,
name|regionBInfo
argument_list|,
literal|null
argument_list|)
decl_stmt|;
name|regionB
operator|.
name|initialize
argument_list|(
name|dirB
argument_list|,
literal|null
argument_list|)
expr_stmt|;
name|regionB
operator|.
name|close
argument_list|()
expr_stmt|;
comment|// Cleanup
name|boolean
name|deleted
init|=
name|fs
operator|.
name|delete
argument_list|(
name|splits
argument_list|,
literal|true
argument_list|)
decl_stmt|;
comment|// Get rid of splits directory
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Cleaned up "
operator|+
name|FSUtils
operator|.
name|getPath
argument_list|(
name|splits
argument_list|)
operator|+
literal|" "
operator|+
name|deleted
argument_list|)
expr_stmt|;
block|}
name|HRegion
name|regions
index|[]
init|=
operator|new
name|HRegion
index|[]
block|{
name|regionA
block|,
name|regionB
block|}
decl_stmt|;
name|this
operator|.
name|historian
operator|.
name|addRegionSplit
argument_list|(
name|this
operator|.
name|regionInfo
argument_list|,
name|regionA
operator|.
name|getRegionInfo
argument_list|()
argument_list|,
name|regionB
operator|.
name|getRegionInfo
argument_list|()
argument_list|)
expr_stmt|;
return|return
name|regions
return|;
block|}
block|}
specifier|protected
name|void
name|prepareToSplit
parameter_list|()
block|{
comment|// nothing
block|}
comment|/*    * @param dir    * @return compaction directory for the passed in<code>dir</code>    */
specifier|static
name|Path
name|getCompactionDir
parameter_list|(
specifier|final
name|Path
name|dir
parameter_list|)
block|{
return|return
operator|new
name|Path
argument_list|(
name|dir
argument_list|,
name|HREGION_COMPACTIONDIR_NAME
argument_list|)
return|;
block|}
comment|/*    * Do preparation for pending compaction.    * Clean out any vestiges of previous failed compactions.    * @throws IOException    */
specifier|private
name|void
name|doRegionCompactionPrep
parameter_list|()
throws|throws
name|IOException
block|{
name|doRegionCompactionCleanup
argument_list|()
expr_stmt|;
block|}
comment|/*    * Removes the compaction directory for this Store.    * @throws IOException    */
specifier|private
name|void
name|doRegionCompactionCleanup
parameter_list|()
throws|throws
name|IOException
block|{
name|FSUtils
operator|.
name|deleteDirectory
argument_list|(
name|this
operator|.
name|fs
argument_list|,
name|this
operator|.
name|regionCompactionDir
argument_list|)
expr_stmt|;
block|}
name|void
name|setForceMajorCompaction
parameter_list|(
specifier|final
name|boolean
name|b
parameter_list|)
block|{
name|this
operator|.
name|forceMajorCompaction
operator|=
name|b
expr_stmt|;
block|}
name|boolean
name|getForceMajorCompaction
parameter_list|()
block|{
return|return
name|this
operator|.
name|forceMajorCompaction
return|;
block|}
comment|/**    * Called by compaction thread and after region is opened to compact the    * HStores if necessary.    *    *<p>This operation could block for a long time, so don't call it from a     * time-sensitive thread.    *    * Note that no locking is necessary at this level because compaction only    * conflicts with a region split, and that cannot happen because the region    * server does them sequentially and not in parallel.    *     * @return mid key if split is needed    * @throws IOException    */
specifier|public
name|byte
index|[]
name|compactStores
parameter_list|()
throws|throws
name|IOException
block|{
name|boolean
name|majorCompaction
init|=
name|this
operator|.
name|forceMajorCompaction
decl_stmt|;
name|this
operator|.
name|forceMajorCompaction
operator|=
literal|false
expr_stmt|;
return|return
name|compactStores
argument_list|(
name|majorCompaction
argument_list|)
return|;
block|}
comment|/*    * Called by compaction thread and after region is opened to compact the    * HStores if necessary.    *    *<p>This operation could block for a long time, so don't call it from a     * time-sensitive thread.    *    * Note that no locking is necessary at this level because compaction only    * conflicts with a region split, and that cannot happen because the region    * server does them sequentially and not in parallel.    *     * @param majorCompaction True to force a major compaction regardless of thresholds    * @return split row if split is needed    * @throws IOException    */
name|byte
index|[]
name|compactStores
parameter_list|(
specifier|final
name|boolean
name|majorCompaction
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|this
operator|.
name|closing
operator|.
name|get
argument_list|()
operator|||
name|this
operator|.
name|closed
operator|.
name|get
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Skipping compaction on "
operator|+
name|this
operator|+
literal|" because closing/closed"
argument_list|)
expr_stmt|;
return|return
literal|null
return|;
block|}
name|splitsAndClosesLock
operator|.
name|readLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
name|byte
index|[]
name|splitRow
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|this
operator|.
name|closed
operator|.
name|get
argument_list|()
condition|)
block|{
return|return
name|splitRow
return|;
block|}
try|try
block|{
synchronized|synchronized
init|(
name|writestate
init|)
block|{
if|if
condition|(
operator|!
name|writestate
operator|.
name|compacting
operator|&&
name|writestate
operator|.
name|writesEnabled
condition|)
block|{
name|writestate
operator|.
name|compacting
operator|=
literal|true
expr_stmt|;
block|}
else|else
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"NOT compacting region "
operator|+
name|this
operator|+
literal|": compacting="
operator|+
name|writestate
operator|.
name|compacting
operator|+
literal|", writesEnabled="
operator|+
name|writestate
operator|.
name|writesEnabled
argument_list|)
expr_stmt|;
return|return
name|splitRow
return|;
block|}
block|}
name|LOG
operator|.
name|info
argument_list|(
literal|"Starting"
operator|+
operator|(
name|majorCompaction
condition|?
literal|" major "
else|:
literal|" "
operator|)
operator|+
literal|"compaction on region "
operator|+
name|this
argument_list|)
expr_stmt|;
name|long
name|startTime
init|=
name|System
operator|.
name|currentTimeMillis
argument_list|()
decl_stmt|;
name|doRegionCompactionPrep
argument_list|()
expr_stmt|;
name|long
name|maxSize
init|=
operator|-
literal|1
decl_stmt|;
for|for
control|(
name|Store
name|store
range|:
name|stores
operator|.
name|values
argument_list|()
control|)
block|{
specifier|final
name|Store
operator|.
name|StoreSize
name|ss
init|=
name|store
operator|.
name|compact
argument_list|(
name|majorCompaction
argument_list|)
decl_stmt|;
if|if
condition|(
name|ss
operator|!=
literal|null
operator|&&
name|ss
operator|.
name|getSize
argument_list|()
operator|>
name|maxSize
condition|)
block|{
name|maxSize
operator|=
name|ss
operator|.
name|getSize
argument_list|()
expr_stmt|;
name|splitRow
operator|=
name|ss
operator|.
name|getSplitRow
argument_list|()
expr_stmt|;
block|}
block|}
name|doRegionCompactionCleanup
argument_list|()
expr_stmt|;
name|String
name|timeTaken
init|=
name|StringUtils
operator|.
name|formatTimeDiff
argument_list|(
name|System
operator|.
name|currentTimeMillis
argument_list|()
argument_list|,
name|startTime
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"compaction completed on region "
operator|+
name|this
operator|+
literal|" in "
operator|+
name|timeTaken
argument_list|)
expr_stmt|;
name|this
operator|.
name|historian
operator|.
name|addRegionCompaction
argument_list|(
name|regionInfo
argument_list|,
name|timeTaken
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
synchronized|synchronized
init|(
name|writestate
init|)
block|{
name|writestate
operator|.
name|compacting
operator|=
literal|false
expr_stmt|;
name|writestate
operator|.
name|notifyAll
argument_list|()
expr_stmt|;
block|}
block|}
return|return
name|splitRow
return|;
block|}
finally|finally
block|{
name|splitsAndClosesLock
operator|.
name|readLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**    * Flush the cache.    *     * When this method is called the cache will be flushed unless:    *<ol>    *<li>the cache is empty</li>    *<li>the region is closed.</li>    *<li>a flush is already in progress</li>    *<li>writes are disabled</li>    *</ol>    *    *<p>This method may block for some time, so it should not be called from a     * time-sensitive thread.    *     * @return true if cache was flushed    *     * @throws IOException    * @throws DroppedSnapshotException Thrown when replay of hlog is required    * because a Snapshot was not properly persisted.    */
specifier|public
name|boolean
name|flushcache
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|this
operator|.
name|closed
operator|.
name|get
argument_list|()
condition|)
block|{
return|return
literal|false
return|;
block|}
synchronized|synchronized
init|(
name|writestate
init|)
block|{
if|if
condition|(
operator|!
name|writestate
operator|.
name|flushing
operator|&&
name|writestate
operator|.
name|writesEnabled
condition|)
block|{
name|this
operator|.
name|writestate
operator|.
name|flushing
operator|=
literal|true
expr_stmt|;
block|}
else|else
block|{
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"NOT flushing memstore for region "
operator|+
name|this
operator|+
literal|", flushing="
operator|+
name|writestate
operator|.
name|flushing
operator|+
literal|", writesEnabled="
operator|+
name|writestate
operator|.
name|writesEnabled
argument_list|)
expr_stmt|;
block|}
return|return
literal|false
return|;
block|}
block|}
try|try
block|{
comment|// Prevent splits and closes
name|splitsAndClosesLock
operator|.
name|readLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
return|return
name|internalFlushcache
argument_list|()
return|;
block|}
finally|finally
block|{
name|splitsAndClosesLock
operator|.
name|readLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
finally|finally
block|{
synchronized|synchronized
init|(
name|writestate
init|)
block|{
name|writestate
operator|.
name|flushing
operator|=
literal|false
expr_stmt|;
name|this
operator|.
name|writestate
operator|.
name|flushRequested
operator|=
literal|false
expr_stmt|;
name|writestate
operator|.
name|notifyAll
argument_list|()
expr_stmt|;
block|}
block|}
block|}
comment|/**    * Flushing the cache is a little tricky. We have a lot of updates in the    * memstore, all of which have also been written to the log. We need to    * write those updates in the memstore out to disk, while being able to    * process reads/writes as much as possible during the flush operation. Also,    * the log has to state clearly the point in time at which the memstore was    * flushed. (That way, during recovery, we know when we can rely on the    * on-disk flushed structures and when we have to recover the memstore from    * the log.)    *     *<p>So, we have a three-step process:    *     *<ul><li>A. Flush the memstore to the on-disk stores, noting the current    * sequence ID for the log.<li>    *     *<li>B. Write a FLUSHCACHE-COMPLETE message to the log, using the sequence    * ID that was current at the time of memstore-flush.</li>    *     *<li>C. Get rid of the memstore structures that are now redundant, as    * they've been flushed to the on-disk HStores.</li>    *</ul>    *<p>This method is protected, but can be accessed via several public    * routes.    *     *<p> This method may block for some time.    *     * @return true if the region needs compacting    *     * @throws IOException    * @throws DroppedSnapshotException Thrown when replay of hlog is required    * because a Snapshot was not properly persisted.    */
specifier|private
name|boolean
name|internalFlushcache
parameter_list|()
throws|throws
name|IOException
block|{
specifier|final
name|long
name|startTime
init|=
name|System
operator|.
name|currentTimeMillis
argument_list|()
decl_stmt|;
comment|// Clear flush flag.
comment|// Record latest flush time
name|this
operator|.
name|lastFlushTime
operator|=
name|startTime
expr_stmt|;
comment|// If nothing to flush, return and avoid logging start/stop flush.
if|if
condition|(
name|this
operator|.
name|memstoreSize
operator|.
name|get
argument_list|()
operator|<=
literal|0
condition|)
block|{
return|return
literal|false
return|;
block|}
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Started memstore flush for region "
operator|+
name|this
operator|+
literal|". Current region memstore size "
operator|+
name|StringUtils
operator|.
name|humanReadableInt
argument_list|(
name|this
operator|.
name|memstoreSize
operator|.
name|get
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|// Stop updates while we snapshot the memstore of all stores. We only have
comment|// to do this for a moment.  Its quick.  The subsequent sequence id that
comment|// goes into the HLog after we've flushed all these snapshots also goes
comment|// into the info file that sits beside the flushed files.
comment|// We also set the memstore size to zero here before we allow updates
comment|// again so its value will represent the size of the updates received
comment|// during the flush
name|long
name|sequenceId
init|=
operator|-
literal|1L
decl_stmt|;
name|long
name|completeSequenceId
init|=
operator|-
literal|1L
decl_stmt|;
name|this
operator|.
name|updatesLock
operator|.
name|writeLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
comment|// Get current size of memstores.
specifier|final
name|long
name|currentMemStoreSize
init|=
name|this
operator|.
name|memstoreSize
operator|.
name|get
argument_list|()
decl_stmt|;
try|try
block|{
for|for
control|(
name|Store
name|s
range|:
name|stores
operator|.
name|values
argument_list|()
control|)
block|{
name|s
operator|.
name|snapshot
argument_list|()
expr_stmt|;
block|}
name|sequenceId
operator|=
name|log
operator|.
name|startCacheFlush
argument_list|()
expr_stmt|;
name|completeSequenceId
operator|=
name|this
operator|.
name|getCompleteCacheFlushSequenceId
argument_list|(
name|sequenceId
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|this
operator|.
name|updatesLock
operator|.
name|writeLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
comment|// Any failure from here on out will be catastrophic requiring server
comment|// restart so hlog content can be replayed and put back into the memstore.
comment|// Otherwise, the snapshot content while backed up in the hlog, it will not
comment|// be part of the current running servers state.
name|boolean
name|compactionRequested
init|=
literal|false
decl_stmt|;
try|try
block|{
comment|// A.  Flush memstore to all the HStores.
comment|// Keep running vector of all store files that includes both old and the
comment|// just-made new flush store file.
for|for
control|(
name|Store
name|hstore
range|:
name|stores
operator|.
name|values
argument_list|()
control|)
block|{
name|boolean
name|needsCompaction
init|=
name|hstore
operator|.
name|flushCache
argument_list|(
name|completeSequenceId
argument_list|)
decl_stmt|;
if|if
condition|(
name|needsCompaction
condition|)
block|{
name|compactionRequested
operator|=
literal|true
expr_stmt|;
block|}
block|}
comment|// Set down the memstore size by amount of flush.
name|this
operator|.
name|memstoreSize
operator|.
name|addAndGet
argument_list|(
operator|-
name|currentMemStoreSize
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Throwable
name|t
parameter_list|)
block|{
comment|// An exception here means that the snapshot was not persisted.
comment|// The hlog needs to be replayed so its content is restored to memstore.
comment|// Currently, only a server restart will do this.
comment|// We used to only catch IOEs but its possible that we'd get other
comment|// exceptions -- e.g. HBASE-659 was about an NPE -- so now we catch
comment|// all and sundry.
name|this
operator|.
name|log
operator|.
name|abortCacheFlush
argument_list|()
expr_stmt|;
name|DroppedSnapshotException
name|dse
init|=
operator|new
name|DroppedSnapshotException
argument_list|(
literal|"region: "
operator|+
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|getRegionName
argument_list|()
argument_list|)
argument_list|)
decl_stmt|;
name|dse
operator|.
name|initCause
argument_list|(
name|t
argument_list|)
expr_stmt|;
throw|throw
name|dse
throw|;
block|}
comment|// If we get to here, the HStores have been written. If we get an
comment|// error in completeCacheFlush it will release the lock it is holding
comment|// B.  Write a FLUSHCACHE-COMPLETE message to the log.
comment|//     This tells future readers that the HStores were emitted correctly,
comment|//     and that all updates to the log for this regionName that have lower
comment|//     log-sequence-ids can be safely ignored.
name|this
operator|.
name|log
operator|.
name|completeCacheFlush
argument_list|(
name|getRegionName
argument_list|()
argument_list|,
name|regionInfo
operator|.
name|getTableDesc
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|,
name|completeSequenceId
argument_list|)
expr_stmt|;
comment|// C. Finally notify anyone waiting on memstore to clear:
comment|// e.g. checkResources().
synchronized|synchronized
init|(
name|this
init|)
block|{
name|notifyAll
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|long
name|now
init|=
name|System
operator|.
name|currentTimeMillis
argument_list|()
decl_stmt|;
name|String
name|timeTaken
init|=
name|StringUtils
operator|.
name|formatTimeDiff
argument_list|(
name|now
argument_list|,
name|startTime
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Finished memstore flush of ~"
operator|+
name|StringUtils
operator|.
name|humanReadableInt
argument_list|(
name|currentMemStoreSize
argument_list|)
operator|+
literal|" for region "
operator|+
name|this
operator|+
literal|" in "
operator|+
operator|(
name|now
operator|-
name|startTime
operator|)
operator|+
literal|"ms, sequence id="
operator|+
name|sequenceId
operator|+
literal|", compaction requested="
operator|+
name|compactionRequested
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|regionInfo
operator|.
name|isMetaRegion
argument_list|()
condition|)
block|{
name|this
operator|.
name|historian
operator|.
name|addRegionFlush
argument_list|(
name|regionInfo
argument_list|,
name|timeTaken
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|compactionRequested
return|;
block|}
comment|/**    * Get the sequence number to be associated with this cache flush. Used by    * TransactionalRegion to not complete pending transactions.    *     *     * @param currentSequenceId    * @return sequence id to complete the cache flush with    */
specifier|protected
name|long
name|getCompleteCacheFlushSequenceId
parameter_list|(
name|long
name|currentSequenceId
parameter_list|)
block|{
return|return
name|currentSequenceId
return|;
block|}
comment|//////////////////////////////////////////////////////////////////////////////
comment|// get() methods for client use.
comment|//////////////////////////////////////////////////////////////////////////////
comment|/**    * Return all the data for the row that matches<i>row</i> exactly,     * or the one that immediately preceeds it, at or immediately before     *<i>ts</i>.    *     * @param row row key    * @return map of values    * @throws IOException    */
name|Result
name|getClosestRowBefore
parameter_list|(
specifier|final
name|byte
index|[]
name|row
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|getClosestRowBefore
argument_list|(
name|row
argument_list|,
name|HConstants
operator|.
name|CATALOG_FAMILY
argument_list|)
return|;
block|}
comment|/**    * Return all the data for the row that matches<i>row</i> exactly,     * or the one that immediately preceeds it, at or immediately before     *<i>ts</i>.    *     * @param row row key    * @param family    * @return map of values    * @throws IOException    */
specifier|public
name|Result
name|getClosestRowBefore
parameter_list|(
specifier|final
name|byte
index|[]
name|row
parameter_list|,
specifier|final
name|byte
index|[]
name|family
parameter_list|)
throws|throws
name|IOException
block|{
comment|// look across all the HStores for this region and determine what the
comment|// closest key is across all column families, since the data may be sparse
name|KeyValue
name|key
init|=
literal|null
decl_stmt|;
name|checkRow
argument_list|(
name|row
argument_list|)
expr_stmt|;
name|splitsAndClosesLock
operator|.
name|readLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
name|Store
name|store
init|=
name|getStore
argument_list|(
name|family
argument_list|)
decl_stmt|;
name|KeyValue
name|kv
init|=
operator|new
name|KeyValue
argument_list|(
name|row
argument_list|,
name|HConstants
operator|.
name|LATEST_TIMESTAMP
argument_list|)
decl_stmt|;
comment|// get the closest key. (HStore.getRowKeyAtOrBefore can return null)
name|key
operator|=
name|store
operator|.
name|getRowKeyAtOrBefore
argument_list|(
name|kv
argument_list|)
expr_stmt|;
if|if
condition|(
name|key
operator|==
literal|null
condition|)
block|{
return|return
literal|null
return|;
block|}
comment|// This will get all results for this store.  TODO: Do we need to do this?
name|Get
name|get
init|=
operator|new
name|Get
argument_list|(
name|key
operator|.
name|getRow
argument_list|()
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|KeyValue
argument_list|>
name|results
init|=
operator|new
name|ArrayList
argument_list|<
name|KeyValue
argument_list|>
argument_list|()
decl_stmt|;
name|store
operator|.
name|get
argument_list|(
name|get
argument_list|,
literal|null
argument_list|,
name|results
argument_list|)
expr_stmt|;
return|return
operator|new
name|Result
argument_list|(
name|results
argument_list|)
return|;
block|}
finally|finally
block|{
name|splitsAndClosesLock
operator|.
name|readLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**    * Return an iterator that scans over the HRegion, returning the indicated     * columns and rows specified by the {@link Scan}.    *<p>    * This Iterator must be closed by the caller.    *    * @param scan configured {@link Scan}    * @return InternalScanner    * @throws IOException    */
specifier|public
name|InternalScanner
name|getScanner
parameter_list|(
name|Scan
name|scan
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|getScanner
argument_list|(
name|scan
argument_list|,
literal|null
argument_list|)
return|;
block|}
specifier|protected
name|InternalScanner
name|getScanner
parameter_list|(
name|Scan
name|scan
parameter_list|,
name|List
argument_list|<
name|KeyValueScanner
argument_list|>
name|additionalScanners
parameter_list|)
throws|throws
name|IOException
block|{
name|newScannerLock
operator|.
name|readLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
if|if
condition|(
name|this
operator|.
name|closed
operator|.
name|get
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Region "
operator|+
name|this
operator|+
literal|" closed"
argument_list|)
throw|;
block|}
comment|// Verify families are all valid
if|if
condition|(
name|scan
operator|.
name|hasFamilies
argument_list|()
condition|)
block|{
for|for
control|(
name|byte
index|[]
name|family
range|:
name|scan
operator|.
name|getFamilyMap
argument_list|()
operator|.
name|keySet
argument_list|()
control|)
block|{
name|checkFamily
argument_list|(
name|family
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
comment|// Adding all families to scanner
for|for
control|(
name|byte
index|[]
name|family
range|:
name|regionInfo
operator|.
name|getTableDesc
argument_list|()
operator|.
name|getFamiliesKeys
argument_list|()
control|)
block|{
name|scan
operator|.
name|addFamily
argument_list|(
name|family
argument_list|)
expr_stmt|;
block|}
block|}
return|return
operator|new
name|RegionScanner
argument_list|(
name|scan
argument_list|,
name|additionalScanners
argument_list|)
return|;
block|}
finally|finally
block|{
name|newScannerLock
operator|.
name|readLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
comment|//////////////////////////////////////////////////////////////////////////////
comment|// set() methods for client use.
comment|//////////////////////////////////////////////////////////////////////////////
comment|/**    * @param delete    * @param lockid    * @param writeToWAL    * @throws IOException    */
specifier|public
name|void
name|delete
parameter_list|(
name|Delete
name|delete
parameter_list|,
name|Integer
name|lockid
parameter_list|,
name|boolean
name|writeToWAL
parameter_list|)
throws|throws
name|IOException
block|{
name|checkReadOnly
argument_list|()
expr_stmt|;
name|checkResources
argument_list|()
expr_stmt|;
name|splitsAndClosesLock
operator|.
name|readLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
name|Integer
name|lid
init|=
literal|null
decl_stmt|;
try|try
block|{
name|byte
index|[]
name|row
init|=
name|delete
operator|.
name|getRow
argument_list|()
decl_stmt|;
comment|// If we did not pass an existing row lock, obtain a new one
name|lid
operator|=
name|getLock
argument_list|(
name|lockid
argument_list|,
name|row
argument_list|)
expr_stmt|;
comment|//Check to see if this is a deleteRow insert
if|if
condition|(
name|delete
operator|.
name|getFamilyMap
argument_list|()
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
for|for
control|(
name|byte
index|[]
name|family
range|:
name|regionInfo
operator|.
name|getTableDesc
argument_list|()
operator|.
name|getFamiliesKeys
argument_list|()
control|)
block|{
comment|// Don't eat the timestamp
name|delete
operator|.
name|deleteFamily
argument_list|(
name|family
argument_list|,
name|delete
operator|.
name|getTimeStamp
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
for|for
control|(
name|byte
index|[]
name|family
range|:
name|delete
operator|.
name|getFamilyMap
argument_list|()
operator|.
name|keySet
argument_list|()
control|)
block|{
if|if
condition|(
name|family
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|NoSuchColumnFamilyException
argument_list|(
literal|"Empty family is invalid"
argument_list|)
throw|;
block|}
name|checkFamily
argument_list|(
name|family
argument_list|)
expr_stmt|;
block|}
block|}
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|byte
index|[]
argument_list|,
name|List
argument_list|<
name|KeyValue
argument_list|>
argument_list|>
name|e
range|:
name|delete
operator|.
name|getFamilyMap
argument_list|()
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|byte
index|[]
name|family
init|=
name|e
operator|.
name|getKey
argument_list|()
decl_stmt|;
name|delete
argument_list|(
name|family
argument_list|,
name|e
operator|.
name|getValue
argument_list|()
argument_list|,
name|writeToWAL
argument_list|)
expr_stmt|;
block|}
block|}
finally|finally
block|{
if|if
condition|(
name|lockid
operator|==
literal|null
condition|)
name|releaseRowLock
argument_list|(
name|lid
argument_list|)
expr_stmt|;
name|splitsAndClosesLock
operator|.
name|readLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**    * @param family    * @param kvs    * @param writeToWAL    * @throws IOException    */
specifier|public
name|void
name|delete
parameter_list|(
name|byte
index|[]
name|family
parameter_list|,
name|List
argument_list|<
name|KeyValue
argument_list|>
name|kvs
parameter_list|,
name|boolean
name|writeToWAL
parameter_list|)
throws|throws
name|IOException
block|{
name|long
name|now
init|=
name|System
operator|.
name|currentTimeMillis
argument_list|()
decl_stmt|;
name|byte
index|[]
name|byteNow
init|=
name|Bytes
operator|.
name|toBytes
argument_list|(
name|now
argument_list|)
decl_stmt|;
name|boolean
name|flush
init|=
literal|false
decl_stmt|;
name|this
operator|.
name|updatesLock
operator|.
name|readLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
if|if
condition|(
name|writeToWAL
condition|)
block|{
name|this
operator|.
name|log
operator|.
name|append
argument_list|(
name|regionInfo
operator|.
name|getRegionName
argument_list|()
argument_list|,
name|regionInfo
operator|.
name|getTableDesc
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|,
name|kvs
argument_list|,
operator|(
name|regionInfo
operator|.
name|isMetaRegion
argument_list|()
operator|||
name|regionInfo
operator|.
name|isRootRegion
argument_list|()
operator|)
argument_list|,
name|now
argument_list|)
expr_stmt|;
block|}
name|long
name|size
init|=
literal|0
decl_stmt|;
name|Store
name|store
init|=
name|getStore
argument_list|(
name|family
argument_list|)
decl_stmt|;
for|for
control|(
name|KeyValue
name|kv
range|:
name|kvs
control|)
block|{
comment|// Check if time is LATEST, change to time of most recent addition if so
comment|// This is expensive.
if|if
condition|(
name|kv
operator|.
name|isLatestTimestamp
argument_list|()
operator|&&
name|kv
operator|.
name|isDeleteType
argument_list|()
condition|)
block|{
name|List
argument_list|<
name|KeyValue
argument_list|>
name|result
init|=
operator|new
name|ArrayList
argument_list|<
name|KeyValue
argument_list|>
argument_list|(
literal|1
argument_list|)
decl_stmt|;
name|Get
name|g
init|=
operator|new
name|Get
argument_list|(
name|kv
operator|.
name|getRow
argument_list|()
argument_list|)
decl_stmt|;
name|NavigableSet
argument_list|<
name|byte
index|[]
argument_list|>
name|qualifiers
init|=
operator|new
name|TreeSet
argument_list|<
name|byte
index|[]
argument_list|>
argument_list|(
name|Bytes
operator|.
name|BYTES_COMPARATOR
argument_list|)
decl_stmt|;
name|byte
index|[]
name|q
init|=
name|kv
operator|.
name|getQualifier
argument_list|()
decl_stmt|;
if|if
condition|(
name|q
operator|==
literal|null
condition|)
name|q
operator|=
name|HConstants
operator|.
name|EMPTY_BYTE_ARRAY
expr_stmt|;
name|qualifiers
operator|.
name|add
argument_list|(
name|q
argument_list|)
expr_stmt|;
name|get
argument_list|(
name|store
argument_list|,
name|g
argument_list|,
name|qualifiers
argument_list|,
name|result
argument_list|)
expr_stmt|;
if|if
condition|(
name|result
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
comment|// Nothing to delete
continue|continue;
block|}
if|if
condition|(
name|result
operator|.
name|size
argument_list|()
operator|>
literal|1
condition|)
block|{
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"Unexpected size: "
operator|+
name|result
operator|.
name|size
argument_list|()
argument_list|)
throw|;
block|}
name|KeyValue
name|getkv
init|=
name|result
operator|.
name|get
argument_list|(
literal|0
argument_list|)
decl_stmt|;
name|Bytes
operator|.
name|putBytes
argument_list|(
name|kv
operator|.
name|getBuffer
argument_list|()
argument_list|,
name|kv
operator|.
name|getTimestampOffset
argument_list|()
argument_list|,
name|getkv
operator|.
name|getBuffer
argument_list|()
argument_list|,
name|getkv
operator|.
name|getTimestampOffset
argument_list|()
argument_list|,
name|Bytes
operator|.
name|SIZEOF_LONG
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|kv
operator|.
name|updateLatestStamp
argument_list|(
name|byteNow
argument_list|)
expr_stmt|;
block|}
name|size
operator|=
name|this
operator|.
name|memstoreSize
operator|.
name|addAndGet
argument_list|(
name|store
operator|.
name|delete
argument_list|(
name|kv
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|flush
operator|=
name|isFlushSize
argument_list|(
name|size
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|this
operator|.
name|updatesLock
operator|.
name|readLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|flush
condition|)
block|{
comment|// Request a cache flush.  Do it outside update lock.
name|requestFlush
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**    * @param put    * @throws IOException    */
specifier|public
name|void
name|put
parameter_list|(
name|Put
name|put
parameter_list|)
throws|throws
name|IOException
block|{
name|this
operator|.
name|put
argument_list|(
name|put
argument_list|,
literal|null
argument_list|,
name|put
operator|.
name|getWriteToWAL
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|/**    * @param put    * @param writeToWAL    * @throws IOException    */
specifier|public
name|void
name|put
parameter_list|(
name|Put
name|put
parameter_list|,
name|boolean
name|writeToWAL
parameter_list|)
throws|throws
name|IOException
block|{
name|this
operator|.
name|put
argument_list|(
name|put
argument_list|,
literal|null
argument_list|,
name|writeToWAL
argument_list|)
expr_stmt|;
block|}
comment|/**    * @param put    * @param lockid    * @throws IOException    */
specifier|public
name|void
name|put
parameter_list|(
name|Put
name|put
parameter_list|,
name|Integer
name|lockid
parameter_list|)
throws|throws
name|IOException
block|{
name|this
operator|.
name|put
argument_list|(
name|put
argument_list|,
name|lockid
argument_list|,
name|put
operator|.
name|getWriteToWAL
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|/**    * @param put    * @param lockid    * @param writeToWAL    * @throws IOException    */
specifier|public
name|void
name|put
parameter_list|(
name|Put
name|put
parameter_list|,
name|Integer
name|lockid
parameter_list|,
name|boolean
name|writeToWAL
parameter_list|)
throws|throws
name|IOException
block|{
name|checkReadOnly
argument_list|()
expr_stmt|;
comment|// Do a rough check that we have resources to accept a write.  The check is
comment|// 'rough' in that between the resource check and the call to obtain a
comment|// read lock, resources may run out.  For now, the thought is that this
comment|// will be extremely rare; we'll deal with it when it happens.
name|checkResources
argument_list|()
expr_stmt|;
name|splitsAndClosesLock
operator|.
name|readLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
comment|// We obtain a per-row lock, so other clients will block while one client
comment|// performs an update. The read lock is released by the client calling
comment|// #commit or #abort or if the HRegionServer lease on the lock expires.
comment|// See HRegionServer#RegionListener for how the expire on HRegionServer
comment|// invokes a HRegion#abort.
name|byte
index|[]
name|row
init|=
name|put
operator|.
name|getRow
argument_list|()
decl_stmt|;
comment|// If we did not pass an existing row lock, obtain a new one
name|Integer
name|lid
init|=
name|getLock
argument_list|(
name|lockid
argument_list|,
name|row
argument_list|)
decl_stmt|;
name|byte
index|[]
name|now
init|=
name|Bytes
operator|.
name|toBytes
argument_list|(
name|System
operator|.
name|currentTimeMillis
argument_list|()
argument_list|)
decl_stmt|;
try|try
block|{
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|byte
index|[]
argument_list|,
name|List
argument_list|<
name|KeyValue
argument_list|>
argument_list|>
name|entry
range|:
name|put
operator|.
name|getFamilyMap
argument_list|()
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|byte
index|[]
name|family
init|=
name|entry
operator|.
name|getKey
argument_list|()
decl_stmt|;
name|checkFamily
argument_list|(
name|family
argument_list|)
expr_stmt|;
name|List
argument_list|<
name|KeyValue
argument_list|>
name|puts
init|=
name|entry
operator|.
name|getValue
argument_list|()
decl_stmt|;
if|if
condition|(
name|updateKeys
argument_list|(
name|puts
argument_list|,
name|now
argument_list|)
condition|)
block|{
name|put
argument_list|(
name|family
argument_list|,
name|puts
argument_list|,
name|writeToWAL
argument_list|)
expr_stmt|;
block|}
block|}
block|}
finally|finally
block|{
if|if
condition|(
name|lockid
operator|==
literal|null
condition|)
name|releaseRowLock
argument_list|(
name|lid
argument_list|)
expr_stmt|;
block|}
block|}
finally|finally
block|{
name|splitsAndClosesLock
operator|.
name|readLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
comment|//TODO, Think that gets/puts and deletes should be refactored a bit so that
comment|//the getting of the lock happens before, so that you would just pass it into
comment|//the methods. So in the case of checkAndPut you could just do lockRow,
comment|//get, put, unlockRow or something
comment|/**    *     * @param row    * @param family    * @param qualifier    * @param expectedValue    * @param put    * @param lockId    * @param writeToWAL    * @throws IOException    * @return true if the new put was execute, false otherwise    */
specifier|public
name|boolean
name|checkAndPut
parameter_list|(
name|byte
index|[]
name|row
parameter_list|,
name|byte
index|[]
name|family
parameter_list|,
name|byte
index|[]
name|qualifier
parameter_list|,
name|byte
index|[]
name|expectedValue
parameter_list|,
name|Put
name|put
parameter_list|,
name|Integer
name|lockId
parameter_list|,
name|boolean
name|writeToWAL
parameter_list|)
throws|throws
name|IOException
block|{
name|checkReadOnly
argument_list|()
expr_stmt|;
comment|//TODO, add check for value length or maybe even better move this to the
comment|//client if this becomes a global setting
name|checkResources
argument_list|()
expr_stmt|;
name|splitsAndClosesLock
operator|.
name|readLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
name|Get
name|get
init|=
operator|new
name|Get
argument_list|(
name|row
argument_list|,
name|put
operator|.
name|getRowLock
argument_list|()
argument_list|)
decl_stmt|;
name|checkFamily
argument_list|(
name|family
argument_list|)
expr_stmt|;
name|get
operator|.
name|addColumn
argument_list|(
name|family
argument_list|,
name|qualifier
argument_list|)
expr_stmt|;
name|byte
index|[]
name|now
init|=
name|Bytes
operator|.
name|toBytes
argument_list|(
name|System
operator|.
name|currentTimeMillis
argument_list|()
argument_list|)
decl_stmt|;
comment|// Lock row
name|Integer
name|lid
init|=
name|getLock
argument_list|(
name|lockId
argument_list|,
name|get
operator|.
name|getRow
argument_list|()
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|KeyValue
argument_list|>
name|result
init|=
operator|new
name|ArrayList
argument_list|<
name|KeyValue
argument_list|>
argument_list|()
decl_stmt|;
try|try
block|{
comment|//Getting data
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|byte
index|[]
argument_list|,
name|NavigableSet
argument_list|<
name|byte
index|[]
argument_list|>
argument_list|>
name|entry
range|:
name|get
operator|.
name|getFamilyMap
argument_list|()
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|get
argument_list|(
name|this
operator|.
name|stores
operator|.
name|get
argument_list|(
name|entry
operator|.
name|getKey
argument_list|()
argument_list|)
argument_list|,
name|get
argument_list|,
name|entry
operator|.
name|getValue
argument_list|()
argument_list|,
name|result
argument_list|)
expr_stmt|;
block|}
name|boolean
name|matches
init|=
literal|false
decl_stmt|;
if|if
condition|(
name|result
operator|.
name|size
argument_list|()
operator|==
literal|0
operator|&&
name|expectedValue
operator|.
name|length
operator|==
literal|0
condition|)
block|{
name|matches
operator|=
literal|true
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|result
operator|.
name|size
argument_list|()
operator|==
literal|1
condition|)
block|{
comment|//Compare the expected value with the actual value
name|byte
index|[]
name|actualValue
init|=
name|result
operator|.
name|get
argument_list|(
literal|0
argument_list|)
operator|.
name|getValue
argument_list|()
decl_stmt|;
name|matches
operator|=
name|Bytes
operator|.
name|equals
argument_list|(
name|expectedValue
argument_list|,
name|actualValue
argument_list|)
expr_stmt|;
block|}
comment|//If matches put the new put
if|if
condition|(
name|matches
condition|)
block|{
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|byte
index|[]
argument_list|,
name|List
argument_list|<
name|KeyValue
argument_list|>
argument_list|>
name|entry
range|:
name|put
operator|.
name|getFamilyMap
argument_list|()
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|byte
index|[]
name|fam
init|=
name|entry
operator|.
name|getKey
argument_list|()
decl_stmt|;
name|checkFamily
argument_list|(
name|fam
argument_list|)
expr_stmt|;
name|List
argument_list|<
name|KeyValue
argument_list|>
name|puts
init|=
name|entry
operator|.
name|getValue
argument_list|()
decl_stmt|;
if|if
condition|(
name|updateKeys
argument_list|(
name|puts
argument_list|,
name|now
argument_list|)
condition|)
block|{
name|put
argument_list|(
name|fam
argument_list|,
name|puts
argument_list|,
name|writeToWAL
argument_list|)
expr_stmt|;
block|}
block|}
return|return
literal|true
return|;
block|}
return|return
literal|false
return|;
block|}
finally|finally
block|{
if|if
condition|(
name|lockId
operator|==
literal|null
condition|)
name|releaseRowLock
argument_list|(
name|lid
argument_list|)
expr_stmt|;
block|}
block|}
finally|finally
block|{
name|splitsAndClosesLock
operator|.
name|readLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**    * Checks if any stamps is Long.MAX_VALUE.  If so, sets them to now.    *<p>    * This acts to replace LATEST_TIMESTAMP with now.    * @param keys    * @param now    * @return<code>true</code> when updating the time stamp completed.    */
specifier|private
name|boolean
name|updateKeys
parameter_list|(
name|List
argument_list|<
name|KeyValue
argument_list|>
name|keys
parameter_list|,
name|byte
index|[]
name|now
parameter_list|)
block|{
if|if
condition|(
name|keys
operator|==
literal|null
operator|||
name|keys
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
return|return
literal|false
return|;
block|}
for|for
control|(
name|KeyValue
name|key
range|:
name|keys
control|)
block|{
if|if
condition|(
name|key
operator|.
name|getTimestamp
argument_list|()
operator|==
name|HConstants
operator|.
name|LATEST_TIMESTAMP
condition|)
block|{
name|key
operator|.
name|updateLatestStamp
argument_list|(
name|now
argument_list|)
expr_stmt|;
block|}
block|}
return|return
literal|true
return|;
block|}
comment|//  /*
comment|//   * Utility method to verify values length.
comment|//   * @param batchUpdate The update to verify
comment|//   * @throws IOException Thrown if a value is too long
comment|//   */
comment|//  private void validateValuesLength(Put put)
comment|//  throws IOException {
comment|//    Map<byte[], List<KeyValue>> families = put.getFamilyMap();
comment|//    for(Map.Entry<byte[], List<KeyValue>> entry : families.entrySet()) {
comment|//      HColumnDescriptor hcd =
comment|//        this.regionInfo.getTableDesc().getFamily(entry.getKey());
comment|//      int maxLen = hcd.getMaxValueLength();
comment|//      for(KeyValue kv : entry.getValue()) {
comment|//        if(kv.getValueLength()> maxLen) {
comment|//          throw new ValueOverMaxLengthException("Value in column "
comment|//            + Bytes.toString(kv.getColumn()) + " is too long. "
comment|//            + kv.getValueLength() + "> " + maxLen);
comment|//        }
comment|//      }
comment|//    }
comment|//  }
comment|/*    * Check if resources to support an update.    *     * Here we synchronize on HRegion, a broad scoped lock.  Its appropriate    * given we're figuring in here whether this region is able to take on    * writes.  This is only method with a synchronize (at time of writing),    * this and the synchronize on 'this' inside in internalFlushCache to send    * the notify.    */
specifier|private
name|void
name|checkResources
parameter_list|()
block|{
name|boolean
name|blocked
init|=
literal|false
decl_stmt|;
while|while
condition|(
name|this
operator|.
name|memstoreSize
operator|.
name|get
argument_list|()
operator|>
name|this
operator|.
name|blockingMemStoreSize
condition|)
block|{
name|requestFlush
argument_list|()
expr_stmt|;
if|if
condition|(
operator|!
name|blocked
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Blocking updates for '"
operator|+
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|"' on region "
operator|+
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|getRegionName
argument_list|()
argument_list|)
operator|+
literal|": memstore size "
operator|+
name|StringUtils
operator|.
name|humanReadableInt
argument_list|(
name|this
operator|.
name|memstoreSize
operator|.
name|get
argument_list|()
argument_list|)
operator|+
literal|" is>= than blocking "
operator|+
name|StringUtils
operator|.
name|humanReadableInt
argument_list|(
name|this
operator|.
name|blockingMemStoreSize
argument_list|)
operator|+
literal|" size"
argument_list|)
expr_stmt|;
block|}
name|blocked
operator|=
literal|true
expr_stmt|;
synchronized|synchronized
init|(
name|this
init|)
block|{
try|try
block|{
name|wait
argument_list|(
name|threadWakeFrequency
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
comment|// continue;
block|}
block|}
block|}
if|if
condition|(
name|blocked
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Unblocking updates for region "
operator|+
name|this
operator|+
literal|" '"
operator|+
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|"'"
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * @throws IOException Throws exception if region is in read-only mode.    */
specifier|protected
name|void
name|checkReadOnly
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|this
operator|.
name|writestate
operator|.
name|isReadOnly
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"region is read only"
argument_list|)
throw|;
block|}
block|}
comment|/**     * Add updates first to the hlog and then add values to memstore.    * Warning: Assumption is caller has lock on passed in row.    * @param edits Cell updates by column    * @praram now    * @throws IOException    */
specifier|private
name|void
name|put
parameter_list|(
specifier|final
name|byte
index|[]
name|family
parameter_list|,
specifier|final
name|List
argument_list|<
name|KeyValue
argument_list|>
name|edits
parameter_list|)
throws|throws
name|IOException
block|{
name|this
operator|.
name|put
argument_list|(
name|family
argument_list|,
name|edits
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
comment|/**     * Add updates first to the hlog (if writeToWal) and then add values to memstore.    * Warning: Assumption is caller has lock on passed in row.    * @param family    * @param edits    * @param writeToWAL if true, then we should write to the log    * @throws IOException    */
specifier|private
name|void
name|put
parameter_list|(
specifier|final
name|byte
index|[]
name|family
parameter_list|,
specifier|final
name|List
argument_list|<
name|KeyValue
argument_list|>
name|edits
parameter_list|,
name|boolean
name|writeToWAL
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|edits
operator|==
literal|null
operator|||
name|edits
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
return|return;
block|}
name|boolean
name|flush
init|=
literal|false
decl_stmt|;
name|this
operator|.
name|updatesLock
operator|.
name|readLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
if|if
condition|(
name|writeToWAL
condition|)
block|{
name|long
name|now
init|=
name|System
operator|.
name|currentTimeMillis
argument_list|()
decl_stmt|;
name|this
operator|.
name|log
operator|.
name|append
argument_list|(
name|regionInfo
operator|.
name|getRegionName
argument_list|()
argument_list|,
name|regionInfo
operator|.
name|getTableDesc
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|,
name|edits
argument_list|,
operator|(
name|regionInfo
operator|.
name|isMetaRegion
argument_list|()
operator|||
name|regionInfo
operator|.
name|isRootRegion
argument_list|()
operator|)
argument_list|,
name|now
argument_list|)
expr_stmt|;
block|}
name|long
name|size
init|=
literal|0
decl_stmt|;
name|Store
name|store
init|=
name|getStore
argument_list|(
name|family
argument_list|)
decl_stmt|;
for|for
control|(
name|KeyValue
name|kv
range|:
name|edits
control|)
block|{
name|size
operator|=
name|this
operator|.
name|memstoreSize
operator|.
name|addAndGet
argument_list|(
name|store
operator|.
name|add
argument_list|(
name|kv
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|flush
operator|=
name|isFlushSize
argument_list|(
name|size
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|this
operator|.
name|updatesLock
operator|.
name|readLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|flush
condition|)
block|{
comment|// Request a cache flush.  Do it outside update lock.
name|requestFlush
argument_list|()
expr_stmt|;
block|}
block|}
specifier|private
name|void
name|requestFlush
parameter_list|()
block|{
if|if
condition|(
name|this
operator|.
name|flushListener
operator|==
literal|null
condition|)
block|{
return|return;
block|}
synchronized|synchronized
init|(
name|writestate
init|)
block|{
if|if
condition|(
name|this
operator|.
name|writestate
operator|.
name|isFlushRequested
argument_list|()
condition|)
block|{
return|return;
block|}
name|writestate
operator|.
name|flushRequested
operator|=
literal|true
expr_stmt|;
block|}
comment|// Make request outside of synchronize block; HBASE-818.
name|this
operator|.
name|flushListener
operator|.
name|request
argument_list|(
name|this
argument_list|)
expr_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Flush requested on "
operator|+
name|this
argument_list|)
expr_stmt|;
block|}
block|}
comment|/*    * @param size    * @return True if size is over the flush threshold    */
specifier|private
name|boolean
name|isFlushSize
parameter_list|(
specifier|final
name|long
name|size
parameter_list|)
block|{
return|return
name|size
operator|>
name|this
operator|.
name|memstoreFlushSize
return|;
block|}
comment|// Do any reconstruction needed from the log
specifier|protected
name|void
name|doReconstructionLog
parameter_list|(
name|Path
name|oldLogFile
parameter_list|,
name|long
name|minSeqId
parameter_list|,
name|long
name|maxSeqId
parameter_list|,
name|Progressable
name|reporter
parameter_list|)
throws|throws
name|UnsupportedEncodingException
throws|,
name|IOException
block|{
comment|// Nothing to do (Replaying is done in HStores)
comment|// Used by subclasses; e.g. THBase.
block|}
specifier|protected
name|Store
name|instantiateHStore
parameter_list|(
name|Path
name|baseDir
parameter_list|,
name|HColumnDescriptor
name|c
parameter_list|,
name|Path
name|oldLogFile
parameter_list|,
name|Progressable
name|reporter
parameter_list|)
throws|throws
name|IOException
block|{
return|return
operator|new
name|Store
argument_list|(
name|baseDir
argument_list|,
name|this
argument_list|,
name|c
argument_list|,
name|this
operator|.
name|fs
argument_list|,
name|oldLogFile
argument_list|,
name|this
operator|.
name|conf
argument_list|,
name|reporter
argument_list|)
return|;
block|}
comment|/**    * Return HStore instance.    * Use with caution.  Exposed for use of fixup utilities.    * @param column Name of column family hosted by this region.    * @return Store that goes with the family on passed<code>column</code>.    * TODO: Make this lookup faster.    */
specifier|public
name|Store
name|getStore
parameter_list|(
specifier|final
name|byte
index|[]
name|column
parameter_list|)
block|{
return|return
name|this
operator|.
name|stores
operator|.
name|get
argument_list|(
name|column
argument_list|)
return|;
block|}
comment|//////////////////////////////////////////////////////////////////////////////
comment|// Support code
comment|//////////////////////////////////////////////////////////////////////////////
comment|/** Make sure this is a valid row for the HRegion */
specifier|private
name|void
name|checkRow
parameter_list|(
specifier|final
name|byte
index|[]
name|row
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
operator|!
name|rowIsInRange
argument_list|(
name|regionInfo
argument_list|,
name|row
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|WrongRegionException
argument_list|(
literal|"Requested row out of range for "
operator|+
literal|"HRegion "
operator|+
name|this
operator|+
literal|", startKey='"
operator|+
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|regionInfo
operator|.
name|getStartKey
argument_list|()
argument_list|)
operator|+
literal|"', getEndKey()='"
operator|+
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|regionInfo
operator|.
name|getEndKey
argument_list|()
argument_list|)
operator|+
literal|"', row='"
operator|+
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|row
argument_list|)
operator|+
literal|"'"
argument_list|)
throw|;
block|}
block|}
comment|/**    * Obtain a lock on the given row.  Blocks until success.    *    * I know it's strange to have two mappings:    *<pre>    *   ROWS  ==> LOCKS    *</pre>    * as well as    *<pre>    *   LOCKS ==> ROWS    *</pre>    *    * But it acts as a guard on the client; a miswritten client just can't    * submit the name of a row and start writing to it; it must know the correct    * lockid, which matches the lock list in memory.    *     *<p>It would be more memory-efficient to assume a correctly-written client,     * which maybe we'll do in the future.    *     * @param row Name of row to lock.    * @throws IOException    * @return The id of the held lock.    */
specifier|public
name|Integer
name|obtainRowLock
parameter_list|(
specifier|final
name|byte
index|[]
name|row
parameter_list|)
throws|throws
name|IOException
block|{
name|checkRow
argument_list|(
name|row
argument_list|)
expr_stmt|;
name|splitsAndClosesLock
operator|.
name|readLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
if|if
condition|(
name|this
operator|.
name|closed
operator|.
name|get
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|NotServingRegionException
argument_list|(
literal|"Region "
operator|+
name|this
operator|+
literal|" closed"
argument_list|)
throw|;
block|}
name|Integer
name|key
init|=
name|Bytes
operator|.
name|mapKey
argument_list|(
name|row
argument_list|)
decl_stmt|;
synchronized|synchronized
init|(
name|locksToRows
init|)
block|{
while|while
condition|(
name|locksToRows
operator|.
name|containsKey
argument_list|(
name|key
argument_list|)
condition|)
block|{
try|try
block|{
name|locksToRows
operator|.
name|wait
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|ie
parameter_list|)
block|{
comment|// Empty
block|}
block|}
name|locksToRows
operator|.
name|put
argument_list|(
name|key
argument_list|,
name|row
argument_list|)
expr_stmt|;
name|locksToRows
operator|.
name|notifyAll
argument_list|()
expr_stmt|;
return|return
name|key
return|;
block|}
block|}
finally|finally
block|{
name|splitsAndClosesLock
operator|.
name|readLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**    * Used by unit tests.    * @param lockid    * @return Row that goes with<code>lockid</code>    */
name|byte
index|[]
name|getRowFromLock
parameter_list|(
specifier|final
name|Integer
name|lockid
parameter_list|)
block|{
return|return
name|locksToRows
operator|.
name|get
argument_list|(
name|lockid
argument_list|)
return|;
block|}
comment|/**     * Release the row lock!    * @param lockid  The lock ID to release.    */
name|void
name|releaseRowLock
parameter_list|(
specifier|final
name|Integer
name|lockid
parameter_list|)
block|{
synchronized|synchronized
init|(
name|locksToRows
init|)
block|{
name|locksToRows
operator|.
name|remove
argument_list|(
name|lockid
argument_list|)
expr_stmt|;
name|locksToRows
operator|.
name|notifyAll
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**    * See if row is currently locked.    * @param lockid    * @return boolean    */
specifier|private
name|boolean
name|isRowLocked
parameter_list|(
specifier|final
name|Integer
name|lockid
parameter_list|)
block|{
synchronized|synchronized
init|(
name|locksToRows
init|)
block|{
if|if
condition|(
name|locksToRows
operator|.
name|containsKey
argument_list|(
name|lockid
argument_list|)
condition|)
block|{
return|return
literal|true
return|;
block|}
return|return
literal|false
return|;
block|}
block|}
comment|/**    * Returns existing row lock if found, otherwise    * obtains a new row lock and returns it.    * @param lockid    * @return lockid    */
specifier|private
name|Integer
name|getLock
parameter_list|(
name|Integer
name|lockid
parameter_list|,
name|byte
index|[]
name|row
parameter_list|)
throws|throws
name|IOException
block|{
name|Integer
name|lid
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|lockid
operator|==
literal|null
condition|)
block|{
name|lid
operator|=
name|obtainRowLock
argument_list|(
name|row
argument_list|)
expr_stmt|;
block|}
else|else
block|{
if|if
condition|(
operator|!
name|isRowLocked
argument_list|(
name|lockid
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Invalid row lock"
argument_list|)
throw|;
block|}
name|lid
operator|=
name|lockid
expr_stmt|;
block|}
return|return
name|lid
return|;
block|}
specifier|private
name|void
name|waitOnRowLocks
parameter_list|()
block|{
synchronized|synchronized
init|(
name|locksToRows
init|)
block|{
while|while
condition|(
name|this
operator|.
name|locksToRows
operator|.
name|size
argument_list|()
operator|>
literal|0
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"waiting for "
operator|+
name|this
operator|.
name|locksToRows
operator|.
name|size
argument_list|()
operator|+
literal|" row locks"
argument_list|)
expr_stmt|;
try|try
block|{
name|this
operator|.
name|locksToRows
operator|.
name|wait
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
comment|// Catch. Let while test determine loop-end.
block|}
block|}
block|}
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|equals
parameter_list|(
name|Object
name|o
parameter_list|)
block|{
return|return
name|this
operator|.
name|hashCode
argument_list|()
operator|==
operator|(
operator|(
name|HRegion
operator|)
name|o
operator|)
operator|.
name|hashCode
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|int
name|hashCode
parameter_list|()
block|{
return|return
name|this
operator|.
name|regionInfo
operator|.
name|getRegionName
argument_list|()
operator|.
name|hashCode
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|String
name|toString
parameter_list|()
block|{
return|return
name|this
operator|.
name|regionInfo
operator|.
name|getRegionNameAsString
argument_list|()
return|;
block|}
comment|/** @return Path of region base directory */
specifier|public
name|Path
name|getBaseDir
parameter_list|()
block|{
return|return
name|this
operator|.
name|basedir
return|;
block|}
comment|/**    * RegionScanner is an iterator through a bunch of rows in an HRegion.    *<p>    * It is used to combine scanners from multiple Stores (aka column families).    */
class|class
name|RegionScanner
implements|implements
name|InternalScanner
block|{
specifier|private
specifier|final
name|KeyValueHeap
name|storeHeap
decl_stmt|;
specifier|private
specifier|final
name|byte
index|[]
name|stopRow
decl_stmt|;
specifier|private
name|Filter
name|filter
decl_stmt|;
specifier|private
name|List
argument_list|<
name|KeyValue
argument_list|>
name|results
init|=
operator|new
name|ArrayList
argument_list|<
name|KeyValue
argument_list|>
argument_list|()
decl_stmt|;
name|RegionScanner
parameter_list|(
name|Scan
name|scan
parameter_list|,
name|List
argument_list|<
name|KeyValueScanner
argument_list|>
name|additionalScanners
parameter_list|)
block|{
name|this
operator|.
name|filter
operator|=
name|scan
operator|.
name|getFilter
argument_list|()
expr_stmt|;
if|if
condition|(
name|Bytes
operator|.
name|equals
argument_list|(
name|scan
operator|.
name|getStopRow
argument_list|()
argument_list|,
name|HConstants
operator|.
name|EMPTY_END_ROW
argument_list|)
condition|)
block|{
name|this
operator|.
name|stopRow
operator|=
literal|null
expr_stmt|;
block|}
else|else
block|{
name|this
operator|.
name|stopRow
operator|=
name|scan
operator|.
name|getStopRow
argument_list|()
expr_stmt|;
block|}
name|List
argument_list|<
name|KeyValueScanner
argument_list|>
name|scanners
init|=
operator|new
name|ArrayList
argument_list|<
name|KeyValueScanner
argument_list|>
argument_list|()
decl_stmt|;
if|if
condition|(
name|additionalScanners
operator|!=
literal|null
condition|)
block|{
name|scanners
operator|.
name|addAll
argument_list|(
name|additionalScanners
argument_list|)
expr_stmt|;
block|}
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|byte
index|[]
argument_list|,
name|NavigableSet
argument_list|<
name|byte
index|[]
argument_list|>
argument_list|>
name|entry
range|:
name|scan
operator|.
name|getFamilyMap
argument_list|()
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|Store
name|store
init|=
name|stores
operator|.
name|get
argument_list|(
name|entry
operator|.
name|getKey
argument_list|()
argument_list|)
decl_stmt|;
name|scanners
operator|.
name|add
argument_list|(
name|store
operator|.
name|getScanner
argument_list|(
name|scan
argument_list|,
name|entry
operator|.
name|getValue
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|this
operator|.
name|storeHeap
operator|=
operator|new
name|KeyValueHeap
argument_list|(
name|scanners
operator|.
name|toArray
argument_list|(
operator|new
name|KeyValueScanner
index|[
literal|0
index|]
argument_list|)
argument_list|,
name|comparator
argument_list|)
expr_stmt|;
block|}
name|RegionScanner
parameter_list|(
name|Scan
name|scan
parameter_list|)
block|{
name|this
argument_list|(
name|scan
argument_list|,
literal|null
argument_list|)
expr_stmt|;
block|}
specifier|private
name|void
name|resetFilters
parameter_list|()
block|{
if|if
condition|(
name|filter
operator|!=
literal|null
condition|)
block|{
name|filter
operator|.
name|reset
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**      * Get the next row of results from this region.      * @param results list to append results to      * @return true if there are more rows, false if scanner is done      * @throws NotServerRegionException If this region is closing or closed      */
annotation|@
name|Override
specifier|public
name|boolean
name|next
parameter_list|(
name|List
argument_list|<
name|KeyValue
argument_list|>
name|outResults
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|closing
operator|.
name|get
argument_list|()
operator|||
name|closed
operator|.
name|get
argument_list|()
condition|)
block|{
name|close
argument_list|()
expr_stmt|;
throw|throw
operator|new
name|NotServingRegionException
argument_list|(
name|regionInfo
operator|.
name|getRegionNameAsString
argument_list|()
operator|+
literal|" is closing="
operator|+
name|closing
operator|.
name|get
argument_list|()
operator|+
literal|" or closed="
operator|+
name|closed
operator|.
name|get
argument_list|()
argument_list|)
throw|;
block|}
name|results
operator|.
name|clear
argument_list|()
expr_stmt|;
name|boolean
name|returnResult
init|=
name|nextInternal
argument_list|()
decl_stmt|;
if|if
condition|(
operator|!
name|returnResult
operator|&&
name|filter
operator|!=
literal|null
operator|&&
name|filter
operator|.
name|filterRow
argument_list|()
condition|)
block|{
name|results
operator|.
name|clear
argument_list|()
expr_stmt|;
block|}
name|outResults
operator|.
name|addAll
argument_list|(
name|results
argument_list|)
expr_stmt|;
name|resetFilters
argument_list|()
expr_stmt|;
if|if
condition|(
name|filter
operator|!=
literal|null
operator|&&
name|filter
operator|.
name|filterAllRemaining
argument_list|()
condition|)
block|{
return|return
literal|false
return|;
block|}
return|return
name|returnResult
return|;
block|}
specifier|private
name|boolean
name|nextInternal
parameter_list|()
throws|throws
name|IOException
block|{
comment|// This method should probably be reorganized a bit... has gotten messy
name|KeyValue
name|kv
decl_stmt|;
name|byte
index|[]
name|currentRow
init|=
literal|null
decl_stmt|;
name|boolean
name|filterCurrentRow
init|=
literal|false
decl_stmt|;
while|while
condition|(
literal|true
condition|)
block|{
name|kv
operator|=
name|this
operator|.
name|storeHeap
operator|.
name|peek
argument_list|()
expr_stmt|;
if|if
condition|(
name|kv
operator|==
literal|null
condition|)
block|{
return|return
literal|false
return|;
block|}
name|byte
index|[]
name|row
init|=
name|kv
operator|.
name|getRow
argument_list|()
decl_stmt|;
if|if
condition|(
name|filterCurrentRow
operator|&&
name|Bytes
operator|.
name|equals
argument_list|(
name|currentRow
argument_list|,
name|row
argument_list|)
condition|)
block|{
comment|// filter all columns until row changes
name|this
operator|.
name|storeHeap
operator|.
name|next
argument_list|(
name|results
argument_list|)
expr_stmt|;
name|results
operator|.
name|clear
argument_list|()
expr_stmt|;
continue|continue;
block|}
comment|// see if current row should be filtered based on row key
if|if
condition|(
name|filter
operator|!=
literal|null
operator|&&
name|filter
operator|.
name|filterRowKey
argument_list|(
name|row
argument_list|,
literal|0
argument_list|,
name|row
operator|.
name|length
argument_list|)
condition|)
block|{
if|if
condition|(
operator|!
name|results
operator|.
name|isEmpty
argument_list|()
operator|&&
operator|!
name|Bytes
operator|.
name|equals
argument_list|(
name|currentRow
argument_list|,
name|row
argument_list|)
condition|)
block|{
return|return
literal|true
return|;
block|}
name|this
operator|.
name|storeHeap
operator|.
name|next
argument_list|(
name|results
argument_list|)
expr_stmt|;
name|results
operator|.
name|clear
argument_list|()
expr_stmt|;
name|resetFilters
argument_list|()
expr_stmt|;
name|filterCurrentRow
operator|=
literal|true
expr_stmt|;
name|currentRow
operator|=
name|row
expr_stmt|;
continue|continue;
block|}
if|if
condition|(
operator|!
name|Bytes
operator|.
name|equals
argument_list|(
name|currentRow
argument_list|,
name|row
argument_list|)
condition|)
block|{
comment|// Continue on the next row:
name|currentRow
operator|=
name|row
expr_stmt|;
name|filterCurrentRow
operator|=
literal|false
expr_stmt|;
comment|// See if we passed stopRow
if|if
condition|(
name|stopRow
operator|!=
literal|null
operator|&&
name|comparator
operator|.
name|compareRows
argument_list|(
name|stopRow
argument_list|,
literal|0
argument_list|,
name|stopRow
operator|.
name|length
argument_list|,
name|currentRow
argument_list|,
literal|0
argument_list|,
name|currentRow
operator|.
name|length
argument_list|)
operator|<=
literal|0
condition|)
block|{
return|return
literal|false
return|;
block|}
comment|// if there are _no_ results or current row should be filtered
if|if
condition|(
name|results
operator|.
name|isEmpty
argument_list|()
operator|||
name|filter
operator|!=
literal|null
operator|&&
name|filter
operator|.
name|filterRow
argument_list|()
condition|)
block|{
comment|// make sure results is empty
name|results
operator|.
name|clear
argument_list|()
expr_stmt|;
name|resetFilters
argument_list|()
expr_stmt|;
continue|continue;
block|}
return|return
literal|true
return|;
block|}
name|this
operator|.
name|storeHeap
operator|.
name|next
argument_list|(
name|results
argument_list|)
expr_stmt|;
block|}
block|}
specifier|public
name|void
name|close
parameter_list|()
block|{
name|storeHeap
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
comment|/**      *       * @param scanner to be closed      */
specifier|public
name|void
name|close
parameter_list|(
name|KeyValueScanner
name|scanner
parameter_list|)
block|{
try|try
block|{
name|scanner
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|NullPointerException
name|npe
parameter_list|)
block|{}
block|}
comment|/**      * @return the current storeHeap      */
specifier|public
name|KeyValueHeap
name|getStoreHeap
parameter_list|()
block|{
return|return
name|this
operator|.
name|storeHeap
return|;
block|}
block|}
comment|// Utility methods
comment|/**    * Convenience method creating new HRegions. Used by createTable and by the    * bootstrap code in the HMaster constructor.    * Note, this method creates an {@link HLog} for the created region. It    * needs to be closed explicitly.  Use {@link HRegion#getLog()} to get    * access.    * @param info Info for region to create.    * @param rootDir Root directory for HBase instance    * @param conf    * @return new HRegion    *     * @throws IOException    */
specifier|public
specifier|static
name|HRegion
name|createHRegion
parameter_list|(
specifier|final
name|HRegionInfo
name|info
parameter_list|,
specifier|final
name|Path
name|rootDir
parameter_list|,
specifier|final
name|HBaseConfiguration
name|conf
parameter_list|)
throws|throws
name|IOException
block|{
name|Path
name|tableDir
init|=
name|HTableDescriptor
operator|.
name|getTableDir
argument_list|(
name|rootDir
argument_list|,
name|info
operator|.
name|getTableDesc
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
name|Path
name|regionDir
init|=
name|HRegion
operator|.
name|getRegionDir
argument_list|(
name|tableDir
argument_list|,
name|info
operator|.
name|getEncodedName
argument_list|()
argument_list|)
decl_stmt|;
name|FileSystem
name|fs
init|=
name|FileSystem
operator|.
name|get
argument_list|(
name|conf
argument_list|)
decl_stmt|;
name|fs
operator|.
name|mkdirs
argument_list|(
name|regionDir
argument_list|)
expr_stmt|;
comment|// Note in historian the creation of new region.
if|if
condition|(
operator|!
name|info
operator|.
name|isMetaRegion
argument_list|()
condition|)
block|{
name|RegionHistorian
operator|.
name|getInstance
argument_list|()
operator|.
name|addRegionCreation
argument_list|(
name|info
argument_list|)
expr_stmt|;
block|}
name|HRegion
name|region
init|=
operator|new
name|HRegion
argument_list|(
name|tableDir
argument_list|,
operator|new
name|HLog
argument_list|(
name|fs
argument_list|,
operator|new
name|Path
argument_list|(
name|regionDir
argument_list|,
name|HREGION_LOGDIR_NAME
argument_list|)
argument_list|,
name|conf
argument_list|,
literal|null
argument_list|)
argument_list|,
name|fs
argument_list|,
name|conf
argument_list|,
name|info
argument_list|,
literal|null
argument_list|)
decl_stmt|;
name|region
operator|.
name|initialize
argument_list|(
literal|null
argument_list|,
literal|null
argument_list|)
expr_stmt|;
return|return
name|region
return|;
block|}
comment|/**    * Convenience method to open a HRegion outside of an HRegionServer context.    * @param info Info for region to be opened.    * @param rootDir Root directory for HBase instance    * @param log HLog for region to use. This method will call    * HLog#setSequenceNumber(long) passing the result of the call to    * HRegion#getMinSequenceId() to ensure the log id is properly kept    * up.  HRegionStore does this every time it opens a new region.    * @param conf    * @return new HRegion    *     * @throws IOException    */
specifier|public
specifier|static
name|HRegion
name|openHRegion
parameter_list|(
specifier|final
name|HRegionInfo
name|info
parameter_list|,
specifier|final
name|Path
name|rootDir
parameter_list|,
specifier|final
name|HLog
name|log
parameter_list|,
specifier|final
name|HBaseConfiguration
name|conf
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Opening region: "
operator|+
name|info
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|info
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|NullPointerException
argument_list|(
literal|"Passed region info is null"
argument_list|)
throw|;
block|}
name|HRegion
name|r
init|=
operator|new
name|HRegion
argument_list|(
name|HTableDescriptor
operator|.
name|getTableDir
argument_list|(
name|rootDir
argument_list|,
name|info
operator|.
name|getTableDesc
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|)
argument_list|,
name|log
argument_list|,
name|FileSystem
operator|.
name|get
argument_list|(
name|conf
argument_list|)
argument_list|,
name|conf
argument_list|,
name|info
argument_list|,
literal|null
argument_list|)
decl_stmt|;
name|r
operator|.
name|initialize
argument_list|(
literal|null
argument_list|,
literal|null
argument_list|)
expr_stmt|;
if|if
condition|(
name|log
operator|!=
literal|null
condition|)
block|{
name|log
operator|.
name|setSequenceNumber
argument_list|(
name|r
operator|.
name|getMinSequenceId
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
name|r
return|;
block|}
comment|/**    * Inserts a new region's meta information into the passed    *<code>meta</code> region. Used by the HMaster bootstrap code adding    * new table to ROOT table.    *     * @param meta META HRegion to be updated    * @param r HRegion to add to<code>meta</code>    *    * @throws IOException    */
specifier|public
specifier|static
name|void
name|addRegionToMETA
parameter_list|(
name|HRegion
name|meta
parameter_list|,
name|HRegion
name|r
parameter_list|)
throws|throws
name|IOException
block|{
name|meta
operator|.
name|checkResources
argument_list|()
expr_stmt|;
comment|// The row key is the region name
name|byte
index|[]
name|row
init|=
name|r
operator|.
name|getRegionName
argument_list|()
decl_stmt|;
name|Integer
name|lid
init|=
name|meta
operator|.
name|obtainRowLock
argument_list|(
name|row
argument_list|)
decl_stmt|;
try|try
block|{
name|List
argument_list|<
name|KeyValue
argument_list|>
name|edits
init|=
operator|new
name|ArrayList
argument_list|<
name|KeyValue
argument_list|>
argument_list|()
decl_stmt|;
name|edits
operator|.
name|add
argument_list|(
operator|new
name|KeyValue
argument_list|(
name|row
argument_list|,
name|CATALOG_FAMILY
argument_list|,
name|REGIONINFO_QUALIFIER
argument_list|,
name|System
operator|.
name|currentTimeMillis
argument_list|()
argument_list|,
name|Writables
operator|.
name|getBytes
argument_list|(
name|r
operator|.
name|getRegionInfo
argument_list|()
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
name|meta
operator|.
name|put
argument_list|(
name|HConstants
operator|.
name|CATALOG_FAMILY
argument_list|,
name|edits
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|meta
operator|.
name|releaseRowLock
argument_list|(
name|lid
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Delete a region's meta information from the passed    *<code>meta</code> region.  Removes content in the 'info' column family.    * Does not remove region historian info.    *     * @param srvr META server to be updated    * @param metaRegionName Meta region name    * @param regionName HRegion to remove from<code>meta</code>    *    * @throws IOException    */
specifier|public
specifier|static
name|void
name|removeRegionFromMETA
parameter_list|(
specifier|final
name|HRegionInterface
name|srvr
parameter_list|,
specifier|final
name|byte
index|[]
name|metaRegionName
parameter_list|,
specifier|final
name|byte
index|[]
name|regionName
parameter_list|)
throws|throws
name|IOException
block|{
name|Delete
name|delete
init|=
operator|new
name|Delete
argument_list|(
name|regionName
argument_list|)
decl_stmt|;
name|delete
operator|.
name|deleteFamily
argument_list|(
name|HConstants
operator|.
name|CATALOG_FAMILY
argument_list|)
expr_stmt|;
name|srvr
operator|.
name|delete
argument_list|(
name|metaRegionName
argument_list|,
name|delete
argument_list|)
expr_stmt|;
block|}
comment|/**    * Utility method used by HMaster marking regions offlined.    * @param srvr META server to be updated    * @param metaRegionName Meta region name    * @param info HRegion to update in<code>meta</code>    *    * @throws IOException    */
specifier|public
specifier|static
name|void
name|offlineRegionInMETA
parameter_list|(
specifier|final
name|HRegionInterface
name|srvr
parameter_list|,
specifier|final
name|byte
index|[]
name|metaRegionName
parameter_list|,
specifier|final
name|HRegionInfo
name|info
parameter_list|)
throws|throws
name|IOException
block|{
comment|// Puts and Deletes used to be "atomic" here.  We can use row locks if
comment|// we need to keep that property, or we can expand Puts and Deletes to
comment|// allow them to be committed at once.
name|byte
index|[]
name|row
init|=
name|info
operator|.
name|getRegionName
argument_list|()
decl_stmt|;
name|Put
name|put
init|=
operator|new
name|Put
argument_list|(
name|row
argument_list|)
decl_stmt|;
name|info
operator|.
name|setOffline
argument_list|(
literal|true
argument_list|)
expr_stmt|;
name|put
operator|.
name|add
argument_list|(
name|CATALOG_FAMILY
argument_list|,
name|REGIONINFO_QUALIFIER
argument_list|,
name|Writables
operator|.
name|getBytes
argument_list|(
name|info
argument_list|)
argument_list|)
expr_stmt|;
name|srvr
operator|.
name|put
argument_list|(
name|metaRegionName
argument_list|,
name|put
argument_list|)
expr_stmt|;
name|Delete
name|del
init|=
operator|new
name|Delete
argument_list|(
name|row
argument_list|)
decl_stmt|;
name|del
operator|.
name|deleteColumns
argument_list|(
name|CATALOG_FAMILY
argument_list|,
name|SERVER_QUALIFIER
argument_list|)
expr_stmt|;
name|del
operator|.
name|deleteColumns
argument_list|(
name|CATALOG_FAMILY
argument_list|,
name|STARTCODE_QUALIFIER
argument_list|)
expr_stmt|;
name|srvr
operator|.
name|delete
argument_list|(
name|metaRegionName
argument_list|,
name|del
argument_list|)
expr_stmt|;
block|}
comment|/**    * Clean COL_SERVER and COL_STARTCODE for passed<code>info</code> in    *<code>.META.</code>    * @param srvr    * @param metaRegionName    * @param info    * @throws IOException    */
specifier|public
specifier|static
name|void
name|cleanRegionInMETA
parameter_list|(
specifier|final
name|HRegionInterface
name|srvr
parameter_list|,
specifier|final
name|byte
index|[]
name|metaRegionName
parameter_list|,
specifier|final
name|HRegionInfo
name|info
parameter_list|)
throws|throws
name|IOException
block|{
name|Delete
name|del
init|=
operator|new
name|Delete
argument_list|(
name|info
operator|.
name|getRegionName
argument_list|()
argument_list|)
decl_stmt|;
name|del
operator|.
name|deleteColumns
argument_list|(
name|CATALOG_FAMILY
argument_list|,
name|SERVER_QUALIFIER
argument_list|)
expr_stmt|;
name|del
operator|.
name|deleteColumns
argument_list|(
name|CATALOG_FAMILY
argument_list|,
name|STARTCODE_QUALIFIER
argument_list|)
expr_stmt|;
name|srvr
operator|.
name|delete
argument_list|(
name|metaRegionName
argument_list|,
name|del
argument_list|)
expr_stmt|;
block|}
comment|/**    * Deletes all the files for a HRegion    *     * @param fs the file system object    * @param rootdir qualified path of HBase root directory    * @param info HRegionInfo for region to be deleted    * @throws IOException    */
specifier|public
specifier|static
name|void
name|deleteRegion
parameter_list|(
name|FileSystem
name|fs
parameter_list|,
name|Path
name|rootdir
parameter_list|,
name|HRegionInfo
name|info
parameter_list|)
throws|throws
name|IOException
block|{
name|deleteRegion
argument_list|(
name|fs
argument_list|,
name|HRegion
operator|.
name|getRegionDir
argument_list|(
name|rootdir
argument_list|,
name|info
argument_list|)
argument_list|)
expr_stmt|;
block|}
specifier|private
specifier|static
name|void
name|deleteRegion
parameter_list|(
name|FileSystem
name|fs
parameter_list|,
name|Path
name|regiondir
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"DELETING region "
operator|+
name|regiondir
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|!
name|fs
operator|.
name|delete
argument_list|(
name|regiondir
argument_list|,
literal|true
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failed delete of "
operator|+
name|regiondir
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Computes the Path of the HRegion    *     * @param tabledir qualified path for table    * @param name ENCODED region name    * @return Path of HRegion directory    */
specifier|public
specifier|static
name|Path
name|getRegionDir
parameter_list|(
specifier|final
name|Path
name|tabledir
parameter_list|,
specifier|final
name|int
name|name
parameter_list|)
block|{
return|return
operator|new
name|Path
argument_list|(
name|tabledir
argument_list|,
name|Integer
operator|.
name|toString
argument_list|(
name|name
argument_list|)
argument_list|)
return|;
block|}
comment|/**    * Computes the Path of the HRegion    *     * @param rootdir qualified path of HBase root directory    * @param info HRegionInfo for the region    * @return qualified path of region directory    */
specifier|public
specifier|static
name|Path
name|getRegionDir
parameter_list|(
specifier|final
name|Path
name|rootdir
parameter_list|,
specifier|final
name|HRegionInfo
name|info
parameter_list|)
block|{
return|return
operator|new
name|Path
argument_list|(
name|HTableDescriptor
operator|.
name|getTableDir
argument_list|(
name|rootdir
argument_list|,
name|info
operator|.
name|getTableDesc
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|)
argument_list|,
name|Integer
operator|.
name|toString
argument_list|(
name|info
operator|.
name|getEncodedName
argument_list|()
argument_list|)
argument_list|)
return|;
block|}
comment|/**    * Determines if the specified row is within the row range specified by the    * specified HRegionInfo    *      * @param info HRegionInfo that specifies the row range    * @param row row to be checked    * @return true if the row is within the range specified by the HRegionInfo    */
specifier|public
specifier|static
name|boolean
name|rowIsInRange
parameter_list|(
name|HRegionInfo
name|info
parameter_list|,
specifier|final
name|byte
index|[]
name|row
parameter_list|)
block|{
return|return
operator|(
operator|(
name|info
operator|.
name|getStartKey
argument_list|()
operator|.
name|length
operator|==
literal|0
operator|)
operator|||
operator|(
name|Bytes
operator|.
name|compareTo
argument_list|(
name|info
operator|.
name|getStartKey
argument_list|()
argument_list|,
name|row
argument_list|)
operator|<=
literal|0
operator|)
operator|)
operator|&&
operator|(
operator|(
name|info
operator|.
name|getEndKey
argument_list|()
operator|.
name|length
operator|==
literal|0
operator|)
operator|||
operator|(
name|Bytes
operator|.
name|compareTo
argument_list|(
name|info
operator|.
name|getEndKey
argument_list|()
argument_list|,
name|row
argument_list|)
operator|>
literal|0
operator|)
operator|)
return|;
block|}
comment|/**    * Make the directories for a specific column family    *     * @param fs the file system    * @param tabledir base directory where region will live (usually the table dir)    * @param hri    * @param colFamily the column family    * @throws IOException    */
specifier|public
specifier|static
name|void
name|makeColumnFamilyDirs
parameter_list|(
name|FileSystem
name|fs
parameter_list|,
name|Path
name|tabledir
parameter_list|,
specifier|final
name|HRegionInfo
name|hri
parameter_list|,
name|byte
index|[]
name|colFamily
parameter_list|)
throws|throws
name|IOException
block|{
name|Path
name|dir
init|=
name|Store
operator|.
name|getStoreHomedir
argument_list|(
name|tabledir
argument_list|,
name|hri
operator|.
name|getEncodedName
argument_list|()
argument_list|,
name|colFamily
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|fs
operator|.
name|mkdirs
argument_list|(
name|dir
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failed to create "
operator|+
name|dir
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Merge two HRegions.  The regions must be adjacent and must not overlap.    *     * @param srcA    * @param srcB    * @return new merged HRegion    * @throws IOException    */
specifier|public
specifier|static
name|HRegion
name|mergeAdjacent
parameter_list|(
specifier|final
name|HRegion
name|srcA
parameter_list|,
specifier|final
name|HRegion
name|srcB
parameter_list|)
throws|throws
name|IOException
block|{
name|HRegion
name|a
init|=
name|srcA
decl_stmt|;
name|HRegion
name|b
init|=
name|srcB
decl_stmt|;
comment|// Make sure that srcA comes first; important for key-ordering during
comment|// write of the merged file.
if|if
condition|(
name|srcA
operator|.
name|getStartKey
argument_list|()
operator|==
literal|null
condition|)
block|{
if|if
condition|(
name|srcB
operator|.
name|getStartKey
argument_list|()
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Cannot merge two regions with null start key"
argument_list|)
throw|;
block|}
comment|// A's start key is null but B's isn't. Assume A comes before B
block|}
elseif|else
if|if
condition|(
operator|(
name|srcB
operator|.
name|getStartKey
argument_list|()
operator|==
literal|null
operator|)
operator|||
operator|(
name|Bytes
operator|.
name|compareTo
argument_list|(
name|srcA
operator|.
name|getStartKey
argument_list|()
argument_list|,
name|srcB
operator|.
name|getStartKey
argument_list|()
argument_list|)
operator|>
literal|0
operator|)
condition|)
block|{
name|a
operator|=
name|srcB
expr_stmt|;
name|b
operator|=
name|srcA
expr_stmt|;
block|}
if|if
condition|(
operator|!
operator|(
name|Bytes
operator|.
name|compareTo
argument_list|(
name|a
operator|.
name|getEndKey
argument_list|()
argument_list|,
name|b
operator|.
name|getStartKey
argument_list|()
argument_list|)
operator|==
literal|0
operator|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Cannot merge non-adjacent regions"
argument_list|)
throw|;
block|}
return|return
name|merge
argument_list|(
name|a
argument_list|,
name|b
argument_list|)
return|;
block|}
comment|/**    * Merge two regions whether they are adjacent or not.    *     * @param a region a    * @param b region b    * @return new merged region    * @throws IOException    */
specifier|public
specifier|static
name|HRegion
name|merge
parameter_list|(
name|HRegion
name|a
parameter_list|,
name|HRegion
name|b
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
operator|!
name|a
operator|.
name|getRegionInfo
argument_list|()
operator|.
name|getTableDesc
argument_list|()
operator|.
name|getNameAsString
argument_list|()
operator|.
name|equals
argument_list|(
name|b
operator|.
name|getRegionInfo
argument_list|()
operator|.
name|getTableDesc
argument_list|()
operator|.
name|getNameAsString
argument_list|()
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Regions do not belong to the same table"
argument_list|)
throw|;
block|}
name|FileSystem
name|fs
init|=
name|a
operator|.
name|getFilesystem
argument_list|()
decl_stmt|;
comment|// Make sure each region's cache is empty
name|a
operator|.
name|flushcache
argument_list|()
expr_stmt|;
name|b
operator|.
name|flushcache
argument_list|()
expr_stmt|;
comment|// Compact each region so we only have one store file per family
name|a
operator|.
name|compactStores
argument_list|(
literal|true
argument_list|)
expr_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Files for region: "
operator|+
name|a
argument_list|)
expr_stmt|;
name|listPaths
argument_list|(
name|fs
argument_list|,
name|a
operator|.
name|getRegionDir
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|b
operator|.
name|compactStores
argument_list|(
literal|true
argument_list|)
expr_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Files for region: "
operator|+
name|b
argument_list|)
expr_stmt|;
name|listPaths
argument_list|(
name|fs
argument_list|,
name|b
operator|.
name|getRegionDir
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|HBaseConfiguration
name|conf
init|=
name|a
operator|.
name|getConf
argument_list|()
decl_stmt|;
name|HTableDescriptor
name|tabledesc
init|=
name|a
operator|.
name|getTableDesc
argument_list|()
decl_stmt|;
name|HLog
name|log
init|=
name|a
operator|.
name|getLog
argument_list|()
decl_stmt|;
name|Path
name|basedir
init|=
name|a
operator|.
name|getBaseDir
argument_list|()
decl_stmt|;
comment|// Presume both are of same region type -- i.e. both user or catalog
comment|// table regions.  This way can use comparator.
specifier|final
name|byte
index|[]
name|startKey
init|=
name|a
operator|.
name|comparator
operator|.
name|matchingRows
argument_list|(
name|a
operator|.
name|getStartKey
argument_list|()
argument_list|,
literal|0
argument_list|,
name|a
operator|.
name|getStartKey
argument_list|()
operator|.
name|length
argument_list|,
name|EMPTY_BYTE_ARRAY
argument_list|,
literal|0
argument_list|,
name|EMPTY_BYTE_ARRAY
operator|.
name|length
argument_list|)
operator|||
name|b
operator|.
name|comparator
operator|.
name|matchingRows
argument_list|(
name|b
operator|.
name|getStartKey
argument_list|()
argument_list|,
literal|0
argument_list|,
name|b
operator|.
name|getStartKey
argument_list|()
operator|.
name|length
argument_list|,
name|EMPTY_BYTE_ARRAY
argument_list|,
literal|0
argument_list|,
name|EMPTY_BYTE_ARRAY
operator|.
name|length
argument_list|)
condition|?
name|EMPTY_BYTE_ARRAY
else|:
name|a
operator|.
name|comparator
operator|.
name|compareRows
argument_list|(
name|a
operator|.
name|getStartKey
argument_list|()
argument_list|,
literal|0
argument_list|,
name|a
operator|.
name|getStartKey
argument_list|()
operator|.
name|length
argument_list|,
name|b
operator|.
name|getStartKey
argument_list|()
argument_list|,
literal|0
argument_list|,
name|b
operator|.
name|getStartKey
argument_list|()
operator|.
name|length
argument_list|)
operator|<=
literal|0
condition|?
name|a
operator|.
name|getStartKey
argument_list|()
else|:
name|b
operator|.
name|getStartKey
argument_list|()
decl_stmt|;
specifier|final
name|byte
index|[]
name|endKey
init|=
name|a
operator|.
name|comparator
operator|.
name|matchingRows
argument_list|(
name|a
operator|.
name|getEndKey
argument_list|()
argument_list|,
literal|0
argument_list|,
name|a
operator|.
name|getEndKey
argument_list|()
operator|.
name|length
argument_list|,
name|EMPTY_BYTE_ARRAY
argument_list|,
literal|0
argument_list|,
name|EMPTY_BYTE_ARRAY
operator|.
name|length
argument_list|)
operator|||
name|a
operator|.
name|comparator
operator|.
name|matchingRows
argument_list|(
name|b
operator|.
name|getEndKey
argument_list|()
argument_list|,
literal|0
argument_list|,
name|b
operator|.
name|getEndKey
argument_list|()
operator|.
name|length
argument_list|,
name|EMPTY_BYTE_ARRAY
argument_list|,
literal|0
argument_list|,
name|EMPTY_BYTE_ARRAY
operator|.
name|length
argument_list|)
condition|?
name|EMPTY_BYTE_ARRAY
else|:
name|a
operator|.
name|comparator
operator|.
name|compareRows
argument_list|(
name|a
operator|.
name|getEndKey
argument_list|()
argument_list|,
literal|0
argument_list|,
name|a
operator|.
name|getEndKey
argument_list|()
operator|.
name|length
argument_list|,
name|b
operator|.
name|getEndKey
argument_list|()
argument_list|,
literal|0
argument_list|,
name|b
operator|.
name|getEndKey
argument_list|()
operator|.
name|length
argument_list|)
operator|<=
literal|0
condition|?
name|b
operator|.
name|getEndKey
argument_list|()
else|:
name|a
operator|.
name|getEndKey
argument_list|()
decl_stmt|;
name|HRegionInfo
name|newRegionInfo
init|=
operator|new
name|HRegionInfo
argument_list|(
name|tabledesc
argument_list|,
name|startKey
argument_list|,
name|endKey
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Creating new region "
operator|+
name|newRegionInfo
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
name|int
name|encodedName
init|=
name|newRegionInfo
operator|.
name|getEncodedName
argument_list|()
decl_stmt|;
name|Path
name|newRegionDir
init|=
name|HRegion
operator|.
name|getRegionDir
argument_list|(
name|a
operator|.
name|getBaseDir
argument_list|()
argument_list|,
name|encodedName
argument_list|)
decl_stmt|;
if|if
condition|(
name|fs
operator|.
name|exists
argument_list|(
name|newRegionDir
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Cannot merge; target file collision at "
operator|+
name|newRegionDir
argument_list|)
throw|;
block|}
name|fs
operator|.
name|mkdirs
argument_list|(
name|newRegionDir
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"starting merge of regions: "
operator|+
name|a
operator|+
literal|" and "
operator|+
name|b
operator|+
literal|" into new region "
operator|+
name|newRegionInfo
operator|.
name|toString
argument_list|()
operator|+
literal|" with start key<"
operator|+
name|Bytes
operator|.
name|toString
argument_list|(
name|startKey
argument_list|)
operator|+
literal|"> and end key<"
operator|+
name|Bytes
operator|.
name|toString
argument_list|(
name|endKey
argument_list|)
operator|+
literal|">"
argument_list|)
expr_stmt|;
comment|// Move HStoreFiles under new region directory
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|List
argument_list|<
name|StoreFile
argument_list|>
argument_list|>
name|byFamily
init|=
operator|new
name|TreeMap
argument_list|<
name|byte
index|[]
argument_list|,
name|List
argument_list|<
name|StoreFile
argument_list|>
argument_list|>
argument_list|(
name|Bytes
operator|.
name|BYTES_COMPARATOR
argument_list|)
decl_stmt|;
name|byFamily
operator|=
name|filesByFamily
argument_list|(
name|byFamily
argument_list|,
name|a
operator|.
name|close
argument_list|()
argument_list|)
expr_stmt|;
name|byFamily
operator|=
name|filesByFamily
argument_list|(
name|byFamily
argument_list|,
name|b
operator|.
name|close
argument_list|()
argument_list|)
expr_stmt|;
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|byte
index|[]
argument_list|,
name|List
argument_list|<
name|StoreFile
argument_list|>
argument_list|>
name|es
range|:
name|byFamily
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|byte
index|[]
name|colFamily
init|=
name|es
operator|.
name|getKey
argument_list|()
decl_stmt|;
name|makeColumnFamilyDirs
argument_list|(
name|fs
argument_list|,
name|basedir
argument_list|,
name|newRegionInfo
argument_list|,
name|colFamily
argument_list|)
expr_stmt|;
comment|// Because we compacted the source regions we should have no more than two
comment|// HStoreFiles per family and there will be no reference store
name|List
argument_list|<
name|StoreFile
argument_list|>
name|srcFiles
init|=
name|es
operator|.
name|getValue
argument_list|()
decl_stmt|;
if|if
condition|(
name|srcFiles
operator|.
name|size
argument_list|()
operator|==
literal|2
condition|)
block|{
name|long
name|seqA
init|=
name|srcFiles
operator|.
name|get
argument_list|(
literal|0
argument_list|)
operator|.
name|getMaxSequenceId
argument_list|()
decl_stmt|;
name|long
name|seqB
init|=
name|srcFiles
operator|.
name|get
argument_list|(
literal|1
argument_list|)
operator|.
name|getMaxSequenceId
argument_list|()
decl_stmt|;
if|if
condition|(
name|seqA
operator|==
name|seqB
condition|)
block|{
comment|// Can't have same sequenceid since on open of a store, this is what
comment|// distingushes the files (see the map of stores how its keyed by
comment|// sequenceid).
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Files have same sequenceid: "
operator|+
name|seqA
argument_list|)
throw|;
block|}
block|}
for|for
control|(
name|StoreFile
name|hsf
range|:
name|srcFiles
control|)
block|{
name|StoreFile
operator|.
name|rename
argument_list|(
name|fs
argument_list|,
name|hsf
operator|.
name|getPath
argument_list|()
argument_list|,
name|StoreFile
operator|.
name|getUniqueFile
argument_list|(
name|fs
argument_list|,
name|Store
operator|.
name|getStoreHomedir
argument_list|(
name|basedir
argument_list|,
name|newRegionInfo
operator|.
name|getEncodedName
argument_list|()
argument_list|,
name|colFamily
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Files for new region"
argument_list|)
expr_stmt|;
name|listPaths
argument_list|(
name|fs
argument_list|,
name|newRegionDir
argument_list|)
expr_stmt|;
block|}
name|HRegion
name|dstRegion
init|=
operator|new
name|HRegion
argument_list|(
name|basedir
argument_list|,
name|log
argument_list|,
name|fs
argument_list|,
name|conf
argument_list|,
name|newRegionInfo
argument_list|,
literal|null
argument_list|)
decl_stmt|;
name|dstRegion
operator|.
name|initialize
argument_list|(
literal|null
argument_list|,
literal|null
argument_list|)
expr_stmt|;
name|dstRegion
operator|.
name|compactStores
argument_list|()
expr_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Files for new region"
argument_list|)
expr_stmt|;
name|listPaths
argument_list|(
name|fs
argument_list|,
name|dstRegion
operator|.
name|getRegionDir
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|deleteRegion
argument_list|(
name|fs
argument_list|,
name|a
operator|.
name|getRegionDir
argument_list|()
argument_list|)
expr_stmt|;
name|deleteRegion
argument_list|(
name|fs
argument_list|,
name|b
operator|.
name|getRegionDir
argument_list|()
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"merge completed. New region is "
operator|+
name|dstRegion
argument_list|)
expr_stmt|;
return|return
name|dstRegion
return|;
block|}
comment|/*    * Fills a map with a vector of store files keyed by column family.     * @param byFamily Map to fill.    * @param storeFiles Store files to process.    * @param family    * @return Returns<code>byFamily</code>    */
specifier|private
specifier|static
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|List
argument_list|<
name|StoreFile
argument_list|>
argument_list|>
name|filesByFamily
parameter_list|(
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|List
argument_list|<
name|StoreFile
argument_list|>
argument_list|>
name|byFamily
parameter_list|,
name|List
argument_list|<
name|StoreFile
argument_list|>
name|storeFiles
parameter_list|)
block|{
for|for
control|(
name|StoreFile
name|src
range|:
name|storeFiles
control|)
block|{
name|byte
index|[]
name|family
init|=
name|src
operator|.
name|getFamily
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|StoreFile
argument_list|>
name|v
init|=
name|byFamily
operator|.
name|get
argument_list|(
name|family
argument_list|)
decl_stmt|;
if|if
condition|(
name|v
operator|==
literal|null
condition|)
block|{
name|v
operator|=
operator|new
name|ArrayList
argument_list|<
name|StoreFile
argument_list|>
argument_list|()
expr_stmt|;
name|byFamily
operator|.
name|put
argument_list|(
name|family
argument_list|,
name|v
argument_list|)
expr_stmt|;
block|}
name|v
operator|.
name|add
argument_list|(
name|src
argument_list|)
expr_stmt|;
block|}
return|return
name|byFamily
return|;
block|}
comment|/**    * @return True if needs a mojor compaction.    * @throws IOException     */
name|boolean
name|isMajorCompaction
parameter_list|()
throws|throws
name|IOException
block|{
for|for
control|(
name|Store
name|store
range|:
name|this
operator|.
name|stores
operator|.
name|values
argument_list|()
control|)
block|{
if|if
condition|(
name|store
operator|.
name|isMajorCompaction
argument_list|()
condition|)
block|{
return|return
literal|true
return|;
block|}
block|}
return|return
literal|false
return|;
block|}
comment|/*    * List the files under the specified directory    *     * @param fs    * @param dir    * @throws IOException    */
specifier|private
specifier|static
name|void
name|listPaths
parameter_list|(
name|FileSystem
name|fs
parameter_list|,
name|Path
name|dir
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|FileStatus
index|[]
name|stats
init|=
name|fs
operator|.
name|listStatus
argument_list|(
name|dir
argument_list|)
decl_stmt|;
if|if
condition|(
name|stats
operator|==
literal|null
operator|||
name|stats
operator|.
name|length
operator|==
literal|0
condition|)
block|{
return|return;
block|}
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|stats
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|String
name|path
init|=
name|stats
index|[
name|i
index|]
operator|.
name|getPath
argument_list|()
operator|.
name|toString
argument_list|()
decl_stmt|;
if|if
condition|(
name|stats
index|[
name|i
index|]
operator|.
name|isDir
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"d "
operator|+
name|path
argument_list|)
expr_stmt|;
name|listPaths
argument_list|(
name|fs
argument_list|,
name|stats
index|[
name|i
index|]
operator|.
name|getPath
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"f "
operator|+
name|path
operator|+
literal|" size="
operator|+
name|stats
index|[
name|i
index|]
operator|.
name|getLen
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
comment|//
comment|// HBASE-880
comment|//
comment|/**    * @param get    * @param lockid    * @return result    * @throws IOException    */
specifier|public
name|Result
name|get
parameter_list|(
specifier|final
name|Get
name|get
parameter_list|,
specifier|final
name|Integer
name|lockid
parameter_list|)
throws|throws
name|IOException
block|{
comment|// Verify families are all valid
if|if
condition|(
name|get
operator|.
name|hasFamilies
argument_list|()
condition|)
block|{
for|for
control|(
name|byte
index|[]
name|family
range|:
name|get
operator|.
name|familySet
argument_list|()
control|)
block|{
name|checkFamily
argument_list|(
name|family
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
comment|// Adding all families to scanner
for|for
control|(
name|byte
index|[]
name|family
range|:
name|regionInfo
operator|.
name|getTableDesc
argument_list|()
operator|.
name|getFamiliesKeys
argument_list|()
control|)
block|{
name|get
operator|.
name|addFamily
argument_list|(
name|family
argument_list|)
expr_stmt|;
block|}
block|}
comment|// Lock row
name|Integer
name|lid
init|=
name|getLock
argument_list|(
name|lockid
argument_list|,
name|get
operator|.
name|getRow
argument_list|()
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|KeyValue
argument_list|>
name|result
init|=
operator|new
name|ArrayList
argument_list|<
name|KeyValue
argument_list|>
argument_list|()
decl_stmt|;
try|try
block|{
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|byte
index|[]
argument_list|,
name|NavigableSet
argument_list|<
name|byte
index|[]
argument_list|>
argument_list|>
name|entry
range|:
name|get
operator|.
name|getFamilyMap
argument_list|()
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|get
argument_list|(
name|this
operator|.
name|stores
operator|.
name|get
argument_list|(
name|entry
operator|.
name|getKey
argument_list|()
argument_list|)
argument_list|,
name|get
argument_list|,
name|entry
operator|.
name|getValue
argument_list|()
argument_list|,
name|result
argument_list|)
expr_stmt|;
block|}
block|}
finally|finally
block|{
if|if
condition|(
name|lockid
operator|==
literal|null
condition|)
name|releaseRowLock
argument_list|(
name|lid
argument_list|)
expr_stmt|;
block|}
return|return
operator|new
name|Result
argument_list|(
name|result
argument_list|)
return|;
block|}
specifier|private
name|void
name|get
parameter_list|(
specifier|final
name|Store
name|store
parameter_list|,
specifier|final
name|Get
name|get
parameter_list|,
specifier|final
name|NavigableSet
argument_list|<
name|byte
index|[]
argument_list|>
name|qualifiers
parameter_list|,
name|List
argument_list|<
name|KeyValue
argument_list|>
name|result
parameter_list|)
throws|throws
name|IOException
block|{
name|store
operator|.
name|get
argument_list|(
name|get
argument_list|,
name|qualifiers
argument_list|,
name|result
argument_list|)
expr_stmt|;
block|}
comment|/**    *     * @param row    * @param family    * @param qualifier    * @param amount    * @return The new value.    * @throws IOException    */
specifier|public
name|long
name|incrementColumnValue
parameter_list|(
name|byte
index|[]
name|row
parameter_list|,
name|byte
index|[]
name|family
parameter_list|,
name|byte
index|[]
name|qualifier
parameter_list|,
name|long
name|amount
parameter_list|,
name|boolean
name|writeToWAL
parameter_list|)
throws|throws
name|IOException
block|{
name|checkRow
argument_list|(
name|row
argument_list|)
expr_stmt|;
name|boolean
name|flush
init|=
literal|false
decl_stmt|;
comment|// Lock row
name|Integer
name|lid
init|=
name|obtainRowLock
argument_list|(
name|row
argument_list|)
decl_stmt|;
name|long
name|result
init|=
name|amount
decl_stmt|;
try|try
block|{
name|Store
name|store
init|=
name|stores
operator|.
name|get
argument_list|(
name|family
argument_list|)
decl_stmt|;
comment|// Get the old value:
name|Get
name|get
init|=
operator|new
name|Get
argument_list|(
name|row
argument_list|)
decl_stmt|;
name|get
operator|.
name|addColumn
argument_list|(
name|family
argument_list|,
name|qualifier
argument_list|)
expr_stmt|;
name|List
argument_list|<
name|KeyValue
argument_list|>
name|results
init|=
operator|new
name|ArrayList
argument_list|<
name|KeyValue
argument_list|>
argument_list|()
decl_stmt|;
name|NavigableSet
argument_list|<
name|byte
index|[]
argument_list|>
name|qualifiers
init|=
operator|new
name|TreeSet
argument_list|<
name|byte
index|[]
argument_list|>
argument_list|(
name|Bytes
operator|.
name|BYTES_COMPARATOR
argument_list|)
decl_stmt|;
name|qualifiers
operator|.
name|add
argument_list|(
name|qualifier
argument_list|)
expr_stmt|;
name|store
operator|.
name|get
argument_list|(
name|get
argument_list|,
name|qualifiers
argument_list|,
name|results
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|results
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|byte
index|[]
name|oldValue
init|=
name|results
operator|.
name|get
argument_list|(
literal|0
argument_list|)
operator|.
name|getValue
argument_list|()
decl_stmt|;
name|KeyValue
name|kv
init|=
name|results
operator|.
name|get
argument_list|(
literal|0
argument_list|)
decl_stmt|;
name|byte
index|[]
name|buffer
init|=
name|kv
operator|.
name|getBuffer
argument_list|()
decl_stmt|;
name|int
name|valueOffset
init|=
name|kv
operator|.
name|getValueOffset
argument_list|()
decl_stmt|;
name|result
operator|+=
name|Bytes
operator|.
name|toLong
argument_list|(
name|buffer
argument_list|,
name|valueOffset
argument_list|,
name|Bytes
operator|.
name|SIZEOF_LONG
argument_list|)
expr_stmt|;
block|}
comment|// bulid the KeyValue now:
name|KeyValue
name|newKv
init|=
operator|new
name|KeyValue
argument_list|(
name|row
argument_list|,
name|family
argument_list|,
name|qualifier
argument_list|,
name|System
operator|.
name|currentTimeMillis
argument_list|()
argument_list|,
name|Bytes
operator|.
name|toBytes
argument_list|(
name|result
argument_list|)
argument_list|)
decl_stmt|;
comment|// now log it:
if|if
condition|(
name|writeToWAL
condition|)
block|{
name|long
name|now
init|=
name|System
operator|.
name|currentTimeMillis
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|KeyValue
argument_list|>
name|edits
init|=
operator|new
name|ArrayList
argument_list|<
name|KeyValue
argument_list|>
argument_list|(
literal|1
argument_list|)
decl_stmt|;
name|edits
operator|.
name|add
argument_list|(
name|newKv
argument_list|)
expr_stmt|;
name|this
operator|.
name|log
operator|.
name|append
argument_list|(
name|regionInfo
operator|.
name|getRegionName
argument_list|()
argument_list|,
name|regionInfo
operator|.
name|getTableDesc
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|,
name|edits
argument_list|,
operator|(
name|regionInfo
operator|.
name|isMetaRegion
argument_list|()
operator|||
name|regionInfo
operator|.
name|isRootRegion
argument_list|()
operator|)
argument_list|,
name|now
argument_list|)
expr_stmt|;
block|}
comment|// Now request the ICV to the store, this will set the timestamp
comment|// appropriately depending on if there is a value in memcache or not.
comment|// returns the
name|long
name|size
init|=
name|store
operator|.
name|updateColumnValue
argument_list|(
name|row
argument_list|,
name|family
argument_list|,
name|qualifier
argument_list|,
name|result
argument_list|)
decl_stmt|;
name|size
operator|=
name|this
operator|.
name|memstoreSize
operator|.
name|addAndGet
argument_list|(
name|size
argument_list|)
expr_stmt|;
name|flush
operator|=
name|isFlushSize
argument_list|(
name|size
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|releaseRowLock
argument_list|(
name|lid
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|flush
condition|)
block|{
comment|// Request a cache flush.  Do it outside update lock.
name|requestFlush
argument_list|()
expr_stmt|;
block|}
return|return
name|result
return|;
block|}
comment|//
comment|// New HBASE-880 Helpers
comment|//
specifier|private
name|void
name|checkFamily
parameter_list|(
specifier|final
name|byte
index|[]
name|family
parameter_list|)
throws|throws
name|NoSuchColumnFamilyException
block|{
if|if
condition|(
operator|!
name|regionInfo
operator|.
name|getTableDesc
argument_list|()
operator|.
name|hasFamily
argument_list|(
name|family
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|NoSuchColumnFamilyException
argument_list|(
literal|"Column family "
operator|+
name|Bytes
operator|.
name|toString
argument_list|(
name|family
argument_list|)
operator|+
literal|" does not exist in region "
operator|+
name|this
operator|+
literal|" in table "
operator|+
name|regionInfo
operator|.
name|getTableDesc
argument_list|()
argument_list|)
throw|;
block|}
block|}
specifier|public
specifier|static
specifier|final
name|long
name|FIXED_OVERHEAD
init|=
name|ClassSize
operator|.
name|align
argument_list|(
operator|(
literal|3
operator|*
name|Bytes
operator|.
name|SIZEOF_LONG
operator|)
operator|+
operator|(
literal|2
operator|*
name|Bytes
operator|.
name|SIZEOF_INT
operator|)
operator|+
name|Bytes
operator|.
name|SIZEOF_BOOLEAN
operator|+
operator|(
literal|20
operator|*
name|ClassSize
operator|.
name|REFERENCE
operator|)
operator|+
name|ClassSize
operator|.
name|OBJECT
argument_list|)
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|long
name|DEEP_OVERHEAD
init|=
name|ClassSize
operator|.
name|align
argument_list|(
name|FIXED_OVERHEAD
operator|+
name|ClassSize
operator|.
name|OBJECT
operator|+
operator|(
literal|2
operator|*
name|ClassSize
operator|.
name|ATOMIC_BOOLEAN
operator|)
operator|+
name|ClassSize
operator|.
name|ATOMIC_LONG
operator|+
name|ClassSize
operator|.
name|ATOMIC_INTEGER
operator|+
name|ClassSize
operator|.
name|CONCURRENT_HASHMAP
operator|+
operator|(
literal|16
operator|*
name|ClassSize
operator|.
name|CONCURRENT_HASHMAP_ENTRY
operator|)
operator|+
operator|(
literal|16
operator|*
name|ClassSize
operator|.
name|CONCURRENT_HASHMAP_SEGMENT
operator|)
operator|+
name|ClassSize
operator|.
name|CONCURRENT_SKIPLISTMAP
operator|+
name|ClassSize
operator|.
name|CONCURRENT_SKIPLISTMAP_ENTRY
operator|+
name|RegionHistorian
operator|.
name|FIXED_OVERHEAD
operator|+
name|HLog
operator|.
name|FIXED_OVERHEAD
operator|+
name|ClassSize
operator|.
name|align
argument_list|(
name|ClassSize
operator|.
name|OBJECT
operator|+
operator|(
literal|5
operator|*
name|Bytes
operator|.
name|SIZEOF_BOOLEAN
operator|)
argument_list|)
operator|+
operator|(
literal|3
operator|*
name|ClassSize
operator|.
name|REENTRANT_LOCK
operator|)
argument_list|)
decl_stmt|;
annotation|@
name|Override
specifier|public
name|long
name|heapSize
parameter_list|()
block|{
name|long
name|heapSize
init|=
name|DEEP_OVERHEAD
decl_stmt|;
for|for
control|(
name|Store
name|store
range|:
name|this
operator|.
name|stores
operator|.
name|values
argument_list|()
control|)
block|{
name|heapSize
operator|+=
name|store
operator|.
name|heapSize
argument_list|()
expr_stmt|;
block|}
return|return
name|heapSize
return|;
block|}
comment|/*    * This method calls System.exit.    * @param message Message to print out.  May be null.    */
specifier|private
specifier|static
name|void
name|printUsageAndExit
parameter_list|(
specifier|final
name|String
name|message
parameter_list|)
block|{
if|if
condition|(
name|message
operator|!=
literal|null
operator|&&
name|message
operator|.
name|length
argument_list|()
operator|>
literal|0
condition|)
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
name|message
argument_list|)
expr_stmt|;
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"Usage: HRegion CATLALOG_TABLE_DIR [major_compact]"
argument_list|)
expr_stmt|;
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"Options:"
argument_list|)
expr_stmt|;
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|" major_compact  Pass this option to major compact "
operator|+
literal|"passed region."
argument_list|)
expr_stmt|;
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"Default outputs scan of passed region."
argument_list|)
expr_stmt|;
name|System
operator|.
name|exit
argument_list|(
literal|1
argument_list|)
expr_stmt|;
block|}
comment|/*    * Process table.    * Do major compaction or list content.    * @param fs    * @param p    * @param log    * @param c    * @param majorCompact    * @throws IOException    */
specifier|private
specifier|static
name|void
name|processTable
parameter_list|(
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Path
name|p
parameter_list|,
specifier|final
name|HLog
name|log
parameter_list|,
specifier|final
name|HBaseConfiguration
name|c
parameter_list|,
specifier|final
name|boolean
name|majorCompact
parameter_list|)
throws|throws
name|IOException
block|{
name|HRegion
name|region
init|=
literal|null
decl_stmt|;
name|String
name|rootStr
init|=
name|Bytes
operator|.
name|toString
argument_list|(
name|HConstants
operator|.
name|ROOT_TABLE_NAME
argument_list|)
decl_stmt|;
name|String
name|metaStr
init|=
name|Bytes
operator|.
name|toString
argument_list|(
name|HConstants
operator|.
name|META_TABLE_NAME
argument_list|)
decl_stmt|;
comment|// Currently expects tables have one region only.
if|if
condition|(
name|p
operator|.
name|getName
argument_list|()
operator|.
name|startsWith
argument_list|(
name|rootStr
argument_list|)
condition|)
block|{
name|region
operator|=
operator|new
name|HRegion
argument_list|(
name|p
argument_list|,
name|log
argument_list|,
name|fs
argument_list|,
name|c
argument_list|,
name|HRegionInfo
operator|.
name|ROOT_REGIONINFO
argument_list|,
literal|null
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|p
operator|.
name|getName
argument_list|()
operator|.
name|startsWith
argument_list|(
name|metaStr
argument_list|)
condition|)
block|{
name|region
operator|=
operator|new
name|HRegion
argument_list|(
name|p
argument_list|,
name|log
argument_list|,
name|fs
argument_list|,
name|c
argument_list|,
name|HRegionInfo
operator|.
name|FIRST_META_REGIONINFO
argument_list|,
literal|null
argument_list|)
expr_stmt|;
block|}
else|else
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Not a known catalog table: "
operator|+
name|p
operator|.
name|toString
argument_list|()
argument_list|)
throw|;
block|}
try|try
block|{
name|region
operator|.
name|initialize
argument_list|(
literal|null
argument_list|,
literal|null
argument_list|)
expr_stmt|;
if|if
condition|(
name|majorCompact
condition|)
block|{
name|region
operator|.
name|compactStores
argument_list|(
literal|true
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// Default behavior
name|Scan
name|scan
init|=
operator|new
name|Scan
argument_list|()
decl_stmt|;
comment|// scan.addFamily(HConstants.CATALOG_FAMILY);
name|InternalScanner
name|scanner
init|=
name|region
operator|.
name|getScanner
argument_list|(
name|scan
argument_list|)
decl_stmt|;
try|try
block|{
name|List
argument_list|<
name|KeyValue
argument_list|>
name|kvs
init|=
operator|new
name|ArrayList
argument_list|<
name|KeyValue
argument_list|>
argument_list|()
decl_stmt|;
name|boolean
name|done
init|=
literal|false
decl_stmt|;
do|do
block|{
name|kvs
operator|.
name|clear
argument_list|()
expr_stmt|;
name|done
operator|=
name|scanner
operator|.
name|next
argument_list|(
name|kvs
argument_list|)
expr_stmt|;
if|if
condition|(
name|kvs
operator|.
name|size
argument_list|()
operator|>
literal|0
condition|)
name|LOG
operator|.
name|info
argument_list|(
name|kvs
argument_list|)
expr_stmt|;
block|}
do|while
condition|(
name|done
condition|)
do|;
block|}
finally|finally
block|{
name|scanner
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
comment|// System.out.println(region.getClosestRowBefore(Bytes.toBytes("GeneratedCSVContent2,E3652782193BC8D66A0BA1629D0FAAAB,9993372036854775807")));
block|}
block|}
finally|finally
block|{
name|region
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**    * For internal use in forcing splits ahead of file size limit.    * @param b    * @return previous value    */
specifier|public
name|boolean
name|shouldSplit
parameter_list|(
name|boolean
name|b
parameter_list|)
block|{
name|boolean
name|old
init|=
name|this
operator|.
name|splitRequest
decl_stmt|;
name|this
operator|.
name|splitRequest
operator|=
name|b
expr_stmt|;
return|return
name|old
return|;
block|}
comment|/**    * Facility for dumping and compacting catalog tables.    * Only does catalog tables since these are only tables we for sure know    * schema on.  For usage run:    *<pre>    *   ./bin/hbase org.apache.hadoop.hbase.regionserver.HRegion    *</pre>    * @param args    * @throws IOException     */
specifier|public
specifier|static
name|void
name|main
parameter_list|(
name|String
index|[]
name|args
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|args
operator|.
name|length
operator|<
literal|1
condition|)
block|{
name|printUsageAndExit
argument_list|(
literal|null
argument_list|)
expr_stmt|;
block|}
name|boolean
name|majorCompact
init|=
literal|false
decl_stmt|;
if|if
condition|(
name|args
operator|.
name|length
operator|>
literal|1
condition|)
block|{
if|if
condition|(
operator|!
name|args
index|[
literal|1
index|]
operator|.
name|toLowerCase
argument_list|()
operator|.
name|startsWith
argument_list|(
literal|"major"
argument_list|)
condition|)
block|{
name|printUsageAndExit
argument_list|(
literal|"ERROR: Unrecognized option<"
operator|+
name|args
index|[
literal|1
index|]
operator|+
literal|">"
argument_list|)
expr_stmt|;
block|}
name|majorCompact
operator|=
literal|true
expr_stmt|;
block|}
name|Path
name|tableDir
init|=
operator|new
name|Path
argument_list|(
name|args
index|[
literal|0
index|]
argument_list|)
decl_stmt|;
name|HBaseConfiguration
name|c
init|=
operator|new
name|HBaseConfiguration
argument_list|()
decl_stmt|;
name|FileSystem
name|fs
init|=
name|FileSystem
operator|.
name|get
argument_list|(
name|c
argument_list|)
decl_stmt|;
name|Path
name|logdir
init|=
operator|new
name|Path
argument_list|(
name|c
operator|.
name|get
argument_list|(
literal|"hbase.tmp.dir"
argument_list|)
argument_list|,
literal|"hlog"
operator|+
name|tableDir
operator|.
name|getName
argument_list|()
operator|+
name|System
operator|.
name|currentTimeMillis
argument_list|()
argument_list|)
decl_stmt|;
name|HLog
name|log
init|=
operator|new
name|HLog
argument_list|(
name|fs
argument_list|,
name|logdir
argument_list|,
name|c
argument_list|,
literal|null
argument_list|)
decl_stmt|;
try|try
block|{
name|processTable
argument_list|(
name|fs
argument_list|,
name|tableDir
argument_list|,
name|log
argument_list|,
name|c
argument_list|,
name|majorCompact
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|log
operator|.
name|close
argument_list|()
expr_stmt|;
name|BlockCache
name|bc
init|=
name|StoreFile
operator|.
name|getBlockCache
argument_list|(
name|c
argument_list|)
decl_stmt|;
if|if
condition|(
name|bc
operator|!=
literal|null
condition|)
name|bc
operator|.
name|shutdown
argument_list|()
expr_stmt|;
block|}
block|}
block|}
end_class

end_unit

