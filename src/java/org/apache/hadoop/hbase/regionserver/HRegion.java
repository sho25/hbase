begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Copyright 2007 The Apache Software Foundation  *  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|UnsupportedEncodingException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collection
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Random
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Set
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|SortedMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|TreeMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|TreeSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ConcurrentHashMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|atomic
operator|.
name|AtomicBoolean
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|atomic
operator|.
name|AtomicInteger
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|atomic
operator|.
name|AtomicLong
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|locks
operator|.
name|ReentrantReadWriteLock
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|Log
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|LogFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileStatus
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|ColumnNameParseException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|DroppedSnapshotException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HBaseConfiguration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HColumnDescriptor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HConstants
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HRegionInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HStoreKey
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HTableDescriptor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|NotServingRegionException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|RegionHistorian
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|filter
operator|.
name|RowFilterInterface
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|BatchOperation
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|BatchUpdate
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|Cell
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|HbaseMapWritable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|RowResult
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|ipc
operator|.
name|HRegionInterface
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|Bytes
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|FSUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|Writables
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|WritableUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|Progressable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|StringUtils
import|;
end_import

begin_comment
comment|/**  * HRegion stores data for a certain region of a table.  It stores all columns  * for each row. A given table consists of one or more HRegions.  *  *<p>We maintain multiple HStores for a single HRegion.  *   *<p>An HStore is a set of rows with some column data; together,  * they make up all the data for the rows.    *  *<p>Each HRegion has a 'startKey' and 'endKey'.  *<p>The first is inclusive, the second is exclusive (except for  * the final region)  The endKey of region 0 is the same as  * startKey for region 1 (if it exists).  The startKey for the  * first region is null. The endKey for the final region is null.  *  *<p>Locking at the HRegion level serves only one purpose: preventing the  * region from being closed (and consequently split) while other operations  * are ongoing. Each row level operation obtains both a row lock and a region  * read lock for the duration of the operation. While a scanner is being  * constructed, getScanner holds a read lock. If the scanner is successfully  * constructed, it holds a read lock until it is closed. A close takes out a  * write lock and consequently will block for ongoing operations and will block  * new operations from starting while the close is in progress.  *   *<p>An HRegion is defined by its table and its key extent.  *   *<p>It consists of at least one HStore.  The number of HStores should be   * configurable, so that data which is accessed together is stored in the same  * HStore.  Right now, we approximate that by building a single HStore for   * each column family.  (This config info will be communicated via the   * tabledesc.)  *   *<p>The HTableDescriptor contains metainfo about the HRegion's table.  * regionName is a unique identifier for this HRegion. (startKey, endKey]  * defines the keyspace for this HRegion.  */
end_comment

begin_class
specifier|public
class|class
name|HRegion
implements|implements
name|HConstants
block|{
specifier|static
specifier|final
name|String
name|SPLITDIR
init|=
literal|"splits"
decl_stmt|;
specifier|static
specifier|final
name|String
name|MERGEDIR
init|=
literal|"merges"
decl_stmt|;
specifier|static
specifier|final
name|Random
name|rand
init|=
operator|new
name|Random
argument_list|()
decl_stmt|;
specifier|static
specifier|final
name|Log
name|LOG
init|=
name|LogFactory
operator|.
name|getLog
argument_list|(
name|HRegion
operator|.
name|class
argument_list|)
decl_stmt|;
specifier|final
name|AtomicBoolean
name|closed
init|=
operator|new
name|AtomicBoolean
argument_list|(
literal|false
argument_list|)
decl_stmt|;
specifier|private
specifier|final
name|RegionHistorian
name|historian
decl_stmt|;
comment|/**    * Merge two HRegions.  The regions must be adjacent andmust not overlap.    *     * @param srcA    * @param srcB    * @return new merged HRegion    * @throws IOException    */
specifier|public
specifier|static
name|HRegion
name|mergeAdjacent
parameter_list|(
specifier|final
name|HRegion
name|srcA
parameter_list|,
specifier|final
name|HRegion
name|srcB
parameter_list|)
throws|throws
name|IOException
block|{
name|HRegion
name|a
init|=
name|srcA
decl_stmt|;
name|HRegion
name|b
init|=
name|srcB
decl_stmt|;
comment|// Make sure that srcA comes first; important for key-ordering during
comment|// write of the merged file.
if|if
condition|(
name|srcA
operator|.
name|getStartKey
argument_list|()
operator|==
literal|null
condition|)
block|{
if|if
condition|(
name|srcB
operator|.
name|getStartKey
argument_list|()
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Cannot merge two regions with null start key"
argument_list|)
throw|;
block|}
comment|// A's start key is null but B's isn't. Assume A comes before B
block|}
elseif|else
if|if
condition|(
operator|(
name|srcB
operator|.
name|getStartKey
argument_list|()
operator|==
literal|null
operator|)
comment|// A is not null but B is
operator|||
operator|(
name|Bytes
operator|.
name|compareTo
argument_list|(
name|srcA
operator|.
name|getStartKey
argument_list|()
argument_list|,
name|srcB
operator|.
name|getStartKey
argument_list|()
argument_list|)
operator|>
literal|0
operator|)
condition|)
block|{
comment|// A> B
name|a
operator|=
name|srcB
expr_stmt|;
name|b
operator|=
name|srcA
expr_stmt|;
block|}
if|if
condition|(
operator|!
name|Bytes
operator|.
name|equals
argument_list|(
name|a
operator|.
name|getEndKey
argument_list|()
argument_list|,
name|b
operator|.
name|getStartKey
argument_list|()
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Cannot merge non-adjacent regions"
argument_list|)
throw|;
block|}
return|return
name|merge
argument_list|(
name|a
argument_list|,
name|b
argument_list|)
return|;
block|}
comment|/**    * Merge two regions whether they are adjacent or not.    *     * @param a region a    * @param b region b    * @return new merged region    * @throws IOException    */
specifier|public
specifier|static
name|HRegion
name|merge
parameter_list|(
name|HRegion
name|a
parameter_list|,
name|HRegion
name|b
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
operator|!
name|a
operator|.
name|getRegionInfo
argument_list|()
operator|.
name|getTableDesc
argument_list|()
operator|.
name|getNameAsString
argument_list|()
operator|.
name|equals
argument_list|(
name|b
operator|.
name|getRegionInfo
argument_list|()
operator|.
name|getTableDesc
argument_list|()
operator|.
name|getNameAsString
argument_list|()
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Regions do not belong to the same table"
argument_list|)
throw|;
block|}
name|FileSystem
name|fs
init|=
name|a
operator|.
name|getFilesystem
argument_list|()
decl_stmt|;
comment|// Make sure each region's cache is empty
name|a
operator|.
name|flushcache
argument_list|()
expr_stmt|;
name|b
operator|.
name|flushcache
argument_list|()
expr_stmt|;
comment|// Compact each region so we only have one store file per family
name|a
operator|.
name|compactStores
argument_list|(
literal|true
argument_list|)
expr_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Files for region: "
operator|+
name|a
argument_list|)
expr_stmt|;
name|listPaths
argument_list|(
name|fs
argument_list|,
name|a
operator|.
name|getRegionDir
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|b
operator|.
name|compactStores
argument_list|(
literal|true
argument_list|)
expr_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Files for region: "
operator|+
name|b
argument_list|)
expr_stmt|;
name|listPaths
argument_list|(
name|fs
argument_list|,
name|b
operator|.
name|getRegionDir
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|HBaseConfiguration
name|conf
init|=
name|a
operator|.
name|getConf
argument_list|()
decl_stmt|;
name|HTableDescriptor
name|tabledesc
init|=
name|a
operator|.
name|getTableDesc
argument_list|()
decl_stmt|;
name|HLog
name|log
init|=
name|a
operator|.
name|getLog
argument_list|()
decl_stmt|;
name|Path
name|basedir
init|=
name|a
operator|.
name|getBaseDir
argument_list|()
decl_stmt|;
specifier|final
name|byte
index|[]
name|startKey
init|=
name|Bytes
operator|.
name|equals
argument_list|(
name|a
operator|.
name|getStartKey
argument_list|()
argument_list|,
name|EMPTY_BYTE_ARRAY
argument_list|)
operator|||
name|Bytes
operator|.
name|equals
argument_list|(
name|b
operator|.
name|getStartKey
argument_list|()
argument_list|,
name|EMPTY_BYTE_ARRAY
argument_list|)
condition|?
name|EMPTY_BYTE_ARRAY
else|:
name|Bytes
operator|.
name|compareTo
argument_list|(
name|a
operator|.
name|getStartKey
argument_list|()
argument_list|,
name|b
operator|.
name|getStartKey
argument_list|()
argument_list|)
operator|<=
literal|0
condition|?
name|a
operator|.
name|getStartKey
argument_list|()
else|:
name|b
operator|.
name|getStartKey
argument_list|()
decl_stmt|;
specifier|final
name|byte
index|[]
name|endKey
init|=
name|Bytes
operator|.
name|equals
argument_list|(
name|a
operator|.
name|getEndKey
argument_list|()
argument_list|,
name|EMPTY_BYTE_ARRAY
argument_list|)
operator|||
name|Bytes
operator|.
name|equals
argument_list|(
name|b
operator|.
name|getEndKey
argument_list|()
argument_list|,
name|EMPTY_BYTE_ARRAY
argument_list|)
condition|?
name|EMPTY_BYTE_ARRAY
else|:
name|Bytes
operator|.
name|compareTo
argument_list|(
name|a
operator|.
name|getEndKey
argument_list|()
argument_list|,
name|b
operator|.
name|getEndKey
argument_list|()
argument_list|)
operator|<=
literal|0
condition|?
name|b
operator|.
name|getEndKey
argument_list|()
else|:
name|a
operator|.
name|getEndKey
argument_list|()
decl_stmt|;
name|HRegionInfo
name|newRegionInfo
init|=
operator|new
name|HRegionInfo
argument_list|(
name|tabledesc
argument_list|,
name|startKey
argument_list|,
name|endKey
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Creating new region "
operator|+
name|newRegionInfo
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
name|int
name|encodedName
init|=
name|newRegionInfo
operator|.
name|getEncodedName
argument_list|()
decl_stmt|;
name|Path
name|newRegionDir
init|=
name|HRegion
operator|.
name|getRegionDir
argument_list|(
name|a
operator|.
name|getBaseDir
argument_list|()
argument_list|,
name|encodedName
argument_list|)
decl_stmt|;
if|if
condition|(
name|fs
operator|.
name|exists
argument_list|(
name|newRegionDir
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Cannot merge; target file collision at "
operator|+
name|newRegionDir
argument_list|)
throw|;
block|}
name|fs
operator|.
name|mkdirs
argument_list|(
name|newRegionDir
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"starting merge of regions: "
operator|+
name|a
operator|+
literal|" and "
operator|+
name|b
operator|+
literal|" into new region "
operator|+
name|newRegionInfo
operator|.
name|toString
argument_list|()
operator|+
literal|" with start key<"
operator|+
name|startKey
operator|+
literal|"> and end key<"
operator|+
name|endKey
operator|+
literal|">"
argument_list|)
expr_stmt|;
comment|// Move HStoreFiles under new region directory
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|List
argument_list|<
name|HStoreFile
argument_list|>
argument_list|>
name|byFamily
init|=
operator|new
name|TreeMap
argument_list|<
name|byte
index|[]
argument_list|,
name|List
argument_list|<
name|HStoreFile
argument_list|>
argument_list|>
argument_list|(
name|Bytes
operator|.
name|BYTES_COMPARATOR
argument_list|)
decl_stmt|;
name|byFamily
operator|=
name|filesByFamily
argument_list|(
name|byFamily
argument_list|,
name|a
operator|.
name|close
argument_list|()
argument_list|)
expr_stmt|;
name|byFamily
operator|=
name|filesByFamily
argument_list|(
name|byFamily
argument_list|,
name|b
operator|.
name|close
argument_list|()
argument_list|)
expr_stmt|;
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|byte
index|[]
argument_list|,
name|List
argument_list|<
name|HStoreFile
argument_list|>
argument_list|>
name|es
range|:
name|byFamily
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|byte
index|[]
name|colFamily
init|=
name|es
operator|.
name|getKey
argument_list|()
decl_stmt|;
name|makeColumnFamilyDirs
argument_list|(
name|fs
argument_list|,
name|basedir
argument_list|,
name|encodedName
argument_list|,
name|colFamily
argument_list|,
name|tabledesc
argument_list|)
expr_stmt|;
comment|// Because we compacted the source regions we should have no more than two
comment|// HStoreFiles per family and there will be no reference store
name|List
argument_list|<
name|HStoreFile
argument_list|>
name|srcFiles
init|=
name|es
operator|.
name|getValue
argument_list|()
decl_stmt|;
if|if
condition|(
name|srcFiles
operator|.
name|size
argument_list|()
operator|==
literal|2
condition|)
block|{
name|long
name|seqA
init|=
name|srcFiles
operator|.
name|get
argument_list|(
literal|0
argument_list|)
operator|.
name|loadInfo
argument_list|(
name|fs
argument_list|)
decl_stmt|;
name|long
name|seqB
init|=
name|srcFiles
operator|.
name|get
argument_list|(
literal|1
argument_list|)
operator|.
name|loadInfo
argument_list|(
name|fs
argument_list|)
decl_stmt|;
if|if
condition|(
name|seqA
operator|==
name|seqB
condition|)
block|{
comment|// We can't have duplicate sequence numbers
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Adjusting sequence id of storeFile "
operator|+
name|srcFiles
operator|.
name|get
argument_list|(
literal|1
argument_list|)
operator|+
literal|" down by one; sequence id A="
operator|+
name|seqA
operator|+
literal|", sequence id B="
operator|+
name|seqB
argument_list|)
expr_stmt|;
block|}
name|srcFiles
operator|.
name|get
argument_list|(
literal|1
argument_list|)
operator|.
name|writeInfo
argument_list|(
name|fs
argument_list|,
name|seqB
operator|-
literal|1
argument_list|)
expr_stmt|;
block|}
block|}
for|for
control|(
name|HStoreFile
name|hsf
range|:
name|srcFiles
control|)
block|{
name|HStoreFile
name|dst
init|=
operator|new
name|HStoreFile
argument_list|(
name|conf
argument_list|,
name|fs
argument_list|,
name|basedir
argument_list|,
name|newRegionInfo
operator|.
name|getEncodedName
argument_list|()
argument_list|,
name|colFamily
argument_list|,
operator|-
literal|1
argument_list|,
literal|null
argument_list|)
decl_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Renaming "
operator|+
name|hsf
operator|+
literal|" to "
operator|+
name|dst
argument_list|)
expr_stmt|;
block|}
name|hsf
operator|.
name|rename
argument_list|(
name|fs
argument_list|,
name|dst
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Files for new region"
argument_list|)
expr_stmt|;
name|listPaths
argument_list|(
name|fs
argument_list|,
name|newRegionDir
argument_list|)
expr_stmt|;
block|}
name|HRegion
name|dstRegion
init|=
operator|new
name|HRegion
argument_list|(
name|basedir
argument_list|,
name|log
argument_list|,
name|fs
argument_list|,
name|conf
argument_list|,
name|newRegionInfo
argument_list|,
literal|null
argument_list|,
literal|null
argument_list|)
decl_stmt|;
name|dstRegion
operator|.
name|compactStores
argument_list|()
expr_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Files for new region"
argument_list|)
expr_stmt|;
name|listPaths
argument_list|(
name|fs
argument_list|,
name|dstRegion
operator|.
name|getRegionDir
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|deleteRegion
argument_list|(
name|fs
argument_list|,
name|a
operator|.
name|getRegionDir
argument_list|()
argument_list|)
expr_stmt|;
name|deleteRegion
argument_list|(
name|fs
argument_list|,
name|b
operator|.
name|getRegionDir
argument_list|()
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"merge completed. New region is "
operator|+
name|dstRegion
argument_list|)
expr_stmt|;
return|return
name|dstRegion
return|;
block|}
comment|/*    * Fills a map with a vector of store files keyed by column family.     * @param byFamily Map to fill.    * @param storeFiles Store files to process.    * @return Returns<code>byFamily</code>    */
specifier|private
specifier|static
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|List
argument_list|<
name|HStoreFile
argument_list|>
argument_list|>
name|filesByFamily
parameter_list|(
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|List
argument_list|<
name|HStoreFile
argument_list|>
argument_list|>
name|byFamily
parameter_list|,
name|List
argument_list|<
name|HStoreFile
argument_list|>
name|storeFiles
parameter_list|)
block|{
for|for
control|(
name|HStoreFile
name|src
range|:
name|storeFiles
control|)
block|{
name|List
argument_list|<
name|HStoreFile
argument_list|>
name|v
init|=
name|byFamily
operator|.
name|get
argument_list|(
name|src
operator|.
name|getColFamily
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|v
operator|==
literal|null
condition|)
block|{
name|v
operator|=
operator|new
name|ArrayList
argument_list|<
name|HStoreFile
argument_list|>
argument_list|()
expr_stmt|;
name|byFamily
operator|.
name|put
argument_list|(
name|src
operator|.
name|getColFamily
argument_list|()
argument_list|,
name|v
argument_list|)
expr_stmt|;
block|}
name|v
operator|.
name|add
argument_list|(
name|src
argument_list|)
expr_stmt|;
block|}
return|return
name|byFamily
return|;
block|}
comment|/*    * Method to list files in use by region    */
specifier|static
name|void
name|listFiles
parameter_list|(
name|FileSystem
name|fs
parameter_list|,
name|HRegion
name|r
parameter_list|)
throws|throws
name|IOException
block|{
name|listPaths
argument_list|(
name|fs
argument_list|,
name|r
operator|.
name|getRegionDir
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|/*    * List the files under the specified directory    *     * @param fs    * @param dir    * @throws IOException    */
specifier|private
specifier|static
name|void
name|listPaths
parameter_list|(
name|FileSystem
name|fs
parameter_list|,
name|Path
name|dir
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|FileStatus
index|[]
name|stats
init|=
name|fs
operator|.
name|listStatus
argument_list|(
name|dir
argument_list|)
decl_stmt|;
if|if
condition|(
name|stats
operator|==
literal|null
operator|||
name|stats
operator|.
name|length
operator|==
literal|0
condition|)
block|{
return|return;
block|}
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|stats
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|String
name|path
init|=
name|stats
index|[
name|i
index|]
operator|.
name|getPath
argument_list|()
operator|.
name|toString
argument_list|()
decl_stmt|;
if|if
condition|(
name|stats
index|[
name|i
index|]
operator|.
name|isDir
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"d "
operator|+
name|path
argument_list|)
expr_stmt|;
name|listPaths
argument_list|(
name|fs
argument_list|,
name|stats
index|[
name|i
index|]
operator|.
name|getPath
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"f "
operator|+
name|path
operator|+
literal|" size="
operator|+
name|stats
index|[
name|i
index|]
operator|.
name|getLen
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
comment|//////////////////////////////////////////////////////////////////////////////
comment|// Members
comment|//////////////////////////////////////////////////////////////////////////////
specifier|private
specifier|final
name|Map
argument_list|<
name|Integer
argument_list|,
name|byte
index|[]
argument_list|>
name|locksToRows
init|=
operator|new
name|ConcurrentHashMap
argument_list|<
name|Integer
argument_list|,
name|byte
index|[]
argument_list|>
argument_list|()
decl_stmt|;
specifier|private
specifier|final
name|Map
argument_list|<
name|Integer
argument_list|,
name|TreeMap
argument_list|<
name|HStoreKey
argument_list|,
name|byte
index|[]
argument_list|>
argument_list|>
name|targetColumns
init|=
operator|new
name|ConcurrentHashMap
argument_list|<
name|Integer
argument_list|,
name|TreeMap
argument_list|<
name|HStoreKey
argument_list|,
name|byte
index|[]
argument_list|>
argument_list|>
argument_list|()
decl_stmt|;
comment|// Default access because read by tests.
specifier|final
name|Map
argument_list|<
name|Integer
argument_list|,
name|HStore
argument_list|>
name|stores
init|=
operator|new
name|ConcurrentHashMap
argument_list|<
name|Integer
argument_list|,
name|HStore
argument_list|>
argument_list|()
decl_stmt|;
specifier|final
name|AtomicLong
name|memcacheSize
init|=
operator|new
name|AtomicLong
argument_list|(
literal|0
argument_list|)
decl_stmt|;
specifier|final
name|Path
name|basedir
decl_stmt|;
specifier|final
name|HLog
name|log
decl_stmt|;
specifier|final
name|FileSystem
name|fs
decl_stmt|;
specifier|final
name|HBaseConfiguration
name|conf
decl_stmt|;
specifier|final
name|HRegionInfo
name|regionInfo
decl_stmt|;
specifier|final
name|Path
name|regiondir
decl_stmt|;
specifier|private
specifier|final
name|Path
name|regionCompactionDir
decl_stmt|;
comment|/*    * Data structure of write state flags used coordinating flushes,    * compactions and closes.    */
specifier|static
class|class
name|WriteState
block|{
comment|// Set while a memcache flush is happening.
specifier|volatile
name|boolean
name|flushing
init|=
literal|false
decl_stmt|;
comment|// Set when a flush has been requested.
specifier|volatile
name|boolean
name|flushRequested
init|=
literal|false
decl_stmt|;
comment|// Set while a compaction is running.
specifier|volatile
name|boolean
name|compacting
init|=
literal|false
decl_stmt|;
comment|// Gets set in close. If set, cannot compact or flush again.
specifier|volatile
name|boolean
name|writesEnabled
init|=
literal|true
decl_stmt|;
comment|// Set if region is read-only
specifier|private
specifier|volatile
name|boolean
name|readOnly
init|=
literal|false
decl_stmt|;
comment|/**      * Set flags that make this region read-only.      */
specifier|synchronized
name|void
name|setReadOnly
parameter_list|(
specifier|final
name|boolean
name|onOff
parameter_list|)
block|{
name|this
operator|.
name|writesEnabled
operator|=
operator|!
name|onOff
expr_stmt|;
name|this
operator|.
name|readOnly
operator|=
name|onOff
expr_stmt|;
block|}
name|boolean
name|isReadOnly
parameter_list|()
block|{
return|return
name|this
operator|.
name|readOnly
return|;
block|}
name|boolean
name|isFlushRequested
parameter_list|()
block|{
return|return
name|this
operator|.
name|flushRequested
return|;
block|}
block|}
specifier|private
specifier|volatile
name|WriteState
name|writestate
init|=
operator|new
name|WriteState
argument_list|()
decl_stmt|;
specifier|final
name|int
name|memcacheFlushSize
decl_stmt|;
specifier|private
specifier|volatile
name|long
name|lastFlushTime
decl_stmt|;
specifier|final
name|FlushRequester
name|flushListener
decl_stmt|;
specifier|private
specifier|final
name|int
name|blockingMemcacheSize
decl_stmt|;
specifier|final
name|long
name|threadWakeFrequency
decl_stmt|;
comment|// Used to guard splits and closes
specifier|private
specifier|final
name|ReentrantReadWriteLock
name|splitsAndClosesLock
init|=
operator|new
name|ReentrantReadWriteLock
argument_list|()
decl_stmt|;
comment|// Stop updates lock
specifier|private
specifier|final
name|ReentrantReadWriteLock
name|updatesLock
init|=
operator|new
name|ReentrantReadWriteLock
argument_list|()
decl_stmt|;
specifier|private
specifier|final
name|Integer
name|splitLock
init|=
operator|new
name|Integer
argument_list|(
literal|0
argument_list|)
decl_stmt|;
specifier|private
specifier|final
name|long
name|minSequenceId
decl_stmt|;
specifier|final
name|AtomicInteger
name|activeScannerCount
init|=
operator|new
name|AtomicInteger
argument_list|(
literal|0
argument_list|)
decl_stmt|;
comment|//////////////////////////////////////////////////////////////////////////////
comment|// Constructor
comment|//////////////////////////////////////////////////////////////////////////////
comment|/**    * HRegion constructor.    *    * @param basedir qualified path of directory where region should be located,    * usually the table directory.    * @param log The HLog is the outbound log for any updates to the HRegion    * (There's a single HLog for all the HRegions on a single HRegionServer.)    * The log file is a logfile from the previous execution that's    * custom-computed for this HRegion. The HRegionServer computes and sorts the    * appropriate log info for this HRegion. If there is a previous log file    * (implying that the HRegion has been written-to before), then read it from    * the supplied path.    * @param fs is the filesystem.      * @param conf is global configuration settings.    * @param regionInfo - HRegionInfo that describes the region    * @param initialFiles If there are initial files (implying that the HRegion    * is new), then read them from the supplied path.    * @param flushListener an object that implements CacheFlushListener or null    * or null    * @throws IOException    */
specifier|public
name|HRegion
parameter_list|(
name|Path
name|basedir
parameter_list|,
name|HLog
name|log
parameter_list|,
name|FileSystem
name|fs
parameter_list|,
name|HBaseConfiguration
name|conf
parameter_list|,
name|HRegionInfo
name|regionInfo
parameter_list|,
name|Path
name|initialFiles
parameter_list|,
name|FlushRequester
name|flushListener
parameter_list|)
throws|throws
name|IOException
block|{
name|this
argument_list|(
name|basedir
argument_list|,
name|log
argument_list|,
name|fs
argument_list|,
name|conf
argument_list|,
name|regionInfo
argument_list|,
name|initialFiles
argument_list|,
name|flushListener
argument_list|,
literal|null
argument_list|)
expr_stmt|;
block|}
comment|/**    * HRegion constructor.    *    * @param log The HLog is the outbound log for any updates to the HRegion    * (There's a single HLog for all the HRegions on a single HRegionServer.)    * The log file is a logfile from the previous execution that's    * custom-computed for this HRegion. The HRegionServer computes and sorts the    * appropriate log info for this HRegion. If there is a previous log file    * (implying that the HRegion has been written-to before), then read it from    * the supplied path.    * @param basedir qualified path of directory where region should be located,    * usually the table directory.    * @param fs is the filesystem.      * @param conf is global configuration settings.    * @param regionInfo - HRegionInfo that describes the region    * @param initialFiles If there are initial files (implying that the HRegion    * is new), then read them from the supplied path.    * @param flushListener an object that implements CacheFlushListener or null    * @param reporter Call on a period so hosting server can report we're    * making progress to master -- otherwise master might think region deploy    * failed.  Can be null.    * @throws IOException    */
specifier|public
name|HRegion
parameter_list|(
name|Path
name|basedir
parameter_list|,
name|HLog
name|log
parameter_list|,
name|FileSystem
name|fs
parameter_list|,
name|HBaseConfiguration
name|conf
parameter_list|,
name|HRegionInfo
name|regionInfo
parameter_list|,
name|Path
name|initialFiles
parameter_list|,
name|FlushRequester
name|flushListener
parameter_list|,
specifier|final
name|Progressable
name|reporter
parameter_list|)
throws|throws
name|IOException
block|{
name|this
operator|.
name|basedir
operator|=
name|basedir
expr_stmt|;
name|this
operator|.
name|log
operator|=
name|log
expr_stmt|;
name|this
operator|.
name|fs
operator|=
name|fs
expr_stmt|;
name|this
operator|.
name|conf
operator|=
name|conf
expr_stmt|;
name|this
operator|.
name|regionInfo
operator|=
name|regionInfo
expr_stmt|;
name|this
operator|.
name|flushListener
operator|=
name|flushListener
expr_stmt|;
name|this
operator|.
name|threadWakeFrequency
operator|=
name|conf
operator|.
name|getLong
argument_list|(
name|THREAD_WAKE_FREQUENCY
argument_list|,
literal|10
operator|*
literal|1000
argument_list|)
expr_stmt|;
name|String
name|encodedNameStr
init|=
name|Integer
operator|.
name|toString
argument_list|(
name|this
operator|.
name|regionInfo
operator|.
name|getEncodedName
argument_list|()
argument_list|)
decl_stmt|;
name|this
operator|.
name|regiondir
operator|=
operator|new
name|Path
argument_list|(
name|basedir
argument_list|,
name|encodedNameStr
argument_list|)
expr_stmt|;
name|Path
name|oldLogFile
init|=
operator|new
name|Path
argument_list|(
name|regiondir
argument_list|,
name|HREGION_OLDLOGFILE_NAME
argument_list|)
decl_stmt|;
name|this
operator|.
name|historian
operator|=
name|RegionHistorian
operator|.
name|getInstance
argument_list|()
expr_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Opening region "
operator|+
name|this
operator|+
literal|"/"
operator|+
name|this
operator|.
name|regionInfo
operator|.
name|getEncodedName
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|this
operator|.
name|regionCompactionDir
operator|=
operator|new
name|Path
argument_list|(
name|getCompactionDir
argument_list|(
name|basedir
argument_list|)
argument_list|,
name|encodedNameStr
argument_list|)
expr_stmt|;
comment|// Move prefab HStore files into place (if any).  This picks up split files
comment|// and any merges from splits and merges dirs.
if|if
condition|(
name|initialFiles
operator|!=
literal|null
operator|&&
name|fs
operator|.
name|exists
argument_list|(
name|initialFiles
argument_list|)
condition|)
block|{
name|fs
operator|.
name|rename
argument_list|(
name|initialFiles
argument_list|,
name|this
operator|.
name|regiondir
argument_list|)
expr_stmt|;
block|}
comment|// Load in all the HStores.
name|long
name|maxSeqId
init|=
operator|-
literal|1
decl_stmt|;
for|for
control|(
name|HColumnDescriptor
name|c
range|:
name|this
operator|.
name|regionInfo
operator|.
name|getTableDesc
argument_list|()
operator|.
name|getFamilies
argument_list|()
control|)
block|{
name|HStore
name|store
init|=
name|instantiateHStore
argument_list|(
name|this
operator|.
name|basedir
argument_list|,
name|c
argument_list|,
name|oldLogFile
argument_list|,
name|reporter
argument_list|)
decl_stmt|;
name|stores
operator|.
name|put
argument_list|(
name|Bytes
operator|.
name|mapKey
argument_list|(
name|c
operator|.
name|getName
argument_list|()
argument_list|)
argument_list|,
name|store
argument_list|)
expr_stmt|;
name|long
name|storeSeqId
init|=
name|store
operator|.
name|getMaxSequenceId
argument_list|()
decl_stmt|;
if|if
condition|(
name|storeSeqId
operator|>
name|maxSeqId
condition|)
block|{
name|maxSeqId
operator|=
name|storeSeqId
expr_stmt|;
block|}
block|}
name|doReconstructionLog
argument_list|(
name|oldLogFile
argument_list|,
name|maxSeqId
argument_list|,
name|reporter
argument_list|)
expr_stmt|;
if|if
condition|(
name|fs
operator|.
name|exists
argument_list|(
name|oldLogFile
argument_list|)
condition|)
block|{
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Deleting old log file: "
operator|+
name|oldLogFile
argument_list|)
expr_stmt|;
block|}
name|fs
operator|.
name|delete
argument_list|(
name|oldLogFile
argument_list|,
literal|false
argument_list|)
expr_stmt|;
block|}
comment|// Add one to the current maximum sequence id so new edits are beyond.
name|this
operator|.
name|minSequenceId
operator|=
name|maxSeqId
operator|+
literal|1
expr_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Next sequence id for region "
operator|+
name|Bytes
operator|.
name|toString
argument_list|(
name|regionInfo
operator|.
name|getRegionName
argument_list|()
argument_list|)
operator|+
literal|" is "
operator|+
name|this
operator|.
name|minSequenceId
argument_list|)
expr_stmt|;
block|}
comment|// Get rid of any splits or merges that were lost in-progress
name|Path
name|splits
init|=
operator|new
name|Path
argument_list|(
name|regiondir
argument_list|,
name|SPLITDIR
argument_list|)
decl_stmt|;
if|if
condition|(
name|fs
operator|.
name|exists
argument_list|(
name|splits
argument_list|)
condition|)
block|{
name|fs
operator|.
name|delete
argument_list|(
name|splits
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
name|Path
name|merges
init|=
operator|new
name|Path
argument_list|(
name|regiondir
argument_list|,
name|MERGEDIR
argument_list|)
decl_stmt|;
if|if
condition|(
name|fs
operator|.
name|exists
argument_list|(
name|merges
argument_list|)
condition|)
block|{
name|fs
operator|.
name|delete
argument_list|(
name|merges
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
name|int
name|flushSize
init|=
name|regionInfo
operator|.
name|getTableDesc
argument_list|()
operator|.
name|getMemcacheFlushSize
argument_list|()
decl_stmt|;
if|if
condition|(
name|flushSize
operator|==
name|HTableDescriptor
operator|.
name|DEFAULT_MEMCACHE_FLUSH_SIZE
condition|)
block|{
name|flushSize
operator|=
name|conf
operator|.
name|getInt
argument_list|(
literal|"hbase.hregion.memcache.flush.size"
argument_list|,
name|HTableDescriptor
operator|.
name|DEFAULT_MEMCACHE_FLUSH_SIZE
argument_list|)
expr_stmt|;
block|}
name|this
operator|.
name|memcacheFlushSize
operator|=
name|flushSize
expr_stmt|;
name|this
operator|.
name|blockingMemcacheSize
operator|=
name|this
operator|.
name|memcacheFlushSize
operator|*
name|conf
operator|.
name|getInt
argument_list|(
literal|"hbase.hregion.memcache.block.multiplier"
argument_list|,
literal|1
argument_list|)
expr_stmt|;
comment|// See if region is meant to run read-only.
if|if
condition|(
name|this
operator|.
name|regionInfo
operator|.
name|getTableDesc
argument_list|()
operator|.
name|isReadOnly
argument_list|()
condition|)
block|{
name|this
operator|.
name|writestate
operator|.
name|setReadOnly
argument_list|(
literal|true
argument_list|)
expr_stmt|;
block|}
comment|// HRegion is ready to go!
name|this
operator|.
name|writestate
operator|.
name|compacting
operator|=
literal|false
expr_stmt|;
name|this
operator|.
name|lastFlushTime
operator|=
name|System
operator|.
name|currentTimeMillis
argument_list|()
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"region "
operator|+
name|this
operator|+
literal|"/"
operator|+
name|this
operator|.
name|regionInfo
operator|.
name|getEncodedName
argument_list|()
operator|+
literal|" available"
argument_list|)
expr_stmt|;
block|}
comment|/**    * @return Updates to this region need to have a sequence id that is>= to    * the this number.    */
name|long
name|getMinSequenceId
parameter_list|()
block|{
return|return
name|this
operator|.
name|minSequenceId
return|;
block|}
comment|/** @return a HRegionInfo object for this region */
specifier|public
name|HRegionInfo
name|getRegionInfo
parameter_list|()
block|{
return|return
name|this
operator|.
name|regionInfo
return|;
block|}
comment|/** @return true if region is closed */
specifier|public
name|boolean
name|isClosed
parameter_list|()
block|{
return|return
name|this
operator|.
name|closed
operator|.
name|get
argument_list|()
return|;
block|}
comment|/**    * Close down this HRegion.  Flush the cache, shut down each HStore, don't     * service any more calls.    *    *<p>This method could take some time to execute, so don't call it from a     * time-sensitive thread.    *     * @return Vector of all the storage files that the HRegion's component     * HStores make use of.  It's a list of all HStoreFile objects. Returns empty    * vector if already closed and null if judged that it should not close.    *     * @throws IOException    */
specifier|public
name|List
argument_list|<
name|HStoreFile
argument_list|>
name|close
parameter_list|()
throws|throws
name|IOException
block|{
return|return
name|close
argument_list|(
literal|false
argument_list|)
return|;
block|}
comment|/**    * Close down this HRegion.  Flush the cache unless abort parameter is true,    * Shut down each HStore, don't service any more calls.    *    * This method could take some time to execute, so don't call it from a     * time-sensitive thread.    *     * @param abort true if server is aborting (only during testing)    * @return Vector of all the storage files that the HRegion's component     * HStores make use of.  It's a list of HStoreFile objects.  Can be null if    * we are not to close at this time or we are already closed.    *     * @throws IOException    */
name|List
argument_list|<
name|HStoreFile
argument_list|>
name|close
parameter_list|(
name|boolean
name|abort
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|isClosed
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"region "
operator|+
name|this
operator|+
literal|" already closed"
argument_list|)
expr_stmt|;
return|return
literal|null
return|;
block|}
synchronized|synchronized
init|(
name|splitLock
init|)
block|{
synchronized|synchronized
init|(
name|writestate
init|)
block|{
comment|// Disable compacting and flushing by background threads for this
comment|// region.
name|writestate
operator|.
name|writesEnabled
operator|=
literal|false
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Compactions and cache flushes disabled for region "
operator|+
name|this
argument_list|)
expr_stmt|;
while|while
condition|(
name|writestate
operator|.
name|compacting
operator|||
name|writestate
operator|.
name|flushing
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"waiting for"
operator|+
operator|(
name|writestate
operator|.
name|compacting
condition|?
literal|" compaction"
else|:
literal|""
operator|)
operator|+
operator|(
name|writestate
operator|.
name|flushing
condition|?
operator|(
name|writestate
operator|.
name|compacting
condition|?
literal|","
else|:
literal|""
operator|)
operator|+
literal|" cache flush"
else|:
literal|""
operator|)
operator|+
literal|" to complete for region "
operator|+
name|this
argument_list|)
expr_stmt|;
try|try
block|{
name|writestate
operator|.
name|wait
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|iex
parameter_list|)
block|{
comment|// continue
block|}
block|}
block|}
name|splitsAndClosesLock
operator|.
name|writeLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Updates and scanners disabled for region "
operator|+
name|this
argument_list|)
expr_stmt|;
try|try
block|{
comment|// Wait for active scanners to finish. The write lock we hold will
comment|// prevent new scanners from being created.
synchronized|synchronized
init|(
name|activeScannerCount
init|)
block|{
while|while
condition|(
name|activeScannerCount
operator|.
name|get
argument_list|()
operator|!=
literal|0
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"waiting for "
operator|+
name|activeScannerCount
operator|.
name|get
argument_list|()
operator|+
literal|" scanners to finish"
argument_list|)
expr_stmt|;
try|try
block|{
name|activeScannerCount
operator|.
name|wait
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
comment|// continue
block|}
block|}
block|}
name|LOG
operator|.
name|debug
argument_list|(
literal|"No more active scanners for region "
operator|+
name|this
argument_list|)
expr_stmt|;
comment|// Write lock means no more row locks can be given out.  Wait on
comment|// outstanding row locks to come in before we close so we do not drop
comment|// outstanding updates.
name|waitOnRowLocks
argument_list|()
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"No more row locks outstanding on region "
operator|+
name|this
argument_list|)
expr_stmt|;
comment|// Don't flush the cache if we are aborting
if|if
condition|(
operator|!
name|abort
condition|)
block|{
name|internalFlushcache
argument_list|()
expr_stmt|;
block|}
name|List
argument_list|<
name|HStoreFile
argument_list|>
name|result
init|=
operator|new
name|ArrayList
argument_list|<
name|HStoreFile
argument_list|>
argument_list|()
decl_stmt|;
for|for
control|(
name|HStore
name|store
range|:
name|stores
operator|.
name|values
argument_list|()
control|)
block|{
name|result
operator|.
name|addAll
argument_list|(
name|store
operator|.
name|close
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|this
operator|.
name|closed
operator|.
name|set
argument_list|(
literal|true
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"closed "
operator|+
name|this
argument_list|)
expr_stmt|;
return|return
name|result
return|;
block|}
finally|finally
block|{
name|splitsAndClosesLock
operator|.
name|writeLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
block|}
comment|//////////////////////////////////////////////////////////////////////////////
comment|// HRegion accessors
comment|//////////////////////////////////////////////////////////////////////////////
comment|/** @return start key for region */
specifier|public
name|byte
index|[]
name|getStartKey
parameter_list|()
block|{
return|return
name|this
operator|.
name|regionInfo
operator|.
name|getStartKey
argument_list|()
return|;
block|}
comment|/** @return end key for region */
specifier|public
name|byte
index|[]
name|getEndKey
parameter_list|()
block|{
return|return
name|this
operator|.
name|regionInfo
operator|.
name|getEndKey
argument_list|()
return|;
block|}
comment|/** @return region id */
specifier|public
name|long
name|getRegionId
parameter_list|()
block|{
return|return
name|this
operator|.
name|regionInfo
operator|.
name|getRegionId
argument_list|()
return|;
block|}
comment|/** @return region name */
specifier|public
name|byte
index|[]
name|getRegionName
parameter_list|()
block|{
return|return
name|this
operator|.
name|regionInfo
operator|.
name|getRegionName
argument_list|()
return|;
block|}
comment|/** @return HTableDescriptor for this region */
specifier|public
name|HTableDescriptor
name|getTableDesc
parameter_list|()
block|{
return|return
name|this
operator|.
name|regionInfo
operator|.
name|getTableDesc
argument_list|()
return|;
block|}
comment|/** @return HLog in use for this region */
specifier|public
name|HLog
name|getLog
parameter_list|()
block|{
return|return
name|this
operator|.
name|log
return|;
block|}
comment|/** @return Configuration object */
specifier|public
name|HBaseConfiguration
name|getConf
parameter_list|()
block|{
return|return
name|this
operator|.
name|conf
return|;
block|}
comment|/** @return region directory Path */
specifier|public
name|Path
name|getRegionDir
parameter_list|()
block|{
return|return
name|this
operator|.
name|regiondir
return|;
block|}
comment|/** @return FileSystem being used by this region */
specifier|public
name|FileSystem
name|getFilesystem
parameter_list|()
block|{
return|return
name|this
operator|.
name|fs
return|;
block|}
comment|/** @return the last time the region was flushed */
specifier|public
name|long
name|getLastFlushTime
parameter_list|()
block|{
return|return
name|this
operator|.
name|lastFlushTime
return|;
block|}
comment|//////////////////////////////////////////////////////////////////////////////
comment|// HRegion maintenance.
comment|//
comment|// These methods are meant to be called periodically by the HRegionServer for
comment|// upkeep.
comment|//////////////////////////////////////////////////////////////////////////////
comment|/** @return returns size of largest HStore. */
specifier|public
name|long
name|getLargestHStoreSize
parameter_list|()
block|{
name|long
name|size
init|=
literal|0
decl_stmt|;
for|for
control|(
name|HStore
name|h
range|:
name|stores
operator|.
name|values
argument_list|()
control|)
block|{
name|long
name|storeSize
init|=
name|h
operator|.
name|getSize
argument_list|()
decl_stmt|;
if|if
condition|(
name|storeSize
operator|>
name|size
condition|)
block|{
name|size
operator|=
name|storeSize
expr_stmt|;
block|}
block|}
return|return
name|size
return|;
block|}
comment|/*    * Split the HRegion to create two brand-new ones.  This also closes    * current HRegion.  Split should be fast since we don't rewrite store files    * but instead create new 'reference' store files that read off the top and    * bottom ranges of parent store files.    * @param midKey key on which to split region    * @return two brand-new (and open) HRegions or null if a split is not needed    * @throws IOException    */
name|HRegion
index|[]
name|splitRegion
parameter_list|(
specifier|final
name|byte
index|[]
name|midKey
parameter_list|)
throws|throws
name|IOException
block|{
synchronized|synchronized
init|(
name|splitLock
init|)
block|{
if|if
condition|(
name|closed
operator|.
name|get
argument_list|()
condition|)
block|{
return|return
literal|null
return|;
block|}
comment|// Add start/end key checking: hbase-428.
name|byte
index|[]
name|startKey
init|=
name|this
operator|.
name|regionInfo
operator|.
name|getStartKey
argument_list|()
decl_stmt|;
name|byte
index|[]
name|endKey
init|=
name|this
operator|.
name|regionInfo
operator|.
name|getEndKey
argument_list|()
decl_stmt|;
if|if
condition|(
name|Bytes
operator|.
name|equals
argument_list|(
name|startKey
argument_list|,
name|midKey
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Startkey ("
operator|+
name|startKey
operator|+
literal|") and midkey + ("
operator|+
name|midKey
operator|+
literal|") are same, not splitting"
argument_list|)
expr_stmt|;
return|return
literal|null
return|;
block|}
if|if
condition|(
name|Bytes
operator|.
name|equals
argument_list|(
name|midKey
argument_list|,
name|endKey
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Endkey and midkey are same, not splitting"
argument_list|)
expr_stmt|;
return|return
literal|null
return|;
block|}
name|LOG
operator|.
name|info
argument_list|(
literal|"Starting split of region "
operator|+
name|this
argument_list|)
expr_stmt|;
name|Path
name|splits
init|=
operator|new
name|Path
argument_list|(
name|this
operator|.
name|regiondir
argument_list|,
name|SPLITDIR
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|this
operator|.
name|fs
operator|.
name|exists
argument_list|(
name|splits
argument_list|)
condition|)
block|{
name|this
operator|.
name|fs
operator|.
name|mkdirs
argument_list|(
name|splits
argument_list|)
expr_stmt|;
block|}
comment|// Calculate regionid to use.  Can't be less than that of parent else
comment|// it'll insert into wrong location over in .META. table: HBASE-710.
name|long
name|rid
init|=
name|System
operator|.
name|currentTimeMillis
argument_list|()
decl_stmt|;
if|if
condition|(
name|rid
operator|<
name|this
operator|.
name|regionInfo
operator|.
name|getRegionId
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Clock skew; parent regions id is "
operator|+
name|this
operator|.
name|regionInfo
operator|.
name|getRegionId
argument_list|()
operator|+
literal|" but current time here is "
operator|+
name|rid
argument_list|)
expr_stmt|;
name|rid
operator|=
name|this
operator|.
name|regionInfo
operator|.
name|getRegionId
argument_list|()
operator|+
literal|1
expr_stmt|;
block|}
name|HRegionInfo
name|regionAInfo
init|=
operator|new
name|HRegionInfo
argument_list|(
name|this
operator|.
name|regionInfo
operator|.
name|getTableDesc
argument_list|()
argument_list|,
name|startKey
argument_list|,
name|midKey
argument_list|,
literal|false
argument_list|,
name|rid
argument_list|)
decl_stmt|;
name|Path
name|dirA
init|=
operator|new
name|Path
argument_list|(
name|splits
argument_list|,
name|Integer
operator|.
name|toString
argument_list|(
name|regionAInfo
operator|.
name|getEncodedName
argument_list|()
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|fs
operator|.
name|exists
argument_list|(
name|dirA
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Cannot split; target file collision at "
operator|+
name|dirA
argument_list|)
throw|;
block|}
name|HRegionInfo
name|regionBInfo
init|=
operator|new
name|HRegionInfo
argument_list|(
name|this
operator|.
name|regionInfo
operator|.
name|getTableDesc
argument_list|()
argument_list|,
name|midKey
argument_list|,
name|endKey
argument_list|,
literal|false
argument_list|,
name|rid
argument_list|)
decl_stmt|;
name|Path
name|dirB
init|=
operator|new
name|Path
argument_list|(
name|splits
argument_list|,
name|Integer
operator|.
name|toString
argument_list|(
name|regionBInfo
operator|.
name|getEncodedName
argument_list|()
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|this
operator|.
name|fs
operator|.
name|exists
argument_list|(
name|dirB
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Cannot split; target file collision at "
operator|+
name|dirB
argument_list|)
throw|;
block|}
comment|// Now close the HRegion.  Close returns all store files or null if not
comment|// supposed to close (? What to do in this case? Implement abort of close?)
comment|// Close also does wait on outstanding rows and calls a flush just-in-case.
name|List
argument_list|<
name|HStoreFile
argument_list|>
name|hstoreFilesToSplit
init|=
name|close
argument_list|(
literal|false
argument_list|)
decl_stmt|;
if|if
condition|(
name|hstoreFilesToSplit
operator|==
literal|null
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Close came back null (Implement abort of close?)"
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"close returned empty vector of HStoreFiles"
argument_list|)
throw|;
block|}
comment|// Split each store file.
for|for
control|(
name|HStoreFile
name|h
range|:
name|hstoreFilesToSplit
control|)
block|{
comment|// A reference to the bottom half of the hsf store file.
name|HStoreFile
operator|.
name|Reference
name|aReference
init|=
operator|new
name|HStoreFile
operator|.
name|Reference
argument_list|(
name|this
operator|.
name|regionInfo
operator|.
name|getEncodedName
argument_list|()
argument_list|,
name|h
operator|.
name|getFileId
argument_list|()
argument_list|,
operator|new
name|HStoreKey
argument_list|(
name|midKey
argument_list|)
argument_list|,
name|HStoreFile
operator|.
name|Range
operator|.
name|bottom
argument_list|)
decl_stmt|;
name|HStoreFile
name|a
init|=
operator|new
name|HStoreFile
argument_list|(
name|this
operator|.
name|conf
argument_list|,
name|fs
argument_list|,
name|splits
argument_list|,
name|regionAInfo
operator|.
name|getEncodedName
argument_list|()
argument_list|,
name|h
operator|.
name|getColFamily
argument_list|()
argument_list|,
operator|-
literal|1
argument_list|,
name|aReference
argument_list|)
decl_stmt|;
comment|// Reference to top half of the hsf store file.
name|HStoreFile
operator|.
name|Reference
name|bReference
init|=
operator|new
name|HStoreFile
operator|.
name|Reference
argument_list|(
name|this
operator|.
name|regionInfo
operator|.
name|getEncodedName
argument_list|()
argument_list|,
name|h
operator|.
name|getFileId
argument_list|()
argument_list|,
operator|new
name|HStoreKey
argument_list|(
name|midKey
argument_list|)
argument_list|,
name|HStoreFile
operator|.
name|Range
operator|.
name|top
argument_list|)
decl_stmt|;
name|HStoreFile
name|b
init|=
operator|new
name|HStoreFile
argument_list|(
name|this
operator|.
name|conf
argument_list|,
name|fs
argument_list|,
name|splits
argument_list|,
name|regionBInfo
operator|.
name|getEncodedName
argument_list|()
argument_list|,
name|h
operator|.
name|getColFamily
argument_list|()
argument_list|,
operator|-
literal|1
argument_list|,
name|bReference
argument_list|)
decl_stmt|;
name|h
operator|.
name|splitStoreFile
argument_list|(
name|a
argument_list|,
name|b
argument_list|,
name|this
operator|.
name|fs
argument_list|)
expr_stmt|;
block|}
comment|// Done!
comment|// Opening the region copies the splits files from the splits directory
comment|// under each region.
name|HRegion
name|regionA
init|=
operator|new
name|HRegion
argument_list|(
name|basedir
argument_list|,
name|log
argument_list|,
name|fs
argument_list|,
name|conf
argument_list|,
name|regionAInfo
argument_list|,
name|dirA
argument_list|,
literal|null
argument_list|)
decl_stmt|;
name|regionA
operator|.
name|close
argument_list|()
expr_stmt|;
name|HRegion
name|regionB
init|=
operator|new
name|HRegion
argument_list|(
name|basedir
argument_list|,
name|log
argument_list|,
name|fs
argument_list|,
name|conf
argument_list|,
name|regionBInfo
argument_list|,
name|dirB
argument_list|,
literal|null
argument_list|)
decl_stmt|;
name|regionB
operator|.
name|close
argument_list|()
expr_stmt|;
comment|// Cleanup
name|boolean
name|deleted
init|=
name|fs
operator|.
name|delete
argument_list|(
name|splits
argument_list|,
literal|true
argument_list|)
decl_stmt|;
comment|// Get rid of splits directory
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Cleaned up "
operator|+
name|FSUtils
operator|.
name|getPath
argument_list|(
name|splits
argument_list|)
operator|+
literal|" "
operator|+
name|deleted
argument_list|)
expr_stmt|;
block|}
name|HRegion
name|regions
index|[]
init|=
operator|new
name|HRegion
index|[]
block|{
name|regionA
block|,
name|regionB
block|}
decl_stmt|;
name|this
operator|.
name|historian
operator|.
name|addRegionSplit
argument_list|(
name|this
operator|.
name|regionInfo
argument_list|,
name|regionA
operator|.
name|getRegionInfo
argument_list|()
argument_list|,
name|regionB
operator|.
name|getRegionInfo
argument_list|()
argument_list|)
expr_stmt|;
return|return
name|regions
return|;
block|}
block|}
comment|/*    * @param dir    * @return compaction directory for the passed in<code>dir</code>    */
specifier|static
name|Path
name|getCompactionDir
parameter_list|(
specifier|final
name|Path
name|dir
parameter_list|)
block|{
return|return
operator|new
name|Path
argument_list|(
name|dir
argument_list|,
literal|"compaction.dir"
argument_list|)
return|;
block|}
comment|/*    * Do preparation for pending compaction.    * Clean out any vestiges of previous failed compactions.    * @throws IOException    */
specifier|private
name|void
name|doRegionCompactionPrep
parameter_list|()
throws|throws
name|IOException
block|{
name|doRegionCompactionCleanup
argument_list|()
expr_stmt|;
block|}
comment|/*    * Removes the compaction directory for this Store.    * @throws IOException    */
specifier|private
name|void
name|doRegionCompactionCleanup
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|this
operator|.
name|fs
operator|.
name|exists
argument_list|(
name|this
operator|.
name|regionCompactionDir
argument_list|)
condition|)
block|{
name|this
operator|.
name|fs
operator|.
name|delete
argument_list|(
name|this
operator|.
name|regionCompactionDir
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Called by compaction thread and after region is opened to compact the    * HStores if necessary.    *    *<p>This operation could block for a long time, so don't call it from a     * time-sensitive thread.    *    * Note that no locking is necessary at this level because compaction only    * conflicts with a region split, and that cannot happen because the region    * server does them sequentially and not in parallel.    *     * @return mid key if split is needed    * @throws IOException    */
specifier|public
name|byte
index|[]
name|compactStores
parameter_list|()
throws|throws
name|IOException
block|{
return|return
name|compactStores
argument_list|(
literal|false
argument_list|)
return|;
block|}
comment|/**    * Called by compaction thread and after region is opened to compact the    * HStores if necessary.    *    *<p>This operation could block for a long time, so don't call it from a     * time-sensitive thread.    *    * Note that no locking is necessary at this level because compaction only    * conflicts with a region split, and that cannot happen because the region    * server does them sequentially and not in parallel.    *     * @param force True to force a compaction regardless of thresholds (Needed    * by merge).    * @return mid key if split is needed    * @throws IOException    */
specifier|private
name|byte
index|[]
name|compactStores
parameter_list|(
specifier|final
name|boolean
name|force
parameter_list|)
throws|throws
name|IOException
block|{
name|byte
index|[]
name|midKey
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|this
operator|.
name|closed
operator|.
name|get
argument_list|()
condition|)
block|{
return|return
name|midKey
return|;
block|}
try|try
block|{
synchronized|synchronized
init|(
name|writestate
init|)
block|{
if|if
condition|(
operator|!
name|writestate
operator|.
name|compacting
operator|&&
name|writestate
operator|.
name|writesEnabled
condition|)
block|{
name|writestate
operator|.
name|compacting
operator|=
literal|true
expr_stmt|;
block|}
else|else
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"NOT compacting region "
operator|+
name|this
operator|+
literal|": compacting="
operator|+
name|writestate
operator|.
name|compacting
operator|+
literal|", writesEnabled="
operator|+
name|writestate
operator|.
name|writesEnabled
argument_list|)
expr_stmt|;
return|return
name|midKey
return|;
block|}
block|}
name|LOG
operator|.
name|info
argument_list|(
literal|"starting compaction on region "
operator|+
name|this
argument_list|)
expr_stmt|;
name|long
name|startTime
init|=
name|System
operator|.
name|currentTimeMillis
argument_list|()
decl_stmt|;
name|doRegionCompactionPrep
argument_list|()
expr_stmt|;
name|long
name|maxSize
init|=
operator|-
literal|1
decl_stmt|;
for|for
control|(
name|HStore
name|store
range|:
name|stores
operator|.
name|values
argument_list|()
control|)
block|{
specifier|final
name|HStore
operator|.
name|StoreSize
name|size
init|=
name|store
operator|.
name|compact
argument_list|(
name|force
argument_list|)
decl_stmt|;
if|if
condition|(
name|size
operator|!=
literal|null
operator|&&
name|size
operator|.
name|getSize
argument_list|()
operator|>
name|maxSize
condition|)
block|{
name|maxSize
operator|=
name|size
operator|.
name|getSize
argument_list|()
expr_stmt|;
name|midKey
operator|=
name|size
operator|.
name|getKey
argument_list|()
expr_stmt|;
block|}
block|}
name|doRegionCompactionCleanup
argument_list|()
expr_stmt|;
name|String
name|timeTaken
init|=
name|StringUtils
operator|.
name|formatTimeDiff
argument_list|(
name|System
operator|.
name|currentTimeMillis
argument_list|()
argument_list|,
name|startTime
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"compaction completed on region "
operator|+
name|this
operator|+
literal|" in "
operator|+
name|timeTaken
argument_list|)
expr_stmt|;
name|this
operator|.
name|historian
operator|.
name|addRegionCompaction
argument_list|(
name|regionInfo
argument_list|,
name|timeTaken
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
synchronized|synchronized
init|(
name|writestate
init|)
block|{
name|writestate
operator|.
name|compacting
operator|=
literal|false
expr_stmt|;
name|writestate
operator|.
name|notifyAll
argument_list|()
expr_stmt|;
block|}
block|}
return|return
name|midKey
return|;
block|}
comment|/**    * Flush the cache.    *     * When this method is called the cache will be flushed unless:    *<ol>    *<li>the cache is empty</li>    *<li>the region is closed.</li>    *<li>a flush is already in progress</li>    *<li>writes are disabled</li>    *</ol>    *    *<p>This method may block for some time, so it should not be called from a     * time-sensitive thread.    *     * @return true if cache was flushed    *     * @throws IOException    * @throws DroppedSnapshotException Thrown when replay of hlog is required    * because a Snapshot was not properly persisted.    */
specifier|public
name|boolean
name|flushcache
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|this
operator|.
name|closed
operator|.
name|get
argument_list|()
condition|)
block|{
return|return
literal|false
return|;
block|}
synchronized|synchronized
init|(
name|writestate
init|)
block|{
if|if
condition|(
operator|!
name|writestate
operator|.
name|flushing
operator|&&
name|writestate
operator|.
name|writesEnabled
condition|)
block|{
name|this
operator|.
name|writestate
operator|.
name|flushing
operator|=
literal|true
expr_stmt|;
block|}
else|else
block|{
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"NOT flushing memcache for region "
operator|+
name|this
operator|+
literal|", flushing="
operator|+
name|writestate
operator|.
name|flushing
operator|+
literal|", writesEnabled="
operator|+
name|writestate
operator|.
name|writesEnabled
argument_list|)
expr_stmt|;
block|}
return|return
literal|false
return|;
block|}
block|}
try|try
block|{
comment|// Prevent splits and closes
name|splitsAndClosesLock
operator|.
name|readLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
return|return
name|internalFlushcache
argument_list|()
return|;
block|}
finally|finally
block|{
name|splitsAndClosesLock
operator|.
name|readLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
finally|finally
block|{
synchronized|synchronized
init|(
name|writestate
init|)
block|{
name|writestate
operator|.
name|flushing
operator|=
literal|false
expr_stmt|;
name|this
operator|.
name|writestate
operator|.
name|flushRequested
operator|=
literal|false
expr_stmt|;
name|writestate
operator|.
name|notifyAll
argument_list|()
expr_stmt|;
block|}
block|}
block|}
comment|/**    * Flushing the cache is a little tricky. We have a lot of updates in the    * HMemcache, all of which have also been written to the log. We need to    * write those updates in the HMemcache out to disk, while being able to    * process reads/writes as much as possible during the flush operation. Also,    * the log has to state clearly the point in time at which the HMemcache was    * flushed. (That way, during recovery, we know when we can rely on the    * on-disk flushed structures and when we have to recover the HMemcache from    * the log.)    *     *<p>So, we have a three-step process:    *     *<ul><li>A. Flush the memcache to the on-disk stores, noting the current    * sequence ID for the log.<li>    *     *<li>B. Write a FLUSHCACHE-COMPLETE message to the log, using the sequence    * ID that was current at the time of memcache-flush.</li>    *     *<li>C. Get rid of the memcache structures that are now redundant, as    * they've been flushed to the on-disk HStores.</li>    *</ul>    *<p>This method is protected, but can be accessed via several public    * routes.    *     *<p> This method may block for some time.    *     * @return true if the region needs compacting    *     * @throws IOException    * @throws DroppedSnapshotException Thrown when replay of hlog is required    * because a Snapshot was not properly persisted.    */
specifier|private
name|boolean
name|internalFlushcache
parameter_list|()
throws|throws
name|IOException
block|{
specifier|final
name|long
name|startTime
init|=
name|System
operator|.
name|currentTimeMillis
argument_list|()
decl_stmt|;
comment|// Clear flush flag.
comment|// Record latest flush time
name|this
operator|.
name|lastFlushTime
operator|=
name|startTime
expr_stmt|;
comment|// If nothing to flush, return and avoid logging start/stop flush.
if|if
condition|(
name|this
operator|.
name|memcacheSize
operator|.
name|get
argument_list|()
operator|<=
literal|0
condition|)
block|{
return|return
literal|false
return|;
block|}
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Started memcache flush for region "
operator|+
name|this
operator|+
literal|". Current region memcache size "
operator|+
name|StringUtils
operator|.
name|humanReadableInt
argument_list|(
name|this
operator|.
name|memcacheSize
operator|.
name|get
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|// Stop updates while we snapshot the memcache of all stores. We only have
comment|// to do this for a moment.  Its quick.  The subsequent sequence id that
comment|// goes into the HLog after we've flushed all these snapshots also goes
comment|// into the info file that sits beside the flushed files.
comment|// We also set the memcache size to zero here before we allow updates
comment|// again so its value will represent the size of the updates received
comment|// during the flush
name|long
name|sequenceId
init|=
operator|-
literal|1L
decl_stmt|;
name|this
operator|.
name|updatesLock
operator|.
name|writeLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
for|for
control|(
name|HStore
name|s
range|:
name|stores
operator|.
name|values
argument_list|()
control|)
block|{
name|s
operator|.
name|snapshot
argument_list|()
expr_stmt|;
block|}
name|sequenceId
operator|=
name|log
operator|.
name|startCacheFlush
argument_list|()
expr_stmt|;
name|this
operator|.
name|memcacheSize
operator|.
name|set
argument_list|(
literal|0
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|this
operator|.
name|updatesLock
operator|.
name|writeLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
comment|// Any failure from here on out will be catastrophic requiring server
comment|// restart so hlog content can be replayed and put back into the memcache.
comment|// Otherwise, the snapshot content while backed up in the hlog, it will not
comment|// be part of the current running servers state.
name|boolean
name|compactionRequested
init|=
literal|false
decl_stmt|;
try|try
block|{
comment|// A.  Flush memcache to all the HStores.
comment|// Keep running vector of all store files that includes both old and the
comment|// just-made new flush store file.
for|for
control|(
name|HStore
name|hstore
range|:
name|stores
operator|.
name|values
argument_list|()
control|)
block|{
name|boolean
name|needsCompaction
init|=
name|hstore
operator|.
name|flushCache
argument_list|(
name|sequenceId
argument_list|)
decl_stmt|;
if|if
condition|(
name|needsCompaction
condition|)
block|{
name|compactionRequested
operator|=
literal|true
expr_stmt|;
block|}
block|}
block|}
catch|catch
parameter_list|(
name|Throwable
name|t
parameter_list|)
block|{
comment|// An exception here means that the snapshot was not persisted.
comment|// The hlog needs to be replayed so its content is restored to memcache.
comment|// Currently, only a server restart will do this.
comment|// We used to only catch IOEs but its possible that we'd get other
comment|// exceptions -- e.g. HBASE-659 was about an NPE -- so now we catch
comment|// all and sundry.
name|this
operator|.
name|log
operator|.
name|abortCacheFlush
argument_list|()
expr_stmt|;
name|DroppedSnapshotException
name|dse
init|=
operator|new
name|DroppedSnapshotException
argument_list|(
literal|"region: "
operator|+
name|Bytes
operator|.
name|toString
argument_list|(
name|getRegionName
argument_list|()
argument_list|)
argument_list|)
decl_stmt|;
name|dse
operator|.
name|initCause
argument_list|(
name|t
argument_list|)
expr_stmt|;
throw|throw
name|dse
throw|;
block|}
comment|// If we get to here, the HStores have been written. If we get an
comment|// error in completeCacheFlush it will release the lock it is holding
comment|// B.  Write a FLUSHCACHE-COMPLETE message to the log.
comment|//     This tells future readers that the HStores were emitted correctly,
comment|//     and that all updates to the log for this regionName that have lower
comment|//     log-sequence-ids can be safely ignored.
name|this
operator|.
name|log
operator|.
name|completeCacheFlush
argument_list|(
name|getRegionName
argument_list|()
argument_list|,
name|regionInfo
operator|.
name|getTableDesc
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|,
name|sequenceId
argument_list|)
expr_stmt|;
comment|// C. Finally notify anyone waiting on memcache to clear:
comment|// e.g. checkResources().
synchronized|synchronized
init|(
name|this
init|)
block|{
name|notifyAll
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|String
name|timeTaken
init|=
name|StringUtils
operator|.
name|formatTimeDiff
argument_list|(
name|System
operator|.
name|currentTimeMillis
argument_list|()
argument_list|,
name|startTime
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Finished memcache flush for region "
operator|+
name|this
operator|+
literal|" in "
operator|+
operator|(
name|System
operator|.
name|currentTimeMillis
argument_list|()
operator|-
name|startTime
operator|)
operator|+
literal|"ms, sequence id="
operator|+
name|sequenceId
operator|+
literal|", compaction requested="
operator|+
name|compactionRequested
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|regionInfo
operator|.
name|isMetaRegion
argument_list|()
condition|)
block|{
name|this
operator|.
name|historian
operator|.
name|addRegionFlush
argument_list|(
name|regionInfo
argument_list|,
name|timeTaken
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|compactionRequested
return|;
block|}
comment|//////////////////////////////////////////////////////////////////////////////
comment|// get() methods for client use.
comment|//////////////////////////////////////////////////////////////////////////////
comment|/**    * Fetch a single data item.    * @param row    * @param column    * @return column value    * @throws IOException    */
specifier|public
name|Cell
name|get
parameter_list|(
name|byte
index|[]
name|row
parameter_list|,
name|byte
index|[]
name|column
parameter_list|)
throws|throws
name|IOException
block|{
name|Cell
index|[]
name|results
init|=
name|get
argument_list|(
name|row
argument_list|,
name|column
argument_list|,
name|Long
operator|.
name|MAX_VALUE
argument_list|,
literal|1
argument_list|)
decl_stmt|;
return|return
operator|(
name|results
operator|==
literal|null
operator|||
name|results
operator|.
name|length
operator|==
literal|0
operator|)
condition|?
literal|null
else|:
name|results
index|[
literal|0
index|]
return|;
block|}
comment|/**    * Fetch multiple versions of a single data item    *     * @param row    * @param column    * @param numVersions    * @return array of values one element per version    * @throws IOException    */
specifier|public
name|Cell
index|[]
name|get
parameter_list|(
name|byte
index|[]
name|row
parameter_list|,
name|byte
index|[]
name|column
parameter_list|,
name|int
name|numVersions
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|get
argument_list|(
name|row
argument_list|,
name|column
argument_list|,
name|Long
operator|.
name|MAX_VALUE
argument_list|,
name|numVersions
argument_list|)
return|;
block|}
comment|/**    * Fetch multiple versions of a single data item, with timestamp.    *    * @param row    * @param column    * @param timestamp    * @param numVersions    * @return array of values one element per version that matches the timestamp    * @throws IOException    */
specifier|public
name|Cell
index|[]
name|get
parameter_list|(
name|byte
index|[]
name|row
parameter_list|,
name|byte
index|[]
name|column
parameter_list|,
name|long
name|timestamp
parameter_list|,
name|int
name|numVersions
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|this
operator|.
name|closed
operator|.
name|get
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Region "
operator|+
name|this
operator|+
literal|" closed"
argument_list|)
throw|;
block|}
comment|// Make sure this is a valid row and valid column
name|checkRow
argument_list|(
name|row
argument_list|)
expr_stmt|;
name|checkColumn
argument_list|(
name|column
argument_list|)
expr_stmt|;
comment|// Don't need a row lock for a simple get
name|HStoreKey
name|key
init|=
operator|new
name|HStoreKey
argument_list|(
name|row
argument_list|,
name|column
argument_list|,
name|timestamp
argument_list|)
decl_stmt|;
return|return
name|getStore
argument_list|(
name|column
argument_list|)
operator|.
name|get
argument_list|(
name|key
argument_list|,
name|numVersions
argument_list|)
return|;
block|}
comment|/**    * Fetch all the columns for the indicated row at a specified timestamp.    * Returns a TreeMap that maps column names to values.    *    * We should eventually use Bloom filters here, to reduce running time.  If     * the database has many column families and is very sparse, then we could be     * checking many files needlessly.  A small Bloom for each row would help us     * determine which column groups are useful for that row.  That would let us     * avoid a bunch of disk activity.    *    * @param row    * @param columns Array of columns you'd like to retrieve. When null, get all.    * @param ts    * @return Map<columnName, Cell> values    * @throws IOException    */
specifier|public
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|Cell
argument_list|>
name|getFull
parameter_list|(
specifier|final
name|byte
index|[]
name|row
parameter_list|,
specifier|final
name|Set
argument_list|<
name|byte
index|[]
argument_list|>
name|columns
parameter_list|,
specifier|final
name|long
name|ts
parameter_list|)
throws|throws
name|IOException
block|{
comment|// Check columns passed
if|if
condition|(
name|columns
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|byte
index|[]
name|column
range|:
name|columns
control|)
block|{
name|checkColumn
argument_list|(
name|column
argument_list|)
expr_stmt|;
block|}
block|}
name|HStoreKey
name|key
init|=
operator|new
name|HStoreKey
argument_list|(
name|row
argument_list|,
name|ts
argument_list|)
decl_stmt|;
name|Integer
name|lid
init|=
name|obtainRowLock
argument_list|(
name|row
argument_list|)
decl_stmt|;
name|HashSet
argument_list|<
name|HStore
argument_list|>
name|storeSet
init|=
operator|new
name|HashSet
argument_list|<
name|HStore
argument_list|>
argument_list|()
decl_stmt|;
try|try
block|{
name|TreeMap
argument_list|<
name|byte
index|[]
argument_list|,
name|Cell
argument_list|>
name|result
init|=
operator|new
name|TreeMap
argument_list|<
name|byte
index|[]
argument_list|,
name|Cell
argument_list|>
argument_list|(
name|Bytes
operator|.
name|BYTES_COMPARATOR
argument_list|)
decl_stmt|;
comment|// Get the concerned columns or all of them
if|if
condition|(
name|columns
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|byte
index|[]
name|bs
range|:
name|columns
control|)
block|{
name|HStore
name|store
init|=
name|stores
operator|.
name|get
argument_list|(
name|Bytes
operator|.
name|mapKey
argument_list|(
name|HStoreKey
operator|.
name|getFamily
argument_list|(
name|bs
argument_list|)
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|store
operator|!=
literal|null
condition|)
block|{
name|storeSet
operator|.
name|add
argument_list|(
name|store
argument_list|)
expr_stmt|;
block|}
block|}
block|}
else|else
block|{
name|storeSet
operator|.
name|addAll
argument_list|(
name|stores
operator|.
name|values
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|// For each column name that is just a column family, open the store
comment|// related to it and fetch everything for that row. HBASE-631
comment|// Also remove each store from storeSet so that these stores
comment|// won't be opened for no reason. HBASE-783
if|if
condition|(
name|columns
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|byte
index|[]
name|bs
range|:
name|columns
control|)
block|{
if|if
condition|(
name|HStoreKey
operator|.
name|getFamilyDelimiterIndex
argument_list|(
name|bs
argument_list|)
operator|==
operator|(
name|bs
operator|.
name|length
operator|-
literal|1
operator|)
condition|)
block|{
name|HStore
name|store
init|=
name|stores
operator|.
name|get
argument_list|(
name|Bytes
operator|.
name|mapKey
argument_list|(
name|HStoreKey
operator|.
name|getFamily
argument_list|(
name|bs
argument_list|)
argument_list|)
argument_list|)
decl_stmt|;
name|store
operator|.
name|getFull
argument_list|(
name|key
argument_list|,
literal|null
argument_list|,
name|result
argument_list|)
expr_stmt|;
name|storeSet
operator|.
name|remove
argument_list|(
name|store
argument_list|)
expr_stmt|;
block|}
block|}
block|}
for|for
control|(
name|HStore
name|targetStore
range|:
name|storeSet
control|)
block|{
name|targetStore
operator|.
name|getFull
argument_list|(
name|key
argument_list|,
name|columns
argument_list|,
name|result
argument_list|)
expr_stmt|;
block|}
return|return
name|result
return|;
block|}
finally|finally
block|{
name|releaseRowLock
argument_list|(
name|lid
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Return all the data for the row that matches<i>row</i> exactly,     * or the one that immediately preceeds it, at or immediately before     *<i>ts</i>.    *     * @param row row key    * @return map of values    * @throws IOException    */
specifier|public
name|RowResult
name|getClosestRowBefore
parameter_list|(
specifier|final
name|byte
index|[]
name|row
parameter_list|)
throws|throws
name|IOException
block|{
comment|// look across all the HStores for this region and determine what the
comment|// closest key is across all column families, since the data may be sparse
name|HStoreKey
name|key
init|=
literal|null
decl_stmt|;
name|checkRow
argument_list|(
name|row
argument_list|)
expr_stmt|;
name|splitsAndClosesLock
operator|.
name|readLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
comment|// examine each column family for the preceeding or matching key
for|for
control|(
name|HStore
name|store
range|:
name|stores
operator|.
name|values
argument_list|()
control|)
block|{
comment|// get the closest key
name|byte
index|[]
name|closestKey
init|=
name|store
operator|.
name|getRowKeyAtOrBefore
argument_list|(
name|row
argument_list|)
decl_stmt|;
comment|// if it happens to be an exact match, we can stop looping
if|if
condition|(
name|Bytes
operator|.
name|equals
argument_list|(
name|row
argument_list|,
name|closestKey
argument_list|)
condition|)
block|{
name|key
operator|=
operator|new
name|HStoreKey
argument_list|(
name|closestKey
argument_list|)
expr_stmt|;
break|break;
block|}
comment|// otherwise, we need to check if it's the max and move to the next
if|if
condition|(
name|closestKey
operator|!=
literal|null
operator|&&
operator|(
name|key
operator|==
literal|null
operator|||
name|Bytes
operator|.
name|compareTo
argument_list|(
name|closestKey
argument_list|,
name|key
operator|.
name|getRow
argument_list|()
argument_list|)
operator|>
literal|0
operator|)
condition|)
block|{
name|key
operator|=
operator|new
name|HStoreKey
argument_list|(
name|closestKey
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|key
operator|==
literal|null
condition|)
block|{
return|return
literal|null
return|;
block|}
comment|// now that we've found our key, get the values
name|HbaseMapWritable
argument_list|<
name|byte
index|[]
argument_list|,
name|Cell
argument_list|>
name|cells
init|=
operator|new
name|HbaseMapWritable
argument_list|<
name|byte
index|[]
argument_list|,
name|Cell
argument_list|>
argument_list|()
decl_stmt|;
for|for
control|(
name|HStore
name|s
range|:
name|stores
operator|.
name|values
argument_list|()
control|)
block|{
name|s
operator|.
name|getFull
argument_list|(
name|key
argument_list|,
literal|null
argument_list|,
name|cells
argument_list|)
expr_stmt|;
block|}
return|return
operator|new
name|RowResult
argument_list|(
name|key
operator|.
name|getRow
argument_list|()
argument_list|,
name|cells
argument_list|)
return|;
block|}
finally|finally
block|{
name|splitsAndClosesLock
operator|.
name|readLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**    * Get<code>versions</code> keys matching the origin key's    * row/column/timestamp and those of an older vintage    * Default access so can be accessed out of {@link HRegionServer}.    * @param origin Where to start searching.    * @param versions How many versions to return. Pass    * {@link HConstants.ALL_VERSIONS} to retrieve all.    * @return Ordered list of<code>versions</code> keys going from newest back.    * @throws IOException    */
specifier|private
name|Set
argument_list|<
name|HStoreKey
argument_list|>
name|getKeys
parameter_list|(
specifier|final
name|HStoreKey
name|origin
parameter_list|,
specifier|final
name|int
name|versions
parameter_list|)
throws|throws
name|IOException
block|{
name|Set
argument_list|<
name|HStoreKey
argument_list|>
name|keys
init|=
operator|new
name|TreeSet
argument_list|<
name|HStoreKey
argument_list|>
argument_list|()
decl_stmt|;
name|Collection
argument_list|<
name|HStore
argument_list|>
name|storesToCheck
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|origin
operator|.
name|getColumn
argument_list|()
operator|==
literal|null
operator|||
name|origin
operator|.
name|getColumn
argument_list|()
operator|.
name|length
operator|==
literal|0
condition|)
block|{
comment|// All families
name|storesToCheck
operator|=
name|this
operator|.
name|stores
operator|.
name|values
argument_list|()
expr_stmt|;
block|}
else|else
block|{
name|storesToCheck
operator|=
operator|new
name|ArrayList
argument_list|<
name|HStore
argument_list|>
argument_list|(
literal|1
argument_list|)
expr_stmt|;
name|storesToCheck
operator|.
name|add
argument_list|(
name|getStore
argument_list|(
name|origin
operator|.
name|getColumn
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
for|for
control|(
name|HStore
name|targetStore
range|:
name|storesToCheck
control|)
block|{
if|if
condition|(
name|targetStore
operator|!=
literal|null
condition|)
block|{
comment|// Pass versions without modification since in the store getKeys, it
comment|// includes the size of the passed<code>keys</code> array when counting.
name|List
argument_list|<
name|HStoreKey
argument_list|>
name|r
init|=
name|targetStore
operator|.
name|getKeys
argument_list|(
name|origin
argument_list|,
name|versions
argument_list|)
decl_stmt|;
if|if
condition|(
name|r
operator|!=
literal|null
condition|)
block|{
name|keys
operator|.
name|addAll
argument_list|(
name|r
argument_list|)
expr_stmt|;
block|}
block|}
block|}
return|return
name|keys
return|;
block|}
comment|/**    * Return an iterator that scans over the HRegion, returning the indicated     * columns for only the rows that match the data filter.  This Iterator must    * be closed by the caller.    *    * @param cols columns to scan. If column name is a column family, all    * columns of the specified column family are returned.  Its also possible    * to pass a regex in the column qualifier. A column qualifier is judged to    * be a regex if it contains at least one of the following characters:    *<code>\+|^&*$[]]}{)(</code>.    * @param firstRow row which is the starting point of the scan    * @param timestamp only return rows whose timestamp is<= this value    * @param filter row filter    * @return InternalScanner    * @throws IOException    */
specifier|public
name|InternalScanner
name|getScanner
parameter_list|(
name|byte
index|[]
index|[]
name|cols
parameter_list|,
name|byte
index|[]
name|firstRow
parameter_list|,
name|long
name|timestamp
parameter_list|,
name|RowFilterInterface
name|filter
parameter_list|)
throws|throws
name|IOException
block|{
name|splitsAndClosesLock
operator|.
name|readLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
if|if
condition|(
name|this
operator|.
name|closed
operator|.
name|get
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Region "
operator|+
name|this
operator|+
literal|" closed"
argument_list|)
throw|;
block|}
name|HashSet
argument_list|<
name|HStore
argument_list|>
name|storeSet
init|=
operator|new
name|HashSet
argument_list|<
name|HStore
argument_list|>
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|cols
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|HStore
name|s
init|=
name|stores
operator|.
name|get
argument_list|(
name|Bytes
operator|.
name|mapKey
argument_list|(
name|HStoreKey
operator|.
name|getFamily
argument_list|(
name|cols
index|[
name|i
index|]
argument_list|)
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|s
operator|!=
literal|null
condition|)
block|{
name|storeSet
operator|.
name|add
argument_list|(
name|s
argument_list|)
expr_stmt|;
block|}
block|}
return|return
operator|new
name|HScanner
argument_list|(
name|cols
argument_list|,
name|firstRow
argument_list|,
name|timestamp
argument_list|,
name|storeSet
operator|.
name|toArray
argument_list|(
operator|new
name|HStore
index|[
name|storeSet
operator|.
name|size
argument_list|()
index|]
argument_list|)
argument_list|,
name|filter
argument_list|)
return|;
block|}
finally|finally
block|{
name|splitsAndClosesLock
operator|.
name|readLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
comment|//////////////////////////////////////////////////////////////////////////////
comment|// set() methods for client use.
comment|//////////////////////////////////////////////////////////////////////////////
comment|/**    * @param b    * @throws IOException    */
specifier|public
name|void
name|batchUpdate
parameter_list|(
name|BatchUpdate
name|b
parameter_list|)
throws|throws
name|IOException
block|{
name|checkReadOnly
argument_list|()
expr_stmt|;
comment|// Do a rough check that we have resources to accept a write.  The check is
comment|// 'rough' in that between the resource check and the call to obtain a
comment|// read lock, resources may run out.  For now, the thought is that this
comment|// will be extremely rare; we'll deal with it when it happens.
name|checkResources
argument_list|()
expr_stmt|;
comment|// We obtain a per-row lock, so other clients will block while one client
comment|// performs an update. The read lock is released by the client calling
comment|// #commit or #abort or if the HRegionServer lease on the lock expires.
comment|// See HRegionServer#RegionListener for how the expire on HRegionServer
comment|// invokes a HRegion#abort.
name|byte
index|[]
name|row
init|=
name|b
operator|.
name|getRow
argument_list|()
decl_stmt|;
name|Integer
name|lid
init|=
name|obtainRowLock
argument_list|(
name|row
argument_list|)
decl_stmt|;
name|long
name|commitTime
init|=
operator|(
name|b
operator|.
name|getTimestamp
argument_list|()
operator|==
name|LATEST_TIMESTAMP
operator|)
condition|?
name|System
operator|.
name|currentTimeMillis
argument_list|()
else|:
name|b
operator|.
name|getTimestamp
argument_list|()
decl_stmt|;
try|try
block|{
name|List
argument_list|<
name|byte
index|[]
argument_list|>
name|deletes
init|=
literal|null
decl_stmt|;
for|for
control|(
name|BatchOperation
name|op
range|:
name|b
control|)
block|{
name|HStoreKey
name|key
init|=
operator|new
name|HStoreKey
argument_list|(
name|row
argument_list|,
name|op
operator|.
name|getColumn
argument_list|()
argument_list|,
name|commitTime
argument_list|)
decl_stmt|;
name|byte
index|[]
name|val
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|op
operator|.
name|isPut
argument_list|()
condition|)
block|{
name|val
operator|=
name|op
operator|.
name|getValue
argument_list|()
expr_stmt|;
if|if
condition|(
name|HLogEdit
operator|.
name|isDeleted
argument_list|(
name|val
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Cannot insert value: "
operator|+
name|val
argument_list|)
throw|;
block|}
block|}
else|else
block|{
if|if
condition|(
name|b
operator|.
name|getTimestamp
argument_list|()
operator|==
name|LATEST_TIMESTAMP
condition|)
block|{
comment|// Save off these deletes
if|if
condition|(
name|deletes
operator|==
literal|null
condition|)
block|{
name|deletes
operator|=
operator|new
name|ArrayList
argument_list|<
name|byte
index|[]
argument_list|>
argument_list|()
expr_stmt|;
block|}
name|deletes
operator|.
name|add
argument_list|(
name|op
operator|.
name|getColumn
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|val
operator|=
name|HLogEdit
operator|.
name|deleteBytes
operator|.
name|get
argument_list|()
expr_stmt|;
block|}
block|}
if|if
condition|(
name|val
operator|!=
literal|null
condition|)
block|{
name|localput
argument_list|(
name|lid
argument_list|,
name|key
argument_list|,
name|val
argument_list|)
expr_stmt|;
block|}
block|}
name|TreeMap
argument_list|<
name|HStoreKey
argument_list|,
name|byte
index|[]
argument_list|>
name|edits
init|=
name|this
operator|.
name|targetColumns
operator|.
name|remove
argument_list|(
name|lid
argument_list|)
decl_stmt|;
if|if
condition|(
name|edits
operator|!=
literal|null
operator|&&
name|edits
operator|.
name|size
argument_list|()
operator|>
literal|0
condition|)
block|{
name|update
argument_list|(
name|edits
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|deletes
operator|!=
literal|null
operator|&&
name|deletes
operator|.
name|size
argument_list|()
operator|>
literal|0
condition|)
block|{
comment|// We have some LATEST_TIMESTAMP deletes to run.
for|for
control|(
name|byte
index|[]
name|column
range|:
name|deletes
control|)
block|{
name|deleteMultiple
argument_list|(
name|row
argument_list|,
name|column
argument_list|,
name|LATEST_TIMESTAMP
argument_list|,
literal|1
argument_list|)
expr_stmt|;
block|}
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|this
operator|.
name|targetColumns
operator|.
name|remove
argument_list|(
name|Long
operator|.
name|valueOf
argument_list|(
name|lid
argument_list|)
argument_list|)
expr_stmt|;
throw|throw
name|e
throw|;
block|}
finally|finally
block|{
name|releaseRowLock
argument_list|(
name|lid
argument_list|)
expr_stmt|;
block|}
block|}
comment|/*    * Check if resources to support an update.    *     * For now, just checks memcache saturation.    *     * Here we synchronize on HRegion, a broad scoped lock.  Its appropriate    * given we're figuring in here whether this region is able to take on    * writes.  This is only method with a synchronize (at time of writing),    * this and the synchronize on 'this' inside in internalFlushCache to send    * the notify.    */
specifier|private
name|void
name|checkResources
parameter_list|()
block|{
if|if
condition|(
name|this
operator|.
name|memcacheSize
operator|.
name|get
argument_list|()
operator|>
name|this
operator|.
name|blockingMemcacheSize
condition|)
block|{
name|requestFlush
argument_list|()
expr_stmt|;
name|doBlocking
argument_list|()
expr_stmt|;
block|}
block|}
specifier|private
specifier|synchronized
name|void
name|doBlocking
parameter_list|()
block|{
name|boolean
name|blocked
init|=
literal|false
decl_stmt|;
while|while
condition|(
name|this
operator|.
name|memcacheSize
operator|.
name|get
argument_list|()
operator|>
name|this
operator|.
name|blockingMemcacheSize
condition|)
block|{
if|if
condition|(
operator|!
name|blocked
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Blocking updates for '"
operator|+
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|"' on region "
operator|+
name|Bytes
operator|.
name|toString
argument_list|(
name|getRegionName
argument_list|()
argument_list|)
operator|+
literal|": Memcache size "
operator|+
name|StringUtils
operator|.
name|humanReadableInt
argument_list|(
name|this
operator|.
name|memcacheSize
operator|.
name|get
argument_list|()
argument_list|)
operator|+
literal|" is>= than blocking "
operator|+
name|StringUtils
operator|.
name|humanReadableInt
argument_list|(
name|this
operator|.
name|blockingMemcacheSize
argument_list|)
operator|+
literal|" size"
argument_list|)
expr_stmt|;
block|}
name|blocked
operator|=
literal|true
expr_stmt|;
try|try
block|{
name|wait
argument_list|(
name|threadWakeFrequency
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
comment|// continue;
block|}
block|}
if|if
condition|(
name|blocked
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Unblocking updates for region "
operator|+
name|this
operator|+
literal|" '"
operator|+
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|"'"
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Delete all cells of the same age as the passed timestamp or older.    * @param row    * @param column    * @param ts Delete all entries that have this timestamp or older    * @throws IOException    */
specifier|public
name|void
name|deleteAll
parameter_list|(
specifier|final
name|byte
index|[]
name|row
parameter_list|,
specifier|final
name|byte
index|[]
name|column
parameter_list|,
specifier|final
name|long
name|ts
parameter_list|)
throws|throws
name|IOException
block|{
name|checkColumn
argument_list|(
name|column
argument_list|)
expr_stmt|;
name|checkReadOnly
argument_list|()
expr_stmt|;
name|Integer
name|lid
init|=
name|obtainRowLock
argument_list|(
name|row
argument_list|)
decl_stmt|;
try|try
block|{
name|deleteMultiple
argument_list|(
name|row
argument_list|,
name|column
argument_list|,
name|ts
argument_list|,
name|ALL_VERSIONS
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|releaseRowLock
argument_list|(
name|lid
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Delete all cells of the same age as the passed timestamp or older.    * @param row    * @param ts Delete all entries that have this timestamp or older    * @throws IOException    */
specifier|public
name|void
name|deleteAll
parameter_list|(
specifier|final
name|byte
index|[]
name|row
parameter_list|,
specifier|final
name|long
name|ts
parameter_list|)
throws|throws
name|IOException
block|{
name|checkReadOnly
argument_list|()
expr_stmt|;
name|Integer
name|lid
init|=
name|obtainRowLock
argument_list|(
name|row
argument_list|)
decl_stmt|;
try|try
block|{
for|for
control|(
name|HStore
name|store
range|:
name|stores
operator|.
name|values
argument_list|()
control|)
block|{
name|List
argument_list|<
name|HStoreKey
argument_list|>
name|keys
init|=
name|store
operator|.
name|getKeys
argument_list|(
operator|new
name|HStoreKey
argument_list|(
name|row
argument_list|,
name|ts
argument_list|)
argument_list|,
name|ALL_VERSIONS
argument_list|)
decl_stmt|;
name|TreeMap
argument_list|<
name|HStoreKey
argument_list|,
name|byte
index|[]
argument_list|>
name|edits
init|=
operator|new
name|TreeMap
argument_list|<
name|HStoreKey
argument_list|,
name|byte
index|[]
argument_list|>
argument_list|()
decl_stmt|;
for|for
control|(
name|HStoreKey
name|key
range|:
name|keys
control|)
block|{
name|edits
operator|.
name|put
argument_list|(
name|key
argument_list|,
name|HLogEdit
operator|.
name|deleteBytes
operator|.
name|get
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|update
argument_list|(
name|edits
argument_list|)
expr_stmt|;
block|}
block|}
finally|finally
block|{
name|releaseRowLock
argument_list|(
name|lid
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Delete all cells for a row with matching column family with timestamps    * less than or equal to<i>timestamp</i>.    *    * @param row The row to operate on    * @param family The column family to match    * @param timestamp Timestamp to match    * @throws IOException    */
specifier|public
name|void
name|deleteFamily
parameter_list|(
name|byte
index|[]
name|row
parameter_list|,
name|byte
index|[]
name|family
parameter_list|,
name|long
name|timestamp
parameter_list|)
throws|throws
name|IOException
block|{
name|checkReadOnly
argument_list|()
expr_stmt|;
name|Integer
name|lid
init|=
name|obtainRowLock
argument_list|(
name|row
argument_list|)
decl_stmt|;
try|try
block|{
comment|// find the HStore for the column family
name|HStore
name|store
init|=
name|getStore
argument_list|(
name|family
argument_list|)
decl_stmt|;
comment|// find all the keys that match our criteria
name|List
argument_list|<
name|HStoreKey
argument_list|>
name|keys
init|=
name|store
operator|.
name|getKeys
argument_list|(
operator|new
name|HStoreKey
argument_list|(
name|row
argument_list|,
name|timestamp
argument_list|)
argument_list|,
name|ALL_VERSIONS
argument_list|)
decl_stmt|;
comment|// delete all the cells
name|TreeMap
argument_list|<
name|HStoreKey
argument_list|,
name|byte
index|[]
argument_list|>
name|edits
init|=
operator|new
name|TreeMap
argument_list|<
name|HStoreKey
argument_list|,
name|byte
index|[]
argument_list|>
argument_list|()
decl_stmt|;
for|for
control|(
name|HStoreKey
name|key
range|:
name|keys
control|)
block|{
name|edits
operator|.
name|put
argument_list|(
name|key
argument_list|,
name|HLogEdit
operator|.
name|deleteBytes
operator|.
name|get
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|update
argument_list|(
name|edits
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|releaseRowLock
argument_list|(
name|lid
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Delete one or many cells.    * Used to support {@link #deleteAll(byte [], byte [], long)} and deletion of    * latest cell.    *     * @param row    * @param column    * @param ts Timestamp to start search on.    * @param versions How many versions to delete. Pass    * {@link HConstants#ALL_VERSIONS} to delete all.    * @throws IOException    */
specifier|private
name|void
name|deleteMultiple
parameter_list|(
specifier|final
name|byte
index|[]
name|row
parameter_list|,
specifier|final
name|byte
index|[]
name|column
parameter_list|,
specifier|final
name|long
name|ts
parameter_list|,
specifier|final
name|int
name|versions
parameter_list|)
throws|throws
name|IOException
block|{
name|checkReadOnly
argument_list|()
expr_stmt|;
name|HStoreKey
name|origin
init|=
operator|new
name|HStoreKey
argument_list|(
name|row
argument_list|,
name|column
argument_list|,
name|ts
argument_list|)
decl_stmt|;
name|Set
argument_list|<
name|HStoreKey
argument_list|>
name|keys
init|=
name|getKeys
argument_list|(
name|origin
argument_list|,
name|versions
argument_list|)
decl_stmt|;
if|if
condition|(
name|keys
operator|.
name|size
argument_list|()
operator|>
literal|0
condition|)
block|{
name|TreeMap
argument_list|<
name|HStoreKey
argument_list|,
name|byte
index|[]
argument_list|>
name|edits
init|=
operator|new
name|TreeMap
argument_list|<
name|HStoreKey
argument_list|,
name|byte
index|[]
argument_list|>
argument_list|()
decl_stmt|;
for|for
control|(
name|HStoreKey
name|key
range|:
name|keys
control|)
block|{
name|edits
operator|.
name|put
argument_list|(
name|key
argument_list|,
name|HLogEdit
operator|.
name|deleteBytes
operator|.
name|get
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|update
argument_list|(
name|edits
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * @throws IOException Throws exception if region is in read-only mode.    */
specifier|protected
name|void
name|checkReadOnly
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|this
operator|.
name|writestate
operator|.
name|isReadOnly
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"region is read only"
argument_list|)
throw|;
block|}
block|}
comment|/**    * Private implementation.    *     * localput() is used for both puts and deletes. We just place the values    * into a per-row pending area, until a commit() or abort() call is received.    * (Or until the user's write-lock expires.)    *     * @param lockid    * @param key     * @param val Value to enter into cell    * @throws IOException    */
specifier|private
name|void
name|localput
parameter_list|(
specifier|final
name|Integer
name|lockid
parameter_list|,
specifier|final
name|HStoreKey
name|key
parameter_list|,
specifier|final
name|byte
index|[]
name|val
parameter_list|)
throws|throws
name|IOException
block|{
name|checkColumn
argument_list|(
name|key
operator|.
name|getColumn
argument_list|()
argument_list|)
expr_stmt|;
name|checkReadOnly
argument_list|()
expr_stmt|;
name|TreeMap
argument_list|<
name|HStoreKey
argument_list|,
name|byte
index|[]
argument_list|>
name|targets
init|=
name|this
operator|.
name|targetColumns
operator|.
name|get
argument_list|(
name|lockid
argument_list|)
decl_stmt|;
if|if
condition|(
name|targets
operator|==
literal|null
condition|)
block|{
name|targets
operator|=
operator|new
name|TreeMap
argument_list|<
name|HStoreKey
argument_list|,
name|byte
index|[]
argument_list|>
argument_list|()
expr_stmt|;
name|this
operator|.
name|targetColumns
operator|.
name|put
argument_list|(
name|lockid
argument_list|,
name|targets
argument_list|)
expr_stmt|;
block|}
name|targets
operator|.
name|put
argument_list|(
name|key
argument_list|,
name|val
argument_list|)
expr_stmt|;
block|}
comment|/*     * Add updates first to the hlog and then add values to memcache.    * Warning: Assumption is caller has lock on passed in row.    * @param row Row to update.    * @param timestamp Timestamp to record the updates against    * @param updatesByColumn Cell updates by column    * @throws IOException    */
specifier|private
name|void
name|update
parameter_list|(
specifier|final
name|TreeMap
argument_list|<
name|HStoreKey
argument_list|,
name|byte
index|[]
argument_list|>
name|updatesByColumn
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|updatesByColumn
operator|==
literal|null
operator|||
name|updatesByColumn
operator|.
name|size
argument_list|()
operator|<=
literal|0
condition|)
block|{
return|return;
block|}
name|checkReadOnly
argument_list|()
expr_stmt|;
name|boolean
name|flush
init|=
literal|false
decl_stmt|;
name|this
operator|.
name|updatesLock
operator|.
name|readLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
name|this
operator|.
name|log
operator|.
name|append
argument_list|(
name|regionInfo
operator|.
name|getRegionName
argument_list|()
argument_list|,
name|regionInfo
operator|.
name|getTableDesc
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|,
name|updatesByColumn
argument_list|)
expr_stmt|;
name|long
name|size
init|=
literal|0
decl_stmt|;
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|HStoreKey
argument_list|,
name|byte
index|[]
argument_list|>
name|e
range|:
name|updatesByColumn
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|HStoreKey
name|key
init|=
name|e
operator|.
name|getKey
argument_list|()
decl_stmt|;
name|size
operator|=
name|this
operator|.
name|memcacheSize
operator|.
name|addAndGet
argument_list|(
name|getStore
argument_list|(
name|key
operator|.
name|getColumn
argument_list|()
argument_list|)
operator|.
name|add
argument_list|(
name|key
argument_list|,
name|e
operator|.
name|getValue
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|flush
operator|=
name|isFlushSize
argument_list|(
name|size
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|this
operator|.
name|updatesLock
operator|.
name|readLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|flush
condition|)
block|{
comment|// Request a cache flush.  Do it outside update lock.
name|requestFlush
argument_list|()
expr_stmt|;
block|}
block|}
specifier|private
name|void
name|requestFlush
parameter_list|()
block|{
if|if
condition|(
name|this
operator|.
name|flushListener
operator|==
literal|null
condition|)
block|{
return|return;
block|}
synchronized|synchronized
init|(
name|writestate
init|)
block|{
if|if
condition|(
name|this
operator|.
name|writestate
operator|.
name|isFlushRequested
argument_list|()
condition|)
block|{
return|return;
block|}
name|writestate
operator|.
name|flushRequested
operator|=
literal|true
expr_stmt|;
block|}
comment|// Make request outside of synchronize block; HBASE-818.
name|this
operator|.
name|flushListener
operator|.
name|request
argument_list|(
name|this
argument_list|)
expr_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Flush requested on "
operator|+
name|this
argument_list|)
expr_stmt|;
block|}
block|}
comment|/*    * @param size    * @return True if size is over the flush threshold    */
specifier|private
name|boolean
name|isFlushSize
parameter_list|(
specifier|final
name|long
name|size
parameter_list|)
block|{
return|return
name|size
operator|>
name|this
operator|.
name|memcacheFlushSize
return|;
block|}
comment|// Do any reconstruction needed from the log
annotation|@
name|SuppressWarnings
argument_list|(
literal|"unused"
argument_list|)
specifier|protected
name|void
name|doReconstructionLog
parameter_list|(
name|Path
name|oldLogFile
parameter_list|,
name|long
name|maxSeqId
parameter_list|,
name|Progressable
name|reporter
parameter_list|)
throws|throws
name|UnsupportedEncodingException
throws|,
name|IOException
block|{
comment|// Nothing to do (Replaying is done in HStores)
block|}
specifier|protected
name|HStore
name|instantiateHStore
parameter_list|(
name|Path
name|baseDir
parameter_list|,
name|HColumnDescriptor
name|c
parameter_list|,
name|Path
name|oldLogFile
parameter_list|,
name|Progressable
name|reporter
parameter_list|)
throws|throws
name|IOException
block|{
return|return
operator|new
name|HStore
argument_list|(
name|baseDir
argument_list|,
name|this
operator|.
name|regionInfo
argument_list|,
name|c
argument_list|,
name|this
operator|.
name|fs
argument_list|,
name|oldLogFile
argument_list|,
name|this
operator|.
name|conf
argument_list|,
name|reporter
argument_list|)
return|;
block|}
comment|/*    * @param column    * @return Store that goes with the family on passed<code>column</code>.    * TODO: Make this lookup faster.    */
specifier|protected
name|HStore
name|getStore
parameter_list|(
specifier|final
name|byte
index|[]
name|column
parameter_list|)
block|{
return|return
name|this
operator|.
name|stores
operator|.
name|get
argument_list|(
name|HStoreKey
operator|.
name|getFamilyMapKey
argument_list|(
name|column
argument_list|)
argument_list|)
return|;
block|}
comment|//////////////////////////////////////////////////////////////////////////////
comment|// Support code
comment|//////////////////////////////////////////////////////////////////////////////
comment|/** Make sure this is a valid row for the HRegion */
specifier|private
name|void
name|checkRow
parameter_list|(
specifier|final
name|byte
index|[]
name|row
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
operator|!
name|rowIsInRange
argument_list|(
name|regionInfo
argument_list|,
name|row
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|WrongRegionException
argument_list|(
literal|"Requested row out of range for "
operator|+
literal|"HRegion "
operator|+
name|this
operator|+
literal|", startKey='"
operator|+
name|Bytes
operator|.
name|toString
argument_list|(
name|regionInfo
operator|.
name|getStartKey
argument_list|()
argument_list|)
operator|+
literal|"', getEndKey()='"
operator|+
name|Bytes
operator|.
name|toString
argument_list|(
name|regionInfo
operator|.
name|getEndKey
argument_list|()
argument_list|)
operator|+
literal|"', row='"
operator|+
name|Bytes
operator|.
name|toString
argument_list|(
name|row
argument_list|)
operator|+
literal|"'"
argument_list|)
throw|;
block|}
block|}
comment|/*    * Make sure this is a valid column for the current table    * @param columnName    * @throws NoSuchColumnFamilyException    */
specifier|private
name|void
name|checkColumn
parameter_list|(
specifier|final
name|byte
index|[]
name|columnName
parameter_list|)
throws|throws
name|NoSuchColumnFamilyException
throws|,
name|ColumnNameParseException
block|{
if|if
condition|(
name|columnName
operator|==
literal|null
condition|)
block|{
return|return;
block|}
name|int
name|index
init|=
name|HStoreKey
operator|.
name|getFamilyDelimiterIndex
argument_list|(
name|columnName
argument_list|)
decl_stmt|;
if|if
condition|(
name|index
operator|<=
literal|0
condition|)
block|{
throw|throw
operator|new
name|ColumnNameParseException
argument_list|(
name|Bytes
operator|.
name|toString
argument_list|(
name|columnName
argument_list|)
operator|+
literal|" is missing column family delimiter '"
operator|+
name|HStoreKey
operator|.
name|COLUMN_FAMILY_DELIMITER
operator|+
literal|"'"
argument_list|)
throw|;
block|}
if|if
condition|(
operator|!
name|regionInfo
operator|.
name|getTableDesc
argument_list|()
operator|.
name|hasFamily
argument_list|(
name|columnName
argument_list|,
name|index
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|NoSuchColumnFamilyException
argument_list|(
literal|"Column family on "
operator|+
name|Bytes
operator|.
name|toString
argument_list|(
name|columnName
argument_list|)
operator|+
literal|" does not exist in region "
operator|+
name|this
operator|+
literal|" in table "
operator|+
name|regionInfo
operator|.
name|getTableDesc
argument_list|()
argument_list|)
throw|;
block|}
block|}
comment|/**    * Obtain a lock on the given row.  Blocks until success.    *    * I know it's strange to have two mappings:    *<pre>    *   ROWS  ==> LOCKS    *</pre>    * as well as    *<pre>    *   LOCKS ==> ROWS    *</pre>    *    * But it acts as a guard on the client; a miswritten client just can't    * submit the name of a row and start writing to it; it must know the correct    * lockid, which matches the lock list in memory.    *     *<p>It would be more memory-efficient to assume a correctly-written client,     * which maybe we'll do in the future.    *     * @param row Name of row to lock.    * @throws IOException    * @return The id of the held lock.    */
name|Integer
name|obtainRowLock
parameter_list|(
specifier|final
name|byte
index|[]
name|row
parameter_list|)
throws|throws
name|IOException
block|{
name|checkRow
argument_list|(
name|row
argument_list|)
expr_stmt|;
name|splitsAndClosesLock
operator|.
name|readLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
if|if
condition|(
name|this
operator|.
name|closed
operator|.
name|get
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|NotServingRegionException
argument_list|(
literal|"Region "
operator|+
name|this
operator|+
literal|" closed"
argument_list|)
throw|;
block|}
name|Integer
name|key
init|=
name|Bytes
operator|.
name|mapKey
argument_list|(
name|row
argument_list|)
decl_stmt|;
synchronized|synchronized
init|(
name|locksToRows
init|)
block|{
while|while
condition|(
name|locksToRows
operator|.
name|containsKey
argument_list|(
name|key
argument_list|)
condition|)
block|{
try|try
block|{
name|locksToRows
operator|.
name|wait
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|ie
parameter_list|)
block|{
comment|// Empty
block|}
block|}
name|locksToRows
operator|.
name|put
argument_list|(
name|key
argument_list|,
name|row
argument_list|)
expr_stmt|;
name|locksToRows
operator|.
name|notifyAll
argument_list|()
expr_stmt|;
return|return
name|key
return|;
block|}
block|}
finally|finally
block|{
name|splitsAndClosesLock
operator|.
name|readLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**    * Used by unit tests.    * @param lockid    * @return Row that goes with<code>lockid</code>    */
name|byte
index|[]
name|getRowFromLock
parameter_list|(
specifier|final
name|Integer
name|lockid
parameter_list|)
block|{
return|return
name|locksToRows
operator|.
name|get
argument_list|(
name|lockid
argument_list|)
return|;
block|}
comment|/**     * Release the row lock!    * @param row Name of row whose lock we are to release    */
name|void
name|releaseRowLock
parameter_list|(
specifier|final
name|Integer
name|lockid
parameter_list|)
block|{
synchronized|synchronized
init|(
name|locksToRows
init|)
block|{
name|locksToRows
operator|.
name|remove
argument_list|(
name|lockid
argument_list|)
expr_stmt|;
name|locksToRows
operator|.
name|notifyAll
argument_list|()
expr_stmt|;
block|}
block|}
specifier|private
name|void
name|waitOnRowLocks
parameter_list|()
block|{
synchronized|synchronized
init|(
name|locksToRows
init|)
block|{
while|while
condition|(
name|this
operator|.
name|locksToRows
operator|.
name|size
argument_list|()
operator|>
literal|0
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"waiting for "
operator|+
name|this
operator|.
name|locksToRows
operator|.
name|size
argument_list|()
operator|+
literal|" row locks"
argument_list|)
expr_stmt|;
try|try
block|{
name|this
operator|.
name|locksToRows
operator|.
name|wait
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
comment|// Catch. Let while test determine loop-end.
block|}
block|}
block|}
block|}
comment|/** {@inheritDoc} */
annotation|@
name|Override
specifier|public
name|boolean
name|equals
parameter_list|(
name|Object
name|o
parameter_list|)
block|{
return|return
name|this
operator|.
name|hashCode
argument_list|()
operator|==
operator|(
operator|(
name|HRegion
operator|)
name|o
operator|)
operator|.
name|hashCode
argument_list|()
return|;
block|}
comment|/** {@inheritDoc} */
annotation|@
name|Override
specifier|public
name|int
name|hashCode
parameter_list|()
block|{
return|return
name|this
operator|.
name|regionInfo
operator|.
name|getRegionName
argument_list|()
operator|.
name|hashCode
argument_list|()
return|;
block|}
comment|/** {@inheritDoc} */
annotation|@
name|Override
specifier|public
name|String
name|toString
parameter_list|()
block|{
return|return
name|this
operator|.
name|regionInfo
operator|.
name|getRegionNameAsString
argument_list|()
return|;
block|}
comment|/** @return Path of region base directory */
specifier|public
name|Path
name|getBaseDir
parameter_list|()
block|{
return|return
name|this
operator|.
name|basedir
return|;
block|}
comment|/**    * HScanner is an iterator through a bunch of rows in an HRegion.    */
specifier|private
class|class
name|HScanner
implements|implements
name|InternalScanner
block|{
specifier|private
name|InternalScanner
index|[]
name|scanners
decl_stmt|;
specifier|private
name|TreeMap
argument_list|<
name|byte
index|[]
argument_list|,
name|Cell
argument_list|>
index|[]
name|resultSets
decl_stmt|;
specifier|private
name|HStoreKey
index|[]
name|keys
decl_stmt|;
specifier|private
name|RowFilterInterface
name|filter
decl_stmt|;
comment|/** Create an HScanner with a handle on many HStores. */
annotation|@
name|SuppressWarnings
argument_list|(
literal|"unchecked"
argument_list|)
name|HScanner
parameter_list|(
name|byte
index|[]
index|[]
name|cols
parameter_list|,
name|byte
index|[]
name|firstRow
parameter_list|,
name|long
name|timestamp
parameter_list|,
name|HStore
index|[]
name|stores
parameter_list|,
name|RowFilterInterface
name|filter
parameter_list|)
throws|throws
name|IOException
block|{
name|this
operator|.
name|filter
operator|=
name|filter
expr_stmt|;
name|this
operator|.
name|scanners
operator|=
operator|new
name|InternalScanner
index|[
name|stores
operator|.
name|length
index|]
expr_stmt|;
try|try
block|{
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|stores
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
comment|// Only pass relevant columns to each store
name|List
argument_list|<
name|byte
index|[]
argument_list|>
name|columns
init|=
operator|new
name|ArrayList
argument_list|<
name|byte
index|[]
argument_list|>
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|j
init|=
literal|0
init|;
name|j
operator|<
name|cols
operator|.
name|length
condition|;
name|j
operator|++
control|)
block|{
if|if
condition|(
name|Bytes
operator|.
name|equals
argument_list|(
name|HStoreKey
operator|.
name|getFamily
argument_list|(
name|cols
index|[
name|j
index|]
argument_list|)
argument_list|,
name|stores
index|[
name|i
index|]
operator|.
name|getFamily
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|)
condition|)
block|{
name|columns
operator|.
name|add
argument_list|(
name|cols
index|[
name|j
index|]
argument_list|)
expr_stmt|;
block|}
block|}
name|RowFilterInterface
name|f
init|=
name|filter
decl_stmt|;
if|if
condition|(
name|f
operator|!=
literal|null
condition|)
block|{
comment|// Need to replicate filters.
comment|// At least WhileMatchRowFilter will mess up the scan if only
comment|// one shared across many rows. See HADOOP-2467.
name|f
operator|=
operator|(
name|RowFilterInterface
operator|)
name|WritableUtils
operator|.
name|clone
argument_list|(
name|filter
argument_list|,
name|conf
argument_list|)
expr_stmt|;
block|}
name|scanners
index|[
name|i
index|]
operator|=
name|stores
index|[
name|i
index|]
operator|.
name|getScanner
argument_list|(
name|timestamp
argument_list|,
name|columns
operator|.
name|toArray
argument_list|(
operator|new
name|byte
index|[
name|columns
operator|.
name|size
argument_list|()
index|]
index|[]
argument_list|)
argument_list|,
name|firstRow
argument_list|,
name|f
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|this
operator|.
name|scanners
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|scanners
index|[
name|i
index|]
operator|!=
literal|null
condition|)
block|{
name|closeScanner
argument_list|(
name|i
argument_list|)
expr_stmt|;
block|}
block|}
throw|throw
name|e
throw|;
block|}
comment|// Advance to the first key in each store.
comment|// All results will match the required column-set and scanTime.
name|this
operator|.
name|resultSets
operator|=
operator|new
name|TreeMap
index|[
name|scanners
operator|.
name|length
index|]
expr_stmt|;
name|this
operator|.
name|keys
operator|=
operator|new
name|HStoreKey
index|[
name|scanners
operator|.
name|length
index|]
expr_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|scanners
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|keys
index|[
name|i
index|]
operator|=
operator|new
name|HStoreKey
argument_list|()
expr_stmt|;
name|resultSets
index|[
name|i
index|]
operator|=
operator|new
name|TreeMap
argument_list|<
name|byte
index|[]
argument_list|,
name|Cell
argument_list|>
argument_list|(
name|Bytes
operator|.
name|BYTES_COMPARATOR
argument_list|)
expr_stmt|;
if|if
condition|(
name|scanners
index|[
name|i
index|]
operator|!=
literal|null
operator|&&
operator|!
name|scanners
index|[
name|i
index|]
operator|.
name|next
argument_list|(
name|keys
index|[
name|i
index|]
argument_list|,
name|resultSets
index|[
name|i
index|]
argument_list|)
condition|)
block|{
name|closeScanner
argument_list|(
name|i
argument_list|)
expr_stmt|;
block|}
block|}
comment|// As we have now successfully completed initialization, increment the
comment|// activeScanner count.
name|activeScannerCount
operator|.
name|incrementAndGet
argument_list|()
expr_stmt|;
block|}
comment|/** {@inheritDoc} */
annotation|@
name|SuppressWarnings
argument_list|(
literal|"null"
argument_list|)
specifier|public
name|boolean
name|next
parameter_list|(
name|HStoreKey
name|key
parameter_list|,
name|SortedMap
argument_list|<
name|byte
index|[]
argument_list|,
name|Cell
argument_list|>
name|results
parameter_list|)
throws|throws
name|IOException
block|{
name|boolean
name|moreToFollow
init|=
literal|false
decl_stmt|;
name|boolean
name|filtered
init|=
literal|false
decl_stmt|;
do|do
block|{
comment|// Find the lowest-possible key.
name|byte
index|[]
name|chosenRow
init|=
literal|null
decl_stmt|;
name|long
name|chosenTimestamp
init|=
operator|-
literal|1
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|this
operator|.
name|keys
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|scanners
index|[
name|i
index|]
operator|!=
literal|null
operator|&&
operator|(
name|chosenRow
operator|==
literal|null
operator|||
operator|(
name|Bytes
operator|.
name|compareTo
argument_list|(
name|keys
index|[
name|i
index|]
operator|.
name|getRow
argument_list|()
argument_list|,
name|chosenRow
argument_list|)
operator|<
literal|0
operator|)
operator|||
operator|(
operator|(
name|Bytes
operator|.
name|compareTo
argument_list|(
name|keys
index|[
name|i
index|]
operator|.
name|getRow
argument_list|()
argument_list|,
name|chosenRow
argument_list|)
operator|==
literal|0
operator|)
operator|&&
operator|(
name|keys
index|[
name|i
index|]
operator|.
name|getTimestamp
argument_list|()
operator|>
name|chosenTimestamp
operator|)
operator|)
operator|)
condition|)
block|{
name|chosenRow
operator|=
name|keys
index|[
name|i
index|]
operator|.
name|getRow
argument_list|()
expr_stmt|;
name|chosenTimestamp
operator|=
name|keys
index|[
name|i
index|]
operator|.
name|getTimestamp
argument_list|()
expr_stmt|;
block|}
block|}
comment|// Store the key and results for each sub-scanner. Merge them as
comment|// appropriate.
if|if
condition|(
name|chosenTimestamp
operator|>=
literal|0
condition|)
block|{
comment|// Here we are setting the passed in key with current row+timestamp
name|key
operator|.
name|setRow
argument_list|(
name|chosenRow
argument_list|)
expr_stmt|;
name|key
operator|.
name|setVersion
argument_list|(
name|chosenTimestamp
argument_list|)
expr_stmt|;
name|key
operator|.
name|setColumn
argument_list|(
name|HConstants
operator|.
name|EMPTY_BYTE_ARRAY
argument_list|)
expr_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|scanners
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|scanners
index|[
name|i
index|]
operator|!=
literal|null
operator|&&
name|Bytes
operator|.
name|compareTo
argument_list|(
name|keys
index|[
name|i
index|]
operator|.
name|getRow
argument_list|()
argument_list|,
name|chosenRow
argument_list|)
operator|==
literal|0
condition|)
block|{
comment|// NOTE: We used to do results.putAll(resultSets[i]);
comment|// but this had the effect of overwriting newer
comment|// values with older ones. So now we only insert
comment|// a result if the map does not contain the key.
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|byte
index|[]
argument_list|,
name|Cell
argument_list|>
name|e
range|:
name|resultSets
index|[
name|i
index|]
operator|.
name|entrySet
argument_list|()
control|)
block|{
if|if
condition|(
operator|!
name|results
operator|.
name|containsKey
argument_list|(
name|e
operator|.
name|getKey
argument_list|()
argument_list|)
condition|)
block|{
name|results
operator|.
name|put
argument_list|(
name|e
operator|.
name|getKey
argument_list|()
argument_list|,
name|e
operator|.
name|getValue
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
name|resultSets
index|[
name|i
index|]
operator|.
name|clear
argument_list|()
expr_stmt|;
if|if
condition|(
operator|!
name|scanners
index|[
name|i
index|]
operator|.
name|next
argument_list|(
name|keys
index|[
name|i
index|]
argument_list|,
name|resultSets
index|[
name|i
index|]
argument_list|)
condition|)
block|{
name|closeScanner
argument_list|(
name|i
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|scanners
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
comment|// If the current scanner is non-null AND has a lower-or-equal
comment|// row label, then its timestamp is bad. We need to advance it.
while|while
condition|(
operator|(
name|scanners
index|[
name|i
index|]
operator|!=
literal|null
operator|)
operator|&&
operator|(
name|Bytes
operator|.
name|compareTo
argument_list|(
name|keys
index|[
name|i
index|]
operator|.
name|getRow
argument_list|()
argument_list|,
name|chosenRow
argument_list|)
operator|<=
literal|0
operator|)
condition|)
block|{
name|resultSets
index|[
name|i
index|]
operator|.
name|clear
argument_list|()
expr_stmt|;
if|if
condition|(
operator|!
name|scanners
index|[
name|i
index|]
operator|.
name|next
argument_list|(
name|keys
index|[
name|i
index|]
argument_list|,
name|resultSets
index|[
name|i
index|]
argument_list|)
condition|)
block|{
name|closeScanner
argument_list|(
name|i
argument_list|)
expr_stmt|;
block|}
block|}
block|}
name|moreToFollow
operator|=
name|chosenTimestamp
operator|>=
literal|0
expr_stmt|;
if|if
condition|(
name|results
operator|==
literal|null
operator|||
name|results
operator|.
name|size
argument_list|()
operator|<=
literal|0
condition|)
block|{
comment|// If we got no results, then there is no more to follow.
name|moreToFollow
operator|=
literal|false
expr_stmt|;
block|}
name|filtered
operator|=
name|filter
operator|==
literal|null
condition|?
literal|false
else|:
name|filter
operator|.
name|filterRow
argument_list|(
name|results
argument_list|)
expr_stmt|;
if|if
condition|(
name|filter
operator|!=
literal|null
operator|&&
name|filter
operator|.
name|filterAllRemaining
argument_list|()
condition|)
block|{
name|moreToFollow
operator|=
literal|false
expr_stmt|;
block|}
if|if
condition|(
name|moreToFollow
condition|)
block|{
if|if
condition|(
name|filter
operator|!=
literal|null
condition|)
block|{
name|filter
operator|.
name|rowProcessed
argument_list|(
name|filtered
argument_list|,
name|key
operator|.
name|getRow
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|filtered
condition|)
block|{
name|results
operator|.
name|clear
argument_list|()
expr_stmt|;
block|}
block|}
block|}
do|while
condition|(
name|filtered
operator|&&
name|moreToFollow
condition|)
do|;
comment|// Make sure scanners closed if no more results
if|if
condition|(
operator|!
name|moreToFollow
condition|)
block|{
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|scanners
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
literal|null
operator|!=
name|scanners
index|[
name|i
index|]
condition|)
block|{
name|closeScanner
argument_list|(
name|i
argument_list|)
expr_stmt|;
block|}
block|}
block|}
return|return
name|moreToFollow
return|;
block|}
comment|/** Shut down a single scanner */
name|void
name|closeScanner
parameter_list|(
name|int
name|i
parameter_list|)
block|{
try|try
block|{
try|try
block|{
name|scanners
index|[
name|i
index|]
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failed closing scanner "
operator|+
name|i
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
block|}
finally|finally
block|{
name|scanners
index|[
name|i
index|]
operator|=
literal|null
expr_stmt|;
comment|// These data members can be null if exception in constructor
if|if
condition|(
name|resultSets
operator|!=
literal|null
condition|)
block|{
name|resultSets
index|[
name|i
index|]
operator|=
literal|null
expr_stmt|;
block|}
if|if
condition|(
name|keys
operator|!=
literal|null
condition|)
block|{
name|keys
index|[
name|i
index|]
operator|=
literal|null
expr_stmt|;
block|}
block|}
block|}
comment|/**      * {@inheritDoc}      */
specifier|public
name|void
name|close
parameter_list|()
block|{
try|try
block|{
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|scanners
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|scanners
index|[
name|i
index|]
operator|!=
literal|null
condition|)
block|{
name|closeScanner
argument_list|(
name|i
argument_list|)
expr_stmt|;
block|}
block|}
block|}
finally|finally
block|{
synchronized|synchronized
init|(
name|activeScannerCount
init|)
block|{
name|int
name|count
init|=
name|activeScannerCount
operator|.
name|decrementAndGet
argument_list|()
decl_stmt|;
if|if
condition|(
name|count
operator|<
literal|0
condition|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"active scanner count less than zero: "
operator|+
name|count
operator|+
literal|" resetting to zero"
argument_list|)
expr_stmt|;
name|activeScannerCount
operator|.
name|set
argument_list|(
literal|0
argument_list|)
expr_stmt|;
name|count
operator|=
literal|0
expr_stmt|;
block|}
if|if
condition|(
name|count
operator|==
literal|0
condition|)
block|{
name|activeScannerCount
operator|.
name|notifyAll
argument_list|()
expr_stmt|;
block|}
block|}
block|}
block|}
comment|/** {@inheritDoc} */
specifier|public
name|boolean
name|isWildcardScanner
parameter_list|()
block|{
throw|throw
operator|new
name|UnsupportedOperationException
argument_list|(
literal|"Unimplemented on HScanner"
argument_list|)
throw|;
block|}
comment|/** {@inheritDoc} */
specifier|public
name|boolean
name|isMultipleMatchScanner
parameter_list|()
block|{
throw|throw
operator|new
name|UnsupportedOperationException
argument_list|(
literal|"Unimplemented on HScanner"
argument_list|)
throw|;
block|}
block|}
comment|// Utility methods
comment|/**    * Convenience method creating new HRegions. Used by createTable and by the    * bootstrap code in the HMaster constructor.    * Note, this method creates an {@link HLog} for the created region. It    * needs to be closed explicitly.  Use {@link HRegion#getLog()} to get    * access.    * @param info Info for region to create.    * @param rootDir Root directory for HBase instance    * @param conf    * @return new HRegion    *     * @throws IOException    */
specifier|public
specifier|static
name|HRegion
name|createHRegion
parameter_list|(
specifier|final
name|HRegionInfo
name|info
parameter_list|,
specifier|final
name|Path
name|rootDir
parameter_list|,
specifier|final
name|HBaseConfiguration
name|conf
parameter_list|)
throws|throws
name|IOException
block|{
name|Path
name|tableDir
init|=
name|HTableDescriptor
operator|.
name|getTableDir
argument_list|(
name|rootDir
argument_list|,
name|info
operator|.
name|getTableDesc
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
name|Path
name|regionDir
init|=
name|HRegion
operator|.
name|getRegionDir
argument_list|(
name|tableDir
argument_list|,
name|info
operator|.
name|getEncodedName
argument_list|()
argument_list|)
decl_stmt|;
name|FileSystem
name|fs
init|=
name|FileSystem
operator|.
name|get
argument_list|(
name|conf
argument_list|)
decl_stmt|;
name|fs
operator|.
name|mkdirs
argument_list|(
name|regionDir
argument_list|)
expr_stmt|;
comment|// Note in historian the creation of new region.
if|if
condition|(
operator|!
name|info
operator|.
name|isMetaRegion
argument_list|()
condition|)
block|{
name|RegionHistorian
operator|.
name|getInstance
argument_list|()
operator|.
name|addRegionCreation
argument_list|(
name|info
argument_list|)
expr_stmt|;
block|}
return|return
operator|new
name|HRegion
argument_list|(
name|tableDir
argument_list|,
operator|new
name|HLog
argument_list|(
name|fs
argument_list|,
operator|new
name|Path
argument_list|(
name|regionDir
argument_list|,
name|HREGION_LOGDIR_NAME
argument_list|)
argument_list|,
name|conf
argument_list|,
literal|null
argument_list|)
argument_list|,
name|fs
argument_list|,
name|conf
argument_list|,
name|info
argument_list|,
literal|null
argument_list|,
literal|null
argument_list|)
return|;
block|}
comment|/**    * Convenience method to open a HRegion outside of an HRegionServer context.    * @param info Info for region to be opened.    * @param rootDir Root directory for HBase instance    * @param log HLog for region to use. This method will call    * HLog#setSequenceNumber(long) passing the result of the call to    * HRegion#getMinSequenceId() to ensure the log id is properly kept    * up.  HRegionStore does this every time it opens a new region.    * @param conf    * @return new HRegion    *     * @throws IOException    */
specifier|public
specifier|static
name|HRegion
name|openHRegion
parameter_list|(
specifier|final
name|HRegionInfo
name|info
parameter_list|,
specifier|final
name|Path
name|rootDir
parameter_list|,
specifier|final
name|HLog
name|log
parameter_list|,
specifier|final
name|HBaseConfiguration
name|conf
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Opening region: "
operator|+
name|info
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|info
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|NullPointerException
argument_list|(
literal|"Passed region info is null"
argument_list|)
throw|;
block|}
name|HRegion
name|r
init|=
operator|new
name|HRegion
argument_list|(
name|HTableDescriptor
operator|.
name|getTableDir
argument_list|(
name|rootDir
argument_list|,
name|info
operator|.
name|getTableDesc
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|)
argument_list|,
name|log
argument_list|,
name|FileSystem
operator|.
name|get
argument_list|(
name|conf
argument_list|)
argument_list|,
name|conf
argument_list|,
name|info
argument_list|,
literal|null
argument_list|,
literal|null
argument_list|)
decl_stmt|;
if|if
condition|(
name|log
operator|!=
literal|null
condition|)
block|{
name|log
operator|.
name|setSequenceNumber
argument_list|(
name|r
operator|.
name|getMinSequenceId
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
name|r
return|;
block|}
comment|/**    * Inserts a new region's meta information into the passed    *<code>meta</code> region. Used by the HMaster bootstrap code adding    * new table to ROOT table.    *     * @param meta META HRegion to be updated    * @param r HRegion to add to<code>meta</code>    *    * @throws IOException    */
specifier|public
specifier|static
name|void
name|addRegionToMETA
parameter_list|(
name|HRegion
name|meta
parameter_list|,
name|HRegion
name|r
parameter_list|)
throws|throws
name|IOException
block|{
name|meta
operator|.
name|checkResources
argument_list|()
expr_stmt|;
comment|// The row key is the region name
name|byte
index|[]
name|row
init|=
name|r
operator|.
name|getRegionName
argument_list|()
decl_stmt|;
name|Integer
name|lid
init|=
name|meta
operator|.
name|obtainRowLock
argument_list|(
name|row
argument_list|)
decl_stmt|;
try|try
block|{
name|HStoreKey
name|key
init|=
operator|new
name|HStoreKey
argument_list|(
name|row
argument_list|,
name|COL_REGIONINFO
argument_list|,
name|System
operator|.
name|currentTimeMillis
argument_list|()
argument_list|)
decl_stmt|;
name|TreeMap
argument_list|<
name|HStoreKey
argument_list|,
name|byte
index|[]
argument_list|>
name|edits
init|=
operator|new
name|TreeMap
argument_list|<
name|HStoreKey
argument_list|,
name|byte
index|[]
argument_list|>
argument_list|()
decl_stmt|;
name|edits
operator|.
name|put
argument_list|(
name|key
argument_list|,
name|Writables
operator|.
name|getBytes
argument_list|(
name|r
operator|.
name|getRegionInfo
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
name|meta
operator|.
name|update
argument_list|(
name|edits
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|meta
operator|.
name|releaseRowLock
argument_list|(
name|lid
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Delete a region's meta information from the passed    *<code>meta</code> region.    *     * @param srvr META server to be updated    * @param metaRegionName Meta region name    * @param regionName HRegion to remove from<code>meta</code>    *    * @throws IOException    */
specifier|public
specifier|static
name|void
name|removeRegionFromMETA
parameter_list|(
specifier|final
name|HRegionInterface
name|srvr
parameter_list|,
specifier|final
name|byte
index|[]
name|metaRegionName
parameter_list|,
specifier|final
name|byte
index|[]
name|regionName
parameter_list|)
throws|throws
name|IOException
block|{
name|srvr
operator|.
name|deleteAll
argument_list|(
name|metaRegionName
argument_list|,
name|regionName
argument_list|,
name|HConstants
operator|.
name|LATEST_TIMESTAMP
argument_list|)
expr_stmt|;
block|}
comment|/**    * Utility method used by HMaster marking regions offlined.    * @param srvr META server to be updated    * @param metaRegionName Meta region name    * @param info HRegion to update in<code>meta</code>    *    * @throws IOException    */
specifier|public
specifier|static
name|void
name|offlineRegionInMETA
parameter_list|(
specifier|final
name|HRegionInterface
name|srvr
parameter_list|,
specifier|final
name|byte
index|[]
name|metaRegionName
parameter_list|,
specifier|final
name|HRegionInfo
name|info
parameter_list|)
throws|throws
name|IOException
block|{
name|BatchUpdate
name|b
init|=
operator|new
name|BatchUpdate
argument_list|(
name|info
operator|.
name|getRegionName
argument_list|()
argument_list|)
decl_stmt|;
name|info
operator|.
name|setOffline
argument_list|(
literal|true
argument_list|)
expr_stmt|;
name|b
operator|.
name|put
argument_list|(
name|COL_REGIONINFO
argument_list|,
name|Writables
operator|.
name|getBytes
argument_list|(
name|info
argument_list|)
argument_list|)
expr_stmt|;
name|b
operator|.
name|delete
argument_list|(
name|COL_SERVER
argument_list|)
expr_stmt|;
name|b
operator|.
name|delete
argument_list|(
name|COL_STARTCODE
argument_list|)
expr_stmt|;
comment|// If carrying splits, they'll be in place when we show up on new
comment|// server.
name|srvr
operator|.
name|batchUpdate
argument_list|(
name|metaRegionName
argument_list|,
name|b
argument_list|)
expr_stmt|;
block|}
comment|/**    * Deletes all the files for a HRegion    *     * @param fs the file system object    * @param rootdir qualified path of HBase root directory    * @param info HRegionInfo for region to be deleted    * @throws IOException    */
specifier|public
specifier|static
name|void
name|deleteRegion
parameter_list|(
name|FileSystem
name|fs
parameter_list|,
name|Path
name|rootdir
parameter_list|,
name|HRegionInfo
name|info
parameter_list|)
throws|throws
name|IOException
block|{
name|deleteRegion
argument_list|(
name|fs
argument_list|,
name|HRegion
operator|.
name|getRegionDir
argument_list|(
name|rootdir
argument_list|,
name|info
argument_list|)
argument_list|)
expr_stmt|;
block|}
specifier|private
specifier|static
name|void
name|deleteRegion
parameter_list|(
name|FileSystem
name|fs
parameter_list|,
name|Path
name|regiondir
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"DELETING region "
operator|+
name|regiondir
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|fs
operator|.
name|delete
argument_list|(
name|regiondir
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
comment|/**    * Computes the Path of the HRegion    *     * @param tabledir qualified path for table    * @param name ENCODED region name    * @return Path of HRegion directory    */
specifier|public
specifier|static
name|Path
name|getRegionDir
parameter_list|(
specifier|final
name|Path
name|tabledir
parameter_list|,
specifier|final
name|int
name|name
parameter_list|)
block|{
return|return
operator|new
name|Path
argument_list|(
name|tabledir
argument_list|,
name|Integer
operator|.
name|toString
argument_list|(
name|name
argument_list|)
argument_list|)
return|;
block|}
comment|/**    * Computes the Path of the HRegion    *     * @param rootdir qualified path of HBase root directory    * @param info HRegionInfo for the region    * @return qualified path of region directory    */
specifier|public
specifier|static
name|Path
name|getRegionDir
parameter_list|(
specifier|final
name|Path
name|rootdir
parameter_list|,
specifier|final
name|HRegionInfo
name|info
parameter_list|)
block|{
return|return
operator|new
name|Path
argument_list|(
name|HTableDescriptor
operator|.
name|getTableDir
argument_list|(
name|rootdir
argument_list|,
name|info
operator|.
name|getTableDesc
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|)
argument_list|,
name|Integer
operator|.
name|toString
argument_list|(
name|info
operator|.
name|getEncodedName
argument_list|()
argument_list|)
argument_list|)
return|;
block|}
comment|/**    * Determines if the specified row is within the row range specified by the    * specified HRegionInfo    *      * @param info HRegionInfo that specifies the row range    * @param row row to be checked    * @return true if the row is within the range specified by the HRegionInfo    */
specifier|public
specifier|static
name|boolean
name|rowIsInRange
parameter_list|(
name|HRegionInfo
name|info
parameter_list|,
specifier|final
name|byte
index|[]
name|row
parameter_list|)
block|{
return|return
operator|(
operator|(
name|info
operator|.
name|getStartKey
argument_list|()
operator|.
name|length
operator|==
literal|0
operator|)
operator|||
operator|(
name|Bytes
operator|.
name|compareTo
argument_list|(
name|info
operator|.
name|getStartKey
argument_list|()
argument_list|,
name|row
argument_list|)
operator|<=
literal|0
operator|)
operator|)
operator|&&
operator|(
operator|(
name|info
operator|.
name|getEndKey
argument_list|()
operator|.
name|length
operator|==
literal|0
operator|)
operator|||
operator|(
name|Bytes
operator|.
name|compareTo
argument_list|(
name|info
operator|.
name|getEndKey
argument_list|()
argument_list|,
name|row
argument_list|)
operator|>
literal|0
operator|)
operator|)
return|;
block|}
comment|/**    * Make the directories for a specific column family    *     * @param fs the file system    * @param basedir base directory where region will live (usually the table dir)    * @param encodedRegionName encoded region name    * @param colFamily the column family    * @param tabledesc table descriptor of table    * @throws IOException    */
specifier|public
specifier|static
name|void
name|makeColumnFamilyDirs
parameter_list|(
name|FileSystem
name|fs
parameter_list|,
name|Path
name|basedir
parameter_list|,
name|int
name|encodedRegionName
parameter_list|,
name|byte
index|[]
name|colFamily
parameter_list|,
name|HTableDescriptor
name|tabledesc
parameter_list|)
throws|throws
name|IOException
block|{
name|fs
operator|.
name|mkdirs
argument_list|(
name|HStoreFile
operator|.
name|getMapDir
argument_list|(
name|basedir
argument_list|,
name|encodedRegionName
argument_list|,
name|colFamily
argument_list|)
argument_list|)
expr_stmt|;
name|fs
operator|.
name|mkdirs
argument_list|(
name|HStoreFile
operator|.
name|getInfoDir
argument_list|(
name|basedir
argument_list|,
name|encodedRegionName
argument_list|,
name|colFamily
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
end_class

end_unit

