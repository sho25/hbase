begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Copyright 2007 The Apache Software Foundation  *  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|EOFException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|FileNotFoundException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collections
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|SortedMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|TreeMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|TreeSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|locks
operator|.
name|Lock
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|locks
operator|.
name|ReentrantLock
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|Log
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|LogFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileStatus
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Syncable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HBaseConfiguration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HConstants
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HRegionInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HStoreKey
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HTableDescriptor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|RemoteExceptionHandler
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|Bytes
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|FSUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|SequenceFile
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|Text
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|SequenceFile
operator|.
name|CompressionType
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|SequenceFile
operator|.
name|Reader
import|;
end_import

begin_comment
comment|/**  * HLog stores all the edits to the HStore.  *  * It performs logfile-rolling, so external callers are not aware that the  * underlying file is being rolled.  *  *<p>  * A single HLog is used by several HRegions simultaneously.  *  *<p>  * Each HRegion is identified by a unique long<code>int</code>. HRegions do  * not need to declare themselves before using the HLog; they simply include  * their HRegion-id in the<code>append</code> or  *<code>completeCacheFlush</code> calls.  *  *<p>  * An HLog consists of multiple on-disk files, which have a chronological order.  * As data is flushed to other (better) on-disk structures, the log becomes  * obsolete. We can destroy all the log messages for a given HRegion-id up to  * the most-recent CACHEFLUSH message from that HRegion.  *  *<p>  * It's only practical to delete entire files. Thus, we delete an entire on-disk  * file F when all of the messages in F have a log-sequence-id that's older  * (smaller) than the most-recent CACHEFLUSH message for every HRegion that has  * a message in F.  *  *<p>  * Synchronized methods can never execute in parallel. However, between the  * start of a cache flush and the completion point, appends are allowed but log  * rolling is not. To prevent log rolling taking place during this period, a  * separate reentrant lock is used.  *  */
end_comment

begin_class
specifier|public
class|class
name|HLog
extends|extends
name|Thread
implements|implements
name|HConstants
implements|,
name|Syncable
block|{
specifier|private
specifier|static
specifier|final
name|Log
name|LOG
init|=
name|LogFactory
operator|.
name|getLog
argument_list|(
name|HLog
operator|.
name|class
argument_list|)
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|String
name|HLOG_DATFILE
init|=
literal|"hlog.dat."
decl_stmt|;
specifier|static
specifier|final
name|byte
index|[]
name|METACOLUMN
init|=
name|Bytes
operator|.
name|toBytes
argument_list|(
literal|"METACOLUMN:"
argument_list|)
decl_stmt|;
specifier|static
specifier|final
name|byte
index|[]
name|METAROW
init|=
name|Bytes
operator|.
name|toBytes
argument_list|(
literal|"METAROW"
argument_list|)
decl_stmt|;
specifier|final
name|FileSystem
name|fs
decl_stmt|;
specifier|final
name|Path
name|dir
decl_stmt|;
specifier|final
name|Configuration
name|conf
decl_stmt|;
specifier|final
name|LogRollListener
name|listener
decl_stmt|;
specifier|private
specifier|final
name|int
name|maxlogentries
decl_stmt|;
specifier|private
specifier|final
name|long
name|optionalFlushInterval
decl_stmt|;
specifier|private
specifier|final
name|int
name|flushlogentries
decl_stmt|;
specifier|private
specifier|volatile
name|int
name|unflushedEntries
init|=
literal|0
decl_stmt|;
specifier|private
specifier|volatile
name|long
name|lastLogFlushTime
decl_stmt|;
specifier|final
name|long
name|threadWakeFrequency
decl_stmt|;
comment|/*    * Current log file.    */
name|SequenceFile
operator|.
name|Writer
name|writer
decl_stmt|;
comment|/*    * Map of all log files but the current one.     */
specifier|final
name|SortedMap
argument_list|<
name|Long
argument_list|,
name|Path
argument_list|>
name|outputfiles
init|=
name|Collections
operator|.
name|synchronizedSortedMap
argument_list|(
operator|new
name|TreeMap
argument_list|<
name|Long
argument_list|,
name|Path
argument_list|>
argument_list|()
argument_list|)
decl_stmt|;
comment|/*    * Map of region to last sequence/edit id.     */
specifier|private
specifier|final
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|Long
argument_list|>
name|lastSeqWritten
init|=
name|Collections
operator|.
name|synchronizedSortedMap
argument_list|(
operator|new
name|TreeMap
argument_list|<
name|byte
index|[]
argument_list|,
name|Long
argument_list|>
argument_list|(
name|Bytes
operator|.
name|BYTES_COMPARATOR
argument_list|)
argument_list|)
decl_stmt|;
specifier|private
specifier|volatile
name|boolean
name|closed
init|=
literal|false
decl_stmt|;
specifier|private
specifier|final
name|Integer
name|sequenceLock
init|=
operator|new
name|Integer
argument_list|(
literal|0
argument_list|)
decl_stmt|;
specifier|private
specifier|volatile
name|long
name|logSeqNum
init|=
literal|0
decl_stmt|;
specifier|private
specifier|volatile
name|long
name|filenum
init|=
literal|0
decl_stmt|;
specifier|private
specifier|volatile
name|long
name|old_filenum
init|=
operator|-
literal|1
decl_stmt|;
specifier|private
specifier|volatile
name|int
name|numEntries
init|=
literal|0
decl_stmt|;
comment|// This lock prevents starting a log roll during a cache flush.
comment|// synchronized is insufficient because a cache flush spans two method calls.
specifier|private
specifier|final
name|Lock
name|cacheFlushLock
init|=
operator|new
name|ReentrantLock
argument_list|()
decl_stmt|;
comment|// We synchronize on updateLock to prevent updates and to prevent a log roll
comment|// during an update
specifier|private
specifier|final
name|Integer
name|updateLock
init|=
operator|new
name|Integer
argument_list|(
literal|0
argument_list|)
decl_stmt|;
comment|/**    * Create an edit log at the given<code>dir</code> location.    *    * You should never have to load an existing log. If there is a log at    * startup, it should have already been processed and deleted by the time the    * HLog object is started up.    *    * @param fs    * @param dir    * @param conf    * @param listener    * @throws IOException    */
specifier|public
name|HLog
parameter_list|(
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Path
name|dir
parameter_list|,
specifier|final
name|Configuration
name|conf
parameter_list|,
specifier|final
name|LogRollListener
name|listener
parameter_list|)
throws|throws
name|IOException
block|{
name|super
argument_list|()
expr_stmt|;
name|this
operator|.
name|fs
operator|=
name|fs
expr_stmt|;
name|this
operator|.
name|dir
operator|=
name|dir
expr_stmt|;
name|this
operator|.
name|conf
operator|=
name|conf
expr_stmt|;
name|this
operator|.
name|listener
operator|=
name|listener
expr_stmt|;
name|this
operator|.
name|setName
argument_list|(
name|this
operator|.
name|getClass
argument_list|()
operator|.
name|getSimpleName
argument_list|()
argument_list|)
expr_stmt|;
name|this
operator|.
name|maxlogentries
operator|=
name|conf
operator|.
name|getInt
argument_list|(
literal|"hbase.regionserver.maxlogentries"
argument_list|,
literal|100000
argument_list|)
expr_stmt|;
name|this
operator|.
name|flushlogentries
operator|=
name|conf
operator|.
name|getInt
argument_list|(
literal|"hbase.regionserver.flushlogentries"
argument_list|,
literal|100
argument_list|)
expr_stmt|;
name|this
operator|.
name|optionalFlushInterval
operator|=
name|conf
operator|.
name|getLong
argument_list|(
literal|"hbase.regionserver.optionallogflushinterval"
argument_list|,
literal|10
operator|*
literal|1000
argument_list|)
expr_stmt|;
name|this
operator|.
name|threadWakeFrequency
operator|=
name|conf
operator|.
name|getLong
argument_list|(
name|THREAD_WAKE_FREQUENCY
argument_list|,
literal|10
operator|*
literal|1000
argument_list|)
expr_stmt|;
name|this
operator|.
name|lastLogFlushTime
operator|=
name|System
operator|.
name|currentTimeMillis
argument_list|()
expr_stmt|;
if|if
condition|(
name|fs
operator|.
name|exists
argument_list|(
name|dir
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Target HLog directory already exists: "
operator|+
name|dir
argument_list|)
throw|;
block|}
name|fs
operator|.
name|mkdirs
argument_list|(
name|dir
argument_list|)
expr_stmt|;
name|rollWriter
argument_list|()
expr_stmt|;
block|}
comment|/*    * Accessor for tests. Not a part of the public API.    * @return Current state of the monotonically increasing file id.    */
specifier|public
name|long
name|getFilenum
parameter_list|()
block|{
return|return
name|this
operator|.
name|filenum
return|;
block|}
comment|/**    * Get the compression type for the hlog files.    * @param c Configuration to use.    * @return the kind of compression to use    */
specifier|private
specifier|static
name|CompressionType
name|getCompressionType
parameter_list|(
specifier|final
name|Configuration
name|c
parameter_list|)
block|{
name|String
name|name
init|=
name|c
operator|.
name|get
argument_list|(
literal|"hbase.io.seqfile.compression.type"
argument_list|)
decl_stmt|;
return|return
name|name
operator|==
literal|null
condition|?
name|CompressionType
operator|.
name|NONE
else|:
name|CompressionType
operator|.
name|valueOf
argument_list|(
name|name
argument_list|)
return|;
block|}
comment|/**    * Called by HRegionServer when it opens a new region to ensure that log    * sequence numbers are always greater than the latest sequence number of the    * region being brought on-line.    *    * @param newvalue We'll set log edit/sequence number to this value if it    * is greater than the current value.    */
name|void
name|setSequenceNumber
parameter_list|(
name|long
name|newvalue
parameter_list|)
block|{
synchronized|synchronized
init|(
name|sequenceLock
init|)
block|{
if|if
condition|(
name|newvalue
operator|>
name|logSeqNum
condition|)
block|{
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"changing sequence number from "
operator|+
name|logSeqNum
operator|+
literal|" to "
operator|+
name|newvalue
argument_list|)
expr_stmt|;
block|}
name|logSeqNum
operator|=
name|newvalue
expr_stmt|;
block|}
block|}
block|}
comment|/**    * @return log sequence number    */
specifier|public
name|long
name|getSequenceNumber
parameter_list|()
block|{
return|return
name|logSeqNum
return|;
block|}
comment|/**    * Roll the log writer. That is, start writing log messages to a new file.    *    * Because a log cannot be rolled during a cache flush, and a cache flush    * spans two method calls, a special lock needs to be obtained so that a cache    * flush cannot start when the log is being rolled and the log cannot be    * rolled during a cache flush.    *    *<p>Note that this method cannot be synchronized because it is possible that    * startCacheFlush runs, obtaining the cacheFlushLock, then this method could    * start which would obtain the lock on this but block on obtaining the    * cacheFlushLock and then completeCacheFlush could be called which would wait    * for the lock on this and consequently never release the cacheFlushLock    *    * @throws FailedLogCloseException    * @throws IOException    */
specifier|public
name|void
name|rollWriter
parameter_list|()
throws|throws
name|FailedLogCloseException
throws|,
name|IOException
block|{
name|this
operator|.
name|cacheFlushLock
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
if|if
condition|(
name|closed
condition|)
block|{
return|return;
block|}
synchronized|synchronized
init|(
name|updateLock
init|)
block|{
if|if
condition|(
name|this
operator|.
name|writer
operator|!=
literal|null
condition|)
block|{
comment|// Close the current writer, get a new one.
try|try
block|{
name|this
operator|.
name|writer
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
comment|// Failed close of log file.  Means we're losing edits.  For now,
comment|// shut ourselves down to minimize loss.  Alternative is to try and
comment|// keep going.  See HBASE-930.
name|FailedLogCloseException
name|flce
init|=
operator|new
name|FailedLogCloseException
argument_list|(
literal|"#"
operator|+
name|this
operator|.
name|filenum
argument_list|)
decl_stmt|;
name|flce
operator|.
name|initCause
argument_list|(
name|e
argument_list|)
expr_stmt|;
throw|throw
name|e
throw|;
block|}
name|Path
name|p
init|=
name|computeFilename
argument_list|(
name|old_filenum
argument_list|)
decl_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Closing current log writer "
operator|+
name|FSUtils
operator|.
name|getPath
argument_list|(
name|p
argument_list|)
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|filenum
operator|>
literal|0
condition|)
block|{
synchronized|synchronized
init|(
name|this
operator|.
name|sequenceLock
init|)
block|{
name|this
operator|.
name|outputfiles
operator|.
name|put
argument_list|(
name|Long
operator|.
name|valueOf
argument_list|(
name|this
operator|.
name|logSeqNum
operator|-
literal|1
argument_list|)
argument_list|,
name|p
argument_list|)
expr_stmt|;
block|}
block|}
block|}
name|old_filenum
operator|=
name|filenum
expr_stmt|;
name|filenum
operator|=
name|System
operator|.
name|currentTimeMillis
argument_list|()
expr_stmt|;
name|Path
name|newPath
init|=
name|computeFilename
argument_list|(
name|filenum
argument_list|)
decl_stmt|;
name|this
operator|.
name|writer
operator|=
name|SequenceFile
operator|.
name|createWriter
argument_list|(
name|this
operator|.
name|fs
argument_list|,
name|this
operator|.
name|conf
argument_list|,
name|newPath
argument_list|,
name|HLogKey
operator|.
name|class
argument_list|,
name|HLogEdit
operator|.
name|class
argument_list|,
name|getCompressionType
argument_list|(
name|this
operator|.
name|conf
argument_list|)
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"New log writer created at "
operator|+
name|FSUtils
operator|.
name|getPath
argument_list|(
name|newPath
argument_list|)
argument_list|)
expr_stmt|;
comment|// Can we delete any of the old log files?
if|if
condition|(
name|this
operator|.
name|outputfiles
operator|.
name|size
argument_list|()
operator|>
literal|0
condition|)
block|{
if|if
condition|(
name|this
operator|.
name|lastSeqWritten
operator|.
name|size
argument_list|()
operator|<=
literal|0
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Last sequence written is empty. Deleting all old hlogs"
argument_list|)
expr_stmt|;
comment|// If so, then no new writes have come in since all regions were
comment|// flushed (and removed from the lastSeqWritten map). Means can
comment|// remove all but currently open log file.
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|Long
argument_list|,
name|Path
argument_list|>
name|e
range|:
name|this
operator|.
name|outputfiles
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|deleteLogFile
argument_list|(
name|e
operator|.
name|getValue
argument_list|()
argument_list|,
name|e
operator|.
name|getKey
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|this
operator|.
name|outputfiles
operator|.
name|clear
argument_list|()
expr_stmt|;
block|}
else|else
block|{
comment|// Get oldest edit/sequence id.  If logs are older than this id,
comment|// then safe to remove.
name|Long
name|oldestOutstandingSeqNum
init|=
name|Collections
operator|.
name|min
argument_list|(
name|this
operator|.
name|lastSeqWritten
operator|.
name|values
argument_list|()
argument_list|)
decl_stmt|;
comment|// Get the set of all log files whose final ID is older than or
comment|// equal to the oldest pending region operation
name|TreeSet
argument_list|<
name|Long
argument_list|>
name|sequenceNumbers
init|=
operator|new
name|TreeSet
argument_list|<
name|Long
argument_list|>
argument_list|(
name|this
operator|.
name|outputfiles
operator|.
name|headMap
argument_list|(
operator|(
name|Long
operator|.
name|valueOf
argument_list|(
name|oldestOutstandingSeqNum
operator|.
name|longValue
argument_list|()
operator|+
literal|1L
argument_list|)
operator|)
argument_list|)
operator|.
name|keySet
argument_list|()
argument_list|)
decl_stmt|;
comment|// Now remove old log files (if any)
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
comment|// Find region associated with oldest key -- helps debugging.
name|byte
index|[]
name|oldestRegion
init|=
literal|null
decl_stmt|;
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|byte
index|[]
argument_list|,
name|Long
argument_list|>
name|e
range|:
name|this
operator|.
name|lastSeqWritten
operator|.
name|entrySet
argument_list|()
control|)
block|{
if|if
condition|(
name|e
operator|.
name|getValue
argument_list|()
operator|.
name|longValue
argument_list|()
operator|==
name|oldestOutstandingSeqNum
operator|.
name|longValue
argument_list|()
condition|)
block|{
name|oldestRegion
operator|=
name|e
operator|.
name|getKey
argument_list|()
expr_stmt|;
break|break;
block|}
block|}
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
operator|&&
name|sequenceNumbers
operator|.
name|size
argument_list|()
operator|>
literal|0
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Found "
operator|+
name|sequenceNumbers
operator|.
name|size
argument_list|()
operator|+
literal|" logs to remove "
operator|+
literal|"using oldest outstanding seqnum of "
operator|+
name|oldestOutstandingSeqNum
operator|+
literal|" from region "
operator|+
name|Bytes
operator|.
name|toString
argument_list|(
name|oldestRegion
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|sequenceNumbers
operator|.
name|size
argument_list|()
operator|>
literal|0
condition|)
block|{
for|for
control|(
name|Long
name|seq
range|:
name|sequenceNumbers
control|)
block|{
name|deleteLogFile
argument_list|(
name|this
operator|.
name|outputfiles
operator|.
name|remove
argument_list|(
name|seq
argument_list|)
argument_list|,
name|seq
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
name|this
operator|.
name|numEntries
operator|=
literal|0
expr_stmt|;
name|updateLock
operator|.
name|notifyAll
argument_list|()
expr_stmt|;
block|}
block|}
finally|finally
block|{
name|this
operator|.
name|cacheFlushLock
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
specifier|private
name|void
name|deleteLogFile
parameter_list|(
specifier|final
name|Path
name|p
parameter_list|,
specifier|final
name|Long
name|seqno
parameter_list|)
throws|throws
name|IOException
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"removing old log file "
operator|+
name|FSUtils
operator|.
name|getPath
argument_list|(
name|p
argument_list|)
operator|+
literal|" whose highest sequence/edit id is "
operator|+
name|seqno
argument_list|)
expr_stmt|;
name|this
operator|.
name|fs
operator|.
name|delete
argument_list|(
name|p
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
comment|/**    * This is a convenience method that computes a new filename with a given    * file-number.    * @param fn    * @return Path    */
specifier|public
name|Path
name|computeFilename
parameter_list|(
specifier|final
name|long
name|fn
parameter_list|)
block|{
return|return
operator|new
name|Path
argument_list|(
name|dir
argument_list|,
name|HLOG_DATFILE
operator|+
name|fn
argument_list|)
return|;
block|}
comment|/**    * Shut down the log and delete the log directory    *    * @throws IOException    */
specifier|public
name|void
name|closeAndDelete
parameter_list|()
throws|throws
name|IOException
block|{
name|close
argument_list|()
expr_stmt|;
name|fs
operator|.
name|delete
argument_list|(
name|dir
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
comment|/**    * Shut down the log.    *    * @throws IOException    */
specifier|public
name|void
name|close
parameter_list|()
throws|throws
name|IOException
block|{
name|cacheFlushLock
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
synchronized|synchronized
init|(
name|updateLock
init|)
block|{
name|this
operator|.
name|closed
operator|=
literal|true
expr_stmt|;
if|if
condition|(
name|this
operator|.
name|isAlive
argument_list|()
condition|)
block|{
name|this
operator|.
name|interrupt
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"closing log writer in "
operator|+
name|this
operator|.
name|dir
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|this
operator|.
name|writer
operator|.
name|close
argument_list|()
expr_stmt|;
name|updateLock
operator|.
name|notifyAll
argument_list|()
expr_stmt|;
block|}
block|}
finally|finally
block|{
name|cacheFlushLock
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**    * Append a set of edits to the log. Log edits are keyed by regionName,    * rowname, and log-sequence-id.    *    * Later, if we sort by these keys, we obtain all the relevant edits for a    * given key-range of the HRegion (TODO). Any edits that do not have a    * matching {@link HConstants#COMPLETE_CACHEFLUSH} message can be discarded.    *    *<p>    * Logs cannot be restarted once closed, or once the HLog process dies. Each    * time the HLog starts, it must create a new log. This means that other    * systems should process the log appropriately upon each startup (and prior    * to initializing HLog).    *    * synchronized prevents appends during the completion of a cache flush or for    * the duration of a log roll.    *    * @param regionName    * @param tableName    * @param row    * @param columns    * @param timestamp    * @throws IOException    */
name|void
name|append
parameter_list|(
name|byte
index|[]
name|regionName
parameter_list|,
name|byte
index|[]
name|tableName
parameter_list|,
name|TreeMap
argument_list|<
name|HStoreKey
argument_list|,
name|byte
index|[]
argument_list|>
name|edits
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|closed
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Cannot append; log is closed"
argument_list|)
throw|;
block|}
synchronized|synchronized
init|(
name|updateLock
init|)
block|{
name|long
name|seqNum
index|[]
init|=
name|obtainSeqNum
argument_list|(
name|edits
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
comment|// The 'lastSeqWritten' map holds the sequence number of the oldest
comment|// write for each region. When the cache is flushed, the entry for the
comment|// region being flushed is removed if the sequence number of the flush
comment|// is greater than or equal to the value in lastSeqWritten.
if|if
condition|(
operator|!
name|this
operator|.
name|lastSeqWritten
operator|.
name|containsKey
argument_list|(
name|regionName
argument_list|)
condition|)
block|{
name|this
operator|.
name|lastSeqWritten
operator|.
name|put
argument_list|(
name|regionName
argument_list|,
name|Long
operator|.
name|valueOf
argument_list|(
name|seqNum
index|[
literal|0
index|]
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|int
name|counter
init|=
literal|0
decl_stmt|;
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|HStoreKey
argument_list|,
name|byte
index|[]
argument_list|>
name|es
range|:
name|edits
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|HStoreKey
name|key
init|=
name|es
operator|.
name|getKey
argument_list|()
decl_stmt|;
name|HLogKey
name|logKey
init|=
operator|new
name|HLogKey
argument_list|(
name|regionName
argument_list|,
name|tableName
argument_list|,
name|key
operator|.
name|getRow
argument_list|()
argument_list|,
name|seqNum
index|[
name|counter
operator|++
index|]
argument_list|)
decl_stmt|;
name|HLogEdit
name|logEdit
init|=
operator|new
name|HLogEdit
argument_list|(
name|key
operator|.
name|getColumn
argument_list|()
argument_list|,
name|es
operator|.
name|getValue
argument_list|()
argument_list|,
name|key
operator|.
name|getTimestamp
argument_list|()
argument_list|)
decl_stmt|;
name|doWrite
argument_list|(
name|logKey
argument_list|,
name|logEdit
argument_list|)
expr_stmt|;
name|this
operator|.
name|numEntries
operator|++
expr_stmt|;
block|}
name|updateLock
operator|.
name|notifyAll
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|this
operator|.
name|numEntries
operator|>
name|this
operator|.
name|maxlogentries
condition|)
block|{
name|requestLogRoll
argument_list|()
expr_stmt|;
block|}
block|}
comment|/** {@inheritDoc} */
annotation|@
name|Override
specifier|public
name|void
name|run
parameter_list|()
block|{
while|while
condition|(
operator|!
name|this
operator|.
name|closed
condition|)
block|{
synchronized|synchronized
init|(
name|updateLock
init|)
block|{
if|if
condition|(
operator|(
operator|(
name|System
operator|.
name|currentTimeMillis
argument_list|()
operator|-
name|this
operator|.
name|optionalFlushInterval
operator|)
operator|>
name|this
operator|.
name|lastLogFlushTime
operator|)
operator|&&
name|this
operator|.
name|unflushedEntries
operator|>
literal|0
condition|)
block|{
try|try
block|{
name|sync
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Error flushing HLog"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
block|}
try|try
block|{
name|updateLock
operator|.
name|wait
argument_list|(
name|this
operator|.
name|threadWakeFrequency
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
comment|// continue
block|}
block|}
block|}
block|}
specifier|public
name|void
name|sync
parameter_list|()
throws|throws
name|IOException
block|{
name|lastLogFlushTime
operator|=
name|System
operator|.
name|currentTimeMillis
argument_list|()
expr_stmt|;
name|this
operator|.
name|writer
operator|.
name|sync
argument_list|()
expr_stmt|;
name|unflushedEntries
operator|=
literal|0
expr_stmt|;
block|}
specifier|private
name|void
name|requestLogRoll
parameter_list|()
block|{
if|if
condition|(
name|this
operator|.
name|listener
operator|!=
literal|null
condition|)
block|{
name|this
operator|.
name|listener
operator|.
name|logRollRequested
argument_list|()
expr_stmt|;
block|}
block|}
specifier|private
name|void
name|doWrite
parameter_list|(
name|HLogKey
name|logKey
parameter_list|,
name|HLogEdit
name|logEdit
parameter_list|)
throws|throws
name|IOException
block|{
try|try
block|{
name|this
operator|.
name|writer
operator|.
name|append
argument_list|(
name|logKey
argument_list|,
name|logEdit
argument_list|)
expr_stmt|;
if|if
condition|(
operator|++
name|unflushedEntries
operator|>=
name|flushlogentries
condition|)
block|{
name|sync
argument_list|()
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|fatal
argument_list|(
literal|"Could not append. Requesting close of log"
argument_list|,
name|e
argument_list|)
expr_stmt|;
name|requestLogRoll
argument_list|()
expr_stmt|;
throw|throw
name|e
throw|;
block|}
block|}
comment|/** Append an entry without a row to the log.    *     * @param regionInfo    * @param logEdit    * @throws IOException    */
specifier|public
name|void
name|append
parameter_list|(
name|HRegionInfo
name|regionInfo
parameter_list|,
name|HLogEdit
name|logEdit
parameter_list|)
throws|throws
name|IOException
block|{
name|this
operator|.
name|append
argument_list|(
name|regionInfo
argument_list|,
operator|new
name|byte
index|[
literal|0
index|]
argument_list|,
name|logEdit
argument_list|)
expr_stmt|;
block|}
comment|/** Append an entry to the log.    *     * @param regionInfo    * @param row    * @param logEdit    * @throws IOException    */
specifier|public
name|void
name|append
parameter_list|(
name|HRegionInfo
name|regionInfo
parameter_list|,
name|byte
index|[]
name|row
parameter_list|,
name|HLogEdit
name|logEdit
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|closed
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Cannot append; log is closed"
argument_list|)
throw|;
block|}
name|byte
index|[]
name|regionName
init|=
name|regionInfo
operator|.
name|getRegionName
argument_list|()
decl_stmt|;
name|byte
index|[]
name|tableName
init|=
name|regionInfo
operator|.
name|getTableDesc
argument_list|()
operator|.
name|getName
argument_list|()
decl_stmt|;
synchronized|synchronized
init|(
name|updateLock
init|)
block|{
name|long
name|seqNum
init|=
name|obtainSeqNum
argument_list|()
decl_stmt|;
comment|// The 'lastSeqWritten' map holds the sequence number of the oldest
comment|// write for each region. When the cache is flushed, the entry for the
comment|// region being flushed is removed if the sequence number of the flush
comment|// is greater than or equal to the value in lastSeqWritten.
if|if
condition|(
operator|!
name|this
operator|.
name|lastSeqWritten
operator|.
name|containsKey
argument_list|(
name|regionName
argument_list|)
condition|)
block|{
name|this
operator|.
name|lastSeqWritten
operator|.
name|put
argument_list|(
name|regionName
argument_list|,
name|Long
operator|.
name|valueOf
argument_list|(
name|seqNum
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|HLogKey
name|logKey
init|=
operator|new
name|HLogKey
argument_list|(
name|regionName
argument_list|,
name|tableName
argument_list|,
name|row
argument_list|,
name|seqNum
argument_list|)
decl_stmt|;
name|doWrite
argument_list|(
name|logKey
argument_list|,
name|logEdit
argument_list|)
expr_stmt|;
name|this
operator|.
name|numEntries
operator|++
expr_stmt|;
name|updateLock
operator|.
name|notifyAll
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|this
operator|.
name|numEntries
operator|>
name|this
operator|.
name|maxlogentries
condition|)
block|{
if|if
condition|(
name|listener
operator|!=
literal|null
condition|)
block|{
name|listener
operator|.
name|logRollRequested
argument_list|()
expr_stmt|;
block|}
block|}
block|}
comment|/** @return How many items have been added to the log */
name|int
name|getNumEntries
parameter_list|()
block|{
return|return
name|numEntries
return|;
block|}
comment|/**    * Obtain a log sequence number.    */
specifier|private
name|long
name|obtainSeqNum
parameter_list|()
block|{
name|long
name|value
decl_stmt|;
synchronized|synchronized
init|(
name|sequenceLock
init|)
block|{
name|value
operator|=
name|logSeqNum
operator|++
expr_stmt|;
block|}
return|return
name|value
return|;
block|}
comment|/** @return the number of log files in use */
name|int
name|getNumLogFiles
parameter_list|()
block|{
return|return
name|outputfiles
operator|.
name|size
argument_list|()
return|;
block|}
comment|/**    * Obtain a specified number of sequence numbers    *    * @param num number of sequence numbers to obtain    * @return array of sequence numbers    */
specifier|private
name|long
index|[]
name|obtainSeqNum
parameter_list|(
name|int
name|num
parameter_list|)
block|{
name|long
index|[]
name|results
init|=
operator|new
name|long
index|[
name|num
index|]
decl_stmt|;
synchronized|synchronized
init|(
name|this
operator|.
name|sequenceLock
init|)
block|{
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|num
condition|;
name|i
operator|++
control|)
block|{
name|results
index|[
name|i
index|]
operator|=
name|this
operator|.
name|logSeqNum
operator|++
expr_stmt|;
block|}
block|}
return|return
name|results
return|;
block|}
comment|/**    * By acquiring a log sequence ID, we can allow log messages to continue while    * we flush the cache.    *    * Acquire a lock so that we do not roll the log between the start and    * completion of a cache-flush. Otherwise the log-seq-id for the flush will    * not appear in the correct logfile.    *    * @return sequence ID to pass {@link #completeCacheFlush(Text, Text, long)}    * @see #completeCacheFlush(Text, Text, long)    * @see #abortCacheFlush()    */
name|long
name|startCacheFlush
parameter_list|()
block|{
name|this
operator|.
name|cacheFlushLock
operator|.
name|lock
argument_list|()
expr_stmt|;
return|return
name|obtainSeqNum
argument_list|()
return|;
block|}
comment|/**    * Complete the cache flush    *    * Protected by cacheFlushLock    *    * @param regionName    * @param tableName    * @param logSeqId    * @throws IOException    */
name|void
name|completeCacheFlush
parameter_list|(
specifier|final
name|byte
index|[]
name|regionName
parameter_list|,
specifier|final
name|byte
index|[]
name|tableName
parameter_list|,
specifier|final
name|long
name|logSeqId
parameter_list|)
throws|throws
name|IOException
block|{
try|try
block|{
if|if
condition|(
name|this
operator|.
name|closed
condition|)
block|{
return|return;
block|}
synchronized|synchronized
init|(
name|updateLock
init|)
block|{
name|this
operator|.
name|writer
operator|.
name|append
argument_list|(
operator|new
name|HLogKey
argument_list|(
name|regionName
argument_list|,
name|tableName
argument_list|,
name|HLog
operator|.
name|METAROW
argument_list|,
name|logSeqId
argument_list|)
argument_list|,
operator|new
name|HLogEdit
argument_list|(
name|HLog
operator|.
name|METACOLUMN
argument_list|,
name|HLogEdit
operator|.
name|completeCacheFlush
operator|.
name|get
argument_list|()
argument_list|,
name|System
operator|.
name|currentTimeMillis
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
name|this
operator|.
name|numEntries
operator|++
expr_stmt|;
name|Long
name|seq
init|=
name|this
operator|.
name|lastSeqWritten
operator|.
name|get
argument_list|(
name|regionName
argument_list|)
decl_stmt|;
if|if
condition|(
name|seq
operator|!=
literal|null
operator|&&
name|logSeqId
operator|>=
name|seq
operator|.
name|longValue
argument_list|()
condition|)
block|{
name|this
operator|.
name|lastSeqWritten
operator|.
name|remove
argument_list|(
name|regionName
argument_list|)
expr_stmt|;
block|}
name|updateLock
operator|.
name|notifyAll
argument_list|()
expr_stmt|;
block|}
block|}
finally|finally
block|{
name|this
operator|.
name|cacheFlushLock
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**    * Abort a cache flush.    * Call if the flush fails. Note that the only recovery for an aborted flush    * currently is a restart of the regionserver so the snapshot content dropped    * by the failure gets restored to the memcache.    */
name|void
name|abortCacheFlush
parameter_list|()
block|{
name|this
operator|.
name|cacheFlushLock
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
comment|/**    * @param column    * @return true if the column is a meta column    */
specifier|public
specifier|static
name|boolean
name|isMetaColumn
parameter_list|(
name|byte
index|[]
name|column
parameter_list|)
block|{
return|return
name|Bytes
operator|.
name|equals
argument_list|(
name|METACOLUMN
argument_list|,
name|column
argument_list|)
return|;
block|}
comment|/**    * Split up a bunch of log files, that are no longer being written to, into    * new files, one per region. Delete the old log files when finished.    *    * @param rootDir qualified root directory of the HBase instance    * @param srcDir Directory of log files to split: e.g.    *<code>${ROOTDIR}/log_HOST_PORT</code>    * @param fs FileSystem    * @param conf HBaseConfiguration    * @throws IOException    */
specifier|public
specifier|static
name|void
name|splitLog
parameter_list|(
name|Path
name|rootDir
parameter_list|,
name|Path
name|srcDir
parameter_list|,
name|FileSystem
name|fs
parameter_list|,
name|Configuration
name|conf
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
operator|!
name|fs
operator|.
name|exists
argument_list|(
name|srcDir
argument_list|)
condition|)
block|{
comment|// Nothing to do
return|return;
block|}
name|FileStatus
name|logfiles
index|[]
init|=
name|fs
operator|.
name|listStatus
argument_list|(
name|srcDir
argument_list|)
decl_stmt|;
if|if
condition|(
name|logfiles
operator|==
literal|null
operator|||
name|logfiles
operator|.
name|length
operator|==
literal|0
condition|)
block|{
comment|// Nothing to do
return|return;
block|}
name|LOG
operator|.
name|info
argument_list|(
literal|"splitting "
operator|+
name|logfiles
operator|.
name|length
operator|+
literal|" log(s) in "
operator|+
name|srcDir
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|SequenceFile
operator|.
name|Writer
argument_list|>
name|logWriters
init|=
operator|new
name|TreeMap
argument_list|<
name|byte
index|[]
argument_list|,
name|SequenceFile
operator|.
name|Writer
argument_list|>
argument_list|(
name|Bytes
operator|.
name|BYTES_COMPARATOR
argument_list|)
decl_stmt|;
try|try
block|{
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|logfiles
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Splitting "
operator|+
name|i
operator|+
literal|" of "
operator|+
name|logfiles
operator|.
name|length
operator|+
literal|": "
operator|+
name|logfiles
index|[
name|i
index|]
operator|.
name|getPath
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|// Check for empty file.
if|if
condition|(
name|logfiles
index|[
name|i
index|]
operator|.
name|getLen
argument_list|()
operator|<=
literal|0
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Skipping "
operator|+
name|logfiles
index|[
name|i
index|]
operator|.
name|toString
argument_list|()
operator|+
literal|" because zero length"
argument_list|)
expr_stmt|;
continue|continue;
block|}
name|HLogKey
name|key
init|=
operator|new
name|HLogKey
argument_list|()
decl_stmt|;
name|HLogEdit
name|val
init|=
operator|new
name|HLogEdit
argument_list|()
decl_stmt|;
name|SequenceFile
operator|.
name|Reader
name|in
init|=
operator|new
name|SequenceFile
operator|.
name|Reader
argument_list|(
name|fs
argument_list|,
name|logfiles
index|[
name|i
index|]
operator|.
name|getPath
argument_list|()
argument_list|,
name|conf
argument_list|)
decl_stmt|;
try|try
block|{
name|int
name|count
init|=
literal|0
decl_stmt|;
for|for
control|(
init|;
name|in
operator|.
name|next
argument_list|(
name|key
argument_list|,
name|val
argument_list|)
condition|;
name|count
operator|++
control|)
block|{
name|byte
index|[]
name|tableName
init|=
name|key
operator|.
name|getTablename
argument_list|()
decl_stmt|;
name|byte
index|[]
name|regionName
init|=
name|key
operator|.
name|getRegionName
argument_list|()
decl_stmt|;
name|SequenceFile
operator|.
name|Writer
name|w
init|=
name|logWriters
operator|.
name|get
argument_list|(
name|regionName
argument_list|)
decl_stmt|;
if|if
condition|(
name|w
operator|==
literal|null
condition|)
block|{
name|Path
name|logfile
init|=
operator|new
name|Path
argument_list|(
name|HRegion
operator|.
name|getRegionDir
argument_list|(
name|HTableDescriptor
operator|.
name|getTableDir
argument_list|(
name|rootDir
argument_list|,
name|tableName
argument_list|)
argument_list|,
name|HRegionInfo
operator|.
name|encodeRegionName
argument_list|(
name|regionName
argument_list|)
argument_list|)
argument_list|,
name|HREGION_OLDLOGFILE_NAME
argument_list|)
decl_stmt|;
name|Path
name|oldlogfile
init|=
literal|null
decl_stmt|;
name|SequenceFile
operator|.
name|Reader
name|old
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|fs
operator|.
name|exists
argument_list|(
name|logfile
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Old log file "
operator|+
name|logfile
operator|+
literal|" already exists. Copying existing file to new file"
argument_list|)
expr_stmt|;
name|oldlogfile
operator|=
operator|new
name|Path
argument_list|(
name|logfile
operator|.
name|toString
argument_list|()
operator|+
literal|".old"
argument_list|)
expr_stmt|;
name|fs
operator|.
name|rename
argument_list|(
name|logfile
argument_list|,
name|oldlogfile
argument_list|)
expr_stmt|;
name|old
operator|=
operator|new
name|SequenceFile
operator|.
name|Reader
argument_list|(
name|fs
argument_list|,
name|oldlogfile
argument_list|,
name|conf
argument_list|)
expr_stmt|;
block|}
name|w
operator|=
name|SequenceFile
operator|.
name|createWriter
argument_list|(
name|fs
argument_list|,
name|conf
argument_list|,
name|logfile
argument_list|,
name|HLogKey
operator|.
name|class
argument_list|,
name|HLogEdit
operator|.
name|class
argument_list|,
name|getCompressionType
argument_list|(
name|conf
argument_list|)
argument_list|)
expr_stmt|;
comment|// Use copy of regionName; regionName object is reused inside in
comment|// HStoreKey.getRegionName so its content changes as we iterate.
name|logWriters
operator|.
name|put
argument_list|(
name|regionName
argument_list|,
name|w
argument_list|)
expr_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Creating new log file writer for path "
operator|+
name|logfile
operator|+
literal|" and region "
operator|+
name|regionName
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|old
operator|!=
literal|null
condition|)
block|{
comment|// Copy from existing log file
name|HLogKey
name|oldkey
init|=
operator|new
name|HLogKey
argument_list|()
decl_stmt|;
name|HLogEdit
name|oldval
init|=
operator|new
name|HLogEdit
argument_list|()
decl_stmt|;
for|for
control|(
init|;
name|old
operator|.
name|next
argument_list|(
name|oldkey
argument_list|,
name|oldval
argument_list|)
condition|;
name|count
operator|++
control|)
block|{
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
operator|&&
name|count
operator|>
literal|0
operator|&&
name|count
operator|%
literal|10000
operator|==
literal|0
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Copied "
operator|+
name|count
operator|+
literal|" edits"
argument_list|)
expr_stmt|;
block|}
name|w
operator|.
name|append
argument_list|(
name|oldkey
argument_list|,
name|oldval
argument_list|)
expr_stmt|;
block|}
name|old
operator|.
name|close
argument_list|()
expr_stmt|;
name|fs
operator|.
name|delete
argument_list|(
name|oldlogfile
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
block|}
name|w
operator|.
name|append
argument_list|(
name|key
argument_list|,
name|val
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Applied "
operator|+
name|count
operator|+
literal|" total edits from "
operator|+
name|logfiles
index|[
name|i
index|]
operator|.
name|getPath
argument_list|()
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|e
operator|=
name|RemoteExceptionHandler
operator|.
name|checkIOException
argument_list|(
name|e
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
operator|(
name|e
operator|instanceof
name|EOFException
operator|)
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Exception processing "
operator|+
name|logfiles
index|[
name|i
index|]
operator|.
name|getPath
argument_list|()
operator|+
literal|" -- continuing. Possible DATA LOSS!"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
block|}
finally|finally
block|{
try|try
block|{
name|in
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Close in finally threw exception -- continuing"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
comment|// Delete the input file now so we do not replay edits.  We could
comment|// have gotten here because of an exception.  If so, probably
comment|// nothing we can do about it. Replaying it, it could work but we
comment|// could be stuck replaying for ever. Just continue though we
comment|// could have lost some edits.
name|fs
operator|.
name|delete
argument_list|(
name|logfiles
index|[
name|i
index|]
operator|.
name|getPath
argument_list|()
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
block|}
block|}
finally|finally
block|{
for|for
control|(
name|SequenceFile
operator|.
name|Writer
name|w
range|:
name|logWriters
operator|.
name|values
argument_list|()
control|)
block|{
name|w
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
block|}
try|try
block|{
name|fs
operator|.
name|delete
argument_list|(
name|srcDir
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|e
operator|=
name|RemoteExceptionHandler
operator|.
name|checkIOException
argument_list|(
name|e
argument_list|)
expr_stmt|;
name|IOException
name|io
init|=
operator|new
name|IOException
argument_list|(
literal|"Cannot delete: "
operator|+
name|srcDir
argument_list|)
decl_stmt|;
name|io
operator|.
name|initCause
argument_list|(
name|e
argument_list|)
expr_stmt|;
throw|throw
name|io
throw|;
block|}
name|LOG
operator|.
name|info
argument_list|(
literal|"log file splitting completed for "
operator|+
name|srcDir
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
specifier|private
specifier|static
name|void
name|usage
parameter_list|()
block|{
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|"Usage: java org.apache.hbase.HLog"
operator|+
literal|" {--dump<logfile>... | --split<logdir>...}"
argument_list|)
expr_stmt|;
block|}
comment|/**    * Pass one or more log file names and it will either dump out a text version    * on<code>stdout</code> or split the specified log files.    *    * @param args    * @throws IOException    */
specifier|public
specifier|static
name|void
name|main
parameter_list|(
name|String
index|[]
name|args
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|args
operator|.
name|length
operator|<
literal|2
condition|)
block|{
name|usage
argument_list|()
expr_stmt|;
name|System
operator|.
name|exit
argument_list|(
operator|-
literal|1
argument_list|)
expr_stmt|;
block|}
name|boolean
name|dump
init|=
literal|true
decl_stmt|;
if|if
condition|(
name|args
index|[
literal|0
index|]
operator|.
name|compareTo
argument_list|(
literal|"--dump"
argument_list|)
operator|!=
literal|0
condition|)
block|{
if|if
condition|(
name|args
index|[
literal|0
index|]
operator|.
name|compareTo
argument_list|(
literal|"--split"
argument_list|)
operator|==
literal|0
condition|)
block|{
name|dump
operator|=
literal|false
expr_stmt|;
block|}
else|else
block|{
name|usage
argument_list|()
expr_stmt|;
name|System
operator|.
name|exit
argument_list|(
operator|-
literal|1
argument_list|)
expr_stmt|;
block|}
block|}
name|Configuration
name|conf
init|=
operator|new
name|HBaseConfiguration
argument_list|()
decl_stmt|;
name|FileSystem
name|fs
init|=
name|FileSystem
operator|.
name|get
argument_list|(
name|conf
argument_list|)
decl_stmt|;
name|Path
name|baseDir
init|=
operator|new
name|Path
argument_list|(
name|conf
operator|.
name|get
argument_list|(
name|HBASE_DIR
argument_list|)
argument_list|)
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|1
init|;
name|i
operator|<
name|args
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|Path
name|logPath
init|=
operator|new
name|Path
argument_list|(
name|args
index|[
name|i
index|]
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|fs
operator|.
name|exists
argument_list|(
name|logPath
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|FileNotFoundException
argument_list|(
name|args
index|[
name|i
index|]
operator|+
literal|" does not exist"
argument_list|)
throw|;
block|}
if|if
condition|(
name|dump
condition|)
block|{
if|if
condition|(
operator|!
name|fs
operator|.
name|isFile
argument_list|(
name|logPath
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|args
index|[
name|i
index|]
operator|+
literal|" is not a file"
argument_list|)
throw|;
block|}
name|Reader
name|log
init|=
operator|new
name|SequenceFile
operator|.
name|Reader
argument_list|(
name|fs
argument_list|,
name|logPath
argument_list|,
name|conf
argument_list|)
decl_stmt|;
try|try
block|{
name|HLogKey
name|key
init|=
operator|new
name|HLogKey
argument_list|()
decl_stmt|;
name|HLogEdit
name|val
init|=
operator|new
name|HLogEdit
argument_list|()
decl_stmt|;
while|while
condition|(
name|log
operator|.
name|next
argument_list|(
name|key
argument_list|,
name|val
argument_list|)
condition|)
block|{
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
name|key
operator|.
name|toString
argument_list|()
operator|+
literal|" "
operator|+
name|val
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
finally|finally
block|{
name|log
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
block|}
else|else
block|{
if|if
condition|(
operator|!
name|fs
operator|.
name|getFileStatus
argument_list|(
name|logPath
argument_list|)
operator|.
name|isDir
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|args
index|[
name|i
index|]
operator|+
literal|" is not a directory"
argument_list|)
throw|;
block|}
name|splitLog
argument_list|(
name|baseDir
argument_list|,
name|logPath
argument_list|,
name|fs
argument_list|,
name|conf
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
end_class

end_unit

