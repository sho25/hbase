begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Copyright 2007 The Apache Software Foundation  *  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|UnsupportedEncodingException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collections
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Iterator
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|SortedMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|TreeMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
operator|.
name|Entry
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|atomic
operator|.
name|AtomicInteger
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|locks
operator|.
name|ReentrantReadWriteLock
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|regex
operator|.
name|Matcher
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|regex
operator|.
name|Pattern
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|Log
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|LogFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FSDataInputStream
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FSDataOutputStream
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|filter
operator|.
name|RowFilterInterface
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|ImmutableBytesWritable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|TextSequence
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|MapFile
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|SequenceFile
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|Text
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|Writable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|WritableComparable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|StringUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|onelab
operator|.
name|filter
operator|.
name|BloomFilter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|onelab
operator|.
name|filter
operator|.
name|CountingBloomFilter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|onelab
operator|.
name|filter
operator|.
name|Filter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|onelab
operator|.
name|filter
operator|.
name|RetouchedBloomFilter
import|;
end_import

begin_comment
comment|/**  * HStore maintains a bunch of data files.  It is responsible for maintaining   * the memory/file hierarchy and for periodic flushes to disk and compacting   * edits to the file.  *  * Locking and transactions are handled at a higher level.  This API should not   * be called directly by any writer, but rather by an HRegion manager.  */
end_comment

begin_class
specifier|public
class|class
name|HStore
implements|implements
name|HConstants
block|{
specifier|static
specifier|final
name|Log
name|LOG
init|=
name|LogFactory
operator|.
name|getLog
argument_list|(
name|HStore
operator|.
name|class
argument_list|)
decl_stmt|;
comment|/**    * The Memcache holds in-memory modifications to the HRegion.  This is really a    * wrapper around a TreeMap that helps us when staging the Memcache out to disk.    */
specifier|static
class|class
name|Memcache
block|{
comment|// Note that since these structures are always accessed with a lock held,
comment|// no additional synchronization is required.
annotation|@
name|SuppressWarnings
argument_list|(
literal|"hiding"
argument_list|)
specifier|private
specifier|final
name|SortedMap
argument_list|<
name|HStoreKey
argument_list|,
name|byte
index|[]
argument_list|>
name|memcache
init|=
name|Collections
operator|.
name|synchronizedSortedMap
argument_list|(
operator|new
name|TreeMap
argument_list|<
name|HStoreKey
argument_list|,
name|byte
index|[]
argument_list|>
argument_list|()
argument_list|)
decl_stmt|;
specifier|volatile
name|SortedMap
argument_list|<
name|HStoreKey
argument_list|,
name|byte
index|[]
argument_list|>
name|snapshot
decl_stmt|;
annotation|@
name|SuppressWarnings
argument_list|(
literal|"hiding"
argument_list|)
specifier|private
specifier|final
name|ReentrantReadWriteLock
name|lock
init|=
operator|new
name|ReentrantReadWriteLock
argument_list|()
decl_stmt|;
comment|/**      * Constructor      */
name|Memcache
parameter_list|()
block|{
name|snapshot
operator|=
name|Collections
operator|.
name|synchronizedSortedMap
argument_list|(
operator|new
name|TreeMap
argument_list|<
name|HStoreKey
argument_list|,
name|byte
index|[]
argument_list|>
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|/**      * Creates a snapshot of the current Memcache      */
name|void
name|snapshot
parameter_list|()
block|{
name|this
operator|.
name|lock
operator|.
name|writeLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
synchronized|synchronized
init|(
name|memcache
init|)
block|{
if|if
condition|(
name|memcache
operator|.
name|size
argument_list|()
operator|!=
literal|0
condition|)
block|{
name|snapshot
operator|.
name|putAll
argument_list|(
name|memcache
argument_list|)
expr_stmt|;
name|memcache
operator|.
name|clear
argument_list|()
expr_stmt|;
block|}
block|}
block|}
finally|finally
block|{
name|this
operator|.
name|lock
operator|.
name|writeLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**      * @return memcache snapshot      */
name|SortedMap
argument_list|<
name|HStoreKey
argument_list|,
name|byte
index|[]
argument_list|>
name|getSnapshot
parameter_list|()
block|{
name|this
operator|.
name|lock
operator|.
name|writeLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
name|SortedMap
argument_list|<
name|HStoreKey
argument_list|,
name|byte
index|[]
argument_list|>
name|currentSnapshot
init|=
name|snapshot
decl_stmt|;
name|snapshot
operator|=
name|Collections
operator|.
name|synchronizedSortedMap
argument_list|(
operator|new
name|TreeMap
argument_list|<
name|HStoreKey
argument_list|,
name|byte
index|[]
argument_list|>
argument_list|()
argument_list|)
expr_stmt|;
return|return
name|currentSnapshot
return|;
block|}
finally|finally
block|{
name|this
operator|.
name|lock
operator|.
name|writeLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**      * Store a value.        * @param key      * @param value      */
name|void
name|add
parameter_list|(
specifier|final
name|HStoreKey
name|key
parameter_list|,
specifier|final
name|byte
index|[]
name|value
parameter_list|)
block|{
name|this
operator|.
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
name|memcache
operator|.
name|put
argument_list|(
name|key
argument_list|,
name|value
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|this
operator|.
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**      * Look back through all the backlog TreeMaps to find the target.      * @param key      * @param numVersions      * @return An array of byte arrays ordered by timestamp.      */
name|List
argument_list|<
name|byte
index|[]
argument_list|>
name|get
parameter_list|(
specifier|final
name|HStoreKey
name|key
parameter_list|,
specifier|final
name|int
name|numVersions
parameter_list|)
block|{
name|this
operator|.
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
name|List
argument_list|<
name|byte
index|[]
argument_list|>
name|results
decl_stmt|;
synchronized|synchronized
init|(
name|memcache
init|)
block|{
name|results
operator|=
name|internalGet
argument_list|(
name|memcache
argument_list|,
name|key
argument_list|,
name|numVersions
argument_list|)
expr_stmt|;
block|}
synchronized|synchronized
init|(
name|snapshot
init|)
block|{
name|results
operator|.
name|addAll
argument_list|(
name|results
operator|.
name|size
argument_list|()
argument_list|,
name|internalGet
argument_list|(
name|snapshot
argument_list|,
name|key
argument_list|,
name|numVersions
operator|-
name|results
operator|.
name|size
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
return|return
name|results
return|;
block|}
finally|finally
block|{
name|this
operator|.
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**      * Return all the available columns for the given key.  The key indicates a       * row and timestamp, but not a column name.      *      * The returned object should map column names to byte arrays (byte[]).      * @param key      * @param results      */
name|void
name|getFull
parameter_list|(
name|HStoreKey
name|key
parameter_list|,
name|SortedMap
argument_list|<
name|Text
argument_list|,
name|byte
index|[]
argument_list|>
name|results
parameter_list|)
block|{
name|this
operator|.
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
synchronized|synchronized
init|(
name|memcache
init|)
block|{
name|internalGetFull
argument_list|(
name|memcache
argument_list|,
name|key
argument_list|,
name|results
argument_list|)
expr_stmt|;
block|}
synchronized|synchronized
init|(
name|snapshot
init|)
block|{
name|internalGetFull
argument_list|(
name|snapshot
argument_list|,
name|key
argument_list|,
name|results
argument_list|)
expr_stmt|;
block|}
block|}
finally|finally
block|{
name|this
operator|.
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
specifier|private
name|void
name|internalGetFull
parameter_list|(
name|SortedMap
argument_list|<
name|HStoreKey
argument_list|,
name|byte
index|[]
argument_list|>
name|map
parameter_list|,
name|HStoreKey
name|key
parameter_list|,
name|SortedMap
argument_list|<
name|Text
argument_list|,
name|byte
index|[]
argument_list|>
name|results
parameter_list|)
block|{
if|if
condition|(
name|map
operator|.
name|isEmpty
argument_list|()
operator|||
name|key
operator|==
literal|null
condition|)
block|{
return|return;
block|}
name|SortedMap
argument_list|<
name|HStoreKey
argument_list|,
name|byte
index|[]
argument_list|>
name|tailMap
init|=
name|map
operator|.
name|tailMap
argument_list|(
name|key
argument_list|)
decl_stmt|;
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|HStoreKey
argument_list|,
name|byte
index|[]
argument_list|>
name|es
range|:
name|tailMap
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|HStoreKey
name|itKey
init|=
name|es
operator|.
name|getKey
argument_list|()
decl_stmt|;
name|Text
name|itCol
init|=
name|itKey
operator|.
name|getColumn
argument_list|()
decl_stmt|;
if|if
condition|(
name|results
operator|.
name|get
argument_list|(
name|itCol
argument_list|)
operator|==
literal|null
operator|&&
name|key
operator|.
name|matchesWithoutColumn
argument_list|(
name|itKey
argument_list|)
condition|)
block|{
name|byte
index|[]
name|val
init|=
name|tailMap
operator|.
name|get
argument_list|(
name|itKey
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|HLogEdit
operator|.
name|isDeleted
argument_list|(
name|val
argument_list|)
condition|)
block|{
name|results
operator|.
name|put
argument_list|(
name|itCol
argument_list|,
name|val
argument_list|)
expr_stmt|;
block|}
block|}
elseif|else
if|if
condition|(
name|key
operator|.
name|getRow
argument_list|()
operator|.
name|compareTo
argument_list|(
name|itKey
operator|.
name|getRow
argument_list|()
argument_list|)
operator|<
literal|0
condition|)
block|{
break|break;
block|}
block|}
block|}
comment|/**      * Find the key that matches<i>row</i> exactly, or the one that immediately      * preceeds it.      */
specifier|public
name|Text
name|getRowKeyAtOrBefore
parameter_list|(
specifier|final
name|Text
name|row
parameter_list|,
name|long
name|timestamp
parameter_list|)
throws|throws
name|IOException
block|{
name|this
operator|.
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
name|Text
name|key_memcache
init|=
literal|null
decl_stmt|;
name|Text
name|key_snapshot
init|=
literal|null
decl_stmt|;
try|try
block|{
synchronized|synchronized
init|(
name|memcache
init|)
block|{
name|key_memcache
operator|=
name|internalGetRowKeyAtOrBefore
argument_list|(
name|memcache
argument_list|,
name|row
argument_list|,
name|timestamp
argument_list|)
expr_stmt|;
block|}
synchronized|synchronized
init|(
name|snapshot
init|)
block|{
name|key_snapshot
operator|=
name|internalGetRowKeyAtOrBefore
argument_list|(
name|snapshot
argument_list|,
name|row
argument_list|,
name|timestamp
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|key_memcache
operator|==
literal|null
operator|&&
name|key_snapshot
operator|==
literal|null
condition|)
block|{
comment|// didn't find any candidates, return null
return|return
literal|null
return|;
block|}
elseif|else
if|if
condition|(
name|key_memcache
operator|==
literal|null
operator|&&
name|key_snapshot
operator|!=
literal|null
condition|)
block|{
return|return
name|key_snapshot
return|;
block|}
elseif|else
if|if
condition|(
name|key_memcache
operator|!=
literal|null
operator|&&
name|key_snapshot
operator|==
literal|null
condition|)
block|{
return|return
name|key_memcache
return|;
block|}
else|else
block|{
comment|// if either is a precise match, return the original row.
if|if
condition|(
operator|(
name|key_memcache
operator|!=
literal|null
operator|&&
name|key_memcache
operator|.
name|equals
argument_list|(
name|row
argument_list|)
operator|)
operator|||
operator|(
name|key_snapshot
operator|!=
literal|null
operator|&&
name|key_snapshot
operator|.
name|equals
argument_list|(
name|row
argument_list|)
operator|)
condition|)
block|{
return|return
name|row
return|;
block|}
else|else
block|{
comment|// no precise matches, so return the one that is closer to the search
comment|// key (greatest)
return|return
name|key_memcache
operator|.
name|compareTo
argument_list|(
name|key_snapshot
argument_list|)
operator|>
literal|0
condition|?
name|key_memcache
else|:
name|key_snapshot
return|;
block|}
block|}
block|}
finally|finally
block|{
name|this
operator|.
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
specifier|private
name|Text
name|internalGetRowKeyAtOrBefore
parameter_list|(
name|SortedMap
argument_list|<
name|HStoreKey
argument_list|,
name|byte
index|[]
argument_list|>
name|map
parameter_list|,
name|Text
name|key
parameter_list|,
name|long
name|timestamp
parameter_list|)
block|{
comment|// TODO: account for deleted cells
name|HStoreKey
name|search_key
init|=
operator|new
name|HStoreKey
argument_list|(
name|key
argument_list|,
name|timestamp
argument_list|)
decl_stmt|;
comment|// get all the entries that come equal or after our search key
name|SortedMap
argument_list|<
name|HStoreKey
argument_list|,
name|byte
index|[]
argument_list|>
name|tailMap
init|=
name|map
operator|.
name|tailMap
argument_list|(
name|search_key
argument_list|)
decl_stmt|;
comment|// if the first item in the tail has a matching row, then we have an
comment|// exact match, and we should return that item
if|if
condition|(
operator|!
name|tailMap
operator|.
name|isEmpty
argument_list|()
operator|&&
name|tailMap
operator|.
name|firstKey
argument_list|()
operator|.
name|getRow
argument_list|()
operator|.
name|equals
argument_list|(
name|key
argument_list|)
condition|)
block|{
comment|// seek forward past any cells that don't fulfill the timestamp
comment|// argument
name|Iterator
argument_list|<
name|HStoreKey
argument_list|>
name|key_iterator
init|=
name|tailMap
operator|.
name|keySet
argument_list|()
operator|.
name|iterator
argument_list|()
decl_stmt|;
name|HStoreKey
name|found_key
init|=
name|key_iterator
operator|.
name|next
argument_list|()
decl_stmt|;
comment|// keep seeking so long as we're in the same row, and the timstamp
comment|// isn't as small as we'd like, and there are more cells to check
while|while
condition|(
name|found_key
operator|.
name|getRow
argument_list|()
operator|.
name|equals
argument_list|(
name|key
argument_list|)
operator|&&
name|found_key
operator|.
name|getTimestamp
argument_list|()
operator|>
name|timestamp
operator|&&
name|key_iterator
operator|.
name|hasNext
argument_list|()
condition|)
block|{
name|found_key
operator|=
name|key_iterator
operator|.
name|next
argument_list|()
expr_stmt|;
block|}
comment|// if this check fails, then we've iterated through all the keys that
comment|// match by row, but none match by timestamp, so we fall through to
comment|// the headMap case.
if|if
condition|(
name|found_key
operator|.
name|getTimestamp
argument_list|()
operator|<=
name|timestamp
condition|)
block|{
comment|// we didn't find a key that matched by timestamp, so we have to
comment|// return null;
comment|/*          LOG.debug("Went searching for " + key + ", found " + found_key.getRow());*/
return|return
name|found_key
operator|.
name|getRow
argument_list|()
return|;
block|}
block|}
comment|// the tail didn't contain the key we're searching for, so we should
comment|// use the last key in the headmap as the closest before
name|SortedMap
argument_list|<
name|HStoreKey
argument_list|,
name|byte
index|[]
argument_list|>
name|headMap
init|=
name|map
operator|.
name|headMap
argument_list|(
name|search_key
argument_list|)
decl_stmt|;
if|if
condition|(
name|headMap
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
comment|/*        LOG.debug("Went searching for " + key + ", found nothing!");*/
return|return
literal|null
return|;
block|}
else|else
block|{
comment|/*        LOG.debug("Went searching for " + key + ", found " + headMap.lastKey().getRow());*/
return|return
name|headMap
operator|.
name|lastKey
argument_list|()
operator|.
name|getRow
argument_list|()
return|;
block|}
block|}
comment|/**      * Examine a single map for the desired key.      *      * TODO - This is kinda slow.  We need a data structure that allows for       * proximity-searches, not just precise-matches.      *       * @param map      * @param key      * @param numVersions      * @return Ordered list of items found in passed<code>map</code>.  If no      * matching values, returns an empty list (does not return null).      */
specifier|private
name|ArrayList
argument_list|<
name|byte
index|[]
argument_list|>
name|internalGet
parameter_list|(
specifier|final
name|SortedMap
argument_list|<
name|HStoreKey
argument_list|,
name|byte
index|[]
argument_list|>
name|map
parameter_list|,
specifier|final
name|HStoreKey
name|key
parameter_list|,
specifier|final
name|int
name|numVersions
parameter_list|)
block|{
name|ArrayList
argument_list|<
name|byte
index|[]
argument_list|>
name|result
init|=
operator|new
name|ArrayList
argument_list|<
name|byte
index|[]
argument_list|>
argument_list|()
decl_stmt|;
comment|// TODO: If get is of a particular version -- numVersions == 1 -- we
comment|// should be able to avoid all of the tailmap creations and iterations
comment|// below.
name|SortedMap
argument_list|<
name|HStoreKey
argument_list|,
name|byte
index|[]
argument_list|>
name|tailMap
init|=
name|map
operator|.
name|tailMap
argument_list|(
name|key
argument_list|)
decl_stmt|;
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|HStoreKey
argument_list|,
name|byte
index|[]
argument_list|>
name|es
range|:
name|tailMap
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|HStoreKey
name|itKey
init|=
name|es
operator|.
name|getKey
argument_list|()
decl_stmt|;
if|if
condition|(
name|itKey
operator|.
name|matchesRowCol
argument_list|(
name|key
argument_list|)
condition|)
block|{
if|if
condition|(
operator|!
name|HLogEdit
operator|.
name|isDeleted
argument_list|(
name|es
operator|.
name|getValue
argument_list|()
argument_list|)
condition|)
block|{
name|result
operator|.
name|add
argument_list|(
name|tailMap
operator|.
name|get
argument_list|(
name|itKey
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|numVersions
operator|>
literal|0
operator|&&
name|result
operator|.
name|size
argument_list|()
operator|>=
name|numVersions
condition|)
block|{
break|break;
block|}
block|}
return|return
name|result
return|;
block|}
comment|/**      * Get<code>versions</code> keys matching the origin key's      * row/column/timestamp and those of an older vintage      * Default access so can be accessed out of {@link HRegionServer}.      * @param origin Where to start searching.      * @param versions How many versions to return. Pass      * {@link HConstants.ALL_VERSIONS} to retrieve all.      * @return Ordered list of<code>versions</code> keys going from newest back.      * @throws IOException      */
name|List
argument_list|<
name|HStoreKey
argument_list|>
name|getKeys
parameter_list|(
specifier|final
name|HStoreKey
name|origin
parameter_list|,
specifier|final
name|int
name|versions
parameter_list|)
block|{
name|this
operator|.
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
name|List
argument_list|<
name|HStoreKey
argument_list|>
name|results
decl_stmt|;
synchronized|synchronized
init|(
name|memcache
init|)
block|{
name|results
operator|=
name|internalGetKeys
argument_list|(
name|this
operator|.
name|memcache
argument_list|,
name|origin
argument_list|,
name|versions
argument_list|)
expr_stmt|;
block|}
synchronized|synchronized
init|(
name|snapshot
init|)
block|{
name|results
operator|.
name|addAll
argument_list|(
name|results
operator|.
name|size
argument_list|()
argument_list|,
name|internalGetKeys
argument_list|(
name|snapshot
argument_list|,
name|origin
argument_list|,
name|versions
operator|==
name|HConstants
operator|.
name|ALL_VERSIONS
condition|?
name|versions
else|:
operator|(
name|versions
operator|-
name|results
operator|.
name|size
argument_list|()
operator|)
argument_list|)
argument_list|)
expr_stmt|;
block|}
return|return
name|results
return|;
block|}
finally|finally
block|{
name|this
operator|.
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
comment|/*      * @param origin Where to start searching.      * @param versions How many versions to return. Pass      * {@link HConstants.ALL_VERSIONS} to retrieve all.      * @return List of all keys that are of the same row and column and of      * equal or older timestamp.  If no keys, returns an empty List. Does not      * return null.      */
specifier|private
name|List
argument_list|<
name|HStoreKey
argument_list|>
name|internalGetKeys
parameter_list|(
specifier|final
name|SortedMap
argument_list|<
name|HStoreKey
argument_list|,
name|byte
index|[]
argument_list|>
name|map
parameter_list|,
specifier|final
name|HStoreKey
name|origin
parameter_list|,
specifier|final
name|int
name|versions
parameter_list|)
block|{
name|List
argument_list|<
name|HStoreKey
argument_list|>
name|result
init|=
operator|new
name|ArrayList
argument_list|<
name|HStoreKey
argument_list|>
argument_list|()
decl_stmt|;
name|SortedMap
argument_list|<
name|HStoreKey
argument_list|,
name|byte
index|[]
argument_list|>
name|tailMap
init|=
name|map
operator|.
name|tailMap
argument_list|(
name|origin
argument_list|)
decl_stmt|;
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|HStoreKey
argument_list|,
name|byte
index|[]
argument_list|>
name|es
range|:
name|tailMap
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|HStoreKey
name|key
init|=
name|es
operator|.
name|getKey
argument_list|()
decl_stmt|;
comment|// if there's no column name, then compare rows and timestamps
if|if
condition|(
name|origin
operator|.
name|getColumn
argument_list|()
operator|.
name|toString
argument_list|()
operator|.
name|equals
argument_list|(
literal|""
argument_list|)
condition|)
block|{
comment|// if the current and origin row don't match, then we can jump
comment|// out of the loop entirely.
if|if
condition|(
operator|!
name|key
operator|.
name|getRow
argument_list|()
operator|.
name|equals
argument_list|(
name|origin
operator|.
name|getRow
argument_list|()
argument_list|)
condition|)
block|{
break|break;
block|}
comment|// if the rows match but the timestamp is newer, skip it so we can
comment|// get to the ones we actually want.
if|if
condition|(
name|key
operator|.
name|getTimestamp
argument_list|()
operator|>
name|origin
operator|.
name|getTimestamp
argument_list|()
condition|)
block|{
continue|continue;
block|}
block|}
else|else
block|{
comment|// compare rows and columns
comment|// if the key doesn't match the row and column, then we're done, since
comment|// all the cells are ordered.
if|if
condition|(
operator|!
name|key
operator|.
name|matchesRowCol
argument_list|(
name|origin
argument_list|)
condition|)
block|{
break|break;
block|}
block|}
if|if
condition|(
operator|!
name|HLogEdit
operator|.
name|isDeleted
argument_list|(
name|es
operator|.
name|getValue
argument_list|()
argument_list|)
condition|)
block|{
name|result
operator|.
name|add
argument_list|(
name|key
argument_list|)
expr_stmt|;
if|if
condition|(
name|versions
operator|!=
name|HConstants
operator|.
name|ALL_VERSIONS
operator|&&
name|result
operator|.
name|size
argument_list|()
operator|>=
name|versions
condition|)
block|{
comment|// We have enough results.  Return.
break|break;
block|}
block|}
block|}
return|return
name|result
return|;
block|}
comment|/**      * @param key      * @return True if an entry and its content is {@link HGlobals.deleteBytes}.      * Use checking values in store. On occasion the memcache has the fact that      * the cell has been deleted.      */
name|boolean
name|isDeleted
parameter_list|(
specifier|final
name|HStoreKey
name|key
parameter_list|)
block|{
return|return
name|HLogEdit
operator|.
name|isDeleted
argument_list|(
name|this
operator|.
name|memcache
operator|.
name|get
argument_list|(
name|key
argument_list|)
argument_list|)
return|;
block|}
comment|/**      * @return a scanner over the keys in the Memcache      */
name|HInternalScannerInterface
name|getScanner
parameter_list|(
name|long
name|timestamp
parameter_list|,
name|Text
name|targetCols
index|[]
parameter_list|,
name|Text
name|firstRow
parameter_list|)
throws|throws
name|IOException
block|{
comment|// Here we rely on ReentrantReadWriteLock's ability to acquire multiple
comment|// locks by the same thread and to be able to downgrade a write lock to
comment|// a read lock. We need to hold a lock throughout this method, but only
comment|// need the write lock while creating the memcache snapshot
name|this
operator|.
name|lock
operator|.
name|writeLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
comment|// hold write lock during memcache snapshot
name|snapshot
argument_list|()
expr_stmt|;
comment|// snapshot memcache
name|this
operator|.
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
comment|// acquire read lock
name|this
operator|.
name|lock
operator|.
name|writeLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
comment|// downgrade to read lock
try|try
block|{
comment|// Prevent a cache flush while we are constructing the scanner
return|return
operator|new
name|MemcacheScanner
argument_list|(
name|timestamp
argument_list|,
name|targetCols
argument_list|,
name|firstRow
argument_list|)
return|;
block|}
finally|finally
block|{
name|this
operator|.
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
comment|//////////////////////////////////////////////////////////////////////////////
comment|// MemcacheScanner implements the HScannerInterface.
comment|// It lets the caller scan the contents of the Memcache.
comment|//////////////////////////////////////////////////////////////////////////////
class|class
name|MemcacheScanner
extends|extends
name|HAbstractScanner
block|{
name|SortedMap
argument_list|<
name|HStoreKey
argument_list|,
name|byte
index|[]
argument_list|>
name|backingMap
decl_stmt|;
name|Iterator
argument_list|<
name|HStoreKey
argument_list|>
name|keyIterator
decl_stmt|;
annotation|@
name|SuppressWarnings
argument_list|(
literal|"unchecked"
argument_list|)
name|MemcacheScanner
parameter_list|(
specifier|final
name|long
name|timestamp
parameter_list|,
specifier|final
name|Text
name|targetCols
index|[]
parameter_list|,
specifier|final
name|Text
name|firstRow
parameter_list|)
throws|throws
name|IOException
block|{
name|super
argument_list|(
name|timestamp
argument_list|,
name|targetCols
argument_list|)
expr_stmt|;
try|try
block|{
name|this
operator|.
name|backingMap
operator|=
operator|new
name|TreeMap
argument_list|<
name|HStoreKey
argument_list|,
name|byte
index|[]
argument_list|>
argument_list|()
expr_stmt|;
name|this
operator|.
name|backingMap
operator|.
name|putAll
argument_list|(
name|snapshot
argument_list|)
expr_stmt|;
name|this
operator|.
name|keys
operator|=
operator|new
name|HStoreKey
index|[
literal|1
index|]
expr_stmt|;
name|this
operator|.
name|vals
operator|=
operator|new
name|byte
index|[
literal|1
index|]
index|[]
expr_stmt|;
comment|// Generate list of iterators
name|HStoreKey
name|firstKey
init|=
operator|new
name|HStoreKey
argument_list|(
name|firstRow
argument_list|)
decl_stmt|;
if|if
condition|(
name|firstRow
operator|!=
literal|null
operator|&&
name|firstRow
operator|.
name|getLength
argument_list|()
operator|!=
literal|0
condition|)
block|{
name|keyIterator
operator|=
name|backingMap
operator|.
name|tailMap
argument_list|(
name|firstKey
argument_list|)
operator|.
name|keySet
argument_list|()
operator|.
name|iterator
argument_list|()
expr_stmt|;
block|}
else|else
block|{
name|keyIterator
operator|=
name|backingMap
operator|.
name|keySet
argument_list|()
operator|.
name|iterator
argument_list|()
expr_stmt|;
block|}
while|while
condition|(
name|getNext
argument_list|(
literal|0
argument_list|)
condition|)
block|{
if|if
condition|(
operator|!
name|findFirstRow
argument_list|(
literal|0
argument_list|,
name|firstRow
argument_list|)
condition|)
block|{
continue|continue;
block|}
if|if
condition|(
name|columnMatch
argument_list|(
literal|0
argument_list|)
condition|)
block|{
break|break;
block|}
block|}
block|}
catch|catch
parameter_list|(
name|RuntimeException
name|ex
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"error initializing Memcache scanner: "
argument_list|,
name|ex
argument_list|)
expr_stmt|;
name|close
argument_list|()
expr_stmt|;
name|IOException
name|e
init|=
operator|new
name|IOException
argument_list|(
literal|"error initializing Memcache scanner"
argument_list|)
decl_stmt|;
name|e
operator|.
name|initCause
argument_list|(
name|ex
argument_list|)
expr_stmt|;
throw|throw
name|e
throw|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ex
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"error initializing Memcache scanner: "
argument_list|,
name|ex
argument_list|)
expr_stmt|;
name|close
argument_list|()
expr_stmt|;
throw|throw
name|ex
throw|;
block|}
block|}
comment|/**        * The user didn't want to start scanning at the first row. This method        * seeks to the requested row.        *        * @param i which iterator to advance        * @param firstRow seek to this row        * @return true if this is the first row        */
annotation|@
name|Override
name|boolean
name|findFirstRow
parameter_list|(
name|int
name|i
parameter_list|,
name|Text
name|firstRow
parameter_list|)
block|{
return|return
name|firstRow
operator|.
name|getLength
argument_list|()
operator|==
literal|0
operator|||
name|keys
index|[
name|i
index|]
operator|.
name|getRow
argument_list|()
operator|.
name|compareTo
argument_list|(
name|firstRow
argument_list|)
operator|>=
literal|0
return|;
block|}
comment|/**        * Get the next value from the specified iterator.        *         * @param i Which iterator to fetch next value from        * @return true if there is more data available        */
annotation|@
name|Override
name|boolean
name|getNext
parameter_list|(
name|int
name|i
parameter_list|)
block|{
name|boolean
name|result
init|=
literal|false
decl_stmt|;
while|while
condition|(
literal|true
condition|)
block|{
if|if
condition|(
operator|!
name|keyIterator
operator|.
name|hasNext
argument_list|()
condition|)
block|{
name|closeSubScanner
argument_list|(
name|i
argument_list|)
expr_stmt|;
break|break;
block|}
comment|// Check key is< than passed timestamp for this scanner.
name|HStoreKey
name|hsk
init|=
name|keyIterator
operator|.
name|next
argument_list|()
decl_stmt|;
if|if
condition|(
name|hsk
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|NullPointerException
argument_list|(
literal|"Unexpected null key"
argument_list|)
throw|;
block|}
if|if
condition|(
name|hsk
operator|.
name|getTimestamp
argument_list|()
operator|<=
name|this
operator|.
name|timestamp
condition|)
block|{
name|this
operator|.
name|keys
index|[
name|i
index|]
operator|=
name|hsk
expr_stmt|;
name|this
operator|.
name|vals
index|[
name|i
index|]
operator|=
name|backingMap
operator|.
name|get
argument_list|(
name|keys
index|[
name|i
index|]
argument_list|)
expr_stmt|;
name|result
operator|=
literal|true
expr_stmt|;
break|break;
block|}
block|}
return|return
name|result
return|;
block|}
comment|/** Shut down an individual map iterator. */
annotation|@
name|Override
name|void
name|closeSubScanner
parameter_list|(
name|int
name|i
parameter_list|)
block|{
name|keyIterator
operator|=
literal|null
expr_stmt|;
name|keys
index|[
name|i
index|]
operator|=
literal|null
expr_stmt|;
name|vals
index|[
name|i
index|]
operator|=
literal|null
expr_stmt|;
name|backingMap
operator|=
literal|null
expr_stmt|;
block|}
comment|/** Shut down map iterators */
specifier|public
name|void
name|close
parameter_list|()
block|{
if|if
condition|(
operator|!
name|scannerClosed
condition|)
block|{
if|if
condition|(
name|keyIterator
operator|!=
literal|null
condition|)
block|{
name|closeSubScanner
argument_list|(
literal|0
argument_list|)
expr_stmt|;
block|}
name|scannerClosed
operator|=
literal|true
expr_stmt|;
block|}
block|}
block|}
block|}
comment|/*    * Regex that will work for straight filenames and for reference names.    * If reference, then the regex has more than just one group.  Group 1 is    * this files id.  Group 2 the referenced region name, etc.    */
specifier|private
specifier|static
name|Pattern
name|REF_NAME_PARSER
init|=
name|Pattern
operator|.
name|compile
argument_list|(
literal|"^(\\d+)(?:\\.(.+))?$"
argument_list|)
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|String
name|BLOOMFILTER_FILE_NAME
init|=
literal|"filter"
decl_stmt|;
specifier|final
name|Memcache
name|memcache
init|=
operator|new
name|Memcache
argument_list|()
decl_stmt|;
specifier|private
specifier|final
name|Path
name|basedir
decl_stmt|;
specifier|private
specifier|final
name|HRegionInfo
name|info
decl_stmt|;
specifier|private
specifier|final
name|HColumnDescriptor
name|family
decl_stmt|;
specifier|private
specifier|final
name|SequenceFile
operator|.
name|CompressionType
name|compression
decl_stmt|;
specifier|final
name|FileSystem
name|fs
decl_stmt|;
specifier|private
specifier|final
name|HBaseConfiguration
name|conf
decl_stmt|;
specifier|private
specifier|final
name|Path
name|filterDir
decl_stmt|;
specifier|final
name|Filter
name|bloomFilter
decl_stmt|;
specifier|private
specifier|final
name|Path
name|compactionDir
decl_stmt|;
specifier|private
specifier|final
name|Integer
name|compactLock
init|=
operator|new
name|Integer
argument_list|(
literal|0
argument_list|)
decl_stmt|;
specifier|private
specifier|final
name|Integer
name|flushLock
init|=
operator|new
name|Integer
argument_list|(
literal|0
argument_list|)
decl_stmt|;
specifier|private
specifier|final
name|ReentrantReadWriteLock
name|lock
init|=
operator|new
name|ReentrantReadWriteLock
argument_list|()
decl_stmt|;
specifier|final
name|AtomicInteger
name|activeScanners
init|=
operator|new
name|AtomicInteger
argument_list|(
literal|0
argument_list|)
decl_stmt|;
specifier|final
name|String
name|storeName
decl_stmt|;
comment|/*    * Sorted Map of readers keyed by sequence id (Most recent should be last in    * in list).    */
specifier|final
name|SortedMap
argument_list|<
name|Long
argument_list|,
name|HStoreFile
argument_list|>
name|storefiles
init|=
name|Collections
operator|.
name|synchronizedSortedMap
argument_list|(
operator|new
name|TreeMap
argument_list|<
name|Long
argument_list|,
name|HStoreFile
argument_list|>
argument_list|()
argument_list|)
decl_stmt|;
comment|/*    * Sorted Map of readers keyed by sequence id (Most recent should be last in    * in list).    */
specifier|private
specifier|final
name|SortedMap
argument_list|<
name|Long
argument_list|,
name|MapFile
operator|.
name|Reader
argument_list|>
name|readers
init|=
operator|new
name|TreeMap
argument_list|<
name|Long
argument_list|,
name|MapFile
operator|.
name|Reader
argument_list|>
argument_list|()
decl_stmt|;
specifier|private
specifier|volatile
name|long
name|maxSeqId
decl_stmt|;
specifier|private
specifier|final
name|int
name|compactionThreshold
decl_stmt|;
specifier|private
specifier|final
name|ReentrantReadWriteLock
name|newScannerLock
init|=
operator|new
name|ReentrantReadWriteLock
argument_list|()
decl_stmt|;
comment|/**    * An HStore is a set of zero or more MapFiles, which stretch backwards over     * time.  A given HStore is responsible for a certain set of columns for a    * row in the HRegion.    *    *<p>The HRegion starts writing to its set of HStores when the HRegion's     * memcache is flushed.  This results in a round of new MapFiles, one for    * each HStore.    *    *<p>There's no reason to consider append-logging at this level; all logging     * and locking is handled at the HRegion level.  HStore just provides    * services to manage sets of MapFiles.  One of the most important of those    * services is MapFile-compaction services.    *    *<p>The only thing having to do with logs that HStore needs to deal with is    * the reconstructionLog.  This is a segment of an HRegion's log that might    * NOT be present upon startup.  If the param is NULL, there's nothing to do.    * If the param is non-NULL, we need to process the log to reconstruct    * a TreeMap that might not have been written to disk before the process    * died.    *    *<p>It's assumed that after this constructor returns, the reconstructionLog    * file will be deleted (by whoever has instantiated the HStore).    *    * @param basedir qualified path under which the region directory lives    * @param info HRegionInfo for this region    * @param family HColumnDescriptor for this column    * @param fs file system object    * @param reconstructionLog existing log file to apply if any    * @param conf configuration object    * @throws IOException    */
name|HStore
parameter_list|(
name|Path
name|basedir
parameter_list|,
name|HRegionInfo
name|info
parameter_list|,
name|HColumnDescriptor
name|family
parameter_list|,
name|FileSystem
name|fs
parameter_list|,
name|Path
name|reconstructionLog
parameter_list|,
name|HBaseConfiguration
name|conf
parameter_list|)
throws|throws
name|IOException
block|{
name|this
operator|.
name|basedir
operator|=
name|basedir
expr_stmt|;
name|this
operator|.
name|info
operator|=
name|info
expr_stmt|;
name|this
operator|.
name|family
operator|=
name|family
expr_stmt|;
name|this
operator|.
name|fs
operator|=
name|fs
expr_stmt|;
name|this
operator|.
name|conf
operator|=
name|conf
expr_stmt|;
name|this
operator|.
name|compactionDir
operator|=
operator|new
name|Path
argument_list|(
name|basedir
argument_list|,
literal|"compaction.dir"
argument_list|)
expr_stmt|;
name|this
operator|.
name|storeName
operator|=
name|this
operator|.
name|info
operator|.
name|getEncodedName
argument_list|()
operator|+
literal|"/"
operator|+
name|this
operator|.
name|family
operator|.
name|getFamilyName
argument_list|()
expr_stmt|;
if|if
condition|(
name|family
operator|.
name|getCompression
argument_list|()
operator|==
name|HColumnDescriptor
operator|.
name|CompressionType
operator|.
name|BLOCK
condition|)
block|{
name|this
operator|.
name|compression
operator|=
name|SequenceFile
operator|.
name|CompressionType
operator|.
name|BLOCK
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|family
operator|.
name|getCompression
argument_list|()
operator|==
name|HColumnDescriptor
operator|.
name|CompressionType
operator|.
name|RECORD
condition|)
block|{
name|this
operator|.
name|compression
operator|=
name|SequenceFile
operator|.
name|CompressionType
operator|.
name|RECORD
expr_stmt|;
block|}
else|else
block|{
name|this
operator|.
name|compression
operator|=
name|SequenceFile
operator|.
name|CompressionType
operator|.
name|NONE
expr_stmt|;
block|}
name|Path
name|mapdir
init|=
name|HStoreFile
operator|.
name|getMapDir
argument_list|(
name|basedir
argument_list|,
name|info
operator|.
name|getEncodedName
argument_list|()
argument_list|,
name|family
operator|.
name|getFamilyName
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|fs
operator|.
name|exists
argument_list|(
name|mapdir
argument_list|)
condition|)
block|{
name|fs
operator|.
name|mkdirs
argument_list|(
name|mapdir
argument_list|)
expr_stmt|;
block|}
name|Path
name|infodir
init|=
name|HStoreFile
operator|.
name|getInfoDir
argument_list|(
name|basedir
argument_list|,
name|info
operator|.
name|getEncodedName
argument_list|()
argument_list|,
name|family
operator|.
name|getFamilyName
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|fs
operator|.
name|exists
argument_list|(
name|infodir
argument_list|)
condition|)
block|{
name|fs
operator|.
name|mkdirs
argument_list|(
name|infodir
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|family
operator|.
name|getBloomFilter
argument_list|()
operator|==
literal|null
condition|)
block|{
name|this
operator|.
name|filterDir
operator|=
literal|null
expr_stmt|;
name|this
operator|.
name|bloomFilter
operator|=
literal|null
expr_stmt|;
block|}
else|else
block|{
name|this
operator|.
name|filterDir
operator|=
name|HStoreFile
operator|.
name|getFilterDir
argument_list|(
name|basedir
argument_list|,
name|info
operator|.
name|getEncodedName
argument_list|()
argument_list|,
name|family
operator|.
name|getFamilyName
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|fs
operator|.
name|exists
argument_list|(
name|filterDir
argument_list|)
condition|)
block|{
name|fs
operator|.
name|mkdirs
argument_list|(
name|filterDir
argument_list|)
expr_stmt|;
block|}
name|this
operator|.
name|bloomFilter
operator|=
name|loadOrCreateBloomFilter
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"starting "
operator|+
name|storeName
operator|+
operator|(
operator|(
name|reconstructionLog
operator|==
literal|null
operator|||
operator|!
name|fs
operator|.
name|exists
argument_list|(
name|reconstructionLog
argument_list|)
operator|)
condition|?
literal|" (no reconstruction log)"
else|:
literal|" with reconstruction log: "
operator|+
name|reconstructionLog
operator|.
name|toString
argument_list|()
operator|)
argument_list|)
expr_stmt|;
block|}
comment|// Go through the 'mapdir' and 'infodir' together, make sure that all
comment|// MapFiles are in a reliable state.  Every entry in 'mapdir' must have a
comment|// corresponding one in 'loginfodir'. Without a corresponding log info
comment|// file, the entry in 'mapdir' must be deleted.
name|List
argument_list|<
name|HStoreFile
argument_list|>
name|hstoreFiles
init|=
name|loadHStoreFiles
argument_list|(
name|infodir
argument_list|,
name|mapdir
argument_list|)
decl_stmt|;
for|for
control|(
name|HStoreFile
name|hsf
range|:
name|hstoreFiles
control|)
block|{
name|this
operator|.
name|storefiles
operator|.
name|put
argument_list|(
name|Long
operator|.
name|valueOf
argument_list|(
name|hsf
operator|.
name|loadInfo
argument_list|(
name|fs
argument_list|)
argument_list|)
argument_list|,
name|hsf
argument_list|)
expr_stmt|;
block|}
comment|// Now go through all the HSTORE_LOGINFOFILEs and figure out the
comment|// most-recent log-seq-ID that's present.  The most-recent such ID means we
comment|// can ignore all log messages up to and including that ID (because they're
comment|// already reflected in the TreeMaps).
comment|//
comment|// If the HSTORE_LOGINFOFILE doesn't contain a number, just ignore it. That
comment|// means it was built prior to the previous run of HStore, and so it cannot
comment|// contain any updates also contained in the log.
name|this
operator|.
name|maxSeqId
operator|=
name|getMaxSequenceId
argument_list|(
name|hstoreFiles
argument_list|)
expr_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"maximum sequence id for hstore "
operator|+
name|storeName
operator|+
literal|" is "
operator|+
name|this
operator|.
name|maxSeqId
argument_list|)
expr_stmt|;
block|}
name|doReconstructionLog
argument_list|(
name|reconstructionLog
argument_list|,
name|maxSeqId
argument_list|)
expr_stmt|;
comment|// By default, we compact if an HStore has more than
comment|// MIN_COMMITS_FOR_COMPACTION map files
name|this
operator|.
name|compactionThreshold
operator|=
name|conf
operator|.
name|getInt
argument_list|(
literal|"hbase.hstore.compactionThreshold"
argument_list|,
literal|3
argument_list|)
expr_stmt|;
comment|// We used to compact in here before bringing the store online.  Instead
comment|// get it online quick even if it needs compactions so we can start
comment|// taking updates as soon as possible (Once online, can take updates even
comment|// during a compaction).
comment|// Move maxSeqId on by one. Why here?  And not in HRegion?
name|this
operator|.
name|maxSeqId
operator|+=
literal|1
expr_stmt|;
comment|// Finally, start up all the map readers! (There should be just one at this
comment|// point, as we've compacted them all.)
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|Long
argument_list|,
name|HStoreFile
argument_list|>
name|e
range|:
name|this
operator|.
name|storefiles
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|this
operator|.
name|readers
operator|.
name|put
argument_list|(
name|e
operator|.
name|getKey
argument_list|()
argument_list|,
name|e
operator|.
name|getValue
argument_list|()
operator|.
name|getReader
argument_list|(
name|this
operator|.
name|fs
argument_list|,
name|this
operator|.
name|bloomFilter
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
comment|/*     * @param hstoreFiles    * @return Maximum sequence number found or -1.    * @throws IOException    */
specifier|private
name|long
name|getMaxSequenceId
parameter_list|(
specifier|final
name|List
argument_list|<
name|HStoreFile
argument_list|>
name|hstoreFiles
parameter_list|)
throws|throws
name|IOException
block|{
name|long
name|maxSeqID
init|=
operator|-
literal|1
decl_stmt|;
for|for
control|(
name|HStoreFile
name|hsf
range|:
name|hstoreFiles
control|)
block|{
name|long
name|seqid
init|=
name|hsf
operator|.
name|loadInfo
argument_list|(
name|fs
argument_list|)
decl_stmt|;
if|if
condition|(
name|seqid
operator|>
literal|0
condition|)
block|{
if|if
condition|(
name|seqid
operator|>
name|maxSeqID
condition|)
block|{
name|maxSeqID
operator|=
name|seqid
expr_stmt|;
block|}
block|}
block|}
return|return
name|maxSeqID
return|;
block|}
name|long
name|getMaxSequenceId
parameter_list|()
block|{
return|return
name|this
operator|.
name|maxSeqId
return|;
block|}
comment|/*    * Read the reconstructionLog to see whether we need to build a brand-new     * MapFile out of non-flushed log entries.      *    * We can ignore any log message that has a sequence ID that's equal to or     * lower than maxSeqID.  (Because we know such log messages are already     * reflected in the MapFiles.)    */
specifier|private
name|void
name|doReconstructionLog
parameter_list|(
specifier|final
name|Path
name|reconstructionLog
parameter_list|,
specifier|final
name|long
name|maxSeqID
parameter_list|)
throws|throws
name|UnsupportedEncodingException
throws|,
name|IOException
block|{
if|if
condition|(
name|reconstructionLog
operator|==
literal|null
operator|||
operator|!
name|fs
operator|.
name|exists
argument_list|(
name|reconstructionLog
argument_list|)
condition|)
block|{
comment|// Nothing to do.
return|return;
block|}
name|long
name|maxSeqIdInLog
init|=
operator|-
literal|1
decl_stmt|;
name|TreeMap
argument_list|<
name|HStoreKey
argument_list|,
name|byte
index|[]
argument_list|>
name|reconstructedCache
init|=
operator|new
name|TreeMap
argument_list|<
name|HStoreKey
argument_list|,
name|byte
index|[]
argument_list|>
argument_list|()
decl_stmt|;
name|SequenceFile
operator|.
name|Reader
name|logReader
init|=
operator|new
name|SequenceFile
operator|.
name|Reader
argument_list|(
name|this
operator|.
name|fs
argument_list|,
name|reconstructionLog
argument_list|,
name|this
operator|.
name|conf
argument_list|)
decl_stmt|;
try|try
block|{
name|HLogKey
name|key
init|=
operator|new
name|HLogKey
argument_list|()
decl_stmt|;
name|HLogEdit
name|val
init|=
operator|new
name|HLogEdit
argument_list|()
decl_stmt|;
name|long
name|skippedEdits
init|=
literal|0
decl_stmt|;
while|while
condition|(
name|logReader
operator|.
name|next
argument_list|(
name|key
argument_list|,
name|val
argument_list|)
condition|)
block|{
name|maxSeqIdInLog
operator|=
name|Math
operator|.
name|max
argument_list|(
name|maxSeqIdInLog
argument_list|,
name|key
operator|.
name|getLogSeqNum
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|key
operator|.
name|getLogSeqNum
argument_list|()
operator|<=
name|maxSeqID
condition|)
block|{
name|skippedEdits
operator|++
expr_stmt|;
continue|continue;
block|}
if|if
condition|(
name|skippedEdits
operator|>
literal|0
operator|&&
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Skipped "
operator|+
name|skippedEdits
operator|+
literal|" edits because sequence id<= "
operator|+
name|maxSeqID
argument_list|)
expr_stmt|;
block|}
comment|// Check this edit is for me. Also, guard against writing
comment|// METACOLUMN info such as HBASE::CACHEFLUSH entries
name|Text
name|column
init|=
name|val
operator|.
name|getColumn
argument_list|()
decl_stmt|;
if|if
condition|(
name|column
operator|.
name|equals
argument_list|(
name|HLog
operator|.
name|METACOLUMN
argument_list|)
operator|||
operator|!
name|key
operator|.
name|getRegionName
argument_list|()
operator|.
name|equals
argument_list|(
name|info
operator|.
name|getRegionName
argument_list|()
argument_list|)
operator|||
operator|!
name|HStoreKey
operator|.
name|extractFamily
argument_list|(
name|column
argument_list|)
operator|.
name|equals
argument_list|(
name|family
operator|.
name|getFamilyName
argument_list|()
argument_list|)
condition|)
block|{
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Passing on edit "
operator|+
name|key
operator|.
name|getRegionName
argument_list|()
operator|+
literal|", "
operator|+
name|column
operator|.
name|toString
argument_list|()
operator|+
literal|": "
operator|+
operator|new
name|String
argument_list|(
name|val
operator|.
name|getVal
argument_list|()
argument_list|,
name|UTF8_ENCODING
argument_list|)
operator|+
literal|", my region: "
operator|+
name|info
operator|.
name|getRegionName
argument_list|()
operator|+
literal|", my column: "
operator|+
name|family
operator|.
name|getFamilyName
argument_list|()
argument_list|)
expr_stmt|;
block|}
continue|continue;
block|}
name|HStoreKey
name|k
init|=
operator|new
name|HStoreKey
argument_list|(
name|key
operator|.
name|getRow
argument_list|()
argument_list|,
name|column
argument_list|,
name|val
operator|.
name|getTimestamp
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Applying edit<"
operator|+
name|k
operator|.
name|toString
argument_list|()
operator|+
literal|"="
operator|+
name|val
operator|.
name|toString
argument_list|()
operator|+
literal|">"
argument_list|)
expr_stmt|;
block|}
name|reconstructedCache
operator|.
name|put
argument_list|(
name|k
argument_list|,
name|val
operator|.
name|getVal
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
finally|finally
block|{
name|logReader
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|reconstructedCache
operator|.
name|size
argument_list|()
operator|>
literal|0
condition|)
block|{
comment|// We create a "virtual flush" at maxSeqIdInLog+1.
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"flushing reconstructionCache"
argument_list|)
expr_stmt|;
block|}
name|internalFlushCache
argument_list|(
name|reconstructedCache
argument_list|,
name|maxSeqIdInLog
operator|+
literal|1
argument_list|)
expr_stmt|;
block|}
block|}
comment|/*    * Creates a series of HStoreFiles loaded from the given directory.    * There must be a matching 'mapdir' and 'loginfo' pair of files.    * If only one exists, we'll delete it.    *    * @param infodir qualified path for info file directory    * @param mapdir qualified path for map file directory    * @throws IOException    */
specifier|private
name|List
argument_list|<
name|HStoreFile
argument_list|>
name|loadHStoreFiles
parameter_list|(
name|Path
name|infodir
parameter_list|,
name|Path
name|mapdir
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"infodir: "
operator|+
name|infodir
operator|.
name|toString
argument_list|()
operator|+
literal|" mapdir: "
operator|+
name|mapdir
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|// Look first at info files.  If a reference, these contain info we need
comment|// to create the HStoreFile.
name|Path
name|infofiles
index|[]
init|=
name|fs
operator|.
name|listPaths
argument_list|(
operator|new
name|Path
index|[]
block|{
name|infodir
block|}
argument_list|)
decl_stmt|;
name|ArrayList
argument_list|<
name|HStoreFile
argument_list|>
name|results
init|=
operator|new
name|ArrayList
argument_list|<
name|HStoreFile
argument_list|>
argument_list|(
name|infofiles
operator|.
name|length
argument_list|)
decl_stmt|;
name|ArrayList
argument_list|<
name|Path
argument_list|>
name|mapfiles
init|=
operator|new
name|ArrayList
argument_list|<
name|Path
argument_list|>
argument_list|(
name|infofiles
operator|.
name|length
argument_list|)
decl_stmt|;
for|for
control|(
name|Path
name|p
range|:
name|infofiles
control|)
block|{
name|Matcher
name|m
init|=
name|REF_NAME_PARSER
operator|.
name|matcher
argument_list|(
name|p
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
comment|/*        *  *  *  *  *  N O T E  *  *  *  *  *        *          *  We call isReference(Path, Matcher) here because it calls        *  Matcher.matches() which must be called before Matcher.group(int)        *  and we don't want to call Matcher.matches() twice.        *          *  *  *  *  *  N O T E  *  *  *  *  *        */
name|boolean
name|isReference
init|=
name|isReference
argument_list|(
name|p
argument_list|,
name|m
argument_list|)
decl_stmt|;
name|long
name|fid
init|=
name|Long
operator|.
name|parseLong
argument_list|(
name|m
operator|.
name|group
argument_list|(
literal|1
argument_list|)
argument_list|)
decl_stmt|;
name|HStoreFile
name|curfile
init|=
literal|null
decl_stmt|;
name|HStoreFile
operator|.
name|Reference
name|reference
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|isReference
condition|)
block|{
name|reference
operator|=
name|readSplitInfo
argument_list|(
name|p
argument_list|,
name|fs
argument_list|)
expr_stmt|;
block|}
name|curfile
operator|=
operator|new
name|HStoreFile
argument_list|(
name|conf
argument_list|,
name|fs
argument_list|,
name|basedir
argument_list|,
name|info
operator|.
name|getEncodedName
argument_list|()
argument_list|,
name|family
operator|.
name|getFamilyName
argument_list|()
argument_list|,
name|fid
argument_list|,
name|reference
argument_list|)
expr_stmt|;
name|Path
name|mapfile
init|=
name|curfile
operator|.
name|getMapFilePath
argument_list|()
decl_stmt|;
if|if
condition|(
operator|!
name|fs
operator|.
name|exists
argument_list|(
name|mapfile
argument_list|)
condition|)
block|{
name|fs
operator|.
name|delete
argument_list|(
name|curfile
operator|.
name|getInfoFilePath
argument_list|()
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|warn
argument_list|(
literal|"Mapfile "
operator|+
name|mapfile
operator|.
name|toString
argument_list|()
operator|+
literal|" does not exist. "
operator|+
literal|"Cleaned up info file.  Continuing..."
argument_list|)
expr_stmt|;
continue|continue;
block|}
comment|// TODO: Confirm referent exists.
comment|// Found map and sympathetic info file.  Add this hstorefile to result.
name|results
operator|.
name|add
argument_list|(
name|curfile
argument_list|)
expr_stmt|;
comment|// Keep list of sympathetic data mapfiles for cleaning info dir in next
comment|// section.  Make sure path is fully qualified for compare.
name|mapfiles
operator|.
name|add
argument_list|(
name|mapfile
argument_list|)
expr_stmt|;
block|}
comment|// List paths by experience returns fully qualified names -- at least when
comment|// running on a mini hdfs cluster.
name|Path
name|datfiles
index|[]
init|=
name|fs
operator|.
name|listPaths
argument_list|(
operator|new
name|Path
index|[]
block|{
name|mapdir
block|}
argument_list|)
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|datfiles
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
comment|// If does not have sympathetic info file, delete.
if|if
condition|(
operator|!
name|mapfiles
operator|.
name|contains
argument_list|(
name|fs
operator|.
name|makeQualified
argument_list|(
name|datfiles
index|[
name|i
index|]
argument_list|)
argument_list|)
condition|)
block|{
name|fs
operator|.
name|delete
argument_list|(
name|datfiles
index|[
name|i
index|]
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|results
return|;
block|}
comment|//////////////////////////////////////////////////////////////////////////////
comment|// Bloom filters
comment|//////////////////////////////////////////////////////////////////////////////
comment|/**    * Called by constructor if a bloom filter is enabled for this column family.    * If the HStore already exists, it will read in the bloom filter saved    * previously. Otherwise, it will create a new bloom filter.    */
specifier|private
name|Filter
name|loadOrCreateBloomFilter
parameter_list|()
throws|throws
name|IOException
block|{
name|Path
name|filterFile
init|=
operator|new
name|Path
argument_list|(
name|filterDir
argument_list|,
name|BLOOMFILTER_FILE_NAME
argument_list|)
decl_stmt|;
name|Filter
name|bloomFilter
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|fs
operator|.
name|exists
argument_list|(
name|filterFile
argument_list|)
condition|)
block|{
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"loading bloom filter for "
operator|+
name|this
operator|.
name|storeName
argument_list|)
expr_stmt|;
block|}
name|BloomFilterDescriptor
operator|.
name|BloomFilterType
name|type
init|=
name|family
operator|.
name|getBloomFilter
argument_list|()
operator|.
name|filterType
decl_stmt|;
switch|switch
condition|(
name|type
condition|)
block|{
case|case
name|BLOOMFILTER
case|:
name|bloomFilter
operator|=
operator|new
name|BloomFilter
argument_list|()
expr_stmt|;
break|break;
case|case
name|COUNTING_BLOOMFILTER
case|:
name|bloomFilter
operator|=
operator|new
name|CountingBloomFilter
argument_list|()
expr_stmt|;
break|break;
case|case
name|RETOUCHED_BLOOMFILTER
case|:
name|bloomFilter
operator|=
operator|new
name|RetouchedBloomFilter
argument_list|()
expr_stmt|;
break|break;
default|default:
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"unknown bloom filter type: "
operator|+
name|type
argument_list|)
throw|;
block|}
name|FSDataInputStream
name|in
init|=
name|fs
operator|.
name|open
argument_list|(
name|filterFile
argument_list|)
decl_stmt|;
try|try
block|{
name|bloomFilter
operator|.
name|readFields
argument_list|(
name|in
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|fs
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
block|}
else|else
block|{
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"creating bloom filter for "
operator|+
name|this
operator|.
name|storeName
argument_list|)
expr_stmt|;
block|}
name|BloomFilterDescriptor
operator|.
name|BloomFilterType
name|type
init|=
name|family
operator|.
name|getBloomFilter
argument_list|()
operator|.
name|filterType
decl_stmt|;
switch|switch
condition|(
name|type
condition|)
block|{
case|case
name|BLOOMFILTER
case|:
name|bloomFilter
operator|=
operator|new
name|BloomFilter
argument_list|(
name|family
operator|.
name|getBloomFilter
argument_list|()
operator|.
name|vectorSize
argument_list|,
name|family
operator|.
name|getBloomFilter
argument_list|()
operator|.
name|nbHash
argument_list|)
expr_stmt|;
break|break;
case|case
name|COUNTING_BLOOMFILTER
case|:
name|bloomFilter
operator|=
operator|new
name|CountingBloomFilter
argument_list|(
name|family
operator|.
name|getBloomFilter
argument_list|()
operator|.
name|vectorSize
argument_list|,
name|family
operator|.
name|getBloomFilter
argument_list|()
operator|.
name|nbHash
argument_list|)
expr_stmt|;
break|break;
case|case
name|RETOUCHED_BLOOMFILTER
case|:
name|bloomFilter
operator|=
operator|new
name|RetouchedBloomFilter
argument_list|(
name|family
operator|.
name|getBloomFilter
argument_list|()
operator|.
name|vectorSize
argument_list|,
name|family
operator|.
name|getBloomFilter
argument_list|()
operator|.
name|nbHash
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|bloomFilter
return|;
block|}
comment|/**    * Flushes bloom filter to disk    *     * @throws IOException    */
specifier|private
name|void
name|flushBloomFilter
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"flushing bloom filter for "
operator|+
name|this
operator|.
name|storeName
argument_list|)
expr_stmt|;
block|}
name|FSDataOutputStream
name|out
init|=
name|fs
operator|.
name|create
argument_list|(
operator|new
name|Path
argument_list|(
name|filterDir
argument_list|,
name|BLOOMFILTER_FILE_NAME
argument_list|)
argument_list|)
decl_stmt|;
try|try
block|{
name|bloomFilter
operator|.
name|write
argument_list|(
name|out
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|out
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"flushed bloom filter for "
operator|+
name|this
operator|.
name|storeName
argument_list|)
expr_stmt|;
block|}
block|}
comment|//////////////////////////////////////////////////////////////////////////////
comment|// End bloom filters
comment|//////////////////////////////////////////////////////////////////////////////
comment|/**    * Adds a value to the memcache    *     * @param key    * @param value    */
name|void
name|add
parameter_list|(
name|HStoreKey
name|key
parameter_list|,
name|byte
index|[]
name|value
parameter_list|)
block|{
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
name|this
operator|.
name|memcache
operator|.
name|add
argument_list|(
name|key
argument_list|,
name|value
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**    * Close all the MapFile readers    *     * We don't need to worry about subsequent requests because the HRegion holds    * a write lock that will prevent any more reads or writes.    *     * @throws IOException    */
name|List
argument_list|<
name|HStoreFile
argument_list|>
name|close
parameter_list|()
throws|throws
name|IOException
block|{
name|ArrayList
argument_list|<
name|HStoreFile
argument_list|>
name|result
init|=
literal|null
decl_stmt|;
name|this
operator|.
name|lock
operator|.
name|writeLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
for|for
control|(
name|MapFile
operator|.
name|Reader
name|reader
range|:
name|this
operator|.
name|readers
operator|.
name|values
argument_list|()
control|)
block|{
name|reader
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
name|this
operator|.
name|readers
operator|.
name|clear
argument_list|()
expr_stmt|;
name|result
operator|=
operator|new
name|ArrayList
argument_list|<
name|HStoreFile
argument_list|>
argument_list|(
name|storefiles
operator|.
name|values
argument_list|()
argument_list|)
expr_stmt|;
name|this
operator|.
name|storefiles
operator|.
name|clear
argument_list|()
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"closed "
operator|+
name|this
operator|.
name|storeName
argument_list|)
expr_stmt|;
return|return
name|result
return|;
block|}
finally|finally
block|{
name|this
operator|.
name|lock
operator|.
name|writeLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
comment|//////////////////////////////////////////////////////////////////////////////
comment|// Flush changes to disk
comment|//////////////////////////////////////////////////////////////////////////////
comment|/**    * Prior to doing a cache flush, we need to snapshot the memcache. Locking is    * handled by the memcache.    */
name|void
name|snapshotMemcache
parameter_list|()
block|{
name|this
operator|.
name|memcache
operator|.
name|snapshot
argument_list|()
expr_stmt|;
block|}
comment|/**    * Write out a brand-new set of items to the disk.    *    * We should only store key/vals that are appropriate for the data-columns     * stored in this HStore.    *    * Also, we are not expecting any reads of this MapFile just yet.    *    * Return the entire list of HStoreFiles currently used by the HStore.    *    * @param logCacheFlushId flush sequence number    * @throws IOException    */
name|void
name|flushCache
parameter_list|(
specifier|final
name|long
name|logCacheFlushId
parameter_list|)
throws|throws
name|IOException
block|{
name|internalFlushCache
argument_list|(
name|memcache
operator|.
name|getSnapshot
argument_list|()
argument_list|,
name|logCacheFlushId
argument_list|)
expr_stmt|;
block|}
specifier|private
name|void
name|internalFlushCache
parameter_list|(
name|SortedMap
argument_list|<
name|HStoreKey
argument_list|,
name|byte
index|[]
argument_list|>
name|cache
parameter_list|,
name|long
name|logCacheFlushId
parameter_list|)
throws|throws
name|IOException
block|{
synchronized|synchronized
init|(
name|flushLock
init|)
block|{
comment|// A. Write the Maps out to the disk
name|HStoreFile
name|flushedFile
init|=
operator|new
name|HStoreFile
argument_list|(
name|conf
argument_list|,
name|fs
argument_list|,
name|basedir
argument_list|,
name|info
operator|.
name|getEncodedName
argument_list|()
argument_list|,
name|family
operator|.
name|getFamilyName
argument_list|()
argument_list|,
operator|-
literal|1L
argument_list|,
literal|null
argument_list|)
decl_stmt|;
name|String
name|name
init|=
name|flushedFile
operator|.
name|toString
argument_list|()
decl_stmt|;
name|MapFile
operator|.
name|Writer
name|out
init|=
name|flushedFile
operator|.
name|getWriter
argument_list|(
name|this
operator|.
name|fs
argument_list|,
name|this
operator|.
name|compression
argument_list|,
name|this
operator|.
name|bloomFilter
argument_list|)
decl_stmt|;
comment|// Here we tried picking up an existing HStoreFile from disk and
comment|// interlacing the memcache flush compacting as we go.  The notion was
comment|// that interlacing would take as long as a pure flush with the added
comment|// benefit of having one less file in the store.  Experiments showed that
comment|// it takes two to three times the amount of time flushing -- more column
comment|// families makes it so the two timings come closer together -- but it
comment|// also complicates the flush. The code was removed.  Needed work picking
comment|// which file to interlace (favor references first, etc.)
comment|//
comment|// Related, looks like 'merging compactions' in BigTable paper interlaces
comment|// a memcache flush.  We don't.
name|int
name|entries
init|=
literal|0
decl_stmt|;
try|try
block|{
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|HStoreKey
argument_list|,
name|byte
index|[]
argument_list|>
name|es
range|:
name|cache
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|HStoreKey
name|curkey
init|=
name|es
operator|.
name|getKey
argument_list|()
decl_stmt|;
name|TextSequence
name|f
init|=
name|HStoreKey
operator|.
name|extractFamily
argument_list|(
name|curkey
operator|.
name|getColumn
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|f
operator|.
name|equals
argument_list|(
name|this
operator|.
name|family
operator|.
name|getFamilyName
argument_list|()
argument_list|)
condition|)
block|{
name|entries
operator|++
expr_stmt|;
name|out
operator|.
name|append
argument_list|(
name|curkey
argument_list|,
operator|new
name|ImmutableBytesWritable
argument_list|(
name|es
operator|.
name|getValue
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
block|}
finally|finally
block|{
name|out
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
comment|// B. Write out the log sequence number that corresponds to this output
comment|// MapFile.  The MapFile is current up to and including the log seq num.
name|flushedFile
operator|.
name|writeInfo
argument_list|(
name|fs
argument_list|,
name|logCacheFlushId
argument_list|)
expr_stmt|;
comment|// C. Flush the bloom filter if any
if|if
condition|(
name|bloomFilter
operator|!=
literal|null
condition|)
block|{
name|flushBloomFilter
argument_list|()
expr_stmt|;
block|}
comment|// D. Finally, make the new MapFile available.
name|this
operator|.
name|lock
operator|.
name|writeLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
name|Long
name|flushid
init|=
name|Long
operator|.
name|valueOf
argument_list|(
name|logCacheFlushId
argument_list|)
decl_stmt|;
comment|// Open the map file reader.
name|this
operator|.
name|readers
operator|.
name|put
argument_list|(
name|flushid
argument_list|,
name|flushedFile
operator|.
name|getReader
argument_list|(
name|this
operator|.
name|fs
argument_list|,
name|this
operator|.
name|bloomFilter
argument_list|)
argument_list|)
expr_stmt|;
name|this
operator|.
name|storefiles
operator|.
name|put
argument_list|(
name|flushid
argument_list|,
name|flushedFile
argument_list|)
expr_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Added "
operator|+
name|name
operator|+
literal|" with "
operator|+
name|entries
operator|+
literal|" entries, sequence id "
operator|+
name|logCacheFlushId
operator|+
literal|", and size "
operator|+
name|StringUtils
operator|.
name|humanReadableInt
argument_list|(
name|flushedFile
operator|.
name|length
argument_list|()
argument_list|)
operator|+
literal|" for "
operator|+
name|this
operator|.
name|storeName
argument_list|)
expr_stmt|;
block|}
block|}
finally|finally
block|{
name|this
operator|.
name|lock
operator|.
name|writeLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
return|return;
block|}
block|}
comment|//////////////////////////////////////////////////////////////////////////////
comment|// Compaction
comment|//////////////////////////////////////////////////////////////////////////////
comment|/**    * @return True if this store needs compaction.    */
name|boolean
name|needsCompaction
parameter_list|()
block|{
name|boolean
name|compactionNeeded
init|=
literal|false
decl_stmt|;
if|if
condition|(
name|this
operator|.
name|storefiles
operator|!=
literal|null
condition|)
block|{
name|compactionNeeded
operator|=
name|this
operator|.
name|storefiles
operator|.
name|size
argument_list|()
operator|>=
name|this
operator|.
name|compactionThreshold
expr_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"compaction for HStore "
operator|+
name|storeName
operator|+
operator|(
name|compactionNeeded
condition|?
literal|" "
else|:
literal|" not "
operator|)
operator|+
literal|"needed."
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|compactionNeeded
return|;
block|}
comment|/**    * Compact the back-HStores.  This method may take some time, so the calling     * thread must be able to block for long periods.    *     *<p>During this time, the HStore can work as usual, getting values from    * MapFiles and writing new MapFiles from the Memcache.    *     * Existing MapFiles are not destroyed until the new compacted TreeMap is     * completely written-out to disk.    *    * The compactLock prevents multiple simultaneous compactions.    * The structureLock prevents us from interfering with other write operations.    *     * We don't want to hold the structureLock for the whole time, as a compact()     * can be lengthy and we want to allow cache-flushes during this period.    * @throws IOException    *     * @return true if compaction completed successfully    */
name|boolean
name|compact
parameter_list|()
throws|throws
name|IOException
block|{
synchronized|synchronized
init|(
name|compactLock
init|)
block|{
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"started compaction of "
operator|+
name|storefiles
operator|.
name|size
argument_list|()
operator|+
literal|" files using "
operator|+
name|compactionDir
operator|.
name|toString
argument_list|()
operator|+
literal|" for "
operator|+
name|this
operator|.
name|storeName
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|this
operator|.
name|fs
operator|.
name|exists
argument_list|(
name|compactionDir
argument_list|)
condition|)
block|{
comment|// Clean out its content in prep. for this new compaction.  Has either
comment|// aborted previous compaction or it has content of a previous
comment|// compaction.
name|Path
index|[]
name|toRemove
init|=
name|this
operator|.
name|fs
operator|.
name|listPaths
argument_list|(
operator|new
name|Path
index|[]
block|{
name|compactionDir
block|}
argument_list|)
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|toRemove
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|this
operator|.
name|fs
operator|.
name|delete
argument_list|(
name|toRemove
index|[
name|i
index|]
argument_list|)
expr_stmt|;
block|}
block|}
comment|// Storefiles are keyed by sequence id. The oldest file comes first.
comment|// We need to return out of here a List that has the newest file first.
name|List
argument_list|<
name|HStoreFile
argument_list|>
name|filesToCompact
init|=
operator|new
name|ArrayList
argument_list|<
name|HStoreFile
argument_list|>
argument_list|(
name|this
operator|.
name|storefiles
operator|.
name|values
argument_list|()
argument_list|)
decl_stmt|;
name|Collections
operator|.
name|reverse
argument_list|(
name|filesToCompact
argument_list|)
expr_stmt|;
if|if
condition|(
name|filesToCompact
operator|.
name|size
argument_list|()
operator|<
literal|1
operator|||
operator|(
name|filesToCompact
operator|.
name|size
argument_list|()
operator|==
literal|1
operator|&&
operator|!
name|filesToCompact
operator|.
name|get
argument_list|(
literal|0
argument_list|)
operator|.
name|isReference
argument_list|()
operator|)
condition|)
block|{
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"nothing to compact for "
operator|+
name|this
operator|.
name|storeName
argument_list|)
expr_stmt|;
block|}
return|return
literal|false
return|;
block|}
if|if
condition|(
operator|!
name|fs
operator|.
name|exists
argument_list|(
name|compactionDir
argument_list|)
operator|&&
operator|!
name|fs
operator|.
name|mkdirs
argument_list|(
name|compactionDir
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Mkdir on "
operator|+
name|compactionDir
operator|.
name|toString
argument_list|()
operator|+
literal|" for "
operator|+
name|this
operator|.
name|storeName
operator|+
literal|" failed"
argument_list|)
expr_stmt|;
return|return
literal|false
return|;
block|}
comment|// Step through them, writing to the brand-new MapFile
name|HStoreFile
name|compactedOutputFile
init|=
operator|new
name|HStoreFile
argument_list|(
name|conf
argument_list|,
name|fs
argument_list|,
name|this
operator|.
name|compactionDir
argument_list|,
name|info
operator|.
name|getEncodedName
argument_list|()
argument_list|,
name|family
operator|.
name|getFamilyName
argument_list|()
argument_list|,
operator|-
literal|1L
argument_list|,
literal|null
argument_list|)
decl_stmt|;
name|MapFile
operator|.
name|Writer
name|compactedOut
init|=
name|compactedOutputFile
operator|.
name|getWriter
argument_list|(
name|this
operator|.
name|fs
argument_list|,
name|this
operator|.
name|compression
argument_list|,
name|this
operator|.
name|bloomFilter
argument_list|)
decl_stmt|;
try|try
block|{
name|compactHStoreFiles
argument_list|(
name|compactedOut
argument_list|,
name|filesToCompact
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|compactedOut
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
comment|// Now, write out an HSTORE_LOGINFOFILE for the brand-new TreeMap.
comment|// Compute max-sequenceID seen in any of the to-be-compacted TreeMaps.
name|long
name|maxId
init|=
name|getMaxSequenceId
argument_list|(
name|filesToCompact
argument_list|)
decl_stmt|;
name|compactedOutputFile
operator|.
name|writeInfo
argument_list|(
name|fs
argument_list|,
name|maxId
argument_list|)
expr_stmt|;
comment|// Move the compaction into place.
name|completeCompaction
argument_list|(
name|filesToCompact
argument_list|,
name|compactedOutputFile
argument_list|)
expr_stmt|;
return|return
literal|true
return|;
block|}
block|}
comment|/*    * Compact passed<code>toCompactFiles</code> into<code>compactedOut</code>.    * We create a new set of MapFile.Reader objects so we don't screw up the    * caching associated with the currently-loaded ones. Our iteration-based    * access pattern is practically designed to ruin the cache.    *     * We work by opening a single MapFile.Reader for each file, and iterating    * through them in parallel. We always increment the lowest-ranked one.    * Updates to a single row/column will appear ranked by timestamp. This allows    * us to throw out deleted values or obsolete versions. @param compactedOut    * @param toCompactFiles @throws IOException    */
specifier|private
name|void
name|compactHStoreFiles
parameter_list|(
specifier|final
name|MapFile
operator|.
name|Writer
name|compactedOut
parameter_list|,
specifier|final
name|List
argument_list|<
name|HStoreFile
argument_list|>
name|toCompactFiles
parameter_list|)
throws|throws
name|IOException
block|{
name|int
name|size
init|=
name|toCompactFiles
operator|.
name|size
argument_list|()
decl_stmt|;
name|CompactionReader
index|[]
name|rdrs
init|=
operator|new
name|CompactionReader
index|[
name|size
index|]
decl_stmt|;
name|int
name|index
init|=
literal|0
decl_stmt|;
for|for
control|(
name|HStoreFile
name|hsf
range|:
name|toCompactFiles
control|)
block|{
try|try
block|{
name|rdrs
index|[
name|index
operator|++
index|]
operator|=
operator|new
name|MapFileCompactionReader
argument_list|(
name|hsf
operator|.
name|getReader
argument_list|(
name|fs
argument_list|,
name|bloomFilter
argument_list|)
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
comment|// Add info about which file threw exception. It may not be in the
comment|// exception message so output a message here where we know the
comment|// culprit.
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failed with "
operator|+
name|e
operator|.
name|toString
argument_list|()
operator|+
literal|": "
operator|+
name|hsf
operator|.
name|toString
argument_list|()
operator|+
operator|(
name|hsf
operator|.
name|isReference
argument_list|()
condition|?
literal|" "
operator|+
name|hsf
operator|.
name|getReference
argument_list|()
operator|.
name|toString
argument_list|()
else|:
literal|""
operator|)
operator|+
literal|" for "
operator|+
name|this
operator|.
name|storeName
argument_list|)
expr_stmt|;
name|closeCompactionReaders
argument_list|(
name|rdrs
argument_list|)
expr_stmt|;
throw|throw
name|e
throw|;
block|}
block|}
try|try
block|{
name|HStoreKey
index|[]
name|keys
init|=
operator|new
name|HStoreKey
index|[
name|rdrs
operator|.
name|length
index|]
decl_stmt|;
name|ImmutableBytesWritable
index|[]
name|vals
init|=
operator|new
name|ImmutableBytesWritable
index|[
name|rdrs
operator|.
name|length
index|]
decl_stmt|;
name|boolean
index|[]
name|done
init|=
operator|new
name|boolean
index|[
name|rdrs
operator|.
name|length
index|]
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|rdrs
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|keys
index|[
name|i
index|]
operator|=
operator|new
name|HStoreKey
argument_list|()
expr_stmt|;
name|vals
index|[
name|i
index|]
operator|=
operator|new
name|ImmutableBytesWritable
argument_list|()
expr_stmt|;
name|done
index|[
name|i
index|]
operator|=
literal|false
expr_stmt|;
block|}
comment|// Now, advance through the readers in order.  This will have the
comment|// effect of a run-time sort of the entire dataset.
name|int
name|numDone
init|=
literal|0
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|rdrs
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|rdrs
index|[
name|i
index|]
operator|.
name|reset
argument_list|()
expr_stmt|;
name|done
index|[
name|i
index|]
operator|=
operator|!
name|rdrs
index|[
name|i
index|]
operator|.
name|next
argument_list|(
name|keys
index|[
name|i
index|]
argument_list|,
name|vals
index|[
name|i
index|]
argument_list|)
expr_stmt|;
if|if
condition|(
name|done
index|[
name|i
index|]
condition|)
block|{
name|numDone
operator|++
expr_stmt|;
block|}
block|}
name|int
name|timesSeen
init|=
literal|0
decl_stmt|;
name|Text
name|lastRow
init|=
operator|new
name|Text
argument_list|()
decl_stmt|;
name|Text
name|lastColumn
init|=
operator|new
name|Text
argument_list|()
decl_stmt|;
comment|// Map of a row deletes keyed by column with a list of timestamps for value
name|Map
argument_list|<
name|Text
argument_list|,
name|List
argument_list|<
name|Long
argument_list|>
argument_list|>
name|deletes
init|=
literal|null
decl_stmt|;
while|while
condition|(
name|numDone
operator|<
name|done
operator|.
name|length
condition|)
block|{
comment|// Find the reader with the smallest key.  If two files have same key
comment|// but different values -- i.e. one is delete and other is non-delete
comment|// value -- we will find the first, the one that was written later and
comment|// therefore the one whose value should make it out to the compacted
comment|// store file.
name|int
name|smallestKey
init|=
operator|-
literal|1
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|rdrs
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|done
index|[
name|i
index|]
condition|)
block|{
continue|continue;
block|}
if|if
condition|(
name|smallestKey
operator|<
literal|0
condition|)
block|{
name|smallestKey
operator|=
name|i
expr_stmt|;
block|}
else|else
block|{
if|if
condition|(
name|keys
index|[
name|i
index|]
operator|.
name|compareTo
argument_list|(
name|keys
index|[
name|smallestKey
index|]
argument_list|)
operator|<
literal|0
condition|)
block|{
name|smallestKey
operator|=
name|i
expr_stmt|;
block|}
block|}
block|}
comment|// Reflect the current key/val in the output
name|HStoreKey
name|sk
init|=
name|keys
index|[
name|smallestKey
index|]
decl_stmt|;
if|if
condition|(
name|lastRow
operator|.
name|equals
argument_list|(
name|sk
operator|.
name|getRow
argument_list|()
argument_list|)
operator|&&
name|lastColumn
operator|.
name|equals
argument_list|(
name|sk
operator|.
name|getColumn
argument_list|()
argument_list|)
condition|)
block|{
name|timesSeen
operator|++
expr_stmt|;
block|}
else|else
block|{
name|timesSeen
operator|=
literal|1
expr_stmt|;
comment|// We are on to a new row.  Create a new deletes list.
name|deletes
operator|=
operator|new
name|HashMap
argument_list|<
name|Text
argument_list|,
name|List
argument_list|<
name|Long
argument_list|>
argument_list|>
argument_list|()
expr_stmt|;
block|}
name|byte
index|[]
name|value
init|=
operator|(
name|vals
index|[
name|smallestKey
index|]
operator|==
literal|null
operator|)
condition|?
literal|null
else|:
name|vals
index|[
name|smallestKey
index|]
operator|.
name|get
argument_list|()
decl_stmt|;
if|if
condition|(
operator|!
name|isDeleted
argument_list|(
name|sk
argument_list|,
name|value
argument_list|,
literal|false
argument_list|,
name|deletes
argument_list|)
operator|&&
name|timesSeen
operator|<=
name|family
operator|.
name|getMaxVersions
argument_list|()
condition|)
block|{
comment|// Keep old versions until we have maxVersions worth.
comment|// Then just skip them.
if|if
condition|(
name|sk
operator|.
name|getRow
argument_list|()
operator|.
name|getLength
argument_list|()
operator|!=
literal|0
operator|&&
name|sk
operator|.
name|getColumn
argument_list|()
operator|.
name|getLength
argument_list|()
operator|!=
literal|0
condition|)
block|{
comment|// Only write out objects which have a non-zero length key and
comment|// value
name|compactedOut
operator|.
name|append
argument_list|(
name|sk
argument_list|,
name|vals
index|[
name|smallestKey
index|]
argument_list|)
expr_stmt|;
block|}
block|}
comment|// Update last-seen items
name|lastRow
operator|.
name|set
argument_list|(
name|sk
operator|.
name|getRow
argument_list|()
argument_list|)
expr_stmt|;
name|lastColumn
operator|.
name|set
argument_list|(
name|sk
operator|.
name|getColumn
argument_list|()
argument_list|)
expr_stmt|;
comment|// Advance the smallest key.  If that reader's all finished, then
comment|// mark it as done.
if|if
condition|(
operator|!
name|rdrs
index|[
name|smallestKey
index|]
operator|.
name|next
argument_list|(
name|keys
index|[
name|smallestKey
index|]
argument_list|,
name|vals
index|[
name|smallestKey
index|]
argument_list|)
condition|)
block|{
name|done
index|[
name|smallestKey
index|]
operator|=
literal|true
expr_stmt|;
name|rdrs
index|[
name|smallestKey
index|]
operator|.
name|close
argument_list|()
expr_stmt|;
name|rdrs
index|[
name|smallestKey
index|]
operator|=
literal|null
expr_stmt|;
name|numDone
operator|++
expr_stmt|;
block|}
block|}
block|}
finally|finally
block|{
name|closeCompactionReaders
argument_list|(
name|rdrs
argument_list|)
expr_stmt|;
block|}
block|}
specifier|private
name|void
name|closeCompactionReaders
parameter_list|(
specifier|final
name|CompactionReader
index|[]
name|rdrs
parameter_list|)
block|{
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|rdrs
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|rdrs
index|[
name|i
index|]
operator|!=
literal|null
condition|)
block|{
try|try
block|{
name|rdrs
index|[
name|i
index|]
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Exception closing reader for "
operator|+
name|this
operator|.
name|storeName
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
comment|/** Interface for generic reader for compactions */
interface|interface
name|CompactionReader
block|{
comment|/**      * Closes the reader      * @throws IOException      */
specifier|public
name|void
name|close
parameter_list|()
throws|throws
name|IOException
function_decl|;
comment|/**      * Get the next key/value pair      *       * @param key      * @param val      * @return true if more data was returned      * @throws IOException      */
specifier|public
name|boolean
name|next
parameter_list|(
name|WritableComparable
name|key
parameter_list|,
name|Writable
name|val
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**      * Resets the reader      * @throws IOException      */
specifier|public
name|void
name|reset
parameter_list|()
throws|throws
name|IOException
function_decl|;
block|}
comment|/** A compaction reader for MapFile */
specifier|static
class|class
name|MapFileCompactionReader
implements|implements
name|CompactionReader
block|{
specifier|final
name|MapFile
operator|.
name|Reader
name|reader
decl_stmt|;
name|MapFileCompactionReader
parameter_list|(
specifier|final
name|MapFile
operator|.
name|Reader
name|r
parameter_list|)
block|{
name|this
operator|.
name|reader
operator|=
name|r
expr_stmt|;
block|}
comment|/** {@inheritDoc} */
specifier|public
name|void
name|close
parameter_list|()
throws|throws
name|IOException
block|{
name|this
operator|.
name|reader
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
comment|/** {@inheritDoc} */
specifier|public
name|boolean
name|next
parameter_list|(
name|WritableComparable
name|key
parameter_list|,
name|Writable
name|val
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|this
operator|.
name|reader
operator|.
name|next
argument_list|(
name|key
argument_list|,
name|val
argument_list|)
return|;
block|}
comment|/** {@inheritDoc} */
specifier|public
name|void
name|reset
parameter_list|()
throws|throws
name|IOException
block|{
name|this
operator|.
name|reader
operator|.
name|reset
argument_list|()
expr_stmt|;
block|}
block|}
comment|/*    * Check if this is cell is deleted.    * If a memcache and a deletes, check key does not have an entry filled.    * Otherwise, check value is not the<code>HGlobals.deleteBytes</code> value.    * If passed value IS deleteBytes, then it is added to the passed    * deletes map.    * @param hsk    * @param value    * @param checkMemcache true if the memcache should be consulted    * @param deletes Map keyed by column with a value of timestamp. Can be null.    * If non-null and passed value is HGlobals.deleteBytes, then we add to this    * map.    * @return True if this is a deleted cell.  Adds the passed deletes map if    * passed value is HGlobals.deleteBytes.   */
specifier|private
name|boolean
name|isDeleted
parameter_list|(
specifier|final
name|HStoreKey
name|hsk
parameter_list|,
specifier|final
name|byte
index|[]
name|value
parameter_list|,
specifier|final
name|boolean
name|checkMemcache
parameter_list|,
specifier|final
name|Map
argument_list|<
name|Text
argument_list|,
name|List
argument_list|<
name|Long
argument_list|>
argument_list|>
name|deletes
parameter_list|)
block|{
if|if
condition|(
name|checkMemcache
operator|&&
name|memcache
operator|.
name|isDeleted
argument_list|(
name|hsk
argument_list|)
condition|)
block|{
return|return
literal|true
return|;
block|}
name|List
argument_list|<
name|Long
argument_list|>
name|timestamps
init|=
operator|(
name|deletes
operator|==
literal|null
operator|)
condition|?
literal|null
else|:
name|deletes
operator|.
name|get
argument_list|(
name|hsk
operator|.
name|getColumn
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|timestamps
operator|!=
literal|null
operator|&&
name|timestamps
operator|.
name|contains
argument_list|(
name|Long
operator|.
name|valueOf
argument_list|(
name|hsk
operator|.
name|getTimestamp
argument_list|()
argument_list|)
argument_list|)
condition|)
block|{
return|return
literal|true
return|;
block|}
if|if
condition|(
name|value
operator|==
literal|null
condition|)
block|{
comment|// If a null value, shouldn't be in here.  Mark it as deleted cell.
return|return
literal|true
return|;
block|}
if|if
condition|(
operator|!
name|HLogEdit
operator|.
name|isDeleted
argument_list|(
name|value
argument_list|)
condition|)
block|{
return|return
literal|false
return|;
block|}
comment|// Cell has delete value.  Save it into deletes.
if|if
condition|(
name|deletes
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
name|timestamps
operator|==
literal|null
condition|)
block|{
name|timestamps
operator|=
operator|new
name|ArrayList
argument_list|<
name|Long
argument_list|>
argument_list|()
expr_stmt|;
name|deletes
operator|.
name|put
argument_list|(
name|hsk
operator|.
name|getColumn
argument_list|()
argument_list|,
name|timestamps
argument_list|)
expr_stmt|;
block|}
comment|// We know its not already in the deletes array else we'd have returned
comment|// earlier so no need to test if timestamps already has this value.
name|timestamps
operator|.
name|add
argument_list|(
name|Long
operator|.
name|valueOf
argument_list|(
name|hsk
operator|.
name|getTimestamp
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
return|return
literal|true
return|;
block|}
comment|/*    * It's assumed that the compactLock  will be acquired prior to calling this     * method!  Otherwise, it is not thread-safe!    *    * It works by processing a compaction that's been written to disk.    *     *<p>It is usually invoked at the end of a compaction, but might also be    * invoked at HStore startup, if the prior execution died midway through.    *     *<p>Moving the compacted TreeMap into place means:    *<pre>    * 1) Wait for active scanners to exit    * 2) Acquiring the write-lock    * 3) Figuring out what MapFiles are going to be replaced    * 4) Moving the new compacted MapFile into place    * 5) Unloading all the replaced MapFiles.    * 6) Deleting all the old MapFile files.    * 7) Loading the new TreeMap.    * 8) Releasing the write-lock    * 9) Allow new scanners to proceed.    *</pre>    *     * @param compactedFiles list of files that were compacted    * @param compactedFile HStoreFile that is the result of the compaction    * @throws IOException    */
specifier|private
name|void
name|completeCompaction
parameter_list|(
name|List
argument_list|<
name|HStoreFile
argument_list|>
name|compactedFiles
parameter_list|,
name|HStoreFile
name|compactedFile
parameter_list|)
throws|throws
name|IOException
block|{
comment|// 1. Wait for active scanners to exit
name|newScannerLock
operator|.
name|writeLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
comment|// prevent new scanners
try|try
block|{
synchronized|synchronized
init|(
name|activeScanners
init|)
block|{
while|while
condition|(
name|activeScanners
operator|.
name|get
argument_list|()
operator|!=
literal|0
condition|)
block|{
try|try
block|{
name|activeScanners
operator|.
name|wait
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
comment|// continue
block|}
block|}
comment|// 2. Acquiring the HStore write-lock
name|this
operator|.
name|lock
operator|.
name|writeLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
block|}
try|try
block|{
comment|// 3. Moving the new MapFile into place.
name|HStoreFile
name|finalCompactedFile
init|=
operator|new
name|HStoreFile
argument_list|(
name|conf
argument_list|,
name|fs
argument_list|,
name|basedir
argument_list|,
name|info
operator|.
name|getEncodedName
argument_list|()
argument_list|,
name|family
operator|.
name|getFamilyName
argument_list|()
argument_list|,
operator|-
literal|1
argument_list|,
literal|null
argument_list|)
decl_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"moving "
operator|+
name|compactedFile
operator|.
name|toString
argument_list|()
operator|+
literal|" in "
operator|+
name|this
operator|.
name|compactionDir
operator|.
name|toString
argument_list|()
operator|+
literal|" to "
operator|+
name|finalCompactedFile
operator|.
name|toString
argument_list|()
operator|+
literal|" in "
operator|+
name|basedir
operator|.
name|toString
argument_list|()
operator|+
literal|" for "
operator|+
name|this
operator|.
name|storeName
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|!
name|compactedFile
operator|.
name|rename
argument_list|(
name|this
operator|.
name|fs
argument_list|,
name|finalCompactedFile
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Failed move of compacted file "
operator|+
name|finalCompactedFile
operator|.
name|toString
argument_list|()
operator|+
literal|" for "
operator|+
name|this
operator|.
name|storeName
argument_list|)
expr_stmt|;
return|return;
block|}
comment|// 4. and 5. Unload all the replaced MapFiles, close and delete.
name|List
argument_list|<
name|Long
argument_list|>
name|toDelete
init|=
operator|new
name|ArrayList
argument_list|<
name|Long
argument_list|>
argument_list|()
decl_stmt|;
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|Long
argument_list|,
name|HStoreFile
argument_list|>
name|e
range|:
name|this
operator|.
name|storefiles
operator|.
name|entrySet
argument_list|()
control|)
block|{
if|if
condition|(
operator|!
name|compactedFiles
operator|.
name|contains
argument_list|(
name|e
operator|.
name|getValue
argument_list|()
argument_list|)
condition|)
block|{
continue|continue;
block|}
name|Long
name|key
init|=
name|e
operator|.
name|getKey
argument_list|()
decl_stmt|;
name|MapFile
operator|.
name|Reader
name|reader
init|=
name|this
operator|.
name|readers
operator|.
name|remove
argument_list|(
name|key
argument_list|)
decl_stmt|;
if|if
condition|(
name|reader
operator|!=
literal|null
condition|)
block|{
name|reader
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
name|toDelete
operator|.
name|add
argument_list|(
name|key
argument_list|)
expr_stmt|;
block|}
try|try
block|{
for|for
control|(
name|Long
name|key
range|:
name|toDelete
control|)
block|{
name|HStoreFile
name|hsf
init|=
name|this
operator|.
name|storefiles
operator|.
name|remove
argument_list|(
name|key
argument_list|)
decl_stmt|;
name|hsf
operator|.
name|delete
argument_list|()
expr_stmt|;
block|}
comment|// 6. Loading the new TreeMap.
name|Long
name|orderVal
init|=
name|Long
operator|.
name|valueOf
argument_list|(
name|finalCompactedFile
operator|.
name|loadInfo
argument_list|(
name|fs
argument_list|)
argument_list|)
decl_stmt|;
name|this
operator|.
name|readers
operator|.
name|put
argument_list|(
name|orderVal
argument_list|,
name|finalCompactedFile
operator|.
name|getReader
argument_list|(
name|this
operator|.
name|fs
argument_list|,
name|this
operator|.
name|bloomFilter
argument_list|)
argument_list|)
expr_stmt|;
name|this
operator|.
name|storefiles
operator|.
name|put
argument_list|(
name|orderVal
argument_list|,
name|finalCompactedFile
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|e
operator|=
name|RemoteExceptionHandler
operator|.
name|checkIOException
argument_list|(
name|e
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|error
argument_list|(
literal|"Failed replacing compacted files for "
operator|+
name|this
operator|.
name|storeName
operator|+
literal|". Compacted file is "
operator|+
name|finalCompactedFile
operator|.
name|toString
argument_list|()
operator|+
literal|".  Files replaced are "
operator|+
name|compactedFiles
operator|.
name|toString
argument_list|()
operator|+
literal|" some of which may have been already removed"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
block|}
finally|finally
block|{
comment|// 7. Releasing the write-lock
name|this
operator|.
name|lock
operator|.
name|writeLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
finally|finally
block|{
comment|// 8. Allow new scanners to proceed.
name|newScannerLock
operator|.
name|writeLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
comment|//////////////////////////////////////////////////////////////////////////////
comment|// Accessors.
comment|// (This is the only section that is directly useful!)
comment|//////////////////////////////////////////////////////////////////////////////
comment|/**    * Return all the available columns for the given key.  The key indicates a     * row and timestamp, but not a column name.    *    * The returned object should map column names to byte arrays (byte[]).    */
name|void
name|getFull
parameter_list|(
name|HStoreKey
name|key
parameter_list|,
name|TreeMap
argument_list|<
name|Text
argument_list|,
name|byte
index|[]
argument_list|>
name|results
parameter_list|)
throws|throws
name|IOException
block|{
name|Map
argument_list|<
name|Text
argument_list|,
name|List
argument_list|<
name|Long
argument_list|>
argument_list|>
name|deletes
init|=
operator|new
name|HashMap
argument_list|<
name|Text
argument_list|,
name|List
argument_list|<
name|Long
argument_list|>
argument_list|>
argument_list|()
decl_stmt|;
if|if
condition|(
name|key
operator|==
literal|null
condition|)
block|{
return|return;
block|}
name|this
operator|.
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
name|memcache
operator|.
name|getFull
argument_list|(
name|key
argument_list|,
name|results
argument_list|)
expr_stmt|;
try|try
block|{
name|MapFile
operator|.
name|Reader
index|[]
name|maparray
init|=
name|getReaders
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
name|maparray
operator|.
name|length
operator|-
literal|1
init|;
name|i
operator|>=
literal|0
condition|;
name|i
operator|--
control|)
block|{
name|MapFile
operator|.
name|Reader
name|map
init|=
name|maparray
index|[
name|i
index|]
decl_stmt|;
synchronized|synchronized
init|(
name|map
init|)
block|{
name|map
operator|.
name|reset
argument_list|()
expr_stmt|;
name|ImmutableBytesWritable
name|readval
init|=
operator|new
name|ImmutableBytesWritable
argument_list|()
decl_stmt|;
name|HStoreKey
name|readkey
init|=
operator|(
name|HStoreKey
operator|)
name|map
operator|.
name|getClosest
argument_list|(
name|key
argument_list|,
name|readval
argument_list|)
decl_stmt|;
if|if
condition|(
name|readkey
operator|==
literal|null
condition|)
block|{
continue|continue;
block|}
do|do
block|{
name|Text
name|readcol
init|=
name|readkey
operator|.
name|getColumn
argument_list|()
decl_stmt|;
if|if
condition|(
name|results
operator|.
name|get
argument_list|(
name|readcol
argument_list|)
operator|==
literal|null
operator|&&
name|key
operator|.
name|matchesWithoutColumn
argument_list|(
name|readkey
argument_list|)
condition|)
block|{
if|if
condition|(
name|isDeleted
argument_list|(
name|readkey
argument_list|,
name|readval
operator|.
name|get
argument_list|()
argument_list|,
literal|true
argument_list|,
name|deletes
argument_list|)
condition|)
block|{
break|break;
block|}
name|results
operator|.
name|put
argument_list|(
operator|new
name|Text
argument_list|(
name|readcol
argument_list|)
argument_list|,
name|readval
operator|.
name|get
argument_list|()
argument_list|)
expr_stmt|;
name|readval
operator|=
operator|new
name|ImmutableBytesWritable
argument_list|()
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|key
operator|.
name|getRow
argument_list|()
operator|.
name|compareTo
argument_list|(
name|readkey
operator|.
name|getRow
argument_list|()
argument_list|)
operator|<
literal|0
condition|)
block|{
break|break;
block|}
block|}
do|while
condition|(
name|map
operator|.
name|next
argument_list|(
name|readkey
argument_list|,
name|readval
argument_list|)
condition|)
do|;
block|}
block|}
block|}
finally|finally
block|{
name|this
operator|.
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
name|MapFile
operator|.
name|Reader
index|[]
name|getReaders
parameter_list|()
block|{
return|return
name|this
operator|.
name|readers
operator|.
name|values
argument_list|()
operator|.
name|toArray
argument_list|(
operator|new
name|MapFile
operator|.
name|Reader
index|[
name|this
operator|.
name|readers
operator|.
name|size
argument_list|()
index|]
argument_list|)
return|;
block|}
comment|/**    * Get the value for the indicated HStoreKey.  Grab the target value and the     * previous 'numVersions-1' values, as well.    *    * If 'numVersions' is negative, the method returns all available versions.    * @param key    * @param numVersions Number of versions to fetch.  Must be> 0.    * @return values for the specified versions    * @throws IOException    */
name|byte
index|[]
index|[]
name|get
parameter_list|(
name|HStoreKey
name|key
parameter_list|,
name|int
name|numVersions
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|numVersions
operator|<=
literal|0
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"Number of versions must be> 0"
argument_list|)
throw|;
block|}
name|this
operator|.
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
comment|// Check the memcache
name|List
argument_list|<
name|byte
index|[]
argument_list|>
name|results
init|=
name|this
operator|.
name|memcache
operator|.
name|get
argument_list|(
name|key
argument_list|,
name|numVersions
argument_list|)
decl_stmt|;
comment|// If we got sufficient versions from memcache, return.
if|if
condition|(
name|results
operator|.
name|size
argument_list|()
operator|==
name|numVersions
condition|)
block|{
return|return
name|ImmutableBytesWritable
operator|.
name|toArray
argument_list|(
name|results
argument_list|)
return|;
block|}
comment|// Keep a list of deleted cell keys.  We need this because as we go through
comment|// the store files, the cell with the delete marker may be in one file and
comment|// the old non-delete cell value in a later store file. If we don't keep
comment|// around the fact that the cell was deleted in a newer record, we end up
comment|// returning the old value if user is asking for more than one version.
comment|// This List of deletes should not large since we are only keeping rows
comment|// and columns that match those set on the scanner and which have delete
comment|// values.  If memory usage becomes an issue, could redo as bloom filter.
name|Map
argument_list|<
name|Text
argument_list|,
name|List
argument_list|<
name|Long
argument_list|>
argument_list|>
name|deletes
init|=
operator|new
name|HashMap
argument_list|<
name|Text
argument_list|,
name|List
argument_list|<
name|Long
argument_list|>
argument_list|>
argument_list|()
decl_stmt|;
comment|// This code below is very close to the body of the getKeys method.
name|MapFile
operator|.
name|Reader
index|[]
name|maparray
init|=
name|getReaders
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
name|maparray
operator|.
name|length
operator|-
literal|1
init|;
name|i
operator|>=
literal|0
condition|;
name|i
operator|--
control|)
block|{
name|MapFile
operator|.
name|Reader
name|map
init|=
name|maparray
index|[
name|i
index|]
decl_stmt|;
synchronized|synchronized
init|(
name|map
init|)
block|{
name|map
operator|.
name|reset
argument_list|()
expr_stmt|;
name|ImmutableBytesWritable
name|readval
init|=
operator|new
name|ImmutableBytesWritable
argument_list|()
decl_stmt|;
name|HStoreKey
name|readkey
init|=
operator|(
name|HStoreKey
operator|)
name|map
operator|.
name|getClosest
argument_list|(
name|key
argument_list|,
name|readval
argument_list|)
decl_stmt|;
if|if
condition|(
name|readkey
operator|==
literal|null
condition|)
block|{
comment|// map.getClosest returns null if the passed key is> than the
comment|// last key in the map file.  getClosest is a bit of a misnomer
comment|// since it returns exact match or the next closest key AFTER not
comment|// BEFORE.
continue|continue;
block|}
if|if
condition|(
operator|!
name|readkey
operator|.
name|matchesRowCol
argument_list|(
name|key
argument_list|)
condition|)
block|{
continue|continue;
block|}
if|if
condition|(
operator|!
name|isDeleted
argument_list|(
name|readkey
argument_list|,
name|readval
operator|.
name|get
argument_list|()
argument_list|,
literal|true
argument_list|,
name|deletes
argument_list|)
condition|)
block|{
name|results
operator|.
name|add
argument_list|(
name|readval
operator|.
name|get
argument_list|()
argument_list|)
expr_stmt|;
comment|// Perhaps only one version is wanted.  I could let this
comment|// test happen later in the for loop test but it would cost
comment|// the allocation of an ImmutableBytesWritable.
if|if
condition|(
name|hasEnoughVersions
argument_list|(
name|numVersions
argument_list|,
name|results
argument_list|)
condition|)
block|{
break|break;
block|}
block|}
for|for
control|(
name|readval
operator|=
operator|new
name|ImmutableBytesWritable
argument_list|()
init|;
name|map
operator|.
name|next
argument_list|(
name|readkey
argument_list|,
name|readval
argument_list|)
operator|&&
name|readkey
operator|.
name|matchesRowCol
argument_list|(
name|key
argument_list|)
operator|&&
operator|!
name|hasEnoughVersions
argument_list|(
name|numVersions
argument_list|,
name|results
argument_list|)
condition|;
name|readval
operator|=
operator|new
name|ImmutableBytesWritable
argument_list|()
control|)
block|{
if|if
condition|(
operator|!
name|isDeleted
argument_list|(
name|readkey
argument_list|,
name|readval
operator|.
name|get
argument_list|()
argument_list|,
literal|true
argument_list|,
name|deletes
argument_list|)
condition|)
block|{
name|results
operator|.
name|add
argument_list|(
name|readval
operator|.
name|get
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
block|}
if|if
condition|(
name|hasEnoughVersions
argument_list|(
name|numVersions
argument_list|,
name|results
argument_list|)
condition|)
block|{
break|break;
block|}
block|}
return|return
name|results
operator|.
name|size
argument_list|()
operator|==
literal|0
condition|?
literal|null
else|:
name|ImmutableBytesWritable
operator|.
name|toArray
argument_list|(
name|results
argument_list|)
return|;
block|}
finally|finally
block|{
name|this
operator|.
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
specifier|private
name|boolean
name|hasEnoughVersions
parameter_list|(
specifier|final
name|int
name|numVersions
parameter_list|,
specifier|final
name|List
argument_list|<
name|byte
index|[]
argument_list|>
name|results
parameter_list|)
block|{
return|return
name|numVersions
operator|>
literal|0
operator|&&
name|results
operator|.
name|size
argument_list|()
operator|>=
name|numVersions
return|;
block|}
comment|/**    * Get<code>versions</code> keys matching the origin key's    * row/column/timestamp and those of an older vintage    * Default access so can be accessed out of {@link HRegionServer}.    * @param origin Where to start searching.    * @param versions How many versions to return. Pass    * {@link HConstants.ALL_VERSIONS} to retrieve all. Versions will include    * size of passed<code>allKeys</code> in its count.    * @param allKeys List of keys prepopulated by keys we found in memcache.    * This method returns this passed list with all matching keys found in    * stores appended.    * @return The passed<code>allKeys</code> with<code>versions</code> of    * matching keys found in store files appended.    * @throws IOException    */
name|List
argument_list|<
name|HStoreKey
argument_list|>
name|getKeys
parameter_list|(
specifier|final
name|HStoreKey
name|origin
parameter_list|,
specifier|final
name|int
name|versions
parameter_list|)
throws|throws
name|IOException
block|{
name|List
argument_list|<
name|HStoreKey
argument_list|>
name|keys
init|=
name|this
operator|.
name|memcache
operator|.
name|getKeys
argument_list|(
name|origin
argument_list|,
name|versions
argument_list|)
decl_stmt|;
if|if
condition|(
name|versions
operator|!=
name|ALL_VERSIONS
operator|&&
name|keys
operator|.
name|size
argument_list|()
operator|>=
name|versions
condition|)
block|{
return|return
name|keys
return|;
block|}
comment|// This code below is very close to the body of the get method.
name|this
operator|.
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
name|MapFile
operator|.
name|Reader
index|[]
name|maparray
init|=
name|getReaders
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
name|maparray
operator|.
name|length
operator|-
literal|1
init|;
name|i
operator|>=
literal|0
condition|;
name|i
operator|--
control|)
block|{
name|MapFile
operator|.
name|Reader
name|map
init|=
name|maparray
index|[
name|i
index|]
decl_stmt|;
synchronized|synchronized
init|(
name|map
init|)
block|{
name|map
operator|.
name|reset
argument_list|()
expr_stmt|;
comment|// do the priming read
name|ImmutableBytesWritable
name|readval
init|=
operator|new
name|ImmutableBytesWritable
argument_list|()
decl_stmt|;
name|HStoreKey
name|readkey
init|=
operator|(
name|HStoreKey
operator|)
name|map
operator|.
name|getClosest
argument_list|(
name|origin
argument_list|,
name|readval
argument_list|)
decl_stmt|;
if|if
condition|(
name|readkey
operator|==
literal|null
condition|)
block|{
comment|// map.getClosest returns null if the passed key is> than the
comment|// last key in the map file.  getClosest is a bit of a misnomer
comment|// since it returns exact match or the next closest key AFTER not
comment|// BEFORE.
continue|continue;
block|}
do|do
block|{
comment|// if the row matches, we might want this one.
if|if
condition|(
name|rowMatches
argument_list|(
name|origin
argument_list|,
name|readkey
argument_list|)
condition|)
block|{
comment|// if the cell matches, then we definitely want this key.
if|if
condition|(
name|cellMatches
argument_list|(
name|origin
argument_list|,
name|readkey
argument_list|)
condition|)
block|{
comment|// store the key if it isn't deleted or superceeded by what's
comment|// in the memcache
if|if
condition|(
operator|!
name|isDeleted
argument_list|(
name|readkey
argument_list|,
name|readval
operator|.
name|get
argument_list|()
argument_list|,
literal|false
argument_list|,
literal|null
argument_list|)
operator|&&
operator|!
name|keys
operator|.
name|contains
argument_list|(
name|readkey
argument_list|)
condition|)
block|{
name|keys
operator|.
name|add
argument_list|(
operator|new
name|HStoreKey
argument_list|(
name|readkey
argument_list|)
argument_list|)
expr_stmt|;
comment|// if we've collected enough versions, then exit the loop.
if|if
condition|(
name|versions
operator|!=
name|ALL_VERSIONS
operator|&&
name|keys
operator|.
name|size
argument_list|()
operator|>=
name|versions
condition|)
block|{
break|break;
block|}
block|}
block|}
else|else
block|{
comment|// the cell doesn't match, but there might be more with different
comment|// timestamps, so move to the next key
continue|continue;
block|}
block|}
else|else
block|{
comment|// the row doesn't match, so we've gone too far.
break|break;
block|}
block|}
do|while
condition|(
name|map
operator|.
name|next
argument_list|(
name|readkey
argument_list|,
name|readval
argument_list|)
condition|)
do|;
comment|// advance to the next key
block|}
block|}
return|return
name|keys
return|;
block|}
finally|finally
block|{
name|this
operator|.
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**    * Find the key that matches<i>row</i> exactly, or the one that immediately    * preceeds it.    */
specifier|public
name|Text
name|getRowKeyAtOrBefore
parameter_list|(
specifier|final
name|Text
name|row
parameter_list|,
specifier|final
name|long
name|timestamp
parameter_list|)
throws|throws
name|IOException
block|{
comment|// if the exact key is found, return that key
comment|// if we find a key that is greater than our search key, then use the
comment|// last key we processed, and if that was null, return null.
name|Text
name|foundKey
init|=
name|memcache
operator|.
name|getRowKeyAtOrBefore
argument_list|(
name|row
argument_list|,
name|timestamp
argument_list|)
decl_stmt|;
if|if
condition|(
name|foundKey
operator|!=
literal|null
condition|)
block|{
return|return
name|foundKey
return|;
block|}
comment|// obtain read lock
name|this
operator|.
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
name|MapFile
operator|.
name|Reader
index|[]
name|maparray
init|=
name|getReaders
argument_list|()
decl_stmt|;
name|Text
name|bestSoFar
init|=
literal|null
decl_stmt|;
name|HStoreKey
name|rowKey
init|=
operator|new
name|HStoreKey
argument_list|(
name|row
argument_list|,
name|timestamp
argument_list|)
decl_stmt|;
comment|// process each store file
for|for
control|(
name|int
name|i
init|=
name|maparray
operator|.
name|length
operator|-
literal|1
init|;
name|i
operator|>=
literal|0
condition|;
name|i
operator|--
control|)
block|{
name|Text
name|row_from_mapfile
init|=
name|rowAtOrBeforeFromMapFile
argument_list|(
name|maparray
index|[
name|i
index|]
argument_list|,
name|row
argument_list|,
name|timestamp
argument_list|)
decl_stmt|;
comment|// for when we have MapFile.Reader#getClosest before functionality
comment|/*        Text row_from_mapfile = null;         WritableComparable value = null;                   HStoreKey hskResult =            (HStoreKey)maparray[i].getClosest(rowKey, value, true);                  if (hskResult != null) {           row_from_mapfile = hskResult.getRow();         }*/
comment|/*        LOG.debug("Best from this mapfile was " + row_from_mapfile);*/
comment|// short circuit on an exact match
if|if
condition|(
name|row
operator|.
name|equals
argument_list|(
name|row_from_mapfile
argument_list|)
condition|)
block|{
return|return
name|row
return|;
block|}
comment|// check to see if we've found a new closest row key as a result
if|if
condition|(
name|bestSoFar
operator|==
literal|null
operator|||
name|bestSoFar
operator|.
name|compareTo
argument_list|(
name|row_from_mapfile
argument_list|)
operator|<
literal|0
condition|)
block|{
name|bestSoFar
operator|=
name|row_from_mapfile
expr_stmt|;
block|}
block|}
comment|/*      LOG.debug("Went searching for " + row + ", found " + bestSoFar);*/
return|return
name|bestSoFar
return|;
block|}
finally|finally
block|{
name|this
operator|.
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**    * Check an individual MapFile for the row at or before a given key     * and timestamp    */
specifier|private
name|Text
name|rowAtOrBeforeFromMapFile
parameter_list|(
name|MapFile
operator|.
name|Reader
name|map
parameter_list|,
name|Text
name|row
parameter_list|,
name|long
name|timestamp
parameter_list|)
throws|throws
name|IOException
block|{
name|Text
name|previousRow
init|=
literal|null
decl_stmt|;
name|ImmutableBytesWritable
name|readval
init|=
operator|new
name|ImmutableBytesWritable
argument_list|()
decl_stmt|;
name|HStoreKey
name|readkey
init|=
operator|new
name|HStoreKey
argument_list|()
decl_stmt|;
synchronized|synchronized
init|(
name|map
init|)
block|{
comment|// start at the beginning of the map
comment|// TODO: this sucks. do a clever binary search instead.
name|map
operator|.
name|reset
argument_list|()
expr_stmt|;
while|while
condition|(
name|map
operator|.
name|next
argument_list|(
name|readkey
argument_list|,
name|readval
argument_list|)
condition|)
block|{
if|if
condition|(
name|readkey
operator|.
name|getRow
argument_list|()
operator|.
name|compareTo
argument_list|(
name|row
argument_list|)
operator|==
literal|0
condition|)
block|{
comment|// exact match on row
if|if
condition|(
name|readkey
operator|.
name|getTimestamp
argument_list|()
operator|<=
name|timestamp
condition|)
block|{
comment|// timestamp fits, return this key
return|return
name|readkey
operator|.
name|getRow
argument_list|()
return|;
block|}
comment|// getting here means that we matched the row, but the timestamp
comment|// is too recent - hopefully one of the next cells will match
comment|// better, so keep rolling
block|}
comment|// if the row key we just read is beyond the key we're searching for,
comment|// then we're done; return the last key we saw before this one
elseif|else
if|if
condition|(
name|readkey
operator|.
name|getRow
argument_list|()
operator|.
name|toString
argument_list|()
operator|.
name|compareTo
argument_list|(
name|row
operator|.
name|toString
argument_list|()
argument_list|)
operator|>
literal|0
condition|)
block|{
return|return
name|previousRow
return|;
block|}
else|else
block|{
comment|// so, the row key doesn't match, and we haven't gone past the row
comment|// we're seeking yet, so this row is a candidate for closest, as
comment|// long as the timestamp is correct.
if|if
condition|(
name|readkey
operator|.
name|getTimestamp
argument_list|()
operator|<=
name|timestamp
condition|)
block|{
name|previousRow
operator|=
operator|new
name|Text
argument_list|(
name|readkey
operator|.
name|getRow
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|// otherwise, ignore this key, because it doesn't fulfill our
comment|// requirements.
block|}
block|}
block|}
comment|// getting here means we exhausted all of the cells in the mapfile.
comment|// whatever satisfying row we reached previously is the row we should
comment|// return
return|return
name|previousRow
return|;
block|}
comment|/**    * Test that the<i>target</i> matches the<i>origin</i>. If the     *<i>origin</i> has an empty column, then it's assumed to mean any column     * matches and only match on row and timestamp. Otherwise, it compares the    * keys with HStoreKey.matchesRowCol().    * @param origin The key we're testing against    * @param target The key we're testing    */
specifier|private
name|boolean
name|cellMatches
parameter_list|(
name|HStoreKey
name|origin
parameter_list|,
name|HStoreKey
name|target
parameter_list|)
block|{
comment|// if the origin's column is empty, then we're matching any column
if|if
condition|(
name|origin
operator|.
name|getColumn
argument_list|()
operator|.
name|equals
argument_list|(
operator|new
name|Text
argument_list|()
argument_list|)
condition|)
block|{
comment|// if the row matches, then...
if|if
condition|(
name|target
operator|.
name|getRow
argument_list|()
operator|.
name|equals
argument_list|(
name|origin
operator|.
name|getRow
argument_list|()
argument_list|)
condition|)
block|{
comment|// check the timestamp
return|return
name|target
operator|.
name|getTimestamp
argument_list|()
operator|<=
name|origin
operator|.
name|getTimestamp
argument_list|()
return|;
block|}
return|return
literal|false
return|;
block|}
comment|// otherwise, we want to match on row and column
return|return
name|target
operator|.
name|matchesRowCol
argument_list|(
name|origin
argument_list|)
return|;
block|}
comment|/**    * Test that the<i>target</i> matches the<i>origin</i>. If the<i>origin</i>    * has an empty column, then it just tests row equivalence. Otherwise, it uses    * HStoreKey.matchesRowCol().    * @param origin Key we're testing against    * @param target Key we're testing    */
specifier|private
name|boolean
name|rowMatches
parameter_list|(
name|HStoreKey
name|origin
parameter_list|,
name|HStoreKey
name|target
parameter_list|)
block|{
comment|// if the origin's column is empty, then we're matching any column
if|if
condition|(
name|origin
operator|.
name|getColumn
argument_list|()
operator|.
name|equals
argument_list|(
operator|new
name|Text
argument_list|()
argument_list|)
condition|)
block|{
comment|// if the row matches, then...
return|return
name|target
operator|.
name|getRow
argument_list|()
operator|.
name|equals
argument_list|(
name|origin
operator|.
name|getRow
argument_list|()
argument_list|)
return|;
block|}
comment|// otherwise, we want to match on row and column
return|return
name|target
operator|.
name|matchesRowCol
argument_list|(
name|origin
argument_list|)
return|;
block|}
comment|/*    * Data structure to hold result of a look at store file sizes.    */
specifier|static
class|class
name|HStoreSize
block|{
specifier|final
name|long
name|aggregate
decl_stmt|;
specifier|final
name|long
name|largest
decl_stmt|;
name|boolean
name|splitable
decl_stmt|;
name|HStoreSize
parameter_list|(
specifier|final
name|long
name|a
parameter_list|,
specifier|final
name|long
name|l
parameter_list|,
specifier|final
name|boolean
name|s
parameter_list|)
block|{
name|this
operator|.
name|aggregate
operator|=
name|a
expr_stmt|;
name|this
operator|.
name|largest
operator|=
name|l
expr_stmt|;
name|this
operator|.
name|splitable
operator|=
name|s
expr_stmt|;
block|}
name|long
name|getAggregate
parameter_list|()
block|{
return|return
name|this
operator|.
name|aggregate
return|;
block|}
name|long
name|getLargest
parameter_list|()
block|{
return|return
name|this
operator|.
name|largest
return|;
block|}
name|boolean
name|isSplitable
parameter_list|()
block|{
return|return
name|this
operator|.
name|splitable
return|;
block|}
name|void
name|setSplitable
parameter_list|(
specifier|final
name|boolean
name|s
parameter_list|)
block|{
name|this
operator|.
name|splitable
operator|=
name|s
expr_stmt|;
block|}
block|}
comment|/**    * Gets size for the store.    *     * @param midKey Gets set to the middle key of the largest splitable store    * file or its set to empty if largest is not splitable.    * @return Sizes for the store and the passed<code>midKey</code> is    * set to midKey of largest splitable.  Otherwise, its set to empty    * to indicate we couldn't find a midkey to split on    */
name|HStoreSize
name|size
parameter_list|(
name|Text
name|midKey
parameter_list|)
block|{
name|long
name|maxSize
init|=
literal|0L
decl_stmt|;
name|long
name|aggregateSize
init|=
literal|0L
decl_stmt|;
comment|// Not splitable if we find a reference store file present in the store.
name|boolean
name|splitable
init|=
literal|true
decl_stmt|;
if|if
condition|(
name|this
operator|.
name|storefiles
operator|.
name|size
argument_list|()
operator|<=
literal|0
condition|)
block|{
return|return
operator|new
name|HStoreSize
argument_list|(
literal|0
argument_list|,
literal|0
argument_list|,
name|splitable
argument_list|)
return|;
block|}
name|this
operator|.
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
name|Long
name|mapIndex
init|=
name|Long
operator|.
name|valueOf
argument_list|(
literal|0L
argument_list|)
decl_stmt|;
comment|// Iterate through all the MapFiles
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|Long
argument_list|,
name|HStoreFile
argument_list|>
name|e
range|:
name|storefiles
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|HStoreFile
name|curHSF
init|=
name|e
operator|.
name|getValue
argument_list|()
decl_stmt|;
name|long
name|size
init|=
name|curHSF
operator|.
name|length
argument_list|()
decl_stmt|;
name|aggregateSize
operator|+=
name|size
expr_stmt|;
if|if
condition|(
name|maxSize
operator|==
literal|0L
operator|||
name|size
operator|>
name|maxSize
condition|)
block|{
comment|// This is the largest one so far
name|maxSize
operator|=
name|size
expr_stmt|;
name|mapIndex
operator|=
name|e
operator|.
name|getKey
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|splitable
condition|)
block|{
name|splitable
operator|=
operator|!
name|curHSF
operator|.
name|isReference
argument_list|()
expr_stmt|;
block|}
block|}
name|MapFile
operator|.
name|Reader
name|r
init|=
name|this
operator|.
name|readers
operator|.
name|get
argument_list|(
name|mapIndex
argument_list|)
decl_stmt|;
comment|// seek back to the beginning of mapfile
name|r
operator|.
name|reset
argument_list|()
expr_stmt|;
comment|// get the first and last keys
name|HStoreKey
name|firstKey
init|=
operator|new
name|HStoreKey
argument_list|()
decl_stmt|;
name|HStoreKey
name|lastKey
init|=
operator|new
name|HStoreKey
argument_list|()
decl_stmt|;
name|Writable
name|value
init|=
operator|new
name|ImmutableBytesWritable
argument_list|()
decl_stmt|;
name|r
operator|.
name|next
argument_list|(
operator|(
name|WritableComparable
operator|)
name|firstKey
argument_list|,
name|value
argument_list|)
expr_stmt|;
name|r
operator|.
name|finalKey
argument_list|(
operator|(
name|WritableComparable
operator|)
name|lastKey
argument_list|)
expr_stmt|;
comment|// get the midkey
name|HStoreKey
name|midkey
init|=
operator|(
name|HStoreKey
operator|)
name|r
operator|.
name|midKey
argument_list|()
decl_stmt|;
if|if
condition|(
name|midkey
operator|!=
literal|null
condition|)
block|{
name|midKey
operator|.
name|set
argument_list|(
operator|(
operator|(
name|HStoreKey
operator|)
name|midkey
operator|)
operator|.
name|getRow
argument_list|()
argument_list|)
expr_stmt|;
comment|// if the midkey is the same as the first and last keys, then we cannot
comment|// (ever) split this region.
if|if
condition|(
name|midkey
operator|.
name|getRow
argument_list|()
operator|.
name|equals
argument_list|(
name|firstKey
operator|.
name|getRow
argument_list|()
argument_list|)
operator|&&
name|midkey
operator|.
name|getRow
argument_list|()
operator|.
name|equals
argument_list|(
name|lastKey
operator|.
name|getRow
argument_list|()
argument_list|)
condition|)
block|{
return|return
operator|new
name|HStoreSize
argument_list|(
name|aggregateSize
argument_list|,
name|maxSize
argument_list|,
literal|false
argument_list|)
return|;
block|}
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failed getting store size for "
operator|+
name|this
operator|.
name|storeName
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|this
operator|.
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
return|return
operator|new
name|HStoreSize
argument_list|(
name|aggregateSize
argument_list|,
name|maxSize
argument_list|,
name|splitable
argument_list|)
return|;
block|}
comment|//////////////////////////////////////////////////////////////////////////////
comment|// File administration
comment|//////////////////////////////////////////////////////////////////////////////
comment|/**    * Return a scanner for both the memcache and the HStore files    */
name|HInternalScannerInterface
name|getScanner
parameter_list|(
name|long
name|timestamp
parameter_list|,
name|Text
name|targetCols
index|[]
parameter_list|,
name|Text
name|firstRow
parameter_list|,
name|RowFilterInterface
name|filter
parameter_list|)
throws|throws
name|IOException
block|{
name|newScannerLock
operator|.
name|readLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
comment|// ability to create a new
comment|// scanner during a compaction
try|try
block|{
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
comment|// lock HStore
try|try
block|{
return|return
operator|new
name|HStoreScanner
argument_list|(
name|targetCols
argument_list|,
name|firstRow
argument_list|,
name|timestamp
argument_list|,
name|filter
argument_list|)
return|;
block|}
finally|finally
block|{
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
finally|finally
block|{
name|newScannerLock
operator|.
name|readLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
comment|/** {@inheritDoc} */
annotation|@
name|Override
specifier|public
name|String
name|toString
parameter_list|()
block|{
return|return
name|this
operator|.
name|storeName
return|;
block|}
comment|/*    * @see writeSplitInfo(Path p, HStoreFile hsf, FileSystem fs)    */
specifier|static
name|HStoreFile
operator|.
name|Reference
name|readSplitInfo
parameter_list|(
specifier|final
name|Path
name|p
parameter_list|,
specifier|final
name|FileSystem
name|fs
parameter_list|)
throws|throws
name|IOException
block|{
name|FSDataInputStream
name|in
init|=
name|fs
operator|.
name|open
argument_list|(
name|p
argument_list|)
decl_stmt|;
try|try
block|{
name|HStoreFile
operator|.
name|Reference
name|r
init|=
operator|new
name|HStoreFile
operator|.
name|Reference
argument_list|()
decl_stmt|;
name|r
operator|.
name|readFields
argument_list|(
name|in
argument_list|)
expr_stmt|;
return|return
name|r
return|;
block|}
finally|finally
block|{
name|in
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**    * @param p Path to check.    * @return True if the path has format of a HStoreFile reference.    */
specifier|public
specifier|static
name|boolean
name|isReference
parameter_list|(
specifier|final
name|Path
name|p
parameter_list|)
block|{
return|return
name|isReference
argument_list|(
name|p
argument_list|,
name|REF_NAME_PARSER
operator|.
name|matcher
argument_list|(
name|p
operator|.
name|getName
argument_list|()
argument_list|)
argument_list|)
return|;
block|}
specifier|private
specifier|static
name|boolean
name|isReference
parameter_list|(
specifier|final
name|Path
name|p
parameter_list|,
specifier|final
name|Matcher
name|m
parameter_list|)
block|{
if|if
condition|(
name|m
operator|==
literal|null
operator|||
operator|!
name|m
operator|.
name|matches
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failed match of store file name "
operator|+
name|p
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"Failed match of store file name "
operator|+
name|p
operator|.
name|toString
argument_list|()
argument_list|)
throw|;
block|}
return|return
name|m
operator|.
name|groupCount
argument_list|()
operator|>
literal|1
operator|&&
name|m
operator|.
name|group
argument_list|(
literal|2
argument_list|)
operator|!=
literal|null
return|;
block|}
comment|/**    * A scanner that iterates through the HStore files    */
specifier|private
class|class
name|StoreFileScanner
extends|extends
name|HAbstractScanner
block|{
annotation|@
name|SuppressWarnings
argument_list|(
literal|"hiding"
argument_list|)
specifier|private
name|MapFile
operator|.
name|Reader
index|[]
name|readers
decl_stmt|;
name|StoreFileScanner
parameter_list|(
name|long
name|timestamp
parameter_list|,
name|Text
index|[]
name|targetCols
parameter_list|,
name|Text
name|firstRow
parameter_list|)
throws|throws
name|IOException
block|{
name|super
argument_list|(
name|timestamp
argument_list|,
name|targetCols
argument_list|)
expr_stmt|;
try|try
block|{
name|this
operator|.
name|readers
operator|=
operator|new
name|MapFile
operator|.
name|Reader
index|[
name|storefiles
operator|.
name|size
argument_list|()
index|]
expr_stmt|;
comment|// Most recent map file should be first
name|int
name|i
init|=
name|readers
operator|.
name|length
operator|-
literal|1
decl_stmt|;
for|for
control|(
name|HStoreFile
name|curHSF
range|:
name|storefiles
operator|.
name|values
argument_list|()
control|)
block|{
name|readers
index|[
name|i
operator|--
index|]
operator|=
name|curHSF
operator|.
name|getReader
argument_list|(
name|fs
argument_list|,
name|bloomFilter
argument_list|)
expr_stmt|;
block|}
name|this
operator|.
name|keys
operator|=
operator|new
name|HStoreKey
index|[
name|readers
operator|.
name|length
index|]
expr_stmt|;
name|this
operator|.
name|vals
operator|=
operator|new
name|byte
index|[
name|readers
operator|.
name|length
index|]
index|[]
expr_stmt|;
comment|// Advance the readers to the first pos.
for|for
control|(
name|i
operator|=
literal|0
init|;
name|i
operator|<
name|readers
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|keys
index|[
name|i
index|]
operator|=
operator|new
name|HStoreKey
argument_list|()
expr_stmt|;
if|if
condition|(
name|firstRow
operator|.
name|getLength
argument_list|()
operator|!=
literal|0
condition|)
block|{
if|if
condition|(
name|findFirstRow
argument_list|(
name|i
argument_list|,
name|firstRow
argument_list|)
condition|)
block|{
continue|continue;
block|}
block|}
while|while
condition|(
name|getNext
argument_list|(
name|i
argument_list|)
condition|)
block|{
if|if
condition|(
name|columnMatch
argument_list|(
name|i
argument_list|)
condition|)
block|{
break|break;
block|}
block|}
block|}
block|}
catch|catch
parameter_list|(
name|Exception
name|ex
parameter_list|)
block|{
name|close
argument_list|()
expr_stmt|;
name|IOException
name|e
init|=
operator|new
name|IOException
argument_list|(
literal|"HStoreScanner failed construction"
argument_list|)
decl_stmt|;
name|e
operator|.
name|initCause
argument_list|(
name|ex
argument_list|)
expr_stmt|;
throw|throw
name|e
throw|;
block|}
block|}
comment|/**      * The user didn't want to start scanning at the first row. This method      * seeks to the requested row.      *      * @param i         - which iterator to advance      * @param firstRow  - seek to this row      * @return          - true if this is the first row or if the row was not found      */
annotation|@
name|Override
name|boolean
name|findFirstRow
parameter_list|(
name|int
name|i
parameter_list|,
name|Text
name|firstRow
parameter_list|)
throws|throws
name|IOException
block|{
name|ImmutableBytesWritable
name|ibw
init|=
operator|new
name|ImmutableBytesWritable
argument_list|()
decl_stmt|;
name|HStoreKey
name|firstKey
init|=
operator|(
name|HStoreKey
operator|)
name|readers
index|[
name|i
index|]
operator|.
name|getClosest
argument_list|(
operator|new
name|HStoreKey
argument_list|(
name|firstRow
argument_list|)
argument_list|,
name|ibw
argument_list|)
decl_stmt|;
if|if
condition|(
name|firstKey
operator|==
literal|null
condition|)
block|{
comment|// Didn't find it. Close the scanner and return TRUE
name|closeSubScanner
argument_list|(
name|i
argument_list|)
expr_stmt|;
return|return
literal|true
return|;
block|}
name|this
operator|.
name|vals
index|[
name|i
index|]
operator|=
name|ibw
operator|.
name|get
argument_list|()
expr_stmt|;
name|keys
index|[
name|i
index|]
operator|.
name|setRow
argument_list|(
name|firstKey
operator|.
name|getRow
argument_list|()
argument_list|)
expr_stmt|;
name|keys
index|[
name|i
index|]
operator|.
name|setColumn
argument_list|(
name|firstKey
operator|.
name|getColumn
argument_list|()
argument_list|)
expr_stmt|;
name|keys
index|[
name|i
index|]
operator|.
name|setVersion
argument_list|(
name|firstKey
operator|.
name|getTimestamp
argument_list|()
argument_list|)
expr_stmt|;
return|return
name|columnMatch
argument_list|(
name|i
argument_list|)
return|;
block|}
comment|/**      * Get the next value from the specified reader.      *       * @param i - which reader to fetch next value from      * @return - true if there is more data available      */
annotation|@
name|Override
name|boolean
name|getNext
parameter_list|(
name|int
name|i
parameter_list|)
throws|throws
name|IOException
block|{
name|boolean
name|result
init|=
literal|false
decl_stmt|;
name|ImmutableBytesWritable
name|ibw
init|=
operator|new
name|ImmutableBytesWritable
argument_list|()
decl_stmt|;
while|while
condition|(
literal|true
condition|)
block|{
if|if
condition|(
operator|!
name|readers
index|[
name|i
index|]
operator|.
name|next
argument_list|(
name|keys
index|[
name|i
index|]
argument_list|,
name|ibw
argument_list|)
condition|)
block|{
name|closeSubScanner
argument_list|(
name|i
argument_list|)
expr_stmt|;
break|break;
block|}
if|if
condition|(
name|keys
index|[
name|i
index|]
operator|.
name|getTimestamp
argument_list|()
operator|<=
name|this
operator|.
name|timestamp
condition|)
block|{
name|vals
index|[
name|i
index|]
operator|=
name|ibw
operator|.
name|get
argument_list|()
expr_stmt|;
name|result
operator|=
literal|true
expr_stmt|;
break|break;
block|}
block|}
return|return
name|result
return|;
block|}
comment|/** Close down the indicated reader. */
annotation|@
name|Override
name|void
name|closeSubScanner
parameter_list|(
name|int
name|i
parameter_list|)
block|{
try|try
block|{
if|if
condition|(
name|readers
index|[
name|i
index|]
operator|!=
literal|null
condition|)
block|{
try|try
block|{
name|readers
index|[
name|i
index|]
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|storeName
operator|+
literal|" closing sub-scanner"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
block|}
block|}
finally|finally
block|{
name|readers
index|[
name|i
index|]
operator|=
literal|null
expr_stmt|;
name|keys
index|[
name|i
index|]
operator|=
literal|null
expr_stmt|;
name|vals
index|[
name|i
index|]
operator|=
literal|null
expr_stmt|;
block|}
block|}
comment|/** Shut it down! */
specifier|public
name|void
name|close
parameter_list|()
block|{
if|if
condition|(
operator|!
name|scannerClosed
condition|)
block|{
try|try
block|{
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|readers
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|readers
index|[
name|i
index|]
operator|!=
literal|null
condition|)
block|{
try|try
block|{
name|readers
index|[
name|i
index|]
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|storeName
operator|+
literal|" closing scanner"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
finally|finally
block|{
name|scannerClosed
operator|=
literal|true
expr_stmt|;
block|}
block|}
block|}
block|}
comment|/**    * Scanner scans both the memcache and the HStore    */
specifier|private
class|class
name|HStoreScanner
implements|implements
name|HInternalScannerInterface
block|{
specifier|private
name|HInternalScannerInterface
index|[]
name|scanners
decl_stmt|;
specifier|private
name|TreeMap
argument_list|<
name|Text
argument_list|,
name|byte
index|[]
argument_list|>
index|[]
name|resultSets
decl_stmt|;
specifier|private
name|HStoreKey
index|[]
name|keys
decl_stmt|;
specifier|private
name|boolean
name|wildcardMatch
init|=
literal|false
decl_stmt|;
specifier|private
name|boolean
name|multipleMatchers
init|=
literal|false
decl_stmt|;
specifier|private
name|RowFilterInterface
name|dataFilter
decl_stmt|;
comment|/** Create an Scanner with a handle on the memcache and HStore files. */
annotation|@
name|SuppressWarnings
argument_list|(
literal|"unchecked"
argument_list|)
name|HStoreScanner
parameter_list|(
name|Text
index|[]
name|targetCols
parameter_list|,
name|Text
name|firstRow
parameter_list|,
name|long
name|timestamp
parameter_list|,
name|RowFilterInterface
name|filter
parameter_list|)
throws|throws
name|IOException
block|{
name|this
operator|.
name|dataFilter
operator|=
name|filter
expr_stmt|;
if|if
condition|(
literal|null
operator|!=
name|dataFilter
condition|)
block|{
name|dataFilter
operator|.
name|reset
argument_list|()
expr_stmt|;
block|}
name|this
operator|.
name|scanners
operator|=
operator|new
name|HInternalScannerInterface
index|[
literal|2
index|]
expr_stmt|;
name|this
operator|.
name|resultSets
operator|=
operator|new
name|TreeMap
index|[
name|scanners
operator|.
name|length
index|]
expr_stmt|;
name|this
operator|.
name|keys
operator|=
operator|new
name|HStoreKey
index|[
name|scanners
operator|.
name|length
index|]
expr_stmt|;
try|try
block|{
name|scanners
index|[
literal|0
index|]
operator|=
name|memcache
operator|.
name|getScanner
argument_list|(
name|timestamp
argument_list|,
name|targetCols
argument_list|,
name|firstRow
argument_list|)
expr_stmt|;
name|scanners
index|[
literal|1
index|]
operator|=
operator|new
name|StoreFileScanner
argument_list|(
name|timestamp
argument_list|,
name|targetCols
argument_list|,
name|firstRow
argument_list|)
expr_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|scanners
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|scanners
index|[
name|i
index|]
operator|.
name|isWildcardScanner
argument_list|()
condition|)
block|{
name|this
operator|.
name|wildcardMatch
operator|=
literal|true
expr_stmt|;
block|}
if|if
condition|(
name|scanners
index|[
name|i
index|]
operator|.
name|isMultipleMatchScanner
argument_list|()
condition|)
block|{
name|this
operator|.
name|multipleMatchers
operator|=
literal|true
expr_stmt|;
block|}
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|this
operator|.
name|scanners
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|scanners
index|[
name|i
index|]
operator|!=
literal|null
condition|)
block|{
name|closeScanner
argument_list|(
name|i
argument_list|)
expr_stmt|;
block|}
block|}
throw|throw
name|e
throw|;
block|}
comment|// Advance to the first key in each scanner.
comment|// All results will match the required column-set and scanTime.
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|scanners
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|keys
index|[
name|i
index|]
operator|=
operator|new
name|HStoreKey
argument_list|()
expr_stmt|;
name|resultSets
index|[
name|i
index|]
operator|=
operator|new
name|TreeMap
argument_list|<
name|Text
argument_list|,
name|byte
index|[]
argument_list|>
argument_list|()
expr_stmt|;
if|if
condition|(
name|scanners
index|[
name|i
index|]
operator|!=
literal|null
operator|&&
operator|!
name|scanners
index|[
name|i
index|]
operator|.
name|next
argument_list|(
name|keys
index|[
name|i
index|]
argument_list|,
name|resultSets
index|[
name|i
index|]
argument_list|)
condition|)
block|{
name|closeScanner
argument_list|(
name|i
argument_list|)
expr_stmt|;
block|}
block|}
comment|// As we have now successfully completed initialization, increment the
comment|// activeScanner count.
name|activeScanners
operator|.
name|incrementAndGet
argument_list|()
expr_stmt|;
block|}
comment|/** @return true if the scanner is a wild card scanner */
specifier|public
name|boolean
name|isWildcardScanner
parameter_list|()
block|{
return|return
name|wildcardMatch
return|;
block|}
comment|/** @return true if the scanner is a multiple match scanner */
specifier|public
name|boolean
name|isMultipleMatchScanner
parameter_list|()
block|{
return|return
name|multipleMatchers
return|;
block|}
comment|/** {@inheritDoc} */
specifier|public
name|boolean
name|next
parameter_list|(
name|HStoreKey
name|key
parameter_list|,
name|SortedMap
argument_list|<
name|Text
argument_list|,
name|byte
index|[]
argument_list|>
name|results
parameter_list|)
throws|throws
name|IOException
block|{
comment|// Filtered flag is set by filters.  If a cell has been 'filtered out'
comment|// -- i.e. it is not to be returned to the caller -- the flag is 'true'.
name|boolean
name|filtered
init|=
literal|true
decl_stmt|;
name|boolean
name|moreToFollow
init|=
literal|true
decl_stmt|;
while|while
condition|(
name|filtered
operator|&&
name|moreToFollow
condition|)
block|{
comment|// Find the lowest-possible key.
name|Text
name|chosenRow
init|=
literal|null
decl_stmt|;
name|long
name|chosenTimestamp
init|=
operator|-
literal|1
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|this
operator|.
name|keys
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|scanners
index|[
name|i
index|]
operator|!=
literal|null
operator|&&
operator|(
name|chosenRow
operator|==
literal|null
operator|||
operator|(
name|keys
index|[
name|i
index|]
operator|.
name|getRow
argument_list|()
operator|.
name|compareTo
argument_list|(
name|chosenRow
argument_list|)
operator|<
literal|0
operator|)
operator|||
operator|(
operator|(
name|keys
index|[
name|i
index|]
operator|.
name|getRow
argument_list|()
operator|.
name|compareTo
argument_list|(
name|chosenRow
argument_list|)
operator|==
literal|0
operator|)
operator|&&
operator|(
name|keys
index|[
name|i
index|]
operator|.
name|getTimestamp
argument_list|()
operator|>
name|chosenTimestamp
operator|)
operator|)
operator|)
condition|)
block|{
name|chosenRow
operator|=
operator|new
name|Text
argument_list|(
name|keys
index|[
name|i
index|]
operator|.
name|getRow
argument_list|()
argument_list|)
expr_stmt|;
name|chosenTimestamp
operator|=
name|keys
index|[
name|i
index|]
operator|.
name|getTimestamp
argument_list|()
expr_stmt|;
block|}
block|}
comment|// Filter whole row by row key?
name|filtered
operator|=
name|dataFilter
operator|!=
literal|null
condition|?
name|dataFilter
operator|.
name|filter
argument_list|(
name|chosenRow
argument_list|)
else|:
literal|false
expr_stmt|;
comment|// Store the key and results for each sub-scanner. Merge them as
comment|// appropriate.
if|if
condition|(
name|chosenTimestamp
operator|>=
literal|0
operator|&&
operator|!
name|filtered
condition|)
block|{
comment|// Here we are setting the passed in key with current row+timestamp
name|key
operator|.
name|setRow
argument_list|(
name|chosenRow
argument_list|)
expr_stmt|;
name|key
operator|.
name|setVersion
argument_list|(
name|chosenTimestamp
argument_list|)
expr_stmt|;
name|key
operator|.
name|setColumn
argument_list|(
name|HConstants
operator|.
name|EMPTY_TEXT
argument_list|)
expr_stmt|;
comment|// Keep list of deleted cell keys within this row.  We need this
comment|// because as we go through scanners, the delete record may be in an
comment|// early scanner and then the same record with a non-delete, non-null
comment|// value in a later. Without history of what we've seen, we'll return
comment|// deleted values. This List should not ever grow too large since we
comment|// are only keeping rows and columns that match those set on the
comment|// scanner and which have delete values.  If memory usage becomes a
comment|// problem, could redo as bloom filter.
name|List
argument_list|<
name|HStoreKey
argument_list|>
name|deletes
init|=
operator|new
name|ArrayList
argument_list|<
name|HStoreKey
argument_list|>
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|scanners
operator|.
name|length
operator|&&
operator|!
name|filtered
condition|;
name|i
operator|++
control|)
block|{
while|while
condition|(
operator|(
name|scanners
index|[
name|i
index|]
operator|!=
literal|null
operator|&&
operator|!
name|filtered
operator|&&
name|moreToFollow
operator|)
operator|&&
operator|(
name|keys
index|[
name|i
index|]
operator|.
name|getRow
argument_list|()
operator|.
name|compareTo
argument_list|(
name|chosenRow
argument_list|)
operator|==
literal|0
operator|)
condition|)
block|{
comment|// If we are doing a wild card match or there are multiple
comment|// matchers per column, we need to scan all the older versions of
comment|// this row to pick up the rest of the family members
if|if
condition|(
operator|!
name|wildcardMatch
operator|&&
operator|!
name|multipleMatchers
operator|&&
operator|(
name|keys
index|[
name|i
index|]
operator|.
name|getTimestamp
argument_list|()
operator|!=
name|chosenTimestamp
operator|)
condition|)
block|{
break|break;
block|}
comment|// Filter out null criteria columns that are not null
if|if
condition|(
name|dataFilter
operator|!=
literal|null
condition|)
block|{
name|filtered
operator|=
name|dataFilter
operator|.
name|filterNotNull
argument_list|(
name|resultSets
index|[
name|i
index|]
argument_list|)
expr_stmt|;
block|}
comment|// NOTE: We used to do results.putAll(resultSets[i]);
comment|// but this had the effect of overwriting newer
comment|// values with older ones. So now we only insert
comment|// a result if the map does not contain the key.
name|HStoreKey
name|hsk
init|=
operator|new
name|HStoreKey
argument_list|(
name|key
operator|.
name|getRow
argument_list|()
argument_list|,
name|EMPTY_TEXT
argument_list|,
name|key
operator|.
name|getTimestamp
argument_list|()
argument_list|)
decl_stmt|;
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|Text
argument_list|,
name|byte
index|[]
argument_list|>
name|e
range|:
name|resultSets
index|[
name|i
index|]
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|hsk
operator|.
name|setColumn
argument_list|(
name|e
operator|.
name|getKey
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|HLogEdit
operator|.
name|isDeleted
argument_list|(
name|e
operator|.
name|getValue
argument_list|()
argument_list|)
condition|)
block|{
if|if
condition|(
operator|!
name|deletes
operator|.
name|contains
argument_list|(
name|hsk
argument_list|)
condition|)
block|{
comment|// Key changes as we cycle the for loop so add a copy to
comment|// the set of deletes.
name|deletes
operator|.
name|add
argument_list|(
operator|new
name|HStoreKey
argument_list|(
name|hsk
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
elseif|else
if|if
condition|(
operator|!
name|deletes
operator|.
name|contains
argument_list|(
name|hsk
argument_list|)
operator|&&
operator|!
name|filtered
operator|&&
name|moreToFollow
operator|&&
operator|!
name|results
operator|.
name|containsKey
argument_list|(
name|e
operator|.
name|getKey
argument_list|()
argument_list|)
condition|)
block|{
if|if
condition|(
name|dataFilter
operator|!=
literal|null
condition|)
block|{
comment|// Filter whole row by column data?
name|filtered
operator|=
name|dataFilter
operator|.
name|filter
argument_list|(
name|chosenRow
argument_list|,
name|e
operator|.
name|getKey
argument_list|()
argument_list|,
name|e
operator|.
name|getValue
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|filtered
condition|)
block|{
name|results
operator|.
name|clear
argument_list|()
expr_stmt|;
break|break;
block|}
block|}
name|results
operator|.
name|put
argument_list|(
name|e
operator|.
name|getKey
argument_list|()
argument_list|,
name|e
operator|.
name|getValue
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
name|resultSets
index|[
name|i
index|]
operator|.
name|clear
argument_list|()
expr_stmt|;
if|if
condition|(
operator|!
name|scanners
index|[
name|i
index|]
operator|.
name|next
argument_list|(
name|keys
index|[
name|i
index|]
argument_list|,
name|resultSets
index|[
name|i
index|]
argument_list|)
condition|)
block|{
name|closeScanner
argument_list|(
name|i
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|scanners
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
comment|// If the current scanner is non-null AND has a lower-or-equal
comment|// row label, then its timestamp is bad. We need to advance it.
while|while
condition|(
operator|(
name|scanners
index|[
name|i
index|]
operator|!=
literal|null
operator|)
operator|&&
operator|(
name|keys
index|[
name|i
index|]
operator|.
name|getRow
argument_list|()
operator|.
name|compareTo
argument_list|(
name|chosenRow
argument_list|)
operator|<=
literal|0
operator|)
condition|)
block|{
name|resultSets
index|[
name|i
index|]
operator|.
name|clear
argument_list|()
expr_stmt|;
if|if
condition|(
operator|!
name|scanners
index|[
name|i
index|]
operator|.
name|next
argument_list|(
name|keys
index|[
name|i
index|]
argument_list|,
name|resultSets
index|[
name|i
index|]
argument_list|)
condition|)
block|{
name|closeScanner
argument_list|(
name|i
argument_list|)
expr_stmt|;
block|}
block|}
block|}
name|moreToFollow
operator|=
name|chosenTimestamp
operator|>=
literal|0
expr_stmt|;
if|if
condition|(
name|dataFilter
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
name|moreToFollow
condition|)
block|{
name|dataFilter
operator|.
name|rowProcessed
argument_list|(
name|filtered
argument_list|,
name|chosenRow
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|dataFilter
operator|.
name|filterAllRemaining
argument_list|()
condition|)
block|{
name|moreToFollow
operator|=
literal|false
expr_stmt|;
block|}
block|}
if|if
condition|(
name|results
operator|.
name|size
argument_list|()
operator|<=
literal|0
operator|&&
operator|!
name|filtered
condition|)
block|{
comment|// There were no results found for this row.  Marked it as
comment|// 'filtered'-out otherwise we will not move on to the next row.
name|filtered
operator|=
literal|true
expr_stmt|;
block|}
block|}
comment|// If we got no results, then there is no more to follow.
if|if
condition|(
name|results
operator|==
literal|null
operator|||
name|results
operator|.
name|size
argument_list|()
operator|<=
literal|0
condition|)
block|{
name|moreToFollow
operator|=
literal|false
expr_stmt|;
block|}
comment|// Make sure scanners closed if no more results
if|if
condition|(
operator|!
name|moreToFollow
condition|)
block|{
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|scanners
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
literal|null
operator|!=
name|scanners
index|[
name|i
index|]
condition|)
block|{
name|closeScanner
argument_list|(
name|i
argument_list|)
expr_stmt|;
block|}
block|}
block|}
return|return
name|moreToFollow
return|;
block|}
comment|/** Shut down a single scanner */
name|void
name|closeScanner
parameter_list|(
name|int
name|i
parameter_list|)
block|{
try|try
block|{
try|try
block|{
name|scanners
index|[
name|i
index|]
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
name|storeName
operator|+
literal|" failed closing scanner "
operator|+
name|i
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
block|}
finally|finally
block|{
name|scanners
index|[
name|i
index|]
operator|=
literal|null
expr_stmt|;
name|keys
index|[
name|i
index|]
operator|=
literal|null
expr_stmt|;
name|resultSets
index|[
name|i
index|]
operator|=
literal|null
expr_stmt|;
block|}
block|}
comment|/** {@inheritDoc} */
specifier|public
name|void
name|close
parameter_list|()
block|{
try|try
block|{
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|scanners
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|scanners
index|[
name|i
index|]
operator|!=
literal|null
condition|)
block|{
name|closeScanner
argument_list|(
name|i
argument_list|)
expr_stmt|;
block|}
block|}
block|}
finally|finally
block|{
synchronized|synchronized
init|(
name|activeScanners
init|)
block|{
name|int
name|numberOfScanners
init|=
name|activeScanners
operator|.
name|decrementAndGet
argument_list|()
decl_stmt|;
if|if
condition|(
name|numberOfScanners
operator|<
literal|0
condition|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|storeName
operator|+
literal|" number of active scanners less than zero: "
operator|+
name|numberOfScanners
operator|+
literal|" resetting to zero"
argument_list|)
expr_stmt|;
name|activeScanners
operator|.
name|set
argument_list|(
literal|0
argument_list|)
expr_stmt|;
name|numberOfScanners
operator|=
literal|0
expr_stmt|;
block|}
if|if
condition|(
name|numberOfScanners
operator|==
literal|0
condition|)
block|{
name|activeScanners
operator|.
name|notifyAll
argument_list|()
expr_stmt|;
block|}
block|}
block|}
block|}
comment|/** {@inheritDoc} */
specifier|public
name|Iterator
argument_list|<
name|Entry
argument_list|<
name|HStoreKey
argument_list|,
name|SortedMap
argument_list|<
name|Text
argument_list|,
name|byte
index|[]
argument_list|>
argument_list|>
argument_list|>
name|iterator
parameter_list|()
block|{
throw|throw
operator|new
name|UnsupportedOperationException
argument_list|(
literal|"Unimplemented serverside. "
operator|+
literal|"next(HStoreKey, StortedMap(...) is more efficient"
argument_list|)
throw|;
block|}
block|}
block|}
end_class

end_unit

