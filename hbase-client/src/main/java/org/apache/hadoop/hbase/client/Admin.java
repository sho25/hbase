begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  *  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|Closeable
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collection
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|Future
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|regex
operator|.
name|Pattern
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|Abortable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|ClusterStatus
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HColumnDescriptor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HRegionInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HTableDescriptor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|NamespaceDescriptor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|NamespaceNotFoundException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|ProcedureInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|RegionLoad
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|ServerName
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|TableExistsException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|TableName
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|TableNotFoundException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|classification
operator|.
name|InterfaceAudience
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|replication
operator|.
name|TableCFs
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|security
operator|.
name|SecurityCapability
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|ipc
operator|.
name|CoprocessorRpcChannel
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|procedure2
operator|.
name|LockInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|quotas
operator|.
name|QuotaFilter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|quotas
operator|.
name|QuotaRetriever
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|quotas
operator|.
name|QuotaSettings
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|wal
operator|.
name|FailedLogCloseException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|replication
operator|.
name|ReplicationException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|replication
operator|.
name|ReplicationPeerConfig
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|replication
operator|.
name|ReplicationPeerDescription
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|snapshot
operator|.
name|HBaseSnapshotException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|snapshot
operator|.
name|RestoreSnapshotException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|snapshot
operator|.
name|SnapshotCreationException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|snapshot
operator|.
name|UnknownSnapshotException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|Pair
import|;
end_import

begin_comment
comment|/**  * The administrative API for HBase. Obtain an instance from an {@link Connection#getAdmin()} and  * call {@link #close()} afterwards.  *<p>Admin can be used to create, drop, list, enable and disable tables, add and drop table  * column families and other administrative operations.  *  * @see ConnectionFactory  * @see Connection  * @see Table  * @since 0.99.0  */
end_comment

begin_interface
annotation|@
name|InterfaceAudience
operator|.
name|Public
specifier|public
interface|interface
name|Admin
extends|extends
name|Abortable
extends|,
name|Closeable
block|{
name|int
name|getOperationTimeout
parameter_list|()
function_decl|;
annotation|@
name|Override
name|void
name|abort
parameter_list|(
name|String
name|why
parameter_list|,
name|Throwable
name|e
parameter_list|)
function_decl|;
annotation|@
name|Override
name|boolean
name|isAborted
parameter_list|()
function_decl|;
comment|/**    * @return Connection used by this object.    */
name|Connection
name|getConnection
parameter_list|()
function_decl|;
comment|/**    * @param tableName Table to check.    * @return True if table exists already.    * @throws IOException    */
name|boolean
name|tableExists
parameter_list|(
specifier|final
name|TableName
name|tableName
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * List all the userspace tables.    *    * @return - returns an array of read-only HTableDescriptors    * @throws IOException if a remote or network exception occurs    */
name|HTableDescriptor
index|[]
name|listTables
parameter_list|()
throws|throws
name|IOException
function_decl|;
comment|/**    * List all the userspace tables matching the given pattern.    *    * @param pattern The compiled regular expression to match against    * @return - returns an array of read-only HTableDescriptors    * @throws IOException if a remote or network exception occurs    * @see #listTables()    */
name|HTableDescriptor
index|[]
name|listTables
parameter_list|(
name|Pattern
name|pattern
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * List all the userspace tables matching the given regular expression.    *    * @param regex The regular expression to match against    * @return - returns an array of HTableDescriptors    * @throws IOException if a remote or network exception occurs    * @see #listTables(java.util.regex.Pattern)    */
name|HTableDescriptor
index|[]
name|listTables
parameter_list|(
name|String
name|regex
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * List all the tables matching the given pattern.    *    * @param pattern The compiled regular expression to match against    * @param includeSysTables False to match only against userspace tables    * @return - returns an array of read-only HTableDescriptors    * @throws IOException if a remote or network exception occurs    * @see #listTables()    */
name|HTableDescriptor
index|[]
name|listTables
parameter_list|(
name|Pattern
name|pattern
parameter_list|,
name|boolean
name|includeSysTables
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * List all the tables matching the given pattern.    *    * @param regex The regular expression to match against    * @param includeSysTables False to match only against userspace tables    * @return - returns an array of read-only HTableDescriptors    * @throws IOException if a remote or network exception occurs    * @see #listTables(java.util.regex.Pattern, boolean)    */
name|HTableDescriptor
index|[]
name|listTables
parameter_list|(
name|String
name|regex
parameter_list|,
name|boolean
name|includeSysTables
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * List all of the names of userspace tables.    *    * @return TableName[] table names    * @throws IOException if a remote or network exception occurs    */
name|TableName
index|[]
name|listTableNames
parameter_list|()
throws|throws
name|IOException
function_decl|;
comment|/**    * List all of the names of userspace tables.    * @param pattern The regular expression to match against    * @return TableName[] table names    * @throws IOException if a remote or network exception occurs    */
name|TableName
index|[]
name|listTableNames
parameter_list|(
name|Pattern
name|pattern
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * List all of the names of userspace tables.    * @param regex The regular expression to match against    * @return TableName[] table names    * @throws IOException if a remote or network exception occurs    */
name|TableName
index|[]
name|listTableNames
parameter_list|(
name|String
name|regex
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * List all of the names of userspace tables.    * @param pattern The regular expression to match against    * @param includeSysTables False to match only against userspace tables    * @return TableName[] table names    * @throws IOException if a remote or network exception occurs    */
name|TableName
index|[]
name|listTableNames
parameter_list|(
specifier|final
name|Pattern
name|pattern
parameter_list|,
specifier|final
name|boolean
name|includeSysTables
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * List all of the names of userspace tables.    * @param regex The regular expression to match against    * @param includeSysTables False to match only against userspace tables    * @return TableName[] table names    * @throws IOException if a remote or network exception occurs    */
name|TableName
index|[]
name|listTableNames
parameter_list|(
specifier|final
name|String
name|regex
parameter_list|,
specifier|final
name|boolean
name|includeSysTables
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Method for getting the tableDescriptor    *    * @param tableName as a {@link TableName}    * @return the read-only tableDescriptor    * @throws org.apache.hadoop.hbase.TableNotFoundException    * @throws IOException if a remote or network exception occurs    */
name|HTableDescriptor
name|getTableDescriptor
parameter_list|(
specifier|final
name|TableName
name|tableName
parameter_list|)
throws|throws
name|TableNotFoundException
throws|,
name|IOException
function_decl|;
comment|/**    * Creates a new table. Synchronous operation.    *    * @param desc table descriptor for table    * @throws IllegalArgumentException if the table name is reserved    * @throws org.apache.hadoop.hbase.MasterNotRunningException if master is not running    * @throws org.apache.hadoop.hbase.TableExistsException if table already exists (If concurrent    * threads, the table may have been created between test-for-existence and attempt-at-creation).    * @throws IOException if a remote or network exception occurs    */
name|void
name|createTable
parameter_list|(
name|HTableDescriptor
name|desc
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Creates a new table with the specified number of regions.  The start key specified will become    * the end key of the first region of the table, and the end key specified will become the start    * key of the last region of the table (the first region has a null start key and the last region    * has a null end key). BigInteger math will be used to divide the key range specified into enough    * segments to make the required number of total regions. Synchronous operation.    *    * @param desc table descriptor for table    * @param startKey beginning of key range    * @param endKey end of key range    * @param numRegions the total number of regions to create    * @throws IllegalArgumentException if the table name is reserved    * @throws org.apache.hadoop.hbase.MasterNotRunningException if master is not running    * @throws org.apache.hadoop.hbase.TableExistsException if table already exists (If concurrent    * threads, the table may have been created between test-for-existence and attempt-at-creation).    * @throws IOException    */
name|void
name|createTable
parameter_list|(
name|HTableDescriptor
name|desc
parameter_list|,
name|byte
index|[]
name|startKey
parameter_list|,
name|byte
index|[]
name|endKey
parameter_list|,
name|int
name|numRegions
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Creates a new table with an initial set of empty regions defined by the specified split keys.    * The total number of regions created will be the number of split keys plus one. Synchronous    * operation. Note : Avoid passing empty split key.    *    * @param desc table descriptor for table    * @param splitKeys array of split keys for the initial regions of the table    * @throws IllegalArgumentException if the table name is reserved, if the split keys are repeated    * and if the split key has empty byte array.    * @throws org.apache.hadoop.hbase.MasterNotRunningException if master is not running    * @throws org.apache.hadoop.hbase.TableExistsException if table already exists (If concurrent    * threads, the table may have been created between test-for-existence and attempt-at-creation).    * @throws IOException    */
name|void
name|createTable
parameter_list|(
specifier|final
name|HTableDescriptor
name|desc
parameter_list|,
name|byte
index|[]
index|[]
name|splitKeys
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Creates a new table but does not block and wait for it to come online.    * You can use Future.get(long, TimeUnit) to wait on the operation to complete.    * It may throw ExecutionException if there was an error while executing the operation    * or TimeoutException in case the wait timeout was not long enough to allow the    * operation to complete.    * Throws IllegalArgumentException Bad table name, if the split keys    *    are repeated and if the split key has empty byte array.    *    * @param desc table descriptor for table    * @param splitKeys keys to check if the table has been created with all split keys    * @throws IOException if a remote or network exception occurs    * @return the result of the async creation. You can use Future.get(long, TimeUnit)    *    to wait on the operation to complete.    */
name|Future
argument_list|<
name|Void
argument_list|>
name|createTableAsync
parameter_list|(
specifier|final
name|HTableDescriptor
name|desc
parameter_list|,
specifier|final
name|byte
index|[]
index|[]
name|splitKeys
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Deletes a table. Synchronous operation.    *    * @param tableName name of table to delete    * @throws IOException if a remote or network exception occurs    */
name|void
name|deleteTable
parameter_list|(
specifier|final
name|TableName
name|tableName
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Deletes the table but does not block and wait for it be completely removed.    * You can use Future.get(long, TimeUnit) to wait on the operation to complete.    * It may throw ExecutionException if there was an error while executing the operation    * or TimeoutException in case the wait timeout was not long enough to allow the    * operation to complete.    *    * @param tableName name of table to delete    * @throws IOException if a remote or network exception occurs    * @return the result of the async delete. You can use Future.get(long, TimeUnit)    *    to wait on the operation to complete.    */
name|Future
argument_list|<
name|Void
argument_list|>
name|deleteTableAsync
parameter_list|(
name|TableName
name|tableName
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Deletes tables matching the passed in pattern and wait on completion. Warning: Use this method    * carefully, there is no prompting and the effect is immediate. Consider using {@link    * #listTables(java.lang.String)} and {@link #deleteTable(org.apache.hadoop.hbase.TableName)}    *    * @param regex The regular expression to match table names against    * @return Table descriptors for tables that couldn't be deleted.    *         The return htds are read-only    * @throws IOException    * @see #deleteTables(java.util.regex.Pattern)    * @see #deleteTable(org.apache.hadoop.hbase.TableName)    */
name|HTableDescriptor
index|[]
name|deleteTables
parameter_list|(
name|String
name|regex
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Delete tables matching the passed in pattern and wait on completion. Warning: Use this method    * carefully, there is no prompting and the effect is immediate. Consider using {@link    * #listTables(java.util.regex.Pattern) } and    * {@link #deleteTable(org.apache.hadoop.hbase.TableName)}    *    * @param pattern The pattern to match table names against    * @return Table descriptors for tables that couldn't be deleted    *         The return htds are read-only    * @throws IOException    */
name|HTableDescriptor
index|[]
name|deleteTables
parameter_list|(
name|Pattern
name|pattern
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Truncate a table.    * Synchronous operation.    *    * @param tableName name of table to truncate    * @param preserveSplits True if the splits should be preserved    * @throws IOException if a remote or network exception occurs    */
specifier|public
name|void
name|truncateTable
parameter_list|(
specifier|final
name|TableName
name|tableName
parameter_list|,
specifier|final
name|boolean
name|preserveSplits
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Truncate the table but does not block and wait for it be completely enabled. You can use    * Future.get(long, TimeUnit) to wait on the operation to complete. It may throw    * ExecutionException if there was an error while executing the operation or TimeoutException in    * case the wait timeout was not long enough to allow the operation to complete.    * @param tableName name of table to delete    * @param preserveSplits true if the splits should be preserved    * @throws IOException if a remote or network exception occurs    * @return the result of the async truncate. You can use Future.get(long, TimeUnit) to wait on the    *         operation to complete.    */
name|Future
argument_list|<
name|Void
argument_list|>
name|truncateTableAsync
parameter_list|(
specifier|final
name|TableName
name|tableName
parameter_list|,
specifier|final
name|boolean
name|preserveSplits
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Enable a table.  May timeout.  Use {@link #enableTableAsync(org.apache.hadoop.hbase.TableName)}    * and {@link #isTableEnabled(org.apache.hadoop.hbase.TableName)} instead. The table has to be in    * disabled state for it to be enabled.    *    * @param tableName name of the table    * @throws IOException if a remote or network exception occurs There could be couple types of    * IOException TableNotFoundException means the table doesn't exist. TableNotDisabledException    * means the table isn't in disabled state.    * @see #isTableEnabled(org.apache.hadoop.hbase.TableName)    * @see #disableTable(org.apache.hadoop.hbase.TableName)    * @see #enableTableAsync(org.apache.hadoop.hbase.TableName)    */
name|void
name|enableTable
parameter_list|(
specifier|final
name|TableName
name|tableName
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Enable the table but does not block and wait for it be completely enabled.    * You can use Future.get(long, TimeUnit) to wait on the operation to complete.    * It may throw ExecutionException if there was an error while executing the operation    * or TimeoutException in case the wait timeout was not long enough to allow the    * operation to complete.    *    * @param tableName name of table to delete    * @throws IOException if a remote or network exception occurs    * @return the result of the async enable. You can use Future.get(long, TimeUnit)    *    to wait on the operation to complete.    */
name|Future
argument_list|<
name|Void
argument_list|>
name|enableTableAsync
parameter_list|(
specifier|final
name|TableName
name|tableName
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Enable tables matching the passed in pattern and wait on completion. Warning: Use this method    * carefully, there is no prompting and the effect is immediate. Consider using {@link    * #listTables(java.lang.String)} and {@link #enableTable(org.apache.hadoop.hbase.TableName)}    *    * @param regex The regular expression to match table names against    * @throws IOException    * @return Table descriptors for tables that couldn't be enabled.    *         The return HTDs are read-only.    * @see #enableTables(java.util.regex.Pattern)    * @see #enableTable(org.apache.hadoop.hbase.TableName)    */
name|HTableDescriptor
index|[]
name|enableTables
parameter_list|(
name|String
name|regex
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Enable tables matching the passed in pattern and wait on completion. Warning: Use this method    * carefully, there is no prompting and the effect is immediate. Consider using {@link    * #listTables(java.util.regex.Pattern) } and    * {@link #enableTable(org.apache.hadoop.hbase.TableName)}    *    * @param pattern The pattern to match table names against    * @throws IOException    * @return Table descriptors for tables that couldn't be enabled.    *         The return HTDs are read-only.    */
name|HTableDescriptor
index|[]
name|enableTables
parameter_list|(
name|Pattern
name|pattern
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Disable the table but does not block and wait for it be completely disabled.    * You can use Future.get(long, TimeUnit) to wait on the operation to complete.    * It may throw ExecutionException if there was an error while executing the operation    * or TimeoutException in case the wait timeout was not long enough to allow the    * operation to complete.    *    * @param tableName name of table to delete    * @throws IOException if a remote or network exception occurs    * @return the result of the async disable. You can use Future.get(long, TimeUnit)    *    to wait on the operation to complete.    */
name|Future
argument_list|<
name|Void
argument_list|>
name|disableTableAsync
parameter_list|(
specifier|final
name|TableName
name|tableName
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Disable table and wait on completion.  May timeout eventually.  Use {@link    * #disableTableAsync(org.apache.hadoop.hbase.TableName)} and    * {@link #isTableDisabled(org.apache.hadoop.hbase.TableName)} instead. The table has to be in    * enabled state for it to be disabled.    *    * @param tableName    * @throws IOException There could be couple types of IOException TableNotFoundException means the    * table doesn't exist. TableNotEnabledException means the table isn't in enabled state.    */
name|void
name|disableTable
parameter_list|(
specifier|final
name|TableName
name|tableName
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Disable tables matching the passed in pattern and wait on completion. Warning: Use this method    * carefully, there is no prompting and the effect is immediate. Consider using {@link    * #listTables(java.lang.String)} and {@link #disableTable(org.apache.hadoop.hbase.TableName)}    *    * @param regex The regular expression to match table names against    * @return Table descriptors for tables that couldn't be disabled    *         The return htds are read-only    * @throws IOException    * @see #disableTables(java.util.regex.Pattern)    * @see #disableTable(org.apache.hadoop.hbase.TableName)    */
name|HTableDescriptor
index|[]
name|disableTables
parameter_list|(
name|String
name|regex
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Disable tables matching the passed in pattern and wait on completion. Warning: Use this method    * carefully, there is no prompting and the effect is immediate. Consider using {@link    * #listTables(java.util.regex.Pattern) } and    * {@link #disableTable(org.apache.hadoop.hbase.TableName)}    *    * @param pattern The pattern to match table names against    * @return Table descriptors for tables that couldn't be disabled    *         The return htds are read-only    * @throws IOException    */
name|HTableDescriptor
index|[]
name|disableTables
parameter_list|(
name|Pattern
name|pattern
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * @param tableName name of table to check    * @return true if table is on-line    * @throws IOException if a remote or network exception occurs    */
name|boolean
name|isTableEnabled
parameter_list|(
name|TableName
name|tableName
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * @param tableName name of table to check    * @return true if table is off-line    * @throws IOException if a remote or network exception occurs    */
name|boolean
name|isTableDisabled
parameter_list|(
name|TableName
name|tableName
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * @param tableName name of table to check    * @return true if all regions of the table are available    * @throws IOException if a remote or network exception occurs    */
name|boolean
name|isTableAvailable
parameter_list|(
name|TableName
name|tableName
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Use this api to check if the table has been created with the specified number of splitkeys    * which was used while creating the given table. Note : If this api is used after a table's    * region gets splitted, the api may return false.    *    * @param tableName name of table to check    * @param splitKeys keys to check if the table has been created with all split keys    * @throws IOException if a remote or network excpetion occurs    */
name|boolean
name|isTableAvailable
parameter_list|(
name|TableName
name|tableName
parameter_list|,
name|byte
index|[]
index|[]
name|splitKeys
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Get the status of alter command - indicates how many regions have received the updated schema    * Asynchronous operation.    *    * @param tableName TableName instance    * @return Pair indicating the number of regions updated Pair.getFirst() is the regions that are    * yet to be updated Pair.getSecond() is the total number of regions of the table    * @throws IOException if a remote or network exception occurs    */
name|Pair
argument_list|<
name|Integer
argument_list|,
name|Integer
argument_list|>
name|getAlterStatus
parameter_list|(
specifier|final
name|TableName
name|tableName
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Get the status of alter command - indicates how many regions have received the updated schema    * Asynchronous operation.    *    * @param tableName name of the table to get the status of    * @return Pair indicating the number of regions updated Pair.getFirst() is the regions that are    * yet to be updated Pair.getSecond() is the total number of regions of the table    * @throws IOException if a remote or network exception occurs    * @deprecated Since 2.0.0. Will be removed in 3.0.0. Use {@link #getAlterStatus(TableName)}    *     instead.    */
annotation|@
name|Deprecated
name|Pair
argument_list|<
name|Integer
argument_list|,
name|Integer
argument_list|>
name|getAlterStatus
parameter_list|(
specifier|final
name|byte
index|[]
name|tableName
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Add a column family to an existing table. Asynchronous operation.    *    * @param tableName name of the table to add column family to    * @param columnFamily column family descriptor of column family to be added    * @throws IOException if a remote or network exception occurs    * @deprecated As of release 2.0.0.    *             (<a href="https://issues.apache.org/jira/browse/HBASE-1989">HBASE-1989</a>).    *             This will be removed in HBase 3.0.0.    *             Use {@link #addColumnFamily(TableName, HColumnDescriptor)}.    */
annotation|@
name|Deprecated
name|void
name|addColumn
parameter_list|(
specifier|final
name|TableName
name|tableName
parameter_list|,
specifier|final
name|HColumnDescriptor
name|columnFamily
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Add a column family to an existing table.    *    * @param tableName name of the table to add column family to    * @param columnFamily column family descriptor of column family to be added    * @throws IOException if a remote or network exception occurs    */
name|void
name|addColumnFamily
parameter_list|(
specifier|final
name|TableName
name|tableName
parameter_list|,
specifier|final
name|HColumnDescriptor
name|columnFamily
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Add a column family to an existing table. Asynchronous operation.    * You can use Future.get(long, TimeUnit) to wait on the operation to complete.    * It may throw ExecutionException if there was an error while executing the operation    * or TimeoutException in case the wait timeout was not long enough to allow the    * operation to complete.    *    * @param tableName name of the table to add column family to    * @param columnFamily column family descriptor of column family to be added    * @throws IOException if a remote or network exception occurs    * @return the result of the async add column family. You can use Future.get(long, TimeUnit) to    *         wait on the operation to complete.    */
name|Future
argument_list|<
name|Void
argument_list|>
name|addColumnFamilyAsync
parameter_list|(
specifier|final
name|TableName
name|tableName
parameter_list|,
specifier|final
name|HColumnDescriptor
name|columnFamily
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Delete a column family from a table. Asynchronous operation.    *    * @param tableName name of table    * @param columnFamily name of column family to be deleted    * @throws IOException if a remote or network exception occurs    * @deprecated As of release 2.0.0.    *             (<a href="https://issues.apache.org/jira/browse/HBASE-1989">HBASE-1989</a>).    *             This will be removed in HBase 3.0.0.    *             Use {@link #deleteColumnFamily(TableName, byte[])}}.    */
annotation|@
name|Deprecated
name|void
name|deleteColumn
parameter_list|(
specifier|final
name|TableName
name|tableName
parameter_list|,
specifier|final
name|byte
index|[]
name|columnFamily
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Delete a column family from a table. Asynchronous operation.    *    * @param tableName name of table    * @param columnFamily name of column family to be deleted    * @throws IOException if a remote or network exception occurs    */
name|void
name|deleteColumnFamily
parameter_list|(
specifier|final
name|TableName
name|tableName
parameter_list|,
specifier|final
name|byte
index|[]
name|columnFamily
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Delete a column family from a table. Asynchronous operation.    * You can use Future.get(long, TimeUnit) to wait on the operation to complete.    * It may throw ExecutionException if there was an error while executing the operation    * or TimeoutException in case the wait timeout was not long enough to allow the    * operation to complete.    *    * @param tableName name of table    * @param columnFamily name of column family to be deleted    * @throws IOException if a remote or network exception occurs    * @return the result of the async delete column family. You can use Future.get(long, TimeUnit) to    *         wait on the operation to complete.    */
name|Future
argument_list|<
name|Void
argument_list|>
name|deleteColumnFamilyAsync
parameter_list|(
specifier|final
name|TableName
name|tableName
parameter_list|,
specifier|final
name|byte
index|[]
name|columnFamily
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Modify an existing column family on a table.    *    * @param tableName name of table    * @param columnFamily new column family descriptor to use    * @throws IOException if a remote or network exception occurs    * @deprecated As of release 2.0.0.    *             (<a href="https://issues.apache.org/jira/browse/HBASE-1989">HBASE-1989</a>).    *             This will be removed in HBase 3.0.0.    *             Use {@link #modifyColumnFamily(TableName, HColumnDescriptor)}.    */
annotation|@
name|Deprecated
name|void
name|modifyColumn
parameter_list|(
specifier|final
name|TableName
name|tableName
parameter_list|,
specifier|final
name|HColumnDescriptor
name|columnFamily
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Modify an existing column family on a table.    *    * @param tableName name of table    * @param columnFamily new column family descriptor to use    * @throws IOException if a remote or network exception occurs    */
name|void
name|modifyColumnFamily
parameter_list|(
specifier|final
name|TableName
name|tableName
parameter_list|,
specifier|final
name|HColumnDescriptor
name|columnFamily
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Modify an existing column family on a table. Asynchronous operation.    * You can use Future.get(long, TimeUnit) to wait on the operation to complete.    * It may throw ExecutionException if there was an error while executing the operation    * or TimeoutException in case the wait timeout was not long enough to allow the    * operation to complete.    *    * @param tableName name of table    * @param columnFamily new column family descriptor to use    * @throws IOException if a remote or network exception occurs    * @return the result of the async modify column family. You can use Future.get(long, TimeUnit) to    *         wait on the operation to complete.    */
name|Future
argument_list|<
name|Void
argument_list|>
name|modifyColumnFamilyAsync
parameter_list|(
name|TableName
name|tableName
parameter_list|,
name|HColumnDescriptor
name|columnFamily
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Close a region. For expert-admins.  Runs close on the regionserver.  The master will not be    * informed of the close.    *    * @param regionname region name to close    * @param serverName If supplied, we'll use this location rather than the one currently in    *<code>hbase:meta</code>    * @throws IOException if a remote or network exception occurs    */
name|void
name|closeRegion
parameter_list|(
specifier|final
name|String
name|regionname
parameter_list|,
specifier|final
name|String
name|serverName
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Close a region.  For expert-admins  Runs close on the regionserver.  The master will not be    * informed of the close.    *    * @param regionname region name to close    * @param serverName The servername of the regionserver.  If passed null we will use servername    * found in the hbase:meta table. A server name is made of host, port and startcode.  Here is an    * example:<code> host187.example.com,60020,1289493121758</code>    * @throws IOException if a remote or network exception occurs    */
name|void
name|closeRegion
parameter_list|(
specifier|final
name|byte
index|[]
name|regionname
parameter_list|,
specifier|final
name|String
name|serverName
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * For expert-admins. Runs close on the regionserver. Closes a region based on the encoded region    * name. The region server name is mandatory. If the servername is provided then based on the    * online regions in the specified regionserver the specified region will be closed. The master    * will not be informed of the close. Note that the regionname is the encoded regionname.    *    * @param encodedRegionName The encoded region name; i.e. the hash that makes up the region name    * suffix: e.g. if regionname is    *<code>TestTable,0094429456,1289497600452.527db22f95c8a9e0116f0cc13c680396.</code>,    * then the encoded region name is:<code>527db22f95c8a9e0116f0cc13c680396</code>.    * @param serverName The servername of the regionserver. A server name is made of host, port and    * startcode. This is mandatory. Here is an example:    *<code> host187.example.com,60020,1289493121758</code>    * @return true if the region was closed, false if not.    * @throws IOException if a remote or network exception occurs    */
name|boolean
name|closeRegionWithEncodedRegionName
parameter_list|(
specifier|final
name|String
name|encodedRegionName
parameter_list|,
specifier|final
name|String
name|serverName
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Close a region.  For expert-admins  Runs close on the regionserver.  The master will not be    * informed of the close.    *    * @param sn    * @param hri    * @throws IOException    */
name|void
name|closeRegion
parameter_list|(
specifier|final
name|ServerName
name|sn
parameter_list|,
specifier|final
name|HRegionInfo
name|hri
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Get all the online regions on a region server.    */
name|List
argument_list|<
name|HRegionInfo
argument_list|>
name|getOnlineRegions
parameter_list|(
specifier|final
name|ServerName
name|sn
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Flush a table. Synchronous operation.    *    * @param tableName table to flush    * @throws IOException if a remote or network exception occurs    */
name|void
name|flush
parameter_list|(
specifier|final
name|TableName
name|tableName
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Flush an individual region. Synchronous operation.    *    * @param regionName region to flush    * @throws IOException if a remote or network exception occurs    */
name|void
name|flushRegion
parameter_list|(
specifier|final
name|byte
index|[]
name|regionName
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Compact a table. Asynchronous operation.    *    * @param tableName table to compact    * @throws IOException if a remote or network exception occurs    */
name|void
name|compact
parameter_list|(
specifier|final
name|TableName
name|tableName
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Compact an individual region. Asynchronous operation.    *    * @param regionName region to compact    * @throws IOException if a remote or network exception occurs    */
name|void
name|compactRegion
parameter_list|(
specifier|final
name|byte
index|[]
name|regionName
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Compact a column family within a table. Asynchronous operation.    *    * @param tableName table to compact    * @param columnFamily column family within a table    * @throws IOException if a remote or network exception occurs    */
name|void
name|compact
parameter_list|(
specifier|final
name|TableName
name|tableName
parameter_list|,
specifier|final
name|byte
index|[]
name|columnFamily
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Compact a column family within a region. Asynchronous operation.    *    * @param regionName region to compact    * @param columnFamily column family within a region    * @throws IOException if a remote or network exception occurs    */
name|void
name|compactRegion
parameter_list|(
specifier|final
name|byte
index|[]
name|regionName
parameter_list|,
specifier|final
name|byte
index|[]
name|columnFamily
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Major compact a table. Asynchronous operation.    *    * @param tableName table to major compact    * @throws IOException if a remote or network exception occurs    */
name|void
name|majorCompact
parameter_list|(
name|TableName
name|tableName
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Major compact a table or an individual region. Asynchronous operation.    *    * @param regionName region to major compact    * @throws IOException if a remote or network exception occurs    */
name|void
name|majorCompactRegion
parameter_list|(
specifier|final
name|byte
index|[]
name|regionName
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Major compact a column family within a table. Asynchronous operation.    *    * @param tableName table to major compact    * @param columnFamily column family within a table    * @throws IOException if a remote or network exception occurs    */
name|void
name|majorCompact
parameter_list|(
name|TableName
name|tableName
parameter_list|,
specifier|final
name|byte
index|[]
name|columnFamily
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Major compact a column family within region. Asynchronous operation.    *    * @param regionName egion to major compact    * @param columnFamily column family within a region    * @throws IOException if a remote or network exception occurs    */
name|void
name|majorCompactRegion
parameter_list|(
specifier|final
name|byte
index|[]
name|regionName
parameter_list|,
specifier|final
name|byte
index|[]
name|columnFamily
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Compact all regions on the region server    * @param sn the region server name    * @param major if it's major compaction    * @throws IOException    * @throws InterruptedException    */
specifier|public
name|void
name|compactRegionServer
parameter_list|(
specifier|final
name|ServerName
name|sn
parameter_list|,
name|boolean
name|major
parameter_list|)
throws|throws
name|IOException
throws|,
name|InterruptedException
function_decl|;
comment|/**    * Move the region<code>r</code> to<code>dest</code>.    *    * @param encodedRegionName The encoded region name; i.e. the hash that makes up the region name    * suffix: e.g. if regionname is    *<code>TestTable,0094429456,1289497600452.527db22f95c8a9e0116f0cc13c680396.</code>,    * then the encoded region name is:<code>527db22f95c8a9e0116f0cc13c680396</code>.    * @param destServerName The servername of the destination regionserver.  If passed the empty byte    * array we'll assign to a random server.  A server name is made of host, port and startcode.    * Here is an example:<code> host187.example.com,60020,1289493121758</code>    * @throws IOException if we can't find a region named    *<code>encodedRegionName</code>    */
name|void
name|move
parameter_list|(
specifier|final
name|byte
index|[]
name|encodedRegionName
parameter_list|,
specifier|final
name|byte
index|[]
name|destServerName
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * @param regionName Region name to assign.    */
name|void
name|assign
parameter_list|(
specifier|final
name|byte
index|[]
name|regionName
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Unassign a region from current hosting regionserver.  Region will then be assigned to a    * regionserver chosen at random.  Region could be reassigned back to the same server.  Use {@link    * #move(byte[], byte[])} if you want to control the region movement.    *    * @param regionName Region to unassign. Will clear any existing RegionPlan if one found.    * @param force If true, force unassign (Will remove region from regions-in-transition too if    * present. If results in double assignment use hbck -fix to resolve. To be used by experts).    */
name|void
name|unassign
parameter_list|(
specifier|final
name|byte
index|[]
name|regionName
parameter_list|,
specifier|final
name|boolean
name|force
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Offline specified region from master's in-memory state. It will not attempt to reassign the    * region as in unassign. This API can be used when a region not served by any region server and    * still online as per Master's in memory state. If this API is incorrectly used on active region    * then master will loose track of that region. This is a special method that should be used by    * experts or hbck.    *    * @param regionName Region to offline.    * @throws IOException    */
name|void
name|offline
parameter_list|(
specifier|final
name|byte
index|[]
name|regionName
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Turn the load balancer on or off.    *    * @param synchronous If true, it waits until current balance() call, if outstanding, to return.    * @return Previous balancer value    */
name|boolean
name|setBalancerRunning
parameter_list|(
specifier|final
name|boolean
name|on
parameter_list|,
specifier|final
name|boolean
name|synchronous
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Invoke the balancer.  Will run the balancer and if regions to move, it will go ahead and do the    * reassignments.  Can NOT run for various reasons.  Check logs.    *    * @return True if balancer ran, false otherwise.    */
name|boolean
name|balancer
parameter_list|()
throws|throws
name|IOException
function_decl|;
comment|/**    * Invoke the balancer.  Will run the balancer and if regions to move, it will    * go ahead and do the reassignments. If there is region in transition, force parameter of true    * would still run balancer. Can *not* run for other reasons.  Check    * logs.    * @param force whether we should force balance even if there is region in transition    * @return True if balancer ran, false otherwise.    */
name|boolean
name|balancer
parameter_list|(
name|boolean
name|force
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Query the current state of the balancer    *    * @return true if the balancer is enabled, false otherwise.    */
name|boolean
name|isBalancerEnabled
parameter_list|()
throws|throws
name|IOException
function_decl|;
comment|/**    * Invoke region normalizer. Can NOT run for various reasons.  Check logs.    *    * @return True if region normalizer ran, false otherwise.    */
name|boolean
name|normalize
parameter_list|()
throws|throws
name|IOException
function_decl|;
comment|/**    * Query the current state of the region normalizer    *    * @return true if region normalizer is enabled, false otherwise.    */
name|boolean
name|isNormalizerEnabled
parameter_list|()
throws|throws
name|IOException
function_decl|;
comment|/**    * Turn region normalizer on or off.    *    * @return Previous normalizer value    */
name|boolean
name|setNormalizerRunning
parameter_list|(
specifier|final
name|boolean
name|on
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Enable/Disable the catalog janitor    *    * @param enable if true enables the catalog janitor    * @return the previous state    */
name|boolean
name|enableCatalogJanitor
parameter_list|(
name|boolean
name|enable
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Ask for a scan of the catalog table    *    * @return the number of entries cleaned    */
name|int
name|runCatalogScan
parameter_list|()
throws|throws
name|IOException
function_decl|;
comment|/**    * Query on the catalog janitor state (Enabled/Disabled?)    *    */
name|boolean
name|isCatalogJanitorEnabled
parameter_list|()
throws|throws
name|IOException
function_decl|;
comment|/**    * Enable/Disable the cleaner chore    *    * @param on if true enables the cleaner chore    * @return the previous state    * @throws IOException    */
specifier|public
name|boolean
name|setCleanerChoreRunning
parameter_list|(
specifier|final
name|boolean
name|on
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Ask for cleaner chore to run    *    * @return True if cleaner chore ran, false otherwise    * @throws IOException    */
specifier|public
name|boolean
name|runCleanerChore
parameter_list|()
throws|throws
name|IOException
function_decl|;
comment|/**    * Query on the cleaner chore state (Enabled/Disabled?)    *    * @throws IOException    */
specifier|public
name|boolean
name|isCleanerChoreEnabled
parameter_list|()
throws|throws
name|IOException
function_decl|;
comment|/**    * Merge two regions. Asynchronous operation.    *    * @param nameOfRegionA encoded or full name of region a    * @param nameOfRegionB encoded or full name of region b    * @param forcible true if do a compulsory merge, otherwise we will only merge two adjacent    * regions    * @throws IOException    * @deprecated Since 2.0. Will be removed in 3.0. Use    *     {@link #mergeRegionsAsync(byte[], byte[], boolean)} instead.    */
annotation|@
name|Deprecated
name|void
name|mergeRegions
parameter_list|(
specifier|final
name|byte
index|[]
name|nameOfRegionA
parameter_list|,
specifier|final
name|byte
index|[]
name|nameOfRegionB
parameter_list|,
specifier|final
name|boolean
name|forcible
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Merge two regions. Asynchronous operation.    *    * @param nameOfRegionA encoded or full name of region a    * @param nameOfRegionB encoded or full name of region b    * @param forcible true if do a compulsory merge, otherwise we will only merge    *          two adjacent regions    * @throws IOException    */
name|Future
argument_list|<
name|Void
argument_list|>
name|mergeRegionsAsync
parameter_list|(
specifier|final
name|byte
index|[]
name|nameOfRegionA
parameter_list|,
specifier|final
name|byte
index|[]
name|nameOfRegionB
parameter_list|,
specifier|final
name|boolean
name|forcible
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Merge regions. Asynchronous operation.    *    * @param nameofRegionsToMerge encoded or full name of daughter regions    * @param forcible true if do a compulsory merge, otherwise we will only merge    *          adjacent regions    * @throws IOException    */
name|Future
argument_list|<
name|Void
argument_list|>
name|mergeRegionsAsync
parameter_list|(
specifier|final
name|byte
index|[]
index|[]
name|nameofRegionsToMerge
parameter_list|,
specifier|final
name|boolean
name|forcible
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Split a table. Asynchronous operation.    *    * @param tableName table to split    * @throws IOException if a remote or network exception occurs    */
name|void
name|split
parameter_list|(
specifier|final
name|TableName
name|tableName
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Split an individual region. Asynchronous operation.    *    * @param regionName region to split    * @throws IOException if a remote or network exception occurs    */
name|void
name|splitRegion
parameter_list|(
specifier|final
name|byte
index|[]
name|regionName
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Split a table. Asynchronous operation.    *    * @param tableName table to split    * @param splitPoint the explicit position to split on    * @throws IOException if a remote or network exception occurs    */
name|void
name|split
parameter_list|(
specifier|final
name|TableName
name|tableName
parameter_list|,
specifier|final
name|byte
index|[]
name|splitPoint
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Split an individual region. Asynchronous operation.    *    * @param regionName region to split    * @param splitPoint the explicit position to split on    * @throws IOException if a remote or network exception occurs    */
name|void
name|splitRegion
parameter_list|(
specifier|final
name|byte
index|[]
name|regionName
parameter_list|,
specifier|final
name|byte
index|[]
name|splitPoint
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Modify an existing table, more IRB friendly version.    *    * @param tableName name of table.    * @param htd modified description of the table    * @throws IOException if a remote or network exception occurs    */
name|void
name|modifyTable
parameter_list|(
specifier|final
name|TableName
name|tableName
parameter_list|,
specifier|final
name|HTableDescriptor
name|htd
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Modify an existing table, more IRB friendly version. Asynchronous operation.  This means that    * it may be a while before your schema change is updated across all of the table.    * You can use Future.get(long, TimeUnit) to wait on the operation to complete.    * It may throw ExecutionException if there was an error while executing the operation    * or TimeoutException in case the wait timeout was not long enough to allow the    * operation to complete.    *    * @param tableName name of table.    * @param htd modified description of the table    * @throws IOException if a remote or network exception occurs    * @return the result of the async modify. You can use Future.get(long, TimeUnit) to wait on the    *     operation to complete    */
name|Future
argument_list|<
name|Void
argument_list|>
name|modifyTableAsync
parameter_list|(
specifier|final
name|TableName
name|tableName
parameter_list|,
specifier|final
name|HTableDescriptor
name|htd
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Shuts down the HBase cluster    *    * @throws IOException if a remote or network exception occurs    */
name|void
name|shutdown
parameter_list|()
throws|throws
name|IOException
function_decl|;
comment|/**    * Shuts down the current HBase master only. Does not shutdown the cluster.    *    * @throws IOException if a remote or network exception occurs    * @see #shutdown()    */
name|void
name|stopMaster
parameter_list|()
throws|throws
name|IOException
function_decl|;
comment|/**    * Check whether Master is in maintenance mode    *    * @throws IOException if a remote or network exception occurs    */
name|boolean
name|isMasterInMaintenanceMode
parameter_list|()
throws|throws
name|IOException
function_decl|;
comment|/**    * Stop the designated regionserver    *    * @param hostnamePort Hostname and port delimited by a<code>:</code> as in    *<code>example.org:1234</code>    * @throws IOException if a remote or network exception occurs    */
name|void
name|stopRegionServer
parameter_list|(
specifier|final
name|String
name|hostnamePort
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * @return cluster status    * @throws IOException if a remote or network exception occurs    */
name|ClusterStatus
name|getClusterStatus
parameter_list|()
throws|throws
name|IOException
function_decl|;
comment|/**    * Get {@link RegionLoad} of all regions hosted on a regionserver.    *    * @param sn region server from which regionload is required.    * @return region load map of all regions hosted on a region server    * @throws IOException if a remote or network exception occurs    */
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|RegionLoad
argument_list|>
name|getRegionLoad
parameter_list|(
name|ServerName
name|sn
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Get {@link RegionLoad} of all regions hosted on a regionserver for a table.    *    * @param sn region server from which regionload is required.    * @param tableName get region load of regions belonging to the table    * @return region load map of all regions of a table hosted on a region server    * @throws IOException if a remote or network exception occurs    */
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|RegionLoad
argument_list|>
name|getRegionLoad
parameter_list|(
name|ServerName
name|sn
parameter_list|,
name|TableName
name|tableName
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * @return Configuration used by the instance.    */
name|Configuration
name|getConfiguration
parameter_list|()
function_decl|;
comment|/**    * Create a new namespace. Blocks until namespace has been successfully created or an exception    * is thrown.    *    * @param descriptor descriptor which describes the new namespace    */
name|void
name|createNamespace
parameter_list|(
specifier|final
name|NamespaceDescriptor
name|descriptor
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Create a new namespace    *    * @param descriptor descriptor which describes the new namespace    * @return the result of the async create namespace operation. Use Future.get(long, TimeUnit) to    *  wait on the operation to complete.    */
name|Future
argument_list|<
name|Void
argument_list|>
name|createNamespaceAsync
parameter_list|(
specifier|final
name|NamespaceDescriptor
name|descriptor
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Modify an existing namespace.  Blocks until namespace has been successfully modified or an    * exception is thrown.    *    * @param descriptor descriptor which describes the new namespace    */
name|void
name|modifyNamespace
parameter_list|(
specifier|final
name|NamespaceDescriptor
name|descriptor
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Modify an existing namespace    *    * @param descriptor descriptor which describes the new namespace    * @return the result of the async modify namespace operation. Use Future.get(long, TimeUnit) to    *  wait on the operation to complete.    */
name|Future
argument_list|<
name|Void
argument_list|>
name|modifyNamespaceAsync
parameter_list|(
specifier|final
name|NamespaceDescriptor
name|descriptor
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Delete an existing namespace. Only empty namespaces (no tables) can be removed.    * Blocks until namespace has been successfully deleted or an    * exception is thrown.    *    * @param name namespace name    */
name|void
name|deleteNamespace
parameter_list|(
specifier|final
name|String
name|name
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Delete an existing namespace. Only empty namespaces (no tables) can be removed.    *    * @param name namespace name    * @return the result of the async delete namespace operation. Use Future.get(long, TimeUnit) to    *  wait on the operation to complete.    */
name|Future
argument_list|<
name|Void
argument_list|>
name|deleteNamespaceAsync
parameter_list|(
specifier|final
name|String
name|name
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Get a namespace descriptor by name    *    * @param name name of namespace descriptor    * @return A descriptor    * @throws org.apache.hadoop.hbase.NamespaceNotFoundException    * @throws IOException if a remote or network exception occurs    */
name|NamespaceDescriptor
name|getNamespaceDescriptor
parameter_list|(
specifier|final
name|String
name|name
parameter_list|)
throws|throws
name|NamespaceNotFoundException
throws|,
name|IOException
function_decl|;
comment|/**    * List available namespace descriptors    *    * @return List of descriptors    */
name|NamespaceDescriptor
index|[]
name|listNamespaceDescriptors
parameter_list|()
throws|throws
name|IOException
function_decl|;
comment|/**    * Get list of table descriptors by namespace    *    * @param name namespace name    * @return HTD[] the read-only tableDescriptors    * @throws IOException    */
name|HTableDescriptor
index|[]
name|listTableDescriptorsByNamespace
parameter_list|(
specifier|final
name|String
name|name
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Get list of table names by namespace    *    * @param name namespace name    * @return The list of table names in the namespace    * @throws IOException    */
name|TableName
index|[]
name|listTableNamesByNamespace
parameter_list|(
specifier|final
name|String
name|name
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Get the regions of a given table.    *    * @param tableName the name of the table    * @return List of {@link HRegionInfo}.    * @throws IOException    */
name|List
argument_list|<
name|HRegionInfo
argument_list|>
name|getTableRegions
parameter_list|(
specifier|final
name|TableName
name|tableName
parameter_list|)
throws|throws
name|IOException
function_decl|;
annotation|@
name|Override
name|void
name|close
parameter_list|()
throws|throws
name|IOException
function_decl|;
comment|/**    * Get tableDescriptors    *    * @param tableNames List of table names    * @return HTD[] the read-only tableDescriptors    * @throws IOException if a remote or network exception occurs    */
name|HTableDescriptor
index|[]
name|getTableDescriptorsByTableName
parameter_list|(
name|List
argument_list|<
name|TableName
argument_list|>
name|tableNames
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Get tableDescriptors    *    * @param names List of table names    * @return HTD[] the read-only tableDescriptors    * @throws IOException if a remote or network exception occurs    */
name|HTableDescriptor
index|[]
name|getTableDescriptors
parameter_list|(
name|List
argument_list|<
name|String
argument_list|>
name|names
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * abort a procedure    * @param procId ID of the procedure to abort    * @param mayInterruptIfRunning if the proc completed at least one step, should it be aborted?    * @return true if aborted, false if procedure already completed or does not exist    * @throws IOException    */
name|boolean
name|abortProcedure
parameter_list|(
specifier|final
name|long
name|procId
parameter_list|,
specifier|final
name|boolean
name|mayInterruptIfRunning
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Abort a procedure but does not block and wait for it be completely removed.    * You can use Future.get(long, TimeUnit) to wait on the operation to complete.    * It may throw ExecutionException if there was an error while executing the operation    * or TimeoutException in case the wait timeout was not long enough to allow the    * operation to complete.    *    * @param procId ID of the procedure to abort    * @param mayInterruptIfRunning if the proc completed at least one step, should it be aborted?    * @return true if aborted, false if procedure already completed or does not exist    * @throws IOException    */
name|Future
argument_list|<
name|Boolean
argument_list|>
name|abortProcedureAsync
parameter_list|(
specifier|final
name|long
name|procId
parameter_list|,
specifier|final
name|boolean
name|mayInterruptIfRunning
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * List procedures    * @return procedure list    * @throws IOException    */
name|ProcedureInfo
index|[]
name|listProcedures
parameter_list|()
throws|throws
name|IOException
function_decl|;
comment|/**    * List locks.    * @return lock list    * @throws IOException if a remote or network exception occurs    */
name|LockInfo
index|[]
name|listLocks
parameter_list|()
throws|throws
name|IOException
function_decl|;
comment|/**    * Roll the log writer. I.e. for filesystem based write ahead logs, start writing to a new file.    *    * Note that the actual rolling of the log writer is asynchronous and may not be complete when    * this method returns. As a side effect of this call, the named region server may schedule    * store flushes at the request of the wal.    *    * @param serverName The servername of the regionserver.    * @throws IOException if a remote or network exception occurs    * @throws org.apache.hadoop.hbase.regionserver.wal.FailedLogCloseException    */
name|void
name|rollWALWriter
parameter_list|(
name|ServerName
name|serverName
parameter_list|)
throws|throws
name|IOException
throws|,
name|FailedLogCloseException
function_decl|;
comment|/**    * Helper delegage to getClusterStatus().getMasterCoprocessors().    * @return an array of master coprocessors    * @see org.apache.hadoop.hbase.ClusterStatus#getMasterCoprocessors()    */
name|String
index|[]
name|getMasterCoprocessors
parameter_list|()
throws|throws
name|IOException
function_decl|;
comment|/**    * Get the current compaction state of a table. It could be in a major compaction, a minor    * compaction, both, or none.    *    * @param tableName table to examine    * @return the current compaction state    * @throws IOException if a remote or network exception occurs    */
name|CompactionState
name|getCompactionState
parameter_list|(
specifier|final
name|TableName
name|tableName
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Get the current compaction state of region. It could be in a major compaction, a minor    * compaction, both, or none.    *    * @param regionName region to examine    * @return the current compaction state    * @throws IOException if a remote or network exception occurs    */
name|CompactionState
name|getCompactionStateForRegion
parameter_list|(
specifier|final
name|byte
index|[]
name|regionName
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Get the timestamp of the last major compaction for the passed table    *    * The timestamp of the oldest HFile resulting from a major compaction of that table,    * or 0 if no such HFile could be found.    *    * @param tableName table to examine    * @return the last major compaction timestamp or 0    * @throws IOException if a remote or network exception occurs    */
name|long
name|getLastMajorCompactionTimestamp
parameter_list|(
specifier|final
name|TableName
name|tableName
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Get the timestamp of the last major compaction for the passed region.    *    * The timestamp of the oldest HFile resulting from a major compaction of that region,    * or 0 if no such HFile could be found.    *    * @param regionName region to examine    * @return the last major compaction timestamp or 0    * @throws IOException if a remote or network exception occurs    */
name|long
name|getLastMajorCompactionTimestampForRegion
parameter_list|(
specifier|final
name|byte
index|[]
name|regionName
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Take a snapshot for the given table. If the table is enabled, a FLUSH-type snapshot will be    * taken. If the table is disabled, an offline snapshot is taken. Snapshots are considered unique    * based on<b>the name of the snapshot</b>. Attempts to take a snapshot with the same name (even    * a different type or with different parameters) will fail with a {@link    * org.apache.hadoop.hbase.snapshot.SnapshotCreationException} indicating the duplicate naming.    * Snapshot names follow the same naming constraints as tables in HBase. See {@link    * org.apache.hadoop.hbase.TableName#isLegalFullyQualifiedTableName(byte[])}.    *    * @param snapshotName name of the snapshot to be created    * @param tableName name of the table for which snapshot is created    * @throws IOException if a remote or network exception occurs    * @throws org.apache.hadoop.hbase.snapshot.SnapshotCreationException if snapshot creation failed    * @throws IllegalArgumentException if the snapshot request is formatted incorrectly    */
name|void
name|snapshot
parameter_list|(
specifier|final
name|String
name|snapshotName
parameter_list|,
specifier|final
name|TableName
name|tableName
parameter_list|)
throws|throws
name|IOException
throws|,
name|SnapshotCreationException
throws|,
name|IllegalArgumentException
function_decl|;
comment|/**    * Create a timestamp consistent snapshot for the given table. Snapshots are considered unique    * based on<b>the name of the snapshot</b>. Attempts to take a snapshot with the same name (even    * different type or with different parameters) will fail with a {@link SnapshotCreationException}    * indicating the duplicate naming. Snapshot names follow the same naming constraints as tables in    * HBase.    *    * @param snapshotName name of the snapshot to be created    * @param tableName name of the table for which snapshot is created    * @throws IOException if a remote or network exception occurs    * @throws SnapshotCreationException if snapshot creation failed    * @throws IllegalArgumentException if the snapshot request is formatted incorrectly    */
name|void
name|snapshot
parameter_list|(
specifier|final
name|byte
index|[]
name|snapshotName
parameter_list|,
specifier|final
name|TableName
name|tableName
parameter_list|)
throws|throws
name|IOException
throws|,
name|SnapshotCreationException
throws|,
name|IllegalArgumentException
function_decl|;
comment|/**    * Create typed snapshot of the table. Snapshots are considered unique based on<b>the name of the    * snapshot</b>. Attempts to take a snapshot with the same name (even a different type or with    * different parameters) will fail with a {@link SnapshotCreationException} indicating the    * duplicate naming. Snapshot names follow the same naming constraints as tables in HBase. See    * {@link org.apache.hadoop.hbase.TableName#isLegalFullyQualifiedTableName(byte[])}.    *    * @param snapshotName name to give the snapshot on the filesystem. Must be unique from all other    * snapshots stored on the cluster    * @param tableName name of the table to snapshot    * @param type type of snapshot to take    * @throws IOException we fail to reach the master    * @throws SnapshotCreationException if snapshot creation failed    * @throws IllegalArgumentException if the snapshot request is formatted incorrectly    */
name|void
name|snapshot
parameter_list|(
specifier|final
name|String
name|snapshotName
parameter_list|,
specifier|final
name|TableName
name|tableName
parameter_list|,
name|SnapshotType
name|type
parameter_list|)
throws|throws
name|IOException
throws|,
name|SnapshotCreationException
throws|,
name|IllegalArgumentException
function_decl|;
comment|/**    * Take a snapshot and wait for the server to complete that snapshot (blocking). Only a single    * snapshot should be taken at a time for an instance of HBase, or results may be undefined (you    * can tell multiple HBase clusters to snapshot at the same time, but only one at a time for a    * single cluster). Snapshots are considered unique based on<b>the name of the snapshot</b>.    * Attempts to take a snapshot with the same name (even a different type or with different    * parameters) will fail with a {@link SnapshotCreationException} indicating the duplicate naming.    * Snapshot names follow the same naming constraints as tables in HBase. See {@link    * org.apache.hadoop.hbase.TableName#isLegalFullyQualifiedTableName(byte[])}. You should probably    * use {@link #snapshot(String, org.apache.hadoop.hbase.TableName)} or    * {@link #snapshot(byte[], org.apache.hadoop.hbase.TableName)} unless you are sure about the type    * of snapshot that you want to take.    *    * @param snapshot snapshot to take    * @throws IOException or we lose contact with the master.    * @throws SnapshotCreationException if snapshot failed to be taken    * @throws IllegalArgumentException if the snapshot request is formatted incorrectly    */
name|void
name|snapshot
parameter_list|(
name|SnapshotDescription
name|snapshot
parameter_list|)
throws|throws
name|IOException
throws|,
name|SnapshotCreationException
throws|,
name|IllegalArgumentException
function_decl|;
comment|/**    * Take a snapshot without waiting for the server to complete that snapshot (asynchronous) Only a    * single snapshot should be taken at a time, or results may be undefined.    *    * @param snapshot snapshot to take    * @throws IOException if the snapshot did not succeed or we lose contact with the master.    * @throws SnapshotCreationException if snapshot creation failed    * @throws IllegalArgumentException if the snapshot request is formatted incorrectly    */
name|void
name|takeSnapshotAsync
parameter_list|(
name|SnapshotDescription
name|snapshot
parameter_list|)
throws|throws
name|IOException
throws|,
name|SnapshotCreationException
function_decl|;
comment|/**    * Check the current state of the passed snapshot. There are three possible states:<ol>    *<li>running - returns<tt>false</tt></li><li>finished - returns<tt>true</tt></li>    *<li>finished with error - throws the exception that caused the snapshot to fail</li></ol> The    * cluster only knows about the most recent snapshot. Therefore, if another snapshot has been    * run/started since the snapshot you are checking, you will receive an {@link    * org.apache.hadoop.hbase.snapshot.UnknownSnapshotException}.    *    * @param snapshot description of the snapshot to check    * @return<tt>true</tt> if the snapshot is completed,<tt>false</tt> if the snapshot is still    * running    * @throws IOException if we have a network issue    * @throws org.apache.hadoop.hbase.snapshot.HBaseSnapshotException if the snapshot failed    * @throws org.apache.hadoop.hbase.snapshot.UnknownSnapshotException if the requested snapshot is    * unknown    */
name|boolean
name|isSnapshotFinished
parameter_list|(
specifier|final
name|SnapshotDescription
name|snapshot
parameter_list|)
throws|throws
name|IOException
throws|,
name|HBaseSnapshotException
throws|,
name|UnknownSnapshotException
function_decl|;
comment|/**    * Restore the specified snapshot on the original table. (The table must be disabled) If the    * "hbase.snapshot.restore.take.failsafe.snapshot" configuration property is set to true, a    * snapshot of the current table is taken before executing the restore operation. In case of    * restore failure, the failsafe snapshot will be restored. If the restore completes without    * problem the failsafe snapshot is deleted.    *    * @param snapshotName name of the snapshot to restore    * @throws IOException if a remote or network exception occurs    * @throws org.apache.hadoop.hbase.snapshot.RestoreSnapshotException if snapshot failed to be    * restored    * @throws IllegalArgumentException if the restore request is formatted incorrectly    */
name|void
name|restoreSnapshot
parameter_list|(
specifier|final
name|byte
index|[]
name|snapshotName
parameter_list|)
throws|throws
name|IOException
throws|,
name|RestoreSnapshotException
function_decl|;
comment|/**    * Restore the specified snapshot on the original table. (The table must be disabled) If the    * "hbase.snapshot.restore.take.failsafe.snapshot" configuration property is set to true, a    * snapshot of the current table is taken before executing the restore operation. In case of    * restore failure, the failsafe snapshot will be restored. If the restore completes without    * problem the failsafe snapshot is deleted.    *    * @param snapshotName name of the snapshot to restore    * @throws IOException if a remote or network exception occurs    * @throws RestoreSnapshotException if snapshot failed to be restored    * @throws IllegalArgumentException if the restore request is formatted incorrectly    */
name|void
name|restoreSnapshot
parameter_list|(
specifier|final
name|String
name|snapshotName
parameter_list|)
throws|throws
name|IOException
throws|,
name|RestoreSnapshotException
function_decl|;
comment|/**    * Restore the specified snapshot on the original table. (The table must be disabled) If the    * "hbase.snapshot.restore.take.failsafe.snapshot" configuration property is set to true, a    * snapshot of the current table is taken before executing the restore operation. In case of    * restore failure, the failsafe snapshot will be restored. If the restore completes without    * problem the failsafe snapshot is deleted.    *    * @param snapshotName name of the snapshot to restore    * @throws IOException if a remote or network exception occurs    * @throws RestoreSnapshotException if snapshot failed to be restored    * @return the result of the async restore snapshot. You can use Future.get(long, TimeUnit)    *    to wait on the operation to complete.    */
name|Future
argument_list|<
name|Void
argument_list|>
name|restoreSnapshotAsync
parameter_list|(
specifier|final
name|String
name|snapshotName
parameter_list|)
throws|throws
name|IOException
throws|,
name|RestoreSnapshotException
function_decl|;
comment|/**    * Restore the specified snapshot on the original table. (The table must be disabled) If    * 'takeFailSafeSnapshot' is set to true, a snapshot of the current table is taken before    * executing the restore operation. In case of restore failure, the failsafe snapshot will be    * restored. If the restore completes without problem the failsafe snapshot is deleted. The    * failsafe snapshot name is configurable by using the property    * "hbase.snapshot.restore.failsafe.name".    *    * @param snapshotName name of the snapshot to restore    * @param takeFailSafeSnapshot true if the failsafe snapshot should be taken    * @throws IOException if a remote or network exception occurs    * @throws RestoreSnapshotException if snapshot failed to be restored    * @throws IllegalArgumentException if the restore request is formatted incorrectly    */
name|void
name|restoreSnapshot
parameter_list|(
specifier|final
name|byte
index|[]
name|snapshotName
parameter_list|,
specifier|final
name|boolean
name|takeFailSafeSnapshot
parameter_list|)
throws|throws
name|IOException
throws|,
name|RestoreSnapshotException
function_decl|;
comment|/**    * Restore the specified snapshot on the original table. (The table must be disabled) If    * 'takeFailSafeSnapshot' is set to true, a snapshot of the current table is taken before    * executing the restore operation. In case of restore failure, the failsafe snapshot will be    * restored. If the restore completes without problem the failsafe snapshot is deleted. The    * failsafe snapshot name is configurable by using the property    * "hbase.snapshot.restore.failsafe.name".    *    * @param snapshotName name of the snapshot to restore    * @param takeFailSafeSnapshot true if the failsafe snapshot should be taken    * @throws IOException if a remote or network exception occurs    * @throws RestoreSnapshotException if snapshot failed to be restored    * @throws IllegalArgumentException if the restore request is formatted incorrectly    */
name|void
name|restoreSnapshot
parameter_list|(
specifier|final
name|String
name|snapshotName
parameter_list|,
specifier|final
name|boolean
name|takeFailSafeSnapshot
parameter_list|)
throws|throws
name|IOException
throws|,
name|RestoreSnapshotException
function_decl|;
comment|/**    * Create a new table by cloning the snapshot content.    *    * @param snapshotName name of the snapshot to be cloned    * @param tableName name of the table where the snapshot will be restored    * @throws IOException if a remote or network exception occurs    * @throws TableExistsException if table to be created already exists    * @throws RestoreSnapshotException if snapshot failed to be cloned    * @throws IllegalArgumentException if the specified table has not a valid name    */
name|void
name|cloneSnapshot
parameter_list|(
specifier|final
name|byte
index|[]
name|snapshotName
parameter_list|,
specifier|final
name|TableName
name|tableName
parameter_list|)
throws|throws
name|IOException
throws|,
name|TableExistsException
throws|,
name|RestoreSnapshotException
function_decl|;
comment|/**    * Create a new table by cloning the snapshot content.    * @param snapshotName name of the snapshot to be cloned    * @param tableName name of the table where the snapshot will be restored    * @param restoreAcl true to clone acl into newly created table    * @throws IOException if a remote or network exception occurs    * @throws TableExistsException if table to be created already exists    * @throws RestoreSnapshotException if snapshot failed to be cloned    * @throws IllegalArgumentException if the specified table has not a valid name    */
name|void
name|cloneSnapshot
parameter_list|(
specifier|final
name|String
name|snapshotName
parameter_list|,
specifier|final
name|TableName
name|tableName
parameter_list|,
specifier|final
name|boolean
name|restoreAcl
parameter_list|)
throws|throws
name|IOException
throws|,
name|TableExistsException
throws|,
name|RestoreSnapshotException
function_decl|;
comment|/**    * Create a new table by cloning the snapshot content.    *    * @param snapshotName name of the snapshot to be cloned    * @param tableName name of the table where the snapshot will be restored    * @throws IOException if a remote or network exception occurs    * @throws TableExistsException if table to be created already exists    * @throws RestoreSnapshotException if snapshot failed to be cloned    * @throws IllegalArgumentException if the specified table has not a valid name    */
name|void
name|cloneSnapshot
parameter_list|(
specifier|final
name|String
name|snapshotName
parameter_list|,
specifier|final
name|TableName
name|tableName
parameter_list|)
throws|throws
name|IOException
throws|,
name|TableExistsException
throws|,
name|RestoreSnapshotException
function_decl|;
comment|/**    * Create a new table by cloning the snapshot content, but does not block    * and wait for it be completely cloned.    * You can use Future.get(long, TimeUnit) to wait on the operation to complete.    * It may throw ExecutionException if there was an error while executing the operation    * or TimeoutException in case the wait timeout was not long enough to allow the    * operation to complete.    *    * @param snapshotName name of the snapshot to be cloned    * @param tableName name of the table where the snapshot will be restored    * @throws IOException if a remote or network exception occurs    * @throws TableExistsException if table to be cloned already exists    * @return the result of the async clone snapshot. You can use Future.get(long, TimeUnit)    *    to wait on the operation to complete.    */
name|Future
argument_list|<
name|Void
argument_list|>
name|cloneSnapshotAsync
parameter_list|(
specifier|final
name|String
name|snapshotName
parameter_list|,
specifier|final
name|TableName
name|tableName
parameter_list|)
throws|throws
name|IOException
throws|,
name|TableExistsException
function_decl|;
comment|/**    * Execute a distributed procedure on a cluster.    *    * @param signature A distributed procedure is uniquely identified by its signature (default the    * root ZK node name of the procedure).    * @param instance The instance name of the procedure. For some procedures, this parameter is    * optional.    * @param props Property/Value pairs of properties passing to the procedure    * @throws IOException    */
name|void
name|execProcedure
parameter_list|(
name|String
name|signature
parameter_list|,
name|String
name|instance
parameter_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|props
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Execute a distributed procedure on a cluster.    *    * @param signature A distributed procedure is uniquely identified by its signature (default the    * root ZK node name of the procedure).    * @param instance The instance name of the procedure. For some procedures, this parameter is    * optional.    * @param props Property/Value pairs of properties passing to the procedure    * @return data returned after procedure execution. null if no return data.    * @throws IOException    */
name|byte
index|[]
name|execProcedureWithRet
parameter_list|(
name|String
name|signature
parameter_list|,
name|String
name|instance
parameter_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|props
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Check the current state of the specified procedure. There are three possible states:<ol>    *<li>running - returns<tt>false</tt></li><li>finished - returns<tt>true</tt></li>    *<li>finished with error - throws the exception that caused the procedure to fail</li></ol>    *    * @param signature The signature that uniquely identifies a procedure    * @param instance The instance name of the procedure    * @param props Property/Value pairs of properties passing to the procedure    * @return true if the specified procedure is finished successfully, false if it is still running    * @throws IOException if the specified procedure finished with error    */
name|boolean
name|isProcedureFinished
parameter_list|(
name|String
name|signature
parameter_list|,
name|String
name|instance
parameter_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|props
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * List completed snapshots.    *    * @return a list of snapshot descriptors for completed snapshots    * @throws IOException if a network error occurs    */
name|List
argument_list|<
name|SnapshotDescription
argument_list|>
name|listSnapshots
parameter_list|()
throws|throws
name|IOException
function_decl|;
comment|/**    * List all the completed snapshots matching the given regular expression.    *    * @param regex The regular expression to match against    * @return - returns a List of SnapshotDescription    * @throws IOException if a remote or network exception occurs    */
name|List
argument_list|<
name|SnapshotDescription
argument_list|>
name|listSnapshots
parameter_list|(
name|String
name|regex
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * List all the completed snapshots matching the given pattern.    *    * @param pattern The compiled regular expression to match against    * @return - returns a List of SnapshotDescription    * @throws IOException if a remote or network exception occurs    */
name|List
argument_list|<
name|SnapshotDescription
argument_list|>
name|listSnapshots
parameter_list|(
name|Pattern
name|pattern
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * List all the completed snapshots matching the given table name regular expression and snapshot    * name regular expression.    * @param tableNameRegex The table name regular expression to match against    * @param snapshotNameRegex The snapshot name regular expression to match against    * @return - returns a List of completed SnapshotDescription    * @throws IOException if a remote or network exception occurs    */
name|List
argument_list|<
name|SnapshotDescription
argument_list|>
name|listTableSnapshots
parameter_list|(
name|String
name|tableNameRegex
parameter_list|,
name|String
name|snapshotNameRegex
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * List all the completed snapshots matching the given table name regular expression and snapshot    * name regular expression.    * @param tableNamePattern The compiled table name regular expression to match against    * @param snapshotNamePattern The compiled snapshot name regular expression to match against    * @return - returns a List of completed SnapshotDescription    * @throws IOException if a remote or network exception occurs    */
name|List
argument_list|<
name|SnapshotDescription
argument_list|>
name|listTableSnapshots
parameter_list|(
name|Pattern
name|tableNamePattern
parameter_list|,
name|Pattern
name|snapshotNamePattern
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Delete an existing snapshot.    *    * @param snapshotName name of the snapshot    * @throws IOException if a remote or network exception occurs    */
name|void
name|deleteSnapshot
parameter_list|(
specifier|final
name|byte
index|[]
name|snapshotName
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Delete an existing snapshot.    *    * @param snapshotName name of the snapshot    * @throws IOException if a remote or network exception occurs    */
name|void
name|deleteSnapshot
parameter_list|(
specifier|final
name|String
name|snapshotName
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Delete existing snapshots whose names match the pattern passed.    *    * @param regex The regular expression to match against    * @throws IOException if a remote or network exception occurs    */
name|void
name|deleteSnapshots
parameter_list|(
specifier|final
name|String
name|regex
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Delete existing snapshots whose names match the pattern passed.    *    * @param pattern pattern for names of the snapshot to match    * @throws IOException if a remote or network exception occurs    */
name|void
name|deleteSnapshots
parameter_list|(
specifier|final
name|Pattern
name|pattern
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Delete all existing snapshots matching the given table name regular expression and snapshot    * name regular expression.    * @param tableNameRegex The table name regular expression to match against    * @param snapshotNameRegex The snapshot name regular expression to match against    * @throws IOException if a remote or network exception occurs    */
name|void
name|deleteTableSnapshots
parameter_list|(
name|String
name|tableNameRegex
parameter_list|,
name|String
name|snapshotNameRegex
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Delete all existing snapshots matching the given table name regular expression and snapshot    * name regular expression.    * @param tableNamePattern The compiled table name regular expression to match against    * @param snapshotNamePattern The compiled snapshot name regular expression to match against    * @throws IOException if a remote or network exception occurs    */
name|void
name|deleteTableSnapshots
parameter_list|(
name|Pattern
name|tableNamePattern
parameter_list|,
name|Pattern
name|snapshotNamePattern
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Apply the new quota settings.    *    * @param quota the quota settings    * @throws IOException if a remote or network exception occurs    */
name|void
name|setQuota
parameter_list|(
specifier|final
name|QuotaSettings
name|quota
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Return a QuotaRetriever to list the quotas based on the filter.    *    * @param filter the quota settings filter    * @return the quota retriever    * @throws IOException if a remote or network exception occurs    */
name|QuotaRetriever
name|getQuotaRetriever
parameter_list|(
specifier|final
name|QuotaFilter
name|filter
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Creates and returns a {@link com.google.protobuf.RpcChannel} instance connected to the active    * master.<p> The obtained {@link com.google.protobuf.RpcChannel} instance can be used to access    * a published coprocessor {@link com.google.protobuf.Service} using standard protobuf service    * invocations:</p><div style="background-color: #cccccc; padding: 2px">    *<blockquote><pre>    * CoprocessorRpcChannel channel = myAdmin.coprocessorService();    * MyService.BlockingInterface service = MyService.newBlockingStub(channel);    * MyCallRequest request = MyCallRequest.newBuilder()    *     ...    *     .build();    * MyCallResponse response = service.myCall(null, request);    *</pre></blockquote></div>    *    * @return A MasterCoprocessorRpcChannel instance    */
name|CoprocessorRpcChannel
name|coprocessorService
parameter_list|()
function_decl|;
comment|/**    * Creates and returns a {@link com.google.protobuf.RpcChannel} instance    * connected to the passed region server.    *    *<p>    * The obtained {@link com.google.protobuf.RpcChannel} instance can be used to access a published    * coprocessor {@link com.google.protobuf.Service} using standard protobuf service invocations:    *</p>    *    *<div style="background-color: #cccccc; padding: 2px">    *<blockquote><pre>    * CoprocessorRpcChannel channel = myAdmin.coprocessorService(serverName);    * MyService.BlockingInterface service = MyService.newBlockingStub(channel);    * MyCallRequest request = MyCallRequest.newBuilder()    *     ...    *     .build();    * MyCallResponse response = service.myCall(null, request);    *</pre></blockquote></div>    *    * @param sn the server name to which the endpoint call is made    * @return A RegionServerCoprocessorRpcChannel instance    */
name|CoprocessorRpcChannel
name|coprocessorService
parameter_list|(
name|ServerName
name|sn
parameter_list|)
function_decl|;
comment|/**    * Update the configuration and trigger an online config change    * on the regionserver    * @param server : The server whose config needs to be updated.    * @throws IOException    */
name|void
name|updateConfiguration
parameter_list|(
name|ServerName
name|server
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Update the configuration and trigger an online config change    * on all the regionservers    * @throws IOException    */
name|void
name|updateConfiguration
parameter_list|()
throws|throws
name|IOException
function_decl|;
comment|/**    * Get the info port of the current master if one is available.    * @return master info port    * @throws IOException    */
specifier|public
name|int
name|getMasterInfoPort
parameter_list|()
throws|throws
name|IOException
function_decl|;
comment|/**    * Compact a table. Asynchronous operation.    *    * @param tableName table to compact    * @param compactType {@link org.apache.hadoop.hbase.client.CompactType}    * @throws IOException    * @throws InterruptedException    */
name|void
name|compact
parameter_list|(
specifier|final
name|TableName
name|tableName
parameter_list|,
name|CompactType
name|compactType
parameter_list|)
throws|throws
name|IOException
throws|,
name|InterruptedException
function_decl|;
comment|/**    * Compact a column family within a table. Asynchronous operation.    *    * @param tableName table to compact    * @param columnFamily column family within a table    * @param compactType {@link org.apache.hadoop.hbase.client.CompactType}    * @throws IOException if not a mob column family or if a remote or network exception occurs    * @throws InterruptedException    */
name|void
name|compact
parameter_list|(
specifier|final
name|TableName
name|tableName
parameter_list|,
specifier|final
name|byte
index|[]
name|columnFamily
parameter_list|,
name|CompactType
name|compactType
parameter_list|)
throws|throws
name|IOException
throws|,
name|InterruptedException
function_decl|;
comment|/**    * Major compact a table. Asynchronous operation.    *    * @param tableName table to compact    * @param compactType {@link org.apache.hadoop.hbase.client.CompactType}    * @throws IOException    * @throws InterruptedException    */
name|void
name|majorCompact
parameter_list|(
specifier|final
name|TableName
name|tableName
parameter_list|,
name|CompactType
name|compactType
parameter_list|)
throws|throws
name|IOException
throws|,
name|InterruptedException
function_decl|;
comment|/**    * Major compact a column family within a table. Asynchronous operation.    *    * @param tableName table to compact    * @param columnFamily column family within a table    * @param compactType {@link org.apache.hadoop.hbase.client.CompactType}    * @throws IOException if not a mob column family or if a remote or network exception occurs    * @throws InterruptedException    */
name|void
name|majorCompact
parameter_list|(
specifier|final
name|TableName
name|tableName
parameter_list|,
specifier|final
name|byte
index|[]
name|columnFamily
parameter_list|,
name|CompactType
name|compactType
parameter_list|)
throws|throws
name|IOException
throws|,
name|InterruptedException
function_decl|;
comment|/**    * Get the current compaction state of a table. It could be in a compaction, or none.    *    * @param tableName table to examine    * @param compactType {@link org.apache.hadoop.hbase.client.CompactType}    * @return the current compaction state    * @throws IOException if a remote or network exception occurs    */
name|CompactionState
name|getCompactionState
parameter_list|(
specifier|final
name|TableName
name|tableName
parameter_list|,
name|CompactType
name|compactType
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Return the set of supported security capabilities.    * @throws IOException    * @throws UnsupportedOperationException    */
name|List
argument_list|<
name|SecurityCapability
argument_list|>
name|getSecurityCapabilities
parameter_list|()
throws|throws
name|IOException
function_decl|;
comment|/**    * Turn the Split or Merge switches on or off.    *    * @param enabled enabled or not    * @param synchronous If true, it waits until current split() call, if outstanding, to return.    * @param switchTypes switchType list {@link MasterSwitchType}    * @return Previous switch value array    */
name|boolean
index|[]
name|setSplitOrMergeEnabled
parameter_list|(
specifier|final
name|boolean
name|enabled
parameter_list|,
specifier|final
name|boolean
name|synchronous
parameter_list|,
specifier|final
name|MasterSwitchType
modifier|...
name|switchTypes
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Query the current state of the switch    *    * @return true if the switch is enabled, false otherwise.    */
name|boolean
name|isSplitOrMergeEnabled
parameter_list|(
specifier|final
name|MasterSwitchType
name|switchType
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Add a new replication peer for replicating data to slave cluster    * @param peerId a short name that identifies the peer    * @param peerConfig configuration for the replication slave cluster    * @throws IOException    */
specifier|default
name|void
name|addReplicationPeer
parameter_list|(
specifier|final
name|String
name|peerId
parameter_list|,
specifier|final
name|ReplicationPeerConfig
name|peerConfig
parameter_list|)
throws|throws
name|IOException
block|{   }
comment|/**    * Remove a peer and stop the replication    * @param peerId a short name that identifies the peer    * @throws IOException    */
specifier|default
name|void
name|removeReplicationPeer
parameter_list|(
specifier|final
name|String
name|peerId
parameter_list|)
throws|throws
name|IOException
block|{   }
comment|/**    * Restart the replication stream to the specified peer    * @param peerId a short name that identifies the peer    * @throws IOException    */
specifier|default
name|void
name|enableReplicationPeer
parameter_list|(
specifier|final
name|String
name|peerId
parameter_list|)
throws|throws
name|IOException
block|{   }
comment|/**    * Stop the replication stream to the specified peer    * @param peerId a short name that identifies the peer    * @throws IOException    */
specifier|default
name|void
name|disableReplicationPeer
parameter_list|(
specifier|final
name|String
name|peerId
parameter_list|)
throws|throws
name|IOException
block|{   }
comment|/**    * Returns the configured ReplicationPeerConfig for the specified peer    * @param peerId a short name that identifies the peer    * @return ReplicationPeerConfig for the peer    * @throws IOException    */
specifier|default
name|ReplicationPeerConfig
name|getReplicationPeerConfig
parameter_list|(
specifier|final
name|String
name|peerId
parameter_list|)
throws|throws
name|IOException
block|{
return|return
operator|new
name|ReplicationPeerConfig
argument_list|()
return|;
block|}
comment|/**    * Update the peerConfig for the specified peer    * @param peerId a short name that identifies the peer    * @param peerConfig new config for the peer    * @throws IOException    */
specifier|default
name|void
name|updateReplicationPeerConfig
parameter_list|(
specifier|final
name|String
name|peerId
parameter_list|,
specifier|final
name|ReplicationPeerConfig
name|peerConfig
parameter_list|)
throws|throws
name|IOException
block|{   }
comment|/**    * Append the replicable table-cf config of the specified peer    * @param id a short that identifies the cluster    * @param tableCfs A map from tableName to column family names    * @throws ReplicationException    * @throws IOException    */
specifier|default
name|void
name|appendReplicationPeerTableCFs
parameter_list|(
name|String
name|id
parameter_list|,
name|Map
argument_list|<
name|TableName
argument_list|,
name|?
extends|extends
name|Collection
argument_list|<
name|String
argument_list|>
argument_list|>
name|tableCfs
parameter_list|)
throws|throws
name|ReplicationException
throws|,
name|IOException
block|{   }
comment|/**    * Remove some table-cfs from config of the specified peer    * @param id a short name that identifies the cluster    * @param tableCfs A map from tableName to column family names    * @throws ReplicationException    * @throws IOException    */
specifier|default
name|void
name|removeReplicationPeerTableCFs
parameter_list|(
name|String
name|id
parameter_list|,
name|Map
argument_list|<
name|TableName
argument_list|,
name|?
extends|extends
name|Collection
argument_list|<
name|String
argument_list|>
argument_list|>
name|tableCfs
parameter_list|)
throws|throws
name|ReplicationException
throws|,
name|IOException
block|{   }
comment|/**    * Return a list of replication peers.    * @return a list of replication peers description    * @throws IOException    */
specifier|default
name|List
argument_list|<
name|ReplicationPeerDescription
argument_list|>
name|listReplicationPeers
parameter_list|()
throws|throws
name|IOException
block|{
return|return
operator|new
name|ArrayList
argument_list|<>
argument_list|()
return|;
block|}
comment|/**    * Return a list of replication peers.    * @param regex The regular expression to match peer id    * @return a list of replication peers description    * @throws IOException    */
specifier|default
name|List
argument_list|<
name|ReplicationPeerDescription
argument_list|>
name|listReplicationPeers
parameter_list|(
name|String
name|regex
parameter_list|)
throws|throws
name|IOException
block|{
return|return
operator|new
name|ArrayList
argument_list|<>
argument_list|()
return|;
block|}
comment|/**    * Return a list of replication peers.    * @param pattern The compiled regular expression to match peer id    * @return a list of replication peers description    * @throws IOException    */
specifier|default
name|List
argument_list|<
name|ReplicationPeerDescription
argument_list|>
name|listReplicationPeers
parameter_list|(
name|Pattern
name|pattern
parameter_list|)
throws|throws
name|IOException
block|{
return|return
operator|new
name|ArrayList
argument_list|<>
argument_list|()
return|;
block|}
comment|/**    * Mark a region server as draining to prevent additional regions from getting assigned to it.    * @param servers List of region servers to drain.    */
name|void
name|drainRegionServers
parameter_list|(
name|List
argument_list|<
name|ServerName
argument_list|>
name|servers
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * List region servers marked as draining to not get additional regions assigned to them.    * @return List of draining region servers.    */
name|List
argument_list|<
name|ServerName
argument_list|>
name|listDrainingRegionServers
parameter_list|()
throws|throws
name|IOException
function_decl|;
comment|/**    * Remove drain from a region server to allow additional regions assignments.    * @param servers List of region servers to remove drain from.    */
name|void
name|removeDrainFromRegionServers
parameter_list|(
name|List
argument_list|<
name|ServerName
argument_list|>
name|servers
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Find all table and column families that are replicated from this cluster    * @return the replicated table-cfs list of this cluster.    */
name|List
argument_list|<
name|TableCFs
argument_list|>
name|listReplicatedTableCFs
parameter_list|()
throws|throws
name|IOException
function_decl|;
comment|/**    * Enable a table's replication switch.    * @param tableName name of the table    * @throws IOException if a remote or network exception occurs    */
name|void
name|enableTableReplication
parameter_list|(
specifier|final
name|TableName
name|tableName
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Disable a table's replication switch.    * @param tableName name of the table    * @throws IOException if a remote or network exception occurs    */
name|void
name|disableTableReplication
parameter_list|(
specifier|final
name|TableName
name|tableName
parameter_list|)
throws|throws
name|IOException
function_decl|;
block|}
end_interface

end_unit

