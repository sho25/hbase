begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/*  *  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|NavigableSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|TreeMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|TreeSet
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HConstants
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|metrics
operator|.
name|ScanMetrics
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|filter
operator|.
name|Filter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|filter
operator|.
name|IncompatibleFilterException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|TimeRange
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|security
operator|.
name|access
operator|.
name|Permission
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|security
operator|.
name|visibility
operator|.
name|Authorizations
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|Bytes
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|yetus
operator|.
name|audience
operator|.
name|InterfaceAudience
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|Logger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|LoggerFactory
import|;
end_import

begin_comment
comment|/**  * Used to perform Scan operations.  *<p>  * All operations are identical to {@link Get} with the exception of instantiation. Rather than  * specifying a single row, an optional startRow and stopRow may be defined. If rows are not  * specified, the Scanner will iterate over all rows.  *<p>  * To get all columns from all rows of a Table, create an instance with no constraints; use the  * {@link #Scan()} constructor. To constrain the scan to specific column families, call  * {@link #addFamily(byte[]) addFamily} for each family to retrieve on your Scan instance.  *<p>  * To get specific columns, call {@link #addColumn(byte[], byte[]) addColumn} for each column to  * retrieve.  *<p>  * To only retrieve columns within a specific range of version timestamps, call  * {@link #setTimeRange(long, long) setTimeRange}.  *<p>  * To only retrieve columns with a specific timestamp, call {@link #setTimestamp(long) setTimestamp}  * .  *<p>  * To limit the number of versions of each column to be returned, call {@link #setMaxVersions(int)  * setMaxVersions}.  *<p>  * To limit the maximum number of values returned for each call to next(), call  * {@link #setBatch(int) setBatch}.  *<p>  * To add a filter, call {@link #setFilter(org.apache.hadoop.hbase.filter.Filter) setFilter}.  *<p>  * For small scan, it is deprecated in 2.0.0. Now we have a {@link #setLimit(int)} method in Scan  * object which is used to tell RS how many rows we want. If the rows return reaches the limit, the  * RS will close the RegionScanner automatically. And we will also fetch data when openScanner in  * the new implementation, this means we can also finish a scan operation in one rpc call. And we  * have also introduced a {@link #setReadType(ReadType)} method. You can use this method to tell RS  * to use pread explicitly.  *<p>  * Expert: To explicitly disable server-side block caching for this scan, execute  * {@link #setCacheBlocks(boolean)}.  *<p>  *<em>Note:</em> Usage alters Scan instances. Internally, attributes are updated as the Scan runs  * and if enabled, metrics accumulate in the Scan instance. Be aware this is the case when you go to  * clone a Scan instance or if you go to reuse a created Scan instance; safer is create a Scan  * instance per usage.  */
end_comment

begin_class
annotation|@
name|InterfaceAudience
operator|.
name|Public
specifier|public
class|class
name|Scan
extends|extends
name|Query
block|{
specifier|private
specifier|static
specifier|final
name|Logger
name|LOG
init|=
name|LoggerFactory
operator|.
name|getLogger
argument_list|(
name|Scan
operator|.
name|class
argument_list|)
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|String
name|RAW_ATTR
init|=
literal|"_raw_"
decl_stmt|;
specifier|private
name|byte
index|[]
name|startRow
init|=
name|HConstants
operator|.
name|EMPTY_START_ROW
decl_stmt|;
specifier|private
name|boolean
name|includeStartRow
init|=
literal|true
decl_stmt|;
specifier|private
name|byte
index|[]
name|stopRow
init|=
name|HConstants
operator|.
name|EMPTY_END_ROW
decl_stmt|;
specifier|private
name|boolean
name|includeStopRow
init|=
literal|false
decl_stmt|;
specifier|private
name|int
name|maxVersions
init|=
literal|1
decl_stmt|;
specifier|private
name|int
name|batch
init|=
operator|-
literal|1
decl_stmt|;
comment|/**    * Partial {@link Result}s are {@link Result}s must be combined to form a complete {@link Result}.    * The {@link Result}s had to be returned in fragments (i.e. as partials) because the size of the    * cells in the row exceeded max result size on the server. Typically partial results will be    * combined client side into complete results before being delivered to the caller. However, if    * this flag is set, the caller is indicating that they do not mind seeing partial results (i.e.    * they understand that the results returned from the Scanner may only represent part of a    * particular row). In such a case, any attempt to combine the partials into a complete result on    * the client side will be skipped, and the caller will be able to see the exact results returned    * from the server.    */
specifier|private
name|boolean
name|allowPartialResults
init|=
literal|false
decl_stmt|;
specifier|private
name|int
name|storeLimit
init|=
operator|-
literal|1
decl_stmt|;
specifier|private
name|int
name|storeOffset
init|=
literal|0
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|String
name|SCAN_ATTRIBUTES_METRICS_ENABLE
init|=
literal|"scan.attributes.metrics.enable"
decl_stmt|;
comment|// If an application wants to use multiple scans over different tables each scan must
comment|// define this attribute with the appropriate table name by calling
comment|// scan.setAttribute(Scan.SCAN_ATTRIBUTES_TABLE_NAME, Bytes.toBytes(tableName))
specifier|static
specifier|public
specifier|final
name|String
name|SCAN_ATTRIBUTES_TABLE_NAME
init|=
literal|"scan.attributes.table.name"
decl_stmt|;
comment|/**    * -1 means no caching specified and the value of {@link HConstants#HBASE_CLIENT_SCANNER_CACHING}    * (default to {@link HConstants#DEFAULT_HBASE_CLIENT_SCANNER_CACHING}) will be used    */
specifier|private
name|int
name|caching
init|=
operator|-
literal|1
decl_stmt|;
specifier|private
name|long
name|maxResultSize
init|=
operator|-
literal|1
decl_stmt|;
specifier|private
name|boolean
name|cacheBlocks
init|=
literal|true
decl_stmt|;
specifier|private
name|boolean
name|reversed
init|=
literal|false
decl_stmt|;
specifier|private
name|TimeRange
name|tr
init|=
name|TimeRange
operator|.
name|allTime
argument_list|()
decl_stmt|;
specifier|private
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|NavigableSet
argument_list|<
name|byte
index|[]
argument_list|>
argument_list|>
name|familyMap
init|=
operator|new
name|TreeMap
argument_list|<
name|byte
index|[]
argument_list|,
name|NavigableSet
argument_list|<
name|byte
index|[]
argument_list|>
argument_list|>
argument_list|(
name|Bytes
operator|.
name|BYTES_COMPARATOR
argument_list|)
decl_stmt|;
specifier|private
name|Boolean
name|asyncPrefetch
init|=
literal|null
decl_stmt|;
comment|/**    * Parameter name for client scanner sync/async prefetch toggle.    * When using async scanner, prefetching data from the server is done at the background.    * The parameter currently won't have any effect in the case that the user has set    * Scan#setSmall or Scan#setReversed    */
specifier|public
specifier|static
specifier|final
name|String
name|HBASE_CLIENT_SCANNER_ASYNC_PREFETCH
init|=
literal|"hbase.client.scanner.async.prefetch"
decl_stmt|;
comment|/**    * Default value of {@link #HBASE_CLIENT_SCANNER_ASYNC_PREFETCH}.    */
specifier|public
specifier|static
specifier|final
name|boolean
name|DEFAULT_HBASE_CLIENT_SCANNER_ASYNC_PREFETCH
init|=
literal|false
decl_stmt|;
comment|/**    * Set it true for small scan to get better performance Small scan should use pread and big scan    * can use seek + read seek + read is fast but can cause two problem (1) resource contention (2)    * cause too much network io [89-fb] Using pread for non-compaction read request    * https://issues.apache.org/jira/browse/HBASE-7266 On the other hand, if setting it true, we    * would do openScanner,next,closeScanner in one RPC call. It means the better performance for    * small scan. [HBASE-9488]. Generally, if the scan range is within one data block(64KB), it could    * be considered as a small scan.    */
specifier|private
name|boolean
name|small
init|=
literal|false
decl_stmt|;
comment|/**    * The mvcc read point to use when open a scanner. Remember to clear it after switching regions as    * the mvcc is only valid within region scope.    */
specifier|private
name|long
name|mvccReadPoint
init|=
operator|-
literal|1L
decl_stmt|;
comment|/**    * The number of rows we want for this scan. We will terminate the scan if the number of return    * rows reaches this value.    */
specifier|private
name|int
name|limit
init|=
operator|-
literal|1
decl_stmt|;
comment|/**    * Control whether to use pread at server side.    */
specifier|private
name|ReadType
name|readType
init|=
name|ReadType
operator|.
name|DEFAULT
decl_stmt|;
specifier|private
name|boolean
name|needCursorResult
init|=
literal|false
decl_stmt|;
comment|/**    * Create a Scan operation across all rows.    */
specifier|public
name|Scan
parameter_list|()
block|{}
comment|/**    * Create a Scan operation starting at the specified row.    *<p>    * If the specified row does not exist, the Scanner will start from the next closest row after the    * specified row.    * @param startRow row to start scanner at or after    * @deprecated since 2.0.0 and will be removed in 3.0.0. Use    *   {@code new Scan().withStartRow(startRow)} instead.    * @see<a href="https://issues.apache.org/jira/browse/HBASE-17320">HBASE-17320</a>    */
annotation|@
name|Deprecated
specifier|public
name|Scan
parameter_list|(
name|byte
index|[]
name|startRow
parameter_list|)
block|{
name|withStartRow
argument_list|(
name|startRow
argument_list|)
expr_stmt|;
block|}
comment|/**    * Create a Scan operation for the range of rows specified.    * @param startRow row to start scanner at or after (inclusive)    * @param stopRow row to stop scanner before (exclusive)    * @deprecated since 2.0.0 and will be removed in 3.0.0. Use    *   {@code new Scan().withStartRow(startRow).withStopRow(stopRow)} instead.    * @see<a href="https://issues.apache.org/jira/browse/HBASE-17320">HBASE-17320</a>    */
annotation|@
name|Deprecated
specifier|public
name|Scan
parameter_list|(
name|byte
index|[]
name|startRow
parameter_list|,
name|byte
index|[]
name|stopRow
parameter_list|)
block|{
name|withStartRow
argument_list|(
name|startRow
argument_list|)
expr_stmt|;
name|setStopRow
argument_list|(
name|stopRow
argument_list|)
expr_stmt|;
block|}
comment|/**    * Creates a new instance of this class while copying all values.    *    * @param scan  The scan instance to copy from.    * @throws IOException When copying the values fails.    */
specifier|public
name|Scan
parameter_list|(
name|Scan
name|scan
parameter_list|)
throws|throws
name|IOException
block|{
name|startRow
operator|=
name|scan
operator|.
name|getStartRow
argument_list|()
expr_stmt|;
name|includeStartRow
operator|=
name|scan
operator|.
name|includeStartRow
argument_list|()
expr_stmt|;
name|stopRow
operator|=
name|scan
operator|.
name|getStopRow
argument_list|()
expr_stmt|;
name|includeStopRow
operator|=
name|scan
operator|.
name|includeStopRow
argument_list|()
expr_stmt|;
name|maxVersions
operator|=
name|scan
operator|.
name|getMaxVersions
argument_list|()
expr_stmt|;
name|batch
operator|=
name|scan
operator|.
name|getBatch
argument_list|()
expr_stmt|;
name|storeLimit
operator|=
name|scan
operator|.
name|getMaxResultsPerColumnFamily
argument_list|()
expr_stmt|;
name|storeOffset
operator|=
name|scan
operator|.
name|getRowOffsetPerColumnFamily
argument_list|()
expr_stmt|;
name|caching
operator|=
name|scan
operator|.
name|getCaching
argument_list|()
expr_stmt|;
name|maxResultSize
operator|=
name|scan
operator|.
name|getMaxResultSize
argument_list|()
expr_stmt|;
name|cacheBlocks
operator|=
name|scan
operator|.
name|getCacheBlocks
argument_list|()
expr_stmt|;
name|filter
operator|=
name|scan
operator|.
name|getFilter
argument_list|()
expr_stmt|;
comment|// clone?
name|loadColumnFamiliesOnDemand
operator|=
name|scan
operator|.
name|getLoadColumnFamiliesOnDemandValue
argument_list|()
expr_stmt|;
name|consistency
operator|=
name|scan
operator|.
name|getConsistency
argument_list|()
expr_stmt|;
name|this
operator|.
name|setIsolationLevel
argument_list|(
name|scan
operator|.
name|getIsolationLevel
argument_list|()
argument_list|)
expr_stmt|;
name|reversed
operator|=
name|scan
operator|.
name|isReversed
argument_list|()
expr_stmt|;
name|asyncPrefetch
operator|=
name|scan
operator|.
name|isAsyncPrefetch
argument_list|()
expr_stmt|;
name|small
operator|=
name|scan
operator|.
name|isSmall
argument_list|()
expr_stmt|;
name|allowPartialResults
operator|=
name|scan
operator|.
name|getAllowPartialResults
argument_list|()
expr_stmt|;
name|tr
operator|=
name|scan
operator|.
name|getTimeRange
argument_list|()
expr_stmt|;
comment|// TimeRange is immutable
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|NavigableSet
argument_list|<
name|byte
index|[]
argument_list|>
argument_list|>
name|fams
init|=
name|scan
operator|.
name|getFamilyMap
argument_list|()
decl_stmt|;
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|byte
index|[]
argument_list|,
name|NavigableSet
argument_list|<
name|byte
index|[]
argument_list|>
argument_list|>
name|entry
range|:
name|fams
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|byte
index|[]
name|fam
init|=
name|entry
operator|.
name|getKey
argument_list|()
decl_stmt|;
name|NavigableSet
argument_list|<
name|byte
index|[]
argument_list|>
name|cols
init|=
name|entry
operator|.
name|getValue
argument_list|()
decl_stmt|;
if|if
condition|(
name|cols
operator|!=
literal|null
operator|&&
name|cols
operator|.
name|size
argument_list|()
operator|>
literal|0
condition|)
block|{
for|for
control|(
name|byte
index|[]
name|col
range|:
name|cols
control|)
block|{
name|addColumn
argument_list|(
name|fam
argument_list|,
name|col
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
name|addFamily
argument_list|(
name|fam
argument_list|)
expr_stmt|;
block|}
block|}
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|String
argument_list|,
name|byte
index|[]
argument_list|>
name|attr
range|:
name|scan
operator|.
name|getAttributesMap
argument_list|()
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|setAttribute
argument_list|(
name|attr
operator|.
name|getKey
argument_list|()
argument_list|,
name|attr
operator|.
name|getValue
argument_list|()
argument_list|)
expr_stmt|;
block|}
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|byte
index|[]
argument_list|,
name|TimeRange
argument_list|>
name|entry
range|:
name|scan
operator|.
name|getColumnFamilyTimeRange
argument_list|()
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|TimeRange
name|tr
init|=
name|entry
operator|.
name|getValue
argument_list|()
decl_stmt|;
name|setColumnFamilyTimeRange
argument_list|(
name|entry
operator|.
name|getKey
argument_list|()
argument_list|,
name|tr
operator|.
name|getMin
argument_list|()
argument_list|,
name|tr
operator|.
name|getMax
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|this
operator|.
name|mvccReadPoint
operator|=
name|scan
operator|.
name|getMvccReadPoint
argument_list|()
expr_stmt|;
name|this
operator|.
name|limit
operator|=
name|scan
operator|.
name|getLimit
argument_list|()
expr_stmt|;
name|this
operator|.
name|needCursorResult
operator|=
name|scan
operator|.
name|isNeedCursorResult
argument_list|()
expr_stmt|;
name|setPriority
argument_list|(
name|scan
operator|.
name|getPriority
argument_list|()
argument_list|)
expr_stmt|;
name|readType
operator|=
name|scan
operator|.
name|getReadType
argument_list|()
expr_stmt|;
name|super
operator|.
name|setReplicaId
argument_list|(
name|scan
operator|.
name|getReplicaId
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|/**    * Builds a scan object with the same specs as get.    * @param get get to model scan after    */
specifier|public
name|Scan
parameter_list|(
name|Get
name|get
parameter_list|)
block|{
name|this
operator|.
name|startRow
operator|=
name|get
operator|.
name|getRow
argument_list|()
expr_stmt|;
name|this
operator|.
name|includeStartRow
operator|=
literal|true
expr_stmt|;
name|this
operator|.
name|stopRow
operator|=
name|get
operator|.
name|getRow
argument_list|()
expr_stmt|;
name|this
operator|.
name|includeStopRow
operator|=
literal|true
expr_stmt|;
name|this
operator|.
name|filter
operator|=
name|get
operator|.
name|getFilter
argument_list|()
expr_stmt|;
name|this
operator|.
name|cacheBlocks
operator|=
name|get
operator|.
name|getCacheBlocks
argument_list|()
expr_stmt|;
name|this
operator|.
name|maxVersions
operator|=
name|get
operator|.
name|getMaxVersions
argument_list|()
expr_stmt|;
name|this
operator|.
name|storeLimit
operator|=
name|get
operator|.
name|getMaxResultsPerColumnFamily
argument_list|()
expr_stmt|;
name|this
operator|.
name|storeOffset
operator|=
name|get
operator|.
name|getRowOffsetPerColumnFamily
argument_list|()
expr_stmt|;
name|this
operator|.
name|tr
operator|=
name|get
operator|.
name|getTimeRange
argument_list|()
expr_stmt|;
name|this
operator|.
name|familyMap
operator|=
name|get
operator|.
name|getFamilyMap
argument_list|()
expr_stmt|;
name|this
operator|.
name|asyncPrefetch
operator|=
literal|false
expr_stmt|;
name|this
operator|.
name|consistency
operator|=
name|get
operator|.
name|getConsistency
argument_list|()
expr_stmt|;
name|this
operator|.
name|setIsolationLevel
argument_list|(
name|get
operator|.
name|getIsolationLevel
argument_list|()
argument_list|)
expr_stmt|;
name|this
operator|.
name|loadColumnFamiliesOnDemand
operator|=
name|get
operator|.
name|getLoadColumnFamiliesOnDemandValue
argument_list|()
expr_stmt|;
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|String
argument_list|,
name|byte
index|[]
argument_list|>
name|attr
range|:
name|get
operator|.
name|getAttributesMap
argument_list|()
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|setAttribute
argument_list|(
name|attr
operator|.
name|getKey
argument_list|()
argument_list|,
name|attr
operator|.
name|getValue
argument_list|()
argument_list|)
expr_stmt|;
block|}
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|byte
index|[]
argument_list|,
name|TimeRange
argument_list|>
name|entry
range|:
name|get
operator|.
name|getColumnFamilyTimeRange
argument_list|()
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|TimeRange
name|tr
init|=
name|entry
operator|.
name|getValue
argument_list|()
decl_stmt|;
name|setColumnFamilyTimeRange
argument_list|(
name|entry
operator|.
name|getKey
argument_list|()
argument_list|,
name|tr
operator|.
name|getMin
argument_list|()
argument_list|,
name|tr
operator|.
name|getMax
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|this
operator|.
name|mvccReadPoint
operator|=
operator|-
literal|1L
expr_stmt|;
name|setPriority
argument_list|(
name|get
operator|.
name|getPriority
argument_list|()
argument_list|)
expr_stmt|;
name|super
operator|.
name|setReplicaId
argument_list|(
name|get
operator|.
name|getReplicaId
argument_list|()
argument_list|)
expr_stmt|;
block|}
specifier|public
name|boolean
name|isGetScan
parameter_list|()
block|{
return|return
name|includeStartRow
operator|&&
name|includeStopRow
operator|&&
name|ClientUtil
operator|.
name|areScanStartRowAndStopRowEqual
argument_list|(
name|this
operator|.
name|startRow
argument_list|,
name|this
operator|.
name|stopRow
argument_list|)
return|;
block|}
comment|/**    * Get all columns from the specified family.    *<p>    * Overrides previous calls to addColumn for this family.    * @param family family name    * @return this    */
specifier|public
name|Scan
name|addFamily
parameter_list|(
name|byte
index|[]
name|family
parameter_list|)
block|{
name|familyMap
operator|.
name|remove
argument_list|(
name|family
argument_list|)
expr_stmt|;
name|familyMap
operator|.
name|put
argument_list|(
name|family
argument_list|,
literal|null
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**    * Get the column from the specified family with the specified qualifier.    *<p>    * Overrides previous calls to addFamily for this family.    * @param family family name    * @param qualifier column qualifier    * @return this    */
specifier|public
name|Scan
name|addColumn
parameter_list|(
name|byte
index|[]
name|family
parameter_list|,
name|byte
index|[]
name|qualifier
parameter_list|)
block|{
name|NavigableSet
argument_list|<
name|byte
index|[]
argument_list|>
name|set
init|=
name|familyMap
operator|.
name|get
argument_list|(
name|family
argument_list|)
decl_stmt|;
if|if
condition|(
name|set
operator|==
literal|null
condition|)
block|{
name|set
operator|=
operator|new
name|TreeSet
argument_list|<>
argument_list|(
name|Bytes
operator|.
name|BYTES_COMPARATOR
argument_list|)
expr_stmt|;
name|familyMap
operator|.
name|put
argument_list|(
name|family
argument_list|,
name|set
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|qualifier
operator|==
literal|null
condition|)
block|{
name|qualifier
operator|=
name|HConstants
operator|.
name|EMPTY_BYTE_ARRAY
expr_stmt|;
block|}
name|set
operator|.
name|add
argument_list|(
name|qualifier
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**    * Get versions of columns only within the specified timestamp range,    * [minStamp, maxStamp).  Note, default maximum versions to return is 1.  If    * your time range spans more than one version and you want all versions    * returned, up the number of versions beyond the default.    * @param minStamp minimum timestamp value, inclusive    * @param maxStamp maximum timestamp value, exclusive    * @see #setMaxVersions()    * @see #setMaxVersions(int)    * @return this    */
specifier|public
name|Scan
name|setTimeRange
parameter_list|(
name|long
name|minStamp
parameter_list|,
name|long
name|maxStamp
parameter_list|)
throws|throws
name|IOException
block|{
name|tr
operator|=
operator|new
name|TimeRange
argument_list|(
name|minStamp
argument_list|,
name|maxStamp
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**    * Get versions of columns with the specified timestamp. Note, default maximum    * versions to return is 1.  If your time range spans more than one version    * and you want all versions returned, up the number of versions beyond the    * defaut.    * @param timestamp version timestamp    * @see #setMaxVersions()    * @see #setMaxVersions(int)    * @return this    * @deprecated As of release 2.0.0, this will be removed in HBase 3.0.0.    *             Use {@link #setTimestamp(long)} instead    */
annotation|@
name|Deprecated
specifier|public
name|Scan
name|setTimeStamp
parameter_list|(
name|long
name|timestamp
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|this
operator|.
name|setTimestamp
argument_list|(
name|timestamp
argument_list|)
return|;
block|}
comment|/**    * Get versions of columns with the specified timestamp. Note, default maximum    * versions to return is 1.  If your time range spans more than one version    * and you want all versions returned, up the number of versions beyond the    * defaut.    * @param timestamp version timestamp    * @see #setMaxVersions()    * @see #setMaxVersions(int)    * @return this    */
specifier|public
name|Scan
name|setTimestamp
parameter_list|(
name|long
name|timestamp
parameter_list|)
block|{
try|try
block|{
name|tr
operator|=
operator|new
name|TimeRange
argument_list|(
name|timestamp
argument_list|,
name|timestamp
operator|+
literal|1
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
comment|// This should never happen, unless integer overflow or something extremely wrong...
name|LOG
operator|.
name|error
argument_list|(
literal|"TimeRange failed, likely caused by integer overflow. "
argument_list|,
name|e
argument_list|)
expr_stmt|;
throw|throw
name|e
throw|;
block|}
return|return
name|this
return|;
block|}
annotation|@
name|Override
specifier|public
name|Scan
name|setColumnFamilyTimeRange
parameter_list|(
name|byte
index|[]
name|cf
parameter_list|,
name|long
name|minStamp
parameter_list|,
name|long
name|maxStamp
parameter_list|)
block|{
return|return
operator|(
name|Scan
operator|)
name|super
operator|.
name|setColumnFamilyTimeRange
argument_list|(
name|cf
argument_list|,
name|minStamp
argument_list|,
name|maxStamp
argument_list|)
return|;
block|}
comment|/**    * Set the start row of the scan.    *<p>    * If the specified row does not exist, the Scanner will start from the next closest row after the    * specified row.    * @param startRow row to start scanner at or after    * @return this    * @throws IllegalArgumentException if startRow does not meet criteria for a row key (when length    *           exceeds {@link HConstants#MAX_ROW_LENGTH})    */
specifier|public
name|Scan
name|withStartRow
parameter_list|(
name|byte
index|[]
name|startRow
parameter_list|)
block|{
return|return
name|withStartRow
argument_list|(
name|startRow
argument_list|,
literal|true
argument_list|)
return|;
block|}
comment|/**    * Set the start row of the scan.    *<p>    * If the specified row does not exist, or the {@code inclusive} is {@code false}, the Scanner    * will start from the next closest row after the specified row.    * @param startRow row to start scanner at or after    * @param inclusive whether we should include the start row when scan    * @return this    * @throws IllegalArgumentException if startRow does not meet criteria for a row key (when length    *           exceeds {@link HConstants#MAX_ROW_LENGTH})    */
specifier|public
name|Scan
name|withStartRow
parameter_list|(
name|byte
index|[]
name|startRow
parameter_list|,
name|boolean
name|inclusive
parameter_list|)
block|{
if|if
condition|(
name|Bytes
operator|.
name|len
argument_list|(
name|startRow
argument_list|)
operator|>
name|HConstants
operator|.
name|MAX_ROW_LENGTH
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"startRow's length must be less than or equal to "
operator|+
name|HConstants
operator|.
name|MAX_ROW_LENGTH
operator|+
literal|" to meet the criteria"
operator|+
literal|" for a row key."
argument_list|)
throw|;
block|}
name|this
operator|.
name|startRow
operator|=
name|startRow
expr_stmt|;
name|this
operator|.
name|includeStartRow
operator|=
name|inclusive
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**    * Set the stop row of the scan.    *<p>    * The scan will include rows that are lexicographically less than the provided stopRow.    *<p>    *<b>Note:</b> When doing a filter for a rowKey<u>Prefix</u> use    * {@link #setRowPrefixFilter(byte[])}. The 'trailing 0' will not yield the desired result.    *</p>    * @param stopRow row to end at (exclusive)    * @return this    * @throws IllegalArgumentException if stopRow does not meet criteria for a row key (when length    *           exceeds {@link HConstants#MAX_ROW_LENGTH})    * @deprecated since 2.0.0 and will be removed in 3.0.0. Use {@link #withStopRow(byte[])} instead.    *   This method may change the inclusive of the stop row to keep compatible with the old    *   behavior.    * @see #withStopRow(byte[])    * @see<a href="https://issues.apache.org/jira/browse/HBASE-17320">HBASE-17320</a>    */
annotation|@
name|Deprecated
specifier|public
name|Scan
name|setStopRow
parameter_list|(
name|byte
index|[]
name|stopRow
parameter_list|)
block|{
name|withStopRow
argument_list|(
name|stopRow
argument_list|)
expr_stmt|;
if|if
condition|(
name|ClientUtil
operator|.
name|areScanStartRowAndStopRowEqual
argument_list|(
name|this
operator|.
name|startRow
argument_list|,
name|this
operator|.
name|stopRow
argument_list|)
condition|)
block|{
comment|// for keeping the old behavior that a scan with the same start and stop row is a get scan.
name|this
operator|.
name|includeStopRow
operator|=
literal|true
expr_stmt|;
block|}
return|return
name|this
return|;
block|}
comment|/**    * Set the stop row of the scan.    *<p>    * The scan will include rows that are lexicographically less than the provided stopRow.    *<p>    *<b>Note:</b> When doing a filter for a rowKey<u>Prefix</u> use    * {@link #setRowPrefixFilter(byte[])}. The 'trailing 0' will not yield the desired result.    *</p>    * @param stopRow row to end at (exclusive)    * @return this    * @throws IllegalArgumentException if stopRow does not meet criteria for a row key (when length    *           exceeds {@link HConstants#MAX_ROW_LENGTH})    */
specifier|public
name|Scan
name|withStopRow
parameter_list|(
name|byte
index|[]
name|stopRow
parameter_list|)
block|{
return|return
name|withStopRow
argument_list|(
name|stopRow
argument_list|,
literal|false
argument_list|)
return|;
block|}
comment|/**    * Set the stop row of the scan.    *<p>    * The scan will include rows that are lexicographically less than (or equal to if    * {@code inclusive} is {@code true}) the provided stopRow.    * @param stopRow row to end at    * @param inclusive whether we should include the stop row when scan    * @return this    * @throws IllegalArgumentException if stopRow does not meet criteria for a row key (when length    *           exceeds {@link HConstants#MAX_ROW_LENGTH})    */
specifier|public
name|Scan
name|withStopRow
parameter_list|(
name|byte
index|[]
name|stopRow
parameter_list|,
name|boolean
name|inclusive
parameter_list|)
block|{
if|if
condition|(
name|Bytes
operator|.
name|len
argument_list|(
name|stopRow
argument_list|)
operator|>
name|HConstants
operator|.
name|MAX_ROW_LENGTH
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"stopRow's length must be less than or equal to "
operator|+
name|HConstants
operator|.
name|MAX_ROW_LENGTH
operator|+
literal|" to meet the criteria"
operator|+
literal|" for a row key."
argument_list|)
throw|;
block|}
name|this
operator|.
name|stopRow
operator|=
name|stopRow
expr_stmt|;
name|this
operator|.
name|includeStopRow
operator|=
name|inclusive
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**    *<p>Set a filter (using stopRow and startRow) so the result set only contains rows where the    * rowKey starts with the specified prefix.</p>    *<p>This is a utility method that converts the desired rowPrefix into the appropriate values    * for the startRow and stopRow to achieve the desired result.</p>    *<p>This can safely be used in combination with setFilter.</p>    *<p><b>NOTE: Doing a {@link #withStartRow(byte[])} and/or {@link #setStopRow(byte[])}    * after this method will yield undefined results.</b></p>    * @param rowPrefix the prefix all rows must start with. (Set<i>null</i> to remove the filter.)    * @return this    */
specifier|public
name|Scan
name|setRowPrefixFilter
parameter_list|(
name|byte
index|[]
name|rowPrefix
parameter_list|)
block|{
if|if
condition|(
name|rowPrefix
operator|==
literal|null
condition|)
block|{
name|withStartRow
argument_list|(
name|HConstants
operator|.
name|EMPTY_START_ROW
argument_list|)
expr_stmt|;
name|setStopRow
argument_list|(
name|HConstants
operator|.
name|EMPTY_END_ROW
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|this
operator|.
name|withStartRow
argument_list|(
name|rowPrefix
argument_list|)
expr_stmt|;
name|this
operator|.
name|setStopRow
argument_list|(
name|ClientUtil
operator|.
name|calculateTheClosestNextRowKeyForPrefix
argument_list|(
name|rowPrefix
argument_list|)
argument_list|)
expr_stmt|;
block|}
return|return
name|this
return|;
block|}
comment|/**    * Get all available versions.    * @return this    * @deprecated since 2.0.0 and will be removed in 3.0.0. It is easy to misunderstand with column    *   family's max versions, so use {@link #readAllVersions()} instead.    * @see #readAllVersions()    * @see<a href="https://issues.apache.org/jira/browse/HBASE-17125">HBASE-17125</a>    */
annotation|@
name|Deprecated
specifier|public
name|Scan
name|setMaxVersions
parameter_list|()
block|{
return|return
name|readAllVersions
argument_list|()
return|;
block|}
comment|/**    * Get up to the specified number of versions of each column.    * @param maxVersions maximum versions for each column    * @return this    * @deprecated since 2.0.0 and will be removed in 3.0.0. It is easy to misunderstand with column    *   family's max versions, so use {@link #readVersions(int)} instead.    * @see #readVersions(int)    * @see<a href="https://issues.apache.org/jira/browse/HBASE-17125">HBASE-17125</a>    */
annotation|@
name|Deprecated
specifier|public
name|Scan
name|setMaxVersions
parameter_list|(
name|int
name|maxVersions
parameter_list|)
block|{
return|return
name|readVersions
argument_list|(
name|maxVersions
argument_list|)
return|;
block|}
comment|/**    * Get all available versions.    * @return this    */
specifier|public
name|Scan
name|readAllVersions
parameter_list|()
block|{
name|this
operator|.
name|maxVersions
operator|=
name|Integer
operator|.
name|MAX_VALUE
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**    * Get up to the specified number of versions of each column.    * @param versions specified number of versions for each column    * @return this    */
specifier|public
name|Scan
name|readVersions
parameter_list|(
name|int
name|versions
parameter_list|)
block|{
name|this
operator|.
name|maxVersions
operator|=
name|versions
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**    * Set the maximum number of cells to return for each call to next(). Callers should be aware    * that this is not equivalent to calling {@link #setAllowPartialResults(boolean)}.    * If you don't allow partial results, the number of cells in each Result must equal to your    * batch setting unless it is the last Result for current row. So this method is helpful in paging    * queries. If you just want to prevent OOM at client, use setAllowPartialResults(true) is better.    * @param batch the maximum number of values    * @see Result#mayHaveMoreCellsInRow()    */
specifier|public
name|Scan
name|setBatch
parameter_list|(
name|int
name|batch
parameter_list|)
block|{
if|if
condition|(
name|this
operator|.
name|hasFilter
argument_list|()
operator|&&
name|this
operator|.
name|filter
operator|.
name|hasFilterRow
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|IncompatibleFilterException
argument_list|(
literal|"Cannot set batch on a scan using a filter"
operator|+
literal|" that returns true for filter.hasFilterRow"
argument_list|)
throw|;
block|}
name|this
operator|.
name|batch
operator|=
name|batch
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**    * Set the maximum number of values to return per row per Column Family    * @param limit the maximum number of values returned / row / CF    */
specifier|public
name|Scan
name|setMaxResultsPerColumnFamily
parameter_list|(
name|int
name|limit
parameter_list|)
block|{
name|this
operator|.
name|storeLimit
operator|=
name|limit
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**    * Set offset for the row per Column Family.    * @param offset is the number of kvs that will be skipped.    */
specifier|public
name|Scan
name|setRowOffsetPerColumnFamily
parameter_list|(
name|int
name|offset
parameter_list|)
block|{
name|this
operator|.
name|storeOffset
operator|=
name|offset
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**    * Set the number of rows for caching that will be passed to scanners.    * If not set, the Configuration setting {@link HConstants#HBASE_CLIENT_SCANNER_CACHING} will    * apply.    * Higher caching values will enable faster scanners but will use more memory.    * @param caching the number of rows for caching    */
specifier|public
name|Scan
name|setCaching
parameter_list|(
name|int
name|caching
parameter_list|)
block|{
name|this
operator|.
name|caching
operator|=
name|caching
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**    * @return the maximum result size in bytes. See {@link #setMaxResultSize(long)}    */
specifier|public
name|long
name|getMaxResultSize
parameter_list|()
block|{
return|return
name|maxResultSize
return|;
block|}
comment|/**    * Set the maximum result size. The default is -1; this means that no specific    * maximum result size will be set for this scan, and the global configured    * value will be used instead. (Defaults to unlimited).    *    * @param maxResultSize The maximum result size in bytes.    */
specifier|public
name|Scan
name|setMaxResultSize
parameter_list|(
name|long
name|maxResultSize
parameter_list|)
block|{
name|this
operator|.
name|maxResultSize
operator|=
name|maxResultSize
expr_stmt|;
return|return
name|this
return|;
block|}
annotation|@
name|Override
specifier|public
name|Scan
name|setFilter
parameter_list|(
name|Filter
name|filter
parameter_list|)
block|{
name|super
operator|.
name|setFilter
argument_list|(
name|filter
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**    * Setting the familyMap    * @param familyMap map of family to qualifier    * @return this    */
specifier|public
name|Scan
name|setFamilyMap
parameter_list|(
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|NavigableSet
argument_list|<
name|byte
index|[]
argument_list|>
argument_list|>
name|familyMap
parameter_list|)
block|{
name|this
operator|.
name|familyMap
operator|=
name|familyMap
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**    * Getting the familyMap    * @return familyMap    */
specifier|public
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|NavigableSet
argument_list|<
name|byte
index|[]
argument_list|>
argument_list|>
name|getFamilyMap
parameter_list|()
block|{
return|return
name|this
operator|.
name|familyMap
return|;
block|}
comment|/**    * @return the number of families in familyMap    */
specifier|public
name|int
name|numFamilies
parameter_list|()
block|{
if|if
condition|(
name|hasFamilies
argument_list|()
condition|)
block|{
return|return
name|this
operator|.
name|familyMap
operator|.
name|size
argument_list|()
return|;
block|}
return|return
literal|0
return|;
block|}
comment|/**    * @return true if familyMap is non empty, false otherwise    */
specifier|public
name|boolean
name|hasFamilies
parameter_list|()
block|{
return|return
operator|!
name|this
operator|.
name|familyMap
operator|.
name|isEmpty
argument_list|()
return|;
block|}
comment|/**    * @return the keys of the familyMap    */
specifier|public
name|byte
index|[]
index|[]
name|getFamilies
parameter_list|()
block|{
if|if
condition|(
name|hasFamilies
argument_list|()
condition|)
block|{
return|return
name|this
operator|.
name|familyMap
operator|.
name|keySet
argument_list|()
operator|.
name|toArray
argument_list|(
operator|new
name|byte
index|[
literal|0
index|]
index|[
literal|0
index|]
argument_list|)
return|;
block|}
return|return
literal|null
return|;
block|}
comment|/**    * @return the startrow    */
specifier|public
name|byte
index|[]
name|getStartRow
parameter_list|()
block|{
return|return
name|this
operator|.
name|startRow
return|;
block|}
comment|/**    * @return if we should include start row when scan    */
specifier|public
name|boolean
name|includeStartRow
parameter_list|()
block|{
return|return
name|includeStartRow
return|;
block|}
comment|/**    * @return the stoprow    */
specifier|public
name|byte
index|[]
name|getStopRow
parameter_list|()
block|{
return|return
name|this
operator|.
name|stopRow
return|;
block|}
comment|/**    * @return if we should include stop row when scan    */
specifier|public
name|boolean
name|includeStopRow
parameter_list|()
block|{
return|return
name|includeStopRow
return|;
block|}
comment|/**    * @return the max number of versions to fetch    */
specifier|public
name|int
name|getMaxVersions
parameter_list|()
block|{
return|return
name|this
operator|.
name|maxVersions
return|;
block|}
comment|/**    * @return maximum number of values to return for a single call to next()    */
specifier|public
name|int
name|getBatch
parameter_list|()
block|{
return|return
name|this
operator|.
name|batch
return|;
block|}
comment|/**    * @return maximum number of values to return per row per CF    */
specifier|public
name|int
name|getMaxResultsPerColumnFamily
parameter_list|()
block|{
return|return
name|this
operator|.
name|storeLimit
return|;
block|}
comment|/**    * Method for retrieving the scan's offset per row per column    * family (#kvs to be skipped)    * @return row offset    */
specifier|public
name|int
name|getRowOffsetPerColumnFamily
parameter_list|()
block|{
return|return
name|this
operator|.
name|storeOffset
return|;
block|}
comment|/**    * @return caching the number of rows fetched when calling next on a scanner    */
specifier|public
name|int
name|getCaching
parameter_list|()
block|{
return|return
name|this
operator|.
name|caching
return|;
block|}
comment|/**    * @return TimeRange    */
specifier|public
name|TimeRange
name|getTimeRange
parameter_list|()
block|{
return|return
name|this
operator|.
name|tr
return|;
block|}
comment|/**    * @return RowFilter    */
annotation|@
name|Override
specifier|public
name|Filter
name|getFilter
parameter_list|()
block|{
return|return
name|filter
return|;
block|}
comment|/**    * @return true is a filter has been specified, false if not    */
specifier|public
name|boolean
name|hasFilter
parameter_list|()
block|{
return|return
name|filter
operator|!=
literal|null
return|;
block|}
comment|/**    * Set whether blocks should be cached for this Scan.    *<p>    * This is true by default.  When true, default settings of the table and    * family are used (this will never override caching blocks if the block    * cache is disabled for that family or entirely).    *    * @param cacheBlocks if false, default settings are overridden and blocks    * will not be cached    */
specifier|public
name|Scan
name|setCacheBlocks
parameter_list|(
name|boolean
name|cacheBlocks
parameter_list|)
block|{
name|this
operator|.
name|cacheBlocks
operator|=
name|cacheBlocks
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**    * Get whether blocks should be cached for this Scan.    * @return true if default caching should be used, false if blocks should not    * be cached    */
specifier|public
name|boolean
name|getCacheBlocks
parameter_list|()
block|{
return|return
name|cacheBlocks
return|;
block|}
comment|/**    * Set whether this scan is a reversed one    *<p>    * This is false by default which means forward(normal) scan.    *    * @param reversed if true, scan will be backward order    * @return this    */
specifier|public
name|Scan
name|setReversed
parameter_list|(
name|boolean
name|reversed
parameter_list|)
block|{
name|this
operator|.
name|reversed
operator|=
name|reversed
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**    * Get whether this scan is a reversed one.    * @return true if backward scan, false if forward(default) scan    */
specifier|public
name|boolean
name|isReversed
parameter_list|()
block|{
return|return
name|reversed
return|;
block|}
comment|/**    * Setting whether the caller wants to see the partial results when server returns    * less-than-expected cells. It is helpful while scanning a huge row to prevent OOM at client.    * By default this value is false and the complete results will be assembled client side    * before being delivered to the caller.    * @param allowPartialResults    * @return this    * @see Result#mayHaveMoreCellsInRow()    * @see #setBatch(int)    */
specifier|public
name|Scan
name|setAllowPartialResults
parameter_list|(
specifier|final
name|boolean
name|allowPartialResults
parameter_list|)
block|{
name|this
operator|.
name|allowPartialResults
operator|=
name|allowPartialResults
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**    * @return true when the constructor of this scan understands that the results they will see may    *         only represent a partial portion of a row. The entire row would be retrieved by    *         subsequent calls to {@link ResultScanner#next()}    */
specifier|public
name|boolean
name|getAllowPartialResults
parameter_list|()
block|{
return|return
name|allowPartialResults
return|;
block|}
annotation|@
name|Override
specifier|public
name|Scan
name|setLoadColumnFamiliesOnDemand
parameter_list|(
name|boolean
name|value
parameter_list|)
block|{
return|return
operator|(
name|Scan
operator|)
name|super
operator|.
name|setLoadColumnFamiliesOnDemand
argument_list|(
name|value
argument_list|)
return|;
block|}
comment|/**    * Compile the table and column family (i.e. schema) information    * into a String. Useful for parsing and aggregation by debugging,    * logging, and administration tools.    * @return Map    */
annotation|@
name|Override
specifier|public
name|Map
argument_list|<
name|String
argument_list|,
name|Object
argument_list|>
name|getFingerprint
parameter_list|()
block|{
name|Map
argument_list|<
name|String
argument_list|,
name|Object
argument_list|>
name|map
init|=
operator|new
name|HashMap
argument_list|<>
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|String
argument_list|>
name|families
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
if|if
condition|(
name|this
operator|.
name|familyMap
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|map
operator|.
name|put
argument_list|(
literal|"families"
argument_list|,
literal|"ALL"
argument_list|)
expr_stmt|;
return|return
name|map
return|;
block|}
else|else
block|{
name|map
operator|.
name|put
argument_list|(
literal|"families"
argument_list|,
name|families
argument_list|)
expr_stmt|;
block|}
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|byte
index|[]
argument_list|,
name|NavigableSet
argument_list|<
name|byte
index|[]
argument_list|>
argument_list|>
name|entry
range|:
name|this
operator|.
name|familyMap
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|families
operator|.
name|add
argument_list|(
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|entry
operator|.
name|getKey
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
return|return
name|map
return|;
block|}
comment|/**    * Compile the details beyond the scope of getFingerprint (row, columns,    * timestamps, etc.) into a Map along with the fingerprinted information.    * Useful for debugging, logging, and administration tools.    * @param maxCols a limit on the number of columns output prior to truncation    * @return Map    */
annotation|@
name|Override
specifier|public
name|Map
argument_list|<
name|String
argument_list|,
name|Object
argument_list|>
name|toMap
parameter_list|(
name|int
name|maxCols
parameter_list|)
block|{
comment|// start with the fingerpring map and build on top of it
name|Map
argument_list|<
name|String
argument_list|,
name|Object
argument_list|>
name|map
init|=
name|getFingerprint
argument_list|()
decl_stmt|;
comment|// map from families to column list replaces fingerprint's list of families
name|Map
argument_list|<
name|String
argument_list|,
name|List
argument_list|<
name|String
argument_list|>
argument_list|>
name|familyColumns
init|=
operator|new
name|HashMap
argument_list|<>
argument_list|()
decl_stmt|;
name|map
operator|.
name|put
argument_list|(
literal|"families"
argument_list|,
name|familyColumns
argument_list|)
expr_stmt|;
comment|// add scalar information first
name|map
operator|.
name|put
argument_list|(
literal|"startRow"
argument_list|,
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|this
operator|.
name|startRow
argument_list|)
argument_list|)
expr_stmt|;
name|map
operator|.
name|put
argument_list|(
literal|"stopRow"
argument_list|,
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|this
operator|.
name|stopRow
argument_list|)
argument_list|)
expr_stmt|;
name|map
operator|.
name|put
argument_list|(
literal|"maxVersions"
argument_list|,
name|this
operator|.
name|maxVersions
argument_list|)
expr_stmt|;
name|map
operator|.
name|put
argument_list|(
literal|"batch"
argument_list|,
name|this
operator|.
name|batch
argument_list|)
expr_stmt|;
name|map
operator|.
name|put
argument_list|(
literal|"caching"
argument_list|,
name|this
operator|.
name|caching
argument_list|)
expr_stmt|;
name|map
operator|.
name|put
argument_list|(
literal|"maxResultSize"
argument_list|,
name|this
operator|.
name|maxResultSize
argument_list|)
expr_stmt|;
name|map
operator|.
name|put
argument_list|(
literal|"cacheBlocks"
argument_list|,
name|this
operator|.
name|cacheBlocks
argument_list|)
expr_stmt|;
name|map
operator|.
name|put
argument_list|(
literal|"loadColumnFamiliesOnDemand"
argument_list|,
name|this
operator|.
name|loadColumnFamiliesOnDemand
argument_list|)
expr_stmt|;
name|List
argument_list|<
name|Long
argument_list|>
name|timeRange
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
literal|2
argument_list|)
decl_stmt|;
name|timeRange
operator|.
name|add
argument_list|(
name|this
operator|.
name|tr
operator|.
name|getMin
argument_list|()
argument_list|)
expr_stmt|;
name|timeRange
operator|.
name|add
argument_list|(
name|this
operator|.
name|tr
operator|.
name|getMax
argument_list|()
argument_list|)
expr_stmt|;
name|map
operator|.
name|put
argument_list|(
literal|"timeRange"
argument_list|,
name|timeRange
argument_list|)
expr_stmt|;
name|int
name|colCount
init|=
literal|0
decl_stmt|;
comment|// iterate through affected families and list out up to maxCols columns
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|byte
index|[]
argument_list|,
name|NavigableSet
argument_list|<
name|byte
index|[]
argument_list|>
argument_list|>
name|entry
range|:
name|this
operator|.
name|familyMap
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|List
argument_list|<
name|String
argument_list|>
name|columns
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
name|familyColumns
operator|.
name|put
argument_list|(
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|entry
operator|.
name|getKey
argument_list|()
argument_list|)
argument_list|,
name|columns
argument_list|)
expr_stmt|;
if|if
condition|(
name|entry
operator|.
name|getValue
argument_list|()
operator|==
literal|null
condition|)
block|{
name|colCount
operator|++
expr_stmt|;
operator|--
name|maxCols
expr_stmt|;
name|columns
operator|.
name|add
argument_list|(
literal|"ALL"
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|colCount
operator|+=
name|entry
operator|.
name|getValue
argument_list|()
operator|.
name|size
argument_list|()
expr_stmt|;
if|if
condition|(
name|maxCols
operator|<=
literal|0
condition|)
block|{
continue|continue;
block|}
for|for
control|(
name|byte
index|[]
name|column
range|:
name|entry
operator|.
name|getValue
argument_list|()
control|)
block|{
if|if
condition|(
operator|--
name|maxCols
operator|<=
literal|0
condition|)
block|{
continue|continue;
block|}
name|columns
operator|.
name|add
argument_list|(
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|column
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
block|}
name|map
operator|.
name|put
argument_list|(
literal|"totalColumns"
argument_list|,
name|colCount
argument_list|)
expr_stmt|;
if|if
condition|(
name|this
operator|.
name|filter
operator|!=
literal|null
condition|)
block|{
name|map
operator|.
name|put
argument_list|(
literal|"filter"
argument_list|,
name|this
operator|.
name|filter
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|// add the id if set
if|if
condition|(
name|getId
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|map
operator|.
name|put
argument_list|(
literal|"id"
argument_list|,
name|getId
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
name|map
return|;
block|}
comment|/**    * Enable/disable "raw" mode for this scan.    * If "raw" is enabled the scan will return all    * delete marker and deleted rows that have not    * been collected, yet.    * This is mostly useful for Scan on column families    * that have KEEP_DELETED_ROWS enabled.    * It is an error to specify any column when "raw" is set.    * @param raw True/False to enable/disable "raw" mode.    */
specifier|public
name|Scan
name|setRaw
parameter_list|(
name|boolean
name|raw
parameter_list|)
block|{
name|setAttribute
argument_list|(
name|RAW_ATTR
argument_list|,
name|Bytes
operator|.
name|toBytes
argument_list|(
name|raw
argument_list|)
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**    * @return True if this Scan is in "raw" mode.    */
specifier|public
name|boolean
name|isRaw
parameter_list|()
block|{
name|byte
index|[]
name|attr
init|=
name|getAttribute
argument_list|(
name|RAW_ATTR
argument_list|)
decl_stmt|;
return|return
name|attr
operator|==
literal|null
condition|?
literal|false
else|:
name|Bytes
operator|.
name|toBoolean
argument_list|(
name|attr
argument_list|)
return|;
block|}
comment|/**    * Set whether this scan is a small scan    *<p>    * Small scan should use pread and big scan can use seek + read seek + read is fast but can cause    * two problem (1) resource contention (2) cause too much network io [89-fb] Using pread for    * non-compaction read request https://issues.apache.org/jira/browse/HBASE-7266 On the other hand,    * if setting it true, we would do openScanner,next,closeScanner in one RPC call. It means the    * better performance for small scan. [HBASE-9488]. Generally, if the scan range is within one    * data block(64KB), it could be considered as a small scan.    * @param small    * @deprecated since 2.0.0 and will be removed in 3.0.0. Use {@link #setLimit(int)} and    *   {@link #setReadType(ReadType)} instead. And for the one rpc optimization, now we will also    *   fetch data when openScanner, and if the number of rows reaches the limit then we will close    *   the scanner automatically which means we will fall back to one rpc.    * @see #setLimit(int)    * @see #setReadType(ReadType)    * @see<a href="https://issues.apache.org/jira/browse/HBASE-17045">HBASE-17045</a>    */
annotation|@
name|Deprecated
specifier|public
name|Scan
name|setSmall
parameter_list|(
name|boolean
name|small
parameter_list|)
block|{
name|this
operator|.
name|small
operator|=
name|small
expr_stmt|;
name|this
operator|.
name|readType
operator|=
name|ReadType
operator|.
name|PREAD
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**    * Get whether this scan is a small scan    * @return true if small scan    * @deprecated since 2.0.0 and will be removed in 3.0.0. See the comment of    *   {@link #setSmall(boolean)}    * @see<a href="https://issues.apache.org/jira/browse/HBASE-17045">HBASE-17045</a>    */
annotation|@
name|Deprecated
specifier|public
name|boolean
name|isSmall
parameter_list|()
block|{
return|return
name|small
return|;
block|}
annotation|@
name|Override
specifier|public
name|Scan
name|setAttribute
parameter_list|(
name|String
name|name
parameter_list|,
name|byte
index|[]
name|value
parameter_list|)
block|{
return|return
operator|(
name|Scan
operator|)
name|super
operator|.
name|setAttribute
argument_list|(
name|name
argument_list|,
name|value
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|Scan
name|setId
parameter_list|(
name|String
name|id
parameter_list|)
block|{
return|return
operator|(
name|Scan
operator|)
name|super
operator|.
name|setId
argument_list|(
name|id
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|Scan
name|setAuthorizations
parameter_list|(
name|Authorizations
name|authorizations
parameter_list|)
block|{
return|return
operator|(
name|Scan
operator|)
name|super
operator|.
name|setAuthorizations
argument_list|(
name|authorizations
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|Scan
name|setACL
parameter_list|(
name|Map
argument_list|<
name|String
argument_list|,
name|Permission
argument_list|>
name|perms
parameter_list|)
block|{
return|return
operator|(
name|Scan
operator|)
name|super
operator|.
name|setACL
argument_list|(
name|perms
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|Scan
name|setACL
parameter_list|(
name|String
name|user
parameter_list|,
name|Permission
name|perms
parameter_list|)
block|{
return|return
operator|(
name|Scan
operator|)
name|super
operator|.
name|setACL
argument_list|(
name|user
argument_list|,
name|perms
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|Scan
name|setConsistency
parameter_list|(
name|Consistency
name|consistency
parameter_list|)
block|{
return|return
operator|(
name|Scan
operator|)
name|super
operator|.
name|setConsistency
argument_list|(
name|consistency
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|Scan
name|setReplicaId
parameter_list|(
name|int
name|Id
parameter_list|)
block|{
return|return
operator|(
name|Scan
operator|)
name|super
operator|.
name|setReplicaId
argument_list|(
name|Id
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|Scan
name|setIsolationLevel
parameter_list|(
name|IsolationLevel
name|level
parameter_list|)
block|{
return|return
operator|(
name|Scan
operator|)
name|super
operator|.
name|setIsolationLevel
argument_list|(
name|level
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|Scan
name|setPriority
parameter_list|(
name|int
name|priority
parameter_list|)
block|{
return|return
operator|(
name|Scan
operator|)
name|super
operator|.
name|setPriority
argument_list|(
name|priority
argument_list|)
return|;
block|}
comment|/**    * Enable collection of {@link ScanMetrics}. For advanced users.    * @param enabled Set to true to enable accumulating scan metrics    */
specifier|public
name|Scan
name|setScanMetricsEnabled
parameter_list|(
specifier|final
name|boolean
name|enabled
parameter_list|)
block|{
name|setAttribute
argument_list|(
name|Scan
operator|.
name|SCAN_ATTRIBUTES_METRICS_ENABLE
argument_list|,
name|Bytes
operator|.
name|toBytes
argument_list|(
name|Boolean
operator|.
name|valueOf
argument_list|(
name|enabled
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**    * @return True if collection of scan metrics is enabled. For advanced users.    */
specifier|public
name|boolean
name|isScanMetricsEnabled
parameter_list|()
block|{
name|byte
index|[]
name|attr
init|=
name|getAttribute
argument_list|(
name|Scan
operator|.
name|SCAN_ATTRIBUTES_METRICS_ENABLE
argument_list|)
decl_stmt|;
return|return
name|attr
operator|==
literal|null
condition|?
literal|false
else|:
name|Bytes
operator|.
name|toBoolean
argument_list|(
name|attr
argument_list|)
return|;
block|}
specifier|public
name|Boolean
name|isAsyncPrefetch
parameter_list|()
block|{
return|return
name|asyncPrefetch
return|;
block|}
comment|/**    * @deprecated Since 3.0.0, will be removed in 4.0.0. After building sync client upon async    *             client, the implementation is always 'async prefetch', so this flag is useless now.    */
annotation|@
name|Deprecated
specifier|public
name|Scan
name|setAsyncPrefetch
parameter_list|(
name|boolean
name|asyncPrefetch
parameter_list|)
block|{
name|this
operator|.
name|asyncPrefetch
operator|=
name|asyncPrefetch
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**    * @return the limit of rows for this scan    */
specifier|public
name|int
name|getLimit
parameter_list|()
block|{
return|return
name|limit
return|;
block|}
comment|/**    * Set the limit of rows for this scan. We will terminate the scan if the number of returned rows    * reaches this value.    *<p>    * This condition will be tested at last, after all other conditions such as stopRow, filter, etc.    * @param limit the limit of rows for this scan    * @return this    */
specifier|public
name|Scan
name|setLimit
parameter_list|(
name|int
name|limit
parameter_list|)
block|{
name|this
operator|.
name|limit
operator|=
name|limit
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**    * Call this when you only want to get one row. It will set {@code limit} to {@code 1}, and also    * set {@code readType} to {@link ReadType#PREAD}.    * @return this    */
specifier|public
name|Scan
name|setOneRowLimit
parameter_list|()
block|{
return|return
name|setLimit
argument_list|(
literal|1
argument_list|)
operator|.
name|setReadType
argument_list|(
name|ReadType
operator|.
name|PREAD
argument_list|)
return|;
block|}
annotation|@
name|InterfaceAudience
operator|.
name|Public
specifier|public
enum|enum
name|ReadType
block|{
name|DEFAULT
block|,
name|STREAM
block|,
name|PREAD
block|}
comment|/**    * @return the read type for this scan    */
specifier|public
name|ReadType
name|getReadType
parameter_list|()
block|{
return|return
name|readType
return|;
block|}
comment|/**    * Set the read type for this scan.    *<p>    * Notice that we may choose to use pread even if you specific {@link ReadType#STREAM} here. For    * example, we will always use pread if this is a get scan.    * @return this    */
specifier|public
name|Scan
name|setReadType
parameter_list|(
name|ReadType
name|readType
parameter_list|)
block|{
name|this
operator|.
name|readType
operator|=
name|readType
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**    * Get the mvcc read point used to open a scanner.    */
name|long
name|getMvccReadPoint
parameter_list|()
block|{
return|return
name|mvccReadPoint
return|;
block|}
comment|/**    * Set the mvcc read point used to open a scanner.    */
name|Scan
name|setMvccReadPoint
parameter_list|(
name|long
name|mvccReadPoint
parameter_list|)
block|{
name|this
operator|.
name|mvccReadPoint
operator|=
name|mvccReadPoint
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**    * Set the mvcc read point to -1 which means do not use it.    */
name|Scan
name|resetMvccReadPoint
parameter_list|()
block|{
return|return
name|setMvccReadPoint
argument_list|(
operator|-
literal|1L
argument_list|)
return|;
block|}
comment|/**    * When the server is slow or we scan a table with many deleted data or we use a sparse filter,    * the server will response heartbeat to prevent timeout. However the scanner will return a Result    * only when client can do it. So if there are many heartbeats, the blocking time on    * ResultScanner#next() may be very long, which is not friendly to online services.    *    * Set this to true then you can get a special Result whose #isCursor() returns true and is not    * contains any real data. It only tells you where the server has scanned. You can call next    * to continue scanning or open a new scanner with this row key as start row whenever you want.    *    * Users can get a cursor when and only when there is a response from the server but we can not    * return a Result to users, for example, this response is a heartbeat or there are partial cells    * but users do not allow partial result.    *    * Now the cursor is in row level which means the special Result will only contains a row key.    * {@link Result#isCursor()}    * {@link Result#getCursor()}    * {@link Cursor}    */
specifier|public
name|Scan
name|setNeedCursorResult
parameter_list|(
name|boolean
name|needCursorResult
parameter_list|)
block|{
name|this
operator|.
name|needCursorResult
operator|=
name|needCursorResult
expr_stmt|;
return|return
name|this
return|;
block|}
specifier|public
name|boolean
name|isNeedCursorResult
parameter_list|()
block|{
return|return
name|needCursorResult
return|;
block|}
comment|/**    * Create a new Scan with a cursor. It only set the position information like start row key.    * The others (like cfs, stop row, limit) should still be filled in by the user.    * {@link Result#isCursor()}    * {@link Result#getCursor()}    * {@link Cursor}    */
specifier|public
specifier|static
name|Scan
name|createScanFromCursor
parameter_list|(
name|Cursor
name|cursor
parameter_list|)
block|{
return|return
operator|new
name|Scan
argument_list|()
operator|.
name|withStartRow
argument_list|(
name|cursor
operator|.
name|getRow
argument_list|()
argument_list|)
return|;
block|}
block|}
end_class

end_unit

