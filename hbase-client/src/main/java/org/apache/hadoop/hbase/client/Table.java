begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  *  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
package|;
end_package

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|protobuf
operator|.
name|Descriptors
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|protobuf
operator|.
name|Message
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|protobuf
operator|.
name|Service
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|protobuf
operator|.
name|ServiceException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|Closeable
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collections
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|TimeUnit
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|lang3
operator|.
name|NotImplementedException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|Cell
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|CompareOperator
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|TableName
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|coprocessor
operator|.
name|Batch
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|TimeRange
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|ipc
operator|.
name|CoprocessorRpcChannel
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|Bytes
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|yetus
operator|.
name|audience
operator|.
name|InterfaceAudience
import|;
end_import

begin_comment
comment|/**  * Used to communicate with a single HBase table.  * Obtain an instance from a {@link Connection} and call {@link #close()} afterwards.  *  *<p><code>Table</code> can be used to get, put, delete or scan data from a table.  * @see ConnectionFactory  * @see Connection  * @see Admin  * @see RegionLocator  * @since 0.99.0  */
end_comment

begin_interface
annotation|@
name|InterfaceAudience
operator|.
name|Public
specifier|public
interface|interface
name|Table
extends|extends
name|Closeable
block|{
comment|/**    * Gets the fully qualified table name instance of this table.    */
name|TableName
name|getName
parameter_list|()
function_decl|;
comment|/**    * Returns the {@link org.apache.hadoop.conf.Configuration} object used by this instance.    *<p>    * The reference returned is not a copy, so any change made to it will    * affect this instance.    */
name|Configuration
name|getConfiguration
parameter_list|()
function_decl|;
comment|/**    * Gets the {@link org.apache.hadoop.hbase.client.TableDescriptor table descriptor} for this table.    * @throws java.io.IOException if a remote or network exception occurs.    */
name|TableDescriptor
name|getDescriptor
parameter_list|()
throws|throws
name|IOException
function_decl|;
comment|/**    * Gets the {@link RegionLocator} for this table.    */
name|RegionLocator
name|getRegionLocator
parameter_list|()
throws|throws
name|IOException
function_decl|;
comment|/**    * Test for the existence of columns in the table, as specified by the Get.    *<p>    *    * This will return true if the Get matches one or more keys, false if not.    *<p>    *    * This is a server-side call so it prevents any data from being transfered to    * the client.    *    * @param get the Get    * @return true if the specified Get matches one or more keys, false if not    * @throws IOException e    */
specifier|default
name|boolean
name|exists
parameter_list|(
name|Get
name|get
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|exists
argument_list|(
name|Collections
operator|.
name|singletonList
argument_list|(
name|get
argument_list|)
argument_list|)
index|[
literal|0
index|]
return|;
block|}
comment|/**    * Test for the existence of columns in the table, as specified by the Gets.    *<p>    *    * This will return an array of booleans. Each value will be true if the related Get matches    * one or more keys, false if not.    *<p>    *    * This is a server-side call so it prevents any data from being transferred to    * the client.    *    * @param gets the Gets    * @return Array of boolean.  True if the specified Get matches one or more keys, false if not.    * @throws IOException e    */
specifier|default
name|boolean
index|[]
name|exists
parameter_list|(
name|List
argument_list|<
name|Get
argument_list|>
name|gets
parameter_list|)
throws|throws
name|IOException
block|{
throw|throw
operator|new
name|NotImplementedException
argument_list|(
literal|"Add an implementation!"
argument_list|)
throw|;
block|}
comment|/**    * Method that does a batch call on Deletes, Gets, Puts, Increments, Appends, RowMutations.    * The ordering of execution of the actions is not defined. Meaning if you do a Put and a    * Get in the same {@link #batch} call, you will not necessarily be    * guaranteed that the Get returns what the Put had put.    *    * @param actions list of Get, Put, Delete, Increment, Append, RowMutations.    * @param results Empty Object[], same size as actions. Provides access to partial    *                results, in case an exception is thrown. A null in the result array means that    *                the call for that action failed, even after retries. The order of the objects    *                in the results array corresponds to the order of actions in the request list.    * @throws IOException    * @since 0.90.0    */
specifier|default
name|void
name|batch
parameter_list|(
specifier|final
name|List
argument_list|<
name|?
extends|extends
name|Row
argument_list|>
name|actions
parameter_list|,
specifier|final
name|Object
index|[]
name|results
parameter_list|)
throws|throws
name|IOException
throws|,
name|InterruptedException
block|{
throw|throw
operator|new
name|NotImplementedException
argument_list|(
literal|"Add an implementation!"
argument_list|)
throw|;
block|}
comment|/**    * Same as {@link #batch(List, Object[])}, but with a callback.    * @since 0.96.0    */
specifier|default
parameter_list|<
name|R
parameter_list|>
name|void
name|batchCallback
parameter_list|(
specifier|final
name|List
argument_list|<
name|?
extends|extends
name|Row
argument_list|>
name|actions
parameter_list|,
specifier|final
name|Object
index|[]
name|results
parameter_list|,
specifier|final
name|Batch
operator|.
name|Callback
argument_list|<
name|R
argument_list|>
name|callback
parameter_list|)
throws|throws
name|IOException
throws|,
name|InterruptedException
block|{
throw|throw
operator|new
name|NotImplementedException
argument_list|(
literal|"Add an implementation!"
argument_list|)
throw|;
block|}
comment|/**    * Extracts certain cells from a given row.    * @param get The object that specifies what data to fetch and from which row.    * @return The data coming from the specified row, if it exists.  If the row    *   specified doesn't exist, the {@link Result} instance returned won't    *   contain any {@link org.apache.hadoop.hbase.KeyValue}, as indicated by    *   {@link Result#isEmpty()}.    * @throws IOException if a remote or network exception occurs.    * @since 0.20.0    */
specifier|default
name|Result
name|get
parameter_list|(
name|Get
name|get
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|get
argument_list|(
name|Collections
operator|.
name|singletonList
argument_list|(
name|get
argument_list|)
argument_list|)
index|[
literal|0
index|]
return|;
block|}
comment|/**    * Extracts specified cells from the given rows, as a batch.    *    * @param gets The objects that specify what data to fetch and from which rows.    * @return The data coming from the specified rows, if it exists.  If the row specified doesn't    *   exist, the {@link Result} instance returned won't contain any    *   {@link org.apache.hadoop.hbase.Cell}s, as indicated by {@link Result#isEmpty()}. If there    *   are any failures even after retries, there will be a<code>null</code> in the results' array    *   for  those Gets, AND an exception will be thrown. The ordering of the Result array    *   corresponds to  the order of the list of passed in Gets.    * @throws IOException if a remote or network exception occurs.    * @since 0.90.0    * @apiNote {@link #put(List)} runs pre-flight validations on the input list on client.    *   Currently {@link #get(List)} doesn't run any validations on the client-side, currently there    *   is no need, but this may change in the future. An    * {@link IllegalArgumentException} will be thrown in this case.    */
specifier|default
name|Result
index|[]
name|get
parameter_list|(
name|List
argument_list|<
name|Get
argument_list|>
name|gets
parameter_list|)
throws|throws
name|IOException
block|{
throw|throw
operator|new
name|NotImplementedException
argument_list|(
literal|"Add an implementation!"
argument_list|)
throw|;
block|}
comment|/**    * Returns a scanner on the current table as specified by the {@link Scan}    * object.    * Note that the passed {@link Scan}'s start row and caching properties    * maybe changed.    *    * @param scan A configured {@link Scan} object.    * @return A scanner.    * @throws IOException if a remote or network exception occurs.    * @since 0.20.0    */
specifier|default
name|ResultScanner
name|getScanner
parameter_list|(
name|Scan
name|scan
parameter_list|)
throws|throws
name|IOException
block|{
throw|throw
operator|new
name|NotImplementedException
argument_list|(
literal|"Add an implementation!"
argument_list|)
throw|;
block|}
comment|/**    * Gets a scanner on the current table for the given family.    *    * @param family The column family to scan.    * @return A scanner.    * @throws IOException if a remote or network exception occurs.    * @since 0.20.0    */
specifier|default
name|ResultScanner
name|getScanner
parameter_list|(
name|byte
index|[]
name|family
parameter_list|)
throws|throws
name|IOException
block|{
throw|throw
operator|new
name|NotImplementedException
argument_list|(
literal|"Add an implementation!"
argument_list|)
throw|;
block|}
comment|/**    * Gets a scanner on the current table for the given family and qualifier.    *    * @param family The column family to scan.    * @param qualifier The column qualifier to scan.    * @return A scanner.    * @throws IOException if a remote or network exception occurs.    * @since 0.20.0    */
specifier|default
name|ResultScanner
name|getScanner
parameter_list|(
name|byte
index|[]
name|family
parameter_list|,
name|byte
index|[]
name|qualifier
parameter_list|)
throws|throws
name|IOException
block|{
throw|throw
operator|new
name|NotImplementedException
argument_list|(
literal|"Add an implementation!"
argument_list|)
throw|;
block|}
comment|/**    * Puts some data in the table.    *    * @param put The data to put.    * @throws IOException if a remote or network exception occurs.    * @since 0.20.0    */
specifier|default
name|void
name|put
parameter_list|(
name|Put
name|put
parameter_list|)
throws|throws
name|IOException
block|{
name|put
argument_list|(
name|Collections
operator|.
name|singletonList
argument_list|(
name|put
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|/**    * Batch puts the specified data into the table.    *<p>    * This can be used for group commit, or for submitting user defined batches. Before sending    * a batch of mutations to the server, the client runs a few validations on the input list. If an    * error is found, for example, a mutation was supplied but was missing it's column an    * {@link IllegalArgumentException} will be thrown and no mutations will be applied. If there    * are any failures even after retries, a {@link RetriesExhaustedWithDetailsException} will be    * thrown. RetriesExhaustedWithDetailsException contains lists of failed mutations and    * corresponding remote exceptions. The ordering of mutations and exceptions in the    * encapsulating exception corresponds to the order of the input list of Put requests.    *    * @param puts The list of mutations to apply.    * @throws IOException if a remote or network exception occurs.    * @since 0.20.0    */
specifier|default
name|void
name|put
parameter_list|(
name|List
argument_list|<
name|Put
argument_list|>
name|puts
parameter_list|)
throws|throws
name|IOException
block|{
throw|throw
operator|new
name|NotImplementedException
argument_list|(
literal|"Add an implementation!"
argument_list|)
throw|;
block|}
comment|/**    * Deletes the specified cells/row.    *    * @param delete The object that specifies what to delete.    * @throws IOException if a remote or network exception occurs.    * @since 0.20.0    */
specifier|default
name|void
name|delete
parameter_list|(
name|Delete
name|delete
parameter_list|)
throws|throws
name|IOException
block|{
throw|throw
operator|new
name|NotImplementedException
argument_list|(
literal|"Add an implementation!"
argument_list|)
throw|;
block|}
comment|/**    * Batch Deletes the specified cells/rows from the table.    *<p>    * If a specified row does not exist, {@link Delete} will report as though sucessful    * delete; no exception will be thrown. If there are any failures even after retries,    * a {@link RetriesExhaustedWithDetailsException} will be thrown.    * RetriesExhaustedWithDetailsException contains lists of failed {@link Delete}s and    * corresponding remote exceptions.    *    * @param deletes List of things to delete. The input list gets modified by this    * method. All successfully applied {@link Delete}s in the list are removed (in particular it    * gets re-ordered, so the order in which the elements are inserted in the list gives no    * guarantee as to the order in which the {@link Delete}s are executed).    * @throws IOException if a remote or network exception occurs. In that case    * the {@code deletes} argument will contain the {@link Delete} instances    * that have not be successfully applied.    * @since 0.20.1    * @apiNote In 3.0.0 version, the input list {@code deletes} will no longer be modified. Also,    * {@link #put(List)} runs pre-flight validations on the input list on client. Currently    * {@link #delete(List)} doesn't run validations on the client, there is no need currently,    * but this may change in the future. An * {@link IllegalArgumentException} will be thrown    * in this case.    */
specifier|default
name|void
name|delete
parameter_list|(
name|List
argument_list|<
name|Delete
argument_list|>
name|deletes
parameter_list|)
throws|throws
name|IOException
block|{
throw|throw
operator|new
name|NotImplementedException
argument_list|(
literal|"Add an implementation!"
argument_list|)
throw|;
block|}
comment|/**    * Atomically checks if a row/family/qualifier value matches the expected value. If it does, it    * adds the Put/Delete/RowMutations.    *<p>    * Use the returned {@link CheckAndMutateBuilder} to construct your request and then execute it.    * This is a fluent style API, the code is like:    *    *<pre>    *<code>    * table.checkAndMutate(row, family).qualifier(qualifier).ifNotExists().thenPut(put);    *</code>    *</pre>    */
specifier|default
name|CheckAndMutateBuilder
name|checkAndMutate
parameter_list|(
name|byte
index|[]
name|row
parameter_list|,
name|byte
index|[]
name|family
parameter_list|)
block|{
throw|throw
operator|new
name|NotImplementedException
argument_list|(
literal|"Add an implementation!"
argument_list|)
throw|;
block|}
comment|/**    * A helper class for sending checkAndMutate request.    */
interface|interface
name|CheckAndMutateBuilder
block|{
comment|/**      * @param qualifier column qualifier to check.      */
name|CheckAndMutateBuilder
name|qualifier
parameter_list|(
name|byte
index|[]
name|qualifier
parameter_list|)
function_decl|;
comment|/**      * @param timeRange timeRange to check      */
name|CheckAndMutateBuilder
name|timeRange
parameter_list|(
name|TimeRange
name|timeRange
parameter_list|)
function_decl|;
comment|/**      * Check for lack of column.      */
name|CheckAndMutateBuilder
name|ifNotExists
parameter_list|()
function_decl|;
comment|/**      * Check for equality.      * @param value the expected value      */
specifier|default
name|CheckAndMutateBuilder
name|ifEquals
parameter_list|(
name|byte
index|[]
name|value
parameter_list|)
block|{
return|return
name|ifMatches
argument_list|(
name|CompareOperator
operator|.
name|EQUAL
argument_list|,
name|value
argument_list|)
return|;
block|}
comment|/**      * @param compareOp comparison operator to use      * @param value the expected value      */
name|CheckAndMutateBuilder
name|ifMatches
parameter_list|(
name|CompareOperator
name|compareOp
parameter_list|,
name|byte
index|[]
name|value
parameter_list|)
function_decl|;
comment|/**      * @param put data to put if check succeeds      * @return {@code true} if the new put was executed, {@code false} otherwise.      */
name|boolean
name|thenPut
parameter_list|(
name|Put
name|put
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**      * @param delete data to delete if check succeeds      * @return {@code true} if the new delete was executed, {@code false} otherwise.      */
name|boolean
name|thenDelete
parameter_list|(
name|Delete
name|delete
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**      * @param mutation mutations to perform if check succeeds      * @return true if the new mutation was executed, false otherwise.      */
name|boolean
name|thenMutate
parameter_list|(
name|RowMutations
name|mutation
parameter_list|)
throws|throws
name|IOException
function_decl|;
block|}
comment|/**    * Performs multiple mutations atomically on a single row. Currently    * {@link Put} and {@link Delete} are supported.    *    * @param rm object that specifies the set of mutations to perform atomically    * @throws IOException    */
specifier|default
name|void
name|mutateRow
parameter_list|(
specifier|final
name|RowMutations
name|rm
parameter_list|)
throws|throws
name|IOException
block|{
throw|throw
operator|new
name|NotImplementedException
argument_list|(
literal|"Add an implementation!"
argument_list|)
throw|;
block|}
comment|/**    * Appends values to one or more columns within a single row.    *<p>    * This operation guaranteed atomicity to readers. Appends are done    * under a single row lock, so write operations to a row are synchronized, and    * readers are guaranteed to see this operation fully completed.    *    * @param append object that specifies the columns and values to be appended    * @throws IOException e    * @return values of columns after the append operation (maybe null)    */
specifier|default
name|Result
name|append
parameter_list|(
specifier|final
name|Append
name|append
parameter_list|)
throws|throws
name|IOException
block|{
throw|throw
operator|new
name|NotImplementedException
argument_list|(
literal|"Add an implementation!"
argument_list|)
throw|;
block|}
comment|/**    * Increments one or more columns within a single row.    *<p>    * This operation ensures atomicity to readers. Increments are done    * under a single row lock, so write operations to a row are synchronized, and    * readers are guaranteed to see this operation fully completed.    *    * @param increment object that specifies the columns and amounts to be used    *                  for the increment operations    * @throws IOException e    * @return values of columns after the increment    */
specifier|default
name|Result
name|increment
parameter_list|(
specifier|final
name|Increment
name|increment
parameter_list|)
throws|throws
name|IOException
block|{
throw|throw
operator|new
name|NotImplementedException
argument_list|(
literal|"Add an implementation!"
argument_list|)
throw|;
block|}
comment|/**    * See {@link #incrementColumnValue(byte[], byte[], byte[], long, Durability)}    *<p>    * The {@link Durability} is defaulted to {@link Durability#SYNC_WAL}.    * @param row The row that contains the cell to increment.    * @param family The column family of the cell to increment.    * @param qualifier The column qualifier of the cell to increment.    * @param amount The amount to increment the cell with (or decrement, if the    * amount is negative).    * @return The new value, post increment.    * @throws IOException if a remote or network exception occurs.    */
specifier|default
name|long
name|incrementColumnValue
parameter_list|(
name|byte
index|[]
name|row
parameter_list|,
name|byte
index|[]
name|family
parameter_list|,
name|byte
index|[]
name|qualifier
parameter_list|,
name|long
name|amount
parameter_list|)
throws|throws
name|IOException
block|{
name|Increment
name|increment
init|=
operator|new
name|Increment
argument_list|(
name|row
argument_list|)
operator|.
name|addColumn
argument_list|(
name|family
argument_list|,
name|qualifier
argument_list|,
name|amount
argument_list|)
decl_stmt|;
name|Cell
name|cell
init|=
name|increment
argument_list|(
name|increment
argument_list|)
operator|.
name|getColumnLatestCell
argument_list|(
name|family
argument_list|,
name|qualifier
argument_list|)
decl_stmt|;
return|return
name|Bytes
operator|.
name|toLong
argument_list|(
name|cell
operator|.
name|getValueArray
argument_list|()
argument_list|,
name|cell
operator|.
name|getValueOffset
argument_list|()
argument_list|,
name|cell
operator|.
name|getValueLength
argument_list|()
argument_list|)
return|;
block|}
comment|/**    * Atomically increments a column value. If the column value already exists    * and is not a big-endian long, this could throw an exception. If the column    * value does not yet exist it is initialized to<code>amount</code> and    * written to the specified column.    *    *<p>Setting durability to {@link Durability#SKIP_WAL} means that in a fail    * scenario you will lose any increments that have not been flushed.    * @param row The row that contains the cell to increment.    * @param family The column family of the cell to increment.    * @param qualifier The column qualifier of the cell to increment.    * @param amount The amount to increment the cell with (or decrement, if the    * amount is negative).    * @param durability The persistence guarantee for this increment.    * @return The new value, post increment.    * @throws IOException if a remote or network exception occurs.    */
specifier|default
name|long
name|incrementColumnValue
parameter_list|(
name|byte
index|[]
name|row
parameter_list|,
name|byte
index|[]
name|family
parameter_list|,
name|byte
index|[]
name|qualifier
parameter_list|,
name|long
name|amount
parameter_list|,
name|Durability
name|durability
parameter_list|)
throws|throws
name|IOException
block|{
name|Increment
name|increment
init|=
operator|new
name|Increment
argument_list|(
name|row
argument_list|)
operator|.
name|addColumn
argument_list|(
name|family
argument_list|,
name|qualifier
argument_list|,
name|amount
argument_list|)
operator|.
name|setDurability
argument_list|(
name|durability
argument_list|)
decl_stmt|;
name|Cell
name|cell
init|=
name|increment
argument_list|(
name|increment
argument_list|)
operator|.
name|getColumnLatestCell
argument_list|(
name|family
argument_list|,
name|qualifier
argument_list|)
decl_stmt|;
return|return
name|Bytes
operator|.
name|toLong
argument_list|(
name|cell
operator|.
name|getValueArray
argument_list|()
argument_list|,
name|cell
operator|.
name|getValueOffset
argument_list|()
argument_list|,
name|cell
operator|.
name|getValueLength
argument_list|()
argument_list|)
return|;
block|}
comment|/**    * Releases any resources held or pending changes in internal buffers.    *    * @throws IOException if a remote or network exception occurs.    */
annotation|@
name|Override
specifier|default
name|void
name|close
parameter_list|()
throws|throws
name|IOException
block|{
throw|throw
operator|new
name|NotImplementedException
argument_list|(
literal|"Add an implementation!"
argument_list|)
throw|;
block|}
comment|/**    * Creates and returns a {@link com.google.protobuf.RpcChannel} instance connected to the    * table region containing the specified row.  The row given does not actually have    * to exist.  Whichever region would contain the row based on start and end keys will    * be used.  Note that the {@code row} parameter is also not passed to the    * coprocessor handler registered for this protocol, unless the {@code row}    * is separately passed as an argument in the service request.  The parameter    * here is only used to locate the region used to handle the call.    *    *<p>    * The obtained {@link com.google.protobuf.RpcChannel} instance can be used to access a published    * coprocessor {@link com.google.protobuf.Service} using standard protobuf service invocations:    *</p>    *    *<div style="background-color: #cccccc; padding: 2px">    *<blockquote><pre>    * CoprocessorRpcChannel channel = myTable.coprocessorService(rowkey);    * MyService.BlockingInterface service = MyService.newBlockingStub(channel);    * MyCallRequest request = MyCallRequest.newBuilder()    *     ...    *     .build();    * MyCallResponse response = service.myCall(null, request);    *</pre></blockquote></div>    *    * @param row The row key used to identify the remote region location    * @return A CoprocessorRpcChannel instance    */
specifier|default
name|CoprocessorRpcChannel
name|coprocessorService
parameter_list|(
name|byte
index|[]
name|row
parameter_list|)
block|{
throw|throw
operator|new
name|NotImplementedException
argument_list|(
literal|"Add an implementation!"
argument_list|)
throw|;
block|}
comment|/**    * Creates an instance of the given {@link com.google.protobuf.Service} subclass for each table    * region spanning the range from the {@code startKey} row to {@code endKey} row (inclusive), and    * invokes the passed {@link org.apache.hadoop.hbase.client.coprocessor.Batch.Call#call} method    * with each {@link com.google.protobuf.Service} instance.    *    * @param service the protocol buffer {@code Service} implementation to call    * @param startKey start region selection with region containing this row.  If {@code null}, the    *   selection will start with the first table region.    * @param endKey select regions up to and including the region containing this row. If    *   {@code null}, selection will continue through the last table region.    * @param callable this instance's    *   {@link org.apache.hadoop.hbase.client.coprocessor.Batch.Call#call}    *   method will be invoked once per table region, using the {@link com.google.protobuf.Service}    *   instance connected to that region.    * @param<T> the {@link com.google.protobuf.Service} subclass to connect to    * @param<R> Return type for the {@code callable} parameter's {@link    * org.apache.hadoop.hbase.client.coprocessor.Batch.Call#call} method    * @return a map of result values keyed by region name    */
specifier|default
parameter_list|<
name|T
extends|extends
name|Service
parameter_list|,
name|R
parameter_list|>
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|R
argument_list|>
name|coprocessorService
parameter_list|(
specifier|final
name|Class
argument_list|<
name|T
argument_list|>
name|service
parameter_list|,
name|byte
index|[]
name|startKey
parameter_list|,
name|byte
index|[]
name|endKey
parameter_list|,
specifier|final
name|Batch
operator|.
name|Call
argument_list|<
name|T
argument_list|,
name|R
argument_list|>
name|callable
parameter_list|)
throws|throws
name|ServiceException
throws|,
name|Throwable
block|{
throw|throw
operator|new
name|NotImplementedException
argument_list|(
literal|"Add an implementation!"
argument_list|)
throw|;
block|}
comment|/**    * Creates an instance of the given {@link com.google.protobuf.Service} subclass for each table    * region spanning the range from the {@code startKey} row to {@code endKey} row (inclusive), and    * invokes the passed {@link org.apache.hadoop.hbase.client.coprocessor.Batch.Call#call} method    * with each {@link Service} instance.    *    *<p> The given    * {@link org.apache.hadoop.hbase.client.coprocessor.Batch.Callback#update(byte[],byte[],Object)}    * method will be called with the return value from each region's    * {@link org.apache.hadoop.hbase.client.coprocessor.Batch.Call#call} invocation.</p>    *    * @param service the protocol buffer {@code Service} implementation to call    * @param startKey start region selection with region containing this row.  If {@code null}, the    *   selection will start with the first table region.    * @param endKey select regions up to and including the region containing this row. If    *   {@code null}, selection will continue through the last table region.    * @param callable this instance's    *   {@link org.apache.hadoop.hbase.client.coprocessor.Batch.Call#call}    *   method will be invoked once per table region, using the {@link Service} instance connected to    *   that region.    * @param<T> the {@link Service} subclass to connect to    * @param<R> Return type for the {@code callable} parameter's {@link    * org.apache.hadoop.hbase.client.coprocessor.Batch.Call#call} method    */
specifier|default
parameter_list|<
name|T
extends|extends
name|Service
parameter_list|,
name|R
parameter_list|>
name|void
name|coprocessorService
parameter_list|(
specifier|final
name|Class
argument_list|<
name|T
argument_list|>
name|service
parameter_list|,
name|byte
index|[]
name|startKey
parameter_list|,
name|byte
index|[]
name|endKey
parameter_list|,
specifier|final
name|Batch
operator|.
name|Call
argument_list|<
name|T
argument_list|,
name|R
argument_list|>
name|callable
parameter_list|,
specifier|final
name|Batch
operator|.
name|Callback
argument_list|<
name|R
argument_list|>
name|callback
parameter_list|)
throws|throws
name|ServiceException
throws|,
name|Throwable
block|{
throw|throw
operator|new
name|NotImplementedException
argument_list|(
literal|"Add an implementation!"
argument_list|)
throw|;
block|}
comment|/**    * Creates an instance of the given {@link com.google.protobuf.Service} subclass for each table    * region spanning the range from the {@code startKey} row to {@code endKey} row (inclusive), all    * the invocations to the same region server will be batched into one call. The coprocessor    * service is invoked according to the service instance, method name and parameters.    *    * @param methodDescriptor    *          the descriptor for the protobuf service method to call.    * @param request    *          the method call parameters    * @param startKey    *          start region selection with region containing this row. If {@code null}, the    *          selection will start with the first table region.    * @param endKey    *          select regions up to and including the region containing this row. If {@code null},    *          selection will continue through the last table region.    * @param responsePrototype    *          the proto type of the response of the method in Service.    * @param<R>    *          the response type for the coprocessor Service method    * @return a map of result values keyed by region name    */
specifier|default
parameter_list|<
name|R
extends|extends
name|Message
parameter_list|>
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|R
argument_list|>
name|batchCoprocessorService
parameter_list|(
name|Descriptors
operator|.
name|MethodDescriptor
name|methodDescriptor
parameter_list|,
name|Message
name|request
parameter_list|,
name|byte
index|[]
name|startKey
parameter_list|,
name|byte
index|[]
name|endKey
parameter_list|,
name|R
name|responsePrototype
parameter_list|)
throws|throws
name|ServiceException
throws|,
name|Throwable
block|{
throw|throw
operator|new
name|NotImplementedException
argument_list|(
literal|"Add an implementation!"
argument_list|)
throw|;
block|}
comment|/**    * Creates an instance of the given {@link com.google.protobuf.Service} subclass for each table    * region spanning the range from the {@code startKey} row to {@code endKey} row (inclusive), all    * the invocations to the same region server will be batched into one call. The coprocessor    * service is invoked according to the service instance, method name and parameters.    *    *<p>    * The given    * {@link org.apache.hadoop.hbase.client.coprocessor.Batch.Callback#update(byte[],byte[],Object)}    * method will be called with the return value from each region's invocation.    *</p>    *    * @param methodDescriptor the descriptor for the protobuf service method to call.    * @param request the method call parameters    * @param startKey start region selection with region containing this row.    *   If {@code null}, the selection will start with the first table region.    * @param endKey select regions up to and including the region containing this row.    *   If {@code null}, selection will continue through the last table region.    * @param responsePrototype the proto type of the response of the method in Service.    * @param callback callback to invoke with the response for each region    * @param<R>    *          the response type for the coprocessor Service method    */
specifier|default
parameter_list|<
name|R
extends|extends
name|Message
parameter_list|>
name|void
name|batchCoprocessorService
parameter_list|(
name|Descriptors
operator|.
name|MethodDescriptor
name|methodDescriptor
parameter_list|,
name|Message
name|request
parameter_list|,
name|byte
index|[]
name|startKey
parameter_list|,
name|byte
index|[]
name|endKey
parameter_list|,
name|R
name|responsePrototype
parameter_list|,
name|Batch
operator|.
name|Callback
argument_list|<
name|R
argument_list|>
name|callback
parameter_list|)
throws|throws
name|ServiceException
throws|,
name|Throwable
block|{
throw|throw
operator|new
name|NotImplementedException
argument_list|(
literal|"Add an implementation!"
argument_list|)
throw|;
block|}
comment|/**    * Get timeout of each rpc request in this Table instance. It will be overridden by a more    * specific rpc timeout config such as readRpcTimeout or writeRpcTimeout.    * @see #getReadRpcTimeout(TimeUnit)    * @see #getWriteRpcTimeout(TimeUnit)    * @param unit the unit of time the timeout to be represented in    * @return rpc timeout in the specified time unit    */
specifier|default
name|long
name|getRpcTimeout
parameter_list|(
name|TimeUnit
name|unit
parameter_list|)
block|{
throw|throw
operator|new
name|NotImplementedException
argument_list|(
literal|"Add an implementation!"
argument_list|)
throw|;
block|}
comment|/**    * Get timeout of each rpc read request in this Table instance.    * @param unit the unit of time the timeout to be represented in    * @return read rpc timeout in the specified time unit    */
specifier|default
name|long
name|getReadRpcTimeout
parameter_list|(
name|TimeUnit
name|unit
parameter_list|)
block|{
throw|throw
operator|new
name|NotImplementedException
argument_list|(
literal|"Add an implementation!"
argument_list|)
throw|;
block|}
comment|/**    * Get timeout of each rpc write request in this Table instance.    * @param unit the unit of time the timeout to be represented in    * @return write rpc timeout in the specified time unit    */
specifier|default
name|long
name|getWriteRpcTimeout
parameter_list|(
name|TimeUnit
name|unit
parameter_list|)
block|{
throw|throw
operator|new
name|NotImplementedException
argument_list|(
literal|"Add an implementation!"
argument_list|)
throw|;
block|}
comment|/**    * Get timeout of each operation in Table instance.    * @param unit the unit of time the timeout to be represented in    * @return operation rpc timeout in the specified time unit    */
specifier|default
name|long
name|getOperationTimeout
parameter_list|(
name|TimeUnit
name|unit
parameter_list|)
block|{
throw|throw
operator|new
name|NotImplementedException
argument_list|(
literal|"Add an implementation!"
argument_list|)
throw|;
block|}
block|}
end_interface

end_unit

