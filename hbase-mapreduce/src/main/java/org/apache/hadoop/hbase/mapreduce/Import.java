begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  *  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|mapreduce
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|ByteArrayInputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|DataInput
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|DataInputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|DataOutput
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|lang
operator|.
name|reflect
operator|.
name|InvocationTargetException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|lang
operator|.
name|reflect
operator|.
name|Method
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collections
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Locale
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|TreeMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|UUID
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configured
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|Cell
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|CellComparator
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|CellUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HBaseConfiguration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|PrivateCellUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|KeyValue
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|KeyValueUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|TableName
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|ZooKeeperConnectionException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|MapReduceExtendedCell
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|zookeeper
operator|.
name|ZKWatcher
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|yetus
operator|.
name|audience
operator|.
name|InterfaceAudience
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|Admin
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|Connection
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|ConnectionFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|Delete
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|Durability
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|Mutation
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|Put
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|RegionLocator
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|Result
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|Table
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|filter
operator|.
name|Filter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|ImmutableBytesWritable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|Bytes
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|zookeeper
operator|.
name|ZKClusterId
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|RawComparator
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|WritableComparable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|WritableComparator
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|Job
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|Partitioner
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|Reducer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|TaskCounter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|lib
operator|.
name|input
operator|.
name|FileInputFormat
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|lib
operator|.
name|input
operator|.
name|SequenceFileInputFormat
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|lib
operator|.
name|output
operator|.
name|FileOutputFormat
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|lib
operator|.
name|partition
operator|.
name|TotalOrderPartitioner
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|Tool
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|ToolRunner
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|zookeeper
operator|.
name|KeeperException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|Logger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|LoggerFactory
import|;
end_import

begin_comment
comment|/**  * Import data written by {@link Export}.  */
end_comment

begin_class
annotation|@
name|InterfaceAudience
operator|.
name|Public
specifier|public
class|class
name|Import
extends|extends
name|Configured
implements|implements
name|Tool
block|{
specifier|private
specifier|static
specifier|final
name|Logger
name|LOG
init|=
name|LoggerFactory
operator|.
name|getLogger
argument_list|(
name|Import
operator|.
name|class
argument_list|)
decl_stmt|;
specifier|final
specifier|static
name|String
name|NAME
init|=
literal|"import"
decl_stmt|;
specifier|public
specifier|final
specifier|static
name|String
name|CF_RENAME_PROP
init|=
literal|"HBASE_IMPORTER_RENAME_CFS"
decl_stmt|;
specifier|public
specifier|final
specifier|static
name|String
name|BULK_OUTPUT_CONF_KEY
init|=
literal|"import.bulk.output"
decl_stmt|;
specifier|public
specifier|final
specifier|static
name|String
name|FILTER_CLASS_CONF_KEY
init|=
literal|"import.filter.class"
decl_stmt|;
specifier|public
specifier|final
specifier|static
name|String
name|FILTER_ARGS_CONF_KEY
init|=
literal|"import.filter.args"
decl_stmt|;
specifier|public
specifier|final
specifier|static
name|String
name|TABLE_NAME
init|=
literal|"import.table.name"
decl_stmt|;
specifier|public
specifier|final
specifier|static
name|String
name|WAL_DURABILITY
init|=
literal|"import.wal.durability"
decl_stmt|;
specifier|public
specifier|final
specifier|static
name|String
name|HAS_LARGE_RESULT
init|=
literal|"import.bulk.hasLargeResult"
decl_stmt|;
specifier|private
specifier|final
specifier|static
name|String
name|JOB_NAME_CONF_KEY
init|=
literal|"mapreduce.job.name"
decl_stmt|;
specifier|public
specifier|static
class|class
name|CellWritableComparablePartitioner
extends|extends
name|Partitioner
argument_list|<
name|CellWritableComparable
argument_list|,
name|Cell
argument_list|>
block|{
specifier|private
specifier|static
name|CellWritableComparable
index|[]
name|START_KEYS
init|=
literal|null
decl_stmt|;
annotation|@
name|Override
specifier|public
name|int
name|getPartition
parameter_list|(
name|CellWritableComparable
name|key
parameter_list|,
name|Cell
name|value
parameter_list|,
name|int
name|numPartitions
parameter_list|)
block|{
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|START_KEYS
operator|.
name|length
condition|;
operator|++
name|i
control|)
block|{
if|if
condition|(
name|key
operator|.
name|compareTo
argument_list|(
name|START_KEYS
index|[
name|i
index|]
argument_list|)
operator|<=
literal|0
condition|)
block|{
return|return
name|i
return|;
block|}
block|}
return|return
name|START_KEYS
operator|.
name|length
return|;
block|}
block|}
specifier|public
specifier|static
class|class
name|CellWritableComparable
implements|implements
name|WritableComparable
argument_list|<
name|CellWritableComparable
argument_list|>
block|{
specifier|private
name|Cell
name|kv
init|=
literal|null
decl_stmt|;
static|static
block|{
comment|// register this comparator
name|WritableComparator
operator|.
name|define
argument_list|(
name|CellWritableComparable
operator|.
name|class
argument_list|,
operator|new
name|CellWritableComparator
argument_list|()
argument_list|)
expr_stmt|;
block|}
specifier|public
name|CellWritableComparable
parameter_list|()
block|{     }
specifier|public
name|CellWritableComparable
parameter_list|(
name|Cell
name|kv
parameter_list|)
block|{
name|this
operator|.
name|kv
operator|=
name|kv
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|write
parameter_list|(
name|DataOutput
name|out
parameter_list|)
throws|throws
name|IOException
block|{
name|out
operator|.
name|writeInt
argument_list|(
name|PrivateCellUtil
operator|.
name|estimatedSerializedSizeOfKey
argument_list|(
name|kv
argument_list|)
argument_list|)
expr_stmt|;
name|out
operator|.
name|writeInt
argument_list|(
literal|0
argument_list|)
expr_stmt|;
name|PrivateCellUtil
operator|.
name|writeFlatKey
argument_list|(
name|kv
argument_list|,
name|out
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|readFields
parameter_list|(
name|DataInput
name|in
parameter_list|)
throws|throws
name|IOException
block|{
name|kv
operator|=
name|KeyValue
operator|.
name|create
argument_list|(
name|in
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
annotation|@
name|edu
operator|.
name|umd
operator|.
name|cs
operator|.
name|findbugs
operator|.
name|annotations
operator|.
name|SuppressWarnings
argument_list|(
name|value
operator|=
literal|"EQ_COMPARETO_USE_OBJECT_EQUALS"
argument_list|,
name|justification
operator|=
literal|"This is wrong, yes, but we should be purging Writables, not fixing them"
argument_list|)
specifier|public
name|int
name|compareTo
parameter_list|(
name|CellWritableComparable
name|o
parameter_list|)
block|{
return|return
name|CellComparator
operator|.
name|getInstance
argument_list|()
operator|.
name|compare
argument_list|(
name|this
operator|.
name|kv
argument_list|,
name|o
operator|.
name|kv
argument_list|)
return|;
block|}
specifier|public
specifier|static
class|class
name|CellWritableComparator
extends|extends
name|WritableComparator
block|{
annotation|@
name|Override
specifier|public
name|int
name|compare
parameter_list|(
name|byte
index|[]
name|b1
parameter_list|,
name|int
name|s1
parameter_list|,
name|int
name|l1
parameter_list|,
name|byte
index|[]
name|b2
parameter_list|,
name|int
name|s2
parameter_list|,
name|int
name|l2
parameter_list|)
block|{
try|try
block|{
name|CellWritableComparable
name|kv1
init|=
operator|new
name|CellWritableComparable
argument_list|()
decl_stmt|;
name|kv1
operator|.
name|readFields
argument_list|(
operator|new
name|DataInputStream
argument_list|(
operator|new
name|ByteArrayInputStream
argument_list|(
name|b1
argument_list|,
name|s1
argument_list|,
name|l1
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
name|CellWritableComparable
name|kv2
init|=
operator|new
name|CellWritableComparable
argument_list|()
decl_stmt|;
name|kv2
operator|.
name|readFields
argument_list|(
operator|new
name|DataInputStream
argument_list|(
operator|new
name|ByteArrayInputStream
argument_list|(
name|b2
argument_list|,
name|s2
argument_list|,
name|l2
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
return|return
name|compare
argument_list|(
name|kv1
argument_list|,
name|kv2
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|RuntimeException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
block|}
block|}
specifier|public
specifier|static
class|class
name|CellReducer
extends|extends
name|Reducer
argument_list|<
name|CellWritableComparable
argument_list|,
name|Cell
argument_list|,
name|ImmutableBytesWritable
argument_list|,
name|Cell
argument_list|>
block|{
specifier|protected
name|void
name|reduce
parameter_list|(
name|CellWritableComparable
name|row
parameter_list|,
name|Iterable
argument_list|<
name|Cell
argument_list|>
name|kvs
parameter_list|,
name|Reducer
argument_list|<
name|CellWritableComparable
argument_list|,
name|Cell
argument_list|,
name|ImmutableBytesWritable
argument_list|,
name|Cell
argument_list|>
operator|.
name|Context
name|context
parameter_list|)
throws|throws
name|java
operator|.
name|io
operator|.
name|IOException
throws|,
name|InterruptedException
block|{
name|int
name|index
init|=
literal|0
decl_stmt|;
for|for
control|(
name|Cell
name|kv
range|:
name|kvs
control|)
block|{
name|context
operator|.
name|write
argument_list|(
operator|new
name|ImmutableBytesWritable
argument_list|(
name|CellUtil
operator|.
name|cloneRow
argument_list|(
name|kv
argument_list|)
argument_list|)
argument_list|,
operator|new
name|MapReduceExtendedCell
argument_list|(
name|kv
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
operator|++
name|index
operator|%
literal|100
operator|==
literal|0
condition|)
name|context
operator|.
name|setStatus
argument_list|(
literal|"Wrote "
operator|+
name|index
operator|+
literal|" KeyValues, "
operator|+
literal|"and the rowkey whose is being wrote is "
operator|+
name|Bytes
operator|.
name|toString
argument_list|(
name|kv
operator|.
name|getRowArray
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
block|}
specifier|public
specifier|static
class|class
name|CellSortImporter
extends|extends
name|TableMapper
argument_list|<
name|CellWritableComparable
argument_list|,
name|Cell
argument_list|>
block|{
specifier|private
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|byte
index|[]
argument_list|>
name|cfRenameMap
decl_stmt|;
specifier|private
name|Filter
name|filter
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|Logger
name|LOG
init|=
name|LoggerFactory
operator|.
name|getLogger
argument_list|(
name|CellImporter
operator|.
name|class
argument_list|)
decl_stmt|;
comment|/**      * @param row  The current table row key.      * @param value  The columns.      * @param context  The current context.      * @throws IOException When something is broken with the data.      */
annotation|@
name|Override
specifier|public
name|void
name|map
parameter_list|(
name|ImmutableBytesWritable
name|row
parameter_list|,
name|Result
name|value
parameter_list|,
name|Context
name|context
parameter_list|)
throws|throws
name|IOException
block|{
try|try
block|{
if|if
condition|(
name|LOG
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|trace
argument_list|(
literal|"Considering the row."
operator|+
name|Bytes
operator|.
name|toString
argument_list|(
name|row
operator|.
name|get
argument_list|()
argument_list|,
name|row
operator|.
name|getOffset
argument_list|()
argument_list|,
name|row
operator|.
name|getLength
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|filter
operator|==
literal|null
operator|||
operator|!
name|filter
operator|.
name|filterRowKey
argument_list|(
name|PrivateCellUtil
operator|.
name|createFirstOnRow
argument_list|(
name|row
operator|.
name|get
argument_list|()
argument_list|,
name|row
operator|.
name|getOffset
argument_list|()
argument_list|,
operator|(
name|short
operator|)
name|row
operator|.
name|getLength
argument_list|()
argument_list|)
argument_list|)
condition|)
block|{
for|for
control|(
name|Cell
name|kv
range|:
name|value
operator|.
name|rawCells
argument_list|()
control|)
block|{
name|kv
operator|=
name|filterKv
argument_list|(
name|filter
argument_list|,
name|kv
argument_list|)
expr_stmt|;
comment|// skip if we filtered it out
if|if
condition|(
name|kv
operator|==
literal|null
condition|)
continue|continue;
name|Cell
name|ret
init|=
name|convertKv
argument_list|(
name|kv
argument_list|,
name|cfRenameMap
argument_list|)
decl_stmt|;
name|context
operator|.
name|write
argument_list|(
operator|new
name|CellWritableComparable
argument_list|(
name|ret
argument_list|)
argument_list|,
name|ret
argument_list|)
expr_stmt|;
block|}
block|}
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Interrupted while emitting Cell"
argument_list|,
name|e
argument_list|)
expr_stmt|;
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|interrupt
argument_list|()
expr_stmt|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|void
name|setup
parameter_list|(
name|Context
name|context
parameter_list|)
throws|throws
name|IOException
block|{
name|cfRenameMap
operator|=
name|createCfRenameMap
argument_list|(
name|context
operator|.
name|getConfiguration
argument_list|()
argument_list|)
expr_stmt|;
name|filter
operator|=
name|instantiateFilter
argument_list|(
name|context
operator|.
name|getConfiguration
argument_list|()
argument_list|)
expr_stmt|;
name|int
name|reduceNum
init|=
name|context
operator|.
name|getNumReduceTasks
argument_list|()
decl_stmt|;
name|Configuration
name|conf
init|=
name|context
operator|.
name|getConfiguration
argument_list|()
decl_stmt|;
name|TableName
name|tableName
init|=
name|TableName
operator|.
name|valueOf
argument_list|(
name|context
operator|.
name|getConfiguration
argument_list|()
operator|.
name|get
argument_list|(
name|TABLE_NAME
argument_list|)
argument_list|)
decl_stmt|;
try|try
init|(
name|Connection
name|conn
init|=
name|ConnectionFactory
operator|.
name|createConnection
argument_list|(
name|conf
argument_list|)
init|;
name|RegionLocator
name|regionLocator
operator|=
name|conn
operator|.
name|getRegionLocator
argument_list|(
name|tableName
argument_list|)
init|)
block|{
name|byte
index|[]
index|[]
name|startKeys
init|=
name|regionLocator
operator|.
name|getStartKeys
argument_list|()
decl_stmt|;
if|if
condition|(
name|startKeys
operator|.
name|length
operator|!=
name|reduceNum
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Region split after job initialization"
argument_list|)
throw|;
block|}
name|CellWritableComparable
index|[]
name|startKeyWraps
init|=
operator|new
name|CellWritableComparable
index|[
name|startKeys
operator|.
name|length
operator|-
literal|1
index|]
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|1
init|;
name|i
operator|<
name|startKeys
operator|.
name|length
condition|;
operator|++
name|i
control|)
block|{
name|startKeyWraps
index|[
name|i
operator|-
literal|1
index|]
operator|=
operator|new
name|CellWritableComparable
argument_list|(
name|KeyValueUtil
operator|.
name|createFirstOnRow
argument_list|(
name|startKeys
index|[
name|i
index|]
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|CellWritableComparablePartitioner
operator|.
name|START_KEYS
operator|=
name|startKeyWraps
expr_stmt|;
block|}
block|}
block|}
comment|/**    * A mapper that just writes out KeyValues.    */
annotation|@
name|edu
operator|.
name|umd
operator|.
name|cs
operator|.
name|findbugs
operator|.
name|annotations
operator|.
name|SuppressWarnings
argument_list|(
name|value
operator|=
literal|"EQ_COMPARETO_USE_OBJECT_EQUALS"
argument_list|,
name|justification
operator|=
literal|"Writables are going away and this has been this way forever"
argument_list|)
specifier|public
specifier|static
class|class
name|CellImporter
extends|extends
name|TableMapper
argument_list|<
name|ImmutableBytesWritable
argument_list|,
name|Cell
argument_list|>
block|{
specifier|private
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|byte
index|[]
argument_list|>
name|cfRenameMap
decl_stmt|;
specifier|private
name|Filter
name|filter
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|Logger
name|LOG
init|=
name|LoggerFactory
operator|.
name|getLogger
argument_list|(
name|CellImporter
operator|.
name|class
argument_list|)
decl_stmt|;
comment|/**      * @param row  The current table row key.      * @param value  The columns.      * @param context  The current context.      * @throws IOException When something is broken with the data.      */
annotation|@
name|Override
specifier|public
name|void
name|map
parameter_list|(
name|ImmutableBytesWritable
name|row
parameter_list|,
name|Result
name|value
parameter_list|,
name|Context
name|context
parameter_list|)
throws|throws
name|IOException
block|{
try|try
block|{
if|if
condition|(
name|LOG
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|trace
argument_list|(
literal|"Considering the row."
operator|+
name|Bytes
operator|.
name|toString
argument_list|(
name|row
operator|.
name|get
argument_list|()
argument_list|,
name|row
operator|.
name|getOffset
argument_list|()
argument_list|,
name|row
operator|.
name|getLength
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|filter
operator|==
literal|null
operator|||
operator|!
name|filter
operator|.
name|filterRowKey
argument_list|(
name|PrivateCellUtil
operator|.
name|createFirstOnRow
argument_list|(
name|row
operator|.
name|get
argument_list|()
argument_list|,
name|row
operator|.
name|getOffset
argument_list|()
argument_list|,
operator|(
name|short
operator|)
name|row
operator|.
name|getLength
argument_list|()
argument_list|)
argument_list|)
condition|)
block|{
for|for
control|(
name|Cell
name|kv
range|:
name|value
operator|.
name|rawCells
argument_list|()
control|)
block|{
name|kv
operator|=
name|filterKv
argument_list|(
name|filter
argument_list|,
name|kv
argument_list|)
expr_stmt|;
comment|// skip if we filtered it out
if|if
condition|(
name|kv
operator|==
literal|null
condition|)
continue|continue;
name|context
operator|.
name|write
argument_list|(
name|row
argument_list|,
operator|new
name|MapReduceExtendedCell
argument_list|(
name|convertKv
argument_list|(
name|kv
argument_list|,
name|cfRenameMap
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Interrupted while emitting Cell"
argument_list|,
name|e
argument_list|)
expr_stmt|;
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|interrupt
argument_list|()
expr_stmt|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|void
name|setup
parameter_list|(
name|Context
name|context
parameter_list|)
block|{
name|cfRenameMap
operator|=
name|createCfRenameMap
argument_list|(
name|context
operator|.
name|getConfiguration
argument_list|()
argument_list|)
expr_stmt|;
name|filter
operator|=
name|instantiateFilter
argument_list|(
name|context
operator|.
name|getConfiguration
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Write table content out to files in hdfs.    */
specifier|public
specifier|static
class|class
name|Importer
extends|extends
name|TableMapper
argument_list|<
name|ImmutableBytesWritable
argument_list|,
name|Mutation
argument_list|>
block|{
specifier|private
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|byte
index|[]
argument_list|>
name|cfRenameMap
decl_stmt|;
specifier|private
name|List
argument_list|<
name|UUID
argument_list|>
name|clusterIds
decl_stmt|;
specifier|private
name|Filter
name|filter
decl_stmt|;
specifier|private
name|Durability
name|durability
decl_stmt|;
comment|/**      * @param row  The current table row key.      * @param value  The columns.      * @param context  The current context.      * @throws IOException When something is broken with the data.      */
annotation|@
name|Override
specifier|public
name|void
name|map
parameter_list|(
name|ImmutableBytesWritable
name|row
parameter_list|,
name|Result
name|value
parameter_list|,
name|Context
name|context
parameter_list|)
throws|throws
name|IOException
block|{
try|try
block|{
name|writeResult
argument_list|(
name|row
argument_list|,
name|value
argument_list|,
name|context
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Interrupted while writing result"
argument_list|,
name|e
argument_list|)
expr_stmt|;
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|interrupt
argument_list|()
expr_stmt|;
block|}
block|}
specifier|private
name|void
name|writeResult
parameter_list|(
name|ImmutableBytesWritable
name|key
parameter_list|,
name|Result
name|result
parameter_list|,
name|Context
name|context
parameter_list|)
throws|throws
name|IOException
throws|,
name|InterruptedException
block|{
name|Put
name|put
init|=
literal|null
decl_stmt|;
name|Delete
name|delete
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|trace
argument_list|(
literal|"Considering the row."
operator|+
name|Bytes
operator|.
name|toString
argument_list|(
name|key
operator|.
name|get
argument_list|()
argument_list|,
name|key
operator|.
name|getOffset
argument_list|()
argument_list|,
name|key
operator|.
name|getLength
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|filter
operator|==
literal|null
operator|||
operator|!
name|filter
operator|.
name|filterRowKey
argument_list|(
name|PrivateCellUtil
operator|.
name|createFirstOnRow
argument_list|(
name|key
operator|.
name|get
argument_list|()
argument_list|,
name|key
operator|.
name|getOffset
argument_list|()
argument_list|,
operator|(
name|short
operator|)
name|key
operator|.
name|getLength
argument_list|()
argument_list|)
argument_list|)
condition|)
block|{
name|processKV
argument_list|(
name|key
argument_list|,
name|result
argument_list|,
name|context
argument_list|,
name|put
argument_list|,
name|delete
argument_list|)
expr_stmt|;
block|}
block|}
specifier|protected
name|void
name|processKV
parameter_list|(
name|ImmutableBytesWritable
name|key
parameter_list|,
name|Result
name|result
parameter_list|,
name|Context
name|context
parameter_list|,
name|Put
name|put
parameter_list|,
name|Delete
name|delete
parameter_list|)
throws|throws
name|IOException
throws|,
name|InterruptedException
block|{
for|for
control|(
name|Cell
name|kv
range|:
name|result
operator|.
name|rawCells
argument_list|()
control|)
block|{
name|kv
operator|=
name|filterKv
argument_list|(
name|filter
argument_list|,
name|kv
argument_list|)
expr_stmt|;
comment|// skip if we filter it out
if|if
condition|(
name|kv
operator|==
literal|null
condition|)
continue|continue;
name|kv
operator|=
name|convertKv
argument_list|(
name|kv
argument_list|,
name|cfRenameMap
argument_list|)
expr_stmt|;
comment|// Deletes and Puts are gathered and written when finished
comment|/*          * If there are sequence of mutations and tombstones in an Export, and after Import the same          * sequence should be restored as it is. If we combine all Delete tombstones into single          * request then there is chance of ignoring few DeleteFamily tombstones, because if we          * submit multiple DeleteFamily tombstones in single Delete request then we are maintaining          * only newest in hbase table and ignoring other. Check - HBASE-12065          */
if|if
condition|(
name|PrivateCellUtil
operator|.
name|isDeleteFamily
argument_list|(
name|kv
argument_list|)
condition|)
block|{
name|Delete
name|deleteFamily
init|=
operator|new
name|Delete
argument_list|(
name|key
operator|.
name|get
argument_list|()
argument_list|)
decl_stmt|;
name|deleteFamily
operator|.
name|add
argument_list|(
name|kv
argument_list|)
expr_stmt|;
if|if
condition|(
name|durability
operator|!=
literal|null
condition|)
block|{
name|deleteFamily
operator|.
name|setDurability
argument_list|(
name|durability
argument_list|)
expr_stmt|;
block|}
name|deleteFamily
operator|.
name|setClusterIds
argument_list|(
name|clusterIds
argument_list|)
expr_stmt|;
name|context
operator|.
name|write
argument_list|(
name|key
argument_list|,
name|deleteFamily
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|CellUtil
operator|.
name|isDelete
argument_list|(
name|kv
argument_list|)
condition|)
block|{
if|if
condition|(
name|delete
operator|==
literal|null
condition|)
block|{
name|delete
operator|=
operator|new
name|Delete
argument_list|(
name|key
operator|.
name|get
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|delete
operator|.
name|add
argument_list|(
name|kv
argument_list|)
expr_stmt|;
block|}
else|else
block|{
if|if
condition|(
name|put
operator|==
literal|null
condition|)
block|{
name|put
operator|=
operator|new
name|Put
argument_list|(
name|key
operator|.
name|get
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|addPutToKv
argument_list|(
name|put
argument_list|,
name|kv
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|put
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
name|durability
operator|!=
literal|null
condition|)
block|{
name|put
operator|.
name|setDurability
argument_list|(
name|durability
argument_list|)
expr_stmt|;
block|}
name|put
operator|.
name|setClusterIds
argument_list|(
name|clusterIds
argument_list|)
expr_stmt|;
name|context
operator|.
name|write
argument_list|(
name|key
argument_list|,
name|put
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|delete
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
name|durability
operator|!=
literal|null
condition|)
block|{
name|delete
operator|.
name|setDurability
argument_list|(
name|durability
argument_list|)
expr_stmt|;
block|}
name|delete
operator|.
name|setClusterIds
argument_list|(
name|clusterIds
argument_list|)
expr_stmt|;
name|context
operator|.
name|write
argument_list|(
name|key
argument_list|,
name|delete
argument_list|)
expr_stmt|;
block|}
block|}
specifier|protected
name|void
name|addPutToKv
parameter_list|(
name|Put
name|put
parameter_list|,
name|Cell
name|kv
parameter_list|)
throws|throws
name|IOException
block|{
name|put
operator|.
name|add
argument_list|(
name|kv
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|setup
parameter_list|(
name|Context
name|context
parameter_list|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Setting up "
operator|+
name|getClass
argument_list|()
operator|+
literal|" mapper."
argument_list|)
expr_stmt|;
name|Configuration
name|conf
init|=
name|context
operator|.
name|getConfiguration
argument_list|()
decl_stmt|;
name|cfRenameMap
operator|=
name|createCfRenameMap
argument_list|(
name|conf
argument_list|)
expr_stmt|;
name|filter
operator|=
name|instantiateFilter
argument_list|(
name|conf
argument_list|)
expr_stmt|;
name|String
name|durabilityStr
init|=
name|conf
operator|.
name|get
argument_list|(
name|WAL_DURABILITY
argument_list|)
decl_stmt|;
if|if
condition|(
name|durabilityStr
operator|!=
literal|null
condition|)
block|{
name|durability
operator|=
name|Durability
operator|.
name|valueOf
argument_list|(
name|durabilityStr
operator|.
name|toUpperCase
argument_list|(
name|Locale
operator|.
name|ROOT
argument_list|)
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"setting WAL durability to "
operator|+
name|durability
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"setting WAL durability to default."
argument_list|)
expr_stmt|;
block|}
comment|// TODO: This is kind of ugly doing setup of ZKW just to read the clusterid.
name|ZKWatcher
name|zkw
init|=
literal|null
decl_stmt|;
name|Exception
name|ex
init|=
literal|null
decl_stmt|;
try|try
block|{
name|zkw
operator|=
operator|new
name|ZKWatcher
argument_list|(
name|conf
argument_list|,
name|context
operator|.
name|getTaskAttemptID
argument_list|()
operator|.
name|toString
argument_list|()
argument_list|,
literal|null
argument_list|)
expr_stmt|;
name|clusterIds
operator|=
name|Collections
operator|.
name|singletonList
argument_list|(
name|ZKClusterId
operator|.
name|getUUIDForCluster
argument_list|(
name|zkw
argument_list|)
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|ZooKeeperConnectionException
name|e
parameter_list|)
block|{
name|ex
operator|=
name|e
expr_stmt|;
name|LOG
operator|.
name|error
argument_list|(
literal|"Problem connecting to ZooKeper during task setup"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|KeeperException
name|e
parameter_list|)
block|{
name|ex
operator|=
name|e
expr_stmt|;
name|LOG
operator|.
name|error
argument_list|(
literal|"Problem reading ZooKeeper data during task setup"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|ex
operator|=
name|e
expr_stmt|;
name|LOG
operator|.
name|error
argument_list|(
literal|"Problem setting up task"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
if|if
condition|(
name|zkw
operator|!=
literal|null
condition|)
name|zkw
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|clusterIds
operator|==
literal|null
condition|)
block|{
comment|// exit early if setup fails
throw|throw
operator|new
name|RuntimeException
argument_list|(
name|ex
argument_list|)
throw|;
block|}
block|}
block|}
comment|/**    * Create a {@link Filter} to apply to all incoming keys ({@link KeyValue KeyValues}) to    * optionally not include in the job output    * @param conf {@link Configuration} from which to load the filter    * @return the filter to use for the task, or<tt>null</tt> if no filter to should be used    * @throws IllegalArgumentException if the filter is misconfigured    */
specifier|public
specifier|static
name|Filter
name|instantiateFilter
parameter_list|(
name|Configuration
name|conf
parameter_list|)
block|{
comment|// get the filter, if it was configured
name|Class
argument_list|<
name|?
extends|extends
name|Filter
argument_list|>
name|filterClass
init|=
name|conf
operator|.
name|getClass
argument_list|(
name|FILTER_CLASS_CONF_KEY
argument_list|,
literal|null
argument_list|,
name|Filter
operator|.
name|class
argument_list|)
decl_stmt|;
if|if
condition|(
name|filterClass
operator|==
literal|null
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"No configured filter class, accepting all keyvalues."
argument_list|)
expr_stmt|;
return|return
literal|null
return|;
block|}
name|LOG
operator|.
name|debug
argument_list|(
literal|"Attempting to create filter:"
operator|+
name|filterClass
argument_list|)
expr_stmt|;
name|String
index|[]
name|filterArgs
init|=
name|conf
operator|.
name|getStrings
argument_list|(
name|FILTER_ARGS_CONF_KEY
argument_list|)
decl_stmt|;
name|ArrayList
argument_list|<
name|byte
index|[]
argument_list|>
name|quotedArgs
init|=
name|toQuotedByteArrays
argument_list|(
name|filterArgs
argument_list|)
decl_stmt|;
try|try
block|{
name|Method
name|m
init|=
name|filterClass
operator|.
name|getMethod
argument_list|(
literal|"createFilterFromArguments"
argument_list|,
name|ArrayList
operator|.
name|class
argument_list|)
decl_stmt|;
return|return
operator|(
name|Filter
operator|)
name|m
operator|.
name|invoke
argument_list|(
literal|null
argument_list|,
name|quotedArgs
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|IllegalAccessException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Couldn't instantiate filter!"
argument_list|,
name|e
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|RuntimeException
argument_list|(
name|e
argument_list|)
throw|;
block|}
catch|catch
parameter_list|(
name|SecurityException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Couldn't instantiate filter!"
argument_list|,
name|e
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|RuntimeException
argument_list|(
name|e
argument_list|)
throw|;
block|}
catch|catch
parameter_list|(
name|NoSuchMethodException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Couldn't instantiate filter!"
argument_list|,
name|e
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|RuntimeException
argument_list|(
name|e
argument_list|)
throw|;
block|}
catch|catch
parameter_list|(
name|IllegalArgumentException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Couldn't instantiate filter!"
argument_list|,
name|e
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|RuntimeException
argument_list|(
name|e
argument_list|)
throw|;
block|}
catch|catch
parameter_list|(
name|InvocationTargetException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Couldn't instantiate filter!"
argument_list|,
name|e
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|RuntimeException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
specifier|private
specifier|static
name|ArrayList
argument_list|<
name|byte
index|[]
argument_list|>
name|toQuotedByteArrays
parameter_list|(
name|String
modifier|...
name|stringArgs
parameter_list|)
block|{
name|ArrayList
argument_list|<
name|byte
index|[]
argument_list|>
name|quotedArgs
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
for|for
control|(
name|String
name|stringArg
range|:
name|stringArgs
control|)
block|{
comment|// all the filters' instantiation methods expected quoted args since they are coming from
comment|// the shell, so add them here, though it shouldn't really be needed :-/
name|quotedArgs
operator|.
name|add
argument_list|(
name|Bytes
operator|.
name|toBytes
argument_list|(
literal|"'"
operator|+
name|stringArg
operator|+
literal|"'"
argument_list|)
argument_list|)
expr_stmt|;
block|}
return|return
name|quotedArgs
return|;
block|}
comment|/**    * Attempt to filter out the keyvalue    * @param c {@link Cell} on which to apply the filter    * @return<tt>null</tt> if the key should not be written, otherwise returns the original    *         {@link Cell}    */
specifier|public
specifier|static
name|Cell
name|filterKv
parameter_list|(
name|Filter
name|filter
parameter_list|,
name|Cell
name|c
parameter_list|)
throws|throws
name|IOException
block|{
comment|// apply the filter and skip this kv if the filter doesn't apply
if|if
condition|(
name|filter
operator|!=
literal|null
condition|)
block|{
name|Filter
operator|.
name|ReturnCode
name|code
init|=
name|filter
operator|.
name|filterCell
argument_list|(
name|c
argument_list|)
decl_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|trace
argument_list|(
literal|"Filter returned:"
operator|+
name|code
operator|+
literal|" for the cell:"
operator|+
name|c
argument_list|)
expr_stmt|;
block|}
comment|// if its not an accept type, then skip this kv
if|if
condition|(
operator|!
operator|(
name|code
operator|.
name|equals
argument_list|(
name|Filter
operator|.
name|ReturnCode
operator|.
name|INCLUDE
argument_list|)
operator|||
name|code
operator|.
name|equals
argument_list|(
name|Filter
operator|.
name|ReturnCode
operator|.
name|INCLUDE_AND_NEXT_COL
argument_list|)
operator|)
condition|)
block|{
return|return
literal|null
return|;
block|}
block|}
return|return
name|c
return|;
block|}
comment|// helper: create a new KeyValue based on CF rename map
specifier|private
specifier|static
name|Cell
name|convertKv
parameter_list|(
name|Cell
name|kv
parameter_list|,
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|byte
index|[]
argument_list|>
name|cfRenameMap
parameter_list|)
block|{
if|if
condition|(
name|cfRenameMap
operator|!=
literal|null
condition|)
block|{
comment|// If there's a rename mapping for this CF, create a new KeyValue
name|byte
index|[]
name|newCfName
init|=
name|cfRenameMap
operator|.
name|get
argument_list|(
name|CellUtil
operator|.
name|cloneFamily
argument_list|(
name|kv
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|newCfName
operator|!=
literal|null
condition|)
block|{
name|kv
operator|=
operator|new
name|KeyValue
argument_list|(
name|kv
operator|.
name|getRowArray
argument_list|()
argument_list|,
comment|// row buffer
name|kv
operator|.
name|getRowOffset
argument_list|()
argument_list|,
comment|// row offset
name|kv
operator|.
name|getRowLength
argument_list|()
argument_list|,
comment|// row length
name|newCfName
argument_list|,
comment|// CF buffer
literal|0
argument_list|,
comment|// CF offset
name|newCfName
operator|.
name|length
argument_list|,
comment|// CF length
name|kv
operator|.
name|getQualifierArray
argument_list|()
argument_list|,
comment|// qualifier buffer
name|kv
operator|.
name|getQualifierOffset
argument_list|()
argument_list|,
comment|// qualifier offset
name|kv
operator|.
name|getQualifierLength
argument_list|()
argument_list|,
comment|// qualifier length
name|kv
operator|.
name|getTimestamp
argument_list|()
argument_list|,
comment|// timestamp
name|KeyValue
operator|.
name|Type
operator|.
name|codeToType
argument_list|(
name|kv
operator|.
name|getTypeByte
argument_list|()
argument_list|)
argument_list|,
comment|// KV Type
name|kv
operator|.
name|getValueArray
argument_list|()
argument_list|,
comment|// value buffer
name|kv
operator|.
name|getValueOffset
argument_list|()
argument_list|,
comment|// value offset
name|kv
operator|.
name|getValueLength
argument_list|()
argument_list|)
expr_stmt|;
comment|// value length
block|}
block|}
return|return
name|kv
return|;
block|}
comment|// helper: make a map from sourceCfName to destCfName by parsing a config key
specifier|private
specifier|static
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|byte
index|[]
argument_list|>
name|createCfRenameMap
parameter_list|(
name|Configuration
name|conf
parameter_list|)
block|{
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|byte
index|[]
argument_list|>
name|cfRenameMap
init|=
literal|null
decl_stmt|;
name|String
name|allMappingsPropVal
init|=
name|conf
operator|.
name|get
argument_list|(
name|CF_RENAME_PROP
argument_list|)
decl_stmt|;
if|if
condition|(
name|allMappingsPropVal
operator|!=
literal|null
condition|)
block|{
comment|// The conf value format should be sourceCf1:destCf1,sourceCf2:destCf2,...
name|String
index|[]
name|allMappings
init|=
name|allMappingsPropVal
operator|.
name|split
argument_list|(
literal|","
argument_list|)
decl_stmt|;
for|for
control|(
name|String
name|mapping
range|:
name|allMappings
control|)
block|{
if|if
condition|(
name|cfRenameMap
operator|==
literal|null
condition|)
block|{
name|cfRenameMap
operator|=
operator|new
name|TreeMap
argument_list|<>
argument_list|(
name|Bytes
operator|.
name|BYTES_COMPARATOR
argument_list|)
expr_stmt|;
block|}
name|String
index|[]
name|srcAndDest
init|=
name|mapping
operator|.
name|split
argument_list|(
literal|":"
argument_list|)
decl_stmt|;
if|if
condition|(
name|srcAndDest
operator|.
name|length
operator|!=
literal|2
condition|)
block|{
continue|continue;
block|}
name|cfRenameMap
operator|.
name|put
argument_list|(
name|srcAndDest
index|[
literal|0
index|]
operator|.
name|getBytes
argument_list|()
argument_list|,
name|srcAndDest
index|[
literal|1
index|]
operator|.
name|getBytes
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|cfRenameMap
return|;
block|}
comment|/**    *<p>Sets a configuration property with key {@link #CF_RENAME_PROP} in conf that tells    * the mapper how to rename column families.    *    *<p>Alternately, instead of calling this function, you could set the configuration key    * {@link #CF_RENAME_PROP} yourself. The value should look like    *<pre>srcCf1:destCf1,srcCf2:destCf2,....</pre>. This would have the same effect on    * the mapper behavior.    *    * @param conf the Configuration in which the {@link #CF_RENAME_PROP} key will be    *  set    * @param renameMap a mapping from source CF names to destination CF names    */
specifier|static
specifier|public
name|void
name|configureCfRenaming
parameter_list|(
name|Configuration
name|conf
parameter_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|renameMap
parameter_list|)
block|{
name|StringBuilder
name|sb
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|entry
range|:
name|renameMap
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|String
name|sourceCf
init|=
name|entry
operator|.
name|getKey
argument_list|()
decl_stmt|;
name|String
name|destCf
init|=
name|entry
operator|.
name|getValue
argument_list|()
decl_stmt|;
if|if
condition|(
name|sourceCf
operator|.
name|contains
argument_list|(
literal|":"
argument_list|)
operator|||
name|sourceCf
operator|.
name|contains
argument_list|(
literal|","
argument_list|)
operator|||
name|destCf
operator|.
name|contains
argument_list|(
literal|":"
argument_list|)
operator|||
name|destCf
operator|.
name|contains
argument_list|(
literal|","
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"Illegal character in CF names: "
operator|+
name|sourceCf
operator|+
literal|", "
operator|+
name|destCf
argument_list|)
throw|;
block|}
if|if
condition|(
name|sb
operator|.
name|length
argument_list|()
operator|!=
literal|0
condition|)
block|{
name|sb
operator|.
name|append
argument_list|(
literal|","
argument_list|)
expr_stmt|;
block|}
name|sb
operator|.
name|append
argument_list|(
name|sourceCf
operator|+
literal|":"
operator|+
name|destCf
argument_list|)
expr_stmt|;
block|}
name|conf
operator|.
name|set
argument_list|(
name|CF_RENAME_PROP
argument_list|,
name|sb
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|/**    * Add a Filter to be instantiated on import    * @param conf Configuration to update (will be passed to the job)    * @param clazz {@link Filter} subclass to instantiate on the server.    * @param filterArgs List of arguments to pass to the filter on instantiation    */
specifier|public
specifier|static
name|void
name|addFilterAndArguments
parameter_list|(
name|Configuration
name|conf
parameter_list|,
name|Class
argument_list|<
name|?
extends|extends
name|Filter
argument_list|>
name|clazz
parameter_list|,
name|List
argument_list|<
name|String
argument_list|>
name|filterArgs
parameter_list|)
throws|throws
name|IOException
block|{
name|conf
operator|.
name|set
argument_list|(
name|Import
operator|.
name|FILTER_CLASS_CONF_KEY
argument_list|,
name|clazz
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
name|conf
operator|.
name|setStrings
argument_list|(
name|Import
operator|.
name|FILTER_ARGS_CONF_KEY
argument_list|,
name|filterArgs
operator|.
name|toArray
argument_list|(
operator|new
name|String
index|[
name|filterArgs
operator|.
name|size
argument_list|()
index|]
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|/**    * Sets up the actual job.    * @param conf The current configuration.    * @param args The command line parameters.    * @return The newly created job.    * @throws IOException When setting up the job fails.    */
specifier|public
specifier|static
name|Job
name|createSubmittableJob
parameter_list|(
name|Configuration
name|conf
parameter_list|,
name|String
index|[]
name|args
parameter_list|)
throws|throws
name|IOException
block|{
name|TableName
name|tableName
init|=
name|TableName
operator|.
name|valueOf
argument_list|(
name|args
index|[
literal|0
index|]
argument_list|)
decl_stmt|;
name|conf
operator|.
name|set
argument_list|(
name|TABLE_NAME
argument_list|,
name|tableName
operator|.
name|getNameAsString
argument_list|()
argument_list|)
expr_stmt|;
name|Path
name|inputDir
init|=
operator|new
name|Path
argument_list|(
name|args
index|[
literal|1
index|]
argument_list|)
decl_stmt|;
name|Job
name|job
init|=
name|Job
operator|.
name|getInstance
argument_list|(
name|conf
argument_list|,
name|conf
operator|.
name|get
argument_list|(
name|JOB_NAME_CONF_KEY
argument_list|,
name|NAME
operator|+
literal|"_"
operator|+
name|tableName
argument_list|)
argument_list|)
decl_stmt|;
name|job
operator|.
name|setJarByClass
argument_list|(
name|Importer
operator|.
name|class
argument_list|)
expr_stmt|;
name|FileInputFormat
operator|.
name|setInputPaths
argument_list|(
name|job
argument_list|,
name|inputDir
argument_list|)
expr_stmt|;
name|job
operator|.
name|setInputFormatClass
argument_list|(
name|SequenceFileInputFormat
operator|.
name|class
argument_list|)
expr_stmt|;
name|String
name|hfileOutPath
init|=
name|conf
operator|.
name|get
argument_list|(
name|BULK_OUTPUT_CONF_KEY
argument_list|)
decl_stmt|;
comment|// make sure we get the filter in the jars
try|try
block|{
name|Class
argument_list|<
name|?
extends|extends
name|Filter
argument_list|>
name|filter
init|=
name|conf
operator|.
name|getClass
argument_list|(
name|FILTER_CLASS_CONF_KEY
argument_list|,
literal|null
argument_list|,
name|Filter
operator|.
name|class
argument_list|)
decl_stmt|;
if|if
condition|(
name|filter
operator|!=
literal|null
condition|)
block|{
name|TableMapReduceUtil
operator|.
name|addDependencyJarsForClasses
argument_list|(
name|conf
argument_list|,
name|filter
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|e
argument_list|)
throw|;
block|}
if|if
condition|(
name|hfileOutPath
operator|!=
literal|null
operator|&&
name|conf
operator|.
name|getBoolean
argument_list|(
name|HAS_LARGE_RESULT
argument_list|,
literal|false
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Use Large Result!!"
argument_list|)
expr_stmt|;
try|try
init|(
name|Connection
name|conn
init|=
name|ConnectionFactory
operator|.
name|createConnection
argument_list|(
name|conf
argument_list|)
init|;           Table table = conn.getTable(tableName)
empty_stmt|;
name|RegionLocator
name|regionLocator
init|=
name|conn
operator|.
name|getRegionLocator
argument_list|(
name|tableName
argument_list|)
init|)
block|{
name|HFileOutputFormat2
operator|.
name|configureIncrementalLoad
argument_list|(
name|job
argument_list|,
name|table
operator|.
name|getDescriptor
argument_list|()
argument_list|,
name|regionLocator
argument_list|)
expr_stmt|;
name|job
operator|.
name|setMapperClass
argument_list|(
name|CellSortImporter
operator|.
name|class
argument_list|)
expr_stmt|;
name|job
operator|.
name|setReducerClass
argument_list|(
name|CellReducer
operator|.
name|class
argument_list|)
expr_stmt|;
name|Path
name|outputDir
init|=
operator|new
name|Path
argument_list|(
name|hfileOutPath
argument_list|)
decl_stmt|;
name|FileOutputFormat
operator|.
name|setOutputPath
argument_list|(
name|job
argument_list|,
name|outputDir
argument_list|)
expr_stmt|;
name|job
operator|.
name|setMapOutputKeyClass
argument_list|(
name|CellWritableComparable
operator|.
name|class
argument_list|)
expr_stmt|;
name|job
operator|.
name|setMapOutputValueClass
argument_list|(
name|MapReduceExtendedCell
operator|.
name|class
argument_list|)
expr_stmt|;
name|job
operator|.
name|getConfiguration
argument_list|()
operator|.
name|setClass
argument_list|(
literal|"mapreduce.job.output.key.comparator.class"
argument_list|,
name|CellWritableComparable
operator|.
name|CellWritableComparator
operator|.
name|class
argument_list|,
name|RawComparator
operator|.
name|class
argument_list|)
expr_stmt|;
name|Path
name|partitionsPath
init|=
operator|new
name|Path
argument_list|(
name|TotalOrderPartitioner
operator|.
name|getPartitionFile
argument_list|(
name|job
operator|.
name|getConfiguration
argument_list|()
argument_list|)
argument_list|)
decl_stmt|;
name|FileSystem
name|fs
init|=
name|FileSystem
operator|.
name|get
argument_list|(
name|job
operator|.
name|getConfiguration
argument_list|()
argument_list|)
decl_stmt|;
name|fs
operator|.
name|deleteOnExit
argument_list|(
name|partitionsPath
argument_list|)
expr_stmt|;
name|job
operator|.
name|setPartitionerClass
argument_list|(
name|CellWritableComparablePartitioner
operator|.
name|class
argument_list|)
expr_stmt|;
name|job
operator|.
name|setNumReduceTasks
argument_list|(
name|regionLocator
operator|.
name|getStartKeys
argument_list|()
operator|.
name|length
argument_list|)
expr_stmt|;
name|TableMapReduceUtil
operator|.
name|addDependencyJarsForClasses
argument_list|(
name|job
operator|.
name|getConfiguration
argument_list|()
argument_list|,
name|org
operator|.
name|apache
operator|.
name|hbase
operator|.
name|thirdparty
operator|.
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Preconditions
operator|.
name|class
argument_list|)
expr_stmt|;
block|}
block|}
elseif|else
if|if
condition|(
name|hfileOutPath
operator|!=
literal|null
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"writing to hfiles for bulk load."
argument_list|)
expr_stmt|;
name|job
operator|.
name|setMapperClass
argument_list|(
name|CellImporter
operator|.
name|class
argument_list|)
expr_stmt|;
try|try
init|(
name|Connection
name|conn
init|=
name|ConnectionFactory
operator|.
name|createConnection
argument_list|(
name|conf
argument_list|)
init|;           Table table = conn.getTable(tableName)
empty_stmt|;
name|RegionLocator
name|regionLocator
init|=
name|conn
operator|.
name|getRegionLocator
argument_list|(
name|tableName
argument_list|)
init|)
block|{
name|job
operator|.
name|setReducerClass
argument_list|(
name|CellSortReducer
operator|.
name|class
argument_list|)
expr_stmt|;
name|Path
name|outputDir
init|=
operator|new
name|Path
argument_list|(
name|hfileOutPath
argument_list|)
decl_stmt|;
name|FileOutputFormat
operator|.
name|setOutputPath
argument_list|(
name|job
argument_list|,
name|outputDir
argument_list|)
expr_stmt|;
name|job
operator|.
name|setMapOutputKeyClass
argument_list|(
name|ImmutableBytesWritable
operator|.
name|class
argument_list|)
expr_stmt|;
name|job
operator|.
name|setMapOutputValueClass
argument_list|(
name|MapReduceExtendedCell
operator|.
name|class
argument_list|)
expr_stmt|;
name|HFileOutputFormat2
operator|.
name|configureIncrementalLoad
argument_list|(
name|job
argument_list|,
name|table
operator|.
name|getDescriptor
argument_list|()
argument_list|,
name|regionLocator
argument_list|)
expr_stmt|;
name|TableMapReduceUtil
operator|.
name|addDependencyJarsForClasses
argument_list|(
name|job
operator|.
name|getConfiguration
argument_list|()
argument_list|,
name|org
operator|.
name|apache
operator|.
name|hbase
operator|.
name|thirdparty
operator|.
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Preconditions
operator|.
name|class
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"writing directly to table from Mapper."
argument_list|)
expr_stmt|;
comment|// No reducers.  Just write straight to table.  Call initTableReducerJob
comment|// because it sets up the TableOutputFormat.
name|job
operator|.
name|setMapperClass
argument_list|(
name|Importer
operator|.
name|class
argument_list|)
expr_stmt|;
name|TableMapReduceUtil
operator|.
name|initTableReducerJob
argument_list|(
name|tableName
operator|.
name|getNameAsString
argument_list|()
argument_list|,
literal|null
argument_list|,
name|job
argument_list|)
expr_stmt|;
name|job
operator|.
name|setNumReduceTasks
argument_list|(
literal|0
argument_list|)
expr_stmt|;
block|}
return|return
name|job
return|;
block|}
comment|/*    * @param errorMsg Error message.  Can be null.    */
specifier|private
specifier|static
name|void
name|usage
parameter_list|(
specifier|final
name|String
name|errorMsg
parameter_list|)
block|{
if|if
condition|(
name|errorMsg
operator|!=
literal|null
operator|&&
name|errorMsg
operator|.
name|length
argument_list|()
operator|>
literal|0
condition|)
block|{
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|"ERROR: "
operator|+
name|errorMsg
argument_list|)
expr_stmt|;
block|}
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|"Usage: Import [options]<tablename><inputdir>"
argument_list|)
expr_stmt|;
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|"By default Import will load data directly into HBase. To instead generate"
argument_list|)
expr_stmt|;
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|"HFiles of data to prepare for a bulk data load, pass the option:"
argument_list|)
expr_stmt|;
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|"  -D"
operator|+
name|BULK_OUTPUT_CONF_KEY
operator|+
literal|"=/path/for/output"
argument_list|)
expr_stmt|;
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|"If there is a large result that includes too much Cell "
operator|+
literal|"whitch can occur OOME caused by the memery sort in reducer, pass the option:"
argument_list|)
expr_stmt|;
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|"  -D"
operator|+
name|HAS_LARGE_RESULT
operator|+
literal|"=true"
argument_list|)
expr_stmt|;
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|" To apply a generic org.apache.hadoop.hbase.filter.Filter to the input, use"
argument_list|)
expr_stmt|;
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|"  -D"
operator|+
name|FILTER_CLASS_CONF_KEY
operator|+
literal|"=<name of filter class>"
argument_list|)
expr_stmt|;
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|"  -D"
operator|+
name|FILTER_ARGS_CONF_KEY
operator|+
literal|"=<comma separated list of args for filter"
argument_list|)
expr_stmt|;
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|" NOTE: The filter will be applied BEFORE doing key renames via the "
operator|+
name|CF_RENAME_PROP
operator|+
literal|" property. Futher, filters will only use the"
operator|+
literal|" Filter#filterRowKey(byte[] buffer, int offset, int length) method to identify "
operator|+
literal|" whether the current row needs to be ignored completely for processing and "
operator|+
literal|" Filter#filterCell(Cell) method to determine if the Cell should be added;"
operator|+
literal|" Filter.ReturnCode#INCLUDE and #INCLUDE_AND_NEXT_COL will be considered as including"
operator|+
literal|" the Cell."
argument_list|)
expr_stmt|;
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|"To import data exported from HBase 0.94, use"
argument_list|)
expr_stmt|;
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|"  -Dhbase.import.version=0.94"
argument_list|)
expr_stmt|;
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|"  -D "
operator|+
name|JOB_NAME_CONF_KEY
operator|+
literal|"=jobName - use the specified mapreduce job name for the import"
argument_list|)
expr_stmt|;
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|"For performance consider the following options:\n"
operator|+
literal|"  -Dmapreduce.map.speculative=false\n"
operator|+
literal|"  -Dmapreduce.reduce.speculative=false\n"
operator|+
literal|"  -D"
operator|+
name|WAL_DURABILITY
operator|+
literal|"=<Used while writing data to hbase."
operator|+
literal|" Allowed values are the supported durability values"
operator|+
literal|" like SKIP_WAL/ASYNC_WAL/SYNC_WAL/...>"
argument_list|)
expr_stmt|;
block|}
comment|/**    * If the durability is set to {@link Durability#SKIP_WAL} and the data is imported to hbase, we    * need to flush all the regions of the table as the data is held in memory and is also not    * present in the Write Ahead Log to replay in scenarios of a crash. This method flushes all the    * regions of the table in the scenarios of import data to hbase with {@link Durability#SKIP_WAL}    */
specifier|public
specifier|static
name|void
name|flushRegionsIfNecessary
parameter_list|(
name|Configuration
name|conf
parameter_list|)
throws|throws
name|IOException
throws|,
name|InterruptedException
block|{
name|String
name|tableName
init|=
name|conf
operator|.
name|get
argument_list|(
name|TABLE_NAME
argument_list|)
decl_stmt|;
name|Admin
name|hAdmin
init|=
literal|null
decl_stmt|;
name|Connection
name|connection
init|=
literal|null
decl_stmt|;
name|String
name|durability
init|=
name|conf
operator|.
name|get
argument_list|(
name|WAL_DURABILITY
argument_list|)
decl_stmt|;
comment|// Need to flush if the data is written to hbase and skip wal is enabled.
if|if
condition|(
name|conf
operator|.
name|get
argument_list|(
name|BULK_OUTPUT_CONF_KEY
argument_list|)
operator|==
literal|null
operator|&&
name|durability
operator|!=
literal|null
operator|&&
name|Durability
operator|.
name|SKIP_WAL
operator|.
name|name
argument_list|()
operator|.
name|equalsIgnoreCase
argument_list|(
name|durability
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Flushing all data that skipped the WAL."
argument_list|)
expr_stmt|;
try|try
block|{
name|connection
operator|=
name|ConnectionFactory
operator|.
name|createConnection
argument_list|(
name|conf
argument_list|)
expr_stmt|;
name|hAdmin
operator|=
name|connection
operator|.
name|getAdmin
argument_list|()
expr_stmt|;
name|hAdmin
operator|.
name|flush
argument_list|(
name|TableName
operator|.
name|valueOf
argument_list|(
name|tableName
argument_list|)
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
if|if
condition|(
name|hAdmin
operator|!=
literal|null
condition|)
block|{
name|hAdmin
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|connection
operator|!=
literal|null
condition|)
block|{
name|connection
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
block|}
block|}
block|}
annotation|@
name|Override
specifier|public
name|int
name|run
parameter_list|(
name|String
index|[]
name|args
parameter_list|)
throws|throws
name|Exception
block|{
if|if
condition|(
name|args
operator|.
name|length
operator|<
literal|2
condition|)
block|{
name|usage
argument_list|(
literal|"Wrong number of arguments: "
operator|+
name|args
operator|.
name|length
argument_list|)
expr_stmt|;
return|return
operator|-
literal|1
return|;
block|}
name|String
name|inputVersionString
init|=
name|System
operator|.
name|getProperty
argument_list|(
name|ResultSerialization
operator|.
name|IMPORT_FORMAT_VER
argument_list|)
decl_stmt|;
if|if
condition|(
name|inputVersionString
operator|!=
literal|null
condition|)
block|{
name|getConf
argument_list|()
operator|.
name|set
argument_list|(
name|ResultSerialization
operator|.
name|IMPORT_FORMAT_VER
argument_list|,
name|inputVersionString
argument_list|)
expr_stmt|;
block|}
name|Job
name|job
init|=
name|createSubmittableJob
argument_list|(
name|getConf
argument_list|()
argument_list|,
name|args
argument_list|)
decl_stmt|;
name|boolean
name|isJobSuccessful
init|=
name|job
operator|.
name|waitForCompletion
argument_list|(
literal|true
argument_list|)
decl_stmt|;
if|if
condition|(
name|isJobSuccessful
condition|)
block|{
comment|// Flush all the regions of the table
name|flushRegionsIfNecessary
argument_list|(
name|getConf
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|long
name|inputRecords
init|=
name|job
operator|.
name|getCounters
argument_list|()
operator|.
name|findCounter
argument_list|(
name|TaskCounter
operator|.
name|MAP_INPUT_RECORDS
argument_list|)
operator|.
name|getValue
argument_list|()
decl_stmt|;
name|long
name|outputRecords
init|=
name|job
operator|.
name|getCounters
argument_list|()
operator|.
name|findCounter
argument_list|(
name|TaskCounter
operator|.
name|MAP_OUTPUT_RECORDS
argument_list|)
operator|.
name|getValue
argument_list|()
decl_stmt|;
if|if
condition|(
name|outputRecords
operator|<
name|inputRecords
condition|)
block|{
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|"Warning, not all records were imported (maybe filtered out)."
argument_list|)
expr_stmt|;
if|if
condition|(
name|outputRecords
operator|==
literal|0
condition|)
block|{
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|"If the data was exported from HBase 0.94 "
operator|+
literal|"consider using -Dhbase.import.version=0.94."
argument_list|)
expr_stmt|;
block|}
block|}
return|return
operator|(
name|isJobSuccessful
condition|?
literal|0
else|:
literal|1
operator|)
return|;
block|}
comment|/**    * Main entry point.    * @param args The command line parameters.    * @throws Exception When running the job fails.    */
specifier|public
specifier|static
name|void
name|main
parameter_list|(
name|String
index|[]
name|args
parameter_list|)
throws|throws
name|Exception
block|{
name|int
name|errCode
init|=
name|ToolRunner
operator|.
name|run
argument_list|(
name|HBaseConfiguration
operator|.
name|create
argument_list|()
argument_list|,
operator|new
name|Import
argument_list|()
argument_list|,
name|args
argument_list|)
decl_stmt|;
name|System
operator|.
name|exit
argument_list|(
name|errCode
argument_list|)
expr_stmt|;
block|}
block|}
end_class

end_unit

