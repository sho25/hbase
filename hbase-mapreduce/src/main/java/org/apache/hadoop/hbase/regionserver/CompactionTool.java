begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
package|;
end_package

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|Store
operator|.
name|PRIORITY_USER
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|LinkedList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Optional
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Set
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configured
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FSDataOutputStream
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileStatus
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HBaseConfiguration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HBaseInterfaceAudience
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HDFSBlocksDistribution
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|RegionInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|TableDescriptor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|mapreduce
operator|.
name|JobUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|mapreduce
operator|.
name|TableMapReduceUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|compactions
operator|.
name|CompactionContext
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|compactions
operator|.
name|CompactionLifeCycleTracker
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|throttle
operator|.
name|NoLimitThroughputController
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|Bytes
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|EnvironmentEdgeManager
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|FSTableDescriptors
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|FSUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|LongWritable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|NullWritable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|Text
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|InputSplit
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|Job
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|JobContext
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|Mapper
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|lib
operator|.
name|input
operator|.
name|FileSplit
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|lib
operator|.
name|input
operator|.
name|TextInputFormat
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|lib
operator|.
name|output
operator|.
name|NullOutputFormat
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|LineReader
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|Tool
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|ToolRunner
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|yetus
operator|.
name|audience
operator|.
name|InterfaceAudience
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|Logger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|LoggerFactory
import|;
end_import

begin_comment
comment|/*  * The CompactionTool allows to execute a compaction specifying a:  *<ul>  *<li>table folder (all regions and families will be compacted)  *<li>region folder (all families in the region will be compacted)  *<li>family folder (the store files will be compacted)  *</ul>  */
end_comment

begin_class
annotation|@
name|InterfaceAudience
operator|.
name|LimitedPrivate
argument_list|(
name|HBaseInterfaceAudience
operator|.
name|TOOLS
argument_list|)
specifier|public
class|class
name|CompactionTool
extends|extends
name|Configured
implements|implements
name|Tool
block|{
specifier|private
specifier|static
specifier|final
name|Logger
name|LOG
init|=
name|LoggerFactory
operator|.
name|getLogger
argument_list|(
name|CompactionTool
operator|.
name|class
argument_list|)
decl_stmt|;
specifier|private
specifier|final
specifier|static
name|String
name|CONF_TMP_DIR
init|=
literal|"hbase.tmp.dir"
decl_stmt|;
specifier|private
specifier|final
specifier|static
name|String
name|CONF_COMPACT_ONCE
init|=
literal|"hbase.compactiontool.compact.once"
decl_stmt|;
specifier|private
specifier|final
specifier|static
name|String
name|CONF_COMPACT_MAJOR
init|=
literal|"hbase.compactiontool.compact.major"
decl_stmt|;
specifier|private
specifier|final
specifier|static
name|String
name|CONF_DELETE_COMPACTED
init|=
literal|"hbase.compactiontool.delete"
decl_stmt|;
comment|/**    * Class responsible to execute the Compaction on the specified path.    * The path can be a table, region or family directory.    */
specifier|private
specifier|static
class|class
name|CompactionWorker
block|{
specifier|private
specifier|final
name|boolean
name|deleteCompacted
decl_stmt|;
specifier|private
specifier|final
name|Configuration
name|conf
decl_stmt|;
specifier|private
specifier|final
name|FileSystem
name|fs
decl_stmt|;
specifier|private
specifier|final
name|Path
name|tmpDir
decl_stmt|;
specifier|public
name|CompactionWorker
parameter_list|(
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Configuration
name|conf
parameter_list|)
block|{
name|this
operator|.
name|conf
operator|=
name|conf
expr_stmt|;
name|this
operator|.
name|deleteCompacted
operator|=
name|conf
operator|.
name|getBoolean
argument_list|(
name|CONF_DELETE_COMPACTED
argument_list|,
literal|false
argument_list|)
expr_stmt|;
name|this
operator|.
name|tmpDir
operator|=
operator|new
name|Path
argument_list|(
name|conf
operator|.
name|get
argument_list|(
name|CONF_TMP_DIR
argument_list|)
argument_list|)
expr_stmt|;
name|this
operator|.
name|fs
operator|=
name|fs
expr_stmt|;
block|}
comment|/**      * Execute the compaction on the specified path.      *      * @param path Directory path on which to run compaction.      * @param compactOnce Execute just a single step of compaction.      * @param major Request major compaction.      */
specifier|public
name|void
name|compact
parameter_list|(
specifier|final
name|Path
name|path
parameter_list|,
specifier|final
name|boolean
name|compactOnce
parameter_list|,
specifier|final
name|boolean
name|major
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|isFamilyDir
argument_list|(
name|fs
argument_list|,
name|path
argument_list|)
condition|)
block|{
name|Path
name|regionDir
init|=
name|path
operator|.
name|getParent
argument_list|()
decl_stmt|;
name|Path
name|tableDir
init|=
name|regionDir
operator|.
name|getParent
argument_list|()
decl_stmt|;
name|TableDescriptor
name|htd
init|=
name|FSTableDescriptors
operator|.
name|getTableDescriptorFromFs
argument_list|(
name|fs
argument_list|,
name|tableDir
argument_list|)
decl_stmt|;
name|RegionInfo
name|hri
init|=
name|HRegionFileSystem
operator|.
name|loadRegionInfoFileContent
argument_list|(
name|fs
argument_list|,
name|regionDir
argument_list|)
decl_stmt|;
name|compactStoreFiles
argument_list|(
name|tableDir
argument_list|,
name|htd
argument_list|,
name|hri
argument_list|,
name|path
operator|.
name|getName
argument_list|()
argument_list|,
name|compactOnce
argument_list|,
name|major
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|isRegionDir
argument_list|(
name|fs
argument_list|,
name|path
argument_list|)
condition|)
block|{
name|Path
name|tableDir
init|=
name|path
operator|.
name|getParent
argument_list|()
decl_stmt|;
name|TableDescriptor
name|htd
init|=
name|FSTableDescriptors
operator|.
name|getTableDescriptorFromFs
argument_list|(
name|fs
argument_list|,
name|tableDir
argument_list|)
decl_stmt|;
name|compactRegion
argument_list|(
name|tableDir
argument_list|,
name|htd
argument_list|,
name|path
argument_list|,
name|compactOnce
argument_list|,
name|major
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|isTableDir
argument_list|(
name|fs
argument_list|,
name|path
argument_list|)
condition|)
block|{
name|compactTable
argument_list|(
name|path
argument_list|,
name|compactOnce
argument_list|,
name|major
argument_list|)
expr_stmt|;
block|}
else|else
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Specified path is not a table, region or family directory. path="
operator|+
name|path
argument_list|)
throw|;
block|}
block|}
specifier|private
name|void
name|compactTable
parameter_list|(
specifier|final
name|Path
name|tableDir
parameter_list|,
specifier|final
name|boolean
name|compactOnce
parameter_list|,
specifier|final
name|boolean
name|major
parameter_list|)
throws|throws
name|IOException
block|{
name|TableDescriptor
name|htd
init|=
name|FSTableDescriptors
operator|.
name|getTableDescriptorFromFs
argument_list|(
name|fs
argument_list|,
name|tableDir
argument_list|)
decl_stmt|;
for|for
control|(
name|Path
name|regionDir
range|:
name|FSUtils
operator|.
name|getRegionDirs
argument_list|(
name|fs
argument_list|,
name|tableDir
argument_list|)
control|)
block|{
name|compactRegion
argument_list|(
name|tableDir
argument_list|,
name|htd
argument_list|,
name|regionDir
argument_list|,
name|compactOnce
argument_list|,
name|major
argument_list|)
expr_stmt|;
block|}
block|}
specifier|private
name|void
name|compactRegion
parameter_list|(
specifier|final
name|Path
name|tableDir
parameter_list|,
specifier|final
name|TableDescriptor
name|htd
parameter_list|,
specifier|final
name|Path
name|regionDir
parameter_list|,
specifier|final
name|boolean
name|compactOnce
parameter_list|,
specifier|final
name|boolean
name|major
parameter_list|)
throws|throws
name|IOException
block|{
name|RegionInfo
name|hri
init|=
name|HRegionFileSystem
operator|.
name|loadRegionInfoFileContent
argument_list|(
name|fs
argument_list|,
name|regionDir
argument_list|)
decl_stmt|;
for|for
control|(
name|Path
name|familyDir
range|:
name|FSUtils
operator|.
name|getFamilyDirs
argument_list|(
name|fs
argument_list|,
name|regionDir
argument_list|)
control|)
block|{
name|compactStoreFiles
argument_list|(
name|tableDir
argument_list|,
name|htd
argument_list|,
name|hri
argument_list|,
name|familyDir
operator|.
name|getName
argument_list|()
argument_list|,
name|compactOnce
argument_list|,
name|major
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**      * Execute the actual compaction job.      * If the compact once flag is not specified, execute the compaction until      * no more compactions are needed. Uses the Configuration settings provided.      */
specifier|private
name|void
name|compactStoreFiles
parameter_list|(
specifier|final
name|Path
name|tableDir
parameter_list|,
specifier|final
name|TableDescriptor
name|htd
parameter_list|,
specifier|final
name|RegionInfo
name|hri
parameter_list|,
specifier|final
name|String
name|familyName
parameter_list|,
specifier|final
name|boolean
name|compactOnce
parameter_list|,
specifier|final
name|boolean
name|major
parameter_list|)
throws|throws
name|IOException
block|{
name|HStore
name|store
init|=
name|getStore
argument_list|(
name|conf
argument_list|,
name|fs
argument_list|,
name|tableDir
argument_list|,
name|htd
argument_list|,
name|hri
argument_list|,
name|familyName
argument_list|,
name|tmpDir
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Compact table="
operator|+
name|htd
operator|.
name|getTableName
argument_list|()
operator|+
literal|" region="
operator|+
name|hri
operator|.
name|getRegionNameAsString
argument_list|()
operator|+
literal|" family="
operator|+
name|familyName
argument_list|)
expr_stmt|;
if|if
condition|(
name|major
condition|)
block|{
name|store
operator|.
name|triggerMajorCompaction
argument_list|()
expr_stmt|;
block|}
do|do
block|{
name|Optional
argument_list|<
name|CompactionContext
argument_list|>
name|compaction
init|=
name|store
operator|.
name|requestCompaction
argument_list|(
name|PRIORITY_USER
argument_list|,
name|CompactionLifeCycleTracker
operator|.
name|DUMMY
argument_list|,
literal|null
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|compaction
operator|.
name|isPresent
argument_list|()
condition|)
block|{
break|break;
block|}
name|List
argument_list|<
name|HStoreFile
argument_list|>
name|storeFiles
init|=
name|store
operator|.
name|compact
argument_list|(
name|compaction
operator|.
name|get
argument_list|()
argument_list|,
name|NoLimitThroughputController
operator|.
name|INSTANCE
argument_list|,
literal|null
argument_list|)
decl_stmt|;
if|if
condition|(
name|storeFiles
operator|!=
literal|null
operator|&&
operator|!
name|storeFiles
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
if|if
condition|(
name|deleteCompacted
condition|)
block|{
for|for
control|(
name|HStoreFile
name|storeFile
range|:
name|storeFiles
control|)
block|{
name|fs
operator|.
name|delete
argument_list|(
name|storeFile
operator|.
name|getPath
argument_list|()
argument_list|,
literal|false
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
do|while
condition|(
name|store
operator|.
name|needsCompaction
argument_list|()
operator|&&
operator|!
name|compactOnce
condition|)
do|;
comment|//We need to close the store properly, to make sure it will archive compacted files
name|store
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
comment|/**      * Create a "mock" HStore that uses the tmpDir specified by the user and      * the store dir to compact as source.      */
specifier|private
specifier|static
name|HStore
name|getStore
parameter_list|(
specifier|final
name|Configuration
name|conf
parameter_list|,
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Path
name|tableDir
parameter_list|,
specifier|final
name|TableDescriptor
name|htd
parameter_list|,
specifier|final
name|RegionInfo
name|hri
parameter_list|,
specifier|final
name|String
name|familyName
parameter_list|,
specifier|final
name|Path
name|tempDir
parameter_list|)
throws|throws
name|IOException
block|{
name|HRegionFileSystem
name|regionFs
init|=
operator|new
name|HRegionFileSystem
argument_list|(
name|conf
argument_list|,
name|fs
argument_list|,
name|tableDir
argument_list|,
name|hri
argument_list|)
block|{
annotation|@
name|Override
specifier|public
name|Path
name|getTempDir
parameter_list|()
block|{
return|return
name|tempDir
return|;
block|}
block|}
decl_stmt|;
name|HRegion
name|region
init|=
operator|new
name|HRegion
argument_list|(
name|regionFs
argument_list|,
literal|null
argument_list|,
name|conf
argument_list|,
name|htd
argument_list|,
literal|null
argument_list|)
decl_stmt|;
return|return
operator|new
name|HStore
argument_list|(
name|region
argument_list|,
name|htd
operator|.
name|getColumnFamily
argument_list|(
name|Bytes
operator|.
name|toBytes
argument_list|(
name|familyName
argument_list|)
argument_list|)
argument_list|,
name|conf
argument_list|,
literal|false
argument_list|)
return|;
block|}
block|}
specifier|private
specifier|static
name|boolean
name|isRegionDir
parameter_list|(
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Path
name|path
parameter_list|)
throws|throws
name|IOException
block|{
name|Path
name|regionInfo
init|=
operator|new
name|Path
argument_list|(
name|path
argument_list|,
name|HRegionFileSystem
operator|.
name|REGION_INFO_FILE
argument_list|)
decl_stmt|;
return|return
name|fs
operator|.
name|exists
argument_list|(
name|regionInfo
argument_list|)
return|;
block|}
specifier|private
specifier|static
name|boolean
name|isTableDir
parameter_list|(
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Path
name|path
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|FSTableDescriptors
operator|.
name|getTableInfoPath
argument_list|(
name|fs
argument_list|,
name|path
argument_list|)
operator|!=
literal|null
return|;
block|}
specifier|private
specifier|static
name|boolean
name|isFamilyDir
parameter_list|(
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Path
name|path
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|isRegionDir
argument_list|(
name|fs
argument_list|,
name|path
operator|.
name|getParent
argument_list|()
argument_list|)
return|;
block|}
specifier|private
specifier|static
class|class
name|CompactionMapper
extends|extends
name|Mapper
argument_list|<
name|LongWritable
argument_list|,
name|Text
argument_list|,
name|NullWritable
argument_list|,
name|NullWritable
argument_list|>
block|{
specifier|private
name|CompactionWorker
name|compactor
init|=
literal|null
decl_stmt|;
specifier|private
name|boolean
name|compactOnce
init|=
literal|false
decl_stmt|;
specifier|private
name|boolean
name|major
init|=
literal|false
decl_stmt|;
annotation|@
name|Override
specifier|public
name|void
name|setup
parameter_list|(
name|Context
name|context
parameter_list|)
block|{
name|Configuration
name|conf
init|=
name|context
operator|.
name|getConfiguration
argument_list|()
decl_stmt|;
name|compactOnce
operator|=
name|conf
operator|.
name|getBoolean
argument_list|(
name|CONF_COMPACT_ONCE
argument_list|,
literal|false
argument_list|)
expr_stmt|;
name|major
operator|=
name|conf
operator|.
name|getBoolean
argument_list|(
name|CONF_COMPACT_MAJOR
argument_list|,
literal|false
argument_list|)
expr_stmt|;
try|try
block|{
name|FileSystem
name|fs
init|=
name|FileSystem
operator|.
name|get
argument_list|(
name|conf
argument_list|)
decl_stmt|;
name|this
operator|.
name|compactor
operator|=
operator|new
name|CompactionWorker
argument_list|(
name|fs
argument_list|,
name|conf
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"Could not get the input FileSystem"
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|void
name|map
parameter_list|(
name|LongWritable
name|key
parameter_list|,
name|Text
name|value
parameter_list|,
name|Context
name|context
parameter_list|)
throws|throws
name|InterruptedException
throws|,
name|IOException
block|{
name|Path
name|path
init|=
operator|new
name|Path
argument_list|(
name|value
operator|.
name|toString
argument_list|()
argument_list|)
decl_stmt|;
name|this
operator|.
name|compactor
operator|.
name|compact
argument_list|(
name|path
argument_list|,
name|compactOnce
argument_list|,
name|major
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Input format that uses store files block location as input split locality.    */
specifier|private
specifier|static
class|class
name|CompactionInputFormat
extends|extends
name|TextInputFormat
block|{
annotation|@
name|Override
specifier|protected
name|boolean
name|isSplitable
parameter_list|(
name|JobContext
name|context
parameter_list|,
name|Path
name|file
parameter_list|)
block|{
return|return
literal|true
return|;
block|}
comment|/**      * Returns a split for each store files directory using the block location      * of each file as locality reference.      */
annotation|@
name|Override
specifier|public
name|List
argument_list|<
name|InputSplit
argument_list|>
name|getSplits
parameter_list|(
name|JobContext
name|job
parameter_list|)
throws|throws
name|IOException
block|{
name|List
argument_list|<
name|InputSplit
argument_list|>
name|splits
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|FileStatus
argument_list|>
name|files
init|=
name|listStatus
argument_list|(
name|job
argument_list|)
decl_stmt|;
name|Text
name|key
init|=
operator|new
name|Text
argument_list|()
decl_stmt|;
for|for
control|(
name|FileStatus
name|file
range|:
name|files
control|)
block|{
name|Path
name|path
init|=
name|file
operator|.
name|getPath
argument_list|()
decl_stmt|;
name|FileSystem
name|fs
init|=
name|path
operator|.
name|getFileSystem
argument_list|(
name|job
operator|.
name|getConfiguration
argument_list|()
argument_list|)
decl_stmt|;
name|LineReader
name|reader
init|=
operator|new
name|LineReader
argument_list|(
name|fs
operator|.
name|open
argument_list|(
name|path
argument_list|)
argument_list|)
decl_stmt|;
name|long
name|pos
init|=
literal|0
decl_stmt|;
name|int
name|n
decl_stmt|;
try|try
block|{
while|while
condition|(
operator|(
name|n
operator|=
name|reader
operator|.
name|readLine
argument_list|(
name|key
argument_list|)
operator|)
operator|>
literal|0
condition|)
block|{
name|String
index|[]
name|hosts
init|=
name|getStoreDirHosts
argument_list|(
name|fs
argument_list|,
name|path
argument_list|)
decl_stmt|;
name|splits
operator|.
name|add
argument_list|(
operator|new
name|FileSplit
argument_list|(
name|path
argument_list|,
name|pos
argument_list|,
name|n
argument_list|,
name|hosts
argument_list|)
argument_list|)
expr_stmt|;
name|pos
operator|+=
name|n
expr_stmt|;
block|}
block|}
finally|finally
block|{
name|reader
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
block|}
return|return
name|splits
return|;
block|}
comment|/**      * return the top hosts of the store files, used by the Split      */
specifier|private
specifier|static
name|String
index|[]
name|getStoreDirHosts
parameter_list|(
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Path
name|path
parameter_list|)
throws|throws
name|IOException
block|{
name|FileStatus
index|[]
name|files
init|=
name|FSUtils
operator|.
name|listStatus
argument_list|(
name|fs
argument_list|,
name|path
argument_list|)
decl_stmt|;
if|if
condition|(
name|files
operator|==
literal|null
condition|)
block|{
return|return
operator|new
name|String
index|[]
block|{}
return|;
block|}
name|HDFSBlocksDistribution
name|hdfsBlocksDistribution
init|=
operator|new
name|HDFSBlocksDistribution
argument_list|()
decl_stmt|;
for|for
control|(
name|FileStatus
name|hfileStatus
range|:
name|files
control|)
block|{
name|HDFSBlocksDistribution
name|storeFileBlocksDistribution
init|=
name|FSUtils
operator|.
name|computeHDFSBlocksDistribution
argument_list|(
name|fs
argument_list|,
name|hfileStatus
argument_list|,
literal|0
argument_list|,
name|hfileStatus
operator|.
name|getLen
argument_list|()
argument_list|)
decl_stmt|;
name|hdfsBlocksDistribution
operator|.
name|add
argument_list|(
name|storeFileBlocksDistribution
argument_list|)
expr_stmt|;
block|}
name|List
argument_list|<
name|String
argument_list|>
name|hosts
init|=
name|hdfsBlocksDistribution
operator|.
name|getTopHosts
argument_list|()
decl_stmt|;
return|return
name|hosts
operator|.
name|toArray
argument_list|(
operator|new
name|String
index|[
name|hosts
operator|.
name|size
argument_list|()
index|]
argument_list|)
return|;
block|}
comment|/**      * Create the input file for the given directories to compact.      * The file is a TextFile with each line corrisponding to a      * store files directory to compact.      */
specifier|public
specifier|static
name|void
name|createInputFile
parameter_list|(
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Path
name|path
parameter_list|,
specifier|final
name|Set
argument_list|<
name|Path
argument_list|>
name|toCompactDirs
parameter_list|)
throws|throws
name|IOException
block|{
comment|// Extract the list of store dirs
name|List
argument_list|<
name|Path
argument_list|>
name|storeDirs
init|=
operator|new
name|LinkedList
argument_list|<>
argument_list|()
decl_stmt|;
for|for
control|(
name|Path
name|compactDir
range|:
name|toCompactDirs
control|)
block|{
if|if
condition|(
name|isFamilyDir
argument_list|(
name|fs
argument_list|,
name|compactDir
argument_list|)
condition|)
block|{
name|storeDirs
operator|.
name|add
argument_list|(
name|compactDir
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|isRegionDir
argument_list|(
name|fs
argument_list|,
name|compactDir
argument_list|)
condition|)
block|{
for|for
control|(
name|Path
name|familyDir
range|:
name|FSUtils
operator|.
name|getFamilyDirs
argument_list|(
name|fs
argument_list|,
name|compactDir
argument_list|)
control|)
block|{
name|storeDirs
operator|.
name|add
argument_list|(
name|familyDir
argument_list|)
expr_stmt|;
block|}
block|}
elseif|else
if|if
condition|(
name|isTableDir
argument_list|(
name|fs
argument_list|,
name|compactDir
argument_list|)
condition|)
block|{
comment|// Lookup regions
for|for
control|(
name|Path
name|regionDir
range|:
name|FSUtils
operator|.
name|getRegionDirs
argument_list|(
name|fs
argument_list|,
name|compactDir
argument_list|)
control|)
block|{
for|for
control|(
name|Path
name|familyDir
range|:
name|FSUtils
operator|.
name|getFamilyDirs
argument_list|(
name|fs
argument_list|,
name|regionDir
argument_list|)
control|)
block|{
name|storeDirs
operator|.
name|add
argument_list|(
name|familyDir
argument_list|)
expr_stmt|;
block|}
block|}
block|}
else|else
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Specified path is not a table, region or family directory. path="
operator|+
name|compactDir
argument_list|)
throw|;
block|}
block|}
comment|// Write Input File
name|FSDataOutputStream
name|stream
init|=
name|fs
operator|.
name|create
argument_list|(
name|path
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Create input file="
operator|+
name|path
operator|+
literal|" with "
operator|+
name|storeDirs
operator|.
name|size
argument_list|()
operator|+
literal|" dirs to compact."
argument_list|)
expr_stmt|;
try|try
block|{
specifier|final
name|byte
index|[]
name|newLine
init|=
name|Bytes
operator|.
name|toBytes
argument_list|(
literal|"\n"
argument_list|)
decl_stmt|;
for|for
control|(
name|Path
name|storeDir
range|:
name|storeDirs
control|)
block|{
name|stream
operator|.
name|write
argument_list|(
name|Bytes
operator|.
name|toBytes
argument_list|(
name|storeDir
operator|.
name|toString
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
name|stream
operator|.
name|write
argument_list|(
name|newLine
argument_list|)
expr_stmt|;
block|}
block|}
finally|finally
block|{
name|stream
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
block|}
block|}
comment|/**    * Execute compaction, using a Map-Reduce job.    */
specifier|private
name|int
name|doMapReduce
parameter_list|(
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Set
argument_list|<
name|Path
argument_list|>
name|toCompactDirs
parameter_list|,
specifier|final
name|boolean
name|compactOnce
parameter_list|,
specifier|final
name|boolean
name|major
parameter_list|)
throws|throws
name|Exception
block|{
name|Configuration
name|conf
init|=
name|getConf
argument_list|()
decl_stmt|;
name|conf
operator|.
name|setBoolean
argument_list|(
name|CONF_COMPACT_ONCE
argument_list|,
name|compactOnce
argument_list|)
expr_stmt|;
name|conf
operator|.
name|setBoolean
argument_list|(
name|CONF_COMPACT_MAJOR
argument_list|,
name|major
argument_list|)
expr_stmt|;
name|Job
name|job
init|=
operator|new
name|Job
argument_list|(
name|conf
argument_list|)
decl_stmt|;
name|job
operator|.
name|setJobName
argument_list|(
literal|"CompactionTool"
argument_list|)
expr_stmt|;
name|job
operator|.
name|setJarByClass
argument_list|(
name|CompactionTool
operator|.
name|class
argument_list|)
expr_stmt|;
name|job
operator|.
name|setMapperClass
argument_list|(
name|CompactionMapper
operator|.
name|class
argument_list|)
expr_stmt|;
name|job
operator|.
name|setInputFormatClass
argument_list|(
name|CompactionInputFormat
operator|.
name|class
argument_list|)
expr_stmt|;
name|job
operator|.
name|setOutputFormatClass
argument_list|(
name|NullOutputFormat
operator|.
name|class
argument_list|)
expr_stmt|;
name|job
operator|.
name|setMapSpeculativeExecution
argument_list|(
literal|false
argument_list|)
expr_stmt|;
name|job
operator|.
name|setNumReduceTasks
argument_list|(
literal|0
argument_list|)
expr_stmt|;
comment|// add dependencies (including HBase ones)
name|TableMapReduceUtil
operator|.
name|addDependencyJars
argument_list|(
name|job
argument_list|)
expr_stmt|;
name|Path
name|stagingDir
init|=
name|JobUtil
operator|.
name|getStagingDir
argument_list|(
name|conf
argument_list|)
decl_stmt|;
try|try
block|{
comment|// Create input file with the store dirs
name|Path
name|inputPath
init|=
operator|new
name|Path
argument_list|(
name|stagingDir
argument_list|,
literal|"compact-"
operator|+
name|EnvironmentEdgeManager
operator|.
name|currentTime
argument_list|()
argument_list|)
decl_stmt|;
name|CompactionInputFormat
operator|.
name|createInputFile
argument_list|(
name|fs
argument_list|,
name|inputPath
argument_list|,
name|toCompactDirs
argument_list|)
expr_stmt|;
name|CompactionInputFormat
operator|.
name|addInputPath
argument_list|(
name|job
argument_list|,
name|inputPath
argument_list|)
expr_stmt|;
comment|// Initialize credential for secure cluster
name|TableMapReduceUtil
operator|.
name|initCredentials
argument_list|(
name|job
argument_list|)
expr_stmt|;
comment|// Start the MR Job and wait
return|return
name|job
operator|.
name|waitForCompletion
argument_list|(
literal|true
argument_list|)
condition|?
literal|0
else|:
literal|1
return|;
block|}
finally|finally
block|{
name|fs
operator|.
name|delete
argument_list|(
name|stagingDir
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Execute compaction, from this client, one path at the time.    */
specifier|private
name|int
name|doClient
parameter_list|(
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Set
argument_list|<
name|Path
argument_list|>
name|toCompactDirs
parameter_list|,
specifier|final
name|boolean
name|compactOnce
parameter_list|,
specifier|final
name|boolean
name|major
parameter_list|)
throws|throws
name|IOException
block|{
name|CompactionWorker
name|worker
init|=
operator|new
name|CompactionWorker
argument_list|(
name|fs
argument_list|,
name|getConf
argument_list|()
argument_list|)
decl_stmt|;
for|for
control|(
name|Path
name|path
range|:
name|toCompactDirs
control|)
block|{
name|worker
operator|.
name|compact
argument_list|(
name|path
argument_list|,
name|compactOnce
argument_list|,
name|major
argument_list|)
expr_stmt|;
block|}
return|return
literal|0
return|;
block|}
annotation|@
name|Override
specifier|public
name|int
name|run
parameter_list|(
name|String
index|[]
name|args
parameter_list|)
throws|throws
name|Exception
block|{
name|Set
argument_list|<
name|Path
argument_list|>
name|toCompactDirs
init|=
operator|new
name|HashSet
argument_list|<>
argument_list|()
decl_stmt|;
name|boolean
name|compactOnce
init|=
literal|false
decl_stmt|;
name|boolean
name|major
init|=
literal|false
decl_stmt|;
name|boolean
name|mapred
init|=
literal|false
decl_stmt|;
name|Configuration
name|conf
init|=
name|getConf
argument_list|()
decl_stmt|;
name|FileSystem
name|fs
init|=
name|FileSystem
operator|.
name|get
argument_list|(
name|conf
argument_list|)
decl_stmt|;
try|try
block|{
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|args
operator|.
name|length
condition|;
operator|++
name|i
control|)
block|{
name|String
name|opt
init|=
name|args
index|[
name|i
index|]
decl_stmt|;
if|if
condition|(
name|opt
operator|.
name|equals
argument_list|(
literal|"-compactOnce"
argument_list|)
condition|)
block|{
name|compactOnce
operator|=
literal|true
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|opt
operator|.
name|equals
argument_list|(
literal|"-major"
argument_list|)
condition|)
block|{
name|major
operator|=
literal|true
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|opt
operator|.
name|equals
argument_list|(
literal|"-mapred"
argument_list|)
condition|)
block|{
name|mapred
operator|=
literal|true
expr_stmt|;
block|}
elseif|else
if|if
condition|(
operator|!
name|opt
operator|.
name|startsWith
argument_list|(
literal|"-"
argument_list|)
condition|)
block|{
name|Path
name|path
init|=
operator|new
name|Path
argument_list|(
name|opt
argument_list|)
decl_stmt|;
name|FileStatus
name|status
init|=
name|fs
operator|.
name|getFileStatus
argument_list|(
name|path
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|status
operator|.
name|isDirectory
argument_list|()
condition|)
block|{
name|printUsage
argument_list|(
literal|"Specified path is not a directory. path="
operator|+
name|path
argument_list|)
expr_stmt|;
return|return
literal|1
return|;
block|}
name|toCompactDirs
operator|.
name|add
argument_list|(
name|path
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|printUsage
argument_list|()
expr_stmt|;
block|}
block|}
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|printUsage
argument_list|(
name|e
operator|.
name|getMessage
argument_list|()
argument_list|)
expr_stmt|;
return|return
literal|1
return|;
block|}
if|if
condition|(
name|toCompactDirs
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|printUsage
argument_list|(
literal|"No directories to compact specified."
argument_list|)
expr_stmt|;
return|return
literal|1
return|;
block|}
comment|// Execute compaction!
if|if
condition|(
name|mapred
condition|)
block|{
return|return
name|doMapReduce
argument_list|(
name|fs
argument_list|,
name|toCompactDirs
argument_list|,
name|compactOnce
argument_list|,
name|major
argument_list|)
return|;
block|}
else|else
block|{
return|return
name|doClient
argument_list|(
name|fs
argument_list|,
name|toCompactDirs
argument_list|,
name|compactOnce
argument_list|,
name|major
argument_list|)
return|;
block|}
block|}
specifier|private
name|void
name|printUsage
parameter_list|()
block|{
name|printUsage
argument_list|(
literal|null
argument_list|)
expr_stmt|;
block|}
specifier|private
name|void
name|printUsage
parameter_list|(
specifier|final
name|String
name|message
parameter_list|)
block|{
if|if
condition|(
name|message
operator|!=
literal|null
operator|&&
name|message
operator|.
name|length
argument_list|()
operator|>
literal|0
condition|)
block|{
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
name|message
argument_list|)
expr_stmt|;
block|}
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|"Usage: java "
operator|+
name|this
operator|.
name|getClass
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|" \\"
argument_list|)
expr_stmt|;
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|"  [-compactOnce] [-major] [-mapred] [-D<property=value>]* files..."
argument_list|)
expr_stmt|;
name|System
operator|.
name|err
operator|.
name|println
argument_list|()
expr_stmt|;
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|"Options:"
argument_list|)
expr_stmt|;
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|" mapred         Use MapReduce to run compaction."
argument_list|)
expr_stmt|;
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|" compactOnce    Execute just one compaction step. (default: while needed)"
argument_list|)
expr_stmt|;
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|" major          Trigger major compaction."
argument_list|)
expr_stmt|;
name|System
operator|.
name|err
operator|.
name|println
argument_list|()
expr_stmt|;
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|"Note: -D properties will be applied to the conf used. "
argument_list|)
expr_stmt|;
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|"For example: "
argument_list|)
expr_stmt|;
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|" To stop delete of compacted file, pass -D"
operator|+
name|CONF_DELETE_COMPACTED
operator|+
literal|"=false"
argument_list|)
expr_stmt|;
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|" To set tmp dir, pass -D"
operator|+
name|CONF_TMP_DIR
operator|+
literal|"=ALTERNATE_DIR"
argument_list|)
expr_stmt|;
name|System
operator|.
name|err
operator|.
name|println
argument_list|()
expr_stmt|;
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|"Examples:"
argument_list|)
expr_stmt|;
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|" To compact the full 'TestTable' using MapReduce:"
argument_list|)
expr_stmt|;
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|" $ hbase "
operator|+
name|this
operator|.
name|getClass
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|" -mapred hdfs://hbase/data/default/TestTable"
argument_list|)
expr_stmt|;
name|System
operator|.
name|err
operator|.
name|println
argument_list|()
expr_stmt|;
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|" To compact column family 'x' of the table 'TestTable' region 'abc':"
argument_list|)
expr_stmt|;
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|" $ hbase "
operator|+
name|this
operator|.
name|getClass
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|" hdfs://hbase/data/default/TestTable/abc/x"
argument_list|)
expr_stmt|;
block|}
specifier|public
specifier|static
name|void
name|main
parameter_list|(
name|String
index|[]
name|args
parameter_list|)
throws|throws
name|Exception
block|{
name|System
operator|.
name|exit
argument_list|(
name|ToolRunner
operator|.
name|run
argument_list|(
name|HBaseConfiguration
operator|.
name|create
argument_list|()
argument_list|,
operator|new
name|CompactionTool
argument_list|()
argument_list|,
name|args
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
end_class

end_unit

