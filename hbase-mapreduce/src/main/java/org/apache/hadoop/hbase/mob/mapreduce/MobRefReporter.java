begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  *  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|mob
operator|.
name|mapreduce
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Arrays
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Base64
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Set
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|UUID
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configured
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileStatus
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|Cell
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HBaseConfiguration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HConstants
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|TableName
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|Admin
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|ColumnFamilyDescriptor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|Connection
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|ConnectionFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|Result
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|Scan
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|TableDescriptor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|HFileLink
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|ImmutableBytesWritable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|mapreduce
operator|.
name|TableInputFormat
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|mapreduce
operator|.
name|TableMapReduceUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|mapreduce
operator|.
name|TableMapper
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|mob
operator|.
name|MobConstants
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|mob
operator|.
name|MobUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|Bytes
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|EnvironmentEdgeManager
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|FSUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|HFileArchiveUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|Pair
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|Text
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|Job
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|Reducer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|lib
operator|.
name|output
operator|.
name|TextOutputFormat
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|security
operator|.
name|UserGroupInformation
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|Tool
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|ToolRunner
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|yetus
operator|.
name|audience
operator|.
name|InterfaceAudience
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|Logger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|LoggerFactory
import|;
end_import

begin_comment
comment|/**  * Scans a given table + CF for all mob reference cells to get the list of backing mob files.  * For each referenced file we attempt to verify that said file is on the FileSystem in a place  * that the MOB system will look when attempting to resolve the actual value.  *  * The job includes counters that can help provide a rough sketch of the mob data.  *  *<pre>  * Map-Reduce Framework  *         Map input records=10000  * ...  *         Reduce output records=99  * ...  * CELLS PER ROW  *         Number of rows with 1s of cells per row=10000  * MOB  *         NUM_CELLS=52364  * PROBLEM  *         Affected rows=338  *         Problem MOB files=2  * ROWS WITH PROBLEMS PER FILE  *         Number of HFiles with 100s of affected rows=2  * SIZES OF CELLS  *         Number of cells with size in the 10,000s of bytes=627  *         Number of cells with size in the 100,000s of bytes=51392  *         Number of cells with size in the 1,000,000s of bytes=345  * SIZES OF ROWS  *         Number of rows with total size in the 100,000s of bytes=6838  *         Number of rows with total size in the 1,000,000s of bytes=3162  *</pre>  *  *   * Map-Reduce Framework:Map input records - the number of rows with mob references  *   * Map-Reduce Framework:Reduce output records - the number of unique hfiles referenced  *   * MOB:NUM_CELLS - the total number of mob reference cells  *   * PROBLEM:Affected rows - the number of rows that reference hfiles with an issue  *   * PROBLEM:Problem MOB files - the number of unique hfiles that have an issue  *   * CELLS PER ROW: - this counter group gives a histogram of the order of magnitude of the  *         number of cells in a given row by grouping by the number of digits used in each count.  *         This allows us to see more about the distribution of cells than what we can determine  *         with just the cell count and the row count. In this particular example we can see that  *         all of our rows have somewhere between 1 - 9 cells.  *   * ROWS WITH PROBLEMS PER FILE: - this counter group gives a histogram of the order of  *         magnitude of the number of rows in each of the hfiles with a problem. e.g. in the  *         example there are 2 hfiles and they each have the same order of magnitude number of rows,  *         specifically between 100 and 999.  *   * SIZES OF CELLS: - this counter group gives a histogram of the order of magnitude of  *         the size of mob values according to our reference cells. e.g. in the example above we  *         have cell sizes that are all between 10,000 bytes and 9,999,999 bytes. From this  *         histogram we can also see that _most_ cells are 100,000 - 999,000 bytes and the smaller  *         and bigger ones are outliers making up less than 2% of mob cells.  *   * SIZES OF ROWS: - this counter group gives a histogram of the order of magnitude of the  *         size of mob values across each row according to our reference cells. In the example above  *         we have rows that are are between 100,000 bytes and 9,999,999 bytes. We can also see that  *         about 2/3rd of our rows are 100,000 - 999,999 bytes.  *  * Generates a report that gives one file status per line, with tabs dividing fields.  *  *<pre>  * RESULT OF LOOKUP	FILE REF	comma seperated, base64 encoded rows when there's a problem  *</pre>  *  * e.g.  *  *<pre>  * MOB DIR	09c576e28a65ed2ead0004d192ffaa382019110184b30a1c7e034573bf8580aef8393402  * MISSING FILE    28e252d7f013973174750d483d358fa020191101f73536e7133f4cd3ab1065edf588d509        MmJiMjMyYzBiMTNjNzc0OTY1ZWY4NTU4ZjBmYmQ2MTUtNTIz,MmEzOGE0YTkzMTZjNDllNWE4MzM1MTdjNDVkMzEwNzAtODg=  *</pre>  *  * Possible results are listed; the first three indicate things are working properly.  *   * MOB DIR - the reference is in the normal MOB area for the given table and CF  *   * HLINK TO ARCHIVE FOR SAME TABLE - the reference is present in the archive area for this  *         table and CF  *   * HLINK TO ARCHIVE FOR OTHER TABLE - the reference is present in a different table and CF,  *         either in the MOB or archive areas (e.g. from a snapshot restore or clone)  *   * ARCHIVE WITH HLINK BUT NOT FROM OUR TABLE - the reference is currently present in the archive  *         area for this table and CF, but it is kept there because a _different_ table has a  *         reference to it (e.g. from a snapshot clone). If these other tables are removed then  *         the file will likely be deleted unless there is a snapshot also referencing it.  *   * ARCHIVE BUT NO HLINKS - the reference is currently present in the archive for this table and  *         CF, but there are no references present to prevent its removal. Unless it is newer than  *         the general TTL (default 5 minutes) or referenced in a snapshot it will be subject to  *         cleaning.  *   * ARCHIVE BUT FAILURE WHILE CHECKING HLINKS - Check the job logs to see why things failed while  *         looking for why this file is being kept around.  *   * MISSING FILE - We couldn't find the reference on the FileSystem. Either there is dataloss due  *         to a bug in the MOB storage system or the MOB storage is damaged but in an edge case that  *         allows it to work for now. You can verify which by doing a raw reference scan to get the  *         referenced hfile and check the underlying filesystem. See the ref guide section on mob  *         for details.  *   * HLINK BUT POINT TO MISSING FILE - There is a pointer in our mob area for this table and CF  *         to a file elsewhere on the FileSystem, however the file it points to no longer exists.  *   * MISSING FILE BUT FAILURE WHILE CHECKING HLINKS - We could not find the referenced file,  *         however you should check the job logs to see why we couldn't check to see if there is a  *         pointer to the referenced file in our archive or another table's archive or mob area.  *  */
end_comment

begin_class
annotation|@
name|InterfaceAudience
operator|.
name|Private
specifier|public
class|class
name|MobRefReporter
extends|extends
name|Configured
implements|implements
name|Tool
block|{
specifier|private
specifier|static
name|Logger
name|LOG
init|=
name|LoggerFactory
operator|.
name|getLogger
argument_list|(
name|MobRefReporter
operator|.
name|class
argument_list|)
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|String
name|NAME
init|=
literal|"mobrefs"
decl_stmt|;
specifier|static
specifier|final
name|String
name|REPORT_JOB_ID
init|=
literal|"mob.report.job.id"
decl_stmt|;
specifier|static
specifier|final
name|String
name|REPORT_START_DATETIME
init|=
literal|"mob.report.job.start"
decl_stmt|;
specifier|public
specifier|static
class|class
name|MobRefMapper
extends|extends
name|TableMapper
argument_list|<
name|Text
argument_list|,
name|ImmutableBytesWritable
argument_list|>
block|{
annotation|@
name|Override
specifier|public
name|void
name|map
parameter_list|(
name|ImmutableBytesWritable
name|r
parameter_list|,
name|Result
name|columns
parameter_list|,
name|Context
name|context
parameter_list|)
throws|throws
name|IOException
throws|,
name|InterruptedException
block|{
if|if
condition|(
name|columns
operator|==
literal|null
condition|)
block|{
return|return;
block|}
name|Cell
index|[]
name|cells
init|=
name|columns
operator|.
name|rawCells
argument_list|()
decl_stmt|;
if|if
condition|(
name|cells
operator|==
literal|null
operator|||
name|cells
operator|.
name|length
operator|==
literal|0
condition|)
block|{
return|return;
block|}
name|Set
argument_list|<
name|String
argument_list|>
name|files
init|=
operator|new
name|HashSet
argument_list|<>
argument_list|()
decl_stmt|;
name|long
name|count
init|=
literal|0
decl_stmt|;
name|long
name|size
init|=
literal|0
decl_stmt|;
for|for
control|(
name|Cell
name|c
range|:
name|cells
control|)
block|{
if|if
condition|(
name|MobUtils
operator|.
name|hasValidMobRefCellValue
argument_list|(
name|c
argument_list|)
condition|)
block|{
comment|// TODO confirm there aren't tags
name|String
name|fileName
init|=
name|MobUtils
operator|.
name|getMobFileName
argument_list|(
name|c
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|files
operator|.
name|contains
argument_list|(
name|fileName
argument_list|)
condition|)
block|{
name|context
operator|.
name|write
argument_list|(
operator|new
name|Text
argument_list|(
name|fileName
argument_list|)
argument_list|,
name|r
argument_list|)
expr_stmt|;
name|files
operator|.
name|add
argument_list|(
name|fileName
argument_list|)
expr_stmt|;
block|}
specifier|final
name|int
name|cellsize
init|=
name|MobUtils
operator|.
name|getMobValueLength
argument_list|(
name|c
argument_list|)
decl_stmt|;
name|context
operator|.
name|getCounter
argument_list|(
literal|"SIZES OF CELLS"
argument_list|,
literal|"Number of cells with size in the "
operator|+
name|log10GroupedString
argument_list|(
name|cellsize
argument_list|)
operator|+
literal|"s of bytes"
argument_list|)
operator|.
name|increment
argument_list|(
literal|1L
argument_list|)
expr_stmt|;
name|size
operator|+=
name|cellsize
expr_stmt|;
name|count
operator|++
expr_stmt|;
block|}
else|else
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"cell is not a mob ref, even though we asked for only refs. cell={}"
argument_list|,
name|c
argument_list|)
expr_stmt|;
block|}
block|}
name|context
operator|.
name|getCounter
argument_list|(
literal|"CELLS PER ROW"
argument_list|,
literal|"Number of rows with "
operator|+
name|log10GroupedString
argument_list|(
name|count
argument_list|)
operator|+
literal|"s of cells per row"
argument_list|)
operator|.
name|increment
argument_list|(
literal|1L
argument_list|)
expr_stmt|;
name|context
operator|.
name|getCounter
argument_list|(
literal|"SIZES OF ROWS"
argument_list|,
literal|"Number of rows with total size in the "
operator|+
name|log10GroupedString
argument_list|(
name|size
argument_list|)
operator|+
literal|"s of bytes"
argument_list|)
operator|.
name|increment
argument_list|(
literal|1L
argument_list|)
expr_stmt|;
name|context
operator|.
name|getCounter
argument_list|(
literal|"MOB"
argument_list|,
literal|"NUM_CELLS"
argument_list|)
operator|.
name|increment
argument_list|(
name|count
argument_list|)
expr_stmt|;
block|}
block|}
specifier|public
specifier|static
class|class
name|MobRefReducer
extends|extends
name|Reducer
argument_list|<
name|Text
argument_list|,
name|ImmutableBytesWritable
argument_list|,
name|Text
argument_list|,
name|Text
argument_list|>
block|{
name|TableName
name|table
decl_stmt|;
name|String
name|mobRegion
decl_stmt|;
name|Path
name|mob
decl_stmt|;
name|Path
name|archive
decl_stmt|;
name|String
name|seperator
decl_stmt|;
comment|/* Results that mean things are fine */
specifier|final
name|Text
name|OK_MOB_DIR
init|=
operator|new
name|Text
argument_list|(
literal|"MOB DIR"
argument_list|)
decl_stmt|;
specifier|final
name|Text
name|OK_HLINK_RESTORE
init|=
operator|new
name|Text
argument_list|(
literal|"HLINK TO ARCHIVE FOR SAME TABLE"
argument_list|)
decl_stmt|;
specifier|final
name|Text
name|OK_HLINK_CLONE
init|=
operator|new
name|Text
argument_list|(
literal|"HLINK TO ARCHIVE FOR OTHER TABLE"
argument_list|)
decl_stmt|;
comment|/* Results that mean something is incorrect */
specifier|final
name|Text
name|INCONSISTENT_ARCHIVE_BAD_LINK
init|=
operator|new
name|Text
argument_list|(
literal|"ARCHIVE WITH HLINK BUT NOT FROM OUR TABLE"
argument_list|)
decl_stmt|;
specifier|final
name|Text
name|INCONSISTENT_ARCHIVE_STALE
init|=
operator|new
name|Text
argument_list|(
literal|"ARCHIVE BUT NO HLINKS"
argument_list|)
decl_stmt|;
specifier|final
name|Text
name|INCONSISTENT_ARCHIVE_IOE
init|=
operator|new
name|Text
argument_list|(
literal|"ARCHIVE BUT FAILURE WHILE CHECKING HLINKS"
argument_list|)
decl_stmt|;
comment|/* Results that mean data is probably already gone */
specifier|final
name|Text
name|DATALOSS_MISSING
init|=
operator|new
name|Text
argument_list|(
literal|"MISSING FILE"
argument_list|)
decl_stmt|;
specifier|final
name|Text
name|DATALOSS_HLINK_DANGLING
init|=
operator|new
name|Text
argument_list|(
literal|"HLINK BUT POINTS TO MISSING FILE"
argument_list|)
decl_stmt|;
specifier|final
name|Text
name|DATALOSS_MISSING_IOE
init|=
operator|new
name|Text
argument_list|(
literal|"MISSING FILE BUT FAILURE WHILE CHECKING HLINKS"
argument_list|)
decl_stmt|;
specifier|final
name|Base64
operator|.
name|Encoder
name|base64
init|=
name|Base64
operator|.
name|getEncoder
argument_list|()
decl_stmt|;
annotation|@
name|Override
specifier|public
name|void
name|setup
parameter_list|(
name|Context
name|context
parameter_list|)
throws|throws
name|IOException
throws|,
name|InterruptedException
block|{
specifier|final
name|Configuration
name|conf
init|=
name|context
operator|.
name|getConfiguration
argument_list|()
decl_stmt|;
specifier|final
name|String
name|tableName
init|=
name|conf
operator|.
name|get
argument_list|(
name|TableInputFormat
operator|.
name|INPUT_TABLE
argument_list|)
decl_stmt|;
if|if
condition|(
literal|null
operator|==
name|tableName
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Job configuration did not include table."
argument_list|)
throw|;
block|}
name|table
operator|=
name|TableName
operator|.
name|valueOf
argument_list|(
name|tableName
argument_list|)
expr_stmt|;
name|mobRegion
operator|=
name|MobUtils
operator|.
name|getMobRegionInfo
argument_list|(
name|table
argument_list|)
operator|.
name|getEncodedName
argument_list|()
expr_stmt|;
specifier|final
name|String
name|family
init|=
name|conf
operator|.
name|get
argument_list|(
name|TableInputFormat
operator|.
name|SCAN_COLUMN_FAMILY
argument_list|)
decl_stmt|;
if|if
condition|(
literal|null
operator|==
name|family
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Job configuration did not include column family"
argument_list|)
throw|;
block|}
name|mob
operator|=
name|MobUtils
operator|.
name|getMobFamilyPath
argument_list|(
name|conf
argument_list|,
name|table
argument_list|,
name|family
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Using active mob area '{}'"
argument_list|,
name|mob
argument_list|)
expr_stmt|;
name|archive
operator|=
name|HFileArchiveUtil
operator|.
name|getStoreArchivePath
argument_list|(
name|conf
argument_list|,
name|table
argument_list|,
name|MobUtils
operator|.
name|getMobRegionInfo
argument_list|(
name|table
argument_list|)
operator|.
name|getEncodedName
argument_list|()
argument_list|,
name|family
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Using archive mob area '{}'"
argument_list|,
name|archive
argument_list|)
expr_stmt|;
name|seperator
operator|=
name|conf
operator|.
name|get
argument_list|(
name|TextOutputFormat
operator|.
name|SEPERATOR
argument_list|,
literal|"\t"
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|reduce
parameter_list|(
name|Text
name|key
parameter_list|,
name|Iterable
argument_list|<
name|ImmutableBytesWritable
argument_list|>
name|rows
parameter_list|,
name|Context
name|context
parameter_list|)
throws|throws
name|IOException
throws|,
name|InterruptedException
block|{
specifier|final
name|Configuration
name|conf
init|=
name|context
operator|.
name|getConfiguration
argument_list|()
decl_stmt|;
specifier|final
name|String
name|file
init|=
name|key
operator|.
name|toString
argument_list|()
decl_stmt|;
comment|// active mob area
if|if
condition|(
name|mob
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
operator|.
name|exists
argument_list|(
operator|new
name|Path
argument_list|(
name|mob
argument_list|,
name|file
argument_list|)
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Found file '{}' in mob area"
argument_list|,
name|file
argument_list|)
expr_stmt|;
name|context
operator|.
name|write
argument_list|(
name|OK_MOB_DIR
argument_list|,
name|key
argument_list|)
expr_stmt|;
comment|// archive area - is there an hlink back reference (from a snapshot from same table)
block|}
elseif|else
if|if
condition|(
name|archive
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
operator|.
name|exists
argument_list|(
operator|new
name|Path
argument_list|(
name|archive
argument_list|,
name|file
argument_list|)
argument_list|)
condition|)
block|{
name|Path
name|backRefDir
init|=
name|HFileLink
operator|.
name|getBackReferencesDir
argument_list|(
name|archive
argument_list|,
name|file
argument_list|)
decl_stmt|;
try|try
block|{
name|FileStatus
index|[]
name|backRefs
init|=
name|FSUtils
operator|.
name|listStatus
argument_list|(
name|archive
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
argument_list|,
name|backRefDir
argument_list|)
decl_stmt|;
if|if
condition|(
name|backRefs
operator|!=
literal|null
condition|)
block|{
name|boolean
name|found
init|=
literal|false
decl_stmt|;
for|for
control|(
name|FileStatus
name|backRef
range|:
name|backRefs
control|)
block|{
name|Pair
argument_list|<
name|TableName
argument_list|,
name|String
argument_list|>
name|refParts
init|=
name|HFileLink
operator|.
name|parseBackReferenceName
argument_list|(
name|backRef
operator|.
name|getPath
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|table
operator|.
name|equals
argument_list|(
name|refParts
operator|.
name|getFirst
argument_list|()
argument_list|)
operator|&&
name|mobRegion
operator|.
name|equals
argument_list|(
name|refParts
operator|.
name|getSecond
argument_list|()
argument_list|)
condition|)
block|{
name|Path
name|hlinkPath
init|=
name|HFileLink
operator|.
name|getHFileFromBackReference
argument_list|(
name|MobUtils
operator|.
name|getMobHome
argument_list|(
name|conf
argument_list|)
argument_list|,
name|backRef
operator|.
name|getPath
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|hlinkPath
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
operator|.
name|exists
argument_list|(
name|hlinkPath
argument_list|)
condition|)
block|{
name|found
operator|=
literal|true
expr_stmt|;
block|}
else|else
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Found file '{}' in archive area with a back reference to the mob area "
operator|+
literal|"for our table, but the mob area does not have a corresponding hfilelink."
argument_list|,
name|file
argument_list|)
expr_stmt|;
block|}
block|}
block|}
if|if
condition|(
name|found
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Found file '{}' in archive area. has proper hlink back references to "
operator|+
literal|"suggest it is from a restored snapshot for this table."
argument_list|,
name|file
argument_list|)
expr_stmt|;
name|context
operator|.
name|write
argument_list|(
name|OK_HLINK_RESTORE
argument_list|,
name|key
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Found file '{}' in archive area, but the hlink back references do not "
operator|+
literal|"properly point to the mob area for our table."
argument_list|,
name|file
argument_list|)
expr_stmt|;
name|context
operator|.
name|write
argument_list|(
name|INCONSISTENT_ARCHIVE_BAD_LINK
argument_list|,
name|encodeRows
argument_list|(
name|context
argument_list|,
name|key
argument_list|,
name|rows
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Found file '{}' in archive area, but there are no hlinks pointing to it. Not "
operator|+
literal|"yet used snapshot or an error."
argument_list|,
name|file
argument_list|)
expr_stmt|;
name|context
operator|.
name|write
argument_list|(
name|INCONSISTENT_ARCHIVE_STALE
argument_list|,
name|encodeRows
argument_list|(
name|context
argument_list|,
name|key
argument_list|,
name|rows
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Found file '{}' in archive area, but got an error while checking "
operator|+
literal|"on back references."
argument_list|,
name|file
argument_list|,
name|e
argument_list|)
expr_stmt|;
name|context
operator|.
name|write
argument_list|(
name|INCONSISTENT_ARCHIVE_IOE
argument_list|,
name|encodeRows
argument_list|(
name|context
argument_list|,
name|key
argument_list|,
name|rows
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
comment|// check for an hlink in the active mob area (from a snapshot of a different table)
try|try
block|{
comment|/**            * we are doing this ourselves instead of using FSUtils.getReferenceFilePaths because            * we know the mob region never splits, so we can only have HFileLink references            * and looking for just them is cheaper then listing everything.            *            * This glob should match the naming convention for HFileLinks to our referenced hfile.            * As simplified explanation those file names look like "table=region-hfile". For details            * see the {@link HFileLink#createHFileLinkName HFileLink implementation}.            */
name|FileStatus
index|[]
name|hlinks
init|=
name|mob
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
operator|.
name|globStatus
argument_list|(
operator|new
name|Path
argument_list|(
name|mob
operator|+
literal|"/*=*-"
operator|+
name|file
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|hlinks
operator|!=
literal|null
operator|&&
name|hlinks
operator|.
name|length
operator|!=
literal|0
condition|)
block|{
if|if
condition|(
name|hlinks
operator|.
name|length
operator|!=
literal|1
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Found file '{}' as hfilelinks in the mob area, but there are more than "
operator|+
literal|"one: {}"
argument_list|,
name|file
argument_list|,
name|Arrays
operator|.
name|deepToString
argument_list|(
name|hlinks
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|HFileLink
name|found
init|=
literal|null
decl_stmt|;
for|for
control|(
name|FileStatus
name|hlink
range|:
name|hlinks
control|)
block|{
name|HFileLink
name|tmp
init|=
name|HFileLink
operator|.
name|buildFromHFileLinkPattern
argument_list|(
name|conf
argument_list|,
name|hlink
operator|.
name|getPath
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|tmp
operator|.
name|exists
argument_list|(
name|archive
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
argument_list|)
condition|)
block|{
name|found
operator|=
name|tmp
expr_stmt|;
break|break;
block|}
else|else
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Target file does not exist for ref {}"
argument_list|,
name|tmp
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|found
operator|!=
literal|null
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Found file '{}' as a ref in the mob area: {}"
argument_list|,
name|file
argument_list|,
name|found
argument_list|)
expr_stmt|;
name|context
operator|.
name|write
argument_list|(
name|OK_HLINK_CLONE
argument_list|,
name|key
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Found file '{}' as ref(s) in the mob area but they do not point to an hfile"
operator|+
literal|" that exists."
argument_list|,
name|file
argument_list|)
expr_stmt|;
name|context
operator|.
name|write
argument_list|(
name|DATALOSS_HLINK_DANGLING
argument_list|,
name|encodeRows
argument_list|(
name|context
argument_list|,
name|key
argument_list|,
name|rows
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Could not find referenced file '{}'. See the docs on this tool."
argument_list|,
name|file
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Note that we don't have the server-side tag from the mob cells that says "
operator|+
literal|"what table the reference is originally from. So if the HFileLink in this table "
operator|+
literal|"is missing but the referenced file is still in the table from that tag, then "
operator|+
literal|"lookups of these impacted rows will work. Do a scan of the reference details "
operator|+
literal|"of the cell for the hfile name and then check the entire hbase install if this "
operator|+
literal|"table was made from a snapshot of another table. see the ref guide section on "
operator|+
literal|"mob for details."
argument_list|)
expr_stmt|;
name|context
operator|.
name|write
argument_list|(
name|DATALOSS_MISSING
argument_list|,
name|encodeRows
argument_list|(
name|context
argument_list|,
name|key
argument_list|,
name|rows
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Exception while checking mob area of our table for HFileLinks that point to {}"
argument_list|,
name|file
argument_list|,
name|e
argument_list|)
expr_stmt|;
name|context
operator|.
name|write
argument_list|(
name|DATALOSS_MISSING_IOE
argument_list|,
name|encodeRows
argument_list|(
name|context
argument_list|,
name|key
argument_list|,
name|rows
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|/**      * reuses the passed Text key. appends the configured seperator and then a comma seperated list      * of base64 encoded row keys      */
specifier|private
name|Text
name|encodeRows
parameter_list|(
name|Context
name|context
parameter_list|,
name|Text
name|key
parameter_list|,
name|Iterable
argument_list|<
name|ImmutableBytesWritable
argument_list|>
name|rows
parameter_list|)
throws|throws
name|IOException
block|{
name|StringBuilder
name|sb
init|=
operator|new
name|StringBuilder
argument_list|(
name|key
operator|.
name|toString
argument_list|()
argument_list|)
decl_stmt|;
name|sb
operator|.
name|append
argument_list|(
name|seperator
argument_list|)
expr_stmt|;
name|boolean
name|moreThanOne
init|=
literal|false
decl_stmt|;
name|long
name|count
init|=
literal|0
decl_stmt|;
for|for
control|(
name|ImmutableBytesWritable
name|row
range|:
name|rows
control|)
block|{
if|if
condition|(
name|moreThanOne
condition|)
block|{
name|sb
operator|.
name|append
argument_list|(
literal|","
argument_list|)
expr_stmt|;
block|}
name|sb
operator|.
name|append
argument_list|(
name|base64
operator|.
name|encodeToString
argument_list|(
name|row
operator|.
name|copyBytes
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
name|moreThanOne
operator|=
literal|true
expr_stmt|;
name|count
operator|++
expr_stmt|;
block|}
name|context
operator|.
name|getCounter
argument_list|(
literal|"PROBLEM"
argument_list|,
literal|"Problem MOB files"
argument_list|)
operator|.
name|increment
argument_list|(
literal|1L
argument_list|)
expr_stmt|;
name|context
operator|.
name|getCounter
argument_list|(
literal|"PROBLEM"
argument_list|,
literal|"Affected rows"
argument_list|)
operator|.
name|increment
argument_list|(
name|count
argument_list|)
expr_stmt|;
name|context
operator|.
name|getCounter
argument_list|(
literal|"ROWS WITH PROBLEMS PER FILE"
argument_list|,
literal|"Number of HFiles with "
operator|+
name|log10GroupedString
argument_list|(
name|count
argument_list|)
operator|+
literal|"s of affected rows"
argument_list|)
operator|.
name|increment
argument_list|(
literal|1L
argument_list|)
expr_stmt|;
name|key
operator|.
name|set
argument_list|(
name|sb
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
return|return
name|key
return|;
block|}
block|}
comment|/**    * Returns the string representation of the given number after grouping it    * into log10 buckets. e.g. 0-9 -> 1, 10-99 -> 10, ..., 100,000-999,999 -> 100,000, etc.    */
specifier|static
name|String
name|log10GroupedString
parameter_list|(
name|long
name|number
parameter_list|)
block|{
return|return
name|String
operator|.
name|format
argument_list|(
literal|"%,d"
argument_list|,
call|(
name|long
call|)
argument_list|(
name|Math
operator|.
name|pow
argument_list|(
literal|10d
argument_list|,
name|Math
operator|.
name|floor
argument_list|(
name|Math
operator|.
name|log10
argument_list|(
name|number
argument_list|)
argument_list|)
argument_list|)
argument_list|)
argument_list|)
return|;
block|}
comment|/**    * Main method for the tool.    * @return 0 if success, 1 for bad args. 2 if job aborted with an exception,    *   3 if mr job was unsuccessful    */
specifier|public
name|int
name|run
parameter_list|(
name|String
index|[]
name|args
parameter_list|)
throws|throws
name|IOException
throws|,
name|InterruptedException
block|{
comment|// TODO make family and table optional
if|if
condition|(
name|args
operator|.
name|length
operator|!=
literal|3
condition|)
block|{
name|printUsage
argument_list|()
expr_stmt|;
return|return
literal|1
return|;
block|}
specifier|final
name|String
name|output
init|=
name|args
index|[
literal|0
index|]
decl_stmt|;
specifier|final
name|String
name|tableName
init|=
name|args
index|[
literal|1
index|]
decl_stmt|;
specifier|final
name|String
name|familyName
init|=
name|args
index|[
literal|2
index|]
decl_stmt|;
specifier|final
name|long
name|reportStartTime
init|=
name|EnvironmentEdgeManager
operator|.
name|currentTime
argument_list|()
decl_stmt|;
name|Configuration
name|conf
init|=
name|getConf
argument_list|()
decl_stmt|;
try|try
block|{
name|FileSystem
name|fs
init|=
name|FileSystem
operator|.
name|get
argument_list|(
name|conf
argument_list|)
decl_stmt|;
comment|// check whether the current user is the same one with the owner of hbase root
name|String
name|currentUserName
init|=
name|UserGroupInformation
operator|.
name|getCurrentUser
argument_list|()
operator|.
name|getShortUserName
argument_list|()
decl_stmt|;
name|FileStatus
index|[]
name|hbaseRootFileStat
init|=
name|fs
operator|.
name|listStatus
argument_list|(
operator|new
name|Path
argument_list|(
name|conf
operator|.
name|get
argument_list|(
name|HConstants
operator|.
name|HBASE_DIR
argument_list|)
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|hbaseRootFileStat
operator|.
name|length
operator|>
literal|0
condition|)
block|{
name|String
name|owner
init|=
name|hbaseRootFileStat
index|[
literal|0
index|]
operator|.
name|getOwner
argument_list|()
decl_stmt|;
if|if
condition|(
operator|!
name|owner
operator|.
name|equals
argument_list|(
name|currentUserName
argument_list|)
condition|)
block|{
name|String
name|errorMsg
init|=
literal|"The current user["
operator|+
name|currentUserName
operator|+
literal|"] does not have hbase root credentials."
operator|+
literal|" If this job fails due to an inability to read HBase's internal directories, "
operator|+
literal|"you will need to rerun as a user with sufficient permissions. The HBase superuser "
operator|+
literal|"is a safe choice."
decl_stmt|;
name|LOG
operator|.
name|warn
argument_list|(
name|errorMsg
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"The passed configs point to an HBase dir does not exist: {}"
argument_list|,
name|conf
operator|.
name|get
argument_list|(
name|HConstants
operator|.
name|HBASE_DIR
argument_list|)
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|IOException
argument_list|(
literal|"The target HBase does not exist"
argument_list|)
throw|;
block|}
name|byte
index|[]
name|family
decl_stmt|;
name|int
name|maxVersions
decl_stmt|;
name|TableName
name|tn
init|=
name|TableName
operator|.
name|valueOf
argument_list|(
name|tableName
argument_list|)
decl_stmt|;
try|try
init|(
name|Connection
name|connection
init|=
name|ConnectionFactory
operator|.
name|createConnection
argument_list|(
name|conf
argument_list|)
init|;
name|Admin
name|admin
operator|=
name|connection
operator|.
name|getAdmin
argument_list|()
init|)
block|{
name|TableDescriptor
name|htd
init|=
name|admin
operator|.
name|getDescriptor
argument_list|(
name|tn
argument_list|)
decl_stmt|;
name|ColumnFamilyDescriptor
name|hcd
init|=
name|htd
operator|.
name|getColumnFamily
argument_list|(
name|Bytes
operator|.
name|toBytes
argument_list|(
name|familyName
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|hcd
operator|==
literal|null
operator|||
operator|!
name|hcd
operator|.
name|isMobEnabled
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Column family "
operator|+
name|familyName
operator|+
literal|" is not a MOB column family"
argument_list|)
throw|;
block|}
name|family
operator|=
name|hcd
operator|.
name|getName
argument_list|()
expr_stmt|;
name|maxVersions
operator|=
name|hcd
operator|.
name|getMaxVersions
argument_list|()
expr_stmt|;
block|}
name|String
name|id
init|=
name|getClass
argument_list|()
operator|.
name|getSimpleName
argument_list|()
operator|+
name|UUID
operator|.
name|randomUUID
argument_list|()
operator|.
name|toString
argument_list|()
operator|.
name|replace
argument_list|(
literal|"-"
argument_list|,
literal|""
argument_list|)
decl_stmt|;
name|Job
name|job
init|=
literal|null
decl_stmt|;
name|Scan
name|scan
init|=
operator|new
name|Scan
argument_list|()
decl_stmt|;
name|scan
operator|.
name|addFamily
argument_list|(
name|family
argument_list|)
expr_stmt|;
comment|// Do not retrieve the mob data when scanning
name|scan
operator|.
name|setAttribute
argument_list|(
name|MobConstants
operator|.
name|MOB_SCAN_RAW
argument_list|,
name|Bytes
operator|.
name|toBytes
argument_list|(
name|Boolean
operator|.
name|TRUE
argument_list|)
argument_list|)
expr_stmt|;
name|scan
operator|.
name|setAttribute
argument_list|(
name|MobConstants
operator|.
name|MOB_SCAN_REF_ONLY
argument_list|,
name|Bytes
operator|.
name|toBytes
argument_list|(
name|Boolean
operator|.
name|TRUE
argument_list|)
argument_list|)
expr_stmt|;
comment|// If a scanner caching value isn't set, pick a smaller default since we know we're doing
comment|// a full table scan and don't want to impact other clients badly.
name|scan
operator|.
name|setCaching
argument_list|(
name|conf
operator|.
name|getInt
argument_list|(
name|HConstants
operator|.
name|HBASE_CLIENT_SCANNER_CACHING
argument_list|,
literal|10000
argument_list|)
argument_list|)
expr_stmt|;
name|scan
operator|.
name|setCacheBlocks
argument_list|(
literal|false
argument_list|)
expr_stmt|;
name|scan
operator|.
name|setMaxVersions
argument_list|(
name|maxVersions
argument_list|)
expr_stmt|;
name|conf
operator|.
name|set
argument_list|(
name|REPORT_JOB_ID
argument_list|,
name|id
argument_list|)
expr_stmt|;
name|job
operator|=
name|Job
operator|.
name|getInstance
argument_list|(
name|conf
argument_list|)
expr_stmt|;
name|job
operator|.
name|setJarByClass
argument_list|(
name|getClass
argument_list|()
argument_list|)
expr_stmt|;
name|TableMapReduceUtil
operator|.
name|initTableMapperJob
argument_list|(
name|tn
argument_list|,
name|scan
argument_list|,
name|MobRefMapper
operator|.
name|class
argument_list|,
name|Text
operator|.
name|class
argument_list|,
name|ImmutableBytesWritable
operator|.
name|class
argument_list|,
name|job
argument_list|)
expr_stmt|;
name|job
operator|.
name|setReducerClass
argument_list|(
name|MobRefReducer
operator|.
name|class
argument_list|)
expr_stmt|;
name|job
operator|.
name|setOutputFormatClass
argument_list|(
name|TextOutputFormat
operator|.
name|class
argument_list|)
expr_stmt|;
name|TextOutputFormat
operator|.
name|setOutputPath
argument_list|(
name|job
argument_list|,
operator|new
name|Path
argument_list|(
name|output
argument_list|)
argument_list|)
expr_stmt|;
name|job
operator|.
name|setJobName
argument_list|(
name|getClass
argument_list|()
operator|.
name|getSimpleName
argument_list|()
operator|+
literal|"-"
operator|+
name|tn
operator|+
literal|"-"
operator|+
name|familyName
argument_list|)
expr_stmt|;
comment|// for use in the reducer. easier than re-parsing it out of the scan string.
name|job
operator|.
name|getConfiguration
argument_list|()
operator|.
name|set
argument_list|(
name|TableInputFormat
operator|.
name|SCAN_COLUMN_FAMILY
argument_list|,
name|familyName
argument_list|)
expr_stmt|;
comment|// Use when we start this job as the base point for file "recency".
name|job
operator|.
name|getConfiguration
argument_list|()
operator|.
name|setLong
argument_list|(
name|REPORT_START_DATETIME
argument_list|,
name|reportStartTime
argument_list|)
expr_stmt|;
if|if
condition|(
name|job
operator|.
name|waitForCompletion
argument_list|(
literal|true
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Finished creating report for '{}', family='{}'"
argument_list|,
name|tn
argument_list|,
name|familyName
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|"Job was not successful"
argument_list|)
expr_stmt|;
return|return
literal|3
return|;
block|}
return|return
literal|0
return|;
block|}
catch|catch
parameter_list|(
name|ClassNotFoundException
decl||
name|RuntimeException
decl||
name|IOException
decl||
name|InterruptedException
name|e
parameter_list|)
block|{
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|"Job aborted due to exception "
operator|+
name|e
argument_list|)
expr_stmt|;
return|return
literal|2
return|;
comment|// job failed
block|}
block|}
specifier|public
specifier|static
name|void
name|main
parameter_list|(
name|String
index|[]
name|args
parameter_list|)
throws|throws
name|Exception
block|{
name|Configuration
name|conf
init|=
name|HBaseConfiguration
operator|.
name|create
argument_list|()
decl_stmt|;
name|int
name|ret
init|=
name|ToolRunner
operator|.
name|run
argument_list|(
name|conf
argument_list|,
operator|new
name|MobRefReporter
argument_list|()
argument_list|,
name|args
argument_list|)
decl_stmt|;
name|System
operator|.
name|exit
argument_list|(
name|ret
argument_list|)
expr_stmt|;
block|}
specifier|private
name|void
name|printUsage
parameter_list|()
block|{
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|"Usage:\n"
operator|+
literal|"--------------------------\n"
operator|+
name|MobRefReporter
operator|.
name|class
operator|.
name|getName
argument_list|()
operator|+
literal|" output-dir tableName familyName"
argument_list|)
expr_stmt|;
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|" output-dir       Where to write output report."
argument_list|)
expr_stmt|;
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|" tableName        The table name"
argument_list|)
expr_stmt|;
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|" familyName       The column family name"
argument_list|)
expr_stmt|;
block|}
block|}
end_class

end_unit

