begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one or more contributor license  * agreements. See the NOTICE file distributed with this work for additional information regarding  * copyright ownership. The ASF licenses this file to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance with the License. You may obtain a  * copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable  * law or agreed to in writing, software distributed under the License is distributed on an "AS IS"  * BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License  * for the specific language governing permissions and limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|mapreduce
package|;
end_package

begin_import
import|import static
name|org
operator|.
name|junit
operator|.
name|Assert
operator|.
name|assertTrue
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|FileNotFoundException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Random
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|TreeSet
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|Log
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|LogFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileStatus
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|*
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|ImmutableBytesWritable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|hfile
operator|.
name|HFile
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|testclassification
operator|.
name|MediumTests
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|Bytes
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|NullWritable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapred
operator|.
name|FileOutputCommitter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|Job
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|Mapper
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|Reducer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|lib
operator|.
name|output
operator|.
name|FileOutputFormat
import|;
end_import

begin_import
import|import
name|org
operator|.
name|junit
operator|.
name|Test
import|;
end_import

begin_import
import|import
name|org
operator|.
name|junit
operator|.
name|experimental
operator|.
name|categories
operator|.
name|Category
import|;
end_import

begin_comment
comment|/**  * Test for{@link MultiHFileOutputFormat}. Sets up and runs a mapreduce job that output directories and  * writes hfiles.  */
end_comment

begin_class
annotation|@
name|Category
argument_list|(
name|MediumTests
operator|.
name|class
argument_list|)
specifier|public
class|class
name|TestMultiHFileOutputFormat
block|{
specifier|private
specifier|static
specifier|final
name|Log
name|LOG
init|=
name|LogFactory
operator|.
name|getLog
argument_list|(
name|TestMultiHFileOutputFormat
operator|.
name|class
argument_list|)
decl_stmt|;
specifier|private
name|HBaseTestingUtility
name|util
init|=
operator|new
name|HBaseTestingUtility
argument_list|()
decl_stmt|;
specifier|private
specifier|static
name|int
name|ROWSPERSPLIT
init|=
literal|10
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|int
name|KEYLEN_DEFAULT
init|=
literal|10
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|String
name|KEYLEN_CONF
init|=
literal|"randomkv.key.length"
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|int
name|VALLEN_DEFAULT
init|=
literal|10
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|String
name|VALLEN_CONF
init|=
literal|"randomkv.val.length"
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|byte
index|[]
index|[]
name|TABLES
init|=
block|{
name|Bytes
operator|.
name|add
argument_list|(
name|Bytes
operator|.
name|toBytes
argument_list|(
name|PerformanceEvaluation
operator|.
name|TABLE_NAME
argument_list|)
argument_list|,
name|Bytes
operator|.
name|toBytes
argument_list|(
literal|"-1"
argument_list|)
argument_list|)
block|,
name|Bytes
operator|.
name|add
argument_list|(
name|Bytes
operator|.
name|toBytes
argument_list|(
name|PerformanceEvaluation
operator|.
name|TABLE_NAME
argument_list|)
argument_list|,
name|Bytes
operator|.
name|toBytes
argument_list|(
literal|"-2"
argument_list|)
argument_list|)
block|}
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|byte
index|[]
index|[]
name|FAMILIES
init|=
block|{
name|Bytes
operator|.
name|add
argument_list|(
name|PerformanceEvaluation
operator|.
name|FAMILY_NAME
argument_list|,
name|Bytes
operator|.
name|toBytes
argument_list|(
literal|"-A"
argument_list|)
argument_list|)
block|,
name|Bytes
operator|.
name|add
argument_list|(
name|PerformanceEvaluation
operator|.
name|FAMILY_NAME
argument_list|,
name|Bytes
operator|.
name|toBytes
argument_list|(
literal|"-B"
argument_list|)
argument_list|)
block|}
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|byte
index|[]
name|QUALIFIER
init|=
name|Bytes
operator|.
name|toBytes
argument_list|(
literal|"data"
argument_list|)
decl_stmt|;
specifier|public
specifier|static
name|void
name|main
parameter_list|(
name|String
index|[]
name|args
parameter_list|)
throws|throws
name|Exception
block|{
operator|new
name|TestMultiHFileOutputFormat
argument_list|()
operator|.
name|testWritingDataIntoHFiles
argument_list|()
expr_stmt|;
block|}
comment|/**      * Run small MR job. this MR job will write HFile into      * testWritingDataIntoHFiles/tableNames/columFamilies/      */
annotation|@
name|Test
specifier|public
name|void
name|testWritingDataIntoHFiles
parameter_list|()
throws|throws
name|Exception
block|{
name|Configuration
name|conf
init|=
name|util
operator|.
name|getConfiguration
argument_list|()
decl_stmt|;
name|util
operator|.
name|startMiniCluster
argument_list|()
expr_stmt|;
name|Path
name|testDir
init|=
name|util
operator|.
name|getDataTestDirOnTestFS
argument_list|(
literal|"testWritingDataIntoHFiles"
argument_list|)
decl_stmt|;
name|FileSystem
name|fs
init|=
name|testDir
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"testWritingDataIntoHFiles dir writing to dir: "
operator|+
name|testDir
argument_list|)
expr_stmt|;
comment|// Set down this value or we OOME in eclipse.
name|conf
operator|.
name|setInt
argument_list|(
literal|"mapreduce.task.io.sort.mb"
argument_list|,
literal|20
argument_list|)
expr_stmt|;
comment|// Write a few files by setting max file size.
name|conf
operator|.
name|setLong
argument_list|(
name|HConstants
operator|.
name|HREGION_MAX_FILESIZE
argument_list|,
literal|64
operator|*
literal|1024
argument_list|)
expr_stmt|;
try|try
block|{
name|Job
name|job
init|=
name|Job
operator|.
name|getInstance
argument_list|(
name|conf
argument_list|,
literal|"testWritingDataIntoHFiles"
argument_list|)
decl_stmt|;
name|FileOutputFormat
operator|.
name|setOutputPath
argument_list|(
name|job
argument_list|,
name|testDir
argument_list|)
expr_stmt|;
name|job
operator|.
name|setInputFormatClass
argument_list|(
name|NMapInputFormat
operator|.
name|class
argument_list|)
expr_stmt|;
name|job
operator|.
name|setMapperClass
argument_list|(
name|Random_TableKV_GeneratingMapper
operator|.
name|class
argument_list|)
expr_stmt|;
name|job
operator|.
name|setMapOutputKeyClass
argument_list|(
name|ImmutableBytesWritable
operator|.
name|class
argument_list|)
expr_stmt|;
name|job
operator|.
name|setMapOutputValueClass
argument_list|(
name|KeyValue
operator|.
name|class
argument_list|)
expr_stmt|;
name|job
operator|.
name|setReducerClass
argument_list|(
name|Table_KeyValueSortReducer
operator|.
name|class
argument_list|)
expr_stmt|;
name|job
operator|.
name|setOutputFormatClass
argument_list|(
name|MultiHFileOutputFormat
operator|.
name|class
argument_list|)
expr_stmt|;
name|job
operator|.
name|getConfiguration
argument_list|()
operator|.
name|setStrings
argument_list|(
literal|"io.serializations"
argument_list|,
name|conf
operator|.
name|get
argument_list|(
literal|"io.serializations"
argument_list|)
argument_list|,
name|MutationSerialization
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|,
name|ResultSerialization
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|,
name|KeyValueSerialization
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
name|TableMapReduceUtil
operator|.
name|addDependencyJars
argument_list|(
name|job
argument_list|)
expr_stmt|;
name|TableMapReduceUtil
operator|.
name|initCredentials
argument_list|(
name|job
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"\nStarting test testWritingDataIntoHFiles\n"
argument_list|)
expr_stmt|;
name|assertTrue
argument_list|(
name|job
operator|.
name|waitForCompletion
argument_list|(
literal|true
argument_list|)
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"\nWaiting on checking MapReduce output\n"
argument_list|)
expr_stmt|;
name|assertTrue
argument_list|(
name|checkMROutput
argument_list|(
name|fs
argument_list|,
name|testDir
argument_list|,
literal|0
argument_list|)
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|testDir
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
operator|.
name|delete
argument_list|(
name|testDir
argument_list|,
literal|true
argument_list|)
expr_stmt|;
name|util
operator|.
name|shutdownMiniCluster
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**      * MR will output a 3 level directory, tableName->ColumnFamilyName->HFile this method to check the      * created directory is correct or not A recursion method, the testDir had better be small size      */
specifier|private
name|boolean
name|checkMROutput
parameter_list|(
name|FileSystem
name|fs
parameter_list|,
name|Path
name|testDir
parameter_list|,
name|int
name|level
parameter_list|)
throws|throws
name|FileNotFoundException
throws|,
name|IOException
block|{
if|if
condition|(
name|level
operator|>=
literal|3
condition|)
block|{
return|return
name|HFile
operator|.
name|isHFileFormat
argument_list|(
name|fs
argument_list|,
name|testDir
argument_list|)
return|;
block|}
name|FileStatus
index|[]
name|fStats
init|=
name|fs
operator|.
name|listStatus
argument_list|(
name|testDir
argument_list|)
decl_stmt|;
if|if
condition|(
name|fStats
operator|==
literal|null
operator|||
name|fStats
operator|.
name|length
operator|<=
literal|0
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Created directory format is not correct"
argument_list|)
expr_stmt|;
return|return
literal|false
return|;
block|}
for|for
control|(
name|FileStatus
name|stats
range|:
name|fStats
control|)
block|{
comment|// skip the _SUCCESS file created by MapReduce
if|if
condition|(
name|level
operator|==
literal|0
operator|&&
name|stats
operator|.
name|getPath
argument_list|()
operator|.
name|getName
argument_list|()
operator|.
name|endsWith
argument_list|(
name|FileOutputCommitter
operator|.
name|SUCCEEDED_FILE_NAME
argument_list|)
condition|)
continue|continue;
if|if
condition|(
name|level
operator|<
literal|2
operator|&&
operator|!
name|stats
operator|.
name|isDirectory
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Created directory format is not correct"
argument_list|)
expr_stmt|;
return|return
literal|false
return|;
block|}
name|boolean
name|flag
init|=
name|checkMROutput
argument_list|(
name|fs
argument_list|,
name|stats
operator|.
name|getPath
argument_list|()
argument_list|,
name|level
operator|+
literal|1
argument_list|)
decl_stmt|;
if|if
condition|(
name|flag
operator|==
literal|false
condition|)
return|return
literal|false
return|;
block|}
return|return
literal|true
return|;
block|}
comment|/**      * Simple mapper that makes<TableName, KeyValue> output. With no input data      */
specifier|static
class|class
name|Random_TableKV_GeneratingMapper
extends|extends
name|Mapper
argument_list|<
name|NullWritable
argument_list|,
name|NullWritable
argument_list|,
name|ImmutableBytesWritable
argument_list|,
name|Cell
argument_list|>
block|{
specifier|private
name|int
name|keyLength
decl_stmt|;
specifier|private
name|int
name|valLength
decl_stmt|;
annotation|@
name|Override
specifier|protected
name|void
name|setup
parameter_list|(
name|Context
name|context
parameter_list|)
throws|throws
name|IOException
throws|,
name|InterruptedException
block|{
name|super
operator|.
name|setup
argument_list|(
name|context
argument_list|)
expr_stmt|;
name|Configuration
name|conf
init|=
name|context
operator|.
name|getConfiguration
argument_list|()
decl_stmt|;
name|keyLength
operator|=
name|conf
operator|.
name|getInt
argument_list|(
name|KEYLEN_CONF
argument_list|,
name|KEYLEN_DEFAULT
argument_list|)
expr_stmt|;
name|valLength
operator|=
name|conf
operator|.
name|getInt
argument_list|(
name|VALLEN_CONF
argument_list|,
name|VALLEN_DEFAULT
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|protected
name|void
name|map
parameter_list|(
name|NullWritable
name|n1
parameter_list|,
name|NullWritable
name|n2
parameter_list|,
name|Mapper
argument_list|<
name|NullWritable
argument_list|,
name|NullWritable
argument_list|,
name|ImmutableBytesWritable
argument_list|,
name|Cell
argument_list|>
operator|.
name|Context
name|context
parameter_list|)
throws|throws
name|java
operator|.
name|io
operator|.
name|IOException
throws|,
name|InterruptedException
block|{
name|byte
name|keyBytes
index|[]
init|=
operator|new
name|byte
index|[
name|keyLength
index|]
decl_stmt|;
name|byte
name|valBytes
index|[]
init|=
operator|new
name|byte
index|[
name|valLength
index|]
decl_stmt|;
name|ArrayList
argument_list|<
name|ImmutableBytesWritable
argument_list|>
name|tables
init|=
operator|new
name|ArrayList
argument_list|<
name|ImmutableBytesWritable
argument_list|>
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|TABLES
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|tables
operator|.
name|add
argument_list|(
operator|new
name|ImmutableBytesWritable
argument_list|(
name|TABLES
index|[
name|i
index|]
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|int
name|taskId
init|=
name|context
operator|.
name|getTaskAttemptID
argument_list|()
operator|.
name|getTaskID
argument_list|()
operator|.
name|getId
argument_list|()
decl_stmt|;
assert|assert
name|taskId
operator|<
name|Byte
operator|.
name|MAX_VALUE
operator|:
literal|"Unit tests dont support> 127 tasks!"
assert|;
name|Random
name|random
init|=
operator|new
name|Random
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|ROWSPERSPLIT
condition|;
name|i
operator|++
control|)
block|{
name|random
operator|.
name|nextBytes
argument_list|(
name|keyBytes
argument_list|)
expr_stmt|;
comment|// Ensure that unique tasks generate unique keys
name|keyBytes
index|[
name|keyLength
operator|-
literal|1
index|]
operator|=
call|(
name|byte
call|)
argument_list|(
name|taskId
operator|&
literal|0xFF
argument_list|)
expr_stmt|;
name|random
operator|.
name|nextBytes
argument_list|(
name|valBytes
argument_list|)
expr_stmt|;
for|for
control|(
name|ImmutableBytesWritable
name|table
range|:
name|tables
control|)
block|{
for|for
control|(
name|byte
index|[]
name|family
range|:
name|FAMILIES
control|)
block|{
name|Cell
name|kv
init|=
operator|new
name|KeyValue
argument_list|(
name|keyBytes
argument_list|,
name|family
argument_list|,
name|QUALIFIER
argument_list|,
name|valBytes
argument_list|)
decl_stmt|;
name|context
operator|.
name|write
argument_list|(
name|table
argument_list|,
name|kv
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
block|}
comment|/**      * Simple Reducer that have input<TableName, KeyValue>, with KeyValues have no order. and output      *<TableName, KeyValue>, with KeyValues are ordered      */
specifier|static
class|class
name|Table_KeyValueSortReducer
extends|extends
name|Reducer
argument_list|<
name|ImmutableBytesWritable
argument_list|,
name|KeyValue
argument_list|,
name|ImmutableBytesWritable
argument_list|,
name|KeyValue
argument_list|>
block|{
specifier|protected
name|void
name|reduce
parameter_list|(
name|ImmutableBytesWritable
name|table
parameter_list|,
name|java
operator|.
name|lang
operator|.
name|Iterable
argument_list|<
name|KeyValue
argument_list|>
name|kvs
parameter_list|,
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|Reducer
argument_list|<
name|ImmutableBytesWritable
argument_list|,
name|KeyValue
argument_list|,
name|ImmutableBytesWritable
argument_list|,
name|KeyValue
argument_list|>
operator|.
name|Context
name|context
parameter_list|)
throws|throws
name|java
operator|.
name|io
operator|.
name|IOException
throws|,
name|InterruptedException
block|{
name|TreeSet
argument_list|<
name|KeyValue
argument_list|>
name|map
init|=
operator|new
name|TreeSet
argument_list|<
name|KeyValue
argument_list|>
argument_list|(
name|KeyValue
operator|.
name|COMPARATOR
argument_list|)
decl_stmt|;
for|for
control|(
name|KeyValue
name|kv
range|:
name|kvs
control|)
block|{
try|try
block|{
name|map
operator|.
name|add
argument_list|(
name|kv
operator|.
name|clone
argument_list|()
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|CloneNotSupportedException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|java
operator|.
name|io
operator|.
name|IOException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
name|context
operator|.
name|setStatus
argument_list|(
literal|"Read "
operator|+
name|map
operator|.
name|getClass
argument_list|()
argument_list|)
expr_stmt|;
name|int
name|index
init|=
literal|0
decl_stmt|;
for|for
control|(
name|KeyValue
name|kv
range|:
name|map
control|)
block|{
name|context
operator|.
name|write
argument_list|(
name|table
argument_list|,
name|kv
argument_list|)
expr_stmt|;
if|if
condition|(
operator|++
name|index
operator|%
literal|100
operator|==
literal|0
condition|)
name|context
operator|.
name|setStatus
argument_list|(
literal|"Wrote "
operator|+
name|index
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
end_class

end_unit

