begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileStatus
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HBaseConfiguration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HColumnDescriptor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HRegionInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|compactions
operator|.
name|CompactionRequest
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|Bytes
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|Tool
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|ToolRunner
import|;
end_import

begin_import
import|import
name|org
operator|.
name|mockito
operator|.
name|Mockito
import|;
end_import

begin_comment
comment|/**  * Compact passed set of files.  * Create an instance and then call {@ink #compact(Store, Collection, boolean, long)}.  * Call this classes {@link #main(String[])} to see how to run compaction code  * 'standalone'.  */
end_comment

begin_class
specifier|public
class|class
name|CompactionTool
implements|implements
name|Tool
block|{
comment|// Instantiates a Store instance and a mocked up HRegion.  The compaction code
comment|// requires a StoreScanner and a StoreScanner has to have a Store; its too
comment|// tangled to do without (Store needs an HRegion which is another tangle).
comment|// TODO: Undo the tangles some day.
specifier|private
name|Configuration
name|conf
decl_stmt|;
name|CompactionTool
parameter_list|()
block|{
name|super
argument_list|()
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|Configuration
name|getConf
parameter_list|()
block|{
return|return
name|this
operator|.
name|conf
return|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|setConf
parameter_list|(
name|Configuration
name|c
parameter_list|)
block|{
name|this
operator|.
name|conf
operator|=
name|c
expr_stmt|;
block|}
specifier|private
name|int
name|usage
parameter_list|(
specifier|final
name|int
name|errCode
parameter_list|)
block|{
return|return
name|usage
argument_list|(
name|errCode
argument_list|,
literal|null
argument_list|)
return|;
block|}
specifier|private
name|int
name|usage
parameter_list|(
specifier|final
name|int
name|errCode
parameter_list|,
specifier|final
name|String
name|errMsg
parameter_list|)
block|{
if|if
condition|(
name|errMsg
operator|!=
literal|null
condition|)
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|"ERROR: "
operator|+
name|errMsg
argument_list|)
expr_stmt|;
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|"Usage: CompactionTool [options]<inputdir>"
argument_list|)
expr_stmt|;
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|" To preserve input files, pass -Dhbase.hstore.compaction.complete=false"
argument_list|)
expr_stmt|;
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|" To set tmp dir, pass -Dhbase.tmp.dir=ALTERNATE_DIR"
argument_list|)
expr_stmt|;
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|" To stop delete of compacted file, pass -Dhbase.compactiontool.delete=false"
argument_list|)
expr_stmt|;
return|return
name|errCode
return|;
block|}
name|int
name|checkdir
parameter_list|(
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Path
name|p
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
operator|!
name|fs
operator|.
name|exists
argument_list|(
name|p
argument_list|)
condition|)
block|{
return|return
name|usage
argument_list|(
operator|-
literal|2
argument_list|,
name|p
operator|.
name|toString
argument_list|()
operator|+
literal|" does not exist."
argument_list|)
return|;
block|}
if|if
condition|(
operator|!
name|fs
operator|.
name|getFileStatus
argument_list|(
name|p
argument_list|)
operator|.
name|isDir
argument_list|()
condition|)
block|{
return|return
name|usage
argument_list|(
operator|-
literal|3
argument_list|,
name|p
operator|.
name|toString
argument_list|()
operator|+
literal|" must be a directory"
argument_list|)
return|;
block|}
return|return
literal|0
return|;
block|}
comment|/**    * Mock up an HRegion instance.  Need to return an HRegionInfo when asked.    * Also need an executor to run storefile open/closes.  Need to repeat    * the thenReturn on getOpenAndCloseThreadPool because otherwise it returns    * cache of first which is closed during the opening.  Also, need to return    * tmpdir, etc.    * @param hri    * @param tmpdir    * @return    */
specifier|private
name|HRegion
name|createHRegion
parameter_list|(
specifier|final
name|HRegionInfo
name|hri
parameter_list|,
specifier|final
name|Path
name|tmpdir
parameter_list|)
block|{
name|HRegion
name|mockedHRegion
init|=
name|Mockito
operator|.
name|mock
argument_list|(
name|HRegion
operator|.
name|class
argument_list|)
decl_stmt|;
name|Mockito
operator|.
name|when
argument_list|(
name|mockedHRegion
operator|.
name|getRegionInfo
argument_list|()
argument_list|)
operator|.
name|thenReturn
argument_list|(
name|hri
argument_list|)
expr_stmt|;
name|Mockito
operator|.
name|when
argument_list|(
name|mockedHRegion
operator|.
name|getStoreFileOpenAndCloseThreadPool
argument_list|(
name|Mockito
operator|.
name|anyString
argument_list|()
argument_list|)
argument_list|)
operator|.
name|thenReturn
argument_list|(
name|HRegion
operator|.
name|getOpenAndCloseThreadPool
argument_list|(
literal|1
argument_list|,
literal|"mockedRegion.opener"
argument_list|)
argument_list|)
operator|.
name|thenReturn
argument_list|(
name|HRegion
operator|.
name|getOpenAndCloseThreadPool
argument_list|(
literal|1
argument_list|,
literal|"mockedRegion.closer"
argument_list|)
argument_list|)
expr_stmt|;
name|Mockito
operator|.
name|when
argument_list|(
name|mockedHRegion
operator|.
name|areWritesEnabled
argument_list|()
argument_list|)
operator|.
name|thenReturn
argument_list|(
literal|true
argument_list|)
expr_stmt|;
name|Mockito
operator|.
name|when
argument_list|(
name|mockedHRegion
operator|.
name|getTmpDir
argument_list|()
argument_list|)
operator|.
name|thenReturn
argument_list|(
name|tmpdir
argument_list|)
expr_stmt|;
return|return
name|mockedHRegion
return|;
block|}
comment|/**    * Fake up a Store around the passed<code>storedir</code>.    * @param fs    * @param storedir    * @param tmpdir    * @return    * @throws IOException    */
specifier|private
name|HStore
name|getStore
parameter_list|(
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Path
name|storedir
parameter_list|,
specifier|final
name|Path
name|tmpdir
parameter_list|)
throws|throws
name|IOException
block|{
comment|// TODO: Let config on table and column family be configurable from
comment|// command-line setting versions, etc.  For now do defaults
name|HColumnDescriptor
name|hcd
init|=
operator|new
name|HColumnDescriptor
argument_list|(
literal|"f"
argument_list|)
decl_stmt|;
name|HRegionInfo
name|hri
init|=
operator|new
name|HRegionInfo
argument_list|(
name|Bytes
operator|.
name|toBytes
argument_list|(
literal|"t"
argument_list|)
argument_list|)
decl_stmt|;
comment|// Get a shell of an HRegion w/ enough functionality to make Store happy.
name|HRegion
name|region
init|=
name|createHRegion
argument_list|(
name|hri
argument_list|,
name|tmpdir
argument_list|)
decl_stmt|;
comment|// Create a Store w/ check of hbase.rootdir blanked out and return our
comment|// list of files instead of have Store search its home dir.
return|return
operator|new
name|HStore
argument_list|(
name|tmpdir
argument_list|,
name|region
argument_list|,
name|hcd
argument_list|,
name|fs
argument_list|,
name|getConf
argument_list|()
argument_list|)
block|{
annotation|@
name|Override
specifier|public
name|FileStatus
index|[]
name|getStoreFiles
parameter_list|()
throws|throws
name|IOException
block|{
return|return
name|this
operator|.
name|fs
operator|.
name|listStatus
argument_list|(
name|getHomedir
argument_list|()
argument_list|)
return|;
block|}
annotation|@
name|Override
name|Path
name|createStoreHomeDir
parameter_list|(
name|FileSystem
name|fs
parameter_list|,
name|Path
name|homedir
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|storedir
return|;
block|}
block|}
return|;
block|}
annotation|@
name|Override
specifier|public
name|int
name|run
parameter_list|(
specifier|final
name|String
index|[]
name|args
parameter_list|)
throws|throws
name|Exception
block|{
if|if
condition|(
name|args
operator|.
name|length
operator|==
literal|0
condition|)
return|return
name|usage
argument_list|(
operator|-
literal|1
argument_list|)
return|;
name|FileSystem
name|fs
init|=
name|FileSystem
operator|.
name|get
argument_list|(
name|getConf
argument_list|()
argument_list|)
decl_stmt|;
specifier|final
name|Path
name|inputdir
init|=
operator|new
name|Path
argument_list|(
name|args
index|[
literal|0
index|]
argument_list|)
decl_stmt|;
specifier|final
name|Path
name|tmpdir
init|=
operator|new
name|Path
argument_list|(
name|getConf
argument_list|()
operator|.
name|get
argument_list|(
literal|"hbase.tmp.dir"
argument_list|)
argument_list|)
decl_stmt|;
name|int
name|errCode
init|=
name|checkdir
argument_list|(
name|fs
argument_list|,
name|inputdir
argument_list|)
decl_stmt|;
if|if
condition|(
name|errCode
operator|!=
literal|0
condition|)
return|return
name|errCode
return|;
name|errCode
operator|=
name|checkdir
argument_list|(
name|fs
argument_list|,
name|tmpdir
argument_list|)
expr_stmt|;
if|if
condition|(
name|errCode
operator|!=
literal|0
condition|)
return|return
name|errCode
return|;
comment|// Get a Store that wraps the inputdir of files to compact.
name|HStore
name|store
init|=
name|getStore
argument_list|(
name|fs
argument_list|,
name|inputdir
argument_list|,
name|tmpdir
argument_list|)
decl_stmt|;
comment|// Now we have a Store, run a compaction of passed files.
try|try
block|{
name|CompactionRequest
name|cr
init|=
name|store
operator|.
name|requestCompaction
argument_list|()
decl_stmt|;
name|StoreFile
name|sf
init|=
name|store
operator|.
name|compact
argument_list|(
name|cr
argument_list|)
decl_stmt|;
if|if
condition|(
name|sf
operator|!=
literal|null
condition|)
block|{
name|sf
operator|.
name|closeReader
argument_list|(
literal|true
argument_list|)
expr_stmt|;
if|if
condition|(
name|conf
operator|.
name|getBoolean
argument_list|(
literal|"hbase.compactiontool.delete"
argument_list|,
literal|true
argument_list|)
condition|)
block|{
if|if
condition|(
operator|!
name|fs
operator|.
name|delete
argument_list|(
name|sf
operator|.
name|getPath
argument_list|()
argument_list|,
literal|false
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Failed delete of "
operator|+
name|sf
operator|.
name|getPath
argument_list|()
argument_list|)
throw|;
block|}
block|}
block|}
block|}
finally|finally
block|{
name|store
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
return|return
literal|0
return|;
block|}
specifier|public
specifier|static
name|void
name|main
parameter_list|(
name|String
index|[]
name|args
parameter_list|)
throws|throws
name|Exception
block|{
name|System
operator|.
name|exit
argument_list|(
name|ToolRunner
operator|.
name|run
argument_list|(
name|HBaseConfiguration
operator|.
name|create
argument_list|()
argument_list|,
operator|new
name|CompactionTool
argument_list|()
argument_list|,
name|args
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
end_class

end_unit

