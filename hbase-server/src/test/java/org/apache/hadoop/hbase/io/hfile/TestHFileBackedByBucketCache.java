begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  *  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|hfile
package|;
end_package

begin_import
import|import static
name|org
operator|.
name|junit
operator|.
name|Assert
operator|.
name|assertEquals
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|junit
operator|.
name|Assert
operator|.
name|assertTrue
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|File
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|Log
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|LogFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|CategoryBasedTimeout
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|Cell
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|CellComparator
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HBaseTestingUtility
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HConstants
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|KeyValue
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|compress
operator|.
name|Compression
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|hfile
operator|.
name|bucket
operator|.
name|BucketAllocator
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|hfile
operator|.
name|bucket
operator|.
name|BucketCache
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|testclassification
operator|.
name|IOTests
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|testclassification
operator|.
name|LargeTests
import|;
end_import

begin_import
import|import
name|org
operator|.
name|junit
operator|.
name|Before
import|;
end_import

begin_import
import|import
name|org
operator|.
name|junit
operator|.
name|Rule
import|;
end_import

begin_import
import|import
name|org
operator|.
name|junit
operator|.
name|Test
import|;
end_import

begin_import
import|import
name|org
operator|.
name|junit
operator|.
name|experimental
operator|.
name|categories
operator|.
name|Category
import|;
end_import

begin_import
import|import
name|org
operator|.
name|junit
operator|.
name|rules
operator|.
name|TestName
import|;
end_import

begin_import
import|import
name|org
operator|.
name|junit
operator|.
name|rules
operator|.
name|TestRule
import|;
end_import

begin_comment
comment|/**  * Test for file-backed BucketCache.  */
end_comment

begin_comment
comment|// This is marked a LargeTest so it runs in its own JVM. We do this because we are making use of
end_comment

begin_comment
comment|// the cache and the cache is global. We don't want any other concurrent test polluting ours which
end_comment

begin_comment
comment|// can happen if more than one test in a single JVM which can happen when tests are small.
end_comment

begin_class
annotation|@
name|Category
argument_list|(
block|{
name|IOTests
operator|.
name|class
block|,
name|LargeTests
operator|.
name|class
block|}
argument_list|)
specifier|public
class|class
name|TestHFileBackedByBucketCache
block|{
specifier|private
specifier|static
specifier|final
name|Log
name|LOG
init|=
name|LogFactory
operator|.
name|getLog
argument_list|(
name|TestHFileBackedByBucketCache
operator|.
name|class
argument_list|)
decl_stmt|;
annotation|@
name|Rule
specifier|public
name|TestName
name|name
init|=
operator|new
name|TestName
argument_list|()
decl_stmt|;
annotation|@
name|Rule
specifier|public
specifier|final
name|TestRule
name|timeout
init|=
name|CategoryBasedTimeout
operator|.
name|builder
argument_list|()
operator|.
name|withTimeout
argument_list|(
name|this
operator|.
name|getClass
argument_list|()
argument_list|)
operator|.
name|withLookingForStuckThread
argument_list|(
literal|true
argument_list|)
operator|.
name|build
argument_list|()
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|HBaseTestingUtility
name|TEST_UTIL
init|=
operator|new
name|HBaseTestingUtility
argument_list|()
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|int
name|ROW_LENGTH
init|=
literal|4
decl_stmt|;
specifier|private
name|Configuration
name|conf
decl_stmt|;
specifier|private
name|FileSystem
name|fs
decl_stmt|;
comment|// MATH! SIZING FOR THE TEST!
comment|// Set bucketcache to be smallest size possible which is 1MB. We do that in the test
comment|// @Before<code>before</code> method. Into out 1MB cache, have it so only one bucket. If
comment|// bucketsize is set to 125kb in size, we will have one bucket in our 1MB bucketcache. It is
comment|// cryptic how this comes about but basically comes down to
comment|// {@link BucketAllocator#FEWEST_ITEMS_IN_BUCKET} being '4'... so 4 * 125 = just over 500k or so
comment|// which makes for one bucket only in 1M which you can see from TRACE logging:
comment|//
comment|// Cache totalSize=532480, buckets=1, bucket capacity=
comment|//   532480=(4*133120)=(FEWEST_ITEMS_IN_BUCKET*(largest configured bucketcache size))
comment|//
comment|// Now into this one big bucket, we write hfileblocks....Each hfileblock has two keys because
comment|// first is under the BLOCKSIZE of 64k and then the second puts us over the 64k...
comment|// so two Cells per block...
comment|/**    * Default size.    */
specifier|private
specifier|static
specifier|final
name|int
name|BLOCKSIZE
init|=
literal|64
operator|*
literal|1024
decl_stmt|;
comment|/**    * Bucket sizes get multiplied by 4 for actual bucket size.    * See {@link BucketAllocator#FEWEST_ITEMS_IN_BUCKET}.    */
specifier|private
specifier|static
specifier|final
name|int
name|BUCKETSIZE
init|=
literal|125
operator|*
literal|1024
decl_stmt|;
comment|/**    * Make it so one Cell is just under a BLOCKSIZE. The second Cell puts us over the BLOCKSIZE    * so we have two Cells per HFilBlock.    */
specifier|private
specifier|static
specifier|final
name|int
name|VALUE_SIZE
init|=
literal|33
operator|*
literal|1024
decl_stmt|;
annotation|@
name|Before
specifier|public
name|void
name|before
parameter_list|()
throws|throws
name|IOException
block|{
comment|// Do setup of a bucketcache that has one bucket only. Enable trace-level logging for
comment|// key classes.
name|this
operator|.
name|conf
operator|=
name|TEST_UTIL
operator|.
name|getConfiguration
argument_list|()
expr_stmt|;
name|this
operator|.
name|fs
operator|=
name|FileSystem
operator|.
name|get
argument_list|(
name|conf
argument_list|)
expr_stmt|;
comment|// Set BucketCache and HFileBlock to log at trace level.
name|setTraceLevel
argument_list|(
name|BucketCache
operator|.
name|class
argument_list|)
expr_stmt|;
name|setTraceLevel
argument_list|(
name|HFileBlock
operator|.
name|class
argument_list|)
expr_stmt|;
name|setTraceLevel
argument_list|(
name|HFileReaderImpl
operator|.
name|class
argument_list|)
expr_stmt|;
name|setTraceLevel
argument_list|(
name|BucketAllocator
operator|.
name|class
argument_list|)
expr_stmt|;
block|}
comment|//  Assumes log4j logging.
specifier|private
specifier|static
name|void
name|setTraceLevel
parameter_list|(
specifier|final
name|Class
argument_list|<
name|?
argument_list|>
name|clazz
parameter_list|)
block|{
name|Log
name|testlog
init|=
name|LogFactory
operator|.
name|getLog
argument_list|(
name|clazz
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
operator|(
operator|(
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|impl
operator|.
name|Log4JLogger
operator|)
name|testlog
operator|)
operator|.
name|getLogger
argument_list|()
operator|.
name|setLevel
argument_list|(
name|org
operator|.
name|apache
operator|.
name|log4j
operator|.
name|Level
operator|.
name|TRACE
argument_list|)
expr_stmt|;
block|}
comment|/**    * Test that bucketcache is caching and that the persist of in-memory map works    * @throws IOException    */
annotation|@
name|Test
specifier|public
name|void
name|testBucketCacheCachesAndPersists
parameter_list|()
throws|throws
name|IOException
block|{
comment|// Set up a bucket cache. Set up one that will persist by passing a
comment|// hbase.bucketcache.persistent.path value to store the in-memory map of what is out in
comment|// the file-backed bucketcache. Set bucketcache to have one size only, BUCKETSIZE.
comment|// See "MATH! SIZING FOR THE TEST!" note above around declaration of BUCKETSIZE
name|String
name|bucketCacheDataFile
init|=
operator|(
operator|new
name|Path
argument_list|(
name|TEST_UTIL
operator|.
name|getDataTestDir
argument_list|()
argument_list|,
literal|"bucketcache.data"
argument_list|)
operator|)
operator|.
name|toString
argument_list|()
decl_stmt|;
operator|(
operator|new
name|File
argument_list|(
name|bucketCacheDataFile
argument_list|)
operator|)
operator|.
name|getParentFile
argument_list|()
operator|.
name|mkdirs
argument_list|()
expr_stmt|;
name|this
operator|.
name|conf
operator|.
name|set
argument_list|(
literal|"hbase.bucketcache.ioengine"
argument_list|,
literal|"file:"
operator|+
name|bucketCacheDataFile
argument_list|)
expr_stmt|;
name|this
operator|.
name|conf
operator|.
name|set
argument_list|(
literal|"hbase.bucketcache.persistent.path"
argument_list|,
name|bucketCacheDataFile
operator|+
literal|".map"
argument_list|)
expr_stmt|;
name|this
operator|.
name|conf
operator|.
name|setStrings
argument_list|(
literal|"hbase.bucketcache.bucket.sizes"
argument_list|,
name|Integer
operator|.
name|toString
argument_list|(
name|BUCKETSIZE
argument_list|)
argument_list|)
expr_stmt|;
comment|// This is minimum bucketcache size.... 1MB.
name|this
operator|.
name|conf
operator|.
name|setInt
argument_list|(
literal|"hbase.bucketcache.size"
argument_list|,
literal|1
argument_list|)
expr_stmt|;
comment|// Write 8 entries which should make for four hfileBlocks.
specifier|final
name|int
name|count
init|=
literal|8
decl_stmt|;
specifier|final
name|int
name|hfileBlockCount
init|=
literal|4
decl_stmt|;
name|Path
name|hfilePath
init|=
operator|new
name|Path
argument_list|(
name|TEST_UTIL
operator|.
name|getDataTestDir
argument_list|()
argument_list|,
name|this
operator|.
name|name
operator|.
name|getMethodName
argument_list|()
argument_list|)
decl_stmt|;
comment|// Clear out any existing global cache instance. Will pollute our tests below. Any concurrent
comment|// running test will pollute our results below.
name|CacheConfig
operator|.
name|GLOBAL_BLOCK_CACHE_INSTANCE
operator|=
literal|null
expr_stmt|;
name|CacheConfig
name|cacheConfig
init|=
operator|new
name|CacheConfig
argument_list|(
name|conf
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|Cell
argument_list|>
name|writtenCells
init|=
name|writeFile
argument_list|(
name|hfilePath
argument_list|,
name|Compression
operator|.
name|Algorithm
operator|.
name|NONE
argument_list|,
name|cacheConfig
argument_list|,
name|count
argument_list|)
decl_stmt|;
name|CacheStats
name|stats
init|=
name|cacheConfig
operator|.
name|getBlockCache
argument_list|()
operator|.
name|getStats
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|Cell
argument_list|>
name|readCells
init|=
name|readFile
argument_list|(
name|hfilePath
argument_list|,
name|cacheConfig
argument_list|)
decl_stmt|;
name|assertTrue
argument_list|(
operator|!
name|writtenCells
operator|.
name|isEmpty
argument_list|()
argument_list|)
expr_stmt|;
name|assertEquals
argument_list|(
name|writtenCells
operator|.
name|size
argument_list|()
argument_list|,
name|readCells
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
name|assertEquals
argument_list|(
name|hfileBlockCount
argument_list|,
name|stats
operator|.
name|getMissCount
argument_list|()
argument_list|)
expr_stmt|;
name|assertEquals
argument_list|(
literal|1
argument_list|,
name|stats
operator|.
name|getHitCount
argument_list|()
argument_list|)
expr_stmt|;
comment|// readFile will read first block is from cache.
comment|// Now, close out the cache and then reopen and verify that cache still has our blocks.
comment|// Assert that persistence works.
name|cacheConfig
operator|.
name|getBlockCache
argument_list|()
operator|.
name|shutdown
argument_list|()
expr_stmt|;
comment|// Need to clear the global cache else the new CacheConfig won't create a bucketcache but
comment|// just reuse the old one.
name|CacheConfig
operator|.
name|GLOBAL_BLOCK_CACHE_INSTANCE
operator|=
literal|null
expr_stmt|;
name|cacheConfig
operator|=
operator|new
name|CacheConfig
argument_list|(
name|conf
argument_list|)
expr_stmt|;
name|stats
operator|=
name|cacheConfig
operator|.
name|getBlockCache
argument_list|()
operator|.
name|getStats
argument_list|()
expr_stmt|;
name|assertEquals
argument_list|(
literal|0
argument_list|,
name|stats
operator|.
name|getHitCachingCount
argument_list|()
argument_list|)
expr_stmt|;
name|readCells
operator|=
name|readFile
argument_list|(
name|hfilePath
argument_list|,
name|cacheConfig
argument_list|)
expr_stmt|;
comment|// readFile will read all hfileblocs in the file, hfileBlockCount, and then one more, so + 1.
name|assertEquals
argument_list|(
name|hfileBlockCount
operator|+
literal|1
argument_list|,
name|stats
operator|.
name|getHitCachingCount
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|/**    * Write a file with<code>count</code> entries.    * @return The Cells written to the file.    * @throws IOException    */
specifier|private
name|List
argument_list|<
name|Cell
argument_list|>
name|writeFile
parameter_list|(
specifier|final
name|Path
name|hfilePath
parameter_list|,
specifier|final
name|Compression
operator|.
name|Algorithm
name|compressAlgo
parameter_list|,
specifier|final
name|CacheConfig
name|cacheConfig
parameter_list|,
specifier|final
name|int
name|count
parameter_list|)
throws|throws
name|IOException
block|{
name|List
argument_list|<
name|Cell
argument_list|>
name|cells
init|=
operator|new
name|ArrayList
argument_list|<
name|Cell
argument_list|>
argument_list|(
name|count
argument_list|)
decl_stmt|;
name|HFileContext
name|context
init|=
operator|new
name|HFileContextBuilder
argument_list|()
operator|.
name|withBlockSize
argument_list|(
name|BLOCKSIZE
argument_list|)
operator|.
name|withCompression
argument_list|(
name|compressAlgo
argument_list|)
operator|.
name|build
argument_list|()
decl_stmt|;
try|try
init|(
name|HFile
operator|.
name|Writer
name|writer
init|=
operator|new
name|HFile
operator|.
name|WriterFactory
argument_list|(
name|conf
argument_list|,
name|cacheConfig
argument_list|)
operator|.
name|withPath
argument_list|(
name|fs
argument_list|,
name|hfilePath
argument_list|)
operator|.
name|withFileContext
argument_list|(
name|context
argument_list|)
operator|.
name|withComparator
argument_list|(
name|CellComparator
operator|.
name|COMPARATOR
argument_list|)
operator|.
name|create
argument_list|()
init|)
block|{
name|byte
index|[]
name|valueBytes
init|=
operator|new
name|byte
index|[
name|VALUE_SIZE
index|]
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|valueBytes
operator|.
name|length
condition|;
name|i
operator|++
control|)
name|valueBytes
index|[
name|i
index|]
operator|=
literal|'0'
expr_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|count
condition|;
operator|++
name|i
control|)
block|{
name|byte
index|[]
name|keyBytes
init|=
name|format
argument_list|(
name|i
argument_list|)
decl_stmt|;
name|KeyValue
name|keyValue
init|=
operator|new
name|KeyValue
argument_list|(
name|keyBytes
argument_list|,
name|HConstants
operator|.
name|CATALOG_FAMILY
argument_list|,
name|keyBytes
argument_list|,
name|HConstants
operator|.
name|LATEST_TIMESTAMP
argument_list|,
name|valueBytes
argument_list|)
decl_stmt|;
name|writer
operator|.
name|append
argument_list|(
name|keyValue
argument_list|)
expr_stmt|;
name|cells
operator|.
name|add
argument_list|(
name|keyValue
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|cells
return|;
block|}
comment|/**    * Read the whole file, then read the first block so we get something from cache for sure.    * So... there are TOTAL_BLOCKS_IN_FILE read + 1. See math at head of this class.    * @return The Cells read from the file.    */
specifier|private
name|List
argument_list|<
name|Cell
argument_list|>
name|readFile
parameter_list|(
specifier|final
name|Path
name|hfilePath
parameter_list|,
specifier|final
name|CacheConfig
name|cacheConfig
parameter_list|)
throws|throws
name|IOException
block|{
name|List
argument_list|<
name|Cell
argument_list|>
name|cells
init|=
operator|new
name|ArrayList
argument_list|<
name|Cell
argument_list|>
argument_list|()
decl_stmt|;
try|try
init|(
name|HFile
operator|.
name|Reader
name|reader
init|=
name|HFile
operator|.
name|createReader
argument_list|(
name|this
operator|.
name|fs
argument_list|,
name|hfilePath
argument_list|,
name|cacheConfig
argument_list|,
name|this
operator|.
name|conf
argument_list|)
init|;
name|HFileScanner
name|scanner
operator|=
name|reader
operator|.
name|getScanner
argument_list|(
literal|true
argument_list|,
literal|true
argument_list|)
init|)
block|{
name|scanner
operator|.
name|seekTo
argument_list|()
expr_stmt|;
do|do
block|{
name|cells
operator|.
name|add
argument_list|(
name|scanner
operator|.
name|getCell
argument_list|()
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
name|scanner
operator|.
name|getKey
argument_list|()
argument_list|)
expr_stmt|;
block|}
do|while
condition|(
name|scanner
operator|.
name|next
argument_list|()
condition|)
do|;
comment|// Do a random seek just so we see a block coming from cache.
name|scanner
operator|.
name|seekTo
argument_list|(
name|reader
operator|.
name|getFirstKey
argument_list|()
argument_list|)
expr_stmt|;
name|scanner
operator|.
name|next
argument_list|()
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
name|scanner
operator|.
name|getCell
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
name|cells
return|;
block|}
comment|/*    * Format passed integer.    * @param number    * @return Returns zero-prefixed ROW_LENGTH-byte wide decimal version of passed    * number (Does absolute in case number is negative).    */
specifier|private
specifier|static
name|byte
index|[]
name|format
parameter_list|(
specifier|final
name|int
name|number
parameter_list|)
block|{
name|byte
index|[]
name|b
init|=
operator|new
name|byte
index|[
name|ROW_LENGTH
index|]
decl_stmt|;
name|int
name|d
init|=
name|Math
operator|.
name|abs
argument_list|(
name|number
argument_list|)
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
name|b
operator|.
name|length
operator|-
literal|1
init|;
name|i
operator|>=
literal|0
condition|;
name|i
operator|--
control|)
block|{
name|b
index|[
name|i
index|]
operator|=
call|(
name|byte
call|)
argument_list|(
operator|(
name|d
operator|%
literal|10
operator|)
operator|+
literal|'0'
argument_list|)
expr_stmt|;
name|d
operator|/=
literal|10
expr_stmt|;
block|}
return|return
name|b
return|;
block|}
block|}
end_class

end_unit

