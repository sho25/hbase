begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  *  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|wal
package|;
end_package

begin_import
import|import static
name|org
operator|.
name|junit
operator|.
name|Assert
operator|.
name|assertEquals
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|junit
operator|.
name|Assert
operator|.
name|assertFalse
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|junit
operator|.
name|Assert
operator|.
name|assertNotNull
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|junit
operator|.
name|Assert
operator|.
name|assertTrue
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|EOFException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|OutputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|lang
operator|.
name|reflect
operator|.
name|InvocationTargetException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|lang
operator|.
name|reflect
operator|.
name|Method
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Set
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|Log
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|LogFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HBaseTestingUtility
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HColumnDescriptor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HConstants
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HRegionInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HTableDescriptor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|KeyValue
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|LargeTests
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|MiniHBaseCluster
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|TableName
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|Get
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|HBaseAdmin
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|HTable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|Put
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|Result
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|ResultScanner
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|Scan
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|fs
operator|.
name|HFileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|HRegion
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|HRegionServer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|Store
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|Bytes
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|FSUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|JVMClusterUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|Threads
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|MiniDFSCluster
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|DatanodeInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|server
operator|.
name|datanode
operator|.
name|DataNode
import|;
end_import

begin_import
import|import
name|org
operator|.
name|junit
operator|.
name|After
import|;
end_import

begin_import
import|import
name|org
operator|.
name|junit
operator|.
name|Assert
import|;
end_import

begin_import
import|import
name|org
operator|.
name|junit
operator|.
name|Before
import|;
end_import

begin_import
import|import
name|org
operator|.
name|junit
operator|.
name|BeforeClass
import|;
end_import

begin_import
import|import
name|org
operator|.
name|junit
operator|.
name|Test
import|;
end_import

begin_import
import|import
name|org
operator|.
name|junit
operator|.
name|experimental
operator|.
name|categories
operator|.
name|Category
import|;
end_import

begin_comment
comment|/**  * Test log deletion as logs are rolled.  */
end_comment

begin_class
annotation|@
name|Category
argument_list|(
name|LargeTests
operator|.
name|class
argument_list|)
specifier|public
class|class
name|TestLogRolling
block|{
specifier|private
specifier|static
specifier|final
name|Log
name|LOG
init|=
name|LogFactory
operator|.
name|getLog
argument_list|(
name|TestLogRolling
operator|.
name|class
argument_list|)
decl_stmt|;
specifier|private
name|HRegionServer
name|server
decl_stmt|;
specifier|private
name|HLog
name|log
decl_stmt|;
specifier|private
name|String
name|tableName
decl_stmt|;
specifier|private
name|byte
index|[]
name|value
decl_stmt|;
specifier|private
name|FileSystem
name|fs
decl_stmt|;
specifier|private
name|MiniDFSCluster
name|dfsCluster
decl_stmt|;
specifier|private
name|HBaseAdmin
name|admin
decl_stmt|;
specifier|private
name|MiniHBaseCluster
name|cluster
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|HBaseTestingUtility
name|TEST_UTIL
init|=
operator|new
name|HBaseTestingUtility
argument_list|()
decl_stmt|;
comment|/**    * constructor    * @throws Exception    */
specifier|public
name|TestLogRolling
parameter_list|()
block|{
name|this
operator|.
name|server
operator|=
literal|null
expr_stmt|;
name|this
operator|.
name|log
operator|=
literal|null
expr_stmt|;
name|this
operator|.
name|tableName
operator|=
literal|null
expr_stmt|;
name|String
name|className
init|=
name|this
operator|.
name|getClass
argument_list|()
operator|.
name|getName
argument_list|()
decl_stmt|;
name|StringBuilder
name|v
init|=
operator|new
name|StringBuilder
argument_list|(
name|className
argument_list|)
decl_stmt|;
while|while
condition|(
name|v
operator|.
name|length
argument_list|()
operator|<
literal|1000
condition|)
block|{
name|v
operator|.
name|append
argument_list|(
name|className
argument_list|)
expr_stmt|;
block|}
name|this
operator|.
name|value
operator|=
name|Bytes
operator|.
name|toBytes
argument_list|(
name|v
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|// Need to override this setup so we can edit the config before it gets sent
comment|// to the HDFS& HBase cluster startup.
annotation|@
name|BeforeClass
specifier|public
specifier|static
name|void
name|setUpBeforeClass
parameter_list|()
throws|throws
name|Exception
block|{
comment|// TODO: testLogRollOnDatanodeDeath fails if short circuit reads are on under the hadoop2
comment|// profile. See HBASE-9337 for related issues.
name|System
operator|.
name|setProperty
argument_list|(
literal|"hbase.tests.use.shortcircuit.reads"
argument_list|,
literal|"false"
argument_list|)
expr_stmt|;
comment|/**** configuration for testLogRolling ****/
comment|// Force a region split after every 768KB
name|TEST_UTIL
operator|.
name|getConfiguration
argument_list|()
operator|.
name|setLong
argument_list|(
name|HConstants
operator|.
name|HREGION_MAX_FILESIZE
argument_list|,
literal|768L
operator|*
literal|1024L
argument_list|)
expr_stmt|;
comment|// We roll the log after every 32 writes
name|TEST_UTIL
operator|.
name|getConfiguration
argument_list|()
operator|.
name|setInt
argument_list|(
literal|"hbase.regionserver.maxlogentries"
argument_list|,
literal|32
argument_list|)
expr_stmt|;
name|TEST_UTIL
operator|.
name|getConfiguration
argument_list|()
operator|.
name|setInt
argument_list|(
literal|"hbase.regionserver.logroll.errors.tolerated"
argument_list|,
literal|2
argument_list|)
expr_stmt|;
name|TEST_UTIL
operator|.
name|getConfiguration
argument_list|()
operator|.
name|setInt
argument_list|(
literal|"ipc.socket.timeout"
argument_list|,
literal|10
operator|*
literal|1000
argument_list|)
expr_stmt|;
name|TEST_UTIL
operator|.
name|getConfiguration
argument_list|()
operator|.
name|setInt
argument_list|(
literal|"hbase.rpc.timeout"
argument_list|,
literal|10
operator|*
literal|1000
argument_list|)
expr_stmt|;
comment|// For less frequently updated regions flush after every 2 flushes
name|TEST_UTIL
operator|.
name|getConfiguration
argument_list|()
operator|.
name|setInt
argument_list|(
literal|"hbase.hregion.memstore.optionalflushcount"
argument_list|,
literal|2
argument_list|)
expr_stmt|;
comment|// We flush the cache after every 8192 bytes
name|TEST_UTIL
operator|.
name|getConfiguration
argument_list|()
operator|.
name|setInt
argument_list|(
name|HConstants
operator|.
name|HREGION_MEMSTORE_FLUSH_SIZE
argument_list|,
literal|8192
argument_list|)
expr_stmt|;
comment|// Increase the amount of time between client retries
name|TEST_UTIL
operator|.
name|getConfiguration
argument_list|()
operator|.
name|setLong
argument_list|(
literal|"hbase.client.pause"
argument_list|,
literal|10
operator|*
literal|1000
argument_list|)
expr_stmt|;
comment|// Reduce thread wake frequency so that other threads can get
comment|// a chance to run.
name|TEST_UTIL
operator|.
name|getConfiguration
argument_list|()
operator|.
name|setInt
argument_list|(
name|HConstants
operator|.
name|THREAD_WAKE_FREQUENCY
argument_list|,
literal|2
operator|*
literal|1000
argument_list|)
expr_stmt|;
comment|/**** configuration for testLogRollOnDatanodeDeath ****/
comment|// make sure log.hflush() calls syncFs() to open a pipeline
name|TEST_UTIL
operator|.
name|getConfiguration
argument_list|()
operator|.
name|setBoolean
argument_list|(
literal|"dfs.support.append"
argument_list|,
literal|true
argument_list|)
expr_stmt|;
comment|// lower the namenode& datanode heartbeat so the namenode
comment|// quickly detects datanode failures
name|TEST_UTIL
operator|.
name|getConfiguration
argument_list|()
operator|.
name|setInt
argument_list|(
literal|"heartbeat.recheck.interval"
argument_list|,
literal|5000
argument_list|)
expr_stmt|;
name|TEST_UTIL
operator|.
name|getConfiguration
argument_list|()
operator|.
name|setInt
argument_list|(
literal|"dfs.heartbeat.interval"
argument_list|,
literal|1
argument_list|)
expr_stmt|;
comment|// the namenode might still try to choose the recently-dead datanode
comment|// for a pipeline, so try to a new pipeline multiple times
name|TEST_UTIL
operator|.
name|getConfiguration
argument_list|()
operator|.
name|setInt
argument_list|(
literal|"dfs.client.block.write.retries"
argument_list|,
literal|30
argument_list|)
expr_stmt|;
name|TEST_UTIL
operator|.
name|getConfiguration
argument_list|()
operator|.
name|setInt
argument_list|(
literal|"hbase.regionserver.hlog.tolerable.lowreplication"
argument_list|,
literal|2
argument_list|)
expr_stmt|;
name|TEST_UTIL
operator|.
name|getConfiguration
argument_list|()
operator|.
name|setInt
argument_list|(
literal|"hbase.regionserver.hlog.lowreplication.rolllimit"
argument_list|,
literal|3
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Before
specifier|public
name|void
name|setUp
parameter_list|()
throws|throws
name|Exception
block|{
name|TEST_UTIL
operator|.
name|startMiniCluster
argument_list|(
literal|1
argument_list|,
literal|1
argument_list|,
literal|2
argument_list|)
expr_stmt|;
name|cluster
operator|=
name|TEST_UTIL
operator|.
name|getHBaseCluster
argument_list|()
expr_stmt|;
name|dfsCluster
operator|=
name|TEST_UTIL
operator|.
name|getDFSCluster
argument_list|()
expr_stmt|;
name|fs
operator|=
name|TEST_UTIL
operator|.
name|getTestFileSystem
argument_list|()
expr_stmt|;
name|admin
operator|=
name|TEST_UTIL
operator|.
name|getHBaseAdmin
argument_list|()
expr_stmt|;
comment|// disable region rebalancing (interferes with log watching)
name|cluster
operator|.
name|getMaster
argument_list|()
operator|.
name|balanceSwitch
argument_list|(
literal|false
argument_list|)
expr_stmt|;
block|}
annotation|@
name|After
specifier|public
name|void
name|tearDown
parameter_list|()
throws|throws
name|Exception
block|{
name|TEST_UTIL
operator|.
name|shutdownMiniCluster
argument_list|()
expr_stmt|;
block|}
specifier|private
name|void
name|startAndWriteData
parameter_list|()
throws|throws
name|IOException
throws|,
name|InterruptedException
block|{
comment|// When the hbase:meta table can be opened, the region servers are running
operator|new
name|HTable
argument_list|(
name|TEST_UTIL
operator|.
name|getConfiguration
argument_list|()
argument_list|,
name|TableName
operator|.
name|META_TABLE_NAME
argument_list|)
expr_stmt|;
name|this
operator|.
name|server
operator|=
name|cluster
operator|.
name|getRegionServerThreads
argument_list|()
operator|.
name|get
argument_list|(
literal|0
argument_list|)
operator|.
name|getRegionServer
argument_list|()
expr_stmt|;
name|this
operator|.
name|log
operator|=
name|server
operator|.
name|getWAL
argument_list|()
expr_stmt|;
name|HTable
name|table
init|=
name|createTestTable
argument_list|(
name|this
operator|.
name|tableName
argument_list|)
decl_stmt|;
name|server
operator|=
name|TEST_UTIL
operator|.
name|getRSForFirstRegionInTable
argument_list|(
name|Bytes
operator|.
name|toBytes
argument_list|(
name|tableName
argument_list|)
argument_list|)
expr_stmt|;
name|this
operator|.
name|log
operator|=
name|server
operator|.
name|getWAL
argument_list|()
expr_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|1
init|;
name|i
operator|<=
literal|256
condition|;
name|i
operator|++
control|)
block|{
comment|// 256 writes should cause 8 log rolls
name|doPut
argument_list|(
name|table
argument_list|,
name|i
argument_list|)
expr_stmt|;
if|if
condition|(
name|i
operator|%
literal|32
operator|==
literal|0
condition|)
block|{
comment|// After every 32 writes sleep to let the log roller run
try|try
block|{
name|Thread
operator|.
name|sleep
argument_list|(
literal|2000
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
comment|// continue
block|}
block|}
block|}
block|}
comment|/**    * Tests that log rolling doesn't hang when no data is written.    */
annotation|@
name|Test
argument_list|(
name|timeout
operator|=
literal|120000
argument_list|)
specifier|public
name|void
name|testLogRollOnNothingWritten
parameter_list|()
throws|throws
name|Exception
block|{
name|Configuration
name|conf
init|=
name|TEST_UTIL
operator|.
name|getConfiguration
argument_list|()
decl_stmt|;
name|HFileSystem
name|fs
init|=
operator|new
name|HFileSystem
argument_list|(
name|conf
argument_list|,
literal|false
argument_list|)
decl_stmt|;
name|HLog
name|newLog
init|=
name|HLogFactory
operator|.
name|createHLog
argument_list|(
name|fs
operator|.
name|getBackingFs
argument_list|()
argument_list|,
name|FSUtils
operator|.
name|getRootDir
argument_list|(
name|conf
argument_list|)
argument_list|,
literal|"test"
argument_list|,
name|conf
argument_list|,
literal|null
argument_list|,
literal|"test.com:8080:1"
argument_list|)
decl_stmt|;
try|try
block|{
comment|// Now roll the log before we write anything.
name|newLog
operator|.
name|rollWriter
argument_list|(
literal|true
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|newLog
operator|.
name|closeAndDelete
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**    * Tests that logs are deleted    * @throws IOException    * @throws org.apache.hadoop.hbase.regionserver.wal.FailedLogCloseException    */
annotation|@
name|Test
specifier|public
name|void
name|testLogRolling
parameter_list|()
throws|throws
name|Exception
block|{
name|this
operator|.
name|tableName
operator|=
name|getName
argument_list|()
expr_stmt|;
comment|// TODO: Why does this write data take for ever?
name|startAndWriteData
argument_list|()
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"after writing there are "
operator|+
operator|(
operator|(
name|FSHLog
operator|)
name|log
operator|)
operator|.
name|getNumRolledLogFiles
argument_list|()
operator|+
literal|" log files"
argument_list|)
expr_stmt|;
comment|// flush all regions
name|List
argument_list|<
name|HRegion
argument_list|>
name|regions
init|=
operator|new
name|ArrayList
argument_list|<
name|HRegion
argument_list|>
argument_list|(
name|server
operator|.
name|getOnlineRegionsLocalContext
argument_list|()
argument_list|)
decl_stmt|;
for|for
control|(
name|HRegion
name|r
range|:
name|regions
control|)
block|{
name|r
operator|.
name|flushcache
argument_list|()
expr_stmt|;
block|}
comment|// Now roll the log
name|log
operator|.
name|rollWriter
argument_list|()
expr_stmt|;
name|int
name|count
init|=
operator|(
operator|(
name|FSHLog
operator|)
name|log
operator|)
operator|.
name|getNumRolledLogFiles
argument_list|()
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"after flushing all regions and rolling logs there are "
operator|+
operator|(
operator|(
name|FSHLog
operator|)
name|log
operator|)
operator|.
name|getNumRolledLogFiles
argument_list|()
operator|+
literal|" log files"
argument_list|)
expr_stmt|;
name|assertTrue
argument_list|(
operator|(
literal|"actual count: "
operator|+
name|count
operator|)
argument_list|,
name|count
operator|<=
literal|2
argument_list|)
expr_stmt|;
block|}
specifier|private
specifier|static
name|String
name|getName
parameter_list|()
block|{
return|return
literal|"TestLogRolling"
return|;
block|}
name|void
name|writeData
parameter_list|(
name|HTable
name|table
parameter_list|,
name|int
name|rownum
parameter_list|)
throws|throws
name|IOException
block|{
name|doPut
argument_list|(
name|table
argument_list|,
name|rownum
argument_list|)
expr_stmt|;
comment|// sleep to let the log roller run (if it needs to)
try|try
block|{
name|Thread
operator|.
name|sleep
argument_list|(
literal|2000
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
comment|// continue
block|}
block|}
name|void
name|validateData
parameter_list|(
name|HTable
name|table
parameter_list|,
name|int
name|rownum
parameter_list|)
throws|throws
name|IOException
block|{
name|String
name|row
init|=
literal|"row"
operator|+
name|String
operator|.
name|format
argument_list|(
literal|"%1$04d"
argument_list|,
name|rownum
argument_list|)
decl_stmt|;
name|Get
name|get
init|=
operator|new
name|Get
argument_list|(
name|Bytes
operator|.
name|toBytes
argument_list|(
name|row
argument_list|)
argument_list|)
decl_stmt|;
name|get
operator|.
name|addFamily
argument_list|(
name|HConstants
operator|.
name|CATALOG_FAMILY
argument_list|)
expr_stmt|;
name|Result
name|result
init|=
name|table
operator|.
name|get
argument_list|(
name|get
argument_list|)
decl_stmt|;
name|assertTrue
argument_list|(
name|result
operator|.
name|size
argument_list|()
operator|==
literal|1
argument_list|)
expr_stmt|;
name|assertTrue
argument_list|(
name|Bytes
operator|.
name|equals
argument_list|(
name|value
argument_list|,
name|result
operator|.
name|getValue
argument_list|(
name|HConstants
operator|.
name|CATALOG_FAMILY
argument_list|,
literal|null
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Validated row "
operator|+
name|row
argument_list|)
expr_stmt|;
block|}
name|void
name|batchWriteAndWait
parameter_list|(
name|HTable
name|table
parameter_list|,
name|int
name|start
parameter_list|,
name|boolean
name|expect
parameter_list|,
name|int
name|timeout
parameter_list|)
throws|throws
name|IOException
block|{
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
literal|10
condition|;
name|i
operator|++
control|)
block|{
name|Put
name|put
init|=
operator|new
name|Put
argument_list|(
name|Bytes
operator|.
name|toBytes
argument_list|(
literal|"row"
operator|+
name|String
operator|.
name|format
argument_list|(
literal|"%1$04d"
argument_list|,
operator|(
name|start
operator|+
name|i
operator|)
argument_list|)
argument_list|)
argument_list|)
decl_stmt|;
name|put
operator|.
name|add
argument_list|(
name|HConstants
operator|.
name|CATALOG_FAMILY
argument_list|,
literal|null
argument_list|,
name|value
argument_list|)
expr_stmt|;
name|table
operator|.
name|put
argument_list|(
name|put
argument_list|)
expr_stmt|;
block|}
name|Put
name|tmpPut
init|=
operator|new
name|Put
argument_list|(
name|Bytes
operator|.
name|toBytes
argument_list|(
literal|"tmprow"
argument_list|)
argument_list|)
decl_stmt|;
name|tmpPut
operator|.
name|add
argument_list|(
name|HConstants
operator|.
name|CATALOG_FAMILY
argument_list|,
literal|null
argument_list|,
name|value
argument_list|)
expr_stmt|;
name|long
name|startTime
init|=
name|System
operator|.
name|currentTimeMillis
argument_list|()
decl_stmt|;
name|long
name|remaining
init|=
name|timeout
decl_stmt|;
while|while
condition|(
name|remaining
operator|>
literal|0
condition|)
block|{
if|if
condition|(
name|log
operator|.
name|isLowReplicationRollEnabled
argument_list|()
operator|==
name|expect
condition|)
block|{
break|break;
block|}
else|else
block|{
comment|// Trigger calling FSHlog#checkLowReplication()
name|table
operator|.
name|put
argument_list|(
name|tmpPut
argument_list|)
expr_stmt|;
try|try
block|{
name|Thread
operator|.
name|sleep
argument_list|(
literal|200
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
comment|// continue
block|}
name|remaining
operator|=
name|timeout
operator|-
operator|(
name|System
operator|.
name|currentTimeMillis
argument_list|()
operator|-
name|startTime
operator|)
expr_stmt|;
block|}
block|}
block|}
comment|/**    * Give me the HDFS pipeline for this log file    */
name|DatanodeInfo
index|[]
name|getPipeline
parameter_list|(
name|HLog
name|log
parameter_list|)
throws|throws
name|IllegalArgumentException
throws|,
name|IllegalAccessException
throws|,
name|InvocationTargetException
block|{
name|OutputStream
name|stm
init|=
operator|(
operator|(
name|FSHLog
operator|)
name|log
operator|)
operator|.
name|getOutputStream
argument_list|()
decl_stmt|;
name|Method
name|getPipeline
init|=
literal|null
decl_stmt|;
for|for
control|(
name|Method
name|m
range|:
name|stm
operator|.
name|getClass
argument_list|()
operator|.
name|getDeclaredMethods
argument_list|()
control|)
block|{
if|if
condition|(
name|m
operator|.
name|getName
argument_list|()
operator|.
name|endsWith
argument_list|(
literal|"getPipeline"
argument_list|)
condition|)
block|{
name|getPipeline
operator|=
name|m
expr_stmt|;
name|getPipeline
operator|.
name|setAccessible
argument_list|(
literal|true
argument_list|)
expr_stmt|;
break|break;
block|}
block|}
name|assertTrue
argument_list|(
literal|"Need DFSOutputStream.getPipeline() for this test"
argument_list|,
literal|null
operator|!=
name|getPipeline
argument_list|)
expr_stmt|;
name|Object
name|repl
init|=
name|getPipeline
operator|.
name|invoke
argument_list|(
name|stm
argument_list|,
operator|new
name|Object
index|[]
block|{}
comment|/* NO_ARGS */
argument_list|)
decl_stmt|;
return|return
operator|(
name|DatanodeInfo
index|[]
operator|)
name|repl
return|;
block|}
comment|/**    * Tests that logs are rolled upon detecting datanode death    * Requires an HDFS jar with HDFS-826& syncFs() support (HDFS-200)    */
annotation|@
name|Test
specifier|public
name|void
name|testLogRollOnDatanodeDeath
parameter_list|()
throws|throws
name|Exception
block|{
name|TEST_UTIL
operator|.
name|ensureSomeRegionServersAvailable
argument_list|(
literal|2
argument_list|)
expr_stmt|;
name|assertTrue
argument_list|(
literal|"This test requires HLog file replication set to 2."
argument_list|,
name|fs
operator|.
name|getDefaultReplication
argument_list|(
name|TEST_UTIL
operator|.
name|getDataTestDirOnTestFS
argument_list|()
argument_list|)
operator|==
literal|2
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Replication="
operator|+
name|fs
operator|.
name|getDefaultReplication
argument_list|(
name|TEST_UTIL
operator|.
name|getDataTestDirOnTestFS
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
name|this
operator|.
name|server
operator|=
name|cluster
operator|.
name|getRegionServer
argument_list|(
literal|0
argument_list|)
expr_stmt|;
name|this
operator|.
name|log
operator|=
name|server
operator|.
name|getWAL
argument_list|()
expr_stmt|;
comment|// Create the test table and open it
name|String
name|tableName
init|=
name|getName
argument_list|()
decl_stmt|;
name|HTableDescriptor
name|desc
init|=
operator|new
name|HTableDescriptor
argument_list|(
name|TableName
operator|.
name|valueOf
argument_list|(
name|tableName
argument_list|)
argument_list|)
decl_stmt|;
name|desc
operator|.
name|addFamily
argument_list|(
operator|new
name|HColumnDescriptor
argument_list|(
name|HConstants
operator|.
name|CATALOG_FAMILY
argument_list|)
argument_list|)
expr_stmt|;
name|admin
operator|.
name|createTable
argument_list|(
name|desc
argument_list|)
expr_stmt|;
name|HTable
name|table
init|=
operator|new
name|HTable
argument_list|(
name|TEST_UTIL
operator|.
name|getConfiguration
argument_list|()
argument_list|,
name|tableName
argument_list|)
decl_stmt|;
name|assertTrue
argument_list|(
name|table
operator|.
name|isAutoFlush
argument_list|()
argument_list|)
expr_stmt|;
name|server
operator|=
name|TEST_UTIL
operator|.
name|getRSForFirstRegionInTable
argument_list|(
name|Bytes
operator|.
name|toBytes
argument_list|(
name|tableName
argument_list|)
argument_list|)
expr_stmt|;
name|this
operator|.
name|log
operator|=
name|server
operator|.
name|getWAL
argument_list|()
expr_stmt|;
name|assertTrue
argument_list|(
literal|"Need HDFS-826 for this test"
argument_list|,
operator|(
operator|(
name|FSHLog
operator|)
name|log
operator|)
operator|.
name|canGetCurReplicas
argument_list|()
argument_list|)
expr_stmt|;
comment|// don't run this test without append support (HDFS-200& HDFS-142)
name|assertTrue
argument_list|(
literal|"Need append support for this test"
argument_list|,
name|FSUtils
operator|.
name|isAppendSupported
argument_list|(
name|TEST_UTIL
operator|.
name|getConfiguration
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
comment|// add up the datanode count, to ensure proper replication when we kill 1
comment|// This function is synchronous; when it returns, the dfs cluster is active
comment|// We start 3 servers and then stop 2 to avoid a directory naming conflict
comment|//  when we stop/start a namenode later, as mentioned in HBASE-5163
name|List
argument_list|<
name|DataNode
argument_list|>
name|existingNodes
init|=
name|dfsCluster
operator|.
name|getDataNodes
argument_list|()
decl_stmt|;
name|int
name|numDataNodes
init|=
literal|3
decl_stmt|;
name|dfsCluster
operator|.
name|startDataNodes
argument_list|(
name|TEST_UTIL
operator|.
name|getConfiguration
argument_list|()
argument_list|,
name|numDataNodes
argument_list|,
literal|true
argument_list|,
literal|null
argument_list|,
literal|null
argument_list|)
expr_stmt|;
name|List
argument_list|<
name|DataNode
argument_list|>
name|allNodes
init|=
name|dfsCluster
operator|.
name|getDataNodes
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
name|allNodes
operator|.
name|size
argument_list|()
operator|-
literal|1
init|;
name|i
operator|>=
literal|0
condition|;
name|i
operator|--
control|)
block|{
if|if
condition|(
name|existingNodes
operator|.
name|contains
argument_list|(
name|allNodes
operator|.
name|get
argument_list|(
name|i
argument_list|)
argument_list|)
condition|)
block|{
name|dfsCluster
operator|.
name|stopDataNode
argument_list|(
name|i
argument_list|)
expr_stmt|;
block|}
block|}
name|assertTrue
argument_list|(
literal|"DataNodes "
operator|+
name|dfsCluster
operator|.
name|getDataNodes
argument_list|()
operator|.
name|size
argument_list|()
operator|+
literal|" default replication "
operator|+
name|fs
operator|.
name|getDefaultReplication
argument_list|(
name|TEST_UTIL
operator|.
name|getDataTestDirOnTestFS
argument_list|()
argument_list|)
argument_list|,
name|dfsCluster
operator|.
name|getDataNodes
argument_list|()
operator|.
name|size
argument_list|()
operator|>=
name|fs
operator|.
name|getDefaultReplication
argument_list|(
name|TEST_UTIL
operator|.
name|getDataTestDirOnTestFS
argument_list|()
argument_list|)
operator|+
literal|1
argument_list|)
expr_stmt|;
name|writeData
argument_list|(
name|table
argument_list|,
literal|2
argument_list|)
expr_stmt|;
name|long
name|curTime
init|=
name|System
operator|.
name|currentTimeMillis
argument_list|()
decl_stmt|;
name|long
name|oldFilenum
init|=
operator|(
operator|(
name|FSHLog
operator|)
name|log
operator|)
operator|.
name|getFilenum
argument_list|()
decl_stmt|;
name|assertTrue
argument_list|(
literal|"Log should have a timestamp older than now"
argument_list|,
name|curTime
operator|>
name|oldFilenum
operator|&&
name|oldFilenum
operator|!=
operator|-
literal|1
argument_list|)
expr_stmt|;
name|assertTrue
argument_list|(
literal|"The log shouldn't have rolled yet"
argument_list|,
name|oldFilenum
operator|==
operator|(
operator|(
name|FSHLog
operator|)
name|log
operator|)
operator|.
name|getFilenum
argument_list|()
argument_list|)
expr_stmt|;
specifier|final
name|DatanodeInfo
index|[]
name|pipeline
init|=
name|getPipeline
argument_list|(
name|log
argument_list|)
decl_stmt|;
name|assertTrue
argument_list|(
name|pipeline
operator|.
name|length
operator|==
name|fs
operator|.
name|getDefaultReplication
argument_list|(
name|TEST_UTIL
operator|.
name|getDataTestDirOnTestFS
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
comment|// kill a datanode in the pipeline to force a log roll on the next sync()
comment|// This function is synchronous, when it returns the node is killed.
name|assertTrue
argument_list|(
name|dfsCluster
operator|.
name|stopDataNode
argument_list|(
name|pipeline
index|[
literal|0
index|]
operator|.
name|getName
argument_list|()
argument_list|)
operator|!=
literal|null
argument_list|)
expr_stmt|;
comment|// this write should succeed, but trigger a log roll
name|writeData
argument_list|(
name|table
argument_list|,
literal|2
argument_list|)
expr_stmt|;
name|long
name|newFilenum
init|=
operator|(
operator|(
name|FSHLog
operator|)
name|log
operator|)
operator|.
name|getFilenum
argument_list|()
decl_stmt|;
name|assertTrue
argument_list|(
literal|"Missing datanode should've triggered a log roll"
argument_list|,
name|newFilenum
operator|>
name|oldFilenum
operator|&&
name|newFilenum
operator|>
name|curTime
argument_list|)
expr_stmt|;
comment|// write some more log data (this should use a new hdfs_out)
name|writeData
argument_list|(
name|table
argument_list|,
literal|3
argument_list|)
expr_stmt|;
name|assertTrue
argument_list|(
literal|"The log should not roll again."
argument_list|,
operator|(
operator|(
name|FSHLog
operator|)
name|log
operator|)
operator|.
name|getFilenum
argument_list|()
operator|==
name|newFilenum
argument_list|)
expr_stmt|;
comment|// kill another datanode in the pipeline, so the replicas will be lower than
comment|// the configured value 2.
name|assertTrue
argument_list|(
name|dfsCluster
operator|.
name|stopDataNode
argument_list|(
name|pipeline
index|[
literal|1
index|]
operator|.
name|getName
argument_list|()
argument_list|)
operator|!=
literal|null
argument_list|)
expr_stmt|;
name|batchWriteAndWait
argument_list|(
name|table
argument_list|,
literal|3
argument_list|,
literal|false
argument_list|,
literal|14000
argument_list|)
expr_stmt|;
name|assertTrue
argument_list|(
literal|"LowReplication Roller should've been disabled, current replication="
operator|+
operator|(
operator|(
name|FSHLog
operator|)
name|log
operator|)
operator|.
name|getLogReplication
argument_list|()
argument_list|,
operator|!
name|log
operator|.
name|isLowReplicationRollEnabled
argument_list|()
argument_list|)
expr_stmt|;
name|dfsCluster
operator|.
name|startDataNodes
argument_list|(
name|TEST_UTIL
operator|.
name|getConfiguration
argument_list|()
argument_list|,
literal|1
argument_list|,
literal|true
argument_list|,
literal|null
argument_list|,
literal|null
argument_list|)
expr_stmt|;
comment|// Force roll writer. The new log file will have the default replications,
comment|// and the LowReplication Roller will be enabled.
name|log
operator|.
name|rollWriter
argument_list|(
literal|true
argument_list|)
expr_stmt|;
name|batchWriteAndWait
argument_list|(
name|table
argument_list|,
literal|13
argument_list|,
literal|true
argument_list|,
literal|10000
argument_list|)
expr_stmt|;
name|assertTrue
argument_list|(
literal|"New log file should have the default replication instead of "
operator|+
operator|(
operator|(
name|FSHLog
operator|)
name|log
operator|)
operator|.
name|getLogReplication
argument_list|()
argument_list|,
operator|(
operator|(
name|FSHLog
operator|)
name|log
operator|)
operator|.
name|getLogReplication
argument_list|()
operator|==
name|fs
operator|.
name|getDefaultReplication
argument_list|(
name|TEST_UTIL
operator|.
name|getDataTestDirOnTestFS
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
name|assertTrue
argument_list|(
literal|"LowReplication Roller should've been enabled"
argument_list|,
name|log
operator|.
name|isLowReplicationRollEnabled
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|/**    * Test that HLog is rolled when all data nodes in the pipeline have been    * restarted.    * @throws Exception    */
annotation|@
name|Test
specifier|public
name|void
name|testLogRollOnPipelineRestart
parameter_list|()
throws|throws
name|Exception
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Starting testLogRollOnPipelineRestart"
argument_list|)
expr_stmt|;
name|assertTrue
argument_list|(
literal|"This test requires HLog file replication."
argument_list|,
name|fs
operator|.
name|getDefaultReplication
argument_list|(
name|TEST_UTIL
operator|.
name|getDataTestDirOnTestFS
argument_list|()
argument_list|)
operator|>
literal|1
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Replication="
operator|+
name|fs
operator|.
name|getDefaultReplication
argument_list|(
name|TEST_UTIL
operator|.
name|getDataTestDirOnTestFS
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
comment|// When the hbase:meta table can be opened, the region servers are running
operator|new
name|HTable
argument_list|(
name|TEST_UTIL
operator|.
name|getConfiguration
argument_list|()
argument_list|,
name|TableName
operator|.
name|META_TABLE_NAME
argument_list|)
expr_stmt|;
name|this
operator|.
name|server
operator|=
name|cluster
operator|.
name|getRegionServer
argument_list|(
literal|0
argument_list|)
expr_stmt|;
name|this
operator|.
name|log
operator|=
name|server
operator|.
name|getWAL
argument_list|()
expr_stmt|;
comment|// Create the test table and open it
name|String
name|tableName
init|=
name|getName
argument_list|()
decl_stmt|;
name|HTableDescriptor
name|desc
init|=
operator|new
name|HTableDescriptor
argument_list|(
name|TableName
operator|.
name|valueOf
argument_list|(
name|tableName
argument_list|)
argument_list|)
decl_stmt|;
name|desc
operator|.
name|addFamily
argument_list|(
operator|new
name|HColumnDescriptor
argument_list|(
name|HConstants
operator|.
name|CATALOG_FAMILY
argument_list|)
argument_list|)
expr_stmt|;
name|admin
operator|.
name|createTable
argument_list|(
name|desc
argument_list|)
expr_stmt|;
name|HTable
name|table
init|=
operator|new
name|HTable
argument_list|(
name|TEST_UTIL
operator|.
name|getConfiguration
argument_list|()
argument_list|,
name|tableName
argument_list|)
decl_stmt|;
name|server
operator|=
name|TEST_UTIL
operator|.
name|getRSForFirstRegionInTable
argument_list|(
name|Bytes
operator|.
name|toBytes
argument_list|(
name|tableName
argument_list|)
argument_list|)
expr_stmt|;
name|this
operator|.
name|log
operator|=
name|server
operator|.
name|getWAL
argument_list|()
expr_stmt|;
specifier|final
name|List
argument_list|<
name|Path
argument_list|>
name|paths
init|=
operator|new
name|ArrayList
argument_list|<
name|Path
argument_list|>
argument_list|()
decl_stmt|;
specifier|final
name|List
argument_list|<
name|Integer
argument_list|>
name|preLogRolledCalled
init|=
operator|new
name|ArrayList
argument_list|<
name|Integer
argument_list|>
argument_list|()
decl_stmt|;
name|paths
operator|.
name|add
argument_list|(
operator|(
operator|(
name|FSHLog
operator|)
name|log
operator|)
operator|.
name|computeFilename
argument_list|()
argument_list|)
expr_stmt|;
name|log
operator|.
name|registerWALActionsListener
argument_list|(
operator|new
name|WALActionsListener
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|void
name|preLogRoll
parameter_list|(
name|Path
name|oldFile
parameter_list|,
name|Path
name|newFile
parameter_list|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"preLogRoll: oldFile="
operator|+
name|oldFile
operator|+
literal|" newFile="
operator|+
name|newFile
argument_list|)
expr_stmt|;
name|preLogRolledCalled
operator|.
name|add
argument_list|(
operator|new
name|Integer
argument_list|(
literal|1
argument_list|)
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|postLogRoll
parameter_list|(
name|Path
name|oldFile
parameter_list|,
name|Path
name|newFile
parameter_list|)
block|{
name|paths
operator|.
name|add
argument_list|(
name|newFile
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|preLogArchive
parameter_list|(
name|Path
name|oldFile
parameter_list|,
name|Path
name|newFile
parameter_list|)
block|{}
annotation|@
name|Override
specifier|public
name|void
name|postLogArchive
parameter_list|(
name|Path
name|oldFile
parameter_list|,
name|Path
name|newFile
parameter_list|)
block|{}
annotation|@
name|Override
specifier|public
name|void
name|logRollRequested
parameter_list|()
block|{}
annotation|@
name|Override
specifier|public
name|void
name|logCloseRequested
parameter_list|()
block|{}
annotation|@
name|Override
specifier|public
name|void
name|visitLogEntryBeforeWrite
parameter_list|(
name|HRegionInfo
name|info
parameter_list|,
name|HLogKey
name|logKey
parameter_list|,
name|WALEdit
name|logEdit
parameter_list|)
block|{}
annotation|@
name|Override
specifier|public
name|void
name|visitLogEntryBeforeWrite
parameter_list|(
name|HTableDescriptor
name|htd
parameter_list|,
name|HLogKey
name|logKey
parameter_list|,
name|WALEdit
name|logEdit
parameter_list|)
block|{}
block|}
argument_list|)
expr_stmt|;
name|assertTrue
argument_list|(
literal|"Need HDFS-826 for this test"
argument_list|,
operator|(
operator|(
name|FSHLog
operator|)
name|log
operator|)
operator|.
name|canGetCurReplicas
argument_list|()
argument_list|)
expr_stmt|;
comment|// don't run this test without append support (HDFS-200& HDFS-142)
name|assertTrue
argument_list|(
literal|"Need append support for this test"
argument_list|,
name|FSUtils
operator|.
name|isAppendSupported
argument_list|(
name|TEST_UTIL
operator|.
name|getConfiguration
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
name|writeData
argument_list|(
name|table
argument_list|,
literal|1002
argument_list|)
expr_stmt|;
name|table
operator|.
name|setAutoFlush
argument_list|(
literal|true
argument_list|,
literal|true
argument_list|)
expr_stmt|;
name|long
name|curTime
init|=
name|System
operator|.
name|currentTimeMillis
argument_list|()
decl_stmt|;
name|long
name|oldFilenum
init|=
name|log
operator|.
name|getFilenum
argument_list|()
decl_stmt|;
name|assertTrue
argument_list|(
literal|"Log should have a timestamp older than now"
argument_list|,
name|curTime
operator|>
name|oldFilenum
operator|&&
name|oldFilenum
operator|!=
operator|-
literal|1
argument_list|)
expr_stmt|;
name|assertTrue
argument_list|(
literal|"The log shouldn't have rolled yet"
argument_list|,
name|oldFilenum
operator|==
name|log
operator|.
name|getFilenum
argument_list|()
argument_list|)
expr_stmt|;
comment|// roll all datanodes in the pipeline
name|dfsCluster
operator|.
name|restartDataNodes
argument_list|()
expr_stmt|;
name|Thread
operator|.
name|sleep
argument_list|(
literal|1000
argument_list|)
expr_stmt|;
name|dfsCluster
operator|.
name|waitActive
argument_list|()
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Data Nodes restarted"
argument_list|)
expr_stmt|;
name|validateData
argument_list|(
name|table
argument_list|,
literal|1002
argument_list|)
expr_stmt|;
comment|// this write should succeed, but trigger a log roll
name|writeData
argument_list|(
name|table
argument_list|,
literal|1003
argument_list|)
expr_stmt|;
name|long
name|newFilenum
init|=
name|log
operator|.
name|getFilenum
argument_list|()
decl_stmt|;
name|assertTrue
argument_list|(
literal|"Missing datanode should've triggered a log roll"
argument_list|,
name|newFilenum
operator|>
name|oldFilenum
operator|&&
name|newFilenum
operator|>
name|curTime
argument_list|)
expr_stmt|;
name|validateData
argument_list|(
name|table
argument_list|,
literal|1003
argument_list|)
expr_stmt|;
name|writeData
argument_list|(
name|table
argument_list|,
literal|1004
argument_list|)
expr_stmt|;
comment|// roll all datanode again
name|dfsCluster
operator|.
name|restartDataNodes
argument_list|()
expr_stmt|;
name|Thread
operator|.
name|sleep
argument_list|(
literal|1000
argument_list|)
expr_stmt|;
name|dfsCluster
operator|.
name|waitActive
argument_list|()
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Data Nodes restarted"
argument_list|)
expr_stmt|;
name|validateData
argument_list|(
name|table
argument_list|,
literal|1004
argument_list|)
expr_stmt|;
comment|// this write should succeed, but trigger a log roll
name|writeData
argument_list|(
name|table
argument_list|,
literal|1005
argument_list|)
expr_stmt|;
comment|// force a log roll to read back and verify previously written logs
name|log
operator|.
name|rollWriter
argument_list|(
literal|true
argument_list|)
expr_stmt|;
name|assertTrue
argument_list|(
literal|"preLogRolledCalled has size of "
operator|+
name|preLogRolledCalled
operator|.
name|size
argument_list|()
argument_list|,
name|preLogRolledCalled
operator|.
name|size
argument_list|()
operator|>=
literal|1
argument_list|)
expr_stmt|;
comment|// read back the data written
name|Set
argument_list|<
name|String
argument_list|>
name|loggedRows
init|=
operator|new
name|HashSet
argument_list|<
name|String
argument_list|>
argument_list|()
decl_stmt|;
name|FSUtils
name|fsUtils
init|=
name|FSUtils
operator|.
name|getInstance
argument_list|(
name|fs
argument_list|,
name|TEST_UTIL
operator|.
name|getConfiguration
argument_list|()
argument_list|)
decl_stmt|;
for|for
control|(
name|Path
name|p
range|:
name|paths
control|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"recovering lease for "
operator|+
name|p
argument_list|)
expr_stmt|;
name|fsUtils
operator|.
name|recoverFileLease
argument_list|(
operator|(
operator|(
name|HFileSystem
operator|)
name|fs
operator|)
operator|.
name|getBackingFs
argument_list|()
argument_list|,
name|p
argument_list|,
name|TEST_UTIL
operator|.
name|getConfiguration
argument_list|()
argument_list|,
literal|null
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Reading HLog "
operator|+
name|FSUtils
operator|.
name|getPath
argument_list|(
name|p
argument_list|)
argument_list|)
expr_stmt|;
name|HLog
operator|.
name|Reader
name|reader
init|=
literal|null
decl_stmt|;
try|try
block|{
name|reader
operator|=
name|HLogFactory
operator|.
name|createReader
argument_list|(
name|fs
argument_list|,
name|p
argument_list|,
name|TEST_UTIL
operator|.
name|getConfiguration
argument_list|()
argument_list|)
expr_stmt|;
name|HLog
operator|.
name|Entry
name|entry
decl_stmt|;
while|while
condition|(
operator|(
name|entry
operator|=
name|reader
operator|.
name|next
argument_list|()
operator|)
operator|!=
literal|null
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"#"
operator|+
name|entry
operator|.
name|getKey
argument_list|()
operator|.
name|getLogSeqNum
argument_list|()
operator|+
literal|": "
operator|+
name|entry
operator|.
name|getEdit
argument_list|()
operator|.
name|getKeyValues
argument_list|()
argument_list|)
expr_stmt|;
for|for
control|(
name|KeyValue
name|kv
range|:
name|entry
operator|.
name|getEdit
argument_list|()
operator|.
name|getKeyValues
argument_list|()
control|)
block|{
name|loggedRows
operator|.
name|add
argument_list|(
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|kv
operator|.
name|getRow
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
block|}
catch|catch
parameter_list|(
name|EOFException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"EOF reading file "
operator|+
name|FSUtils
operator|.
name|getPath
argument_list|(
name|p
argument_list|)
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
if|if
condition|(
name|reader
operator|!=
literal|null
condition|)
name|reader
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
block|}
comment|// verify the written rows are there
name|assertTrue
argument_list|(
name|loggedRows
operator|.
name|contains
argument_list|(
literal|"row1002"
argument_list|)
argument_list|)
expr_stmt|;
name|assertTrue
argument_list|(
name|loggedRows
operator|.
name|contains
argument_list|(
literal|"row1003"
argument_list|)
argument_list|)
expr_stmt|;
name|assertTrue
argument_list|(
name|loggedRows
operator|.
name|contains
argument_list|(
literal|"row1004"
argument_list|)
argument_list|)
expr_stmt|;
name|assertTrue
argument_list|(
name|loggedRows
operator|.
name|contains
argument_list|(
literal|"row1005"
argument_list|)
argument_list|)
expr_stmt|;
comment|// flush all regions
name|List
argument_list|<
name|HRegion
argument_list|>
name|regions
init|=
operator|new
name|ArrayList
argument_list|<
name|HRegion
argument_list|>
argument_list|(
name|server
operator|.
name|getOnlineRegionsLocalContext
argument_list|()
argument_list|)
decl_stmt|;
for|for
control|(
name|HRegion
name|r
range|:
name|regions
control|)
block|{
name|r
operator|.
name|flushcache
argument_list|()
expr_stmt|;
block|}
name|ResultScanner
name|scanner
init|=
name|table
operator|.
name|getScanner
argument_list|(
operator|new
name|Scan
argument_list|()
argument_list|)
decl_stmt|;
try|try
block|{
for|for
control|(
name|int
name|i
init|=
literal|2
init|;
name|i
operator|<=
literal|5
condition|;
name|i
operator|++
control|)
block|{
name|Result
name|r
init|=
name|scanner
operator|.
name|next
argument_list|()
decl_stmt|;
name|assertNotNull
argument_list|(
name|r
argument_list|)
expr_stmt|;
name|assertFalse
argument_list|(
name|r
operator|.
name|isEmpty
argument_list|()
argument_list|)
expr_stmt|;
name|assertEquals
argument_list|(
literal|"row100"
operator|+
name|i
argument_list|,
name|Bytes
operator|.
name|toString
argument_list|(
name|r
operator|.
name|getRow
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
finally|finally
block|{
name|scanner
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
comment|// verify that no region servers aborted
for|for
control|(
name|JVMClusterUtil
operator|.
name|RegionServerThread
name|rsThread
range|:
name|TEST_UTIL
operator|.
name|getHBaseCluster
argument_list|()
operator|.
name|getRegionServerThreads
argument_list|()
control|)
block|{
name|assertFalse
argument_list|(
name|rsThread
operator|.
name|getRegionServer
argument_list|()
operator|.
name|isAborted
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Tests that logs are deleted when some region has a compaction    * record in WAL and no other records. See HBASE-8597.    */
annotation|@
name|Test
specifier|public
name|void
name|testCompactionRecordDoesntBlockRolling
parameter_list|()
throws|throws
name|Exception
block|{
comment|// When the hbase:meta table can be opened, the region servers are running
operator|new
name|HTable
argument_list|(
name|TEST_UTIL
operator|.
name|getConfiguration
argument_list|()
argument_list|,
name|TableName
operator|.
name|META_TABLE_NAME
argument_list|)
expr_stmt|;
name|String
name|tableName
init|=
name|getName
argument_list|()
decl_stmt|;
name|HTable
name|table
init|=
name|createTestTable
argument_list|(
name|tableName
argument_list|)
decl_stmt|;
name|String
name|tableName2
init|=
name|tableName
operator|+
literal|"1"
decl_stmt|;
name|HTable
name|table2
init|=
name|createTestTable
argument_list|(
name|tableName2
argument_list|)
decl_stmt|;
name|server
operator|=
name|TEST_UTIL
operator|.
name|getRSForFirstRegionInTable
argument_list|(
name|Bytes
operator|.
name|toBytes
argument_list|(
name|tableName
argument_list|)
argument_list|)
expr_stmt|;
name|this
operator|.
name|log
operator|=
name|server
operator|.
name|getWAL
argument_list|()
expr_stmt|;
name|FSHLog
name|fshLog
init|=
operator|(
name|FSHLog
operator|)
name|log
decl_stmt|;
name|HRegion
name|region
init|=
name|server
operator|.
name|getOnlineRegions
argument_list|(
name|table2
operator|.
name|getName
argument_list|()
argument_list|)
operator|.
name|get
argument_list|(
literal|0
argument_list|)
decl_stmt|;
name|Store
name|s
init|=
name|region
operator|.
name|getStore
argument_list|(
name|HConstants
operator|.
name|CATALOG_FAMILY
argument_list|)
decl_stmt|;
comment|//have to flush namespace to ensure it doesn't affect wall tests
name|admin
operator|.
name|flush
argument_list|(
name|TableName
operator|.
name|NAMESPACE_TABLE_NAME
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
comment|// Put some stuff into table2, to make sure we have some files to compact.
for|for
control|(
name|int
name|i
init|=
literal|1
init|;
name|i
operator|<=
literal|2
condition|;
operator|++
name|i
control|)
block|{
name|doPut
argument_list|(
name|table2
argument_list|,
name|i
argument_list|)
expr_stmt|;
name|admin
operator|.
name|flush
argument_list|(
name|table2
operator|.
name|getTableName
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|doPut
argument_list|(
name|table2
argument_list|,
literal|3
argument_list|)
expr_stmt|;
comment|// don't flush yet, or compaction might trigger before we roll WAL
name|assertEquals
argument_list|(
literal|"Should have no WAL after initial writes"
argument_list|,
literal|0
argument_list|,
name|fshLog
operator|.
name|getNumRolledLogFiles
argument_list|()
argument_list|)
expr_stmt|;
name|assertEquals
argument_list|(
literal|2
argument_list|,
name|s
operator|.
name|getStorefilesCount
argument_list|()
argument_list|)
expr_stmt|;
comment|// Roll the log and compact table2, to have compaction record in the 2nd WAL.
name|fshLog
operator|.
name|rollWriter
argument_list|()
expr_stmt|;
name|assertEquals
argument_list|(
literal|"Should have WAL; one table is not flushed"
argument_list|,
literal|1
argument_list|,
name|fshLog
operator|.
name|getNumRolledLogFiles
argument_list|()
argument_list|)
expr_stmt|;
name|admin
operator|.
name|flush
argument_list|(
name|table2
operator|.
name|getTableName
argument_list|()
argument_list|)
expr_stmt|;
name|region
operator|.
name|compactStores
argument_list|()
expr_stmt|;
comment|// Wait for compaction in case if flush triggered it before us.
name|Assert
operator|.
name|assertNotNull
argument_list|(
name|s
argument_list|)
expr_stmt|;
for|for
control|(
name|int
name|waitTime
init|=
literal|3000
init|;
name|s
operator|.
name|getStorefilesCount
argument_list|()
operator|>
literal|1
operator|&&
name|waitTime
operator|>
literal|0
condition|;
name|waitTime
operator|-=
literal|200
control|)
block|{
name|Threads
operator|.
name|sleepWithoutInterrupt
argument_list|(
literal|200
argument_list|)
expr_stmt|;
block|}
name|assertEquals
argument_list|(
literal|"Compaction didn't happen"
argument_list|,
literal|1
argument_list|,
name|s
operator|.
name|getStorefilesCount
argument_list|()
argument_list|)
expr_stmt|;
comment|// Write some value to the table so the WAL cannot be deleted until table is flushed.
name|doPut
argument_list|(
name|table
argument_list|,
literal|0
argument_list|)
expr_stmt|;
comment|// Now 2nd WAL will have compaction record for table2 and put for table.
name|fshLog
operator|.
name|rollWriter
argument_list|()
expr_stmt|;
comment|// 1st WAL deleted, 2nd not deleted yet.
name|assertEquals
argument_list|(
literal|"Should have WAL; one table is not flushed"
argument_list|,
literal|1
argument_list|,
name|fshLog
operator|.
name|getNumRolledLogFiles
argument_list|()
argument_list|)
expr_stmt|;
comment|// Flush table to make latest WAL obsolete; write another record, and roll again.
name|admin
operator|.
name|flush
argument_list|(
name|table
operator|.
name|getTableName
argument_list|()
argument_list|)
expr_stmt|;
name|doPut
argument_list|(
name|table
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|fshLog
operator|.
name|rollWriter
argument_list|()
expr_stmt|;
comment|// Now 2nd WAL is deleted and 3rd is added.
name|assertEquals
argument_list|(
literal|"Should have 1 WALs at the end"
argument_list|,
literal|1
argument_list|,
name|fshLog
operator|.
name|getNumRolledLogFiles
argument_list|()
argument_list|)
expr_stmt|;
name|table
operator|.
name|close
argument_list|()
expr_stmt|;
name|table2
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
specifier|private
name|void
name|doPut
parameter_list|(
name|HTable
name|table
parameter_list|,
name|int
name|i
parameter_list|)
throws|throws
name|IOException
block|{
name|Put
name|put
init|=
operator|new
name|Put
argument_list|(
name|Bytes
operator|.
name|toBytes
argument_list|(
literal|"row"
operator|+
name|String
operator|.
name|format
argument_list|(
literal|"%1$04d"
argument_list|,
name|i
argument_list|)
argument_list|)
argument_list|)
decl_stmt|;
name|put
operator|.
name|add
argument_list|(
name|HConstants
operator|.
name|CATALOG_FAMILY
argument_list|,
literal|null
argument_list|,
name|value
argument_list|)
expr_stmt|;
name|table
operator|.
name|put
argument_list|(
name|put
argument_list|)
expr_stmt|;
block|}
specifier|private
name|HTable
name|createTestTable
parameter_list|(
name|String
name|tableName
parameter_list|)
throws|throws
name|IOException
block|{
comment|// Create the test table and open it
name|HTableDescriptor
name|desc
init|=
operator|new
name|HTableDescriptor
argument_list|(
name|TableName
operator|.
name|valueOf
argument_list|(
name|tableName
argument_list|)
argument_list|)
decl_stmt|;
name|desc
operator|.
name|addFamily
argument_list|(
operator|new
name|HColumnDescriptor
argument_list|(
name|HConstants
operator|.
name|CATALOG_FAMILY
argument_list|)
argument_list|)
expr_stmt|;
name|admin
operator|.
name|createTable
argument_list|(
name|desc
argument_list|)
expr_stmt|;
return|return
operator|new
name|HTable
argument_list|(
name|TEST_UTIL
operator|.
name|getConfiguration
argument_list|()
argument_list|,
name|tableName
argument_list|)
return|;
block|}
block|}
end_class

end_unit

