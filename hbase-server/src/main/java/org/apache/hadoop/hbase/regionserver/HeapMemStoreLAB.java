begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  *  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
package|;
end_package

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|BlockingQueue
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|LinkedBlockingQueue
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|atomic
operator|.
name|AtomicBoolean
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|atomic
operator|.
name|AtomicInteger
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|atomic
operator|.
name|AtomicReference
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|Log
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|LogFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|Cell
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|KeyValueUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|classification
operator|.
name|InterfaceAudience
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|MemStoreChunkPool
operator|.
name|PooledChunk
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|annotations
operator|.
name|VisibleForTesting
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Preconditions
import|;
end_import

begin_comment
comment|/**  * A memstore-local allocation buffer.  *<p>  * The MemStoreLAB is basically a bump-the-pointer allocator that allocates  * big (2MB) byte[] chunks from and then doles it out to threads that request  * slices into the array.  *<p>  * The purpose of this class is to combat heap fragmentation in the  * regionserver. By ensuring that all KeyValues in a given memstore refer  * only to large chunks of contiguous memory, we ensure that large blocks  * get freed up when the memstore is flushed.  *<p>  * Without the MSLAB, the byte array allocated during insertion end up  * interleaved throughout the heap, and the old generation gets progressively  * more fragmented until a stop-the-world compacting collection occurs.  *<p>  * TODO: we should probably benchmark whether word-aligning the allocations  * would provide a performance improvement - probably would speed up the  * Bytes.toLong/Bytes.toInt calls in KeyValue, but some of those are cached  * anyway  */
end_comment

begin_class
annotation|@
name|InterfaceAudience
operator|.
name|Private
specifier|public
class|class
name|HeapMemStoreLAB
implements|implements
name|MemStoreLAB
block|{
specifier|static
specifier|final
name|String
name|CHUNK_SIZE_KEY
init|=
literal|"hbase.hregion.memstore.mslab.chunksize"
decl_stmt|;
specifier|static
specifier|final
name|int
name|CHUNK_SIZE_DEFAULT
init|=
literal|2048
operator|*
literal|1024
decl_stmt|;
specifier|static
specifier|final
name|String
name|MAX_ALLOC_KEY
init|=
literal|"hbase.hregion.memstore.mslab.max.allocation"
decl_stmt|;
specifier|static
specifier|final
name|int
name|MAX_ALLOC_DEFAULT
init|=
literal|256
operator|*
literal|1024
decl_stmt|;
comment|// allocs bigger than this don't go through
comment|// allocator
specifier|static
specifier|final
name|Log
name|LOG
init|=
name|LogFactory
operator|.
name|getLog
argument_list|(
name|HeapMemStoreLAB
operator|.
name|class
argument_list|)
decl_stmt|;
specifier|private
name|AtomicReference
argument_list|<
name|Chunk
argument_list|>
name|curChunk
init|=
operator|new
name|AtomicReference
argument_list|<
name|Chunk
argument_list|>
argument_list|()
decl_stmt|;
comment|// A queue of chunks from pool contained by this memstore LAB
annotation|@
name|VisibleForTesting
name|BlockingQueue
argument_list|<
name|PooledChunk
argument_list|>
name|pooledChunkQueue
init|=
literal|null
decl_stmt|;
specifier|private
specifier|final
name|int
name|chunkSize
decl_stmt|;
specifier|private
specifier|final
name|int
name|maxAlloc
decl_stmt|;
specifier|private
specifier|final
name|MemStoreChunkPool
name|chunkPool
decl_stmt|;
comment|// This flag is for closing this instance, its set when clearing snapshot of
comment|// memstore
specifier|private
specifier|volatile
name|boolean
name|closed
init|=
literal|false
decl_stmt|;
comment|// This flag is for reclaiming chunks. Its set when putting chunks back to
comment|// pool
specifier|private
name|AtomicBoolean
name|reclaimed
init|=
operator|new
name|AtomicBoolean
argument_list|(
literal|false
argument_list|)
decl_stmt|;
comment|// Current count of open scanners which reading data from this MemStoreLAB
specifier|private
specifier|final
name|AtomicInteger
name|openScannerCount
init|=
operator|new
name|AtomicInteger
argument_list|()
decl_stmt|;
comment|// Used in testing
specifier|public
name|HeapMemStoreLAB
parameter_list|()
block|{
name|this
argument_list|(
operator|new
name|Configuration
argument_list|()
argument_list|)
expr_stmt|;
block|}
specifier|public
name|HeapMemStoreLAB
parameter_list|(
name|Configuration
name|conf
parameter_list|)
block|{
name|chunkSize
operator|=
name|conf
operator|.
name|getInt
argument_list|(
name|CHUNK_SIZE_KEY
argument_list|,
name|CHUNK_SIZE_DEFAULT
argument_list|)
expr_stmt|;
name|maxAlloc
operator|=
name|conf
operator|.
name|getInt
argument_list|(
name|MAX_ALLOC_KEY
argument_list|,
name|MAX_ALLOC_DEFAULT
argument_list|)
expr_stmt|;
name|this
operator|.
name|chunkPool
operator|=
name|MemStoreChunkPool
operator|.
name|getPool
argument_list|(
name|conf
argument_list|)
expr_stmt|;
comment|// currently chunkQueue is only used for chunkPool
if|if
condition|(
name|this
operator|.
name|chunkPool
operator|!=
literal|null
condition|)
block|{
comment|// set queue length to chunk pool max count to avoid keeping reference of
comment|// too many non-reclaimable chunks
name|pooledChunkQueue
operator|=
operator|new
name|LinkedBlockingQueue
argument_list|<
name|PooledChunk
argument_list|>
argument_list|(
name|chunkPool
operator|.
name|getMaxCount
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|// if we don't exclude allocations>CHUNK_SIZE, we'd infiniteloop on one!
name|Preconditions
operator|.
name|checkArgument
argument_list|(
name|maxAlloc
operator|<=
name|chunkSize
argument_list|,
name|MAX_ALLOC_KEY
operator|+
literal|" must be less than "
operator|+
name|CHUNK_SIZE_KEY
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|Cell
name|copyCellInto
parameter_list|(
name|Cell
name|cell
parameter_list|)
block|{
name|int
name|size
init|=
name|KeyValueUtil
operator|.
name|length
argument_list|(
name|cell
argument_list|)
decl_stmt|;
name|Preconditions
operator|.
name|checkArgument
argument_list|(
name|size
operator|>=
literal|0
argument_list|,
literal|"negative size"
argument_list|)
expr_stmt|;
comment|// Callers should satisfy large allocations directly from JVM since they
comment|// don't cause fragmentation as badly.
if|if
condition|(
name|size
operator|>
name|maxAlloc
condition|)
block|{
return|return
literal|null
return|;
block|}
name|Chunk
name|c
init|=
literal|null
decl_stmt|;
name|int
name|allocOffset
init|=
literal|0
decl_stmt|;
while|while
condition|(
literal|true
condition|)
block|{
name|c
operator|=
name|getOrMakeChunk
argument_list|()
expr_stmt|;
comment|// Try to allocate from this chunk
name|allocOffset
operator|=
name|c
operator|.
name|alloc
argument_list|(
name|size
argument_list|)
expr_stmt|;
if|if
condition|(
name|allocOffset
operator|!=
operator|-
literal|1
condition|)
block|{
comment|// We succeeded - this is the common case - small alloc
comment|// from a big buffer
break|break;
block|}
comment|// not enough space!
comment|// try to retire this chunk
name|tryRetireChunk
argument_list|(
name|c
argument_list|)
expr_stmt|;
block|}
return|return
name|KeyValueUtil
operator|.
name|copyCellTo
argument_list|(
name|cell
argument_list|,
name|c
operator|.
name|getData
argument_list|()
argument_list|,
name|allocOffset
argument_list|,
name|size
argument_list|)
return|;
block|}
comment|/**    * Close this instance since it won't be used any more, try to put the chunks    * back to pool    */
annotation|@
name|Override
specifier|public
name|void
name|close
parameter_list|()
block|{
name|this
operator|.
name|closed
operator|=
literal|true
expr_stmt|;
comment|// We could put back the chunks to pool for reusing only when there is no
comment|// opening scanner which will read their data
if|if
condition|(
name|chunkPool
operator|!=
literal|null
operator|&&
name|openScannerCount
operator|.
name|get
argument_list|()
operator|==
literal|0
operator|&&
name|reclaimed
operator|.
name|compareAndSet
argument_list|(
literal|false
argument_list|,
literal|true
argument_list|)
condition|)
block|{
name|chunkPool
operator|.
name|putbackChunks
argument_list|(
name|this
operator|.
name|pooledChunkQueue
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Called when opening a scanner on the data of this MemStoreLAB    */
annotation|@
name|Override
specifier|public
name|void
name|incScannerCount
parameter_list|()
block|{
name|this
operator|.
name|openScannerCount
operator|.
name|incrementAndGet
argument_list|()
expr_stmt|;
block|}
comment|/**    * Called when closing a scanner on the data of this MemStoreLAB    */
annotation|@
name|Override
specifier|public
name|void
name|decScannerCount
parameter_list|()
block|{
name|int
name|count
init|=
name|this
operator|.
name|openScannerCount
operator|.
name|decrementAndGet
argument_list|()
decl_stmt|;
if|if
condition|(
name|this
operator|.
name|closed
operator|&&
name|chunkPool
operator|!=
literal|null
operator|&&
name|count
operator|==
literal|0
operator|&&
name|reclaimed
operator|.
name|compareAndSet
argument_list|(
literal|false
argument_list|,
literal|true
argument_list|)
condition|)
block|{
name|chunkPool
operator|.
name|putbackChunks
argument_list|(
name|this
operator|.
name|pooledChunkQueue
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Try to retire the current chunk if it is still    *<code>c</code>. Postcondition is that curChunk.get()    * != c    * @param c the chunk to retire    * @return true if we won the race to retire the chunk    */
specifier|private
name|void
name|tryRetireChunk
parameter_list|(
name|Chunk
name|c
parameter_list|)
block|{
name|curChunk
operator|.
name|compareAndSet
argument_list|(
name|c
argument_list|,
literal|null
argument_list|)
expr_stmt|;
comment|// If the CAS succeeds, that means that we won the race
comment|// to retire the chunk. We could use this opportunity to
comment|// update metrics on external fragmentation.
comment|//
comment|// If the CAS fails, that means that someone else already
comment|// retired the chunk for us.
block|}
comment|/**    * Get the current chunk, or, if there is no current chunk,    * allocate a new one from the JVM.    */
specifier|private
name|Chunk
name|getOrMakeChunk
parameter_list|()
block|{
while|while
condition|(
literal|true
condition|)
block|{
comment|// Try to get the chunk
name|Chunk
name|c
init|=
name|curChunk
operator|.
name|get
argument_list|()
decl_stmt|;
if|if
condition|(
name|c
operator|!=
literal|null
condition|)
block|{
return|return
name|c
return|;
block|}
comment|// No current chunk, so we want to allocate one. We race
comment|// against other allocators to CAS in an uninitialized chunk
comment|// (which is cheap to allocate)
if|if
condition|(
name|chunkPool
operator|!=
literal|null
condition|)
block|{
name|c
operator|=
name|chunkPool
operator|.
name|getChunk
argument_list|()
expr_stmt|;
block|}
name|boolean
name|pooledChunk
init|=
literal|false
decl_stmt|;
if|if
condition|(
name|c
operator|!=
literal|null
condition|)
block|{
comment|// This is chunk from pool
name|pooledChunk
operator|=
literal|true
expr_stmt|;
block|}
else|else
block|{
name|c
operator|=
operator|new
name|Chunk
argument_list|(
name|chunkSize
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|curChunk
operator|.
name|compareAndSet
argument_list|(
literal|null
argument_list|,
name|c
argument_list|)
condition|)
block|{
comment|// we won race - now we need to actually do the expensive
comment|// allocation step
name|c
operator|.
name|init
argument_list|()
expr_stmt|;
if|if
condition|(
name|pooledChunk
condition|)
block|{
if|if
condition|(
operator|!
name|this
operator|.
name|closed
operator|&&
operator|!
name|this
operator|.
name|pooledChunkQueue
operator|.
name|offer
argument_list|(
operator|(
name|PooledChunk
operator|)
name|c
argument_list|)
condition|)
block|{
if|if
condition|(
name|LOG
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|trace
argument_list|(
literal|"Chunk queue is full, won't reuse this new chunk. Current queue size: "
operator|+
name|pooledChunkQueue
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
block|}
return|return
name|c
return|;
block|}
elseif|else
if|if
condition|(
name|pooledChunk
condition|)
block|{
name|chunkPool
operator|.
name|putbackChunk
argument_list|(
operator|(
name|PooledChunk
operator|)
name|c
argument_list|)
expr_stmt|;
block|}
comment|// someone else won race - that's fine, we'll try to grab theirs
comment|// in the next iteration of the loop.
block|}
block|}
annotation|@
name|VisibleForTesting
name|Chunk
name|getCurrentChunk
parameter_list|()
block|{
return|return
name|this
operator|.
name|curChunk
operator|.
name|get
argument_list|()
return|;
block|}
annotation|@
name|VisibleForTesting
name|BlockingQueue
argument_list|<
name|PooledChunk
argument_list|>
name|getChunkQueue
parameter_list|()
block|{
return|return
name|this
operator|.
name|pooledChunkQueue
return|;
block|}
block|}
end_class

end_unit

