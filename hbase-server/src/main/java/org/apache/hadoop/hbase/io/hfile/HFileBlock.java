begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/*  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|hfile
package|;
end_package

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|ByteBuffAllocator
operator|.
name|HEAP
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|DataInputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|DataOutput
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|DataOutputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|nio
operator|.
name|ByteBuffer
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|atomic
operator|.
name|AtomicReference
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|locks
operator|.
name|Lock
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|locks
operator|.
name|ReentrantLock
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FSDataInputStream
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FSDataOutputStream
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|Cell
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HConstants
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|ByteBuffAllocator
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|util
operator|.
name|BlockIOUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|yetus
operator|.
name|audience
operator|.
name|InterfaceAudience
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|Logger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|LoggerFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|fs
operator|.
name|HFileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|ByteArrayOutputStream
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|ByteBuffInputStream
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|ByteBufferWriterDataOutputStream
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|FSDataInputStreamWrapper
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|encoding
operator|.
name|DataBlockEncoding
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|encoding
operator|.
name|HFileBlockDecodingContext
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|encoding
operator|.
name|HFileBlockDefaultDecodingContext
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|encoding
operator|.
name|HFileBlockDefaultEncodingContext
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|encoding
operator|.
name|HFileBlockEncodingContext
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|nio
operator|.
name|ByteBuff
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|nio
operator|.
name|MultiByteBuff
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|nio
operator|.
name|SingleByteBuff
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|Bytes
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|ChecksumType
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|ClassSize
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hbase
operator|.
name|thirdparty
operator|.
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|annotations
operator|.
name|VisibleForTesting
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hbase
operator|.
name|thirdparty
operator|.
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Preconditions
import|;
end_import

begin_comment
comment|/**  * Cacheable Blocks of an {@link HFile} version 2 file.  * Version 2 was introduced in hbase-0.92.0.  *  *<p>Version 1 was the original file block. Version 2 was introduced when we changed the hbase file  * format to support multi-level block indexes and compound bloom filters (HBASE-3857). Support  * for Version 1 was removed in hbase-1.3.0.  *  *<h3>HFileBlock: Version 2</h3>  * In version 2, a block is structured as follows:  *<ul>  *<li><b>Header:</b> See Writer#putHeader() for where header is written; header total size is  * HFILEBLOCK_HEADER_SIZE  *<ul>  *<li>0. blockType: Magic record identifying the {@link BlockType} (8 bytes):  * e.g.<code>DATABLK*</code>  *<li>1. onDiskSizeWithoutHeader: Compressed -- a.k.a 'on disk' -- block size, excluding header,  * but including tailing checksum bytes (4 bytes)  *<li>2. uncompressedSizeWithoutHeader: Uncompressed block size, excluding header, and excluding  * checksum bytes (4 bytes)  *<li>3. prevBlockOffset: The offset of the previous block of the same type (8 bytes). This is  * used to navigate to the previous block without having to go to the block index  *<li>4: For minorVersions&gt;=1, the ordinal describing checksum type (1 byte)  *<li>5: For minorVersions&gt;=1, the number of data bytes/checksum chunk (4 bytes)  *<li>6: onDiskDataSizeWithHeader: For minorVersions&gt;=1, the size of data 'on disk', including  * header, excluding checksums (4 bytes)  *</ul>  *</li>  *<li><b>Raw/Compressed/Encrypted/Encoded data:</b> The compression  * algorithm is the same for all the blocks in an {@link HFile}. If compression is NONE, this is  * just raw, serialized Cells.  *<li><b>Tail:</b> For minorVersions&gt;=1, a series of 4 byte checksums, one each for  * the number of bytes specified by bytesPerChecksum.  *</ul>  *  *<h3>Caching</h3>  * Caches cache whole blocks with trailing checksums if any. We then tag on some metadata, the  * content of BLOCK_METADATA_SPACE which will be flag on if we are doing 'hbase'  * checksums and then the offset into the file which is needed when we re-make a cache key  * when we return the block to the cache as 'done'.  * See {@link Cacheable#serialize(ByteBuffer, boolean)} and {@link Cacheable#getDeserializer()}.  *  *<p>TODO: Should we cache the checksums? Down in Writer#getBlockForCaching(CacheConfig) where  * we make a block to cache-on-write, there is an attempt at turning off checksums. This is not the  * only place we get blocks to cache. We also will cache the raw return from an hdfs read. In this  * case, the checksums may be present. If the cache is backed by something that doesn't do ECC,  * say an SSD, we might want to preserve checksums. For now this is open question.  *<p>TODO: Over in BucketCache, we save a block allocation by doing a custom serialization.  * Be sure to change it if serialization changes in here. Could we add a method here that takes an  * IOEngine and that then serializes to it rather than expose our internals over in BucketCache?  * IOEngine is in the bucket subpackage. Pull it up? Then this class knows about bucketcache. Ugh.  */
end_comment

begin_class
annotation|@
name|InterfaceAudience
operator|.
name|Private
specifier|public
class|class
name|HFileBlock
implements|implements
name|Cacheable
block|{
specifier|private
specifier|static
specifier|final
name|Logger
name|LOG
init|=
name|LoggerFactory
operator|.
name|getLogger
argument_list|(
name|HFileBlock
operator|.
name|class
argument_list|)
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|int
name|FIXED_OVERHEAD
init|=
name|ClassSize
operator|.
name|align
argument_list|(
name|ClassSize
operator|.
name|OBJECT
operator|+
comment|// BlockType, ByteBuff, MemoryType, HFileContext, ByteBuffAllocator
literal|5
operator|*
name|ClassSize
operator|.
name|REFERENCE
operator|+
comment|// On-disk size, uncompressed size, and next block's on-disk size
comment|// bytePerChecksum and onDiskDataSize
literal|4
operator|*
name|Bytes
operator|.
name|SIZEOF_INT
operator|+
comment|// This and previous block offset
literal|2
operator|*
name|Bytes
operator|.
name|SIZEOF_LONG
argument_list|)
decl_stmt|;
comment|// Block Header fields.
comment|// TODO: encapsulate Header related logic in this inner class.
specifier|static
class|class
name|Header
block|{
comment|// Format of header is:
comment|// 8 bytes - block magic
comment|// 4 bytes int - onDiskSizeWithoutHeader
comment|// 4 bytes int - uncompressedSizeWithoutHeader
comment|// 8 bytes long - prevBlockOffset
comment|// The following 3 are only present if header contains checksum information
comment|// 1 byte - checksum type
comment|// 4 byte int - bytes per checksum
comment|// 4 byte int - onDiskDataSizeWithHeader
specifier|static
name|int
name|BLOCK_MAGIC_INDEX
init|=
literal|0
decl_stmt|;
specifier|static
name|int
name|ON_DISK_SIZE_WITHOUT_HEADER_INDEX
init|=
literal|8
decl_stmt|;
specifier|static
name|int
name|UNCOMPRESSED_SIZE_WITHOUT_HEADER_INDEX
init|=
literal|12
decl_stmt|;
specifier|static
name|int
name|PREV_BLOCK_OFFSET_INDEX
init|=
literal|16
decl_stmt|;
specifier|static
name|int
name|CHECKSUM_TYPE_INDEX
init|=
literal|24
decl_stmt|;
specifier|static
name|int
name|BYTES_PER_CHECKSUM_INDEX
init|=
literal|25
decl_stmt|;
specifier|static
name|int
name|ON_DISK_DATA_SIZE_WITH_HEADER_INDEX
init|=
literal|29
decl_stmt|;
block|}
comment|/** Type of block. Header field 0. */
specifier|private
name|BlockType
name|blockType
decl_stmt|;
comment|/**    * Size on disk excluding header, including checksum. Header field 1.    * @see Writer#putHeader(byte[], int, int, int, int)    */
specifier|private
name|int
name|onDiskSizeWithoutHeader
decl_stmt|;
comment|/**    * Size of pure data. Does not include header or checksums. Header field 2.    * @see Writer#putHeader(byte[], int, int, int, int)    */
specifier|private
name|int
name|uncompressedSizeWithoutHeader
decl_stmt|;
comment|/**    * The offset of the previous block on disk. Header field 3.    * @see Writer#putHeader(byte[], int, int, int, int)    */
specifier|private
name|long
name|prevBlockOffset
decl_stmt|;
comment|/**    * Size on disk of header + data. Excludes checksum. Header field 6,    * OR calculated from {@link #onDiskSizeWithoutHeader} when using HDFS checksum.    * @see Writer#putHeader(byte[], int, int, int, int)    */
specifier|private
name|int
name|onDiskDataSizeWithHeader
decl_stmt|;
comment|// End of Block Header fields.
comment|/**    * The in-memory representation of the hfile block. Can be on or offheap. Can be backed by    * a single ByteBuffer or by many. Make no assumptions.    *    *<p>Be careful reading from this<code>buf</code>. Duplicate and work on the duplicate or if    * not, be sure to reset position and limit else trouble down the road.    *    *<p>TODO: Make this read-only once made.    *    *<p>We are using the ByteBuff type. ByteBuffer is not extensible yet we need to be able to have    * a ByteBuffer-like API across multiple ByteBuffers reading from a cache such as BucketCache.    * So, we have this ByteBuff type. Unfortunately, it is spread all about HFileBlock. Would be    * good if could be confined to cache-use only but hard-to-do.    */
specifier|private
name|ByteBuff
name|buf
decl_stmt|;
comment|/** Meta data that holds meta information on the hfileblock.    */
specifier|private
name|HFileContext
name|fileContext
decl_stmt|;
comment|/**    * The offset of this block in the file. Populated by the reader for    * convenience of access. This offset is not part of the block header.    */
specifier|private
name|long
name|offset
init|=
name|UNSET
decl_stmt|;
specifier|private
name|MemoryType
name|memType
init|=
name|MemoryType
operator|.
name|EXCLUSIVE
decl_stmt|;
comment|/**    * The on-disk size of the next block, including the header and checksums if present.    * UNSET if unknown.    *    * Blocks try to carry the size of the next block to read in this data member. Usually    * we get block sizes from the hfile index but sometimes the index is not available:    * e.g. when we read the indexes themselves (indexes are stored in blocks, we do not    * have an index for the indexes). Saves seeks especially around file open when    * there is a flurry of reading in hfile metadata.    */
specifier|private
name|int
name|nextBlockOnDiskSize
init|=
name|UNSET
decl_stmt|;
specifier|private
name|ByteBuffAllocator
name|allocator
decl_stmt|;
comment|/**    * On a checksum failure, do these many succeeding read requests using hdfs checksums before    * auto-reenabling hbase checksum verification.    */
specifier|static
specifier|final
name|int
name|CHECKSUM_VERIFICATION_NUM_IO_THRESHOLD
init|=
literal|3
decl_stmt|;
specifier|private
specifier|static
name|int
name|UNSET
init|=
operator|-
literal|1
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|boolean
name|FILL_HEADER
init|=
literal|true
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|boolean
name|DONT_FILL_HEADER
init|=
literal|false
decl_stmt|;
comment|// How to get the estimate correctly? if it is a singleBB?
specifier|public
specifier|static
specifier|final
name|int
name|MULTI_BYTE_BUFFER_HEAP_SIZE
init|=
operator|(
name|int
operator|)
name|ClassSize
operator|.
name|estimateBase
argument_list|(
name|MultiByteBuff
operator|.
name|class
argument_list|,
literal|false
argument_list|)
decl_stmt|;
comment|/**    * Space for metadata on a block that gets stored along with the block when we cache it.    * There are a few bytes stuck on the end of the HFileBlock that we pull in from HDFS.    * 8 bytes are for the offset of this block (long) in the file. Offset is important because is is    * used when we remake the CacheKey when we return block to the cache when done. There is also    * a flag on whether checksumming is being done by hbase or not. See class comment for note on    * uncertain state of checksumming of blocks that come out of cache (should we or should we not?).    * Finally there are 4 bytes to hold the length of the next block which can save a seek on    * occasion if available.    * (This EXTRA info came in with original commit of the bucketcache, HBASE-7404. It was    * formerly known as EXTRA_SERIALIZATION_SPACE).    */
specifier|static
specifier|final
name|int
name|BLOCK_METADATA_SPACE
init|=
name|Bytes
operator|.
name|SIZEOF_BYTE
operator|+
name|Bytes
operator|.
name|SIZEOF_LONG
operator|+
name|Bytes
operator|.
name|SIZEOF_INT
decl_stmt|;
comment|/**    * Each checksum value is an integer that can be stored in 4 bytes.    */
specifier|static
specifier|final
name|int
name|CHECKSUM_SIZE
init|=
name|Bytes
operator|.
name|SIZEOF_INT
decl_stmt|;
specifier|static
specifier|final
name|byte
index|[]
name|DUMMY_HEADER_NO_CHECKSUM
init|=
operator|new
name|byte
index|[
name|HConstants
operator|.
name|HFILEBLOCK_HEADER_SIZE_NO_CHECKSUM
index|]
decl_stmt|;
comment|/**    * Used deserializing blocks from Cache.    *    *<code>    * ++++++++++++++    * + HFileBlock +    * ++++++++++++++    * + Checksums  +<= Optional    * ++++++++++++++    * + Metadata!  +<= See note on BLOCK_METADATA_SPACE above.    * ++++++++++++++    *</code>    * @see #serialize(ByteBuffer, boolean)    */
specifier|public
specifier|static
specifier|final
name|CacheableDeserializer
argument_list|<
name|Cacheable
argument_list|>
name|BLOCK_DESERIALIZER
init|=
operator|new
name|BlockDeserializer
argument_list|()
decl_stmt|;
specifier|public
specifier|static
specifier|final
class|class
name|BlockDeserializer
implements|implements
name|CacheableDeserializer
argument_list|<
name|Cacheable
argument_list|>
block|{
specifier|private
name|BlockDeserializer
parameter_list|()
block|{     }
annotation|@
name|Override
specifier|public
name|HFileBlock
name|deserialize
parameter_list|(
name|ByteBuff
name|buf
parameter_list|,
name|ByteBuffAllocator
name|alloc
parameter_list|,
name|MemoryType
name|memType
parameter_list|)
throws|throws
name|IOException
block|{
comment|// The buf has the file block followed by block metadata.
comment|// Set limit to just before the BLOCK_METADATA_SPACE then rewind.
name|buf
operator|.
name|limit
argument_list|(
name|buf
operator|.
name|limit
argument_list|()
operator|-
name|BLOCK_METADATA_SPACE
argument_list|)
operator|.
name|rewind
argument_list|()
expr_stmt|;
comment|// Get a new buffer to pass the HFileBlock for it to 'own'.
name|ByteBuff
name|newByteBuff
init|=
name|buf
operator|.
name|slice
argument_list|()
decl_stmt|;
comment|// Read out the BLOCK_METADATA_SPACE content and shove into our HFileBlock.
name|buf
operator|.
name|position
argument_list|(
name|buf
operator|.
name|limit
argument_list|()
argument_list|)
expr_stmt|;
name|buf
operator|.
name|limit
argument_list|(
name|buf
operator|.
name|limit
argument_list|()
operator|+
name|HFileBlock
operator|.
name|BLOCK_METADATA_SPACE
argument_list|)
expr_stmt|;
name|boolean
name|usesChecksum
init|=
name|buf
operator|.
name|get
argument_list|()
operator|==
operator|(
name|byte
operator|)
literal|1
decl_stmt|;
name|long
name|offset
init|=
name|buf
operator|.
name|getLong
argument_list|()
decl_stmt|;
name|int
name|nextBlockOnDiskSize
init|=
name|buf
operator|.
name|getInt
argument_list|()
decl_stmt|;
return|return
operator|new
name|HFileBlock
argument_list|(
name|newByteBuff
argument_list|,
name|usesChecksum
argument_list|,
name|memType
argument_list|,
name|offset
argument_list|,
name|nextBlockOnDiskSize
argument_list|,
literal|null
argument_list|,
name|alloc
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|int
name|getDeserializerIdentifier
parameter_list|()
block|{
return|return
name|DESERIALIZER_IDENTIFIER
return|;
block|}
block|}
specifier|private
specifier|static
specifier|final
name|int
name|DESERIALIZER_IDENTIFIER
decl_stmt|;
static|static
block|{
name|DESERIALIZER_IDENTIFIER
operator|=
name|CacheableDeserializerIdManager
operator|.
name|registerDeserializer
argument_list|(
name|BLOCK_DESERIALIZER
argument_list|)
expr_stmt|;
block|}
comment|/**    * Copy constructor. Creates a shallow copy of {@code that}'s buffer.    */
specifier|private
name|HFileBlock
parameter_list|(
name|HFileBlock
name|that
parameter_list|)
block|{
name|this
argument_list|(
name|that
argument_list|,
literal|false
argument_list|)
expr_stmt|;
block|}
comment|/**    * Copy constructor. Creates a shallow/deep copy of {@code that}'s buffer as per the boolean    * param.    */
specifier|private
name|HFileBlock
parameter_list|(
name|HFileBlock
name|that
parameter_list|,
name|boolean
name|bufCopy
parameter_list|)
block|{
name|init
argument_list|(
name|that
operator|.
name|blockType
argument_list|,
name|that
operator|.
name|onDiskSizeWithoutHeader
argument_list|,
name|that
operator|.
name|uncompressedSizeWithoutHeader
argument_list|,
name|that
operator|.
name|prevBlockOffset
argument_list|,
name|that
operator|.
name|offset
argument_list|,
name|that
operator|.
name|onDiskDataSizeWithHeader
argument_list|,
name|that
operator|.
name|nextBlockOnDiskSize
argument_list|,
name|that
operator|.
name|fileContext
argument_list|,
name|that
operator|.
name|allocator
argument_list|)
expr_stmt|;
if|if
condition|(
name|bufCopy
condition|)
block|{
name|this
operator|.
name|buf
operator|=
name|ByteBuff
operator|.
name|wrap
argument_list|(
name|ByteBuffer
operator|.
name|wrap
argument_list|(
name|that
operator|.
name|buf
operator|.
name|toBytes
argument_list|(
literal|0
argument_list|,
name|that
operator|.
name|buf
operator|.
name|limit
argument_list|()
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|this
operator|.
name|buf
operator|=
name|that
operator|.
name|buf
operator|.
name|duplicate
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**    * Creates a new {@link HFile} block from the given fields. This constructor    * is used only while writing blocks and caching,    * and is sitting in a byte buffer and we want to stuff the block into cache.    *    *<p>TODO: The caller presumes no checksumming    *<p>TODO: HFile block writer can also off-heap ?</p>    * required of this block instance since going into cache; checksum already verified on    * underlying block data pulled in from filesystem. Is that correct? What if cache is SSD?    *    * @param blockType the type of this block, see {@link BlockType}    * @param onDiskSizeWithoutHeader see {@link #onDiskSizeWithoutHeader}    * @param uncompressedSizeWithoutHeader see {@link #uncompressedSizeWithoutHeader}    * @param prevBlockOffset see {@link #prevBlockOffset}    * @param b block header ({@link HConstants#HFILEBLOCK_HEADER_SIZE} bytes)    * @param fillHeader when true, write the first 4 header fields into passed buffer.    * @param offset the file offset the block was read from    * @param onDiskDataSizeWithHeader see {@link #onDiskDataSizeWithHeader}    * @param fileContext HFile meta data    */
annotation|@
name|VisibleForTesting
specifier|public
name|HFileBlock
parameter_list|(
name|BlockType
name|blockType
parameter_list|,
name|int
name|onDiskSizeWithoutHeader
parameter_list|,
name|int
name|uncompressedSizeWithoutHeader
parameter_list|,
name|long
name|prevBlockOffset
parameter_list|,
name|ByteBuffer
name|b
parameter_list|,
name|boolean
name|fillHeader
parameter_list|,
name|long
name|offset
parameter_list|,
specifier|final
name|int
name|nextBlockOnDiskSize
parameter_list|,
name|int
name|onDiskDataSizeWithHeader
parameter_list|,
name|HFileContext
name|fileContext
parameter_list|,
name|ByteBuffAllocator
name|allocator
parameter_list|)
block|{
name|init
argument_list|(
name|blockType
argument_list|,
name|onDiskSizeWithoutHeader
argument_list|,
name|uncompressedSizeWithoutHeader
argument_list|,
name|prevBlockOffset
argument_list|,
name|offset
argument_list|,
name|onDiskDataSizeWithHeader
argument_list|,
name|nextBlockOnDiskSize
argument_list|,
name|fileContext
argument_list|,
name|allocator
argument_list|)
expr_stmt|;
name|this
operator|.
name|buf
operator|=
operator|new
name|SingleByteBuff
argument_list|(
name|b
argument_list|)
expr_stmt|;
if|if
condition|(
name|fillHeader
condition|)
block|{
name|overwriteHeader
argument_list|()
expr_stmt|;
block|}
name|this
operator|.
name|buf
operator|.
name|rewind
argument_list|()
expr_stmt|;
block|}
comment|/**    * Creates a block from an existing buffer starting with a header. Rewinds    * and takes ownership of the buffer. By definition of rewind, ignores the    * buffer position, but if you slice the buffer beforehand, it will rewind    * to that point.    * @param buf Has header, content, and trailing checksums if present.    */
name|HFileBlock
parameter_list|(
name|ByteBuff
name|buf
parameter_list|,
name|boolean
name|usesHBaseChecksum
parameter_list|,
name|MemoryType
name|memType
parameter_list|,
specifier|final
name|long
name|offset
parameter_list|,
specifier|final
name|int
name|nextBlockOnDiskSize
parameter_list|,
name|HFileContext
name|fileContext
parameter_list|,
name|ByteBuffAllocator
name|allocator
parameter_list|)
throws|throws
name|IOException
block|{
name|buf
operator|.
name|rewind
argument_list|()
expr_stmt|;
specifier|final
name|BlockType
name|blockType
init|=
name|BlockType
operator|.
name|read
argument_list|(
name|buf
argument_list|)
decl_stmt|;
specifier|final
name|int
name|onDiskSizeWithoutHeader
init|=
name|buf
operator|.
name|getInt
argument_list|(
name|Header
operator|.
name|ON_DISK_SIZE_WITHOUT_HEADER_INDEX
argument_list|)
decl_stmt|;
specifier|final
name|int
name|uncompressedSizeWithoutHeader
init|=
name|buf
operator|.
name|getInt
argument_list|(
name|Header
operator|.
name|UNCOMPRESSED_SIZE_WITHOUT_HEADER_INDEX
argument_list|)
decl_stmt|;
specifier|final
name|long
name|prevBlockOffset
init|=
name|buf
operator|.
name|getLong
argument_list|(
name|Header
operator|.
name|PREV_BLOCK_OFFSET_INDEX
argument_list|)
decl_stmt|;
comment|// This constructor is called when we deserialize a block from cache and when we read a block in
comment|// from the fs. fileCache is null when deserialized from cache so need to make up one.
name|HFileContextBuilder
name|fileContextBuilder
init|=
name|fileContext
operator|!=
literal|null
condition|?
operator|new
name|HFileContextBuilder
argument_list|(
name|fileContext
argument_list|)
else|:
operator|new
name|HFileContextBuilder
argument_list|()
decl_stmt|;
name|fileContextBuilder
operator|.
name|withHBaseCheckSum
argument_list|(
name|usesHBaseChecksum
argument_list|)
expr_stmt|;
name|int
name|onDiskDataSizeWithHeader
decl_stmt|;
if|if
condition|(
name|usesHBaseChecksum
condition|)
block|{
name|byte
name|checksumType
init|=
name|buf
operator|.
name|get
argument_list|(
name|Header
operator|.
name|CHECKSUM_TYPE_INDEX
argument_list|)
decl_stmt|;
name|int
name|bytesPerChecksum
init|=
name|buf
operator|.
name|getInt
argument_list|(
name|Header
operator|.
name|BYTES_PER_CHECKSUM_INDEX
argument_list|)
decl_stmt|;
name|onDiskDataSizeWithHeader
operator|=
name|buf
operator|.
name|getInt
argument_list|(
name|Header
operator|.
name|ON_DISK_DATA_SIZE_WITH_HEADER_INDEX
argument_list|)
expr_stmt|;
comment|// Use the checksum type and bytes per checksum from header, not from filecontext.
name|fileContextBuilder
operator|.
name|withChecksumType
argument_list|(
name|ChecksumType
operator|.
name|codeToType
argument_list|(
name|checksumType
argument_list|)
argument_list|)
expr_stmt|;
name|fileContextBuilder
operator|.
name|withBytesPerCheckSum
argument_list|(
name|bytesPerChecksum
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|fileContextBuilder
operator|.
name|withChecksumType
argument_list|(
name|ChecksumType
operator|.
name|NULL
argument_list|)
expr_stmt|;
name|fileContextBuilder
operator|.
name|withBytesPerCheckSum
argument_list|(
literal|0
argument_list|)
expr_stmt|;
comment|// Need to fix onDiskDataSizeWithHeader; there are not checksums after-block-data
name|onDiskDataSizeWithHeader
operator|=
name|onDiskSizeWithoutHeader
operator|+
name|headerSize
argument_list|(
name|usesHBaseChecksum
argument_list|)
expr_stmt|;
block|}
name|fileContext
operator|=
name|fileContextBuilder
operator|.
name|build
argument_list|()
expr_stmt|;
assert|assert
name|usesHBaseChecksum
operator|==
name|fileContext
operator|.
name|isUseHBaseChecksum
argument_list|()
assert|;
name|init
argument_list|(
name|blockType
argument_list|,
name|onDiskSizeWithoutHeader
argument_list|,
name|uncompressedSizeWithoutHeader
argument_list|,
name|prevBlockOffset
argument_list|,
name|offset
argument_list|,
name|onDiskDataSizeWithHeader
argument_list|,
name|nextBlockOnDiskSize
argument_list|,
name|fileContext
argument_list|,
name|allocator
argument_list|)
expr_stmt|;
name|this
operator|.
name|memType
operator|=
name|memType
expr_stmt|;
name|this
operator|.
name|offset
operator|=
name|offset
expr_stmt|;
name|this
operator|.
name|buf
operator|=
name|buf
expr_stmt|;
name|this
operator|.
name|buf
operator|.
name|rewind
argument_list|()
expr_stmt|;
block|}
comment|/**    * Called from constructors.    */
specifier|private
name|void
name|init
parameter_list|(
name|BlockType
name|blockType
parameter_list|,
name|int
name|onDiskSizeWithoutHeader
parameter_list|,
name|int
name|uncompressedSizeWithoutHeader
parameter_list|,
name|long
name|prevBlockOffset
parameter_list|,
name|long
name|offset
parameter_list|,
name|int
name|onDiskDataSizeWithHeader
parameter_list|,
specifier|final
name|int
name|nextBlockOnDiskSize
parameter_list|,
name|HFileContext
name|fileContext
parameter_list|,
name|ByteBuffAllocator
name|allocator
parameter_list|)
block|{
name|this
operator|.
name|blockType
operator|=
name|blockType
expr_stmt|;
name|this
operator|.
name|onDiskSizeWithoutHeader
operator|=
name|onDiskSizeWithoutHeader
expr_stmt|;
name|this
operator|.
name|uncompressedSizeWithoutHeader
operator|=
name|uncompressedSizeWithoutHeader
expr_stmt|;
name|this
operator|.
name|prevBlockOffset
operator|=
name|prevBlockOffset
expr_stmt|;
name|this
operator|.
name|offset
operator|=
name|offset
expr_stmt|;
name|this
operator|.
name|onDiskDataSizeWithHeader
operator|=
name|onDiskDataSizeWithHeader
expr_stmt|;
name|this
operator|.
name|nextBlockOnDiskSize
operator|=
name|nextBlockOnDiskSize
expr_stmt|;
name|this
operator|.
name|fileContext
operator|=
name|fileContext
expr_stmt|;
name|this
operator|.
name|allocator
operator|=
name|allocator
expr_stmt|;
block|}
comment|/**    * Parse total on disk size including header and checksum.    * @param headerBuf Header ByteBuffer. Presumed exact size of header.    * @param verifyChecksum true if checksum verification is in use.    * @return Size of the block with header included.    */
specifier|private
specifier|static
name|int
name|getOnDiskSizeWithHeader
parameter_list|(
specifier|final
name|ByteBuff
name|headerBuf
parameter_list|,
name|boolean
name|verifyChecksum
parameter_list|)
block|{
return|return
name|headerBuf
operator|.
name|getInt
argument_list|(
name|Header
operator|.
name|ON_DISK_SIZE_WITHOUT_HEADER_INDEX
argument_list|)
operator|+
name|headerSize
argument_list|(
name|verifyChecksum
argument_list|)
return|;
block|}
comment|/**    * @return the on-disk size of the next block (including the header size and any checksums if    * present) read by peeking into the next block's header; use as a hint when doing    * a read of the next block when scanning or running over a file.    */
name|int
name|getNextBlockOnDiskSize
parameter_list|()
block|{
return|return
name|nextBlockOnDiskSize
return|;
block|}
annotation|@
name|Override
specifier|public
name|BlockType
name|getBlockType
parameter_list|()
block|{
return|return
name|blockType
return|;
block|}
annotation|@
name|Override
specifier|public
name|int
name|refCnt
parameter_list|()
block|{
return|return
name|buf
operator|.
name|refCnt
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|HFileBlock
name|retain
parameter_list|()
block|{
name|buf
operator|.
name|retain
argument_list|()
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**    * Call {@link ByteBuff#release()} to decrease the reference count, if no other reference, it will    * return back the {@link ByteBuffer} to {@link org.apache.hadoop.hbase.io.ByteBuffAllocator}    */
annotation|@
name|Override
specifier|public
name|boolean
name|release
parameter_list|()
block|{
return|return
name|buf
operator|.
name|release
argument_list|()
return|;
block|}
comment|/** @return get data block encoding id that was used to encode this block */
name|short
name|getDataBlockEncodingId
parameter_list|()
block|{
if|if
condition|(
name|blockType
operator|!=
name|BlockType
operator|.
name|ENCODED_DATA
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"Querying encoder ID of a block "
operator|+
literal|"of type other than "
operator|+
name|BlockType
operator|.
name|ENCODED_DATA
operator|+
literal|": "
operator|+
name|blockType
argument_list|)
throw|;
block|}
return|return
name|buf
operator|.
name|getShort
argument_list|(
name|headerSize
argument_list|()
argument_list|)
return|;
block|}
comment|/**    * @return the on-disk size of header + data part + checksum.    */
specifier|public
name|int
name|getOnDiskSizeWithHeader
parameter_list|()
block|{
return|return
name|onDiskSizeWithoutHeader
operator|+
name|headerSize
argument_list|()
return|;
block|}
comment|/**    * @return the on-disk size of the data part + checksum (header excluded).    */
name|int
name|getOnDiskSizeWithoutHeader
parameter_list|()
block|{
return|return
name|onDiskSizeWithoutHeader
return|;
block|}
comment|/**    * @return the uncompressed size of data part (header and checksum excluded).    */
name|int
name|getUncompressedSizeWithoutHeader
parameter_list|()
block|{
return|return
name|uncompressedSizeWithoutHeader
return|;
block|}
comment|/**    * @return the offset of the previous block of the same type in the file, or    *         -1 if unknown    */
name|long
name|getPrevBlockOffset
parameter_list|()
block|{
return|return
name|prevBlockOffset
return|;
block|}
comment|/**    * Rewinds {@code buf} and writes first 4 header fields. {@code buf} position    * is modified as side-effect.    */
specifier|private
name|void
name|overwriteHeader
parameter_list|()
block|{
name|buf
operator|.
name|rewind
argument_list|()
expr_stmt|;
name|blockType
operator|.
name|write
argument_list|(
name|buf
argument_list|)
expr_stmt|;
name|buf
operator|.
name|putInt
argument_list|(
name|onDiskSizeWithoutHeader
argument_list|)
expr_stmt|;
name|buf
operator|.
name|putInt
argument_list|(
name|uncompressedSizeWithoutHeader
argument_list|)
expr_stmt|;
name|buf
operator|.
name|putLong
argument_list|(
name|prevBlockOffset
argument_list|)
expr_stmt|;
if|if
condition|(
name|this
operator|.
name|fileContext
operator|.
name|isUseHBaseChecksum
argument_list|()
condition|)
block|{
name|buf
operator|.
name|put
argument_list|(
name|fileContext
operator|.
name|getChecksumType
argument_list|()
operator|.
name|getCode
argument_list|()
argument_list|)
expr_stmt|;
name|buf
operator|.
name|putInt
argument_list|(
name|fileContext
operator|.
name|getBytesPerChecksum
argument_list|()
argument_list|)
expr_stmt|;
name|buf
operator|.
name|putInt
argument_list|(
name|onDiskDataSizeWithHeader
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Returns a buffer that does not include the header and checksum.    * @return the buffer with header skipped and checksum omitted.    */
specifier|public
name|ByteBuff
name|getBufferWithoutHeader
parameter_list|()
block|{
return|return
name|this
operator|.
name|getBufferWithoutHeader
argument_list|(
literal|false
argument_list|)
return|;
block|}
comment|/**    * Returns a buffer that does not include the header or checksum.    * @param withChecksum to indicate whether include the checksum or not.    * @return the buffer with header skipped and checksum omitted.    */
specifier|public
name|ByteBuff
name|getBufferWithoutHeader
parameter_list|(
name|boolean
name|withChecksum
parameter_list|)
block|{
name|ByteBuff
name|dup
init|=
name|getBufferReadOnly
argument_list|()
decl_stmt|;
name|int
name|delta
init|=
name|withChecksum
condition|?
literal|0
else|:
name|totalChecksumBytes
argument_list|()
decl_stmt|;
return|return
name|dup
operator|.
name|position
argument_list|(
name|headerSize
argument_list|()
argument_list|)
operator|.
name|limit
argument_list|(
name|buf
operator|.
name|limit
argument_list|()
operator|-
name|delta
argument_list|)
operator|.
name|slice
argument_list|()
return|;
block|}
comment|/**    * Returns a read-only duplicate of the buffer this block stores internally ready to be read.    * Clients must not modify the buffer object though they may set position and limit on the    * returned buffer since we pass back a duplicate. This method has to be public because it is used    * in {@link CompoundBloomFilter} to avoid object creation on every Bloom    * filter lookup, but has to be used with caution. Buffer holds header, block content,    * and any follow-on checksums if present.    *    * @return the buffer of this block for read-only operations    */
specifier|public
name|ByteBuff
name|getBufferReadOnly
parameter_list|()
block|{
comment|// TODO: ByteBuf does not support asReadOnlyBuffer(). Fix.
name|ByteBuff
name|dup
init|=
name|this
operator|.
name|buf
operator|.
name|duplicate
argument_list|()
decl_stmt|;
assert|assert
name|dup
operator|.
name|position
argument_list|()
operator|==
literal|0
assert|;
return|return
name|dup
return|;
block|}
specifier|public
name|ByteBuffAllocator
name|getByteBuffAllocator
parameter_list|()
block|{
return|return
name|this
operator|.
name|allocator
return|;
block|}
annotation|@
name|VisibleForTesting
specifier|private
name|void
name|sanityCheckAssertion
parameter_list|(
name|long
name|valueFromBuf
parameter_list|,
name|long
name|valueFromField
parameter_list|,
name|String
name|fieldName
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|valueFromBuf
operator|!=
name|valueFromField
condition|)
block|{
throw|throw
operator|new
name|AssertionError
argument_list|(
name|fieldName
operator|+
literal|" in the buffer ("
operator|+
name|valueFromBuf
operator|+
literal|") is different from that in the field ("
operator|+
name|valueFromField
operator|+
literal|")"
argument_list|)
throw|;
block|}
block|}
annotation|@
name|VisibleForTesting
specifier|private
name|void
name|sanityCheckAssertion
parameter_list|(
name|BlockType
name|valueFromBuf
parameter_list|,
name|BlockType
name|valueFromField
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|valueFromBuf
operator|!=
name|valueFromField
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Block type stored in the buffer: "
operator|+
name|valueFromBuf
operator|+
literal|", block type field: "
operator|+
name|valueFromField
argument_list|)
throw|;
block|}
block|}
comment|/**    * Checks if the block is internally consistent, i.e. the first    * {@link HConstants#HFILEBLOCK_HEADER_SIZE} bytes of the buffer contain a    * valid header consistent with the fields. Assumes a packed block structure.    * This function is primary for testing and debugging, and is not    * thread-safe, because it alters the internal buffer pointer.    * Used by tests only.    */
annotation|@
name|VisibleForTesting
name|void
name|sanityCheck
parameter_list|()
throws|throws
name|IOException
block|{
comment|// Duplicate so no side-effects
name|ByteBuff
name|dup
init|=
name|this
operator|.
name|buf
operator|.
name|duplicate
argument_list|()
operator|.
name|rewind
argument_list|()
decl_stmt|;
name|sanityCheckAssertion
argument_list|(
name|BlockType
operator|.
name|read
argument_list|(
name|dup
argument_list|)
argument_list|,
name|blockType
argument_list|)
expr_stmt|;
name|sanityCheckAssertion
argument_list|(
name|dup
operator|.
name|getInt
argument_list|()
argument_list|,
name|onDiskSizeWithoutHeader
argument_list|,
literal|"onDiskSizeWithoutHeader"
argument_list|)
expr_stmt|;
name|sanityCheckAssertion
argument_list|(
name|dup
operator|.
name|getInt
argument_list|()
argument_list|,
name|uncompressedSizeWithoutHeader
argument_list|,
literal|"uncompressedSizeWithoutHeader"
argument_list|)
expr_stmt|;
name|sanityCheckAssertion
argument_list|(
name|dup
operator|.
name|getLong
argument_list|()
argument_list|,
name|prevBlockOffset
argument_list|,
literal|"prevBlockOffset"
argument_list|)
expr_stmt|;
if|if
condition|(
name|this
operator|.
name|fileContext
operator|.
name|isUseHBaseChecksum
argument_list|()
condition|)
block|{
name|sanityCheckAssertion
argument_list|(
name|dup
operator|.
name|get
argument_list|()
argument_list|,
name|this
operator|.
name|fileContext
operator|.
name|getChecksumType
argument_list|()
operator|.
name|getCode
argument_list|()
argument_list|,
literal|"checksumType"
argument_list|)
expr_stmt|;
name|sanityCheckAssertion
argument_list|(
name|dup
operator|.
name|getInt
argument_list|()
argument_list|,
name|this
operator|.
name|fileContext
operator|.
name|getBytesPerChecksum
argument_list|()
argument_list|,
literal|"bytesPerChecksum"
argument_list|)
expr_stmt|;
name|sanityCheckAssertion
argument_list|(
name|dup
operator|.
name|getInt
argument_list|()
argument_list|,
name|onDiskDataSizeWithHeader
argument_list|,
literal|"onDiskDataSizeWithHeader"
argument_list|)
expr_stmt|;
block|}
name|int
name|cksumBytes
init|=
name|totalChecksumBytes
argument_list|()
decl_stmt|;
name|int
name|expectedBufLimit
init|=
name|onDiskDataSizeWithHeader
operator|+
name|cksumBytes
decl_stmt|;
if|if
condition|(
name|dup
operator|.
name|limit
argument_list|()
operator|!=
name|expectedBufLimit
condition|)
block|{
throw|throw
operator|new
name|AssertionError
argument_list|(
literal|"Expected limit "
operator|+
name|expectedBufLimit
operator|+
literal|", got "
operator|+
name|dup
operator|.
name|limit
argument_list|()
argument_list|)
throw|;
block|}
comment|// We might optionally allocate HFILEBLOCK_HEADER_SIZE more bytes to read the next
comment|// block's header, so there are two sensible values for buffer capacity.
name|int
name|hdrSize
init|=
name|headerSize
argument_list|()
decl_stmt|;
name|dup
operator|.
name|rewind
argument_list|()
expr_stmt|;
if|if
condition|(
name|dup
operator|.
name|remaining
argument_list|()
operator|!=
name|expectedBufLimit
operator|&&
name|dup
operator|.
name|remaining
argument_list|()
operator|!=
name|expectedBufLimit
operator|+
name|hdrSize
condition|)
block|{
throw|throw
operator|new
name|AssertionError
argument_list|(
literal|"Invalid buffer capacity: "
operator|+
name|dup
operator|.
name|remaining
argument_list|()
operator|+
literal|", expected "
operator|+
name|expectedBufLimit
operator|+
literal|" or "
operator|+
operator|(
name|expectedBufLimit
operator|+
name|hdrSize
operator|)
argument_list|)
throw|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|String
name|toString
parameter_list|()
block|{
name|StringBuilder
name|sb
init|=
operator|new
name|StringBuilder
argument_list|()
operator|.
name|append
argument_list|(
literal|"["
argument_list|)
operator|.
name|append
argument_list|(
literal|"blockType="
argument_list|)
operator|.
name|append
argument_list|(
name|blockType
argument_list|)
operator|.
name|append
argument_list|(
literal|", fileOffset="
argument_list|)
operator|.
name|append
argument_list|(
name|offset
argument_list|)
operator|.
name|append
argument_list|(
literal|", headerSize="
argument_list|)
operator|.
name|append
argument_list|(
name|headerSize
argument_list|()
argument_list|)
operator|.
name|append
argument_list|(
literal|", onDiskSizeWithoutHeader="
argument_list|)
operator|.
name|append
argument_list|(
name|onDiskSizeWithoutHeader
argument_list|)
operator|.
name|append
argument_list|(
literal|", uncompressedSizeWithoutHeader="
argument_list|)
operator|.
name|append
argument_list|(
name|uncompressedSizeWithoutHeader
argument_list|)
operator|.
name|append
argument_list|(
literal|", prevBlockOffset="
argument_list|)
operator|.
name|append
argument_list|(
name|prevBlockOffset
argument_list|)
operator|.
name|append
argument_list|(
literal|", isUseHBaseChecksum="
argument_list|)
operator|.
name|append
argument_list|(
name|fileContext
operator|.
name|isUseHBaseChecksum
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|fileContext
operator|.
name|isUseHBaseChecksum
argument_list|()
condition|)
block|{
name|sb
operator|.
name|append
argument_list|(
literal|", checksumType="
argument_list|)
operator|.
name|append
argument_list|(
name|ChecksumType
operator|.
name|codeToType
argument_list|(
name|this
operator|.
name|buf
operator|.
name|get
argument_list|(
literal|24
argument_list|)
argument_list|)
argument_list|)
operator|.
name|append
argument_list|(
literal|", bytesPerChecksum="
argument_list|)
operator|.
name|append
argument_list|(
name|this
operator|.
name|buf
operator|.
name|getInt
argument_list|(
literal|24
operator|+
literal|1
argument_list|)
argument_list|)
operator|.
name|append
argument_list|(
literal|", onDiskDataSizeWithHeader="
argument_list|)
operator|.
name|append
argument_list|(
name|onDiskDataSizeWithHeader
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|sb
operator|.
name|append
argument_list|(
literal|", onDiskDataSizeWithHeader="
argument_list|)
operator|.
name|append
argument_list|(
name|onDiskDataSizeWithHeader
argument_list|)
operator|.
name|append
argument_list|(
literal|"("
argument_list|)
operator|.
name|append
argument_list|(
name|onDiskSizeWithoutHeader
argument_list|)
operator|.
name|append
argument_list|(
literal|"+"
argument_list|)
operator|.
name|append
argument_list|(
name|HConstants
operator|.
name|HFILEBLOCK_HEADER_SIZE_NO_CHECKSUM
argument_list|)
operator|.
name|append
argument_list|(
literal|")"
argument_list|)
expr_stmt|;
block|}
name|String
name|dataBegin
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|buf
operator|.
name|hasArray
argument_list|()
condition|)
block|{
name|dataBegin
operator|=
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|buf
operator|.
name|array
argument_list|()
argument_list|,
name|buf
operator|.
name|arrayOffset
argument_list|()
operator|+
name|headerSize
argument_list|()
argument_list|,
name|Math
operator|.
name|min
argument_list|(
literal|32
argument_list|,
name|buf
operator|.
name|limit
argument_list|()
operator|-
name|buf
operator|.
name|arrayOffset
argument_list|()
operator|-
name|headerSize
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|ByteBuff
name|bufWithoutHeader
init|=
name|getBufferWithoutHeader
argument_list|()
decl_stmt|;
name|byte
index|[]
name|dataBeginBytes
init|=
operator|new
name|byte
index|[
name|Math
operator|.
name|min
argument_list|(
literal|32
argument_list|,
name|bufWithoutHeader
operator|.
name|limit
argument_list|()
operator|-
name|bufWithoutHeader
operator|.
name|position
argument_list|()
argument_list|)
index|]
decl_stmt|;
name|bufWithoutHeader
operator|.
name|get
argument_list|(
name|dataBeginBytes
argument_list|)
expr_stmt|;
name|dataBegin
operator|=
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|dataBeginBytes
argument_list|)
expr_stmt|;
block|}
name|sb
operator|.
name|append
argument_list|(
literal|", getOnDiskSizeWithHeader="
argument_list|)
operator|.
name|append
argument_list|(
name|getOnDiskSizeWithHeader
argument_list|()
argument_list|)
operator|.
name|append
argument_list|(
literal|", totalChecksumBytes="
argument_list|)
operator|.
name|append
argument_list|(
name|totalChecksumBytes
argument_list|()
argument_list|)
operator|.
name|append
argument_list|(
literal|", isUnpacked="
argument_list|)
operator|.
name|append
argument_list|(
name|isUnpacked
argument_list|()
argument_list|)
operator|.
name|append
argument_list|(
literal|", buf=["
argument_list|)
operator|.
name|append
argument_list|(
name|buf
argument_list|)
operator|.
name|append
argument_list|(
literal|"]"
argument_list|)
operator|.
name|append
argument_list|(
literal|", dataBeginsWith="
argument_list|)
operator|.
name|append
argument_list|(
name|dataBegin
argument_list|)
operator|.
name|append
argument_list|(
literal|", fileContext="
argument_list|)
operator|.
name|append
argument_list|(
name|fileContext
argument_list|)
operator|.
name|append
argument_list|(
literal|", nextBlockOnDiskSize="
argument_list|)
operator|.
name|append
argument_list|(
name|nextBlockOnDiskSize
argument_list|)
operator|.
name|append
argument_list|(
literal|"]"
argument_list|)
expr_stmt|;
return|return
name|sb
operator|.
name|toString
argument_list|()
return|;
block|}
comment|/**    * Retrieves the decompressed/decrypted view of this block. An encoded block remains in its    * encoded structure. Internal structures are shared between instances where applicable.    */
name|HFileBlock
name|unpack
parameter_list|(
name|HFileContext
name|fileContext
parameter_list|,
name|FSReader
name|reader
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
operator|!
name|fileContext
operator|.
name|isCompressedOrEncrypted
argument_list|()
condition|)
block|{
comment|// TODO: cannot use our own fileContext here because HFileBlock(ByteBuffer, boolean),
comment|// which is used for block serialization to L2 cache, does not preserve encoding and
comment|// encryption details.
return|return
name|this
return|;
block|}
name|HFileBlock
name|unpacked
init|=
operator|new
name|HFileBlock
argument_list|(
name|this
argument_list|)
decl_stmt|;
name|unpacked
operator|.
name|allocateBuffer
argument_list|()
expr_stmt|;
comment|// allocates space for the decompressed block
name|boolean
name|succ
init|=
literal|false
decl_stmt|;
try|try
block|{
name|HFileBlockDecodingContext
name|ctx
init|=
name|blockType
operator|==
name|BlockType
operator|.
name|ENCODED_DATA
condition|?
name|reader
operator|.
name|getBlockDecodingContext
argument_list|()
else|:
name|reader
operator|.
name|getDefaultBlockDecodingContext
argument_list|()
decl_stmt|;
comment|// Create a duplicated buffer without the header part.
name|ByteBuff
name|dup
init|=
name|this
operator|.
name|buf
operator|.
name|duplicate
argument_list|()
decl_stmt|;
name|dup
operator|.
name|position
argument_list|(
name|this
operator|.
name|headerSize
argument_list|()
argument_list|)
expr_stmt|;
name|dup
operator|=
name|dup
operator|.
name|slice
argument_list|()
expr_stmt|;
comment|// Decode the dup into unpacked#buf
name|ctx
operator|.
name|prepareDecoding
argument_list|(
name|unpacked
operator|.
name|getOnDiskSizeWithoutHeader
argument_list|()
argument_list|,
name|unpacked
operator|.
name|getUncompressedSizeWithoutHeader
argument_list|()
argument_list|,
name|unpacked
operator|.
name|getBufferWithoutHeader
argument_list|(
literal|true
argument_list|)
argument_list|,
name|dup
argument_list|)
expr_stmt|;
name|succ
operator|=
literal|true
expr_stmt|;
return|return
name|unpacked
return|;
block|}
finally|finally
block|{
if|if
condition|(
operator|!
name|succ
condition|)
block|{
name|unpacked
operator|.
name|release
argument_list|()
expr_stmt|;
block|}
block|}
block|}
comment|/**    * Always allocates a new buffer of the correct size. Copies header bytes    * from the existing buffer. Does not change header fields.    * Reserve room to keep checksum bytes too.    */
specifier|private
name|void
name|allocateBuffer
parameter_list|()
block|{
name|int
name|cksumBytes
init|=
name|totalChecksumBytes
argument_list|()
decl_stmt|;
name|int
name|headerSize
init|=
name|headerSize
argument_list|()
decl_stmt|;
name|int
name|capacityNeeded
init|=
name|headerSize
operator|+
name|uncompressedSizeWithoutHeader
operator|+
name|cksumBytes
decl_stmt|;
name|ByteBuff
name|newBuf
init|=
name|allocator
operator|.
name|allocate
argument_list|(
name|capacityNeeded
argument_list|)
decl_stmt|;
comment|// Copy header bytes into newBuf.
name|buf
operator|.
name|position
argument_list|(
literal|0
argument_list|)
expr_stmt|;
name|newBuf
operator|.
name|put
argument_list|(
literal|0
argument_list|,
name|buf
argument_list|,
literal|0
argument_list|,
name|headerSize
argument_list|)
expr_stmt|;
name|buf
operator|=
name|newBuf
expr_stmt|;
comment|// set limit to exclude next block's header
name|buf
operator|.
name|limit
argument_list|(
name|capacityNeeded
argument_list|)
expr_stmt|;
block|}
comment|/**    * Return true when this block's buffer has been unpacked, false otherwise. Note this is a    * calculated heuristic, not tracked attribute of the block.    */
specifier|public
name|boolean
name|isUnpacked
parameter_list|()
block|{
specifier|final
name|int
name|cksumBytes
init|=
name|totalChecksumBytes
argument_list|()
decl_stmt|;
specifier|final
name|int
name|headerSize
init|=
name|headerSize
argument_list|()
decl_stmt|;
specifier|final
name|int
name|expectedCapacity
init|=
name|headerSize
operator|+
name|uncompressedSizeWithoutHeader
operator|+
name|cksumBytes
decl_stmt|;
specifier|final
name|int
name|bufCapacity
init|=
name|buf
operator|.
name|remaining
argument_list|()
decl_stmt|;
return|return
name|bufCapacity
operator|==
name|expectedCapacity
operator|||
name|bufCapacity
operator|==
name|expectedCapacity
operator|+
name|headerSize
return|;
block|}
comment|/**    * Cannot be {@link #UNSET}. Must be a legitimate value. Used re-making the {@link BlockCacheKey} when    * block is returned to the cache.    * @return the offset of this block in the file it was read from    */
name|long
name|getOffset
parameter_list|()
block|{
if|if
condition|(
name|offset
operator|<
literal|0
condition|)
block|{
throw|throw
operator|new
name|IllegalStateException
argument_list|(
literal|"HFile block offset not initialized properly"
argument_list|)
throw|;
block|}
return|return
name|offset
return|;
block|}
comment|/**    * @return a byte stream reading the data + checksum of this block    */
name|DataInputStream
name|getByteStream
parameter_list|()
block|{
name|ByteBuff
name|dup
init|=
name|this
operator|.
name|buf
operator|.
name|duplicate
argument_list|()
decl_stmt|;
name|dup
operator|.
name|position
argument_list|(
name|this
operator|.
name|headerSize
argument_list|()
argument_list|)
expr_stmt|;
return|return
operator|new
name|DataInputStream
argument_list|(
operator|new
name|ByteBuffInputStream
argument_list|(
name|dup
argument_list|)
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|heapSize
parameter_list|()
block|{
name|long
name|size
init|=
name|FIXED_OVERHEAD
decl_stmt|;
name|size
operator|+=
name|fileContext
operator|.
name|heapSize
argument_list|()
expr_stmt|;
if|if
condition|(
name|buf
operator|!=
literal|null
condition|)
block|{
comment|// Deep overhead of the byte buffer. Needs to be aligned separately.
name|size
operator|+=
name|ClassSize
operator|.
name|align
argument_list|(
name|buf
operator|.
name|capacity
argument_list|()
operator|+
name|MULTI_BYTE_BUFFER_HEAP_SIZE
argument_list|)
expr_stmt|;
block|}
return|return
name|ClassSize
operator|.
name|align
argument_list|(
name|size
argument_list|)
return|;
block|}
comment|/**    * @return true to indicate the block is allocated from JVM heap, otherwise from off-heap.    */
name|boolean
name|isOnHeap
parameter_list|()
block|{
return|return
name|buf
operator|.
name|hasArray
argument_list|()
return|;
block|}
comment|/**    * Unified version 2 {@link HFile} block writer. The intended usage pattern    * is as follows:    *<ol>    *<li>Construct an {@link HFileBlock.Writer}, providing a compression algorithm.    *<li>Call {@link Writer#startWriting} and get a data stream to write to.    *<li>Write your data into the stream.    *<li>Call Writer#writeHeaderAndData(FSDataOutputStream) as many times as you need to.    * store the serialized block into an external stream.    *<li>Repeat to write more blocks.    *</ol>    *<p>    */
specifier|static
class|class
name|Writer
block|{
specifier|private
enum|enum
name|State
block|{
name|INIT
block|,
name|WRITING
block|,
name|BLOCK_READY
block|}
comment|/** Writer state. Used to ensure the correct usage protocol. */
specifier|private
name|State
name|state
init|=
name|State
operator|.
name|INIT
decl_stmt|;
comment|/** Data block encoder used for data blocks */
specifier|private
specifier|final
name|HFileDataBlockEncoder
name|dataBlockEncoder
decl_stmt|;
specifier|private
name|HFileBlockEncodingContext
name|dataBlockEncodingCtx
decl_stmt|;
comment|/** block encoding context for non-data blocks*/
specifier|private
name|HFileBlockDefaultEncodingContext
name|defaultBlockEncodingCtx
decl_stmt|;
comment|/**      * The stream we use to accumulate data into a block in an uncompressed format.      * We reset this stream at the end of each block and reuse it. The      * header is written as the first {@link HConstants#HFILEBLOCK_HEADER_SIZE} bytes into this      * stream.      */
specifier|private
name|ByteArrayOutputStream
name|baosInMemory
decl_stmt|;
comment|/**      * Current block type. Set in {@link #startWriting(BlockType)}. Could be      * changed in {@link #finishBlock()} from {@link BlockType#DATA}      * to {@link BlockType#ENCODED_DATA}.      */
specifier|private
name|BlockType
name|blockType
decl_stmt|;
comment|/**      * A stream that we write uncompressed bytes to, which compresses them and      * writes them to {@link #baosInMemory}.      */
specifier|private
name|DataOutputStream
name|userDataStream
decl_stmt|;
comment|// Size of actual data being written. Not considering the block encoding/compression. This
comment|// includes the header size also.
specifier|private
name|int
name|unencodedDataSizeWritten
decl_stmt|;
comment|// Size of actual data being written. considering the block encoding. This
comment|// includes the header size also.
specifier|private
name|int
name|encodedDataSizeWritten
decl_stmt|;
comment|/**      * Bytes to be written to the file system, including the header. Compressed      * if compression is turned on. It also includes the checksum data that      * immediately follows the block data. (header + data + checksums)      */
specifier|private
name|ByteArrayOutputStream
name|onDiskBlockBytesWithHeader
decl_stmt|;
comment|/**      * The size of the checksum data on disk. It is used only if data is      * not compressed. If data is compressed, then the checksums are already      * part of onDiskBytesWithHeader. If data is uncompressed, then this      * variable stores the checksum data for this block.      */
specifier|private
name|byte
index|[]
name|onDiskChecksum
init|=
name|HConstants
operator|.
name|EMPTY_BYTE_ARRAY
decl_stmt|;
comment|/**      * Current block's start offset in the {@link HFile}. Set in      * {@link #writeHeaderAndData(FSDataOutputStream)}.      */
specifier|private
name|long
name|startOffset
decl_stmt|;
comment|/**      * Offset of previous block by block type. Updated when the next block is      * started.      */
specifier|private
name|long
index|[]
name|prevOffsetByType
decl_stmt|;
comment|/** The offset of the previous block of the same type */
specifier|private
name|long
name|prevOffset
decl_stmt|;
comment|/** Meta data that holds information about the hfileblock**/
specifier|private
name|HFileContext
name|fileContext
decl_stmt|;
comment|/**      * @param dataBlockEncoder data block encoding algorithm to use      */
specifier|public
name|Writer
parameter_list|(
name|HFileDataBlockEncoder
name|dataBlockEncoder
parameter_list|,
name|HFileContext
name|fileContext
parameter_list|)
block|{
if|if
condition|(
name|fileContext
operator|.
name|getBytesPerChecksum
argument_list|()
operator|<
name|HConstants
operator|.
name|HFILEBLOCK_HEADER_SIZE
condition|)
block|{
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"Unsupported value of bytesPerChecksum. "
operator|+
literal|" Minimum is "
operator|+
name|HConstants
operator|.
name|HFILEBLOCK_HEADER_SIZE
operator|+
literal|" but the configured value is "
operator|+
name|fileContext
operator|.
name|getBytesPerChecksum
argument_list|()
argument_list|)
throw|;
block|}
name|this
operator|.
name|dataBlockEncoder
operator|=
name|dataBlockEncoder
operator|!=
literal|null
condition|?
name|dataBlockEncoder
else|:
name|NoOpDataBlockEncoder
operator|.
name|INSTANCE
expr_stmt|;
name|this
operator|.
name|dataBlockEncodingCtx
operator|=
name|this
operator|.
name|dataBlockEncoder
operator|.
name|newDataBlockEncodingContext
argument_list|(
name|HConstants
operator|.
name|HFILEBLOCK_DUMMY_HEADER
argument_list|,
name|fileContext
argument_list|)
expr_stmt|;
comment|// TODO: This should be lazily instantiated since we usually do NOT need this default encoder
name|this
operator|.
name|defaultBlockEncodingCtx
operator|=
operator|new
name|HFileBlockDefaultEncodingContext
argument_list|(
literal|null
argument_list|,
name|HConstants
operator|.
name|HFILEBLOCK_DUMMY_HEADER
argument_list|,
name|fileContext
argument_list|)
expr_stmt|;
comment|// TODO: Set BAOS initial size. Use fileContext.getBlocksize() and add for header/checksum
name|baosInMemory
operator|=
operator|new
name|ByteArrayOutputStream
argument_list|()
expr_stmt|;
name|prevOffsetByType
operator|=
operator|new
name|long
index|[
name|BlockType
operator|.
name|values
argument_list|()
operator|.
name|length
index|]
expr_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|prevOffsetByType
operator|.
name|length
condition|;
operator|++
name|i
control|)
block|{
name|prevOffsetByType
index|[
name|i
index|]
operator|=
name|UNSET
expr_stmt|;
block|}
comment|// TODO: Why fileContext saved away when we have dataBlockEncoder and/or
comment|// defaultDataBlockEncoder?
name|this
operator|.
name|fileContext
operator|=
name|fileContext
expr_stmt|;
block|}
comment|/**      * Starts writing into the block. The previous block's data is discarded.      *      * @return the stream the user can write their data into      * @throws IOException      */
name|DataOutputStream
name|startWriting
parameter_list|(
name|BlockType
name|newBlockType
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|state
operator|==
name|State
operator|.
name|BLOCK_READY
operator|&&
name|startOffset
operator|!=
operator|-
literal|1
condition|)
block|{
comment|// We had a previous block that was written to a stream at a specific
comment|// offset. Save that offset as the last offset of a block of that type.
name|prevOffsetByType
index|[
name|blockType
operator|.
name|getId
argument_list|()
index|]
operator|=
name|startOffset
expr_stmt|;
block|}
name|startOffset
operator|=
operator|-
literal|1
expr_stmt|;
name|blockType
operator|=
name|newBlockType
expr_stmt|;
name|baosInMemory
operator|.
name|reset
argument_list|()
expr_stmt|;
name|baosInMemory
operator|.
name|write
argument_list|(
name|HConstants
operator|.
name|HFILEBLOCK_DUMMY_HEADER
argument_list|)
expr_stmt|;
name|state
operator|=
name|State
operator|.
name|WRITING
expr_stmt|;
comment|// We will compress it later in finishBlock()
name|userDataStream
operator|=
operator|new
name|ByteBufferWriterDataOutputStream
argument_list|(
name|baosInMemory
argument_list|)
expr_stmt|;
if|if
condition|(
name|newBlockType
operator|==
name|BlockType
operator|.
name|DATA
condition|)
block|{
name|this
operator|.
name|dataBlockEncoder
operator|.
name|startBlockEncoding
argument_list|(
name|dataBlockEncodingCtx
argument_list|,
name|userDataStream
argument_list|)
expr_stmt|;
block|}
name|this
operator|.
name|unencodedDataSizeWritten
operator|=
literal|0
expr_stmt|;
name|this
operator|.
name|encodedDataSizeWritten
operator|=
literal|0
expr_stmt|;
return|return
name|userDataStream
return|;
block|}
comment|/**      * Writes the Cell to this block      * @param cell      * @throws IOException      */
name|void
name|write
parameter_list|(
name|Cell
name|cell
parameter_list|)
throws|throws
name|IOException
block|{
name|expectState
argument_list|(
name|State
operator|.
name|WRITING
argument_list|)
expr_stmt|;
name|int
name|posBeforeEncode
init|=
name|this
operator|.
name|userDataStream
operator|.
name|size
argument_list|()
decl_stmt|;
name|this
operator|.
name|unencodedDataSizeWritten
operator|+=
name|this
operator|.
name|dataBlockEncoder
operator|.
name|encode
argument_list|(
name|cell
argument_list|,
name|dataBlockEncodingCtx
argument_list|,
name|this
operator|.
name|userDataStream
argument_list|)
expr_stmt|;
name|this
operator|.
name|encodedDataSizeWritten
operator|+=
name|this
operator|.
name|userDataStream
operator|.
name|size
argument_list|()
operator|-
name|posBeforeEncode
expr_stmt|;
block|}
comment|/**      * Transitions the block writer from the "writing" state to the "block      * ready" state.  Does nothing if a block is already finished.      */
name|void
name|ensureBlockReady
parameter_list|()
throws|throws
name|IOException
block|{
name|Preconditions
operator|.
name|checkState
argument_list|(
name|state
operator|!=
name|State
operator|.
name|INIT
argument_list|,
literal|"Unexpected state: "
operator|+
name|state
argument_list|)
expr_stmt|;
if|if
condition|(
name|state
operator|==
name|State
operator|.
name|BLOCK_READY
condition|)
block|{
return|return;
block|}
comment|// This will set state to BLOCK_READY.
name|finishBlock
argument_list|()
expr_stmt|;
block|}
comment|/**      * Finish up writing of the block.      * Flushes the compressing stream (if using compression), fills out the header,      * does any compression/encryption of bytes to flush out to disk, and manages      * the cache on write content, if applicable. Sets block write state to "block ready".      */
specifier|private
name|void
name|finishBlock
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|blockType
operator|==
name|BlockType
operator|.
name|DATA
condition|)
block|{
name|this
operator|.
name|dataBlockEncoder
operator|.
name|endBlockEncoding
argument_list|(
name|dataBlockEncodingCtx
argument_list|,
name|userDataStream
argument_list|,
name|baosInMemory
operator|.
name|getBuffer
argument_list|()
argument_list|,
name|blockType
argument_list|)
expr_stmt|;
name|blockType
operator|=
name|dataBlockEncodingCtx
operator|.
name|getBlockType
argument_list|()
expr_stmt|;
block|}
name|userDataStream
operator|.
name|flush
argument_list|()
expr_stmt|;
name|prevOffset
operator|=
name|prevOffsetByType
index|[
name|blockType
operator|.
name|getId
argument_list|()
index|]
expr_stmt|;
comment|// We need to set state before we can package the block up for cache-on-write. In a way, the
comment|// block is ready, but not yet encoded or compressed.
name|state
operator|=
name|State
operator|.
name|BLOCK_READY
expr_stmt|;
name|Bytes
name|compressAndEncryptDat
decl_stmt|;
if|if
condition|(
name|blockType
operator|==
name|BlockType
operator|.
name|DATA
operator|||
name|blockType
operator|==
name|BlockType
operator|.
name|ENCODED_DATA
condition|)
block|{
name|compressAndEncryptDat
operator|=
name|dataBlockEncodingCtx
operator|.
name|compressAndEncrypt
argument_list|(
name|baosInMemory
operator|.
name|getBuffer
argument_list|()
argument_list|,
literal|0
argument_list|,
name|baosInMemory
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|compressAndEncryptDat
operator|=
name|defaultBlockEncodingCtx
operator|.
name|compressAndEncrypt
argument_list|(
name|baosInMemory
operator|.
name|getBuffer
argument_list|()
argument_list|,
literal|0
argument_list|,
name|baosInMemory
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|compressAndEncryptDat
operator|==
literal|null
condition|)
block|{
name|compressAndEncryptDat
operator|=
operator|new
name|Bytes
argument_list|(
name|baosInMemory
operator|.
name|getBuffer
argument_list|()
argument_list|,
literal|0
argument_list|,
name|baosInMemory
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|onDiskBlockBytesWithHeader
operator|==
literal|null
condition|)
block|{
name|onDiskBlockBytesWithHeader
operator|=
operator|new
name|ByteArrayOutputStream
argument_list|(
name|compressAndEncryptDat
operator|.
name|getLength
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|onDiskBlockBytesWithHeader
operator|.
name|reset
argument_list|()
expr_stmt|;
name|onDiskBlockBytesWithHeader
operator|.
name|write
argument_list|(
name|compressAndEncryptDat
operator|.
name|get
argument_list|()
argument_list|,
name|compressAndEncryptDat
operator|.
name|getOffset
argument_list|()
argument_list|,
name|compressAndEncryptDat
operator|.
name|getLength
argument_list|()
argument_list|)
expr_stmt|;
comment|// Calculate how many bytes we need for checksum on the tail of the block.
name|int
name|numBytes
init|=
operator|(
name|int
operator|)
name|ChecksumUtil
operator|.
name|numBytes
argument_list|(
name|onDiskBlockBytesWithHeader
operator|.
name|size
argument_list|()
argument_list|,
name|fileContext
operator|.
name|getBytesPerChecksum
argument_list|()
argument_list|)
decl_stmt|;
comment|// Put the header for the on disk bytes; header currently is unfilled-out
name|putHeader
argument_list|(
name|onDiskBlockBytesWithHeader
argument_list|,
name|onDiskBlockBytesWithHeader
operator|.
name|size
argument_list|()
operator|+
name|numBytes
argument_list|,
name|baosInMemory
operator|.
name|size
argument_list|()
argument_list|,
name|onDiskBlockBytesWithHeader
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|onDiskChecksum
operator|.
name|length
operator|!=
name|numBytes
condition|)
block|{
name|onDiskChecksum
operator|=
operator|new
name|byte
index|[
name|numBytes
index|]
expr_stmt|;
block|}
name|ChecksumUtil
operator|.
name|generateChecksums
argument_list|(
name|onDiskBlockBytesWithHeader
operator|.
name|getBuffer
argument_list|()
argument_list|,
literal|0
argument_list|,
name|onDiskBlockBytesWithHeader
operator|.
name|size
argument_list|()
argument_list|,
name|onDiskChecksum
argument_list|,
literal|0
argument_list|,
name|fileContext
operator|.
name|getChecksumType
argument_list|()
argument_list|,
name|fileContext
operator|.
name|getBytesPerChecksum
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|/**      * Put the header into the given byte array at the given offset.      * @param onDiskSize size of the block on disk header + data + checksum      * @param uncompressedSize size of the block after decompression (but      *          before optional data block decoding) including header      * @param onDiskDataSize size of the block on disk with header      *        and data but not including the checksums      */
specifier|private
name|void
name|putHeader
parameter_list|(
name|byte
index|[]
name|dest
parameter_list|,
name|int
name|offset
parameter_list|,
name|int
name|onDiskSize
parameter_list|,
name|int
name|uncompressedSize
parameter_list|,
name|int
name|onDiskDataSize
parameter_list|)
block|{
name|offset
operator|=
name|blockType
operator|.
name|put
argument_list|(
name|dest
argument_list|,
name|offset
argument_list|)
expr_stmt|;
name|offset
operator|=
name|Bytes
operator|.
name|putInt
argument_list|(
name|dest
argument_list|,
name|offset
argument_list|,
name|onDiskSize
operator|-
name|HConstants
operator|.
name|HFILEBLOCK_HEADER_SIZE
argument_list|)
expr_stmt|;
name|offset
operator|=
name|Bytes
operator|.
name|putInt
argument_list|(
name|dest
argument_list|,
name|offset
argument_list|,
name|uncompressedSize
operator|-
name|HConstants
operator|.
name|HFILEBLOCK_HEADER_SIZE
argument_list|)
expr_stmt|;
name|offset
operator|=
name|Bytes
operator|.
name|putLong
argument_list|(
name|dest
argument_list|,
name|offset
argument_list|,
name|prevOffset
argument_list|)
expr_stmt|;
name|offset
operator|=
name|Bytes
operator|.
name|putByte
argument_list|(
name|dest
argument_list|,
name|offset
argument_list|,
name|fileContext
operator|.
name|getChecksumType
argument_list|()
operator|.
name|getCode
argument_list|()
argument_list|)
expr_stmt|;
name|offset
operator|=
name|Bytes
operator|.
name|putInt
argument_list|(
name|dest
argument_list|,
name|offset
argument_list|,
name|fileContext
operator|.
name|getBytesPerChecksum
argument_list|()
argument_list|)
expr_stmt|;
name|Bytes
operator|.
name|putInt
argument_list|(
name|dest
argument_list|,
name|offset
argument_list|,
name|onDiskDataSize
argument_list|)
expr_stmt|;
block|}
specifier|private
name|void
name|putHeader
parameter_list|(
name|ByteArrayOutputStream
name|dest
parameter_list|,
name|int
name|onDiskSize
parameter_list|,
name|int
name|uncompressedSize
parameter_list|,
name|int
name|onDiskDataSize
parameter_list|)
block|{
name|putHeader
argument_list|(
name|dest
operator|.
name|getBuffer
argument_list|()
argument_list|,
literal|0
argument_list|,
name|onDiskSize
argument_list|,
name|uncompressedSize
argument_list|,
name|onDiskDataSize
argument_list|)
expr_stmt|;
block|}
comment|/**      * Similar to {@link #writeHeaderAndData(FSDataOutputStream)}, but records      * the offset of this block so that it can be referenced in the next block      * of the same type.      *      * @param out      * @throws IOException      */
name|void
name|writeHeaderAndData
parameter_list|(
name|FSDataOutputStream
name|out
parameter_list|)
throws|throws
name|IOException
block|{
name|long
name|offset
init|=
name|out
operator|.
name|getPos
argument_list|()
decl_stmt|;
if|if
condition|(
name|startOffset
operator|!=
name|UNSET
operator|&&
name|offset
operator|!=
name|startOffset
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"A "
operator|+
name|blockType
operator|+
literal|" block written to a "
operator|+
literal|"stream twice, first at offset "
operator|+
name|startOffset
operator|+
literal|", then at "
operator|+
name|offset
argument_list|)
throw|;
block|}
name|startOffset
operator|=
name|offset
expr_stmt|;
name|finishBlockAndWriteHeaderAndData
argument_list|(
operator|(
name|DataOutputStream
operator|)
name|out
argument_list|)
expr_stmt|;
block|}
comment|/**      * Writes the header and the compressed data of this block (or uncompressed      * data when not using compression) into the given stream. Can be called in      * the "writing" state or in the "block ready" state. If called in the      * "writing" state, transitions the writer to the "block ready" state.      *      * @param out the output stream to write the      * @throws IOException      */
specifier|protected
name|void
name|finishBlockAndWriteHeaderAndData
parameter_list|(
name|DataOutputStream
name|out
parameter_list|)
throws|throws
name|IOException
block|{
name|ensureBlockReady
argument_list|()
expr_stmt|;
name|long
name|startTime
init|=
name|System
operator|.
name|currentTimeMillis
argument_list|()
decl_stmt|;
name|out
operator|.
name|write
argument_list|(
name|onDiskBlockBytesWithHeader
operator|.
name|getBuffer
argument_list|()
argument_list|,
literal|0
argument_list|,
name|onDiskBlockBytesWithHeader
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
name|out
operator|.
name|write
argument_list|(
name|onDiskChecksum
argument_list|)
expr_stmt|;
name|HFile
operator|.
name|updateWriteLatency
argument_list|(
name|System
operator|.
name|currentTimeMillis
argument_list|()
operator|-
name|startTime
argument_list|)
expr_stmt|;
block|}
comment|/**      * Returns the header or the compressed data (or uncompressed data when not      * using compression) as a byte array. Can be called in the "writing" state      * or in the "block ready" state. If called in the "writing" state,      * transitions the writer to the "block ready" state. This returns      * the header + data + checksums stored on disk.      *      * @return header and data as they would be stored on disk in a byte array      * @throws IOException      */
name|byte
index|[]
name|getHeaderAndDataForTest
parameter_list|()
throws|throws
name|IOException
block|{
name|ensureBlockReady
argument_list|()
expr_stmt|;
comment|// This is not very optimal, because we are doing an extra copy.
comment|// But this method is used only by unit tests.
name|byte
index|[]
name|output
init|=
operator|new
name|byte
index|[
name|onDiskBlockBytesWithHeader
operator|.
name|size
argument_list|()
operator|+
name|onDiskChecksum
operator|.
name|length
index|]
decl_stmt|;
name|System
operator|.
name|arraycopy
argument_list|(
name|onDiskBlockBytesWithHeader
operator|.
name|getBuffer
argument_list|()
argument_list|,
literal|0
argument_list|,
name|output
argument_list|,
literal|0
argument_list|,
name|onDiskBlockBytesWithHeader
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
name|System
operator|.
name|arraycopy
argument_list|(
name|onDiskChecksum
argument_list|,
literal|0
argument_list|,
name|output
argument_list|,
name|onDiskBlockBytesWithHeader
operator|.
name|size
argument_list|()
argument_list|,
name|onDiskChecksum
operator|.
name|length
argument_list|)
expr_stmt|;
return|return
name|output
return|;
block|}
comment|/**      * Releases resources used by this writer.      */
name|void
name|release
parameter_list|()
block|{
if|if
condition|(
name|dataBlockEncodingCtx
operator|!=
literal|null
condition|)
block|{
name|dataBlockEncodingCtx
operator|.
name|close
argument_list|()
expr_stmt|;
name|dataBlockEncodingCtx
operator|=
literal|null
expr_stmt|;
block|}
if|if
condition|(
name|defaultBlockEncodingCtx
operator|!=
literal|null
condition|)
block|{
name|defaultBlockEncodingCtx
operator|.
name|close
argument_list|()
expr_stmt|;
name|defaultBlockEncodingCtx
operator|=
literal|null
expr_stmt|;
block|}
block|}
comment|/**      * Returns the on-disk size of the data portion of the block. This is the      * compressed size if compression is enabled. Can only be called in the      * "block ready" state. Header is not compressed, and its size is not      * included in the return value.      *      * @return the on-disk size of the block, not including the header.      */
name|int
name|getOnDiskSizeWithoutHeader
parameter_list|()
block|{
name|expectState
argument_list|(
name|State
operator|.
name|BLOCK_READY
argument_list|)
expr_stmt|;
return|return
name|onDiskBlockBytesWithHeader
operator|.
name|size
argument_list|()
operator|+
name|onDiskChecksum
operator|.
name|length
operator|-
name|HConstants
operator|.
name|HFILEBLOCK_HEADER_SIZE
return|;
block|}
comment|/**      * Returns the on-disk size of the block. Can only be called in the      * "block ready" state.      *      * @return the on-disk size of the block ready to be written, including the      *         header size, the data and the checksum data.      */
name|int
name|getOnDiskSizeWithHeader
parameter_list|()
block|{
name|expectState
argument_list|(
name|State
operator|.
name|BLOCK_READY
argument_list|)
expr_stmt|;
return|return
name|onDiskBlockBytesWithHeader
operator|.
name|size
argument_list|()
operator|+
name|onDiskChecksum
operator|.
name|length
return|;
block|}
comment|/**      * The uncompressed size of the block data. Does not include header size.      */
name|int
name|getUncompressedSizeWithoutHeader
parameter_list|()
block|{
name|expectState
argument_list|(
name|State
operator|.
name|BLOCK_READY
argument_list|)
expr_stmt|;
return|return
name|baosInMemory
operator|.
name|size
argument_list|()
operator|-
name|HConstants
operator|.
name|HFILEBLOCK_HEADER_SIZE
return|;
block|}
comment|/**      * The uncompressed size of the block data, including header size.      */
name|int
name|getUncompressedSizeWithHeader
parameter_list|()
block|{
name|expectState
argument_list|(
name|State
operator|.
name|BLOCK_READY
argument_list|)
expr_stmt|;
return|return
name|baosInMemory
operator|.
name|size
argument_list|()
return|;
block|}
comment|/** @return true if a block is being written  */
name|boolean
name|isWriting
parameter_list|()
block|{
return|return
name|state
operator|==
name|State
operator|.
name|WRITING
return|;
block|}
comment|/**      * Returns the number of bytes written into the current block so far, or      * zero if not writing the block at the moment. Note that this will return      * zero in the "block ready" state as well.      *      * @return the number of bytes written      */
specifier|public
name|int
name|encodedBlockSizeWritten
parameter_list|()
block|{
if|if
condition|(
name|state
operator|!=
name|State
operator|.
name|WRITING
condition|)
return|return
literal|0
return|;
return|return
name|this
operator|.
name|encodedDataSizeWritten
return|;
block|}
comment|/**      * Returns the number of bytes written into the current block so far, or      * zero if not writing the block at the moment. Note that this will return      * zero in the "block ready" state as well.      *      * @return the number of bytes written      */
name|int
name|blockSizeWritten
parameter_list|()
block|{
if|if
condition|(
name|state
operator|!=
name|State
operator|.
name|WRITING
condition|)
return|return
literal|0
return|;
return|return
name|this
operator|.
name|unencodedDataSizeWritten
return|;
block|}
comment|/**      * Clones the header followed by the uncompressed data, even if using      * compression. This is needed for storing uncompressed blocks in the block      * cache. Can be called in the "writing" state or the "block ready" state.      * Returns only the header and data, does not include checksum data.      *      * @return Returns a copy of uncompressed block bytes for caching on write      */
annotation|@
name|VisibleForTesting
name|ByteBuffer
name|cloneUncompressedBufferWithHeader
parameter_list|()
block|{
name|expectState
argument_list|(
name|State
operator|.
name|BLOCK_READY
argument_list|)
expr_stmt|;
name|byte
index|[]
name|uncompressedBlockBytesWithHeader
init|=
name|baosInMemory
operator|.
name|toByteArray
argument_list|()
decl_stmt|;
name|int
name|numBytes
init|=
operator|(
name|int
operator|)
name|ChecksumUtil
operator|.
name|numBytes
argument_list|(
name|onDiskBlockBytesWithHeader
operator|.
name|size
argument_list|()
argument_list|,
name|fileContext
operator|.
name|getBytesPerChecksum
argument_list|()
argument_list|)
decl_stmt|;
name|putHeader
argument_list|(
name|uncompressedBlockBytesWithHeader
argument_list|,
literal|0
argument_list|,
name|onDiskBlockBytesWithHeader
operator|.
name|size
argument_list|()
operator|+
name|numBytes
argument_list|,
name|baosInMemory
operator|.
name|size
argument_list|()
argument_list|,
name|onDiskBlockBytesWithHeader
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
return|return
name|ByteBuffer
operator|.
name|wrap
argument_list|(
name|uncompressedBlockBytesWithHeader
argument_list|)
return|;
block|}
comment|/**      * Clones the header followed by the on-disk (compressed/encoded/encrypted) data. This is needed      * for storing packed blocks in the block cache. Returns only the header and data, Does not      * include checksum data.      * @return Returns a copy of block bytes for caching on write      */
specifier|private
name|ByteBuffer
name|cloneOnDiskBufferWithHeader
parameter_list|()
block|{
name|expectState
argument_list|(
name|State
operator|.
name|BLOCK_READY
argument_list|)
expr_stmt|;
return|return
name|ByteBuffer
operator|.
name|wrap
argument_list|(
name|onDiskBlockBytesWithHeader
operator|.
name|toByteArray
argument_list|()
argument_list|)
return|;
block|}
specifier|private
name|void
name|expectState
parameter_list|(
name|State
name|expectedState
parameter_list|)
block|{
if|if
condition|(
name|state
operator|!=
name|expectedState
condition|)
block|{
throw|throw
operator|new
name|IllegalStateException
argument_list|(
literal|"Expected state: "
operator|+
name|expectedState
operator|+
literal|", actual state: "
operator|+
name|state
argument_list|)
throw|;
block|}
block|}
comment|/**      * Takes the given {@link BlockWritable} instance, creates a new block of      * its appropriate type, writes the writable into this block, and flushes      * the block into the output stream. The writer is instructed not to buffer      * uncompressed bytes for cache-on-write.      *      * @param bw the block-writable object to write as a block      * @param out the file system output stream      * @throws IOException      */
name|void
name|writeBlock
parameter_list|(
name|BlockWritable
name|bw
parameter_list|,
name|FSDataOutputStream
name|out
parameter_list|)
throws|throws
name|IOException
block|{
name|bw
operator|.
name|writeToBlock
argument_list|(
name|startWriting
argument_list|(
name|bw
operator|.
name|getBlockType
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
name|writeHeaderAndData
argument_list|(
name|out
argument_list|)
expr_stmt|;
block|}
comment|/**      * Creates a new HFileBlock. Checksums have already been validated, so      * the byte buffer passed into the constructor of this newly created      * block does not have checksum data even though the header minor      * version is MINOR_VERSION_WITH_CHECKSUM. This is indicated by setting a      * 0 value in bytesPerChecksum. This method copies the on-disk or      * uncompressed data to build the HFileBlock which is used only      * while writing blocks and caching.      *      *<p>TODO: Should there be an option where a cache can ask that hbase preserve block      * checksums for checking after a block comes out of the cache? Otehrwise, cache is responsible      * for blocks being wholesome (ECC memory or if file-backed, it does checksumming).      */
name|HFileBlock
name|getBlockForCaching
parameter_list|(
name|CacheConfig
name|cacheConf
parameter_list|)
block|{
name|HFileContext
name|newContext
init|=
operator|new
name|HFileContextBuilder
argument_list|()
operator|.
name|withBlockSize
argument_list|(
name|fileContext
operator|.
name|getBlocksize
argument_list|()
argument_list|)
operator|.
name|withBytesPerCheckSum
argument_list|(
literal|0
argument_list|)
operator|.
name|withChecksumType
argument_list|(
name|ChecksumType
operator|.
name|NULL
argument_list|)
comment|// no checksums in cached data
operator|.
name|withCompression
argument_list|(
name|fileContext
operator|.
name|getCompression
argument_list|()
argument_list|)
operator|.
name|withDataBlockEncoding
argument_list|(
name|fileContext
operator|.
name|getDataBlockEncoding
argument_list|()
argument_list|)
operator|.
name|withHBaseCheckSum
argument_list|(
name|fileContext
operator|.
name|isUseHBaseChecksum
argument_list|()
argument_list|)
operator|.
name|withCompressTags
argument_list|(
name|fileContext
operator|.
name|isCompressTags
argument_list|()
argument_list|)
operator|.
name|withIncludesMvcc
argument_list|(
name|fileContext
operator|.
name|isIncludesMvcc
argument_list|()
argument_list|)
operator|.
name|withIncludesTags
argument_list|(
name|fileContext
operator|.
name|isIncludesTags
argument_list|()
argument_list|)
operator|.
name|build
argument_list|()
decl_stmt|;
return|return
operator|new
name|HFileBlock
argument_list|(
name|blockType
argument_list|,
name|getOnDiskSizeWithoutHeader
argument_list|()
argument_list|,
name|getUncompressedSizeWithoutHeader
argument_list|()
argument_list|,
name|prevOffset
argument_list|,
name|cacheConf
operator|.
name|shouldCacheCompressed
argument_list|(
name|blockType
operator|.
name|getCategory
argument_list|()
argument_list|)
condition|?
name|cloneOnDiskBufferWithHeader
argument_list|()
else|:
name|cloneUncompressedBufferWithHeader
argument_list|()
argument_list|,
name|FILL_HEADER
argument_list|,
name|startOffset
argument_list|,
name|UNSET
argument_list|,
name|onDiskBlockBytesWithHeader
operator|.
name|size
argument_list|()
operator|+
name|onDiskChecksum
operator|.
name|length
argument_list|,
name|newContext
argument_list|,
name|cacheConf
operator|.
name|getByteBuffAllocator
argument_list|()
argument_list|)
return|;
block|}
block|}
comment|/** Something that can be written into a block. */
interface|interface
name|BlockWritable
block|{
comment|/** The type of block this data should use. */
name|BlockType
name|getBlockType
parameter_list|()
function_decl|;
comment|/**      * Writes the block to the provided stream. Must not write any magic      * records.      *      * @param out a stream to write uncompressed data into      */
name|void
name|writeToBlock
parameter_list|(
name|DataOutput
name|out
parameter_list|)
throws|throws
name|IOException
function_decl|;
block|}
comment|/**    * Iterator for reading {@link HFileBlock}s in load-on-open-section, such as root data index    * block, meta index block, file info block etc.    */
interface|interface
name|BlockIterator
block|{
comment|/**      * Get the next block, or null if there are no more blocks to iterate.      */
name|HFileBlock
name|nextBlock
parameter_list|()
throws|throws
name|IOException
function_decl|;
comment|/**      * Similar to {@link #nextBlock()} but checks block type, throws an exception if incorrect, and      * returns the HFile block      */
name|HFileBlock
name|nextBlockWithBlockType
parameter_list|(
name|BlockType
name|blockType
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**      * Now we use the {@link ByteBuffAllocator} to manage the nio ByteBuffers for HFileBlocks, so we      * must deallocate all of the ByteBuffers in the end life. the BlockIterator's life cycle is      * starting from opening an HFileReader and stopped when the HFileReader#close, so we will keep      * track all the read blocks until we call {@link BlockIterator#freeBlocks()} when closing the      * HFileReader. Sum bytes of those blocks in load-on-open section should be quite small, so      * tracking them should be OK.      */
name|void
name|freeBlocks
parameter_list|()
function_decl|;
block|}
comment|/** An HFile block reader with iteration ability. */
interface|interface
name|FSReader
block|{
comment|/**      * Reads the block at the given offset in the file with the given on-disk size and uncompressed      * size.      * @param offset of the file to read      * @param onDiskSize the on-disk size of the entire block, including all applicable headers, or      *          -1 if unknown      * @param pread true to use pread, otherwise use the stream read.      * @param updateMetrics update the metrics or not.      * @param intoHeap allocate the block's ByteBuff by {@link ByteBuffAllocator} or JVM heap. For      *          LRUBlockCache, we must ensure that the block to cache is an heap one, because the      *          memory occupation is based on heap now, also for {@link CombinedBlockCache}, we use      *          the heap LRUBlockCache as L1 cache to cache small blocks such as IndexBlock or      *          MetaBlock for faster access. So introduce an flag here to decide whether allocate      *          from JVM heap or not so that we can avoid an extra off-heap to heap memory copy when      *          using LRUBlockCache. For most cases, we known what's the expected block type we'll      *          read, while for some special case (Example: HFileReaderImpl#readNextDataBlock()), we      *          cannot pre-decide what's the expected block type, then we can only allocate block's      *          ByteBuff from {@link ByteBuffAllocator} firstly, and then when caching it in      *          {@link LruBlockCache} we'll check whether the ByteBuff is from heap or not, if not      *          then we'll clone it to an heap one and cache it.      * @return the newly read block      */
name|HFileBlock
name|readBlockData
parameter_list|(
name|long
name|offset
parameter_list|,
name|long
name|onDiskSize
parameter_list|,
name|boolean
name|pread
parameter_list|,
name|boolean
name|updateMetrics
parameter_list|,
name|boolean
name|intoHeap
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**      * Creates a block iterator over the given portion of the {@link HFile}.      * The iterator returns blocks starting with offset such that offset&lt;=      * startOffset&lt; endOffset. Returned blocks are always unpacked.      * Used when no hfile index available; e.g. reading in the hfile index      * blocks themselves on file open.      *      * @param startOffset the offset of the block to start iteration with      * @param endOffset the offset to end iteration at (exclusive)      * @return an iterator of blocks between the two given offsets      */
name|BlockIterator
name|blockRange
parameter_list|(
name|long
name|startOffset
parameter_list|,
name|long
name|endOffset
parameter_list|)
function_decl|;
comment|/** Closes the backing streams */
name|void
name|closeStreams
parameter_list|()
throws|throws
name|IOException
function_decl|;
comment|/** Get a decoder for {@link BlockType#ENCODED_DATA} blocks from this file. */
name|HFileBlockDecodingContext
name|getBlockDecodingContext
parameter_list|()
function_decl|;
comment|/** Get the default decoder for blocks from this file. */
name|HFileBlockDecodingContext
name|getDefaultBlockDecodingContext
parameter_list|()
function_decl|;
name|void
name|setIncludesMemStoreTS
parameter_list|(
name|boolean
name|includesMemstoreTS
parameter_list|)
function_decl|;
name|void
name|setDataBlockEncoder
parameter_list|(
name|HFileDataBlockEncoder
name|encoder
parameter_list|)
function_decl|;
comment|/**      * To close the stream's socket. Note: This can be concurrently called from multiple threads and      * implementation should take care of thread safety.      */
name|void
name|unbufferStream
parameter_list|()
function_decl|;
block|}
comment|/**    * Data-structure to use caching the header of the NEXT block. Only works if next read    * that comes in here is next in sequence in this block.    *    * When we read, we read current block and the next blocks' header. We do this so we have    * the length of the next block to read if the hfile index is not available (rare, at    * hfile open only).    */
specifier|private
specifier|static
class|class
name|PrefetchedHeader
block|{
name|long
name|offset
init|=
operator|-
literal|1
decl_stmt|;
name|byte
index|[]
name|header
init|=
operator|new
name|byte
index|[
name|HConstants
operator|.
name|HFILEBLOCK_HEADER_SIZE
index|]
decl_stmt|;
specifier|final
name|ByteBuff
name|buf
init|=
operator|new
name|SingleByteBuff
argument_list|(
name|ByteBuffer
operator|.
name|wrap
argument_list|(
name|header
argument_list|,
literal|0
argument_list|,
name|header
operator|.
name|length
argument_list|)
argument_list|)
decl_stmt|;
annotation|@
name|Override
specifier|public
name|String
name|toString
parameter_list|()
block|{
return|return
literal|"offset="
operator|+
name|this
operator|.
name|offset
operator|+
literal|", header="
operator|+
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|header
argument_list|)
return|;
block|}
block|}
comment|/**    * Reads version 2 HFile blocks from the filesystem.    */
specifier|static
class|class
name|FSReaderImpl
implements|implements
name|FSReader
block|{
comment|/** The file system stream of the underlying {@link HFile} that      * does or doesn't do checksum validations in the filesystem */
specifier|private
name|FSDataInputStreamWrapper
name|streamWrapper
decl_stmt|;
specifier|private
name|HFileBlockDecodingContext
name|encodedBlockDecodingCtx
decl_stmt|;
comment|/** Default context used when BlockType != {@link BlockType#ENCODED_DATA}. */
specifier|private
specifier|final
name|HFileBlockDefaultDecodingContext
name|defaultDecodingCtx
decl_stmt|;
comment|/**      * Cache of the NEXT header after this. Check it is indeed next blocks header      * before using it. TODO: Review. This overread into next block to fetch      * next blocks header seems unnecessary given we usually get the block size      * from the hfile index. Review!      */
specifier|private
name|AtomicReference
argument_list|<
name|PrefetchedHeader
argument_list|>
name|prefetchedHeader
init|=
operator|new
name|AtomicReference
argument_list|<>
argument_list|(
operator|new
name|PrefetchedHeader
argument_list|()
argument_list|)
decl_stmt|;
comment|/** The size of the file we are reading from, or -1 if unknown. */
specifier|private
name|long
name|fileSize
decl_stmt|;
comment|/** The size of the header */
annotation|@
name|VisibleForTesting
specifier|protected
specifier|final
name|int
name|hdrSize
decl_stmt|;
comment|/** The filesystem used to access data */
specifier|private
name|HFileSystem
name|hfs
decl_stmt|;
specifier|private
name|HFileContext
name|fileContext
decl_stmt|;
comment|// Cache the fileName
specifier|private
name|String
name|pathName
decl_stmt|;
specifier|private
specifier|final
name|ByteBuffAllocator
name|allocator
decl_stmt|;
specifier|private
specifier|final
name|Lock
name|streamLock
init|=
operator|new
name|ReentrantLock
argument_list|()
decl_stmt|;
name|FSReaderImpl
parameter_list|(
name|FSDataInputStreamWrapper
name|stream
parameter_list|,
name|long
name|fileSize
parameter_list|,
name|HFileSystem
name|hfs
parameter_list|,
name|Path
name|path
parameter_list|,
name|HFileContext
name|fileContext
parameter_list|,
name|ByteBuffAllocator
name|allocator
parameter_list|)
throws|throws
name|IOException
block|{
name|this
operator|.
name|fileSize
operator|=
name|fileSize
expr_stmt|;
name|this
operator|.
name|hfs
operator|=
name|hfs
expr_stmt|;
if|if
condition|(
name|path
operator|!=
literal|null
condition|)
block|{
name|this
operator|.
name|pathName
operator|=
name|path
operator|.
name|toString
argument_list|()
expr_stmt|;
block|}
name|this
operator|.
name|fileContext
operator|=
name|fileContext
expr_stmt|;
name|this
operator|.
name|hdrSize
operator|=
name|headerSize
argument_list|(
name|fileContext
operator|.
name|isUseHBaseChecksum
argument_list|()
argument_list|)
expr_stmt|;
name|this
operator|.
name|allocator
operator|=
name|allocator
expr_stmt|;
name|this
operator|.
name|streamWrapper
operator|=
name|stream
expr_stmt|;
comment|// Older versions of HBase didn't support checksum.
name|this
operator|.
name|streamWrapper
operator|.
name|prepareForBlockReader
argument_list|(
operator|!
name|fileContext
operator|.
name|isUseHBaseChecksum
argument_list|()
argument_list|)
expr_stmt|;
name|defaultDecodingCtx
operator|=
operator|new
name|HFileBlockDefaultDecodingContext
argument_list|(
name|fileContext
argument_list|)
expr_stmt|;
name|encodedBlockDecodingCtx
operator|=
name|defaultDecodingCtx
expr_stmt|;
block|}
comment|/**      * A constructor that reads files with the latest minor version. This is used by unit tests      * only.      */
name|FSReaderImpl
parameter_list|(
name|FSDataInputStream
name|istream
parameter_list|,
name|long
name|fileSize
parameter_list|,
name|HFileContext
name|fileContext
parameter_list|,
name|ByteBuffAllocator
name|allocator
parameter_list|)
throws|throws
name|IOException
block|{
name|this
argument_list|(
operator|new
name|FSDataInputStreamWrapper
argument_list|(
name|istream
argument_list|)
argument_list|,
name|fileSize
argument_list|,
literal|null
argument_list|,
literal|null
argument_list|,
name|fileContext
argument_list|,
name|allocator
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|BlockIterator
name|blockRange
parameter_list|(
specifier|final
name|long
name|startOffset
parameter_list|,
specifier|final
name|long
name|endOffset
parameter_list|)
block|{
specifier|final
name|FSReader
name|owner
init|=
name|this
decl_stmt|;
comment|// handle for inner class
return|return
operator|new
name|BlockIterator
argument_list|()
block|{
specifier|private
specifier|volatile
name|boolean
name|freed
init|=
literal|false
decl_stmt|;
comment|// Tracking all read blocks until we call freeBlocks.
specifier|private
name|List
argument_list|<
name|HFileBlock
argument_list|>
name|blockTracker
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
specifier|private
name|long
name|offset
init|=
name|startOffset
decl_stmt|;
comment|// Cache length of next block. Current block has the length of next block in it.
specifier|private
name|long
name|length
init|=
operator|-
literal|1
decl_stmt|;
annotation|@
name|Override
specifier|public
name|HFileBlock
name|nextBlock
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|offset
operator|>=
name|endOffset
condition|)
block|{
return|return
literal|null
return|;
block|}
name|HFileBlock
name|b
init|=
name|readBlockData
argument_list|(
name|offset
argument_list|,
name|length
argument_list|,
literal|false
argument_list|,
literal|false
argument_list|,
literal|true
argument_list|)
decl_stmt|;
name|offset
operator|+=
name|b
operator|.
name|getOnDiskSizeWithHeader
argument_list|()
expr_stmt|;
name|length
operator|=
name|b
operator|.
name|getNextBlockOnDiskSize
argument_list|()
expr_stmt|;
name|HFileBlock
name|uncompressed
init|=
name|b
operator|.
name|unpack
argument_list|(
name|fileContext
argument_list|,
name|owner
argument_list|)
decl_stmt|;
if|if
condition|(
name|uncompressed
operator|!=
name|b
condition|)
block|{
name|b
operator|.
name|release
argument_list|()
expr_stmt|;
comment|// Need to release the compressed Block now.
block|}
name|blockTracker
operator|.
name|add
argument_list|(
name|uncompressed
argument_list|)
expr_stmt|;
return|return
name|uncompressed
return|;
block|}
annotation|@
name|Override
specifier|public
name|HFileBlock
name|nextBlockWithBlockType
parameter_list|(
name|BlockType
name|blockType
parameter_list|)
throws|throws
name|IOException
block|{
name|HFileBlock
name|blk
init|=
name|nextBlock
argument_list|()
decl_stmt|;
if|if
condition|(
name|blk
operator|.
name|getBlockType
argument_list|()
operator|!=
name|blockType
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Expected block of type "
operator|+
name|blockType
operator|+
literal|" but found "
operator|+
name|blk
operator|.
name|getBlockType
argument_list|()
argument_list|)
throw|;
block|}
return|return
name|blk
return|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|freeBlocks
parameter_list|()
block|{
if|if
condition|(
name|freed
condition|)
block|{
return|return;
block|}
name|blockTracker
operator|.
name|forEach
argument_list|(
name|HFileBlock
operator|::
name|release
argument_list|)
expr_stmt|;
name|blockTracker
operator|=
literal|null
expr_stmt|;
name|freed
operator|=
literal|true
expr_stmt|;
block|}
block|}
return|;
block|}
comment|/**      * Does a positional read or a seek and read into the given byte buffer. We need take care that      * we will call the {@link ByteBuff#release()} for every exit to deallocate the ByteBuffers,      * otherwise the memory leak may happen.      * @param dest destination buffer      * @param size size of read      * @param peekIntoNextBlock whether to read the next block's on-disk size      * @param fileOffset position in the stream to read at      * @param pread whether we should do a positional read      * @param istream The input source of data      * @return true to indicate the destination buffer include the next block header, otherwise only      *         include the current block data without the next block header.      * @throws IOException if any IO error happen.      */
specifier|protected
name|boolean
name|readAtOffset
parameter_list|(
name|FSDataInputStream
name|istream
parameter_list|,
name|ByteBuff
name|dest
parameter_list|,
name|int
name|size
parameter_list|,
name|boolean
name|peekIntoNextBlock
parameter_list|,
name|long
name|fileOffset
parameter_list|,
name|boolean
name|pread
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
operator|!
name|pread
condition|)
block|{
comment|// Seek + read. Better for scanning.
name|HFileUtil
operator|.
name|seekOnMultipleSources
argument_list|(
name|istream
argument_list|,
name|fileOffset
argument_list|)
expr_stmt|;
name|long
name|realOffset
init|=
name|istream
operator|.
name|getPos
argument_list|()
decl_stmt|;
if|if
condition|(
name|realOffset
operator|!=
name|fileOffset
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Tried to seek to "
operator|+
name|fileOffset
operator|+
literal|" to read "
operator|+
name|size
operator|+
literal|" bytes, but pos="
operator|+
name|realOffset
operator|+
literal|" after seek"
argument_list|)
throw|;
block|}
if|if
condition|(
operator|!
name|peekIntoNextBlock
condition|)
block|{
name|BlockIOUtils
operator|.
name|readFully
argument_list|(
name|dest
argument_list|,
name|istream
argument_list|,
name|size
argument_list|)
expr_stmt|;
return|return
literal|false
return|;
block|}
comment|// Try to read the next block header
if|if
condition|(
operator|!
name|BlockIOUtils
operator|.
name|readWithExtra
argument_list|(
name|dest
argument_list|,
name|istream
argument_list|,
name|size
argument_list|,
name|hdrSize
argument_list|)
condition|)
block|{
comment|// did not read the next block header.
return|return
literal|false
return|;
block|}
block|}
else|else
block|{
comment|// Positional read. Better for random reads; or when the streamLock is already locked.
name|int
name|extraSize
init|=
name|peekIntoNextBlock
condition|?
name|hdrSize
else|:
literal|0
decl_stmt|;
if|if
condition|(
operator|!
name|BlockIOUtils
operator|.
name|preadWithExtra
argument_list|(
name|dest
argument_list|,
name|istream
argument_list|,
name|fileOffset
argument_list|,
name|size
argument_list|,
name|extraSize
argument_list|)
condition|)
block|{
comment|// did not read the next block header.
return|return
literal|false
return|;
block|}
block|}
assert|assert
name|peekIntoNextBlock
assert|;
return|return
literal|true
return|;
block|}
comment|/**      * Reads a version 2 block (version 1 blocks not supported and not expected). Tries to do as      * little memory allocation as possible, using the provided on-disk size.      * @param offset the offset in the stream to read at      * @param onDiskSizeWithHeaderL the on-disk size of the block, including the header, or -1 if      *          unknown; i.e. when iterating over blocks reading in the file metadata info.      * @param pread whether to use a positional read      * @param updateMetrics whether to update the metrics      * @param intoHeap allocate ByteBuff of block from heap or off-heap.      * @see FSReader#readBlockData(long, long, boolean, boolean, boolean) for more details about the      *      useHeap.      */
annotation|@
name|Override
specifier|public
name|HFileBlock
name|readBlockData
parameter_list|(
name|long
name|offset
parameter_list|,
name|long
name|onDiskSizeWithHeaderL
parameter_list|,
name|boolean
name|pread
parameter_list|,
name|boolean
name|updateMetrics
parameter_list|,
name|boolean
name|intoHeap
parameter_list|)
throws|throws
name|IOException
block|{
comment|// Get a copy of the current state of whether to validate
comment|// hbase checksums or not for this read call. This is not
comment|// thread-safe but the one constaint is that if we decide
comment|// to skip hbase checksum verification then we are
comment|// guaranteed to use hdfs checksum verification.
name|boolean
name|doVerificationThruHBaseChecksum
init|=
name|streamWrapper
operator|.
name|shouldUseHBaseChecksum
argument_list|()
decl_stmt|;
name|FSDataInputStream
name|is
init|=
name|streamWrapper
operator|.
name|getStream
argument_list|(
name|doVerificationThruHBaseChecksum
argument_list|)
decl_stmt|;
name|HFileBlock
name|blk
init|=
name|readBlockDataInternal
argument_list|(
name|is
argument_list|,
name|offset
argument_list|,
name|onDiskSizeWithHeaderL
argument_list|,
name|pread
argument_list|,
name|doVerificationThruHBaseChecksum
argument_list|,
name|updateMetrics
argument_list|,
name|intoHeap
argument_list|)
decl_stmt|;
if|if
condition|(
name|blk
operator|==
literal|null
condition|)
block|{
name|HFile
operator|.
name|LOG
operator|.
name|warn
argument_list|(
literal|"HBase checksum verification failed for file "
operator|+
name|pathName
operator|+
literal|" at offset "
operator|+
name|offset
operator|+
literal|" filesize "
operator|+
name|fileSize
operator|+
literal|". Retrying read with HDFS checksums turned on..."
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|doVerificationThruHBaseChecksum
condition|)
block|{
name|String
name|msg
init|=
literal|"HBase checksum verification failed for file "
operator|+
name|pathName
operator|+
literal|" at offset "
operator|+
name|offset
operator|+
literal|" filesize "
operator|+
name|fileSize
operator|+
literal|" but this cannot happen because doVerify is "
operator|+
name|doVerificationThruHBaseChecksum
decl_stmt|;
name|HFile
operator|.
name|LOG
operator|.
name|warn
argument_list|(
name|msg
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|IOException
argument_list|(
name|msg
argument_list|)
throw|;
comment|// cannot happen case here
block|}
name|HFile
operator|.
name|CHECKSUM_FAILURES
operator|.
name|increment
argument_list|()
expr_stmt|;
comment|// update metrics
comment|// If we have a checksum failure, we fall back into a mode where
comment|// the next few reads use HDFS level checksums. We aim to make the
comment|// next CHECKSUM_VERIFICATION_NUM_IO_THRESHOLD reads avoid
comment|// hbase checksum verification, but since this value is set without
comment|// holding any locks, it can so happen that we might actually do
comment|// a few more than precisely this number.
name|is
operator|=
name|this
operator|.
name|streamWrapper
operator|.
name|fallbackToFsChecksum
argument_list|(
name|CHECKSUM_VERIFICATION_NUM_IO_THRESHOLD
argument_list|)
expr_stmt|;
name|doVerificationThruHBaseChecksum
operator|=
literal|false
expr_stmt|;
name|blk
operator|=
name|readBlockDataInternal
argument_list|(
name|is
argument_list|,
name|offset
argument_list|,
name|onDiskSizeWithHeaderL
argument_list|,
name|pread
argument_list|,
name|doVerificationThruHBaseChecksum
argument_list|,
name|updateMetrics
argument_list|,
name|intoHeap
argument_list|)
expr_stmt|;
if|if
condition|(
name|blk
operator|!=
literal|null
condition|)
block|{
name|HFile
operator|.
name|LOG
operator|.
name|warn
argument_list|(
literal|"HDFS checksum verification succeeded for file "
operator|+
name|pathName
operator|+
literal|" at offset "
operator|+
name|offset
operator|+
literal|" filesize "
operator|+
name|fileSize
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|blk
operator|==
literal|null
operator|&&
operator|!
name|doVerificationThruHBaseChecksum
condition|)
block|{
name|String
name|msg
init|=
literal|"readBlockData failed, possibly due to "
operator|+
literal|"checksum verification failed for file "
operator|+
name|pathName
operator|+
literal|" at offset "
operator|+
name|offset
operator|+
literal|" filesize "
operator|+
name|fileSize
decl_stmt|;
name|HFile
operator|.
name|LOG
operator|.
name|warn
argument_list|(
name|msg
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|IOException
argument_list|(
name|msg
argument_list|)
throw|;
block|}
comment|// If there is a checksum mismatch earlier, then retry with
comment|// HBase checksums switched off and use HDFS checksum verification.
comment|// This triggers HDFS to detect and fix corrupt replicas. The
comment|// next checksumOffCount read requests will use HDFS checksums.
comment|// The decrementing of this.checksumOffCount is not thread-safe,
comment|// but it is harmless because eventually checksumOffCount will be
comment|// a negative number.
name|streamWrapper
operator|.
name|checksumOk
argument_list|()
expr_stmt|;
return|return
name|blk
return|;
block|}
comment|/**      * @return Check<code>onDiskSizeWithHeaderL</code> size is healthy and then return it as an int      * @throws IOException      */
specifier|private
specifier|static
name|int
name|checkAndGetSizeAsInt
parameter_list|(
specifier|final
name|long
name|onDiskSizeWithHeaderL
parameter_list|,
specifier|final
name|int
name|hdrSize
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
operator|(
name|onDiskSizeWithHeaderL
operator|<
name|hdrSize
operator|&&
name|onDiskSizeWithHeaderL
operator|!=
operator|-
literal|1
operator|)
operator|||
name|onDiskSizeWithHeaderL
operator|>=
name|Integer
operator|.
name|MAX_VALUE
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Invalid onDisksize="
operator|+
name|onDiskSizeWithHeaderL
operator|+
literal|": expected to be at least "
operator|+
name|hdrSize
operator|+
literal|" and at most "
operator|+
name|Integer
operator|.
name|MAX_VALUE
operator|+
literal|", or -1"
argument_list|)
throw|;
block|}
return|return
operator|(
name|int
operator|)
name|onDiskSizeWithHeaderL
return|;
block|}
comment|/**      * Verify the passed in onDiskSizeWithHeader aligns with what is in the header else something      * is not right.      * @throws IOException      */
specifier|private
name|void
name|verifyOnDiskSizeMatchesHeader
parameter_list|(
specifier|final
name|int
name|passedIn
parameter_list|,
specifier|final
name|ByteBuff
name|headerBuf
parameter_list|,
specifier|final
name|long
name|offset
parameter_list|,
name|boolean
name|verifyChecksum
parameter_list|)
throws|throws
name|IOException
block|{
comment|// Assert size provided aligns with what is in the header
name|int
name|fromHeader
init|=
name|getOnDiskSizeWithHeader
argument_list|(
name|headerBuf
argument_list|,
name|verifyChecksum
argument_list|)
decl_stmt|;
if|if
condition|(
name|passedIn
operator|!=
name|fromHeader
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Passed in onDiskSizeWithHeader="
operator|+
name|passedIn
operator|+
literal|" != "
operator|+
name|fromHeader
operator|+
literal|", offset="
operator|+
name|offset
operator|+
literal|", fileContext="
operator|+
name|this
operator|.
name|fileContext
argument_list|)
throw|;
block|}
block|}
comment|/**      * Check atomic reference cache for this block's header. Cache only good if next      * read coming through is next in sequence in the block. We read next block's      * header on the tail of reading the previous block to save a seek. Otherwise,      * we have to do a seek to read the header before we can pull in the block OR      * we have to backup the stream because we over-read (the next block's header).      * @see PrefetchedHeader      * @return The cached block header or null if not found.      * @see #cacheNextBlockHeader(long, ByteBuff, int, int)      */
specifier|private
name|ByteBuff
name|getCachedHeader
parameter_list|(
specifier|final
name|long
name|offset
parameter_list|)
block|{
name|PrefetchedHeader
name|ph
init|=
name|this
operator|.
name|prefetchedHeader
operator|.
name|get
argument_list|()
decl_stmt|;
return|return
name|ph
operator|!=
literal|null
operator|&&
name|ph
operator|.
name|offset
operator|==
name|offset
condition|?
name|ph
operator|.
name|buf
else|:
literal|null
return|;
block|}
comment|/**      * Save away the next blocks header in atomic reference.      * @see #getCachedHeader(long)      * @see PrefetchedHeader      */
specifier|private
name|void
name|cacheNextBlockHeader
parameter_list|(
specifier|final
name|long
name|offset
parameter_list|,
name|ByteBuff
name|onDiskBlock
parameter_list|,
name|int
name|onDiskSizeWithHeader
parameter_list|,
name|int
name|headerLength
parameter_list|)
block|{
name|PrefetchedHeader
name|ph
init|=
operator|new
name|PrefetchedHeader
argument_list|()
decl_stmt|;
name|ph
operator|.
name|offset
operator|=
name|offset
expr_stmt|;
name|onDiskBlock
operator|.
name|get
argument_list|(
name|onDiskSizeWithHeader
argument_list|,
name|ph
operator|.
name|header
argument_list|,
literal|0
argument_list|,
name|headerLength
argument_list|)
expr_stmt|;
name|this
operator|.
name|prefetchedHeader
operator|.
name|set
argument_list|(
name|ph
argument_list|)
expr_stmt|;
block|}
specifier|private
name|int
name|getNextBlockOnDiskSize
parameter_list|(
name|boolean
name|readNextHeader
parameter_list|,
name|ByteBuff
name|onDiskBlock
parameter_list|,
name|int
name|onDiskSizeWithHeader
parameter_list|)
block|{
name|int
name|nextBlockOnDiskSize
init|=
operator|-
literal|1
decl_stmt|;
if|if
condition|(
name|readNextHeader
condition|)
block|{
name|nextBlockOnDiskSize
operator|=
name|onDiskBlock
operator|.
name|getIntAfterPosition
argument_list|(
name|onDiskSizeWithHeader
operator|+
name|BlockType
operator|.
name|MAGIC_LENGTH
argument_list|)
operator|+
name|hdrSize
expr_stmt|;
block|}
return|return
name|nextBlockOnDiskSize
return|;
block|}
specifier|private
name|ByteBuff
name|allocate
parameter_list|(
name|int
name|size
parameter_list|,
name|boolean
name|intoHeap
parameter_list|)
block|{
return|return
name|intoHeap
condition|?
name|HEAP
operator|.
name|allocate
argument_list|(
name|size
argument_list|)
else|:
name|allocator
operator|.
name|allocate
argument_list|(
name|size
argument_list|)
return|;
block|}
comment|/**      * Reads a version 2 block.      * @param offset the offset in the stream to read at.      * @param onDiskSizeWithHeaderL the on-disk size of the block, including the header and      *          checksums if present or -1 if unknown (as a long). Can be -1 if we are doing raw      *          iteration of blocks as when loading up file metadata; i.e. the first read of a new      *          file. Usually non-null gotten from the file index.      * @param pread whether to use a positional read      * @param verifyChecksum Whether to use HBase checksums. If HBase checksum is switched off, then      *          use HDFS checksum. Can also flip on/off reading same file if we hit a troublesome      *          patch in an hfile.      * @param updateMetrics whether need to update the metrics.      * @param intoHeap allocate the ByteBuff of block from heap or off-heap.      * @return the HFileBlock or null if there is a HBase checksum mismatch      */
annotation|@
name|VisibleForTesting
specifier|protected
name|HFileBlock
name|readBlockDataInternal
parameter_list|(
name|FSDataInputStream
name|is
parameter_list|,
name|long
name|offset
parameter_list|,
name|long
name|onDiskSizeWithHeaderL
parameter_list|,
name|boolean
name|pread
parameter_list|,
name|boolean
name|verifyChecksum
parameter_list|,
name|boolean
name|updateMetrics
parameter_list|,
name|boolean
name|intoHeap
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|offset
operator|<
literal|0
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Invalid offset="
operator|+
name|offset
operator|+
literal|" trying to read "
operator|+
literal|"block (onDiskSize="
operator|+
name|onDiskSizeWithHeaderL
operator|+
literal|")"
argument_list|)
throw|;
block|}
name|int
name|onDiskSizeWithHeader
init|=
name|checkAndGetSizeAsInt
argument_list|(
name|onDiskSizeWithHeaderL
argument_list|,
name|hdrSize
argument_list|)
decl_stmt|;
comment|// Try and get cached header. Will serve us in rare case where onDiskSizeWithHeaderL is -1
comment|// and will save us having to seek the stream backwards to reread the header we
comment|// read the last time through here.
name|ByteBuff
name|headerBuf
init|=
name|getCachedHeader
argument_list|(
name|offset
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|trace
argument_list|(
literal|"Reading {} at offset={}, pread={}, verifyChecksum={}, cachedHeader={}, "
operator|+
literal|"onDiskSizeWithHeader={}"
argument_list|,
name|this
operator|.
name|fileContext
operator|.
name|getHFileName
argument_list|()
argument_list|,
name|offset
argument_list|,
name|pread
argument_list|,
name|verifyChecksum
argument_list|,
name|headerBuf
argument_list|,
name|onDiskSizeWithHeader
argument_list|)
expr_stmt|;
comment|// This is NOT same as verifyChecksum. This latter is whether to do hbase
comment|// checksums. Can change with circumstances. The below flag is whether the
comment|// file has support for checksums (version 2+).
name|boolean
name|checksumSupport
init|=
name|this
operator|.
name|fileContext
operator|.
name|isUseHBaseChecksum
argument_list|()
decl_stmt|;
name|long
name|startTime
init|=
name|System
operator|.
name|currentTimeMillis
argument_list|()
decl_stmt|;
if|if
condition|(
name|onDiskSizeWithHeader
operator|<=
literal|0
condition|)
block|{
comment|// We were not passed the block size. Need to get it from the header. If header was
comment|// not cached (see getCachedHeader above), need to seek to pull it in. This is costly
comment|// and should happen very rarely. Currently happens on open of a hfile reader where we
comment|// read the trailer blocks to pull in the indices. Otherwise, we are reading block sizes
comment|// out of the hfile index. To check, enable TRACE in this file and you'll get an exception
comment|// in a LOG every time we seek. See HBASE-17072 for more detail.
if|if
condition|(
name|headerBuf
operator|==
literal|null
condition|)
block|{
if|if
condition|(
name|LOG
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|trace
argument_list|(
literal|"Extra see to get block size!"
argument_list|,
operator|new
name|RuntimeException
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|headerBuf
operator|=
name|HEAP
operator|.
name|allocate
argument_list|(
name|hdrSize
argument_list|)
expr_stmt|;
name|readAtOffset
argument_list|(
name|is
argument_list|,
name|headerBuf
argument_list|,
name|hdrSize
argument_list|,
literal|false
argument_list|,
name|offset
argument_list|,
name|pread
argument_list|)
expr_stmt|;
name|headerBuf
operator|.
name|rewind
argument_list|()
expr_stmt|;
block|}
name|onDiskSizeWithHeader
operator|=
name|getOnDiskSizeWithHeader
argument_list|(
name|headerBuf
argument_list|,
name|checksumSupport
argument_list|)
expr_stmt|;
block|}
name|int
name|preReadHeaderSize
init|=
name|headerBuf
operator|==
literal|null
condition|?
literal|0
else|:
name|hdrSize
decl_stmt|;
comment|// Allocate enough space to fit the next block's header too; saves a seek next time through.
comment|// onDiskBlock is whole block + header + checksums then extra hdrSize to read next header;
comment|// onDiskSizeWithHeader is header, body, and any checksums if present. preReadHeaderSize
comment|// says where to start reading. If we have the header cached, then we don't need to read
comment|// it again and we can likely read from last place we left off w/o need to backup and reread
comment|// the header we read last time through here.
name|ByteBuff
name|onDiskBlock
init|=
name|this
operator|.
name|allocate
argument_list|(
name|onDiskSizeWithHeader
operator|+
name|hdrSize
argument_list|,
name|intoHeap
argument_list|)
decl_stmt|;
name|boolean
name|initHFileBlockSuccess
init|=
literal|false
decl_stmt|;
try|try
block|{
if|if
condition|(
name|headerBuf
operator|!=
literal|null
condition|)
block|{
name|onDiskBlock
operator|.
name|put
argument_list|(
literal|0
argument_list|,
name|headerBuf
argument_list|,
literal|0
argument_list|,
name|hdrSize
argument_list|)
operator|.
name|position
argument_list|(
name|hdrSize
argument_list|)
expr_stmt|;
block|}
name|boolean
name|readNextHeader
init|=
name|readAtOffset
argument_list|(
name|is
argument_list|,
name|onDiskBlock
argument_list|,
name|onDiskSizeWithHeader
operator|-
name|preReadHeaderSize
argument_list|,
literal|true
argument_list|,
name|offset
operator|+
name|preReadHeaderSize
argument_list|,
name|pread
argument_list|)
decl_stmt|;
name|onDiskBlock
operator|.
name|rewind
argument_list|()
expr_stmt|;
comment|// in case of moving position when copying a cached header
name|int
name|nextBlockOnDiskSize
init|=
name|getNextBlockOnDiskSize
argument_list|(
name|readNextHeader
argument_list|,
name|onDiskBlock
argument_list|,
name|onDiskSizeWithHeader
argument_list|)
decl_stmt|;
if|if
condition|(
name|headerBuf
operator|==
literal|null
condition|)
block|{
name|headerBuf
operator|=
name|onDiskBlock
operator|.
name|duplicate
argument_list|()
operator|.
name|position
argument_list|(
literal|0
argument_list|)
operator|.
name|limit
argument_list|(
name|hdrSize
argument_list|)
expr_stmt|;
block|}
comment|// Do a few checks before we go instantiate HFileBlock.
assert|assert
name|onDiskSizeWithHeader
operator|>
name|this
operator|.
name|hdrSize
assert|;
name|verifyOnDiskSizeMatchesHeader
argument_list|(
name|onDiskSizeWithHeader
argument_list|,
name|headerBuf
argument_list|,
name|offset
argument_list|,
name|checksumSupport
argument_list|)
expr_stmt|;
name|ByteBuff
name|curBlock
init|=
name|onDiskBlock
operator|.
name|duplicate
argument_list|()
operator|.
name|position
argument_list|(
literal|0
argument_list|)
operator|.
name|limit
argument_list|(
name|onDiskSizeWithHeader
argument_list|)
decl_stmt|;
comment|// Verify checksum of the data before using it for building HFileBlock.
if|if
condition|(
name|verifyChecksum
operator|&&
operator|!
name|validateChecksum
argument_list|(
name|offset
argument_list|,
name|curBlock
argument_list|,
name|hdrSize
argument_list|)
condition|)
block|{
return|return
literal|null
return|;
block|}
name|long
name|duration
init|=
name|System
operator|.
name|currentTimeMillis
argument_list|()
operator|-
name|startTime
decl_stmt|;
if|if
condition|(
name|updateMetrics
condition|)
block|{
name|HFile
operator|.
name|updateReadLatency
argument_list|(
name|duration
argument_list|,
name|pread
argument_list|)
expr_stmt|;
block|}
comment|// The onDiskBlock will become the headerAndDataBuffer for this block.
comment|// If nextBlockOnDiskSizeWithHeader is not zero, the onDiskBlock already
comment|// contains the header of next block, so no need to set next block's header in it.
name|HFileBlock
name|hFileBlock
init|=
operator|new
name|HFileBlock
argument_list|(
name|curBlock
argument_list|,
name|checksumSupport
argument_list|,
name|MemoryType
operator|.
name|EXCLUSIVE
argument_list|,
name|offset
argument_list|,
name|nextBlockOnDiskSize
argument_list|,
name|fileContext
argument_list|,
name|intoHeap
condition|?
name|HEAP
else|:
name|allocator
argument_list|)
decl_stmt|;
comment|// Run check on uncompressed sizings.
if|if
condition|(
operator|!
name|fileContext
operator|.
name|isCompressedOrEncrypted
argument_list|()
condition|)
block|{
name|hFileBlock
operator|.
name|sanityCheckUncompressed
argument_list|()
expr_stmt|;
block|}
name|LOG
operator|.
name|trace
argument_list|(
literal|"Read {} in {} ns"
argument_list|,
name|hFileBlock
argument_list|,
name|duration
argument_list|)
expr_stmt|;
comment|// Cache next block header if we read it for the next time through here.
if|if
condition|(
name|nextBlockOnDiskSize
operator|!=
operator|-
literal|1
condition|)
block|{
name|cacheNextBlockHeader
argument_list|(
name|offset
operator|+
name|hFileBlock
operator|.
name|getOnDiskSizeWithHeader
argument_list|()
argument_list|,
name|onDiskBlock
argument_list|,
name|onDiskSizeWithHeader
argument_list|,
name|hdrSize
argument_list|)
expr_stmt|;
block|}
name|initHFileBlockSuccess
operator|=
literal|true
expr_stmt|;
return|return
name|hFileBlock
return|;
block|}
finally|finally
block|{
if|if
condition|(
operator|!
name|initHFileBlockSuccess
condition|)
block|{
name|onDiskBlock
operator|.
name|release
argument_list|()
expr_stmt|;
block|}
block|}
block|}
annotation|@
name|Override
specifier|public
name|void
name|setIncludesMemStoreTS
parameter_list|(
name|boolean
name|includesMemstoreTS
parameter_list|)
block|{
name|this
operator|.
name|fileContext
operator|.
name|setIncludesMvcc
argument_list|(
name|includesMemstoreTS
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|setDataBlockEncoder
parameter_list|(
name|HFileDataBlockEncoder
name|encoder
parameter_list|)
block|{
name|encodedBlockDecodingCtx
operator|=
name|encoder
operator|.
name|newDataBlockDecodingContext
argument_list|(
name|this
operator|.
name|fileContext
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|HFileBlockDecodingContext
name|getBlockDecodingContext
parameter_list|()
block|{
return|return
name|this
operator|.
name|encodedBlockDecodingCtx
return|;
block|}
annotation|@
name|Override
specifier|public
name|HFileBlockDecodingContext
name|getDefaultBlockDecodingContext
parameter_list|()
block|{
return|return
name|this
operator|.
name|defaultDecodingCtx
return|;
block|}
comment|/**      * Generates the checksum for the header as well as the data and then validates it.      * If the block doesn't uses checksum, returns false.      * @return True if checksum matches, else false.      */
specifier|private
name|boolean
name|validateChecksum
parameter_list|(
name|long
name|offset
parameter_list|,
name|ByteBuff
name|data
parameter_list|,
name|int
name|hdrSize
parameter_list|)
block|{
comment|// If this is an older version of the block that does not have checksums, then return false
comment|// indicating that checksum verification did not succeed. Actually, this method should never
comment|// be called when the minorVersion is 0, thus this is a defensive check for a cannot-happen
comment|// case. Since this is a cannot-happen case, it is better to return false to indicate a
comment|// checksum validation failure.
if|if
condition|(
operator|!
name|fileContext
operator|.
name|isUseHBaseChecksum
argument_list|()
condition|)
block|{
return|return
literal|false
return|;
block|}
return|return
name|ChecksumUtil
operator|.
name|validateChecksum
argument_list|(
name|data
argument_list|,
name|pathName
argument_list|,
name|offset
argument_list|,
name|hdrSize
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|closeStreams
parameter_list|()
throws|throws
name|IOException
block|{
name|streamWrapper
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|unbufferStream
parameter_list|()
block|{
comment|// To handle concurrent reads, ensure that no other client is accessing the streams while we
comment|// unbuffer it.
if|if
condition|(
name|streamLock
operator|.
name|tryLock
argument_list|()
condition|)
block|{
try|try
block|{
name|this
operator|.
name|streamWrapper
operator|.
name|unbuffer
argument_list|()
expr_stmt|;
block|}
finally|finally
block|{
name|streamLock
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
block|}
annotation|@
name|Override
specifier|public
name|String
name|toString
parameter_list|()
block|{
return|return
literal|"hfs="
operator|+
name|hfs
operator|+
literal|", path="
operator|+
name|pathName
operator|+
literal|", fileContext="
operator|+
name|fileContext
return|;
block|}
block|}
comment|/** An additional sanity-check in case no compression or encryption is being used. */
annotation|@
name|VisibleForTesting
name|void
name|sanityCheckUncompressed
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|onDiskSizeWithoutHeader
operator|!=
name|uncompressedSizeWithoutHeader
operator|+
name|totalChecksumBytes
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Using no compression but "
operator|+
literal|"onDiskSizeWithoutHeader="
operator|+
name|onDiskSizeWithoutHeader
operator|+
literal|", "
operator|+
literal|"uncompressedSizeWithoutHeader="
operator|+
name|uncompressedSizeWithoutHeader
operator|+
literal|", numChecksumbytes="
operator|+
name|totalChecksumBytes
argument_list|()
argument_list|)
throw|;
block|}
block|}
comment|// Cacheable implementation
annotation|@
name|Override
specifier|public
name|int
name|getSerializedLength
parameter_list|()
block|{
if|if
condition|(
name|buf
operator|!=
literal|null
condition|)
block|{
comment|// Include extra bytes for block metadata.
return|return
name|this
operator|.
name|buf
operator|.
name|limit
argument_list|()
operator|+
name|BLOCK_METADATA_SPACE
return|;
block|}
return|return
literal|0
return|;
block|}
comment|// Cacheable implementation
annotation|@
name|Override
specifier|public
name|void
name|serialize
parameter_list|(
name|ByteBuffer
name|destination
parameter_list|,
name|boolean
name|includeNextBlockMetadata
parameter_list|)
block|{
name|this
operator|.
name|buf
operator|.
name|get
argument_list|(
name|destination
argument_list|,
literal|0
argument_list|,
name|getSerializedLength
argument_list|()
operator|-
name|BLOCK_METADATA_SPACE
argument_list|)
expr_stmt|;
name|destination
operator|=
name|addMetaData
argument_list|(
name|destination
argument_list|,
name|includeNextBlockMetadata
argument_list|)
expr_stmt|;
comment|// Make it ready for reading. flip sets position to zero and limit to current position which
comment|// is what we want if we do not want to serialize the block plus checksums if present plus
comment|// metadata.
name|destination
operator|.
name|flip
argument_list|()
expr_stmt|;
block|}
comment|/**    * For use by bucketcache. This exposes internals.    */
specifier|public
name|ByteBuffer
name|getMetaData
parameter_list|()
block|{
name|ByteBuffer
name|bb
init|=
name|ByteBuffer
operator|.
name|allocate
argument_list|(
name|BLOCK_METADATA_SPACE
argument_list|)
decl_stmt|;
name|bb
operator|=
name|addMetaData
argument_list|(
name|bb
argument_list|,
literal|true
argument_list|)
expr_stmt|;
name|bb
operator|.
name|flip
argument_list|()
expr_stmt|;
return|return
name|bb
return|;
block|}
comment|/**    * Adds metadata at current position (position is moved forward). Does not flip or reset.    * @return The passed<code>destination</code> with metadata added.    */
specifier|private
name|ByteBuffer
name|addMetaData
parameter_list|(
specifier|final
name|ByteBuffer
name|destination
parameter_list|,
name|boolean
name|includeNextBlockMetadata
parameter_list|)
block|{
name|destination
operator|.
name|put
argument_list|(
name|this
operator|.
name|fileContext
operator|.
name|isUseHBaseChecksum
argument_list|()
condition|?
operator|(
name|byte
operator|)
literal|1
else|:
operator|(
name|byte
operator|)
literal|0
argument_list|)
expr_stmt|;
name|destination
operator|.
name|putLong
argument_list|(
name|this
operator|.
name|offset
argument_list|)
expr_stmt|;
if|if
condition|(
name|includeNextBlockMetadata
condition|)
block|{
name|destination
operator|.
name|putInt
argument_list|(
name|this
operator|.
name|nextBlockOnDiskSize
argument_list|)
expr_stmt|;
block|}
return|return
name|destination
return|;
block|}
comment|// Cacheable implementation
annotation|@
name|Override
specifier|public
name|CacheableDeserializer
argument_list|<
name|Cacheable
argument_list|>
name|getDeserializer
parameter_list|()
block|{
return|return
name|HFileBlock
operator|.
name|BLOCK_DESERIALIZER
return|;
block|}
annotation|@
name|Override
specifier|public
name|int
name|hashCode
parameter_list|()
block|{
name|int
name|result
init|=
literal|1
decl_stmt|;
name|result
operator|=
name|result
operator|*
literal|31
operator|+
name|blockType
operator|.
name|hashCode
argument_list|()
expr_stmt|;
name|result
operator|=
name|result
operator|*
literal|31
operator|+
name|nextBlockOnDiskSize
expr_stmt|;
name|result
operator|=
name|result
operator|*
literal|31
operator|+
call|(
name|int
call|)
argument_list|(
name|offset
operator|^
operator|(
name|offset
operator|>>>
literal|32
operator|)
argument_list|)
expr_stmt|;
name|result
operator|=
name|result
operator|*
literal|31
operator|+
name|onDiskSizeWithoutHeader
expr_stmt|;
name|result
operator|=
name|result
operator|*
literal|31
operator|+
call|(
name|int
call|)
argument_list|(
name|prevBlockOffset
operator|^
operator|(
name|prevBlockOffset
operator|>>>
literal|32
operator|)
argument_list|)
expr_stmt|;
name|result
operator|=
name|result
operator|*
literal|31
operator|+
name|uncompressedSizeWithoutHeader
expr_stmt|;
name|result
operator|=
name|result
operator|*
literal|31
operator|+
name|buf
operator|.
name|hashCode
argument_list|()
expr_stmt|;
return|return
name|result
return|;
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|equals
parameter_list|(
name|Object
name|comparison
parameter_list|)
block|{
if|if
condition|(
name|this
operator|==
name|comparison
condition|)
block|{
return|return
literal|true
return|;
block|}
if|if
condition|(
name|comparison
operator|==
literal|null
condition|)
block|{
return|return
literal|false
return|;
block|}
if|if
condition|(
name|comparison
operator|.
name|getClass
argument_list|()
operator|!=
name|this
operator|.
name|getClass
argument_list|()
condition|)
block|{
return|return
literal|false
return|;
block|}
name|HFileBlock
name|castedComparison
init|=
operator|(
name|HFileBlock
operator|)
name|comparison
decl_stmt|;
if|if
condition|(
name|castedComparison
operator|.
name|blockType
operator|!=
name|this
operator|.
name|blockType
condition|)
block|{
return|return
literal|false
return|;
block|}
if|if
condition|(
name|castedComparison
operator|.
name|nextBlockOnDiskSize
operator|!=
name|this
operator|.
name|nextBlockOnDiskSize
condition|)
block|{
return|return
literal|false
return|;
block|}
comment|// Offset is important. Needed when we have to remake cachekey when block is returned to cache.
if|if
condition|(
name|castedComparison
operator|.
name|offset
operator|!=
name|this
operator|.
name|offset
condition|)
block|{
return|return
literal|false
return|;
block|}
if|if
condition|(
name|castedComparison
operator|.
name|onDiskSizeWithoutHeader
operator|!=
name|this
operator|.
name|onDiskSizeWithoutHeader
condition|)
block|{
return|return
literal|false
return|;
block|}
if|if
condition|(
name|castedComparison
operator|.
name|prevBlockOffset
operator|!=
name|this
operator|.
name|prevBlockOffset
condition|)
block|{
return|return
literal|false
return|;
block|}
if|if
condition|(
name|castedComparison
operator|.
name|uncompressedSizeWithoutHeader
operator|!=
name|this
operator|.
name|uncompressedSizeWithoutHeader
condition|)
block|{
return|return
literal|false
return|;
block|}
if|if
condition|(
name|ByteBuff
operator|.
name|compareTo
argument_list|(
name|this
operator|.
name|buf
argument_list|,
literal|0
argument_list|,
name|this
operator|.
name|buf
operator|.
name|limit
argument_list|()
argument_list|,
name|castedComparison
operator|.
name|buf
argument_list|,
literal|0
argument_list|,
name|castedComparison
operator|.
name|buf
operator|.
name|limit
argument_list|()
argument_list|)
operator|!=
literal|0
condition|)
block|{
return|return
literal|false
return|;
block|}
return|return
literal|true
return|;
block|}
name|DataBlockEncoding
name|getDataBlockEncoding
parameter_list|()
block|{
if|if
condition|(
name|blockType
operator|==
name|BlockType
operator|.
name|ENCODED_DATA
condition|)
block|{
return|return
name|DataBlockEncoding
operator|.
name|getEncodingById
argument_list|(
name|getDataBlockEncodingId
argument_list|()
argument_list|)
return|;
block|}
return|return
name|DataBlockEncoding
operator|.
name|NONE
return|;
block|}
annotation|@
name|VisibleForTesting
name|byte
name|getChecksumType
parameter_list|()
block|{
return|return
name|this
operator|.
name|fileContext
operator|.
name|getChecksumType
argument_list|()
operator|.
name|getCode
argument_list|()
return|;
block|}
name|int
name|getBytesPerChecksum
parameter_list|()
block|{
return|return
name|this
operator|.
name|fileContext
operator|.
name|getBytesPerChecksum
argument_list|()
return|;
block|}
comment|/** @return the size of data on disk + header. Excludes checksum. */
annotation|@
name|VisibleForTesting
name|int
name|getOnDiskDataSizeWithHeader
parameter_list|()
block|{
return|return
name|this
operator|.
name|onDiskDataSizeWithHeader
return|;
block|}
comment|/**    * Calculate the number of bytes required to store all the checksums    * for this block. Each checksum value is a 4 byte integer.    */
name|int
name|totalChecksumBytes
parameter_list|()
block|{
comment|// If the hfile block has minorVersion 0, then there are no checksum
comment|// data to validate. Similarly, a zero value in this.bytesPerChecksum
comment|// indicates that cached blocks do not have checksum data because
comment|// checksums were already validated when the block was read from disk.
if|if
condition|(
operator|!
name|fileContext
operator|.
name|isUseHBaseChecksum
argument_list|()
operator|||
name|this
operator|.
name|fileContext
operator|.
name|getBytesPerChecksum
argument_list|()
operator|==
literal|0
condition|)
block|{
return|return
literal|0
return|;
block|}
return|return
operator|(
name|int
operator|)
name|ChecksumUtil
operator|.
name|numBytes
argument_list|(
name|onDiskDataSizeWithHeader
argument_list|,
name|this
operator|.
name|fileContext
operator|.
name|getBytesPerChecksum
argument_list|()
argument_list|)
return|;
block|}
comment|/**    * Returns the size of this block header.    */
specifier|public
name|int
name|headerSize
parameter_list|()
block|{
return|return
name|headerSize
argument_list|(
name|this
operator|.
name|fileContext
operator|.
name|isUseHBaseChecksum
argument_list|()
argument_list|)
return|;
block|}
comment|/**    * Maps a minor version to the size of the header.    */
specifier|public
specifier|static
name|int
name|headerSize
parameter_list|(
name|boolean
name|usesHBaseChecksum
parameter_list|)
block|{
return|return
name|usesHBaseChecksum
condition|?
name|HConstants
operator|.
name|HFILEBLOCK_HEADER_SIZE
else|:
name|HConstants
operator|.
name|HFILEBLOCK_HEADER_SIZE_NO_CHECKSUM
return|;
block|}
comment|/**    * Return the appropriate DUMMY_HEADER for the minor version    */
annotation|@
name|VisibleForTesting
comment|// TODO: Why is this in here?
name|byte
index|[]
name|getDummyHeaderForVersion
parameter_list|()
block|{
return|return
name|getDummyHeaderForVersion
argument_list|(
name|this
operator|.
name|fileContext
operator|.
name|isUseHBaseChecksum
argument_list|()
argument_list|)
return|;
block|}
comment|/**    * Return the appropriate DUMMY_HEADER for the minor version    */
specifier|static
specifier|private
name|byte
index|[]
name|getDummyHeaderForVersion
parameter_list|(
name|boolean
name|usesHBaseChecksum
parameter_list|)
block|{
return|return
name|usesHBaseChecksum
condition|?
name|HConstants
operator|.
name|HFILEBLOCK_DUMMY_HEADER
else|:
name|DUMMY_HEADER_NO_CHECKSUM
return|;
block|}
comment|/**    * @return This HFileBlocks fileContext which will a derivative of the    * fileContext for the file from which this block's data was originally read.    */
name|HFileContext
name|getHFileContext
parameter_list|()
block|{
return|return
name|this
operator|.
name|fileContext
return|;
block|}
annotation|@
name|Override
specifier|public
name|MemoryType
name|getMemoryType
parameter_list|()
block|{
return|return
name|this
operator|.
name|memType
return|;
block|}
comment|/**    * @return true if this block is backed by a shared memory area(such as that of a BucketCache).    */
name|boolean
name|usesSharedMemory
parameter_list|()
block|{
return|return
name|this
operator|.
name|memType
operator|==
name|MemoryType
operator|.
name|SHARED
return|;
block|}
comment|/**    * Convert the contents of the block header into a human readable string.    * This is mostly helpful for debugging. This assumes that the block    * has minor version> 0.    */
annotation|@
name|VisibleForTesting
specifier|static
name|String
name|toStringHeader
parameter_list|(
name|ByteBuff
name|buf
parameter_list|)
throws|throws
name|IOException
block|{
name|byte
index|[]
name|magicBuf
init|=
operator|new
name|byte
index|[
name|Math
operator|.
name|min
argument_list|(
name|buf
operator|.
name|limit
argument_list|()
operator|-
name|buf
operator|.
name|position
argument_list|()
argument_list|,
name|BlockType
operator|.
name|MAGIC_LENGTH
argument_list|)
index|]
decl_stmt|;
name|buf
operator|.
name|get
argument_list|(
name|magicBuf
argument_list|)
expr_stmt|;
name|BlockType
name|bt
init|=
name|BlockType
operator|.
name|parse
argument_list|(
name|magicBuf
argument_list|,
literal|0
argument_list|,
name|BlockType
operator|.
name|MAGIC_LENGTH
argument_list|)
decl_stmt|;
name|int
name|compressedBlockSizeNoHeader
init|=
name|buf
operator|.
name|getInt
argument_list|()
decl_stmt|;
name|int
name|uncompressedBlockSizeNoHeader
init|=
name|buf
operator|.
name|getInt
argument_list|()
decl_stmt|;
name|long
name|prevBlockOffset
init|=
name|buf
operator|.
name|getLong
argument_list|()
decl_stmt|;
name|byte
name|cksumtype
init|=
name|buf
operator|.
name|get
argument_list|()
decl_stmt|;
name|long
name|bytesPerChecksum
init|=
name|buf
operator|.
name|getInt
argument_list|()
decl_stmt|;
name|long
name|onDiskDataSizeWithHeader
init|=
name|buf
operator|.
name|getInt
argument_list|()
decl_stmt|;
return|return
literal|" Header dump: magic: "
operator|+
name|Bytes
operator|.
name|toString
argument_list|(
name|magicBuf
argument_list|)
operator|+
literal|" blockType "
operator|+
name|bt
operator|+
literal|" compressedBlockSizeNoHeader "
operator|+
name|compressedBlockSizeNoHeader
operator|+
literal|" uncompressedBlockSizeNoHeader "
operator|+
name|uncompressedBlockSizeNoHeader
operator|+
literal|" prevBlockOffset "
operator|+
name|prevBlockOffset
operator|+
literal|" checksumType "
operator|+
name|ChecksumType
operator|.
name|codeToType
argument_list|(
name|cksumtype
argument_list|)
operator|+
literal|" bytesPerChecksum "
operator|+
name|bytesPerChecksum
operator|+
literal|" onDiskDataSizeWithHeader "
operator|+
name|onDiskDataSizeWithHeader
return|;
block|}
specifier|public
name|HFileBlock
name|deepCloneOnHeap
parameter_list|()
block|{
return|return
operator|new
name|HFileBlock
argument_list|(
name|this
argument_list|,
literal|true
argument_list|)
return|;
block|}
block|}
end_class

end_unit

