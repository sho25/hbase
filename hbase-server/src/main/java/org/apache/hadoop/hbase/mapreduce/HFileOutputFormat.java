begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  *  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|mapreduce
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|Log
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|LogFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|classification
operator|.
name|InterfaceAudience
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|classification
operator|.
name|InterfaceStability
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HTableDescriptor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|KeyValue
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|HTable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|Table
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|ImmutableBytesWritable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|compress
operator|.
name|Compression
operator|.
name|Algorithm
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|encoding
operator|.
name|DataBlockEncoding
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|BloomType
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|Job
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|RecordWriter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|TaskAttemptContext
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|mapreduce
operator|.
name|lib
operator|.
name|output
operator|.
name|FileOutputFormat
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|annotations
operator|.
name|VisibleForTesting
import|;
end_import

begin_comment
comment|/**  * Writes HFiles. Passed KeyValues must arrive in order.  * Writes current time as the sequence id for the file. Sets the major compacted  * attribute on created hfiles. Calling write(null,null) will forcibly roll  * all HFiles being written.  *<p>  * Using this class as part of a MapReduce job is best done  * using {@link #configureIncrementalLoad(Job, HTable)}.  * @see KeyValueSortReducer  * @deprecated use {@link HFileOutputFormat2} instead.  */
end_comment

begin_class
annotation|@
name|Deprecated
annotation|@
name|InterfaceAudience
operator|.
name|Public
annotation|@
name|InterfaceStability
operator|.
name|Stable
specifier|public
class|class
name|HFileOutputFormat
extends|extends
name|FileOutputFormat
argument_list|<
name|ImmutableBytesWritable
argument_list|,
name|KeyValue
argument_list|>
block|{
specifier|static
name|Log
name|LOG
init|=
name|LogFactory
operator|.
name|getLog
argument_list|(
name|HFileOutputFormat
operator|.
name|class
argument_list|)
decl_stmt|;
comment|// This constant is public since the client can modify this when setting
comment|// up their conf object and thus refer to this symbol.
comment|// It is present for backwards compatibility reasons. Use it only to
comment|// override the auto-detection of datablock encoding.
specifier|public
specifier|static
specifier|final
name|String
name|DATABLOCK_ENCODING_OVERRIDE_CONF_KEY
init|=
name|HFileOutputFormat2
operator|.
name|DATABLOCK_ENCODING_OVERRIDE_CONF_KEY
decl_stmt|;
annotation|@
name|Override
specifier|public
name|RecordWriter
argument_list|<
name|ImmutableBytesWritable
argument_list|,
name|KeyValue
argument_list|>
name|getRecordWriter
parameter_list|(
specifier|final
name|TaskAttemptContext
name|context
parameter_list|)
throws|throws
name|IOException
throws|,
name|InterruptedException
block|{
return|return
name|HFileOutputFormat2
operator|.
name|createRecordWriter
argument_list|(
name|context
argument_list|)
return|;
block|}
comment|/**    * Configure a MapReduce Job to perform an incremental load into the given    * table. This    *<ul>    *<li>Inspects the table to configure a total order partitioner</li>    *<li>Uploads the partitions file to the cluster and adds it to the DistributedCache</li>    *<li>Sets the number of reduce tasks to match the current number of regions</li>    *<li>Sets the output key/value class to match HFileOutputFormat's requirements</li>    *<li>Sets the reducer up to perform the appropriate sorting (either KeyValueSortReducer or    *     PutSortReducer)</li>    *</ul>    * The user should be sure to set the map output value class to either KeyValue or Put before    * running this function.    */
specifier|public
specifier|static
name|void
name|configureIncrementalLoad
parameter_list|(
name|Job
name|job
parameter_list|,
name|HTable
name|table
parameter_list|)
throws|throws
name|IOException
block|{
name|HFileOutputFormat2
operator|.
name|configureIncrementalLoad
argument_list|(
name|job
argument_list|,
name|table
operator|.
name|getTableDescriptor
argument_list|()
argument_list|,
name|table
operator|.
name|getRegionLocator
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|/**    * Runs inside the task to deserialize column family to compression algorithm    * map from the configuration.    *    * @param conf to read the serialized values from    * @return a map from column family to the configured compression algorithm    */
annotation|@
name|VisibleForTesting
specifier|static
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|Algorithm
argument_list|>
name|createFamilyCompressionMap
parameter_list|(
name|Configuration
name|conf
parameter_list|)
block|{
return|return
name|HFileOutputFormat2
operator|.
name|createFamilyCompressionMap
argument_list|(
name|conf
argument_list|)
return|;
block|}
comment|/**    * Runs inside the task to deserialize column family to bloom filter type    * map from the configuration.    *    * @param conf to read the serialized values from    * @return a map from column family to the the configured bloom filter type    */
annotation|@
name|VisibleForTesting
specifier|static
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|BloomType
argument_list|>
name|createFamilyBloomTypeMap
parameter_list|(
name|Configuration
name|conf
parameter_list|)
block|{
return|return
name|HFileOutputFormat2
operator|.
name|createFamilyBloomTypeMap
argument_list|(
name|conf
argument_list|)
return|;
block|}
comment|/**    * Runs inside the task to deserialize column family to block size    * map from the configuration.    *    * @param conf to read the serialized values from    * @return a map from column family to the configured block size    */
annotation|@
name|VisibleForTesting
specifier|static
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|Integer
argument_list|>
name|createFamilyBlockSizeMap
parameter_list|(
name|Configuration
name|conf
parameter_list|)
block|{
return|return
name|HFileOutputFormat2
operator|.
name|createFamilyBlockSizeMap
argument_list|(
name|conf
argument_list|)
return|;
block|}
comment|/**    * Runs inside the task to deserialize column family to data block encoding    * type map from the configuration.    *    * @param conf to read the serialized values from    * @return a map from column family to HFileDataBlockEncoder for the    *         configured data block type for the family    */
annotation|@
name|VisibleForTesting
specifier|static
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|DataBlockEncoding
argument_list|>
name|createFamilyDataBlockEncodingMap
parameter_list|(
name|Configuration
name|conf
parameter_list|)
block|{
return|return
name|HFileOutputFormat2
operator|.
name|createFamilyDataBlockEncodingMap
argument_list|(
name|conf
argument_list|)
return|;
block|}
comment|/**    * Configure<code>job</code> with a TotalOrderPartitioner, partitioning against    *<code>splitPoints</code>. Cleans up the partitions file after job exists.    */
specifier|static
name|void
name|configurePartitioner
parameter_list|(
name|Job
name|job
parameter_list|,
name|List
argument_list|<
name|ImmutableBytesWritable
argument_list|>
name|splitPoints
parameter_list|)
throws|throws
name|IOException
block|{
name|HFileOutputFormat2
operator|.
name|configurePartitioner
argument_list|(
name|job
argument_list|,
name|splitPoints
argument_list|)
expr_stmt|;
block|}
specifier|static
name|void
name|configureCompression
parameter_list|(
name|Table
name|table
parameter_list|,
name|Configuration
name|conf
parameter_list|)
throws|throws
name|IOException
block|{
name|HFileOutputFormat2
operator|.
name|configureCompression
argument_list|(
name|conf
argument_list|,
name|table
operator|.
name|getTableDescriptor
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|/**    * Serialize column family to block size map to configuration.    * Invoked while configuring the MR job for incremental load.    *    * @param table to read the properties from    * @param conf to persist serialized values into    * @throws IOException    *           on failure to read column family descriptors    */
annotation|@
name|VisibleForTesting
specifier|static
name|void
name|configureBlockSize
parameter_list|(
name|Table
name|table
parameter_list|,
name|Configuration
name|conf
parameter_list|)
throws|throws
name|IOException
block|{
name|HFileOutputFormat2
operator|.
name|configureBlockSize
argument_list|(
name|table
operator|.
name|getTableDescriptor
argument_list|()
argument_list|,
name|conf
argument_list|)
expr_stmt|;
block|}
comment|/**    * Serialize column family to bloom type map to configuration.    * Invoked while configuring the MR job for incremental load.    *    * @param table to read the properties from    * @param conf to persist serialized values into    * @throws IOException    *           on failure to read column family descriptors    */
annotation|@
name|VisibleForTesting
specifier|static
name|void
name|configureBloomType
parameter_list|(
name|Table
name|table
parameter_list|,
name|Configuration
name|conf
parameter_list|)
throws|throws
name|IOException
block|{
name|HFileOutputFormat2
operator|.
name|configureBloomType
argument_list|(
name|table
operator|.
name|getTableDescriptor
argument_list|()
argument_list|,
name|conf
argument_list|)
expr_stmt|;
block|}
comment|/**    * Serialize column family to data block encoding map to configuration.    * Invoked while configuring the MR job for incremental load.    *    * @param table to read the properties from    * @param conf to persist serialized values into    * @throws IOException    *           on failure to read column family descriptors    */
annotation|@
name|VisibleForTesting
specifier|static
name|void
name|configureDataBlockEncoding
parameter_list|(
name|Table
name|table
parameter_list|,
name|Configuration
name|conf
parameter_list|)
throws|throws
name|IOException
block|{
name|HTableDescriptor
name|tableDescriptor
init|=
name|table
operator|.
name|getTableDescriptor
argument_list|()
decl_stmt|;
name|HFileOutputFormat2
operator|.
name|configureDataBlockEncoding
argument_list|(
name|tableDescriptor
argument_list|,
name|conf
argument_list|)
expr_stmt|;
block|}
block|}
end_class

end_unit

