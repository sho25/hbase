begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/*  *  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|hfile
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|ByteArrayOutputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|DataInput
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|DataInputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|DataOutput
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|DataOutputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|nio
operator|.
name|ByteBuffer
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collections
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|atomic
operator|.
name|AtomicReference
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FSDataOutputStream
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|ByteBufferKeyOnlyKeyValue
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|Cell
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|CellComparator
import|;
end_import

begin_comment
comment|//import org.apache.hadoop.hbase.CellComparatorImpl;
end_comment

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|CellUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|PrivateCellUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|KeyValue
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|KeyValue
operator|.
name|KeyOnlyKeyValue
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|yetus
operator|.
name|audience
operator|.
name|InterfaceAudience
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|Logger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|LoggerFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|HeapSize
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|encoding
operator|.
name|DataBlockEncoding
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|hfile
operator|.
name|HFile
operator|.
name|CachingBlockReader
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|nio
operator|.
name|ByteBuff
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|KeyValueScanner
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|Bytes
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|ClassSize
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|ObjectIntPair
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|WritableUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|StringUtils
import|;
end_import

begin_comment
comment|/**  * Provides functionality to write ({@link BlockIndexWriter}) and read  * BlockIndexReader  * single-level and multi-level block indexes.  *  * Examples of how to use the block index writer can be found in  * {@link org.apache.hadoop.hbase.io.hfile.CompoundBloomFilterWriter} and  *  {@link HFileWriterImpl}. Examples of how to use the reader can be  *  found in {@link HFileReaderImpl} and  *  org.apache.hadoop.hbase.io.hfile.TestHFileBlockIndex.  */
end_comment

begin_class
annotation|@
name|InterfaceAudience
operator|.
name|Private
specifier|public
class|class
name|HFileBlockIndex
block|{
specifier|private
specifier|static
specifier|final
name|Logger
name|LOG
init|=
name|LoggerFactory
operator|.
name|getLogger
argument_list|(
name|HFileBlockIndex
operator|.
name|class
argument_list|)
decl_stmt|;
specifier|static
specifier|final
name|int
name|DEFAULT_MAX_CHUNK_SIZE
init|=
literal|128
operator|*
literal|1024
decl_stmt|;
comment|/**    * The maximum size guideline for index blocks (both leaf, intermediate, and    * root). If not specified,<code>DEFAULT_MAX_CHUNK_SIZE</code> is used.    */
specifier|public
specifier|static
specifier|final
name|String
name|MAX_CHUNK_SIZE_KEY
init|=
literal|"hfile.index.block.max.size"
decl_stmt|;
comment|/**    * Minimum number of entries in a single index block. Even if we are above the    * hfile.index.block.max.size we will keep writing to the same block unless we have that many    * entries. We should have at least a few entries so that we don't have too many levels in the    * multi-level index. This should be at least 2 to make sure there is no infinite recursion.    */
specifier|public
specifier|static
specifier|final
name|String
name|MIN_INDEX_NUM_ENTRIES_KEY
init|=
literal|"hfile.index.block.min.entries"
decl_stmt|;
specifier|static
specifier|final
name|int
name|DEFAULT_MIN_INDEX_NUM_ENTRIES
init|=
literal|16
decl_stmt|;
comment|/**    * The number of bytes stored in each "secondary index" entry in addition to    * key bytes in the non-root index block format. The first long is the file    * offset of the deeper-level block the entry points to, and the int that    * follows is that block's on-disk size without including header.    */
specifier|static
specifier|final
name|int
name|SECONDARY_INDEX_ENTRY_OVERHEAD
init|=
name|Bytes
operator|.
name|SIZEOF_INT
operator|+
name|Bytes
operator|.
name|SIZEOF_LONG
decl_stmt|;
comment|/**    * Error message when trying to use inline block API in single-level mode.    */
specifier|private
specifier|static
specifier|final
name|String
name|INLINE_BLOCKS_NOT_ALLOWED
init|=
literal|"Inline blocks are not allowed in the single-level-only mode"
decl_stmt|;
comment|/**    * The size of a meta-data record used for finding the mid-key in a    * multi-level index. Consists of the middle leaf-level index block offset    * (long), its on-disk size without header included (int), and the mid-key    * entry's zero-based index in that leaf index block.    */
specifier|private
specifier|static
specifier|final
name|int
name|MID_KEY_METADATA_SIZE
init|=
name|Bytes
operator|.
name|SIZEOF_LONG
operator|+
literal|2
operator|*
name|Bytes
operator|.
name|SIZEOF_INT
decl_stmt|;
comment|/**    * An implementation of the BlockIndexReader that deals with block keys which are plain    * byte[] like MetaBlock or the Bloom Block for ROW bloom.    * Does not need a comparator. It can work on Bytes.BYTES_RAWCOMPARATOR    */
specifier|static
class|class
name|ByteArrayKeyBlockIndexReader
extends|extends
name|BlockIndexReader
block|{
specifier|private
name|byte
index|[]
index|[]
name|blockKeys
decl_stmt|;
specifier|public
name|ByteArrayKeyBlockIndexReader
parameter_list|(
specifier|final
name|int
name|treeLevel
parameter_list|)
block|{
comment|// Can be null for METAINDEX block
name|searchTreeLevel
operator|=
name|treeLevel
expr_stmt|;
block|}
annotation|@
name|Override
specifier|protected
name|long
name|calculateHeapSizeForBlockKeys
parameter_list|(
name|long
name|heapSize
parameter_list|)
block|{
comment|// Calculating the size of blockKeys
if|if
condition|(
name|blockKeys
operator|!=
literal|null
condition|)
block|{
name|heapSize
operator|+=
name|ClassSize
operator|.
name|REFERENCE
expr_stmt|;
comment|// Adding array + references overhead
name|heapSize
operator|+=
name|ClassSize
operator|.
name|align
argument_list|(
name|ClassSize
operator|.
name|ARRAY
operator|+
name|blockKeys
operator|.
name|length
operator|*
name|ClassSize
operator|.
name|REFERENCE
argument_list|)
expr_stmt|;
comment|// Adding bytes
for|for
control|(
name|byte
index|[]
name|key
range|:
name|blockKeys
control|)
block|{
name|heapSize
operator|+=
name|ClassSize
operator|.
name|align
argument_list|(
name|ClassSize
operator|.
name|ARRAY
operator|+
name|key
operator|.
name|length
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|heapSize
return|;
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|isEmpty
parameter_list|()
block|{
return|return
name|blockKeys
operator|.
name|length
operator|==
literal|0
return|;
block|}
comment|/**      * @param i      *          from 0 to {@link #getRootBlockCount() - 1}      */
specifier|public
name|byte
index|[]
name|getRootBlockKey
parameter_list|(
name|int
name|i
parameter_list|)
block|{
return|return
name|blockKeys
index|[
name|i
index|]
return|;
block|}
annotation|@
name|Override
specifier|public
name|BlockWithScanInfo
name|loadDataBlockWithScanInfo
parameter_list|(
name|Cell
name|key
parameter_list|,
name|HFileBlock
name|currentBlock
parameter_list|,
name|boolean
name|cacheBlocks
parameter_list|,
name|boolean
name|pread
parameter_list|,
name|boolean
name|isCompaction
parameter_list|,
name|DataBlockEncoding
name|expectedDataBlockEncoding
parameter_list|,
name|CachingBlockReader
name|cachingBlockReader
parameter_list|)
throws|throws
name|IOException
block|{
comment|// this would not be needed
return|return
literal|null
return|;
block|}
annotation|@
name|Override
specifier|public
name|Cell
name|midkey
parameter_list|(
name|CachingBlockReader
name|cachingBlockReader
parameter_list|)
throws|throws
name|IOException
block|{
comment|// Not needed here
return|return
literal|null
return|;
block|}
annotation|@
name|Override
specifier|protected
name|void
name|initialize
parameter_list|(
name|int
name|numEntries
parameter_list|)
block|{
name|blockKeys
operator|=
operator|new
name|byte
index|[
name|numEntries
index|]
index|[]
expr_stmt|;
block|}
annotation|@
name|Override
specifier|protected
name|void
name|add
parameter_list|(
specifier|final
name|byte
index|[]
name|key
parameter_list|,
specifier|final
name|long
name|offset
parameter_list|,
specifier|final
name|int
name|dataSize
parameter_list|)
block|{
name|blockOffsets
index|[
name|rootCount
index|]
operator|=
name|offset
expr_stmt|;
name|blockKeys
index|[
name|rootCount
index|]
operator|=
name|key
expr_stmt|;
name|blockDataSizes
index|[
name|rootCount
index|]
operator|=
name|dataSize
expr_stmt|;
name|rootCount
operator|++
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|int
name|rootBlockContainingKey
parameter_list|(
name|byte
index|[]
name|key
parameter_list|,
name|int
name|offset
parameter_list|,
name|int
name|length
parameter_list|,
name|CellComparator
name|comp
parameter_list|)
block|{
name|int
name|pos
init|=
name|Bytes
operator|.
name|binarySearch
argument_list|(
name|blockKeys
argument_list|,
name|key
argument_list|,
name|offset
argument_list|,
name|length
argument_list|)
decl_stmt|;
comment|// pos is between -(blockKeys.length + 1) to blockKeys.length - 1, see
comment|// binarySearch's javadoc.
if|if
condition|(
name|pos
operator|>=
literal|0
condition|)
block|{
comment|// This means this is an exact match with an element of blockKeys.
assert|assert
name|pos
operator|<
name|blockKeys
operator|.
name|length
assert|;
return|return
name|pos
return|;
block|}
comment|// Otherwise, pos = -(i + 1), where blockKeys[i - 1]< key< blockKeys[i],
comment|// and i is in [0, blockKeys.length]. We are returning j = i - 1 such that
comment|// blockKeys[j]<= key< blockKeys[j + 1]. In particular, j = -1 if
comment|// key< blockKeys[0], meaning the file does not contain the given key.
name|int
name|i
init|=
operator|-
name|pos
operator|-
literal|1
decl_stmt|;
assert|assert
literal|0
operator|<=
name|i
operator|&&
name|i
operator|<=
name|blockKeys
operator|.
name|length
assert|;
return|return
name|i
operator|-
literal|1
return|;
block|}
annotation|@
name|Override
specifier|public
name|int
name|rootBlockContainingKey
parameter_list|(
name|Cell
name|key
parameter_list|)
block|{
comment|// Should not be called on this because here it deals only with byte[]
throw|throw
operator|new
name|UnsupportedOperationException
argument_list|(
literal|"Cannot search for a key that is of Cell type. Only plain byte array keys "
operator|+
literal|"can be searched for"
argument_list|)
throw|;
block|}
annotation|@
name|Override
specifier|public
name|String
name|toString
parameter_list|()
block|{
name|StringBuilder
name|sb
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
name|sb
operator|.
name|append
argument_list|(
literal|"size="
operator|+
name|rootCount
argument_list|)
operator|.
name|append
argument_list|(
literal|"\n"
argument_list|)
expr_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|rootCount
condition|;
name|i
operator|++
control|)
block|{
name|sb
operator|.
name|append
argument_list|(
literal|"key="
argument_list|)
operator|.
name|append
argument_list|(
name|KeyValue
operator|.
name|keyToString
argument_list|(
name|blockKeys
index|[
name|i
index|]
argument_list|)
argument_list|)
operator|.
name|append
argument_list|(
literal|"\n  offset="
argument_list|)
operator|.
name|append
argument_list|(
name|blockOffsets
index|[
name|i
index|]
argument_list|)
operator|.
name|append
argument_list|(
literal|", dataSize="
operator|+
name|blockDataSizes
index|[
name|i
index|]
argument_list|)
operator|.
name|append
argument_list|(
literal|"\n"
argument_list|)
expr_stmt|;
block|}
return|return
name|sb
operator|.
name|toString
argument_list|()
return|;
block|}
block|}
comment|/**    * An implementation of the BlockIndexReader that deals with block keys which are the key    * part of a cell like the Data block index or the ROW_COL bloom blocks    * This needs a comparator to work with the Cells    */
specifier|static
class|class
name|CellBasedKeyBlockIndexReader
extends|extends
name|BlockIndexReader
block|{
specifier|private
name|Cell
index|[]
name|blockKeys
decl_stmt|;
comment|/** Pre-computed mid-key */
specifier|private
name|AtomicReference
argument_list|<
name|Cell
argument_list|>
name|midKey
init|=
operator|new
name|AtomicReference
argument_list|<>
argument_list|()
decl_stmt|;
comment|/** Needed doing lookup on blocks. */
specifier|private
name|CellComparator
name|comparator
decl_stmt|;
specifier|public
name|CellBasedKeyBlockIndexReader
parameter_list|(
specifier|final
name|CellComparator
name|c
parameter_list|,
specifier|final
name|int
name|treeLevel
parameter_list|)
block|{
comment|// Can be null for METAINDEX block
name|comparator
operator|=
name|c
expr_stmt|;
name|searchTreeLevel
operator|=
name|treeLevel
expr_stmt|;
block|}
annotation|@
name|Override
specifier|protected
name|long
name|calculateHeapSizeForBlockKeys
parameter_list|(
name|long
name|heapSize
parameter_list|)
block|{
if|if
condition|(
name|blockKeys
operator|!=
literal|null
condition|)
block|{
name|heapSize
operator|+=
name|ClassSize
operator|.
name|REFERENCE
expr_stmt|;
comment|// Adding array + references overhead
name|heapSize
operator|+=
name|ClassSize
operator|.
name|align
argument_list|(
name|ClassSize
operator|.
name|ARRAY
operator|+
name|blockKeys
operator|.
name|length
operator|*
name|ClassSize
operator|.
name|REFERENCE
argument_list|)
expr_stmt|;
comment|// Adding blockKeys
for|for
control|(
name|Cell
name|key
range|:
name|blockKeys
control|)
block|{
name|heapSize
operator|+=
name|ClassSize
operator|.
name|align
argument_list|(
name|key
operator|.
name|heapSize
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
comment|// Add comparator and the midkey atomicreference
name|heapSize
operator|+=
literal|2
operator|*
name|ClassSize
operator|.
name|REFERENCE
expr_stmt|;
return|return
name|heapSize
return|;
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|isEmpty
parameter_list|()
block|{
return|return
name|blockKeys
operator|.
name|length
operator|==
literal|0
return|;
block|}
comment|/**      * @param i      *          from 0 to {@link #getRootBlockCount() - 1}      */
specifier|public
name|Cell
name|getRootBlockKey
parameter_list|(
name|int
name|i
parameter_list|)
block|{
return|return
name|blockKeys
index|[
name|i
index|]
return|;
block|}
annotation|@
name|Override
specifier|public
name|BlockWithScanInfo
name|loadDataBlockWithScanInfo
parameter_list|(
name|Cell
name|key
parameter_list|,
name|HFileBlock
name|currentBlock
parameter_list|,
name|boolean
name|cacheBlocks
parameter_list|,
name|boolean
name|pread
parameter_list|,
name|boolean
name|isCompaction
parameter_list|,
name|DataBlockEncoding
name|expectedDataBlockEncoding
parameter_list|,
name|CachingBlockReader
name|cachingBlockReader
parameter_list|)
throws|throws
name|IOException
block|{
name|int
name|rootLevelIndex
init|=
name|rootBlockContainingKey
argument_list|(
name|key
argument_list|)
decl_stmt|;
if|if
condition|(
name|rootLevelIndex
operator|<
literal|0
operator|||
name|rootLevelIndex
operator|>=
name|blockOffsets
operator|.
name|length
condition|)
block|{
return|return
literal|null
return|;
block|}
comment|// the next indexed key
name|Cell
name|nextIndexedKey
init|=
literal|null
decl_stmt|;
comment|// Read the next-level (intermediate or leaf) index block.
name|long
name|currentOffset
init|=
name|blockOffsets
index|[
name|rootLevelIndex
index|]
decl_stmt|;
name|int
name|currentOnDiskSize
init|=
name|blockDataSizes
index|[
name|rootLevelIndex
index|]
decl_stmt|;
if|if
condition|(
name|rootLevelIndex
operator|<
name|blockKeys
operator|.
name|length
operator|-
literal|1
condition|)
block|{
name|nextIndexedKey
operator|=
name|blockKeys
index|[
name|rootLevelIndex
operator|+
literal|1
index|]
expr_stmt|;
block|}
else|else
block|{
name|nextIndexedKey
operator|=
name|KeyValueScanner
operator|.
name|NO_NEXT_INDEXED_KEY
expr_stmt|;
block|}
name|int
name|lookupLevel
init|=
literal|1
decl_stmt|;
comment|// How many levels deep we are in our lookup.
name|int
name|index
init|=
operator|-
literal|1
decl_stmt|;
name|HFileBlock
name|block
init|=
literal|null
decl_stmt|;
name|KeyOnlyKeyValue
name|tmpNextIndexKV
init|=
operator|new
name|KeyValue
operator|.
name|KeyOnlyKeyValue
argument_list|()
decl_stmt|;
while|while
condition|(
literal|true
condition|)
block|{
try|try
block|{
comment|// Must initialize it with null here, because if don't and once an exception happen in
comment|// readBlock, then we'll release the previous assigned block twice in the finally block.
comment|// (See HBASE-22422)
name|block
operator|=
literal|null
expr_stmt|;
if|if
condition|(
name|currentBlock
operator|!=
literal|null
operator|&&
name|currentBlock
operator|.
name|getOffset
argument_list|()
operator|==
name|currentOffset
condition|)
block|{
comment|// Avoid reading the same block again, even with caching turned off.
comment|// This is crucial for compaction-type workload which might have
comment|// caching turned off. This is like a one-block cache inside the
comment|// scanner.
name|block
operator|=
name|currentBlock
expr_stmt|;
block|}
else|else
block|{
comment|// Call HFile's caching block reader API. We always cache index
comment|// blocks, otherwise we might get terrible performance.
name|boolean
name|shouldCache
init|=
name|cacheBlocks
operator|||
operator|(
name|lookupLevel
operator|<
name|searchTreeLevel
operator|)
decl_stmt|;
name|BlockType
name|expectedBlockType
decl_stmt|;
if|if
condition|(
name|lookupLevel
operator|<
name|searchTreeLevel
operator|-
literal|1
condition|)
block|{
name|expectedBlockType
operator|=
name|BlockType
operator|.
name|INTERMEDIATE_INDEX
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|lookupLevel
operator|==
name|searchTreeLevel
operator|-
literal|1
condition|)
block|{
name|expectedBlockType
operator|=
name|BlockType
operator|.
name|LEAF_INDEX
expr_stmt|;
block|}
else|else
block|{
comment|// this also accounts for ENCODED_DATA
name|expectedBlockType
operator|=
name|BlockType
operator|.
name|DATA
expr_stmt|;
block|}
name|block
operator|=
name|cachingBlockReader
operator|.
name|readBlock
argument_list|(
name|currentOffset
argument_list|,
name|currentOnDiskSize
argument_list|,
name|shouldCache
argument_list|,
name|pread
argument_list|,
name|isCompaction
argument_list|,
literal|true
argument_list|,
name|expectedBlockType
argument_list|,
name|expectedDataBlockEncoding
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|block
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Failed to read block at offset "
operator|+
name|currentOffset
operator|+
literal|", onDiskSize="
operator|+
name|currentOnDiskSize
argument_list|)
throw|;
block|}
comment|// Found a data block, break the loop and check our level in the tree.
if|if
condition|(
name|block
operator|.
name|getBlockType
argument_list|()
operator|.
name|isData
argument_list|()
condition|)
block|{
break|break;
block|}
comment|// Not a data block. This must be a leaf-level or intermediate-level
comment|// index block. We don't allow going deeper than searchTreeLevel.
if|if
condition|(
operator|++
name|lookupLevel
operator|>
name|searchTreeLevel
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Search Tree Level overflow: lookupLevel="
operator|+
name|lookupLevel
operator|+
literal|", searchTreeLevel="
operator|+
name|searchTreeLevel
argument_list|)
throw|;
block|}
comment|// Locate the entry corresponding to the given key in the non-root
comment|// (leaf or intermediate-level) index block.
name|ByteBuff
name|buffer
init|=
name|block
operator|.
name|getBufferWithoutHeader
argument_list|()
decl_stmt|;
name|index
operator|=
name|locateNonRootIndexEntry
argument_list|(
name|buffer
argument_list|,
name|key
argument_list|,
name|comparator
argument_list|)
expr_stmt|;
if|if
condition|(
name|index
operator|==
operator|-
literal|1
condition|)
block|{
comment|// This has to be changed
comment|// For now change this to key value
throw|throw
operator|new
name|IOException
argument_list|(
literal|"The key "
operator|+
name|CellUtil
operator|.
name|getCellKeyAsString
argument_list|(
name|key
argument_list|)
operator|+
literal|" is before the"
operator|+
literal|" first key of the non-root index block "
operator|+
name|block
argument_list|)
throw|;
block|}
name|currentOffset
operator|=
name|buffer
operator|.
name|getLong
argument_list|()
expr_stmt|;
name|currentOnDiskSize
operator|=
name|buffer
operator|.
name|getInt
argument_list|()
expr_stmt|;
comment|// Only update next indexed key if there is a next indexed key in the current level
name|byte
index|[]
name|nonRootIndexedKey
init|=
name|getNonRootIndexedKey
argument_list|(
name|buffer
argument_list|,
name|index
operator|+
literal|1
argument_list|)
decl_stmt|;
if|if
condition|(
name|nonRootIndexedKey
operator|!=
literal|null
condition|)
block|{
name|tmpNextIndexKV
operator|.
name|setKey
argument_list|(
name|nonRootIndexedKey
argument_list|,
literal|0
argument_list|,
name|nonRootIndexedKey
operator|.
name|length
argument_list|)
expr_stmt|;
name|nextIndexedKey
operator|=
name|tmpNextIndexKV
expr_stmt|;
block|}
block|}
finally|finally
block|{
if|if
condition|(
name|block
operator|!=
literal|null
operator|&&
operator|!
name|block
operator|.
name|getBlockType
argument_list|()
operator|.
name|isData
argument_list|()
condition|)
block|{
comment|// Release the block immediately if it is not the data block
name|block
operator|.
name|release
argument_list|()
expr_stmt|;
block|}
block|}
block|}
if|if
condition|(
name|lookupLevel
operator|!=
name|searchTreeLevel
condition|)
block|{
assert|assert
name|block
operator|.
name|getBlockType
argument_list|()
operator|.
name|isData
argument_list|()
assert|;
comment|// Though we have retrieved a data block we have found an issue
comment|// in the retrieved data block. Hence returned the block so that
comment|// the ref count can be decremented
if|if
condition|(
name|block
operator|!=
literal|null
condition|)
block|{
name|block
operator|.
name|release
argument_list|()
expr_stmt|;
block|}
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Reached a data block at level "
operator|+
name|lookupLevel
operator|+
literal|" but the number of levels is "
operator|+
name|searchTreeLevel
argument_list|)
throw|;
block|}
comment|// set the next indexed key for the current block.
return|return
operator|new
name|BlockWithScanInfo
argument_list|(
name|block
argument_list|,
name|nextIndexedKey
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|Cell
name|midkey
parameter_list|(
name|CachingBlockReader
name|cachingBlockReader
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|rootCount
operator|==
literal|0
condition|)
throw|throw
operator|new
name|IOException
argument_list|(
literal|"HFile empty"
argument_list|)
throw|;
name|Cell
name|targetMidKey
init|=
name|this
operator|.
name|midKey
operator|.
name|get
argument_list|()
decl_stmt|;
if|if
condition|(
name|targetMidKey
operator|!=
literal|null
condition|)
block|{
return|return
name|targetMidKey
return|;
block|}
if|if
condition|(
name|midLeafBlockOffset
operator|>=
literal|0
condition|)
block|{
if|if
condition|(
name|cachingBlockReader
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Have to read the middle leaf block but "
operator|+
literal|"no block reader available"
argument_list|)
throw|;
block|}
comment|// Caching, using pread, assuming this is not a compaction.
name|HFileBlock
name|midLeafBlock
init|=
name|cachingBlockReader
operator|.
name|readBlock
argument_list|(
name|midLeafBlockOffset
argument_list|,
name|midLeafBlockOnDiskSize
argument_list|,
literal|true
argument_list|,
literal|true
argument_list|,
literal|false
argument_list|,
literal|true
argument_list|,
name|BlockType
operator|.
name|LEAF_INDEX
argument_list|,
literal|null
argument_list|)
decl_stmt|;
try|try
block|{
name|ByteBuff
name|b
init|=
name|midLeafBlock
operator|.
name|getBufferWithoutHeader
argument_list|()
decl_stmt|;
name|int
name|numDataBlocks
init|=
name|b
operator|.
name|getIntAfterPosition
argument_list|(
literal|0
argument_list|)
decl_stmt|;
name|int
name|keyRelOffset
init|=
name|b
operator|.
name|getIntAfterPosition
argument_list|(
name|Bytes
operator|.
name|SIZEOF_INT
operator|*
operator|(
name|midKeyEntry
operator|+
literal|1
operator|)
argument_list|)
decl_stmt|;
name|int
name|keyLen
init|=
name|b
operator|.
name|getIntAfterPosition
argument_list|(
name|Bytes
operator|.
name|SIZEOF_INT
operator|*
operator|(
name|midKeyEntry
operator|+
literal|2
operator|)
argument_list|)
operator|-
name|keyRelOffset
operator|-
name|SECONDARY_INDEX_ENTRY_OVERHEAD
decl_stmt|;
name|int
name|keyOffset
init|=
name|Bytes
operator|.
name|SIZEOF_INT
operator|*
operator|(
name|numDataBlocks
operator|+
literal|2
operator|)
operator|+
name|keyRelOffset
operator|+
name|SECONDARY_INDEX_ENTRY_OVERHEAD
decl_stmt|;
name|byte
index|[]
name|bytes
init|=
name|b
operator|.
name|toBytes
argument_list|(
name|keyOffset
argument_list|,
name|keyLen
argument_list|)
decl_stmt|;
name|targetMidKey
operator|=
operator|new
name|KeyValue
operator|.
name|KeyOnlyKeyValue
argument_list|(
name|bytes
argument_list|,
literal|0
argument_list|,
name|bytes
operator|.
name|length
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|midLeafBlock
operator|.
name|release
argument_list|()
expr_stmt|;
block|}
block|}
else|else
block|{
comment|// The middle of the root-level index.
name|targetMidKey
operator|=
name|blockKeys
index|[
name|rootCount
operator|/
literal|2
index|]
expr_stmt|;
block|}
name|this
operator|.
name|midKey
operator|.
name|set
argument_list|(
name|targetMidKey
argument_list|)
expr_stmt|;
return|return
name|targetMidKey
return|;
block|}
annotation|@
name|Override
specifier|protected
name|void
name|initialize
parameter_list|(
name|int
name|numEntries
parameter_list|)
block|{
name|blockKeys
operator|=
operator|new
name|Cell
index|[
name|numEntries
index|]
expr_stmt|;
block|}
comment|/**      * Adds a new entry in the root block index. Only used when reading.      *      * @param key Last key in the block      * @param offset file offset where the block is stored      * @param dataSize the uncompressed data size      */
annotation|@
name|Override
specifier|protected
name|void
name|add
parameter_list|(
specifier|final
name|byte
index|[]
name|key
parameter_list|,
specifier|final
name|long
name|offset
parameter_list|,
specifier|final
name|int
name|dataSize
parameter_list|)
block|{
name|blockOffsets
index|[
name|rootCount
index|]
operator|=
name|offset
expr_stmt|;
comment|// Create the blockKeys as Cells once when the reader is opened
name|blockKeys
index|[
name|rootCount
index|]
operator|=
operator|new
name|KeyValue
operator|.
name|KeyOnlyKeyValue
argument_list|(
name|key
argument_list|,
literal|0
argument_list|,
name|key
operator|.
name|length
argument_list|)
expr_stmt|;
name|blockDataSizes
index|[
name|rootCount
index|]
operator|=
name|dataSize
expr_stmt|;
name|rootCount
operator|++
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|int
name|rootBlockContainingKey
parameter_list|(
specifier|final
name|byte
index|[]
name|key
parameter_list|,
name|int
name|offset
parameter_list|,
name|int
name|length
parameter_list|,
name|CellComparator
name|comp
parameter_list|)
block|{
comment|// This should always be called with Cell not with a byte[] key
throw|throw
operator|new
name|UnsupportedOperationException
argument_list|(
literal|"Cannot find for a key containing plain byte "
operator|+
literal|"array. Only cell based keys can be searched for"
argument_list|)
throw|;
block|}
annotation|@
name|Override
specifier|public
name|int
name|rootBlockContainingKey
parameter_list|(
name|Cell
name|key
parameter_list|)
block|{
comment|// Here the comparator should not be null as this happens for the root-level block
name|int
name|pos
init|=
name|Bytes
operator|.
name|binarySearch
argument_list|(
name|blockKeys
argument_list|,
name|key
argument_list|,
name|comparator
argument_list|)
decl_stmt|;
comment|// pos is between -(blockKeys.length + 1) to blockKeys.length - 1, see
comment|// binarySearch's javadoc.
if|if
condition|(
name|pos
operator|>=
literal|0
condition|)
block|{
comment|// This means this is an exact match with an element of blockKeys.
assert|assert
name|pos
operator|<
name|blockKeys
operator|.
name|length
assert|;
return|return
name|pos
return|;
block|}
comment|// Otherwise, pos = -(i + 1), where blockKeys[i - 1]< key< blockKeys[i],
comment|// and i is in [0, blockKeys.length]. We are returning j = i - 1 such that
comment|// blockKeys[j]<= key< blockKeys[j + 1]. In particular, j = -1 if
comment|// key< blockKeys[0], meaning the file does not contain the given key.
name|int
name|i
init|=
operator|-
name|pos
operator|-
literal|1
decl_stmt|;
assert|assert
literal|0
operator|<=
name|i
operator|&&
name|i
operator|<=
name|blockKeys
operator|.
name|length
assert|;
return|return
name|i
operator|-
literal|1
return|;
block|}
annotation|@
name|Override
specifier|public
name|String
name|toString
parameter_list|()
block|{
name|StringBuilder
name|sb
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
name|sb
operator|.
name|append
argument_list|(
literal|"size="
operator|+
name|rootCount
argument_list|)
operator|.
name|append
argument_list|(
literal|"\n"
argument_list|)
expr_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|rootCount
condition|;
name|i
operator|++
control|)
block|{
name|sb
operator|.
name|append
argument_list|(
literal|"key="
argument_list|)
operator|.
name|append
argument_list|(
operator|(
name|blockKeys
index|[
name|i
index|]
operator|)
argument_list|)
operator|.
name|append
argument_list|(
literal|"\n  offset="
argument_list|)
operator|.
name|append
argument_list|(
name|blockOffsets
index|[
name|i
index|]
argument_list|)
operator|.
name|append
argument_list|(
literal|", dataSize="
operator|+
name|blockDataSizes
index|[
name|i
index|]
argument_list|)
operator|.
name|append
argument_list|(
literal|"\n"
argument_list|)
expr_stmt|;
block|}
return|return
name|sb
operator|.
name|toString
argument_list|()
return|;
block|}
block|}
comment|/**    * The reader will always hold the root level index in the memory. Index    * blocks at all other levels will be cached in the LRU cache in practice,    * although this API does not enforce that.    *    *<p>All non-root (leaf and intermediate) index blocks contain what we call a    * "secondary index": an array of offsets to the entries within the block.    * This allows us to do binary search for the entry corresponding to the    * given key without having to deserialize the block.    */
specifier|static
specifier|abstract
class|class
name|BlockIndexReader
implements|implements
name|HeapSize
block|{
specifier|protected
name|long
index|[]
name|blockOffsets
decl_stmt|;
specifier|protected
name|int
index|[]
name|blockDataSizes
decl_stmt|;
specifier|protected
name|int
name|rootCount
init|=
literal|0
decl_stmt|;
comment|// Mid-key metadata.
specifier|protected
name|long
name|midLeafBlockOffset
init|=
operator|-
literal|1
decl_stmt|;
specifier|protected
name|int
name|midLeafBlockOnDiskSize
init|=
operator|-
literal|1
decl_stmt|;
specifier|protected
name|int
name|midKeyEntry
init|=
operator|-
literal|1
decl_stmt|;
comment|/**      * The number of levels in the block index tree. One if there is only root      * level, two for root and leaf levels, etc.      */
specifier|protected
name|int
name|searchTreeLevel
decl_stmt|;
comment|/**      * @return true if the block index is empty.      */
specifier|public
specifier|abstract
name|boolean
name|isEmpty
parameter_list|()
function_decl|;
comment|/**      * Verifies that the block index is non-empty and throws an      * {@link IllegalStateException} otherwise.      */
specifier|public
name|void
name|ensureNonEmpty
parameter_list|()
block|{
if|if
condition|(
name|isEmpty
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|IllegalStateException
argument_list|(
literal|"Block index is empty or not loaded"
argument_list|)
throw|;
block|}
block|}
comment|/**      * Return the data block which contains this key. This function will only      * be called when the HFile version is larger than 1.      *      * @param key the key we are looking for      * @param currentBlock the current block, to avoid re-reading the same block      * @param cacheBlocks      * @param pread      * @param isCompaction      * @param expectedDataBlockEncoding the data block encoding the caller is      *          expecting the data block to be in, or null to not perform this      *          check and return the block irrespective of the encoding      * @return reader a basic way to load blocks      * @throws IOException      */
specifier|public
name|HFileBlock
name|seekToDataBlock
parameter_list|(
specifier|final
name|Cell
name|key
parameter_list|,
name|HFileBlock
name|currentBlock
parameter_list|,
name|boolean
name|cacheBlocks
parameter_list|,
name|boolean
name|pread
parameter_list|,
name|boolean
name|isCompaction
parameter_list|,
name|DataBlockEncoding
name|expectedDataBlockEncoding
parameter_list|,
name|CachingBlockReader
name|cachingBlockReader
parameter_list|)
throws|throws
name|IOException
block|{
name|BlockWithScanInfo
name|blockWithScanInfo
init|=
name|loadDataBlockWithScanInfo
argument_list|(
name|key
argument_list|,
name|currentBlock
argument_list|,
name|cacheBlocks
argument_list|,
name|pread
argument_list|,
name|isCompaction
argument_list|,
name|expectedDataBlockEncoding
argument_list|,
name|cachingBlockReader
argument_list|)
decl_stmt|;
if|if
condition|(
name|blockWithScanInfo
operator|==
literal|null
condition|)
block|{
return|return
literal|null
return|;
block|}
else|else
block|{
return|return
name|blockWithScanInfo
operator|.
name|getHFileBlock
argument_list|()
return|;
block|}
block|}
comment|/**      * Return the BlockWithScanInfo, a data structure which contains the Data HFileBlock with      * other scan info such as the key that starts the next HFileBlock. This function will only      * be called when the HFile version is larger than 1.      *      * @param key the key we are looking for      * @param currentBlock the current block, to avoid re-reading the same block      * @param expectedDataBlockEncoding the data block encoding the caller is      *          expecting the data block to be in, or null to not perform this      *          check and return the block irrespective of the encoding.      * @return the BlockWithScanInfo which contains the DataBlock with other      *         scan info such as nextIndexedKey.      * @throws IOException      */
specifier|public
specifier|abstract
name|BlockWithScanInfo
name|loadDataBlockWithScanInfo
parameter_list|(
name|Cell
name|key
parameter_list|,
name|HFileBlock
name|currentBlock
parameter_list|,
name|boolean
name|cacheBlocks
parameter_list|,
name|boolean
name|pread
parameter_list|,
name|boolean
name|isCompaction
parameter_list|,
name|DataBlockEncoding
name|expectedDataBlockEncoding
parameter_list|,
name|CachingBlockReader
name|cachingBlockReader
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**      * An approximation to the {@link HFile}'s mid-key. Operates on block      * boundaries, and does not go inside blocks. In other words, returns the      * first key of the middle block of the file.      *      * @return the first key of the middle block      */
specifier|public
specifier|abstract
name|Cell
name|midkey
parameter_list|(
name|CachingBlockReader
name|cachingBlockReader
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**      * @param i from 0 to {@link #getRootBlockCount() - 1}      */
specifier|public
name|long
name|getRootBlockOffset
parameter_list|(
name|int
name|i
parameter_list|)
block|{
return|return
name|blockOffsets
index|[
name|i
index|]
return|;
block|}
comment|/**      * @param i zero-based index of a root-level block      * @return the on-disk size of the root-level block for version 2, or the      *         uncompressed size for version 1      */
specifier|public
name|int
name|getRootBlockDataSize
parameter_list|(
name|int
name|i
parameter_list|)
block|{
return|return
name|blockDataSizes
index|[
name|i
index|]
return|;
block|}
comment|/**      * @return the number of root-level blocks in this block index      */
specifier|public
name|int
name|getRootBlockCount
parameter_list|()
block|{
return|return
name|rootCount
return|;
block|}
comment|/**      * Finds the root-level index block containing the given key.      *      * @param key      *          Key to find      * @param comp      *          the comparator to be used      * @return Offset of block containing<code>key</code> (between 0 and the      *         number of blocks - 1) or -1 if this file does not contain the      *         request.      */
comment|// When we want to find the meta index block or bloom block for ROW bloom
comment|// type Bytes.BYTES_RAWCOMPARATOR would be enough. For the ROW_COL bloom case we need the
comment|// CellComparator.
specifier|public
specifier|abstract
name|int
name|rootBlockContainingKey
parameter_list|(
specifier|final
name|byte
index|[]
name|key
parameter_list|,
name|int
name|offset
parameter_list|,
name|int
name|length
parameter_list|,
name|CellComparator
name|comp
parameter_list|)
function_decl|;
comment|/**      * Finds the root-level index block containing the given key.      *      * @param key      *          Key to find      * @return Offset of block containing<code>key</code> (between 0 and the      *         number of blocks - 1) or -1 if this file does not contain the      *         request.      */
comment|// When we want to find the meta index block or bloom block for ROW bloom
comment|// type
comment|// Bytes.BYTES_RAWCOMPARATOR would be enough. For the ROW_COL bloom case we
comment|// need the CellComparator.
specifier|public
name|int
name|rootBlockContainingKey
parameter_list|(
specifier|final
name|byte
index|[]
name|key
parameter_list|,
name|int
name|offset
parameter_list|,
name|int
name|length
parameter_list|)
block|{
return|return
name|rootBlockContainingKey
argument_list|(
name|key
argument_list|,
name|offset
argument_list|,
name|length
argument_list|,
literal|null
argument_list|)
return|;
block|}
comment|/**      * Finds the root-level index block containing the given key.      *      * @param key      *          Key to find      */
specifier|public
specifier|abstract
name|int
name|rootBlockContainingKey
parameter_list|(
specifier|final
name|Cell
name|key
parameter_list|)
function_decl|;
comment|/**      * The indexed key at the ith position in the nonRootIndex. The position starts at 0.      * @param nonRootIndex      * @param i the ith position      * @return The indexed key at the ith position in the nonRootIndex.      */
specifier|protected
name|byte
index|[]
name|getNonRootIndexedKey
parameter_list|(
name|ByteBuff
name|nonRootIndex
parameter_list|,
name|int
name|i
parameter_list|)
block|{
name|int
name|numEntries
init|=
name|nonRootIndex
operator|.
name|getInt
argument_list|(
literal|0
argument_list|)
decl_stmt|;
if|if
condition|(
name|i
operator|<
literal|0
operator|||
name|i
operator|>=
name|numEntries
condition|)
block|{
return|return
literal|null
return|;
block|}
comment|// Entries start after the number of entries and the secondary index.
comment|// The secondary index takes numEntries + 1 ints.
name|int
name|entriesOffset
init|=
name|Bytes
operator|.
name|SIZEOF_INT
operator|*
operator|(
name|numEntries
operator|+
literal|2
operator|)
decl_stmt|;
comment|// Targetkey's offset relative to the end of secondary index
name|int
name|targetKeyRelOffset
init|=
name|nonRootIndex
operator|.
name|getInt
argument_list|(
name|Bytes
operator|.
name|SIZEOF_INT
operator|*
operator|(
name|i
operator|+
literal|1
operator|)
argument_list|)
decl_stmt|;
comment|// The offset of the target key in the blockIndex buffer
name|int
name|targetKeyOffset
init|=
name|entriesOffset
comment|// Skip secondary index
operator|+
name|targetKeyRelOffset
comment|// Skip all entries until mid
operator|+
name|SECONDARY_INDEX_ENTRY_OVERHEAD
decl_stmt|;
comment|// Skip offset and on-disk-size
comment|// We subtract the two consecutive secondary index elements, which
comment|// gives us the size of the whole (offset, onDiskSize, key) tuple. We
comment|// then need to subtract the overhead of offset and onDiskSize.
name|int
name|targetKeyLength
init|=
name|nonRootIndex
operator|.
name|getInt
argument_list|(
name|Bytes
operator|.
name|SIZEOF_INT
operator|*
operator|(
name|i
operator|+
literal|2
operator|)
argument_list|)
operator|-
name|targetKeyRelOffset
operator|-
name|SECONDARY_INDEX_ENTRY_OVERHEAD
decl_stmt|;
comment|// TODO check whether we can make BB backed Cell here? So can avoid bytes copy.
return|return
name|nonRootIndex
operator|.
name|toBytes
argument_list|(
name|targetKeyOffset
argument_list|,
name|targetKeyLength
argument_list|)
return|;
block|}
comment|/**      * Performs a binary search over a non-root level index block. Utilizes the      * secondary index, which records the offsets of (offset, onDiskSize,      * firstKey) tuples of all entries.      *      * @param key      *          the key we are searching for offsets to individual entries in      *          the blockIndex buffer      * @param nonRootIndex      *          the non-root index block buffer, starting with the secondary      *          index. The position is ignored.      * @return the index i in [0, numEntries - 1] such that keys[i]<= key<      *         keys[i + 1], if keys is the array of all keys being searched, or      *         -1 otherwise      * @throws IOException      */
specifier|static
name|int
name|binarySearchNonRootIndex
parameter_list|(
name|Cell
name|key
parameter_list|,
name|ByteBuff
name|nonRootIndex
parameter_list|,
name|CellComparator
name|comparator
parameter_list|)
block|{
name|int
name|numEntries
init|=
name|nonRootIndex
operator|.
name|getIntAfterPosition
argument_list|(
literal|0
argument_list|)
decl_stmt|;
name|int
name|low
init|=
literal|0
decl_stmt|;
name|int
name|high
init|=
name|numEntries
operator|-
literal|1
decl_stmt|;
name|int
name|mid
init|=
literal|0
decl_stmt|;
comment|// Entries start after the number of entries and the secondary index.
comment|// The secondary index takes numEntries + 1 ints.
name|int
name|entriesOffset
init|=
name|Bytes
operator|.
name|SIZEOF_INT
operator|*
operator|(
name|numEntries
operator|+
literal|2
operator|)
decl_stmt|;
comment|// If we imagine that keys[-1] = -Infinity and
comment|// keys[numEntries] = Infinity, then we are maintaining an invariant that
comment|// keys[low - 1]< key< keys[high + 1] while narrowing down the range.
name|ByteBufferKeyOnlyKeyValue
name|nonRootIndexkeyOnlyKV
init|=
operator|new
name|ByteBufferKeyOnlyKeyValue
argument_list|()
decl_stmt|;
name|ObjectIntPair
argument_list|<
name|ByteBuffer
argument_list|>
name|pair
init|=
operator|new
name|ObjectIntPair
argument_list|<>
argument_list|()
decl_stmt|;
while|while
condition|(
name|low
operator|<=
name|high
condition|)
block|{
name|mid
operator|=
name|low
operator|+
operator|(
operator|(
name|high
operator|-
name|low
operator|)
operator|>>
literal|1
operator|)
expr_stmt|;
comment|// Midkey's offset relative to the end of secondary index
name|int
name|midKeyRelOffset
init|=
name|nonRootIndex
operator|.
name|getIntAfterPosition
argument_list|(
name|Bytes
operator|.
name|SIZEOF_INT
operator|*
operator|(
name|mid
operator|+
literal|1
operator|)
argument_list|)
decl_stmt|;
comment|// The offset of the middle key in the blockIndex buffer
name|int
name|midKeyOffset
init|=
name|entriesOffset
comment|// Skip secondary index
operator|+
name|midKeyRelOffset
comment|// Skip all entries until mid
operator|+
name|SECONDARY_INDEX_ENTRY_OVERHEAD
decl_stmt|;
comment|// Skip offset and on-disk-size
comment|// We subtract the two consecutive secondary index elements, which
comment|// gives us the size of the whole (offset, onDiskSize, key) tuple. We
comment|// then need to subtract the overhead of offset and onDiskSize.
name|int
name|midLength
init|=
name|nonRootIndex
operator|.
name|getIntAfterPosition
argument_list|(
name|Bytes
operator|.
name|SIZEOF_INT
operator|*
operator|(
name|mid
operator|+
literal|2
operator|)
argument_list|)
operator|-
name|midKeyRelOffset
operator|-
name|SECONDARY_INDEX_ENTRY_OVERHEAD
decl_stmt|;
comment|// we have to compare in this order, because the comparator order
comment|// has special logic when the 'left side' is a special key.
comment|// TODO make KeyOnlyKeyValue to be Buffer backed and avoid array() call. This has to be
comment|// done after HBASE-12224& HBASE-12282
comment|// TODO avoid array call.
name|nonRootIndex
operator|.
name|asSubByteBuffer
argument_list|(
name|midKeyOffset
argument_list|,
name|midLength
argument_list|,
name|pair
argument_list|)
expr_stmt|;
name|nonRootIndexkeyOnlyKV
operator|.
name|setKey
argument_list|(
name|pair
operator|.
name|getFirst
argument_list|()
argument_list|,
name|pair
operator|.
name|getSecond
argument_list|()
argument_list|,
name|midLength
argument_list|)
expr_stmt|;
name|int
name|cmp
init|=
name|PrivateCellUtil
operator|.
name|compareKeyIgnoresMvcc
argument_list|(
name|comparator
argument_list|,
name|key
argument_list|,
name|nonRootIndexkeyOnlyKV
argument_list|)
decl_stmt|;
comment|// key lives above the midpoint
if|if
condition|(
name|cmp
operator|>
literal|0
condition|)
name|low
operator|=
name|mid
operator|+
literal|1
expr_stmt|;
comment|// Maintain the invariant that keys[low - 1]< key
comment|// key lives below the midpoint
elseif|else
if|if
condition|(
name|cmp
operator|<
literal|0
condition|)
name|high
operator|=
name|mid
operator|-
literal|1
expr_stmt|;
comment|// Maintain the invariant that key< keys[high + 1]
else|else
return|return
name|mid
return|;
comment|// exact match
block|}
comment|// As per our invariant, keys[low - 1]< key< keys[high + 1], meaning
comment|// that low - 1< high + 1 and (low - high)<= 1. As per the loop break
comment|// condition, low>= high + 1. Therefore, low = high + 1.
if|if
condition|(
name|low
operator|!=
name|high
operator|+
literal|1
condition|)
block|{
throw|throw
operator|new
name|IllegalStateException
argument_list|(
literal|"Binary search broken: low="
operator|+
name|low
operator|+
literal|" "
operator|+
literal|"instead of "
operator|+
operator|(
name|high
operator|+
literal|1
operator|)
argument_list|)
throw|;
block|}
comment|// OK, our invariant says that keys[low - 1]< key< keys[low]. We need to
comment|// return i such that keys[i]<= key< keys[i + 1]. Therefore i = low - 1.
name|int
name|i
init|=
name|low
operator|-
literal|1
decl_stmt|;
comment|// Some extra validation on the result.
if|if
condition|(
name|i
operator|<
operator|-
literal|1
operator|||
name|i
operator|>=
name|numEntries
condition|)
block|{
throw|throw
operator|new
name|IllegalStateException
argument_list|(
literal|"Binary search broken: result is "
operator|+
name|i
operator|+
literal|" but expected to be between -1 and (numEntries - 1) = "
operator|+
operator|(
name|numEntries
operator|-
literal|1
operator|)
argument_list|)
throw|;
block|}
return|return
name|i
return|;
block|}
comment|/**      * Search for one key using the secondary index in a non-root block. In case      * of success, positions the provided buffer at the entry of interest, where      * the file offset and the on-disk-size can be read.      *      * @param nonRootBlock      *          a non-root block without header. Initial position does not      *          matter.      * @param key      *          the byte array containing the key      * @return the index position where the given key was found, otherwise      *         return -1 in the case the given key is before the first key.      *      */
specifier|static
name|int
name|locateNonRootIndexEntry
parameter_list|(
name|ByteBuff
name|nonRootBlock
parameter_list|,
name|Cell
name|key
parameter_list|,
name|CellComparator
name|comparator
parameter_list|)
block|{
name|int
name|entryIndex
init|=
name|binarySearchNonRootIndex
argument_list|(
name|key
argument_list|,
name|nonRootBlock
argument_list|,
name|comparator
argument_list|)
decl_stmt|;
if|if
condition|(
name|entryIndex
operator|!=
operator|-
literal|1
condition|)
block|{
name|int
name|numEntries
init|=
name|nonRootBlock
operator|.
name|getIntAfterPosition
argument_list|(
literal|0
argument_list|)
decl_stmt|;
comment|// The end of secondary index and the beginning of entries themselves.
name|int
name|entriesOffset
init|=
name|Bytes
operator|.
name|SIZEOF_INT
operator|*
operator|(
name|numEntries
operator|+
literal|2
operator|)
decl_stmt|;
comment|// The offset of the entry we are interested in relative to the end of
comment|// the secondary index.
name|int
name|entryRelOffset
init|=
name|nonRootBlock
operator|.
name|getIntAfterPosition
argument_list|(
name|Bytes
operator|.
name|SIZEOF_INT
operator|*
operator|(
literal|1
operator|+
name|entryIndex
operator|)
argument_list|)
decl_stmt|;
name|nonRootBlock
operator|.
name|position
argument_list|(
name|entriesOffset
operator|+
name|entryRelOffset
argument_list|)
expr_stmt|;
block|}
return|return
name|entryIndex
return|;
block|}
comment|/**      * Read in the root-level index from the given input stream. Must match      * what was written into the root level by      * {@link BlockIndexWriter#writeIndexBlocks(FSDataOutputStream)} at the      * offset that function returned.      *      * @param in the buffered input stream or wrapped byte input stream      * @param numEntries the number of root-level index entries      * @throws IOException      */
specifier|public
name|void
name|readRootIndex
parameter_list|(
name|DataInput
name|in
parameter_list|,
specifier|final
name|int
name|numEntries
parameter_list|)
throws|throws
name|IOException
block|{
name|blockOffsets
operator|=
operator|new
name|long
index|[
name|numEntries
index|]
expr_stmt|;
name|initialize
argument_list|(
name|numEntries
argument_list|)
expr_stmt|;
name|blockDataSizes
operator|=
operator|new
name|int
index|[
name|numEntries
index|]
expr_stmt|;
comment|// If index size is zero, no index was written.
if|if
condition|(
name|numEntries
operator|>
literal|0
condition|)
block|{
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|numEntries
condition|;
operator|++
name|i
control|)
block|{
name|long
name|offset
init|=
name|in
operator|.
name|readLong
argument_list|()
decl_stmt|;
name|int
name|dataSize
init|=
name|in
operator|.
name|readInt
argument_list|()
decl_stmt|;
name|byte
index|[]
name|key
init|=
name|Bytes
operator|.
name|readByteArray
argument_list|(
name|in
argument_list|)
decl_stmt|;
name|add
argument_list|(
name|key
argument_list|,
name|offset
argument_list|,
name|dataSize
argument_list|)
expr_stmt|;
block|}
block|}
block|}
specifier|protected
specifier|abstract
name|void
name|initialize
parameter_list|(
name|int
name|numEntries
parameter_list|)
function_decl|;
specifier|protected
specifier|abstract
name|void
name|add
parameter_list|(
specifier|final
name|byte
index|[]
name|key
parameter_list|,
specifier|final
name|long
name|offset
parameter_list|,
specifier|final
name|int
name|dataSize
parameter_list|)
function_decl|;
comment|/**      * Read in the root-level index from the given input stream. Must match      * what was written into the root level by      * {@link BlockIndexWriter#writeIndexBlocks(FSDataOutputStream)} at the      * offset that function returned.      *      * @param blk the HFile block      * @param numEntries the number of root-level index entries      * @return the buffered input stream or wrapped byte input stream      * @throws IOException      */
specifier|public
name|DataInputStream
name|readRootIndex
parameter_list|(
name|HFileBlock
name|blk
parameter_list|,
specifier|final
name|int
name|numEntries
parameter_list|)
throws|throws
name|IOException
block|{
name|DataInputStream
name|in
init|=
name|blk
operator|.
name|getByteStream
argument_list|()
decl_stmt|;
name|readRootIndex
argument_list|(
name|in
argument_list|,
name|numEntries
argument_list|)
expr_stmt|;
return|return
name|in
return|;
block|}
comment|/**      * Read the root-level metadata of a multi-level block index. Based on      * {@link #readRootIndex(DataInput, int)}, but also reads metadata      * necessary to compute the mid-key in a multi-level index.      *      * @param blk the HFile block      * @param numEntries the number of root-level index entries      * @throws IOException      */
specifier|public
name|void
name|readMultiLevelIndexRoot
parameter_list|(
name|HFileBlock
name|blk
parameter_list|,
specifier|final
name|int
name|numEntries
parameter_list|)
throws|throws
name|IOException
block|{
name|DataInputStream
name|in
init|=
name|readRootIndex
argument_list|(
name|blk
argument_list|,
name|numEntries
argument_list|)
decl_stmt|;
comment|// after reading the root index the checksum bytes have to
comment|// be subtracted to know if the mid key exists.
name|int
name|checkSumBytes
init|=
name|blk
operator|.
name|totalChecksumBytes
argument_list|()
decl_stmt|;
if|if
condition|(
operator|(
name|in
operator|.
name|available
argument_list|()
operator|-
name|checkSumBytes
operator|)
operator|<
name|MID_KEY_METADATA_SIZE
condition|)
block|{
comment|// No mid-key metadata available.
return|return;
block|}
name|midLeafBlockOffset
operator|=
name|in
operator|.
name|readLong
argument_list|()
expr_stmt|;
name|midLeafBlockOnDiskSize
operator|=
name|in
operator|.
name|readInt
argument_list|()
expr_stmt|;
name|midKeyEntry
operator|=
name|in
operator|.
name|readInt
argument_list|()
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|heapSize
parameter_list|()
block|{
comment|// The BlockIndexReader does not have the blockKey, comparator and the midkey atomic reference
name|long
name|heapSize
init|=
name|ClassSize
operator|.
name|align
argument_list|(
literal|3
operator|*
name|ClassSize
operator|.
name|REFERENCE
operator|+
literal|2
operator|*
name|Bytes
operator|.
name|SIZEOF_INT
operator|+
name|ClassSize
operator|.
name|OBJECT
argument_list|)
decl_stmt|;
comment|// Mid-key metadata.
name|heapSize
operator|+=
name|MID_KEY_METADATA_SIZE
expr_stmt|;
name|heapSize
operator|=
name|calculateHeapSizeForBlockKeys
argument_list|(
name|heapSize
argument_list|)
expr_stmt|;
if|if
condition|(
name|blockOffsets
operator|!=
literal|null
condition|)
block|{
name|heapSize
operator|+=
name|ClassSize
operator|.
name|align
argument_list|(
name|ClassSize
operator|.
name|ARRAY
operator|+
name|blockOffsets
operator|.
name|length
operator|*
name|Bytes
operator|.
name|SIZEOF_LONG
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|blockDataSizes
operator|!=
literal|null
condition|)
block|{
name|heapSize
operator|+=
name|ClassSize
operator|.
name|align
argument_list|(
name|ClassSize
operator|.
name|ARRAY
operator|+
name|blockDataSizes
operator|.
name|length
operator|*
name|Bytes
operator|.
name|SIZEOF_INT
argument_list|)
expr_stmt|;
block|}
return|return
name|ClassSize
operator|.
name|align
argument_list|(
name|heapSize
argument_list|)
return|;
block|}
specifier|protected
specifier|abstract
name|long
name|calculateHeapSizeForBlockKeys
parameter_list|(
name|long
name|heapSize
parameter_list|)
function_decl|;
block|}
comment|/**    * Writes the block index into the output stream. Generate the tree from    * bottom up. The leaf level is written to disk as a sequence of inline    * blocks, if it is larger than a certain number of bytes. If the leaf level    * is not large enough, we write all entries to the root level instead.    *    * After all leaf blocks have been written, we end up with an index    * referencing the resulting leaf index blocks. If that index is larger than    * the allowed root index size, the writer will break it up into    * reasonable-size intermediate-level index block chunks write those chunks    * out, and create another index referencing those chunks. This will be    * repeated until the remaining index is small enough to become the root    * index. However, in most practical cases we will only have leaf-level    * blocks and the root index, or just the root index.    */
specifier|public
specifier|static
class|class
name|BlockIndexWriter
implements|implements
name|InlineBlockWriter
block|{
comment|/**      * While the index is being written, this represents the current block      * index referencing all leaf blocks, with one exception. If the file is      * being closed and there are not enough blocks to complete even a single      * leaf block, no leaf blocks get written and this contains the entire      * block index. After all levels of the index were written by      * {@link #writeIndexBlocks(FSDataOutputStream)}, this contains the final      * root-level index.      */
specifier|private
name|BlockIndexChunk
name|rootChunk
init|=
operator|new
name|BlockIndexChunk
argument_list|()
decl_stmt|;
comment|/**      * Current leaf-level chunk. New entries referencing data blocks get added      * to this chunk until it grows large enough to be written to disk.      */
specifier|private
name|BlockIndexChunk
name|curInlineChunk
init|=
operator|new
name|BlockIndexChunk
argument_list|()
decl_stmt|;
comment|/**      * The number of block index levels. This is one if there is only root      * level (even empty), two if there a leaf level and root level, and is      * higher if there are intermediate levels. This is only final after      * {@link #writeIndexBlocks(FSDataOutputStream)} has been called. The      * initial value accounts for the root level, and will be increased to two      * as soon as we find out there is a leaf-level in      * {@link #blockWritten(long, int, int)}.      */
specifier|private
name|int
name|numLevels
init|=
literal|1
decl_stmt|;
specifier|private
name|HFileBlock
operator|.
name|Writer
name|blockWriter
decl_stmt|;
specifier|private
name|byte
index|[]
name|firstKey
init|=
literal|null
decl_stmt|;
comment|/**      * The total number of leaf-level entries, i.e. entries referenced by      * leaf-level blocks. For the data block index this is equal to the number      * of data blocks.      */
specifier|private
name|long
name|totalNumEntries
decl_stmt|;
comment|/** Total compressed size of all index blocks. */
specifier|private
name|long
name|totalBlockOnDiskSize
decl_stmt|;
comment|/** Total uncompressed size of all index blocks. */
specifier|private
name|long
name|totalBlockUncompressedSize
decl_stmt|;
comment|/** The maximum size guideline of all multi-level index blocks. */
specifier|private
name|int
name|maxChunkSize
decl_stmt|;
comment|/** The maximum level of multi-level index blocks */
specifier|private
name|int
name|minIndexNumEntries
decl_stmt|;
comment|/** Whether we require this block index to always be single-level. */
specifier|private
name|boolean
name|singleLevelOnly
decl_stmt|;
comment|/** CacheConfig, or null if cache-on-write is disabled */
specifier|private
name|CacheConfig
name|cacheConf
decl_stmt|;
comment|/** Name to use for computing cache keys */
specifier|private
name|String
name|nameForCaching
decl_stmt|;
comment|/** Creates a single-level block index writer */
specifier|public
name|BlockIndexWriter
parameter_list|()
block|{
name|this
argument_list|(
literal|null
argument_list|,
literal|null
argument_list|,
literal|null
argument_list|)
expr_stmt|;
name|singleLevelOnly
operator|=
literal|true
expr_stmt|;
block|}
comment|/**      * Creates a multi-level block index writer.      *      * @param blockWriter the block writer to use to write index blocks      * @param cacheConf used to determine when and how a block should be cached-on-write.      */
specifier|public
name|BlockIndexWriter
parameter_list|(
name|HFileBlock
operator|.
name|Writer
name|blockWriter
parameter_list|,
name|CacheConfig
name|cacheConf
parameter_list|,
name|String
name|nameForCaching
parameter_list|)
block|{
if|if
condition|(
operator|(
name|cacheConf
operator|==
literal|null
operator|)
operator|!=
operator|(
name|nameForCaching
operator|==
literal|null
operator|)
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"Block cache and file name for "
operator|+
literal|"caching must be both specified or both null"
argument_list|)
throw|;
block|}
name|this
operator|.
name|blockWriter
operator|=
name|blockWriter
expr_stmt|;
name|this
operator|.
name|cacheConf
operator|=
name|cacheConf
expr_stmt|;
name|this
operator|.
name|nameForCaching
operator|=
name|nameForCaching
expr_stmt|;
name|this
operator|.
name|maxChunkSize
operator|=
name|HFileBlockIndex
operator|.
name|DEFAULT_MAX_CHUNK_SIZE
expr_stmt|;
name|this
operator|.
name|minIndexNumEntries
operator|=
name|HFileBlockIndex
operator|.
name|DEFAULT_MIN_INDEX_NUM_ENTRIES
expr_stmt|;
block|}
specifier|public
name|void
name|setMaxChunkSize
parameter_list|(
name|int
name|maxChunkSize
parameter_list|)
block|{
if|if
condition|(
name|maxChunkSize
operator|<=
literal|0
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"Invalid maximum index block size"
argument_list|)
throw|;
block|}
name|this
operator|.
name|maxChunkSize
operator|=
name|maxChunkSize
expr_stmt|;
block|}
specifier|public
name|void
name|setMinIndexNumEntries
parameter_list|(
name|int
name|minIndexNumEntries
parameter_list|)
block|{
if|if
condition|(
name|minIndexNumEntries
operator|<=
literal|1
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"Invalid maximum index level, should be>= 2"
argument_list|)
throw|;
block|}
name|this
operator|.
name|minIndexNumEntries
operator|=
name|minIndexNumEntries
expr_stmt|;
block|}
comment|/**      * Writes the root level and intermediate levels of the block index into      * the output stream, generating the tree from bottom up. Assumes that the      * leaf level has been inline-written to the disk if there is enough data      * for more than one leaf block. We iterate by breaking the current level      * of the block index, starting with the index of all leaf-level blocks,      * into chunks small enough to be written to disk, and generate its parent      * level, until we end up with a level small enough to become the root      * level.      *      * If the leaf level is not large enough, there is no inline block index      * anymore, so we only write that level of block index to disk as the root      * level.      *      * @param out FSDataOutputStream      * @return position at which we entered the root-level index.      * @throws IOException      */
specifier|public
name|long
name|writeIndexBlocks
parameter_list|(
name|FSDataOutputStream
name|out
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|curInlineChunk
operator|!=
literal|null
operator|&&
name|curInlineChunk
operator|.
name|getNumEntries
argument_list|()
operator|!=
literal|0
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Trying to write a multi-level block index, "
operator|+
literal|"but are "
operator|+
name|curInlineChunk
operator|.
name|getNumEntries
argument_list|()
operator|+
literal|" entries in the "
operator|+
literal|"last inline chunk."
argument_list|)
throw|;
block|}
comment|// We need to get mid-key metadata before we create intermediate
comment|// indexes and overwrite the root chunk.
name|byte
index|[]
name|midKeyMetadata
init|=
name|numLevels
operator|>
literal|1
condition|?
name|rootChunk
operator|.
name|getMidKeyMetadata
argument_list|()
else|:
literal|null
decl_stmt|;
if|if
condition|(
name|curInlineChunk
operator|!=
literal|null
condition|)
block|{
while|while
condition|(
name|rootChunk
operator|.
name|getRootSize
argument_list|()
operator|>
name|maxChunkSize
comment|// HBASE-16288: if firstKey is larger than maxChunkSize we will loop indefinitely
operator|&&
name|rootChunk
operator|.
name|getNumEntries
argument_list|()
operator|>
name|minIndexNumEntries
comment|// Sanity check. We will not hit this (minIndexNumEntries ^ 16) blocks can be addressed
operator|&&
name|numLevels
operator|<
literal|16
condition|)
block|{
name|rootChunk
operator|=
name|writeIntermediateLevel
argument_list|(
name|out
argument_list|,
name|rootChunk
argument_list|)
expr_stmt|;
name|numLevels
operator|+=
literal|1
expr_stmt|;
block|}
block|}
comment|// write the root level
name|long
name|rootLevelIndexPos
init|=
name|out
operator|.
name|getPos
argument_list|()
decl_stmt|;
block|{
name|DataOutput
name|blockStream
init|=
name|blockWriter
operator|.
name|startWriting
argument_list|(
name|BlockType
operator|.
name|ROOT_INDEX
argument_list|)
decl_stmt|;
name|rootChunk
operator|.
name|writeRoot
argument_list|(
name|blockStream
argument_list|)
expr_stmt|;
if|if
condition|(
name|midKeyMetadata
operator|!=
literal|null
condition|)
name|blockStream
operator|.
name|write
argument_list|(
name|midKeyMetadata
argument_list|)
expr_stmt|;
name|blockWriter
operator|.
name|writeHeaderAndData
argument_list|(
name|out
argument_list|)
expr_stmt|;
if|if
condition|(
name|cacheConf
operator|!=
literal|null
condition|)
block|{
name|cacheConf
operator|.
name|getBlockCache
argument_list|()
operator|.
name|ifPresent
argument_list|(
name|cache
lambda|->
block|{
name|HFileBlock
name|blockForCaching
init|=
name|blockWriter
operator|.
name|getBlockForCaching
argument_list|(
name|cacheConf
argument_list|)
decl_stmt|;
name|cache
operator|.
name|cacheBlock
argument_list|(
operator|new
name|BlockCacheKey
argument_list|(
name|nameForCaching
argument_list|,
name|rootLevelIndexPos
argument_list|,
literal|true
argument_list|,
name|blockForCaching
operator|.
name|getBlockType
argument_list|()
argument_list|)
argument_list|,
name|blockForCaching
argument_list|)
expr_stmt|;
block|}
argument_list|)
expr_stmt|;
block|}
block|}
comment|// Add root index block size
name|totalBlockOnDiskSize
operator|+=
name|blockWriter
operator|.
name|getOnDiskSizeWithoutHeader
argument_list|()
expr_stmt|;
name|totalBlockUncompressedSize
operator|+=
name|blockWriter
operator|.
name|getUncompressedSizeWithoutHeader
argument_list|()
expr_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|trace
argument_list|(
literal|"Wrote a "
operator|+
name|numLevels
operator|+
literal|"-level index with root level at pos "
operator|+
name|rootLevelIndexPos
operator|+
literal|", "
operator|+
name|rootChunk
operator|.
name|getNumEntries
argument_list|()
operator|+
literal|" root-level entries, "
operator|+
name|totalNumEntries
operator|+
literal|" total entries, "
operator|+
name|StringUtils
operator|.
name|humanReadableInt
argument_list|(
name|this
operator|.
name|totalBlockOnDiskSize
argument_list|)
operator|+
literal|" on-disk size, "
operator|+
name|StringUtils
operator|.
name|humanReadableInt
argument_list|(
name|totalBlockUncompressedSize
argument_list|)
operator|+
literal|" total uncompressed size."
argument_list|)
expr_stmt|;
block|}
return|return
name|rootLevelIndexPos
return|;
block|}
comment|/**      * Writes the block index data as a single level only. Does not do any      * block framing.      *      * @param out the buffered output stream to write the index to. Typically a      *          stream writing into an {@link HFile} block.      * @param description a short description of the index being written. Used      *          in a log message.      * @throws IOException      */
specifier|public
name|void
name|writeSingleLevelIndex
parameter_list|(
name|DataOutput
name|out
parameter_list|,
name|String
name|description
parameter_list|)
throws|throws
name|IOException
block|{
name|expectNumLevels
argument_list|(
literal|1
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|singleLevelOnly
condition|)
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Single-level mode is turned off"
argument_list|)
throw|;
if|if
condition|(
name|rootChunk
operator|.
name|getNumEntries
argument_list|()
operator|>
literal|0
condition|)
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Root-level entries already added in "
operator|+
literal|"single-level mode"
argument_list|)
throw|;
name|rootChunk
operator|=
name|curInlineChunk
expr_stmt|;
name|curInlineChunk
operator|=
operator|new
name|BlockIndexChunk
argument_list|()
expr_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|trace
argument_list|(
literal|"Wrote a single-level "
operator|+
name|description
operator|+
literal|" index with "
operator|+
name|rootChunk
operator|.
name|getNumEntries
argument_list|()
operator|+
literal|" entries, "
operator|+
name|rootChunk
operator|.
name|getRootSize
argument_list|()
operator|+
literal|" bytes"
argument_list|)
expr_stmt|;
block|}
name|rootChunk
operator|.
name|writeRoot
argument_list|(
name|out
argument_list|)
expr_stmt|;
block|}
comment|/**      * Split the current level of the block index into intermediate index      * blocks of permitted size and write those blocks to disk. Return the next      * level of the block index referencing those intermediate-level blocks.      *      * @param out      * @param currentLevel the current level of the block index, such as the a      *          chunk referencing all leaf-level index blocks      * @return the parent level block index, which becomes the root index after      *         a few (usually zero) iterations      * @throws IOException      */
specifier|private
name|BlockIndexChunk
name|writeIntermediateLevel
parameter_list|(
name|FSDataOutputStream
name|out
parameter_list|,
name|BlockIndexChunk
name|currentLevel
parameter_list|)
throws|throws
name|IOException
block|{
comment|// Entries referencing intermediate-level blocks we are about to create.
name|BlockIndexChunk
name|parent
init|=
operator|new
name|BlockIndexChunk
argument_list|()
decl_stmt|;
comment|// The current intermediate-level block index chunk.
name|BlockIndexChunk
name|curChunk
init|=
operator|new
name|BlockIndexChunk
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|currentLevel
operator|.
name|getNumEntries
argument_list|()
condition|;
operator|++
name|i
control|)
block|{
name|curChunk
operator|.
name|add
argument_list|(
name|currentLevel
operator|.
name|getBlockKey
argument_list|(
name|i
argument_list|)
argument_list|,
name|currentLevel
operator|.
name|getBlockOffset
argument_list|(
name|i
argument_list|)
argument_list|,
name|currentLevel
operator|.
name|getOnDiskDataSize
argument_list|(
name|i
argument_list|)
argument_list|)
expr_stmt|;
comment|// HBASE-16288: We have to have at least minIndexNumEntries(16) items in the index so that
comment|// we won't end up with too-many levels for a index with very large rowKeys. Also, if the
comment|// first key is larger than maxChunkSize this will cause infinite recursion.
if|if
condition|(
name|i
operator|>=
name|minIndexNumEntries
operator|&&
name|curChunk
operator|.
name|getRootSize
argument_list|()
operator|>=
name|maxChunkSize
condition|)
block|{
name|writeIntermediateBlock
argument_list|(
name|out
argument_list|,
name|parent
argument_list|,
name|curChunk
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|curChunk
operator|.
name|getNumEntries
argument_list|()
operator|>
literal|0
condition|)
block|{
name|writeIntermediateBlock
argument_list|(
name|out
argument_list|,
name|parent
argument_list|,
name|curChunk
argument_list|)
expr_stmt|;
block|}
return|return
name|parent
return|;
block|}
specifier|private
name|void
name|writeIntermediateBlock
parameter_list|(
name|FSDataOutputStream
name|out
parameter_list|,
name|BlockIndexChunk
name|parent
parameter_list|,
name|BlockIndexChunk
name|curChunk
parameter_list|)
throws|throws
name|IOException
block|{
name|long
name|beginOffset
init|=
name|out
operator|.
name|getPos
argument_list|()
decl_stmt|;
name|DataOutputStream
name|dos
init|=
name|blockWriter
operator|.
name|startWriting
argument_list|(
name|BlockType
operator|.
name|INTERMEDIATE_INDEX
argument_list|)
decl_stmt|;
name|curChunk
operator|.
name|writeNonRoot
argument_list|(
name|dos
argument_list|)
expr_stmt|;
name|byte
index|[]
name|curFirstKey
init|=
name|curChunk
operator|.
name|getBlockKey
argument_list|(
literal|0
argument_list|)
decl_stmt|;
name|blockWriter
operator|.
name|writeHeaderAndData
argument_list|(
name|out
argument_list|)
expr_stmt|;
if|if
condition|(
name|getCacheOnWrite
argument_list|()
condition|)
block|{
name|cacheConf
operator|.
name|getBlockCache
argument_list|()
operator|.
name|ifPresent
argument_list|(
name|cache
lambda|->
block|{
name|HFileBlock
name|blockForCaching
init|=
name|blockWriter
operator|.
name|getBlockForCaching
argument_list|(
name|cacheConf
argument_list|)
decl_stmt|;
name|cache
operator|.
name|cacheBlock
argument_list|(
operator|new
name|BlockCacheKey
argument_list|(
name|nameForCaching
argument_list|,
name|beginOffset
argument_list|,
literal|true
argument_list|,
name|blockForCaching
operator|.
name|getBlockType
argument_list|()
argument_list|)
argument_list|,
name|blockForCaching
argument_list|)
expr_stmt|;
block|}
argument_list|)
expr_stmt|;
block|}
comment|// Add intermediate index block size
name|totalBlockOnDiskSize
operator|+=
name|blockWriter
operator|.
name|getOnDiskSizeWithoutHeader
argument_list|()
expr_stmt|;
name|totalBlockUncompressedSize
operator|+=
name|blockWriter
operator|.
name|getUncompressedSizeWithoutHeader
argument_list|()
expr_stmt|;
comment|// OFFSET is the beginning offset the chunk of block index entries.
comment|// SIZE is the total byte size of the chunk of block index entries
comment|// + the secondary index size
comment|// FIRST_KEY is the first key in the chunk of block index
comment|// entries.
name|parent
operator|.
name|add
argument_list|(
name|curFirstKey
argument_list|,
name|beginOffset
argument_list|,
name|blockWriter
operator|.
name|getOnDiskSizeWithHeader
argument_list|()
argument_list|)
expr_stmt|;
comment|// clear current block index chunk
name|curChunk
operator|.
name|clear
argument_list|()
expr_stmt|;
name|curFirstKey
operator|=
literal|null
expr_stmt|;
block|}
comment|/**      * @return how many block index entries there are in the root level      */
specifier|public
specifier|final
name|int
name|getNumRootEntries
parameter_list|()
block|{
return|return
name|rootChunk
operator|.
name|getNumEntries
argument_list|()
return|;
block|}
comment|/**      * @return the number of levels in this block index.      */
specifier|public
name|int
name|getNumLevels
parameter_list|()
block|{
return|return
name|numLevels
return|;
block|}
specifier|private
name|void
name|expectNumLevels
parameter_list|(
name|int
name|expectedNumLevels
parameter_list|)
block|{
if|if
condition|(
name|numLevels
operator|!=
name|expectedNumLevels
condition|)
block|{
throw|throw
operator|new
name|IllegalStateException
argument_list|(
literal|"Number of block index levels is "
operator|+
name|numLevels
operator|+
literal|"but is expected to be "
operator|+
name|expectedNumLevels
argument_list|)
throw|;
block|}
block|}
comment|/**      * Whether there is an inline block ready to be written. In general, we      * write an leaf-level index block as an inline block as soon as its size      * as serialized in the non-root format reaches a certain threshold.      */
annotation|@
name|Override
specifier|public
name|boolean
name|shouldWriteBlock
parameter_list|(
name|boolean
name|closing
parameter_list|)
block|{
if|if
condition|(
name|singleLevelOnly
condition|)
block|{
throw|throw
operator|new
name|UnsupportedOperationException
argument_list|(
name|INLINE_BLOCKS_NOT_ALLOWED
argument_list|)
throw|;
block|}
if|if
condition|(
name|curInlineChunk
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|IllegalStateException
argument_list|(
literal|"curInlineChunk is null; has shouldWriteBlock been "
operator|+
literal|"called with closing=true and then called again?"
argument_list|)
throw|;
block|}
if|if
condition|(
name|curInlineChunk
operator|.
name|getNumEntries
argument_list|()
operator|==
literal|0
condition|)
block|{
return|return
literal|false
return|;
block|}
comment|// We do have some entries in the current inline chunk.
if|if
condition|(
name|closing
condition|)
block|{
if|if
condition|(
name|rootChunk
operator|.
name|getNumEntries
argument_list|()
operator|==
literal|0
condition|)
block|{
comment|// We did not add any leaf-level blocks yet. Instead of creating a
comment|// leaf level with one block, move these entries to the root level.
name|expectNumLevels
argument_list|(
literal|1
argument_list|)
expr_stmt|;
name|rootChunk
operator|=
name|curInlineChunk
expr_stmt|;
name|curInlineChunk
operator|=
literal|null
expr_stmt|;
comment|// Disallow adding any more index entries.
return|return
literal|false
return|;
block|}
return|return
literal|true
return|;
block|}
else|else
block|{
return|return
name|curInlineChunk
operator|.
name|getNonRootSize
argument_list|()
operator|>=
name|maxChunkSize
return|;
block|}
block|}
comment|/**      * Write out the current inline index block. Inline blocks are non-root      * blocks, so the non-root index format is used.      *      * @param out      */
annotation|@
name|Override
specifier|public
name|void
name|writeInlineBlock
parameter_list|(
name|DataOutput
name|out
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|singleLevelOnly
condition|)
throw|throw
operator|new
name|UnsupportedOperationException
argument_list|(
name|INLINE_BLOCKS_NOT_ALLOWED
argument_list|)
throw|;
comment|// Write the inline block index to the output stream in the non-root
comment|// index block format.
name|curInlineChunk
operator|.
name|writeNonRoot
argument_list|(
name|out
argument_list|)
expr_stmt|;
comment|// Save the first key of the inline block so that we can add it to the
comment|// parent-level index.
name|firstKey
operator|=
name|curInlineChunk
operator|.
name|getBlockKey
argument_list|(
literal|0
argument_list|)
expr_stmt|;
comment|// Start a new inline index block
name|curInlineChunk
operator|.
name|clear
argument_list|()
expr_stmt|;
block|}
comment|/**      * Called after an inline block has been written so that we can add an      * entry referring to that block to the parent-level index.      */
annotation|@
name|Override
specifier|public
name|void
name|blockWritten
parameter_list|(
name|long
name|offset
parameter_list|,
name|int
name|onDiskSize
parameter_list|,
name|int
name|uncompressedSize
parameter_list|)
block|{
comment|// Add leaf index block size
name|totalBlockOnDiskSize
operator|+=
name|onDiskSize
expr_stmt|;
name|totalBlockUncompressedSize
operator|+=
name|uncompressedSize
expr_stmt|;
if|if
condition|(
name|singleLevelOnly
condition|)
throw|throw
operator|new
name|UnsupportedOperationException
argument_list|(
name|INLINE_BLOCKS_NOT_ALLOWED
argument_list|)
throw|;
if|if
condition|(
name|firstKey
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|IllegalStateException
argument_list|(
literal|"Trying to add second-level index "
operator|+
literal|"entry with offset="
operator|+
name|offset
operator|+
literal|" and onDiskSize="
operator|+
name|onDiskSize
operator|+
literal|"but the first key was not set in writeInlineBlock"
argument_list|)
throw|;
block|}
if|if
condition|(
name|rootChunk
operator|.
name|getNumEntries
argument_list|()
operator|==
literal|0
condition|)
block|{
comment|// We are writing the first leaf block, so increase index level.
name|expectNumLevels
argument_list|(
literal|1
argument_list|)
expr_stmt|;
name|numLevels
operator|=
literal|2
expr_stmt|;
block|}
comment|// Add another entry to the second-level index. Include the number of
comment|// entries in all previous leaf-level chunks for mid-key calculation.
name|rootChunk
operator|.
name|add
argument_list|(
name|firstKey
argument_list|,
name|offset
argument_list|,
name|onDiskSize
argument_list|,
name|totalNumEntries
argument_list|)
expr_stmt|;
name|firstKey
operator|=
literal|null
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|BlockType
name|getInlineBlockType
parameter_list|()
block|{
return|return
name|BlockType
operator|.
name|LEAF_INDEX
return|;
block|}
comment|/**      * Add one index entry to the current leaf-level block. When the leaf-level      * block gets large enough, it will be flushed to disk as an inline block.      *      * @param firstKey the first key of the data block      * @param blockOffset the offset of the data block      * @param blockDataSize the on-disk size of the data block ({@link HFile}      *          format version 2), or the uncompressed size of the data block (      *          {@link HFile} format version 1).      */
specifier|public
name|void
name|addEntry
parameter_list|(
name|byte
index|[]
name|firstKey
parameter_list|,
name|long
name|blockOffset
parameter_list|,
name|int
name|blockDataSize
parameter_list|)
block|{
name|curInlineChunk
operator|.
name|add
argument_list|(
name|firstKey
argument_list|,
name|blockOffset
argument_list|,
name|blockDataSize
argument_list|)
expr_stmt|;
operator|++
name|totalNumEntries
expr_stmt|;
block|}
comment|/**      * @throws IOException if we happened to write a multi-level index.      */
specifier|public
name|void
name|ensureSingleLevel
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|numLevels
operator|>
literal|1
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Wrote a "
operator|+
name|numLevels
operator|+
literal|"-level index with "
operator|+
name|rootChunk
operator|.
name|getNumEntries
argument_list|()
operator|+
literal|" root-level entries, but "
operator|+
literal|"this is expected to be a single-level block index."
argument_list|)
throw|;
block|}
block|}
comment|/**      * @return true if we are using cache-on-write. This is configured by the      *         caller of the constructor by either passing a valid block cache      *         or null.      */
annotation|@
name|Override
specifier|public
name|boolean
name|getCacheOnWrite
parameter_list|()
block|{
return|return
name|cacheConf
operator|!=
literal|null
operator|&&
name|cacheConf
operator|.
name|shouldCacheIndexesOnWrite
argument_list|()
return|;
block|}
comment|/**      * The total uncompressed size of the root index block, intermediate-level      * index blocks, and leaf-level index blocks.      *      * @return the total uncompressed size of all index blocks      */
specifier|public
name|long
name|getTotalUncompressedSize
parameter_list|()
block|{
return|return
name|totalBlockUncompressedSize
return|;
block|}
block|}
comment|/**    * A single chunk of the block index in the process of writing. The data in    * this chunk can become a leaf-level, intermediate-level, or root index    * block.    */
specifier|static
class|class
name|BlockIndexChunk
block|{
comment|/** First keys of the key range corresponding to each index entry. */
specifier|private
specifier|final
name|List
argument_list|<
name|byte
index|[]
argument_list|>
name|blockKeys
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
comment|/** Block offset in backing stream. */
specifier|private
specifier|final
name|List
argument_list|<
name|Long
argument_list|>
name|blockOffsets
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
comment|/** On-disk data sizes of lower-level data or index blocks. */
specifier|private
specifier|final
name|List
argument_list|<
name|Integer
argument_list|>
name|onDiskDataSizes
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
comment|/**      * The cumulative number of sub-entries, i.e. entries on deeper-level block      * index entries. numSubEntriesAt[i] is the number of sub-entries in the      * blocks corresponding to this chunk's entries #0 through #i inclusively.      */
specifier|private
specifier|final
name|List
argument_list|<
name|Long
argument_list|>
name|numSubEntriesAt
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
comment|/**      * The offset of the next entry to be added, relative to the end of the      * "secondary index" in the "non-root" format representation of this index      * chunk. This is the next value to be added to the secondary index.      */
specifier|private
name|int
name|curTotalNonRootEntrySize
init|=
literal|0
decl_stmt|;
comment|/**      * The accumulated size of this chunk if stored in the root index format.      */
specifier|private
name|int
name|curTotalRootSize
init|=
literal|0
decl_stmt|;
comment|/**      * The "secondary index" used for binary search over variable-length      * records in a "non-root" format block. These offsets are relative to the      * end of this secondary index.      */
specifier|private
specifier|final
name|List
argument_list|<
name|Integer
argument_list|>
name|secondaryIndexOffsetMarks
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
comment|/**      * Adds a new entry to this block index chunk.      *      * @param firstKey the first key in the block pointed to by this entry      * @param blockOffset the offset of the next-level block pointed to by this      *          entry      * @param onDiskDataSize the on-disk data of the block pointed to by this      *          entry, including header size      * @param curTotalNumSubEntries if this chunk is the root index chunk under      *          construction, this specifies the current total number of      *          sub-entries in all leaf-level chunks, including the one      *          corresponding to the second-level entry being added.      */
name|void
name|add
parameter_list|(
name|byte
index|[]
name|firstKey
parameter_list|,
name|long
name|blockOffset
parameter_list|,
name|int
name|onDiskDataSize
parameter_list|,
name|long
name|curTotalNumSubEntries
parameter_list|)
block|{
comment|// Record the offset for the secondary index
name|secondaryIndexOffsetMarks
operator|.
name|add
argument_list|(
name|curTotalNonRootEntrySize
argument_list|)
expr_stmt|;
name|curTotalNonRootEntrySize
operator|+=
name|SECONDARY_INDEX_ENTRY_OVERHEAD
operator|+
name|firstKey
operator|.
name|length
expr_stmt|;
name|curTotalRootSize
operator|+=
name|Bytes
operator|.
name|SIZEOF_LONG
operator|+
name|Bytes
operator|.
name|SIZEOF_INT
operator|+
name|WritableUtils
operator|.
name|getVIntSize
argument_list|(
name|firstKey
operator|.
name|length
argument_list|)
operator|+
name|firstKey
operator|.
name|length
expr_stmt|;
name|blockKeys
operator|.
name|add
argument_list|(
name|firstKey
argument_list|)
expr_stmt|;
name|blockOffsets
operator|.
name|add
argument_list|(
name|blockOffset
argument_list|)
expr_stmt|;
name|onDiskDataSizes
operator|.
name|add
argument_list|(
name|onDiskDataSize
argument_list|)
expr_stmt|;
if|if
condition|(
name|curTotalNumSubEntries
operator|!=
operator|-
literal|1
condition|)
block|{
name|numSubEntriesAt
operator|.
name|add
argument_list|(
name|curTotalNumSubEntries
argument_list|)
expr_stmt|;
comment|// Make sure the parallel arrays are in sync.
if|if
condition|(
name|numSubEntriesAt
operator|.
name|size
argument_list|()
operator|!=
name|blockKeys
operator|.
name|size
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|IllegalStateException
argument_list|(
literal|"Only have key/value count "
operator|+
literal|"stats for "
operator|+
name|numSubEntriesAt
operator|.
name|size
argument_list|()
operator|+
literal|" block index "
operator|+
literal|"entries out of "
operator|+
name|blockKeys
operator|.
name|size
argument_list|()
argument_list|)
throw|;
block|}
block|}
block|}
comment|/**      * The same as {@link #add(byte[], long, int, long)} but does not take the      * key/value into account. Used for single-level indexes.      *      * @see #add(byte[], long, int, long)      */
specifier|public
name|void
name|add
parameter_list|(
name|byte
index|[]
name|firstKey
parameter_list|,
name|long
name|blockOffset
parameter_list|,
name|int
name|onDiskDataSize
parameter_list|)
block|{
name|add
argument_list|(
name|firstKey
argument_list|,
name|blockOffset
argument_list|,
name|onDiskDataSize
argument_list|,
operator|-
literal|1
argument_list|)
expr_stmt|;
block|}
specifier|public
name|void
name|clear
parameter_list|()
block|{
name|blockKeys
operator|.
name|clear
argument_list|()
expr_stmt|;
name|blockOffsets
operator|.
name|clear
argument_list|()
expr_stmt|;
name|onDiskDataSizes
operator|.
name|clear
argument_list|()
expr_stmt|;
name|secondaryIndexOffsetMarks
operator|.
name|clear
argument_list|()
expr_stmt|;
name|numSubEntriesAt
operator|.
name|clear
argument_list|()
expr_stmt|;
name|curTotalNonRootEntrySize
operator|=
literal|0
expr_stmt|;
name|curTotalRootSize
operator|=
literal|0
expr_stmt|;
block|}
comment|/**      * Finds the entry corresponding to the deeper-level index block containing      * the given deeper-level entry (a "sub-entry"), assuming a global 0-based      * ordering of sub-entries.      *      *<p>      *<i> Implementation note.</i> We are looking for i such that      * numSubEntriesAt[i - 1]<= k< numSubEntriesAt[i], because a deeper-level      * block #i (0-based) contains sub-entries # numSubEntriesAt[i - 1]'th      * through numSubEntriesAt[i] - 1, assuming a global 0-based ordering of      * sub-entries. i is by definition the insertion point of k in      * numSubEntriesAt.      *      * @param k sub-entry index, from 0 to the total number sub-entries - 1      * @return the 0-based index of the entry corresponding to the given      *         sub-entry      */
specifier|public
name|int
name|getEntryBySubEntry
parameter_list|(
name|long
name|k
parameter_list|)
block|{
comment|// We define mid-key as the key corresponding to k'th sub-entry
comment|// (0-based).
name|int
name|i
init|=
name|Collections
operator|.
name|binarySearch
argument_list|(
name|numSubEntriesAt
argument_list|,
name|k
argument_list|)
decl_stmt|;
comment|// Exact match: cumulativeWeight[i] = k. This means chunks #0 through
comment|// #i contain exactly k sub-entries, and the sub-entry #k (0-based)
comment|// is in the (i + 1)'th chunk.
if|if
condition|(
name|i
operator|>=
literal|0
condition|)
return|return
name|i
operator|+
literal|1
return|;
comment|// Inexact match. Return the insertion point.
return|return
operator|-
name|i
operator|-
literal|1
return|;
block|}
comment|/**      * Used when writing the root block index of a multi-level block index.      * Serializes additional information allowing to efficiently identify the      * mid-key.      *      * @return a few serialized fields for finding the mid-key      * @throws IOException if could not create metadata for computing mid-key      */
specifier|public
name|byte
index|[]
name|getMidKeyMetadata
parameter_list|()
throws|throws
name|IOException
block|{
name|ByteArrayOutputStream
name|baos
init|=
operator|new
name|ByteArrayOutputStream
argument_list|(
name|MID_KEY_METADATA_SIZE
argument_list|)
decl_stmt|;
name|DataOutputStream
name|baosDos
init|=
operator|new
name|DataOutputStream
argument_list|(
name|baos
argument_list|)
decl_stmt|;
name|long
name|totalNumSubEntries
init|=
name|numSubEntriesAt
operator|.
name|get
argument_list|(
name|blockKeys
operator|.
name|size
argument_list|()
operator|-
literal|1
argument_list|)
decl_stmt|;
if|if
condition|(
name|totalNumSubEntries
operator|==
literal|0
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"No leaf-level entries, mid-key unavailable"
argument_list|)
throw|;
block|}
name|long
name|midKeySubEntry
init|=
operator|(
name|totalNumSubEntries
operator|-
literal|1
operator|)
operator|/
literal|2
decl_stmt|;
name|int
name|midKeyEntry
init|=
name|getEntryBySubEntry
argument_list|(
name|midKeySubEntry
argument_list|)
decl_stmt|;
name|baosDos
operator|.
name|writeLong
argument_list|(
name|blockOffsets
operator|.
name|get
argument_list|(
name|midKeyEntry
argument_list|)
argument_list|)
expr_stmt|;
name|baosDos
operator|.
name|writeInt
argument_list|(
name|onDiskDataSizes
operator|.
name|get
argument_list|(
name|midKeyEntry
argument_list|)
argument_list|)
expr_stmt|;
name|long
name|numSubEntriesBefore
init|=
name|midKeyEntry
operator|>
literal|0
condition|?
name|numSubEntriesAt
operator|.
name|get
argument_list|(
name|midKeyEntry
operator|-
literal|1
argument_list|)
else|:
literal|0
decl_stmt|;
name|long
name|subEntryWithinEntry
init|=
name|midKeySubEntry
operator|-
name|numSubEntriesBefore
decl_stmt|;
if|if
condition|(
name|subEntryWithinEntry
argument_list|<
literal|0
operator|||
name|subEntryWithinEntry
argument_list|>
name|Integer
operator|.
name|MAX_VALUE
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Could not identify mid-key index within the "
operator|+
literal|"leaf-level block containing mid-key: out of range ("
operator|+
name|subEntryWithinEntry
operator|+
literal|", numSubEntriesBefore="
operator|+
name|numSubEntriesBefore
operator|+
literal|", midKeySubEntry="
operator|+
name|midKeySubEntry
operator|+
literal|")"
argument_list|)
throw|;
block|}
name|baosDos
operator|.
name|writeInt
argument_list|(
operator|(
name|int
operator|)
name|subEntryWithinEntry
argument_list|)
expr_stmt|;
if|if
condition|(
name|baosDos
operator|.
name|size
argument_list|()
operator|!=
name|MID_KEY_METADATA_SIZE
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Could not write mid-key metadata: size="
operator|+
name|baosDos
operator|.
name|size
argument_list|()
operator|+
literal|", correct size: "
operator|+
name|MID_KEY_METADATA_SIZE
argument_list|)
throw|;
block|}
comment|// Close just to be good citizens, although this has no effect.
name|baos
operator|.
name|close
argument_list|()
expr_stmt|;
return|return
name|baos
operator|.
name|toByteArray
argument_list|()
return|;
block|}
comment|/**      * Writes the block index chunk in the non-root index block format. This      * format contains the number of entries, an index of integer offsets      * for quick binary search on variable-length records, and tuples of      * block offset, on-disk block size, and the first key for each entry.      *      * @param out      * @throws IOException      */
name|void
name|writeNonRoot
parameter_list|(
name|DataOutput
name|out
parameter_list|)
throws|throws
name|IOException
block|{
comment|// The number of entries in the block.
name|out
operator|.
name|writeInt
argument_list|(
name|blockKeys
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|secondaryIndexOffsetMarks
operator|.
name|size
argument_list|()
operator|!=
name|blockKeys
operator|.
name|size
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Corrupted block index chunk writer: "
operator|+
name|blockKeys
operator|.
name|size
argument_list|()
operator|+
literal|" entries but "
operator|+
name|secondaryIndexOffsetMarks
operator|.
name|size
argument_list|()
operator|+
literal|" secondary index items"
argument_list|)
throw|;
block|}
comment|// For each entry, write a "secondary index" of relative offsets to the
comment|// entries from the end of the secondary index. This works, because at
comment|// read time we read the number of entries and know where the secondary
comment|// index ends.
for|for
control|(
name|int
name|currentSecondaryIndex
range|:
name|secondaryIndexOffsetMarks
control|)
name|out
operator|.
name|writeInt
argument_list|(
name|currentSecondaryIndex
argument_list|)
expr_stmt|;
comment|// We include one other element in the secondary index to calculate the
comment|// size of each entry more easily by subtracting secondary index elements.
name|out
operator|.
name|writeInt
argument_list|(
name|curTotalNonRootEntrySize
argument_list|)
expr_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|blockKeys
operator|.
name|size
argument_list|()
condition|;
operator|++
name|i
control|)
block|{
name|out
operator|.
name|writeLong
argument_list|(
name|blockOffsets
operator|.
name|get
argument_list|(
name|i
argument_list|)
argument_list|)
expr_stmt|;
name|out
operator|.
name|writeInt
argument_list|(
name|onDiskDataSizes
operator|.
name|get
argument_list|(
name|i
argument_list|)
argument_list|)
expr_stmt|;
name|out
operator|.
name|write
argument_list|(
name|blockKeys
operator|.
name|get
argument_list|(
name|i
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**      * @return the size of this chunk if stored in the non-root index block      *         format      */
name|int
name|getNonRootSize
parameter_list|()
block|{
return|return
name|Bytes
operator|.
name|SIZEOF_INT
comment|// Number of entries
operator|+
name|Bytes
operator|.
name|SIZEOF_INT
operator|*
operator|(
name|blockKeys
operator|.
name|size
argument_list|()
operator|+
literal|1
operator|)
comment|// Secondary index
operator|+
name|curTotalNonRootEntrySize
return|;
comment|// All entries
block|}
comment|/**      * Writes this chunk into the given output stream in the root block index      * format. This format is similar to the {@link HFile} version 1 block      * index format, except that we store on-disk size of the block instead of      * its uncompressed size.      *      * @param out the data output stream to write the block index to. Typically      *          a stream writing into an {@link HFile} block.      * @throws IOException      */
name|void
name|writeRoot
parameter_list|(
name|DataOutput
name|out
parameter_list|)
throws|throws
name|IOException
block|{
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|blockKeys
operator|.
name|size
argument_list|()
condition|;
operator|++
name|i
control|)
block|{
name|out
operator|.
name|writeLong
argument_list|(
name|blockOffsets
operator|.
name|get
argument_list|(
name|i
argument_list|)
argument_list|)
expr_stmt|;
name|out
operator|.
name|writeInt
argument_list|(
name|onDiskDataSizes
operator|.
name|get
argument_list|(
name|i
argument_list|)
argument_list|)
expr_stmt|;
name|Bytes
operator|.
name|writeByteArray
argument_list|(
name|out
argument_list|,
name|blockKeys
operator|.
name|get
argument_list|(
name|i
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**      * @return the size of this chunk if stored in the root index block format      */
name|int
name|getRootSize
parameter_list|()
block|{
return|return
name|curTotalRootSize
return|;
block|}
comment|/**      * @return the number of entries in this block index chunk      */
specifier|public
name|int
name|getNumEntries
parameter_list|()
block|{
return|return
name|blockKeys
operator|.
name|size
argument_list|()
return|;
block|}
specifier|public
name|byte
index|[]
name|getBlockKey
parameter_list|(
name|int
name|i
parameter_list|)
block|{
return|return
name|blockKeys
operator|.
name|get
argument_list|(
name|i
argument_list|)
return|;
block|}
specifier|public
name|long
name|getBlockOffset
parameter_list|(
name|int
name|i
parameter_list|)
block|{
return|return
name|blockOffsets
operator|.
name|get
argument_list|(
name|i
argument_list|)
return|;
block|}
specifier|public
name|int
name|getOnDiskDataSize
parameter_list|(
name|int
name|i
parameter_list|)
block|{
return|return
name|onDiskDataSizes
operator|.
name|get
argument_list|(
name|i
argument_list|)
return|;
block|}
specifier|public
name|long
name|getCumulativeNumKV
parameter_list|(
name|int
name|i
parameter_list|)
block|{
if|if
condition|(
name|i
operator|<
literal|0
condition|)
return|return
literal|0
return|;
return|return
name|numSubEntriesAt
operator|.
name|get
argument_list|(
name|i
argument_list|)
return|;
block|}
block|}
specifier|public
specifier|static
name|int
name|getMaxChunkSize
parameter_list|(
name|Configuration
name|conf
parameter_list|)
block|{
return|return
name|conf
operator|.
name|getInt
argument_list|(
name|MAX_CHUNK_SIZE_KEY
argument_list|,
name|DEFAULT_MAX_CHUNK_SIZE
argument_list|)
return|;
block|}
specifier|public
specifier|static
name|int
name|getMinIndexNumEntries
parameter_list|(
name|Configuration
name|conf
parameter_list|)
block|{
return|return
name|conf
operator|.
name|getInt
argument_list|(
name|MIN_INDEX_NUM_ENTRIES_KEY
argument_list|,
name|DEFAULT_MIN_INDEX_NUM_ENTRIES
argument_list|)
return|;
block|}
block|}
end_class

end_unit

