begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|backup
operator|.
name|example
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|classification
operator|.
name|InterfaceAudience
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configured
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|HConnection
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|Bytes
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|zookeeper
operator|.
name|ZKUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|zookeeper
operator|.
name|ZooKeeperWatcher
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|zookeeper
operator|.
name|KeeperException
import|;
end_import

begin_comment
comment|/**  * Example class for how to use the table archiving coordinated via zookeeper  */
end_comment

begin_class
annotation|@
name|InterfaceAudience
operator|.
name|Private
specifier|public
class|class
name|ZKTableArchiveClient
extends|extends
name|Configured
block|{
comment|/** Configuration key for the archive node. */
specifier|private
specifier|static
specifier|final
name|String
name|ZOOKEEPER_ZNODE_HFILE_ARCHIVE_KEY
init|=
literal|"zookeeper.znode.hfile.archive"
decl_stmt|;
specifier|private
name|HConnection
name|connection
decl_stmt|;
specifier|public
name|ZKTableArchiveClient
parameter_list|(
name|Configuration
name|conf
parameter_list|,
name|HConnection
name|connection
parameter_list|)
block|{
name|super
argument_list|(
name|conf
argument_list|)
expr_stmt|;
name|this
operator|.
name|connection
operator|=
name|connection
expr_stmt|;
block|}
comment|/**    * Turn on backups for all HFiles for the given table.    *<p>    * All deleted hfiles are moved to the archive directory under the table directory, rather than    * being deleted.    *<p>    * If backups are already enabled for this table, does nothing.    *<p>    * If the table does not exist, the archiving the table's hfiles is still enabled as a future    * table with that name may be created shortly.    * @param table name of the table to start backing up    * @throws IOException if an unexpected exception occurs    * @throws KeeperException if zookeeper can't be reached    */
specifier|public
name|void
name|enableHFileBackupAsync
parameter_list|(
specifier|final
name|byte
index|[]
name|table
parameter_list|)
throws|throws
name|IOException
throws|,
name|KeeperException
block|{
name|createHFileArchiveManager
argument_list|()
operator|.
name|enableHFileBackup
argument_list|(
name|table
argument_list|)
operator|.
name|stop
argument_list|()
expr_stmt|;
block|}
comment|/**    * Disable hfile backups for the given table.    *<p>    * Previously backed up files are still retained (if present).    *<p>    * Asynchronous operation - some extra HFiles may be retained, in the archive directory after    * disable is called, dependent on the latency in zookeeper to the servers.    * @param table name of the table stop backing up    * @throws IOException if an unexpected exception occurs    * @throws KeeperException if zookeeper can't be reached    */
specifier|public
name|void
name|disableHFileBackup
parameter_list|(
name|String
name|table
parameter_list|)
throws|throws
name|IOException
throws|,
name|KeeperException
block|{
name|disableHFileBackup
argument_list|(
name|Bytes
operator|.
name|toBytes
argument_list|(
name|table
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|/**    * Disable hfile backups for the given table.    *<p>    * Previously backed up files are still retained (if present).    *<p>    * Asynchronous operation - some extra HFiles may be retained, in the archive directory after    * disable is called, dependent on the latency in zookeeper to the servers.    * @param table name of the table stop backing up    * @throws IOException if an unexpected exception occurs    * @throws KeeperException if zookeeper can't be reached    */
specifier|public
name|void
name|disableHFileBackup
parameter_list|(
specifier|final
name|byte
index|[]
name|table
parameter_list|)
throws|throws
name|IOException
throws|,
name|KeeperException
block|{
name|createHFileArchiveManager
argument_list|()
operator|.
name|disableHFileBackup
argument_list|(
name|table
argument_list|)
operator|.
name|stop
argument_list|()
expr_stmt|;
block|}
comment|/**    * Disable hfile backups for all tables.    *<p>    * Previously backed up files are still retained (if present).    *<p>    * Asynchronous operation - some extra HFiles may be retained, in the archive directory after    * disable is called, dependent on the latency in zookeeper to the servers.    * @throws IOException if an unexpected exception occurs    * @throws KeeperException if zookeeper can't be reached    */
specifier|public
name|void
name|disableHFileBackup
parameter_list|()
throws|throws
name|IOException
throws|,
name|KeeperException
block|{
name|createHFileArchiveManager
argument_list|()
operator|.
name|disableHFileBackup
argument_list|()
operator|.
name|stop
argument_list|()
expr_stmt|;
block|}
comment|/**    * Determine if archiving is enabled (but not necessarily fully propagated) for a table    * @param table name of the table to check    * @return<tt>true</tt> if it is,<tt>false</tt> otherwise    * @throws IOException if a connection to ZooKeeper cannot be established    * @throws KeeperException    */
specifier|public
name|boolean
name|getArchivingEnabled
parameter_list|(
name|byte
index|[]
name|table
parameter_list|)
throws|throws
name|IOException
throws|,
name|KeeperException
block|{
name|HFileArchiveManager
name|manager
init|=
name|createHFileArchiveManager
argument_list|()
decl_stmt|;
try|try
block|{
return|return
name|manager
operator|.
name|isArchivingEnabled
argument_list|(
name|table
argument_list|)
return|;
block|}
finally|finally
block|{
name|manager
operator|.
name|stop
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**    * Determine if archiving is enabled (but not necessarily fully propagated) for a table    * @param table name of the table to check    * @return<tt>true</tt> if it is,<tt>false</tt> otherwise    * @throws IOException if an unexpected network issue occurs    * @throws KeeperException if zookeeper can't be reached    */
specifier|public
name|boolean
name|getArchivingEnabled
parameter_list|(
name|String
name|table
parameter_list|)
throws|throws
name|IOException
throws|,
name|KeeperException
block|{
return|return
name|getArchivingEnabled
argument_list|(
name|Bytes
operator|.
name|toBytes
argument_list|(
name|table
argument_list|)
argument_list|)
return|;
block|}
comment|/**    * @return A new {@link HFileArchiveManager} to manage which tables' hfiles should be archived    *         rather than deleted.    * @throws KeeperException if we can't reach zookeeper    * @throws IOException if an unexpected network issue occurs    */
specifier|private
specifier|synchronized
name|HFileArchiveManager
name|createHFileArchiveManager
parameter_list|()
throws|throws
name|KeeperException
throws|,
name|IOException
block|{
return|return
operator|new
name|HFileArchiveManager
argument_list|(
name|this
operator|.
name|connection
argument_list|,
name|this
operator|.
name|getConf
argument_list|()
argument_list|)
return|;
block|}
comment|/**    * @param conf conf to read for the base archive node    * @param zooKeeper zookeeper to used for building the full path    * @return get the znode for long-term archival of a table for    */
specifier|public
specifier|static
name|String
name|getArchiveZNode
parameter_list|(
name|Configuration
name|conf
parameter_list|,
name|ZooKeeperWatcher
name|zooKeeper
parameter_list|)
block|{
return|return
name|ZKUtil
operator|.
name|joinZNode
argument_list|(
name|zooKeeper
operator|.
name|baseZNode
argument_list|,
name|conf
operator|.
name|get
argument_list|(
name|ZOOKEEPER_ZNODE_HFILE_ARCHIVE_KEY
argument_list|,
name|TableHFileArchiveTracker
operator|.
name|HFILE_ARCHIVE_ZNODE_PARENT
argument_list|)
argument_list|)
return|;
block|}
block|}
end_class

end_unit

