begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/*  *  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|replication
operator|.
name|regionserver
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|EOFException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|FileNotFoundException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|SocketTimeoutException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Arrays
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Comparator
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|NavigableMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Random
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Set
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|UUID
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|CountDownLatch
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|PriorityBlockingQueue
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|TimeUnit
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|atomic
operator|.
name|AtomicBoolean
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|Log
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|LogFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|classification
operator|.
name|InterfaceAudience
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileStatus
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HConstants
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|KeyValue
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|ServerName
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|Stoppable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|AdminProtocol
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|HConnection
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|HConnectionManager
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|protobuf
operator|.
name|ProtobufUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|wal
operator|.
name|HLog
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|wal
operator|.
name|HLogFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|wal
operator|.
name|HLogKey
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|wal
operator|.
name|WALEdit
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|replication
operator|.
name|ReplicationZookeeper
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|replication
operator|.
name|regionserver
operator|.
name|metrics
operator|.
name|ReplicationSourceMetrics
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|wal
operator|.
name|HLog
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|wal
operator|.
name|HLogUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|Bytes
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|Threads
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|zookeeper
operator|.
name|ZKClusterId
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|ipc
operator|.
name|RemoteException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|zookeeper
operator|.
name|KeeperException
import|;
end_import

begin_comment
comment|/**  * Class that handles the source of a replication stream.  * Currently does not handle more than 1 slave  * For each slave cluster it selects a random number of peers  * using a replication ratio. For example, if replication ration = 0.1  * and slave cluster has 100 region servers, 10 will be selected.  *<p/>  * A stream is considered down when we cannot contact a region server on the  * peer cluster for more than 55 seconds by default.  *<p/>  *  */
end_comment

begin_class
annotation|@
name|InterfaceAudience
operator|.
name|Private
specifier|public
class|class
name|ReplicationSource
extends|extends
name|Thread
implements|implements
name|ReplicationSourceInterface
block|{
specifier|private
specifier|static
specifier|final
name|Log
name|LOG
init|=
name|LogFactory
operator|.
name|getLog
argument_list|(
name|ReplicationSource
operator|.
name|class
argument_list|)
decl_stmt|;
comment|// Queue of logs to process
specifier|private
name|PriorityBlockingQueue
argument_list|<
name|Path
argument_list|>
name|queue
decl_stmt|;
comment|// container of entries to replicate
specifier|private
name|HLog
operator|.
name|Entry
index|[]
name|entriesArray
decl_stmt|;
specifier|private
name|HConnection
name|conn
decl_stmt|;
comment|// Helper class for zookeeper
specifier|private
name|ReplicationZookeeper
name|zkHelper
decl_stmt|;
specifier|private
name|Configuration
name|conf
decl_stmt|;
comment|// ratio of region servers to chose from a slave cluster
specifier|private
name|float
name|ratio
decl_stmt|;
specifier|private
name|Random
name|random
decl_stmt|;
comment|// should we replicate or not?
specifier|private
name|AtomicBoolean
name|replicating
decl_stmt|;
comment|// id of the peer cluster this source replicates to
specifier|private
name|String
name|peerId
decl_stmt|;
comment|// The manager of all sources to which we ping back our progress
specifier|private
name|ReplicationSourceManager
name|manager
decl_stmt|;
comment|// Should we stop everything?
specifier|private
name|Stoppable
name|stopper
decl_stmt|;
comment|// List of chosen sinks (region servers)
specifier|private
name|List
argument_list|<
name|ServerName
argument_list|>
name|currentPeers
decl_stmt|;
comment|// How long should we sleep for each retry
specifier|private
name|long
name|sleepForRetries
decl_stmt|;
comment|// Max size in bytes of entriesArray
specifier|private
name|long
name|replicationQueueSizeCapacity
decl_stmt|;
comment|// Max number of entries in entriesArray
specifier|private
name|int
name|replicationQueueNbCapacity
decl_stmt|;
comment|// Our reader for the current log
specifier|private
name|HLog
operator|.
name|Reader
name|reader
decl_stmt|;
comment|// Current position in the log
specifier|private
name|long
name|position
init|=
literal|0
decl_stmt|;
comment|// Last position in the log that we sent to ZooKeeper
specifier|private
name|long
name|lastLoggedPosition
init|=
operator|-
literal|1
decl_stmt|;
comment|// Path of the current log
specifier|private
specifier|volatile
name|Path
name|currentPath
decl_stmt|;
specifier|private
name|FileSystem
name|fs
decl_stmt|;
comment|// id of this cluster
specifier|private
name|UUID
name|clusterId
decl_stmt|;
comment|// id of the other cluster
specifier|private
name|UUID
name|peerClusterId
decl_stmt|;
comment|// total number of edits we replicated
specifier|private
name|long
name|totalReplicatedEdits
init|=
literal|0
decl_stmt|;
comment|// The znode we currently play with
specifier|private
name|String
name|peerClusterZnode
decl_stmt|;
comment|// Indicates if this queue is recovered (and will be deleted when depleted)
specifier|private
name|boolean
name|queueRecovered
decl_stmt|;
comment|// List of all the dead region servers that had this queue (if recovered)
specifier|private
name|String
index|[]
name|deadRegionServers
decl_stmt|;
comment|// Maximum number of retries before taking bold actions
specifier|private
name|int
name|maxRetriesMultiplier
decl_stmt|;
comment|// Socket timeouts require even bolder actions since we don't want to DDOS
specifier|private
name|int
name|socketTimeoutMultiplier
decl_stmt|;
comment|// Current number of entries that we need to replicate
specifier|private
name|int
name|currentNbEntries
init|=
literal|0
decl_stmt|;
comment|// Current number of operations (Put/Delete) that we need to replicate
specifier|private
name|int
name|currentNbOperations
init|=
literal|0
decl_stmt|;
comment|// Indicates if this particular source is running
specifier|private
specifier|volatile
name|boolean
name|running
init|=
literal|true
decl_stmt|;
comment|// Metrics for this source
specifier|private
name|ReplicationSourceMetrics
name|metrics
decl_stmt|;
comment|/**    * Instantiation method used by region servers    *    * @param conf configuration to use    * @param fs file system to use    * @param manager replication manager to ping to    * @param stopper     the atomic boolean to use to stop the regionserver    * @param replicating the atomic boolean that starts/stops replication    * @param peerClusterZnode the name of our znode    * @throws IOException    */
specifier|public
name|void
name|init
parameter_list|(
specifier|final
name|Configuration
name|conf
parameter_list|,
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|ReplicationSourceManager
name|manager
parameter_list|,
specifier|final
name|Stoppable
name|stopper
parameter_list|,
specifier|final
name|AtomicBoolean
name|replicating
parameter_list|,
specifier|final
name|String
name|peerClusterZnode
parameter_list|)
throws|throws
name|IOException
block|{
name|this
operator|.
name|stopper
operator|=
name|stopper
expr_stmt|;
name|this
operator|.
name|conf
operator|=
name|conf
expr_stmt|;
name|this
operator|.
name|replicationQueueSizeCapacity
operator|=
name|this
operator|.
name|conf
operator|.
name|getLong
argument_list|(
literal|"replication.source.size.capacity"
argument_list|,
literal|1024
operator|*
literal|1024
operator|*
literal|64
argument_list|)
expr_stmt|;
name|this
operator|.
name|replicationQueueNbCapacity
operator|=
name|this
operator|.
name|conf
operator|.
name|getInt
argument_list|(
literal|"replication.source.nb.capacity"
argument_list|,
literal|25000
argument_list|)
expr_stmt|;
name|this
operator|.
name|entriesArray
operator|=
operator|new
name|HLog
operator|.
name|Entry
index|[
name|this
operator|.
name|replicationQueueNbCapacity
index|]
expr_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|this
operator|.
name|replicationQueueNbCapacity
condition|;
name|i
operator|++
control|)
block|{
name|this
operator|.
name|entriesArray
index|[
name|i
index|]
operator|=
operator|new
name|HLog
operator|.
name|Entry
argument_list|()
expr_stmt|;
block|}
name|this
operator|.
name|maxRetriesMultiplier
operator|=
name|this
operator|.
name|conf
operator|.
name|getInt
argument_list|(
literal|"replication.source.maxretriesmultiplier"
argument_list|,
literal|10
argument_list|)
expr_stmt|;
name|this
operator|.
name|socketTimeoutMultiplier
operator|=
name|maxRetriesMultiplier
operator|*
name|maxRetriesMultiplier
expr_stmt|;
name|this
operator|.
name|queue
operator|=
operator|new
name|PriorityBlockingQueue
argument_list|<
name|Path
argument_list|>
argument_list|(
name|conf
operator|.
name|getInt
argument_list|(
literal|"hbase.regionserver.maxlogs"
argument_list|,
literal|32
argument_list|)
argument_list|,
operator|new
name|LogsComparator
argument_list|()
argument_list|)
expr_stmt|;
name|this
operator|.
name|conn
operator|=
name|HConnectionManager
operator|.
name|getConnection
argument_list|(
name|conf
argument_list|)
expr_stmt|;
name|this
operator|.
name|zkHelper
operator|=
name|manager
operator|.
name|getRepZkWrapper
argument_list|()
expr_stmt|;
name|this
operator|.
name|ratio
operator|=
name|this
operator|.
name|conf
operator|.
name|getFloat
argument_list|(
literal|"replication.source.ratio"
argument_list|,
literal|0.1f
argument_list|)
expr_stmt|;
name|this
operator|.
name|currentPeers
operator|=
operator|new
name|ArrayList
argument_list|<
name|ServerName
argument_list|>
argument_list|()
expr_stmt|;
name|this
operator|.
name|random
operator|=
operator|new
name|Random
argument_list|()
expr_stmt|;
name|this
operator|.
name|replicating
operator|=
name|replicating
expr_stmt|;
name|this
operator|.
name|manager
operator|=
name|manager
expr_stmt|;
name|this
operator|.
name|sleepForRetries
operator|=
name|this
operator|.
name|conf
operator|.
name|getLong
argument_list|(
literal|"replication.source.sleepforretries"
argument_list|,
literal|1000
argument_list|)
expr_stmt|;
name|this
operator|.
name|fs
operator|=
name|fs
expr_stmt|;
name|this
operator|.
name|metrics
operator|=
operator|new
name|ReplicationSourceMetrics
argument_list|(
name|peerClusterZnode
argument_list|)
expr_stmt|;
try|try
block|{
name|this
operator|.
name|clusterId
operator|=
name|zkHelper
operator|.
name|getUUIDForCluster
argument_list|(
name|zkHelper
operator|.
name|getZookeeperWatcher
argument_list|()
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|KeeperException
name|ke
parameter_list|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Could not read cluster id"
argument_list|,
name|ke
argument_list|)
throw|;
block|}
comment|// Finally look if this is a recovered queue
name|this
operator|.
name|checkIfQueueRecovered
argument_list|(
name|peerClusterZnode
argument_list|)
expr_stmt|;
block|}
comment|// The passed znode will be either the id of the peer cluster or
comment|// the handling story of that queue in the form of id-servername-*
specifier|private
name|void
name|checkIfQueueRecovered
parameter_list|(
name|String
name|peerClusterZnode
parameter_list|)
block|{
name|String
index|[]
name|parts
init|=
name|peerClusterZnode
operator|.
name|split
argument_list|(
literal|"-"
argument_list|)
decl_stmt|;
name|this
operator|.
name|queueRecovered
operator|=
name|parts
operator|.
name|length
operator|!=
literal|1
expr_stmt|;
name|this
operator|.
name|peerId
operator|=
name|this
operator|.
name|queueRecovered
condition|?
name|parts
index|[
literal|0
index|]
else|:
name|peerClusterZnode
expr_stmt|;
name|this
operator|.
name|peerClusterZnode
operator|=
name|peerClusterZnode
expr_stmt|;
name|this
operator|.
name|deadRegionServers
operator|=
operator|new
name|String
index|[
name|parts
operator|.
name|length
operator|-
literal|1
index|]
expr_stmt|;
comment|// Extract all the places where we could find the hlogs
for|for
control|(
name|int
name|i
init|=
literal|1
init|;
name|i
operator|<
name|parts
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|this
operator|.
name|deadRegionServers
index|[
name|i
operator|-
literal|1
index|]
operator|=
name|parts
index|[
name|i
index|]
expr_stmt|;
block|}
block|}
comment|/**    * Select a number of peers at random using the ratio. Mininum 1.    */
specifier|private
name|void
name|chooseSinks
parameter_list|()
block|{
name|this
operator|.
name|currentPeers
operator|.
name|clear
argument_list|()
expr_stmt|;
name|List
argument_list|<
name|ServerName
argument_list|>
name|addresses
init|=
name|this
operator|.
name|zkHelper
operator|.
name|getSlavesAddresses
argument_list|(
name|peerId
argument_list|)
decl_stmt|;
name|Set
argument_list|<
name|ServerName
argument_list|>
name|setOfAddr
init|=
operator|new
name|HashSet
argument_list|<
name|ServerName
argument_list|>
argument_list|()
decl_stmt|;
name|int
name|nbPeers
init|=
call|(
name|int
call|)
argument_list|(
name|Math
operator|.
name|ceil
argument_list|(
name|addresses
operator|.
name|size
argument_list|()
operator|*
name|ratio
argument_list|)
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Getting "
operator|+
name|nbPeers
operator|+
literal|" rs from peer cluster # "
operator|+
name|peerId
argument_list|)
expr_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|nbPeers
condition|;
name|i
operator|++
control|)
block|{
name|ServerName
name|sn
decl_stmt|;
comment|// Make sure we get one address that we don't already have
do|do
block|{
name|sn
operator|=
name|addresses
operator|.
name|get
argument_list|(
name|this
operator|.
name|random
operator|.
name|nextInt
argument_list|(
name|addresses
operator|.
name|size
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
do|while
condition|(
name|setOfAddr
operator|.
name|contains
argument_list|(
name|sn
argument_list|)
condition|)
do|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Choosing peer "
operator|+
name|sn
argument_list|)
expr_stmt|;
name|setOfAddr
operator|.
name|add
argument_list|(
name|sn
argument_list|)
expr_stmt|;
block|}
name|this
operator|.
name|currentPeers
operator|.
name|addAll
argument_list|(
name|setOfAddr
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|enqueueLog
parameter_list|(
name|Path
name|log
parameter_list|)
block|{
name|this
operator|.
name|queue
operator|.
name|put
argument_list|(
name|log
argument_list|)
expr_stmt|;
name|this
operator|.
name|metrics
operator|.
name|setSizeOfLogQueue
argument_list|(
name|queue
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|run
parameter_list|()
block|{
name|connectToPeers
argument_list|()
expr_stmt|;
comment|// We were stopped while looping to connect to sinks, just abort
if|if
condition|(
operator|!
name|this
operator|.
name|isActive
argument_list|()
condition|)
block|{
name|metrics
operator|.
name|clear
argument_list|()
expr_stmt|;
return|return;
block|}
name|int
name|sleepMultiplier
init|=
literal|1
decl_stmt|;
comment|// delay this until we are in an asynchronous thread
while|while
condition|(
name|this
operator|.
name|peerClusterId
operator|==
literal|null
condition|)
block|{
name|this
operator|.
name|peerClusterId
operator|=
name|zkHelper
operator|.
name|getPeerUUID
argument_list|(
name|this
operator|.
name|peerId
argument_list|)
expr_stmt|;
if|if
condition|(
name|this
operator|.
name|peerClusterId
operator|==
literal|null
condition|)
block|{
if|if
condition|(
name|sleepForRetries
argument_list|(
literal|"Cannot contact the peer's zk ensemble"
argument_list|,
name|sleepMultiplier
argument_list|)
condition|)
block|{
name|sleepMultiplier
operator|++
expr_stmt|;
block|}
block|}
block|}
comment|// resetting to 1 to reuse later
name|sleepMultiplier
operator|=
literal|1
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Replicating "
operator|+
name|clusterId
operator|+
literal|" -> "
operator|+
name|peerClusterId
argument_list|)
expr_stmt|;
comment|// If this is recovered, the queue is already full and the first log
comment|// normally has a position (unless the RS failed between 2 logs)
if|if
condition|(
name|this
operator|.
name|queueRecovered
condition|)
block|{
try|try
block|{
name|this
operator|.
name|position
operator|=
name|this
operator|.
name|zkHelper
operator|.
name|getHLogRepPosition
argument_list|(
name|this
operator|.
name|peerClusterZnode
argument_list|,
name|this
operator|.
name|queue
operator|.
name|peek
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|KeeperException
name|e
parameter_list|)
block|{
name|this
operator|.
name|terminate
argument_list|(
literal|"Couldn't get the position of this recovered queue "
operator|+
name|peerClusterZnode
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
block|}
comment|// Loop until we close down
while|while
condition|(
name|isActive
argument_list|()
condition|)
block|{
comment|// Sleep until replication is enabled again
if|if
condition|(
operator|!
name|isPeerEnabled
argument_list|()
condition|)
block|{
if|if
condition|(
name|sleepForRetries
argument_list|(
literal|"Replication is disabled"
argument_list|,
name|sleepMultiplier
argument_list|)
condition|)
block|{
name|sleepMultiplier
operator|++
expr_stmt|;
block|}
continue|continue;
block|}
name|Path
name|oldPath
init|=
name|getCurrentPath
argument_list|()
decl_stmt|;
comment|//note that in the current scenario,
comment|//oldPath will be null when a log roll
comment|//happens.
comment|// Get a new path
name|boolean
name|hasCurrentPath
init|=
name|getNextPath
argument_list|()
decl_stmt|;
if|if
condition|(
name|getCurrentPath
argument_list|()
operator|!=
literal|null
operator|&&
name|oldPath
operator|==
literal|null
condition|)
block|{
name|sleepMultiplier
operator|=
literal|1
expr_stmt|;
comment|//reset the sleepMultiplier on a path change
block|}
if|if
condition|(
operator|!
name|hasCurrentPath
condition|)
block|{
if|if
condition|(
name|sleepForRetries
argument_list|(
literal|"No log to process"
argument_list|,
name|sleepMultiplier
argument_list|)
condition|)
block|{
name|sleepMultiplier
operator|++
expr_stmt|;
block|}
continue|continue;
block|}
comment|// Open a reader on it
if|if
condition|(
operator|!
name|openReader
argument_list|(
name|sleepMultiplier
argument_list|)
condition|)
block|{
comment|// Reset the sleep multiplier, else it'd be reused for the next file
name|sleepMultiplier
operator|=
literal|1
expr_stmt|;
continue|continue;
block|}
comment|// If we got a null reader but didn't continue, then sleep and continue
if|if
condition|(
name|this
operator|.
name|reader
operator|==
literal|null
condition|)
block|{
if|if
condition|(
name|sleepForRetries
argument_list|(
literal|"Unable to open a reader"
argument_list|,
name|sleepMultiplier
argument_list|)
condition|)
block|{
name|sleepMultiplier
operator|++
expr_stmt|;
block|}
continue|continue;
block|}
name|boolean
name|gotIOE
init|=
literal|false
decl_stmt|;
name|currentNbEntries
operator|=
literal|0
expr_stmt|;
try|try
block|{
if|if
condition|(
name|readAllEntriesToReplicateOrNextFile
argument_list|()
condition|)
block|{
continue|continue;
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|ioe
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
name|peerClusterZnode
operator|+
literal|" Got: "
argument_list|,
name|ioe
argument_list|)
expr_stmt|;
name|gotIOE
operator|=
literal|true
expr_stmt|;
if|if
condition|(
name|ioe
operator|.
name|getCause
argument_list|()
operator|instanceof
name|EOFException
condition|)
block|{
name|boolean
name|considerDumping
init|=
literal|false
decl_stmt|;
if|if
condition|(
name|this
operator|.
name|queueRecovered
condition|)
block|{
try|try
block|{
name|FileStatus
name|stat
init|=
name|this
operator|.
name|fs
operator|.
name|getFileStatus
argument_list|(
name|this
operator|.
name|currentPath
argument_list|)
decl_stmt|;
if|if
condition|(
name|stat
operator|.
name|getLen
argument_list|()
operator|==
literal|0
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
name|peerClusterZnode
operator|+
literal|" Got EOF and the file was empty"
argument_list|)
expr_stmt|;
block|}
name|considerDumping
operator|=
literal|true
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
name|peerClusterZnode
operator|+
literal|" Got while getting file size: "
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
block|}
elseif|else
if|if
condition|(
name|currentNbEntries
operator|!=
literal|0
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
name|peerClusterZnode
operator|+
literal|" Got EOF while reading, "
operator|+
literal|"looks like this file is broken? "
operator|+
name|currentPath
argument_list|)
expr_stmt|;
name|considerDumping
operator|=
literal|true
expr_stmt|;
name|currentNbEntries
operator|=
literal|0
expr_stmt|;
block|}
if|if
condition|(
name|considerDumping
operator|&&
name|sleepMultiplier
operator|==
name|this
operator|.
name|maxRetriesMultiplier
operator|&&
name|processEndOfFile
argument_list|()
condition|)
block|{
continue|continue;
block|}
block|}
block|}
finally|finally
block|{
try|try
block|{
if|if
condition|(
name|this
operator|.
name|reader
operator|!=
literal|null
condition|)
block|{
name|this
operator|.
name|reader
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|gotIOE
operator|=
literal|true
expr_stmt|;
name|LOG
operator|.
name|warn
argument_list|(
literal|"Unable to finalize the tailing of a file"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
block|}
comment|// If we didn't get anything to replicate, or if we hit a IOE,
comment|// wait a bit and retry.
comment|// But if we need to stop, don't bother sleeping
if|if
condition|(
name|this
operator|.
name|isActive
argument_list|()
operator|&&
operator|(
name|gotIOE
operator|||
name|currentNbEntries
operator|==
literal|0
operator|)
condition|)
block|{
if|if
condition|(
name|this
operator|.
name|lastLoggedPosition
operator|!=
name|this
operator|.
name|position
condition|)
block|{
name|this
operator|.
name|manager
operator|.
name|logPositionAndCleanOldLogs
argument_list|(
name|this
operator|.
name|currentPath
argument_list|,
name|this
operator|.
name|peerClusterZnode
argument_list|,
name|this
operator|.
name|position
argument_list|,
name|queueRecovered
argument_list|)
expr_stmt|;
name|this
operator|.
name|lastLoggedPosition
operator|=
name|this
operator|.
name|position
expr_stmt|;
block|}
if|if
condition|(
name|sleepForRetries
argument_list|(
literal|"Nothing to replicate"
argument_list|,
name|sleepMultiplier
argument_list|)
condition|)
block|{
name|sleepMultiplier
operator|++
expr_stmt|;
block|}
continue|continue;
block|}
name|sleepMultiplier
operator|=
literal|1
expr_stmt|;
name|shipEdits
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|this
operator|.
name|conn
operator|!=
literal|null
condition|)
block|{
try|try
block|{
name|this
operator|.
name|conn
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Attempt to close connection failed"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
block|}
name|LOG
operator|.
name|debug
argument_list|(
literal|"Source exiting "
operator|+
name|peerId
argument_list|)
expr_stmt|;
name|metrics
operator|.
name|clear
argument_list|()
expr_stmt|;
block|}
comment|/**    * Read all the entries from the current log files and retain those    * that need to be replicated. Else, process the end of the current file.    * @return true if we got nothing and went to the next file, false if we got    * entries    * @throws IOException    */
specifier|protected
name|boolean
name|readAllEntriesToReplicateOrNextFile
parameter_list|()
throws|throws
name|IOException
block|{
name|long
name|seenEntries
init|=
literal|0
decl_stmt|;
if|if
condition|(
name|this
operator|.
name|position
operator|!=
literal|0
condition|)
block|{
name|this
operator|.
name|reader
operator|.
name|seek
argument_list|(
name|this
operator|.
name|position
argument_list|)
expr_stmt|;
block|}
name|long
name|startPosition
init|=
name|this
operator|.
name|position
decl_stmt|;
name|HLog
operator|.
name|Entry
name|entry
init|=
name|readNextAndSetPosition
argument_list|()
decl_stmt|;
while|while
condition|(
name|entry
operator|!=
literal|null
condition|)
block|{
name|WALEdit
name|edit
init|=
name|entry
operator|.
name|getEdit
argument_list|()
decl_stmt|;
name|this
operator|.
name|metrics
operator|.
name|incrLogEditsRead
argument_list|()
expr_stmt|;
name|seenEntries
operator|++
expr_stmt|;
comment|// Remove all KVs that should not be replicated
name|HLogKey
name|logKey
init|=
name|entry
operator|.
name|getKey
argument_list|()
decl_stmt|;
comment|// don't replicate if the log entries originated in the peer
if|if
condition|(
operator|!
name|logKey
operator|.
name|getClusterId
argument_list|()
operator|.
name|equals
argument_list|(
name|peerClusterId
argument_list|)
condition|)
block|{
name|removeNonReplicableEdits
argument_list|(
name|edit
argument_list|)
expr_stmt|;
comment|// Don't replicate catalog entries, if the WALEdit wasn't
comment|// containing anything to replicate and if we're currently not set to replicate
if|if
condition|(
operator|!
operator|(
name|Bytes
operator|.
name|equals
argument_list|(
name|logKey
operator|.
name|getTablename
argument_list|()
argument_list|,
name|HConstants
operator|.
name|ROOT_TABLE_NAME
argument_list|)
operator|||
name|Bytes
operator|.
name|equals
argument_list|(
name|logKey
operator|.
name|getTablename
argument_list|()
argument_list|,
name|HConstants
operator|.
name|META_TABLE_NAME
argument_list|)
operator|)
operator|&&
name|edit
operator|.
name|size
argument_list|()
operator|!=
literal|0
operator|&&
name|replicating
operator|.
name|get
argument_list|()
condition|)
block|{
comment|// Only set the clusterId if is a local key.
comment|// This ensures that the originator sets the cluster id
comment|// and all replicas retain the initial cluster id.
comment|// This is *only* place where a cluster id other than the default is set.
if|if
condition|(
name|HConstants
operator|.
name|DEFAULT_CLUSTER_ID
operator|==
name|logKey
operator|.
name|getClusterId
argument_list|()
condition|)
block|{
name|logKey
operator|.
name|setClusterId
argument_list|(
name|this
operator|.
name|clusterId
argument_list|)
expr_stmt|;
block|}
name|currentNbOperations
operator|+=
name|countDistinctRowKeys
argument_list|(
name|edit
argument_list|)
expr_stmt|;
name|currentNbEntries
operator|++
expr_stmt|;
block|}
else|else
block|{
name|this
operator|.
name|metrics
operator|.
name|incrLogEditsFiltered
argument_list|()
expr_stmt|;
block|}
block|}
comment|// Stop if too many entries or too big
if|if
condition|(
operator|(
name|this
operator|.
name|reader
operator|.
name|getPosition
argument_list|()
operator|-
name|startPosition
operator|)
operator|>=
name|this
operator|.
name|replicationQueueSizeCapacity
operator|||
name|currentNbEntries
operator|>=
name|this
operator|.
name|replicationQueueNbCapacity
condition|)
block|{
break|break;
block|}
try|try
block|{
name|entry
operator|=
name|readNextAndSetPosition
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ie
parameter_list|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Break on IOE: "
operator|+
name|ie
operator|.
name|getMessage
argument_list|()
argument_list|)
expr_stmt|;
break|break;
block|}
block|}
name|LOG
operator|.
name|debug
argument_list|(
literal|"currentNbOperations:"
operator|+
name|currentNbOperations
operator|+
literal|" and seenEntries:"
operator|+
name|seenEntries
operator|+
literal|" and size: "
operator|+
operator|(
name|this
operator|.
name|reader
operator|.
name|getPosition
argument_list|()
operator|-
name|startPosition
operator|)
argument_list|)
expr_stmt|;
comment|// If we didn't get anything and the queue has an object, it means we
comment|// hit the end of the file for sure
return|return
name|seenEntries
operator|==
literal|0
operator|&&
name|processEndOfFile
argument_list|()
return|;
block|}
specifier|private
name|HLog
operator|.
name|Entry
name|readNextAndSetPosition
parameter_list|()
throws|throws
name|IOException
block|{
name|HLog
operator|.
name|Entry
name|entry
init|=
name|this
operator|.
name|reader
operator|.
name|next
argument_list|(
name|entriesArray
index|[
name|currentNbEntries
index|]
argument_list|)
decl_stmt|;
comment|// Store the position so that in the future the reader can start
comment|// reading from here. If the above call to next() throws an
comment|// exception, the position won't be changed and retry will happen
comment|// from the last known good position
name|this
operator|.
name|position
operator|=
name|this
operator|.
name|reader
operator|.
name|getPosition
argument_list|()
expr_stmt|;
return|return
name|entry
return|;
block|}
specifier|private
name|void
name|connectToPeers
parameter_list|()
block|{
comment|// Connect to peer cluster first, unless we have to stop
while|while
condition|(
name|this
operator|.
name|isActive
argument_list|()
operator|&&
name|this
operator|.
name|currentPeers
operator|.
name|size
argument_list|()
operator|==
literal|0
condition|)
block|{
try|try
block|{
name|chooseSinks
argument_list|()
expr_stmt|;
name|Thread
operator|.
name|sleep
argument_list|(
name|this
operator|.
name|sleepForRetries
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Interrupted while trying to connect to sinks"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|/**    * Poll for the next path    * @return true if a path was obtained, false if not    */
specifier|protected
name|boolean
name|getNextPath
parameter_list|()
block|{
try|try
block|{
if|if
condition|(
name|this
operator|.
name|currentPath
operator|==
literal|null
condition|)
block|{
name|this
operator|.
name|currentPath
operator|=
name|queue
operator|.
name|poll
argument_list|(
name|this
operator|.
name|sleepForRetries
argument_list|,
name|TimeUnit
operator|.
name|MILLISECONDS
argument_list|)
expr_stmt|;
name|this
operator|.
name|metrics
operator|.
name|setSizeOfLogQueue
argument_list|(
name|queue
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Interrupted while reading edits"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
return|return
name|this
operator|.
name|currentPath
operator|!=
literal|null
return|;
block|}
comment|/**    * Open a reader on the current path    *    * @param sleepMultiplier by how many times the default sleeping time is augmented    * @return true if we should continue with that file, false if we are over with it    */
specifier|protected
name|boolean
name|openReader
parameter_list|(
name|int
name|sleepMultiplier
parameter_list|)
block|{
try|try
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Opening log for replication "
operator|+
name|this
operator|.
name|currentPath
operator|.
name|getName
argument_list|()
operator|+
literal|" at "
operator|+
name|this
operator|.
name|position
argument_list|)
expr_stmt|;
try|try
block|{
name|this
operator|.
name|reader
operator|=
literal|null
expr_stmt|;
name|this
operator|.
name|reader
operator|=
name|HLogFactory
operator|.
name|createReader
argument_list|(
name|this
operator|.
name|fs
argument_list|,
name|this
operator|.
name|currentPath
argument_list|,
name|this
operator|.
name|conf
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|FileNotFoundException
name|fnfe
parameter_list|)
block|{
if|if
condition|(
name|this
operator|.
name|queueRecovered
condition|)
block|{
comment|// We didn't find the log in the archive directory, look if it still
comment|// exists in the dead RS folder (there could be a chain of failures
comment|// to look at)
name|LOG
operator|.
name|info
argument_list|(
literal|"NB dead servers : "
operator|+
name|deadRegionServers
operator|.
name|length
argument_list|)
expr_stmt|;
for|for
control|(
name|int
name|i
init|=
name|this
operator|.
name|deadRegionServers
operator|.
name|length
operator|-
literal|1
init|;
name|i
operator|>=
literal|0
condition|;
name|i
operator|--
control|)
block|{
name|Path
name|deadRsDirectory
init|=
operator|new
name|Path
argument_list|(
name|manager
operator|.
name|getLogDir
argument_list|()
operator|.
name|getParent
argument_list|()
argument_list|,
name|this
operator|.
name|deadRegionServers
index|[
name|i
index|]
argument_list|)
decl_stmt|;
name|Path
index|[]
name|locs
init|=
operator|new
name|Path
index|[]
block|{
operator|new
name|Path
argument_list|(
name|deadRsDirectory
argument_list|,
name|currentPath
operator|.
name|getName
argument_list|()
argument_list|)
block|,
operator|new
name|Path
argument_list|(
name|deadRsDirectory
operator|.
name|suffix
argument_list|(
name|HLog
operator|.
name|SPLITTING_EXT
argument_list|)
argument_list|,
name|currentPath
operator|.
name|getName
argument_list|()
argument_list|)
block|,             }
decl_stmt|;
for|for
control|(
name|Path
name|possibleLogLocation
range|:
name|locs
control|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Possible location "
operator|+
name|possibleLogLocation
operator|.
name|toUri
argument_list|()
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|this
operator|.
name|manager
operator|.
name|getFs
argument_list|()
operator|.
name|exists
argument_list|(
name|possibleLogLocation
argument_list|)
condition|)
block|{
comment|// We found the right new location
name|LOG
operator|.
name|info
argument_list|(
literal|"Log "
operator|+
name|this
operator|.
name|currentPath
operator|+
literal|" still exists at "
operator|+
name|possibleLogLocation
argument_list|)
expr_stmt|;
comment|// Breaking here will make us sleep since reader is null
return|return
literal|true
return|;
block|}
block|}
block|}
comment|// TODO What happens if the log was missing from every single location?
comment|// Although we need to check a couple of times as the log could have
comment|// been moved by the master between the checks
comment|// It can also happen if a recovered queue wasn't properly cleaned,
comment|// such that the znode pointing to a log exists but the log was
comment|// deleted a long time ago.
comment|// For the moment, we'll throw the IO and processEndOfFile
throw|throw
operator|new
name|IOException
argument_list|(
literal|"File from recovered queue is "
operator|+
literal|"nowhere to be found"
argument_list|,
name|fnfe
argument_list|)
throw|;
block|}
else|else
block|{
comment|// If the log was archived, continue reading from there
name|Path
name|archivedLogLocation
init|=
operator|new
name|Path
argument_list|(
name|manager
operator|.
name|getOldLogDir
argument_list|()
argument_list|,
name|currentPath
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|this
operator|.
name|manager
operator|.
name|getFs
argument_list|()
operator|.
name|exists
argument_list|(
name|archivedLogLocation
argument_list|)
condition|)
block|{
name|currentPath
operator|=
name|archivedLogLocation
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Log "
operator|+
name|this
operator|.
name|currentPath
operator|+
literal|" was moved to "
operator|+
name|archivedLogLocation
argument_list|)
expr_stmt|;
comment|// Open the log at the new location
name|this
operator|.
name|openReader
argument_list|(
name|sleepMultiplier
argument_list|)
expr_stmt|;
block|}
comment|// TODO What happens the log is missing in both places?
block|}
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|ioe
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
name|peerClusterZnode
operator|+
literal|" Got: "
argument_list|,
name|ioe
argument_list|)
expr_stmt|;
comment|// TODO Need a better way to determinate if a file is really gone but
comment|// TODO without scanning all logs dir
if|if
condition|(
name|sleepMultiplier
operator|==
name|this
operator|.
name|maxRetriesMultiplier
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Waited too long for this file, considering dumping"
argument_list|)
expr_stmt|;
return|return
operator|!
name|processEndOfFile
argument_list|()
return|;
block|}
block|}
return|return
literal|true
return|;
block|}
comment|/**    * Do the sleeping logic    * @param msg Why we sleep    * @param sleepMultiplier by how many times the default sleeping time is augmented    * @return True if<code>sleepMultiplier</code> is&lt;<code>maxRetriesMultiplier</code>    */
specifier|protected
name|boolean
name|sleepForRetries
parameter_list|(
name|String
name|msg
parameter_list|,
name|int
name|sleepMultiplier
parameter_list|)
block|{
try|try
block|{
name|LOG
operator|.
name|debug
argument_list|(
name|msg
operator|+
literal|", sleeping "
operator|+
name|sleepForRetries
operator|+
literal|" times "
operator|+
name|sleepMultiplier
argument_list|)
expr_stmt|;
name|Thread
operator|.
name|sleep
argument_list|(
name|this
operator|.
name|sleepForRetries
operator|*
name|sleepMultiplier
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Interrupted while sleeping between retries"
argument_list|)
expr_stmt|;
block|}
return|return
name|sleepMultiplier
operator|<
name|maxRetriesMultiplier
return|;
block|}
comment|/**    * We only want KVs that are scoped other than local    * @param edit The KV to check for replication    */
specifier|protected
name|void
name|removeNonReplicableEdits
parameter_list|(
name|WALEdit
name|edit
parameter_list|)
block|{
name|NavigableMap
argument_list|<
name|byte
index|[]
argument_list|,
name|Integer
argument_list|>
name|scopes
init|=
name|edit
operator|.
name|getScopes
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|KeyValue
argument_list|>
name|kvs
init|=
name|edit
operator|.
name|getKeyValues
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
name|edit
operator|.
name|size
argument_list|()
operator|-
literal|1
init|;
name|i
operator|>=
literal|0
condition|;
name|i
operator|--
control|)
block|{
name|KeyValue
name|kv
init|=
name|kvs
operator|.
name|get
argument_list|(
name|i
argument_list|)
decl_stmt|;
comment|// The scope will be null or empty if
comment|// there's nothing to replicate in that WALEdit
if|if
condition|(
name|scopes
operator|==
literal|null
operator|||
operator|!
name|scopes
operator|.
name|containsKey
argument_list|(
name|kv
operator|.
name|getFamily
argument_list|()
argument_list|)
condition|)
block|{
name|kvs
operator|.
name|remove
argument_list|(
name|i
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|/**    * Count the number of different row keys in the given edit because of    * mini-batching. We assume that there's at least one KV in the WALEdit.    * @param edit edit to count row keys from    * @return number of different row keys    */
specifier|private
name|int
name|countDistinctRowKeys
parameter_list|(
name|WALEdit
name|edit
parameter_list|)
block|{
name|List
argument_list|<
name|KeyValue
argument_list|>
name|kvs
init|=
name|edit
operator|.
name|getKeyValues
argument_list|()
decl_stmt|;
name|int
name|distinctRowKeys
init|=
literal|1
decl_stmt|;
name|KeyValue
name|lastKV
init|=
name|kvs
operator|.
name|get
argument_list|(
literal|0
argument_list|)
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|edit
operator|.
name|size
argument_list|()
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
operator|!
name|kvs
operator|.
name|get
argument_list|(
name|i
argument_list|)
operator|.
name|matchingRow
argument_list|(
name|lastKV
argument_list|)
condition|)
block|{
name|distinctRowKeys
operator|++
expr_stmt|;
block|}
block|}
return|return
name|distinctRowKeys
return|;
block|}
comment|/**    * Do the shipping logic    */
specifier|protected
name|void
name|shipEdits
parameter_list|()
block|{
name|int
name|sleepMultiplier
init|=
literal|1
decl_stmt|;
if|if
condition|(
name|this
operator|.
name|currentNbEntries
operator|==
literal|0
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Was given 0 edits to ship"
argument_list|)
expr_stmt|;
return|return;
block|}
while|while
condition|(
name|this
operator|.
name|isActive
argument_list|()
condition|)
block|{
if|if
condition|(
operator|!
name|isPeerEnabled
argument_list|()
condition|)
block|{
if|if
condition|(
name|sleepForRetries
argument_list|(
literal|"Replication is disabled"
argument_list|,
name|sleepMultiplier
argument_list|)
condition|)
block|{
name|sleepMultiplier
operator|++
expr_stmt|;
block|}
continue|continue;
block|}
try|try
block|{
name|AdminProtocol
name|rrs
init|=
name|getRS
argument_list|()
decl_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Replicating "
operator|+
name|currentNbEntries
argument_list|)
expr_stmt|;
name|ProtobufUtil
operator|.
name|replicateWALEntry
argument_list|(
name|rrs
argument_list|,
name|Arrays
operator|.
name|copyOf
argument_list|(
name|this
operator|.
name|entriesArray
argument_list|,
name|currentNbEntries
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|this
operator|.
name|lastLoggedPosition
operator|!=
name|this
operator|.
name|position
condition|)
block|{
name|this
operator|.
name|manager
operator|.
name|logPositionAndCleanOldLogs
argument_list|(
name|this
operator|.
name|currentPath
argument_list|,
name|this
operator|.
name|peerClusterZnode
argument_list|,
name|this
operator|.
name|position
argument_list|,
name|queueRecovered
argument_list|)
expr_stmt|;
name|this
operator|.
name|lastLoggedPosition
operator|=
name|this
operator|.
name|position
expr_stmt|;
block|}
name|this
operator|.
name|totalReplicatedEdits
operator|+=
name|currentNbEntries
expr_stmt|;
name|this
operator|.
name|metrics
operator|.
name|shipBatch
argument_list|(
name|this
operator|.
name|currentNbOperations
argument_list|)
expr_stmt|;
name|this
operator|.
name|metrics
operator|.
name|setAgeOfLastShippedOp
argument_list|(
name|this
operator|.
name|entriesArray
index|[
name|currentNbEntries
operator|-
literal|1
index|]
operator|.
name|getKey
argument_list|()
operator|.
name|getWriteTime
argument_list|()
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Replicated in total: "
operator|+
name|this
operator|.
name|totalReplicatedEdits
argument_list|)
expr_stmt|;
break|break;
block|}
catch|catch
parameter_list|(
name|IOException
name|ioe
parameter_list|)
block|{
comment|// Didn't ship anything, but must still age the last time we did
name|this
operator|.
name|metrics
operator|.
name|refreshAgeOfLastShippedOp
argument_list|()
expr_stmt|;
if|if
condition|(
name|ioe
operator|instanceof
name|RemoteException
condition|)
block|{
name|ioe
operator|=
operator|(
operator|(
name|RemoteException
operator|)
name|ioe
operator|)
operator|.
name|unwrapRemoteException
argument_list|()
expr_stmt|;
name|LOG
operator|.
name|warn
argument_list|(
literal|"Can't replicate because of an error on the remote cluster: "
argument_list|,
name|ioe
argument_list|)
expr_stmt|;
block|}
else|else
block|{
if|if
condition|(
name|ioe
operator|instanceof
name|SocketTimeoutException
condition|)
block|{
comment|// This exception means we waited for more than 60s and nothing
comment|// happened, the cluster is alive and calling it right away
comment|// even for a test just makes things worse.
name|sleepForRetries
argument_list|(
literal|"Encountered a SocketTimeoutException. Since the "
operator|+
literal|"call to the remote cluster timed out, which is usually "
operator|+
literal|"caused by a machine failure or a massive slowdown"
argument_list|,
name|this
operator|.
name|socketTimeoutMultiplier
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Can't replicate because of a local or network error: "
argument_list|,
name|ioe
argument_list|)
expr_stmt|;
block|}
block|}
try|try
block|{
name|boolean
name|down
decl_stmt|;
comment|// Spin while the slave is down and we're not asked to shutdown/close
do|do
block|{
name|down
operator|=
name|isSlaveDown
argument_list|()
expr_stmt|;
if|if
condition|(
name|down
condition|)
block|{
if|if
condition|(
name|sleepForRetries
argument_list|(
literal|"Since we are unable to replicate"
argument_list|,
name|sleepMultiplier
argument_list|)
condition|)
block|{
name|sleepMultiplier
operator|++
expr_stmt|;
block|}
else|else
block|{
name|chooseSinks
argument_list|()
expr_stmt|;
block|}
block|}
block|}
do|while
condition|(
name|this
operator|.
name|isActive
argument_list|()
operator|&&
name|down
condition|)
do|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Interrupted while trying to contact the peer cluster"
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
comment|/**    * check whether the peer is enabled or not    *    * @return true if the peer is enabled, otherwise false    */
specifier|protected
name|boolean
name|isPeerEnabled
parameter_list|()
block|{
return|return
name|this
operator|.
name|replicating
operator|.
name|get
argument_list|()
operator|&&
name|this
operator|.
name|zkHelper
operator|.
name|getPeerEnabled
argument_list|(
name|peerId
argument_list|)
return|;
block|}
comment|/**    * If the queue isn't empty, switch to the next one    * Else if this is a recovered queue, it means we're done!    * Else we'll just continue to try reading the log file    * @return true if we're done with the current file, false if we should    * continue trying to read from it    */
specifier|protected
name|boolean
name|processEndOfFile
parameter_list|()
block|{
if|if
condition|(
name|this
operator|.
name|queue
operator|.
name|size
argument_list|()
operator|!=
literal|0
condition|)
block|{
name|this
operator|.
name|currentPath
operator|=
literal|null
expr_stmt|;
name|this
operator|.
name|position
operator|=
literal|0
expr_stmt|;
return|return
literal|true
return|;
block|}
elseif|else
if|if
condition|(
name|this
operator|.
name|queueRecovered
condition|)
block|{
name|this
operator|.
name|manager
operator|.
name|closeRecoveredQueue
argument_list|(
name|this
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Finished recovering the queue"
argument_list|)
expr_stmt|;
name|this
operator|.
name|running
operator|=
literal|false
expr_stmt|;
return|return
literal|true
return|;
block|}
return|return
literal|false
return|;
block|}
specifier|public
name|void
name|startup
parameter_list|()
block|{
name|String
name|n
init|=
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|getName
argument_list|()
decl_stmt|;
name|Thread
operator|.
name|UncaughtExceptionHandler
name|handler
init|=
operator|new
name|Thread
operator|.
name|UncaughtExceptionHandler
argument_list|()
block|{
specifier|public
name|void
name|uncaughtException
parameter_list|(
specifier|final
name|Thread
name|t
parameter_list|,
specifier|final
name|Throwable
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Unexpected exception in ReplicationSource,"
operator|+
literal|" currentPath="
operator|+
name|currentPath
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
block|}
decl_stmt|;
name|Threads
operator|.
name|setDaemonThreadRunning
argument_list|(
name|this
argument_list|,
name|n
operator|+
literal|".replicationSource,"
operator|+
name|peerClusterZnode
argument_list|,
name|handler
argument_list|)
expr_stmt|;
block|}
specifier|public
name|void
name|terminate
parameter_list|(
name|String
name|reason
parameter_list|)
block|{
name|terminate
argument_list|(
name|reason
argument_list|,
literal|null
argument_list|)
expr_stmt|;
block|}
specifier|public
name|void
name|terminate
parameter_list|(
name|String
name|reason
parameter_list|,
name|Exception
name|cause
parameter_list|)
block|{
if|if
condition|(
name|cause
operator|==
literal|null
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Closing source "
operator|+
name|this
operator|.
name|peerClusterZnode
operator|+
literal|" because: "
operator|+
name|reason
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Closing source "
operator|+
name|this
operator|.
name|peerClusterZnode
operator|+
literal|" because an error occurred: "
operator|+
name|reason
argument_list|,
name|cause
argument_list|)
expr_stmt|;
block|}
name|this
operator|.
name|running
operator|=
literal|false
expr_stmt|;
name|Threads
operator|.
name|shutdown
argument_list|(
name|this
argument_list|,
name|this
operator|.
name|sleepForRetries
argument_list|)
expr_stmt|;
block|}
comment|/**    * Get a new region server at random from this peer    * @return    * @throws IOException    */
specifier|private
name|AdminProtocol
name|getRS
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|this
operator|.
name|currentPeers
operator|.
name|size
argument_list|()
operator|==
literal|0
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|this
operator|.
name|peerClusterZnode
operator|+
literal|" has 0 region servers"
argument_list|)
throw|;
block|}
name|ServerName
name|address
init|=
name|currentPeers
operator|.
name|get
argument_list|(
name|random
operator|.
name|nextInt
argument_list|(
name|this
operator|.
name|currentPeers
operator|.
name|size
argument_list|()
argument_list|)
argument_list|)
decl_stmt|;
return|return
name|this
operator|.
name|conn
operator|.
name|getAdmin
argument_list|(
name|address
operator|.
name|getHostname
argument_list|()
argument_list|,
name|address
operator|.
name|getPort
argument_list|()
argument_list|)
return|;
block|}
comment|/**    * Check if the slave is down by trying to establish a connection    * @return true if down, false if up    * @throws InterruptedException    */
specifier|public
name|boolean
name|isSlaveDown
parameter_list|()
throws|throws
name|InterruptedException
block|{
specifier|final
name|CountDownLatch
name|latch
init|=
operator|new
name|CountDownLatch
argument_list|(
literal|1
argument_list|)
decl_stmt|;
name|Thread
name|pingThread
init|=
operator|new
name|Thread
argument_list|()
block|{
specifier|public
name|void
name|run
parameter_list|()
block|{
try|try
block|{
name|AdminProtocol
name|rrs
init|=
name|getRS
argument_list|()
decl_stmt|;
comment|// Dummy call which should fail
name|ProtobufUtil
operator|.
name|getServerInfo
argument_list|(
name|rrs
argument_list|)
expr_stmt|;
name|latch
operator|.
name|countDown
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ex
parameter_list|)
block|{
if|if
condition|(
name|ex
operator|instanceof
name|RemoteException
condition|)
block|{
name|ex
operator|=
operator|(
operator|(
name|RemoteException
operator|)
name|ex
operator|)
operator|.
name|unwrapRemoteException
argument_list|()
expr_stmt|;
block|}
name|LOG
operator|.
name|info
argument_list|(
literal|"Slave cluster looks down: "
operator|+
name|ex
operator|.
name|getMessage
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
block|}
decl_stmt|;
name|pingThread
operator|.
name|start
argument_list|()
expr_stmt|;
comment|// awaits returns true if countDown happened
name|boolean
name|down
init|=
operator|!
name|latch
operator|.
name|await
argument_list|(
name|this
operator|.
name|sleepForRetries
argument_list|,
name|TimeUnit
operator|.
name|MILLISECONDS
argument_list|)
decl_stmt|;
name|pingThread
operator|.
name|interrupt
argument_list|()
expr_stmt|;
return|return
name|down
return|;
block|}
specifier|public
name|String
name|getPeerClusterZnode
parameter_list|()
block|{
return|return
name|this
operator|.
name|peerClusterZnode
return|;
block|}
specifier|public
name|String
name|getPeerClusterId
parameter_list|()
block|{
return|return
name|this
operator|.
name|peerId
return|;
block|}
specifier|public
name|Path
name|getCurrentPath
parameter_list|()
block|{
return|return
name|this
operator|.
name|currentPath
return|;
block|}
specifier|private
name|boolean
name|isActive
parameter_list|()
block|{
return|return
operator|!
name|this
operator|.
name|stopper
operator|.
name|isStopped
argument_list|()
operator|&&
name|this
operator|.
name|running
return|;
block|}
comment|/**    * Comparator used to compare logs together based on their start time    */
specifier|public
specifier|static
class|class
name|LogsComparator
implements|implements
name|Comparator
argument_list|<
name|Path
argument_list|>
block|{
annotation|@
name|Override
specifier|public
name|int
name|compare
parameter_list|(
name|Path
name|o1
parameter_list|,
name|Path
name|o2
parameter_list|)
block|{
return|return
name|Long
operator|.
name|valueOf
argument_list|(
name|getTS
argument_list|(
name|o1
argument_list|)
argument_list|)
operator|.
name|compareTo
argument_list|(
name|getTS
argument_list|(
name|o2
argument_list|)
argument_list|)
return|;
block|}
comment|/**      * Split a path to get the start time      * For example: 10.20.20.171%3A60020.1277499063250      * @param p path to split      * @return start time      */
specifier|private
name|long
name|getTS
parameter_list|(
name|Path
name|p
parameter_list|)
block|{
name|String
index|[]
name|parts
init|=
name|p
operator|.
name|getName
argument_list|()
operator|.
name|split
argument_list|(
literal|"\\."
argument_list|)
decl_stmt|;
return|return
name|Long
operator|.
name|parseLong
argument_list|(
name|parts
index|[
name|parts
operator|.
name|length
operator|-
literal|1
index|]
argument_list|)
return|;
block|}
block|}
block|}
end_class

end_unit

