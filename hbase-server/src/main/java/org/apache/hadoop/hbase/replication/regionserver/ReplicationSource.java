begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/*  *  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|replication
operator|.
name|regionserver
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|EOFException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|FileNotFoundException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Comparator
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|UUID
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|PriorityBlockingQueue
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|TimeUnit
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|lang
operator|.
name|StringUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|Log
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|LogFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|classification
operator|.
name|InterfaceAudience
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileStatus
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|Cell
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|CellUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HBaseConfiguration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HConstants
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|Stoppable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|wal
operator|.
name|HLog
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|wal
operator|.
name|HLogKey
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|wal
operator|.
name|WALEdit
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|replication
operator|.
name|ChainWALEntryFilter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|replication
operator|.
name|ReplicationEndpoint
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|replication
operator|.
name|ReplicationException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|replication
operator|.
name|ReplicationPeers
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|replication
operator|.
name|ReplicationQueueInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|replication
operator|.
name|ReplicationQueues
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|replication
operator|.
name|SystemTableWALEntryFilter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|replication
operator|.
name|WALEntryFilter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|Threads
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|Lists
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ListenableFuture
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|util
operator|.
name|concurrent
operator|.
name|Service
import|;
end_import

begin_comment
comment|/**  * Class that handles the source of a replication stream.  * Currently does not handle more than 1 slave  * For each slave cluster it selects a random number of peers  * using a replication ratio. For example, if replication ration = 0.1  * and slave cluster has 100 region servers, 10 will be selected.  *<p/>  * A stream is considered down when we cannot contact a region server on the  * peer cluster for more than 55 seconds by default.  *<p/>  *  */
end_comment

begin_class
annotation|@
name|InterfaceAudience
operator|.
name|Private
specifier|public
class|class
name|ReplicationSource
extends|extends
name|Thread
implements|implements
name|ReplicationSourceInterface
block|{
specifier|public
specifier|static
specifier|final
name|Log
name|LOG
init|=
name|LogFactory
operator|.
name|getLog
argument_list|(
name|ReplicationSource
operator|.
name|class
argument_list|)
decl_stmt|;
comment|// Queue of logs to process
specifier|private
name|PriorityBlockingQueue
argument_list|<
name|Path
argument_list|>
name|queue
decl_stmt|;
specifier|private
name|ReplicationQueues
name|replicationQueues
decl_stmt|;
specifier|private
name|ReplicationPeers
name|replicationPeers
decl_stmt|;
specifier|private
name|Configuration
name|conf
decl_stmt|;
specifier|private
name|ReplicationQueueInfo
name|replicationQueueInfo
decl_stmt|;
comment|// id of the peer cluster this source replicates to
specifier|private
name|String
name|peerId
decl_stmt|;
comment|// The manager of all sources to which we ping back our progress
specifier|private
name|ReplicationSourceManager
name|manager
decl_stmt|;
comment|// Should we stop everything?
specifier|private
name|Stoppable
name|stopper
decl_stmt|;
comment|// How long should we sleep for each retry
specifier|private
name|long
name|sleepForRetries
decl_stmt|;
comment|// Max size in bytes of entriesArray
specifier|private
name|long
name|replicationQueueSizeCapacity
decl_stmt|;
comment|// Max number of entries in entriesArray
specifier|private
name|int
name|replicationQueueNbCapacity
decl_stmt|;
comment|// Our reader for the current log
specifier|private
name|HLog
operator|.
name|Reader
name|reader
decl_stmt|;
comment|// Last position in the log that we sent to ZooKeeper
specifier|private
name|long
name|lastLoggedPosition
init|=
operator|-
literal|1
decl_stmt|;
comment|// Path of the current log
specifier|private
specifier|volatile
name|Path
name|currentPath
decl_stmt|;
specifier|private
name|FileSystem
name|fs
decl_stmt|;
comment|// id of this cluster
specifier|private
name|UUID
name|clusterId
decl_stmt|;
comment|// id of the other cluster
specifier|private
name|UUID
name|peerClusterId
decl_stmt|;
comment|// total number of edits we replicated
specifier|private
name|long
name|totalReplicatedEdits
init|=
literal|0
decl_stmt|;
comment|// total number of edits we replicated
specifier|private
name|long
name|totalReplicatedOperations
init|=
literal|0
decl_stmt|;
comment|// The znode we currently play with
specifier|private
name|String
name|peerClusterZnode
decl_stmt|;
comment|// Maximum number of retries before taking bold actions
specifier|private
name|int
name|maxRetriesMultiplier
decl_stmt|;
comment|// Current number of operations (Put/Delete) that we need to replicate
specifier|private
name|int
name|currentNbOperations
init|=
literal|0
decl_stmt|;
comment|// Current size of data we need to replicate
specifier|private
name|int
name|currentSize
init|=
literal|0
decl_stmt|;
comment|// Indicates if this particular source is running
specifier|private
specifier|volatile
name|boolean
name|running
init|=
literal|true
decl_stmt|;
comment|// Metrics for this source
specifier|private
name|MetricsSource
name|metrics
decl_stmt|;
comment|// Handle on the log reader helper
specifier|private
name|ReplicationHLogReaderManager
name|repLogReader
decl_stmt|;
comment|//WARN threshold for the number of queued logs, defaults to 2
specifier|private
name|int
name|logQueueWarnThreshold
decl_stmt|;
comment|// ReplicationEndpoint which will handle the actual replication
specifier|private
name|ReplicationEndpoint
name|replicationEndpoint
decl_stmt|;
comment|// A filter (or a chain of filters) for the WAL entries.
specifier|private
name|WALEntryFilter
name|walEntryFilter
decl_stmt|;
comment|// Context for ReplicationEndpoint#replicate()
specifier|private
name|ReplicationEndpoint
operator|.
name|ReplicateContext
name|replicateContext
decl_stmt|;
comment|// throttler
specifier|private
name|ReplicationThrottler
name|throttler
decl_stmt|;
comment|/**    * Instantiation method used by region servers    *    * @param conf configuration to use    * @param fs file system to use    * @param manager replication manager to ping to    * @param stopper     the atomic boolean to use to stop the regionserver    * @param peerClusterZnode the name of our znode    * @param clusterId unique UUID for the cluster    * @param replicationEndpoint the replication endpoint implementation    * @param metrics metrics for replication source    * @throws IOException    */
annotation|@
name|Override
specifier|public
name|void
name|init
parameter_list|(
specifier|final
name|Configuration
name|conf
parameter_list|,
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|ReplicationSourceManager
name|manager
parameter_list|,
specifier|final
name|ReplicationQueues
name|replicationQueues
parameter_list|,
specifier|final
name|ReplicationPeers
name|replicationPeers
parameter_list|,
specifier|final
name|Stoppable
name|stopper
parameter_list|,
specifier|final
name|String
name|peerClusterZnode
parameter_list|,
specifier|final
name|UUID
name|clusterId
parameter_list|,
name|ReplicationEndpoint
name|replicationEndpoint
parameter_list|,
specifier|final
name|MetricsSource
name|metrics
parameter_list|)
throws|throws
name|IOException
block|{
name|this
operator|.
name|stopper
operator|=
name|stopper
expr_stmt|;
name|this
operator|.
name|conf
operator|=
name|HBaseConfiguration
operator|.
name|create
argument_list|(
name|conf
argument_list|)
expr_stmt|;
name|decorateConf
argument_list|()
expr_stmt|;
name|this
operator|.
name|replicationQueueSizeCapacity
operator|=
name|this
operator|.
name|conf
operator|.
name|getLong
argument_list|(
literal|"replication.source.size.capacity"
argument_list|,
literal|1024
operator|*
literal|1024
operator|*
literal|64
argument_list|)
expr_stmt|;
name|this
operator|.
name|replicationQueueNbCapacity
operator|=
name|this
operator|.
name|conf
operator|.
name|getInt
argument_list|(
literal|"replication.source.nb.capacity"
argument_list|,
literal|25000
argument_list|)
expr_stmt|;
name|this
operator|.
name|maxRetriesMultiplier
operator|=
name|this
operator|.
name|conf
operator|.
name|getInt
argument_list|(
literal|"replication.source.maxretriesmultiplier"
argument_list|,
literal|10
argument_list|)
expr_stmt|;
name|this
operator|.
name|queue
operator|=
operator|new
name|PriorityBlockingQueue
argument_list|<
name|Path
argument_list|>
argument_list|(
name|this
operator|.
name|conf
operator|.
name|getInt
argument_list|(
literal|"hbase.regionserver.maxlogs"
argument_list|,
literal|32
argument_list|)
argument_list|,
operator|new
name|LogsComparator
argument_list|()
argument_list|)
expr_stmt|;
name|long
name|bandwidth
init|=
name|this
operator|.
name|conf
operator|.
name|getLong
argument_list|(
literal|"replication.source.per.peer.node.bandwidth"
argument_list|,
literal|0
argument_list|)
decl_stmt|;
name|this
operator|.
name|throttler
operator|=
operator|new
name|ReplicationThrottler
argument_list|(
operator|(
name|double
operator|)
name|bandwidth
operator|/
literal|10.0
argument_list|)
expr_stmt|;
name|this
operator|.
name|replicationQueues
operator|=
name|replicationQueues
expr_stmt|;
name|this
operator|.
name|replicationPeers
operator|=
name|replicationPeers
expr_stmt|;
name|this
operator|.
name|manager
operator|=
name|manager
expr_stmt|;
name|this
operator|.
name|sleepForRetries
operator|=
name|this
operator|.
name|conf
operator|.
name|getLong
argument_list|(
literal|"replication.source.sleepforretries"
argument_list|,
literal|1000
argument_list|)
expr_stmt|;
name|this
operator|.
name|fs
operator|=
name|fs
expr_stmt|;
name|this
operator|.
name|metrics
operator|=
name|metrics
expr_stmt|;
name|this
operator|.
name|repLogReader
operator|=
operator|new
name|ReplicationHLogReaderManager
argument_list|(
name|this
operator|.
name|fs
argument_list|,
name|this
operator|.
name|conf
argument_list|)
expr_stmt|;
name|this
operator|.
name|clusterId
operator|=
name|clusterId
expr_stmt|;
name|this
operator|.
name|peerClusterZnode
operator|=
name|peerClusterZnode
expr_stmt|;
name|this
operator|.
name|replicationQueueInfo
operator|=
operator|new
name|ReplicationQueueInfo
argument_list|(
name|peerClusterZnode
argument_list|)
expr_stmt|;
comment|// ReplicationQueueInfo parses the peerId out of the znode for us
name|this
operator|.
name|peerId
operator|=
name|this
operator|.
name|replicationQueueInfo
operator|.
name|getPeerId
argument_list|()
expr_stmt|;
name|this
operator|.
name|logQueueWarnThreshold
operator|=
name|this
operator|.
name|conf
operator|.
name|getInt
argument_list|(
literal|"replication.source.log.queue.warn"
argument_list|,
literal|2
argument_list|)
expr_stmt|;
name|this
operator|.
name|replicationEndpoint
operator|=
name|replicationEndpoint
expr_stmt|;
name|this
operator|.
name|replicateContext
operator|=
operator|new
name|ReplicationEndpoint
operator|.
name|ReplicateContext
argument_list|()
expr_stmt|;
block|}
specifier|private
name|void
name|decorateConf
parameter_list|()
block|{
name|String
name|replicationCodec
init|=
name|this
operator|.
name|conf
operator|.
name|get
argument_list|(
name|HConstants
operator|.
name|REPLICATION_CODEC_CONF_KEY
argument_list|)
decl_stmt|;
if|if
condition|(
name|StringUtils
operator|.
name|isNotEmpty
argument_list|(
name|replicationCodec
argument_list|)
condition|)
block|{
name|this
operator|.
name|conf
operator|.
name|set
argument_list|(
name|HConstants
operator|.
name|RPC_CODEC_CONF_KEY
argument_list|,
name|replicationCodec
argument_list|)
expr_stmt|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|void
name|enqueueLog
parameter_list|(
name|Path
name|log
parameter_list|)
block|{
name|this
operator|.
name|queue
operator|.
name|put
argument_list|(
name|log
argument_list|)
expr_stmt|;
name|int
name|queueSize
init|=
name|queue
operator|.
name|size
argument_list|()
decl_stmt|;
name|this
operator|.
name|metrics
operator|.
name|setSizeOfLogQueue
argument_list|(
name|queueSize
argument_list|)
expr_stmt|;
comment|// This will log a warning for each new log that gets created above the warn threshold
if|if
condition|(
name|queueSize
operator|>
name|this
operator|.
name|logQueueWarnThreshold
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Queue size: "
operator|+
name|queueSize
operator|+
literal|" exceeds value of replication.source.log.queue.warn: "
operator|+
name|logQueueWarnThreshold
argument_list|)
expr_stmt|;
block|}
block|}
specifier|private
name|void
name|uninitialize
parameter_list|()
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Source exiting "
operator|+
name|this
operator|.
name|peerId
argument_list|)
expr_stmt|;
name|metrics
operator|.
name|clear
argument_list|()
expr_stmt|;
if|if
condition|(
name|replicationEndpoint
operator|.
name|state
argument_list|()
operator|==
name|Service
operator|.
name|State
operator|.
name|STARTING
operator|||
name|replicationEndpoint
operator|.
name|state
argument_list|()
operator|==
name|Service
operator|.
name|State
operator|.
name|RUNNING
condition|)
block|{
name|replicationEndpoint
operator|.
name|stopAndWait
argument_list|()
expr_stmt|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|void
name|run
parameter_list|()
block|{
comment|// We were stopped while looping to connect to sinks, just abort
if|if
condition|(
operator|!
name|this
operator|.
name|isActive
argument_list|()
condition|)
block|{
name|uninitialize
argument_list|()
expr_stmt|;
return|return;
block|}
try|try
block|{
comment|// start the endpoint, connect to the cluster
name|Service
operator|.
name|State
name|state
init|=
name|replicationEndpoint
operator|.
name|start
argument_list|()
operator|.
name|get
argument_list|()
decl_stmt|;
if|if
condition|(
name|state
operator|!=
name|Service
operator|.
name|State
operator|.
name|RUNNING
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"ReplicationEndpoint was not started. Exiting"
argument_list|)
expr_stmt|;
name|uninitialize
argument_list|()
expr_stmt|;
return|return;
block|}
block|}
catch|catch
parameter_list|(
name|Exception
name|ex
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Error starting ReplicationEndpoint, exiting"
argument_list|,
name|ex
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|RuntimeException
argument_list|(
name|ex
argument_list|)
throw|;
block|}
comment|// get the WALEntryFilter from ReplicationEndpoint and add it to default filters
name|ArrayList
argument_list|<
name|WALEntryFilter
argument_list|>
name|filters
init|=
name|Lists
operator|.
name|newArrayList
argument_list|(
operator|(
name|WALEntryFilter
operator|)
operator|new
name|SystemTableWALEntryFilter
argument_list|()
argument_list|)
decl_stmt|;
name|WALEntryFilter
name|filterFromEndpoint
init|=
name|this
operator|.
name|replicationEndpoint
operator|.
name|getWALEntryfilter
argument_list|()
decl_stmt|;
if|if
condition|(
name|filterFromEndpoint
operator|!=
literal|null
condition|)
block|{
name|filters
operator|.
name|add
argument_list|(
name|filterFromEndpoint
argument_list|)
expr_stmt|;
block|}
name|this
operator|.
name|walEntryFilter
operator|=
operator|new
name|ChainWALEntryFilter
argument_list|(
name|filters
argument_list|)
expr_stmt|;
name|int
name|sleepMultiplier
init|=
literal|1
decl_stmt|;
comment|// delay this until we are in an asynchronous thread
while|while
condition|(
name|this
operator|.
name|isActive
argument_list|()
operator|&&
name|this
operator|.
name|peerClusterId
operator|==
literal|null
condition|)
block|{
name|this
operator|.
name|peerClusterId
operator|=
name|replicationEndpoint
operator|.
name|getPeerUUID
argument_list|()
expr_stmt|;
if|if
condition|(
name|this
operator|.
name|isActive
argument_list|()
operator|&&
name|this
operator|.
name|peerClusterId
operator|==
literal|null
condition|)
block|{
if|if
condition|(
name|sleepForRetries
argument_list|(
literal|"Cannot contact the peer's zk ensemble"
argument_list|,
name|sleepMultiplier
argument_list|)
condition|)
block|{
name|sleepMultiplier
operator|++
expr_stmt|;
block|}
block|}
block|}
comment|// We were stopped while looping to contact peer's zk ensemble, just abort
if|if
condition|(
operator|!
name|this
operator|.
name|isActive
argument_list|()
condition|)
block|{
name|uninitialize
argument_list|()
expr_stmt|;
return|return;
block|}
comment|// resetting to 1 to reuse later
name|sleepMultiplier
operator|=
literal|1
expr_stmt|;
comment|// In rare case, zookeeper setting may be messed up. That leads to the incorrect
comment|// peerClusterId value, which is the same as the source clusterId
if|if
condition|(
name|clusterId
operator|.
name|equals
argument_list|(
name|peerClusterId
argument_list|)
operator|&&
operator|!
name|replicationEndpoint
operator|.
name|canReplicateToSameCluster
argument_list|()
condition|)
block|{
name|this
operator|.
name|terminate
argument_list|(
literal|"ClusterId "
operator|+
name|clusterId
operator|+
literal|" is replicating to itself: peerClusterId "
operator|+
name|peerClusterId
operator|+
literal|" which is not allowed by ReplicationEndpoint:"
operator|+
name|replicationEndpoint
operator|.
name|getClass
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|,
literal|null
argument_list|,
literal|false
argument_list|)
expr_stmt|;
block|}
name|LOG
operator|.
name|info
argument_list|(
literal|"Replicating "
operator|+
name|clusterId
operator|+
literal|" -> "
operator|+
name|peerClusterId
argument_list|)
expr_stmt|;
comment|// If this is recovered, the queue is already full and the first log
comment|// normally has a position (unless the RS failed between 2 logs)
if|if
condition|(
name|this
operator|.
name|replicationQueueInfo
operator|.
name|isQueueRecovered
argument_list|()
condition|)
block|{
try|try
block|{
name|this
operator|.
name|repLogReader
operator|.
name|setPosition
argument_list|(
name|this
operator|.
name|replicationQueues
operator|.
name|getLogPosition
argument_list|(
name|this
operator|.
name|peerClusterZnode
argument_list|,
name|this
operator|.
name|queue
operator|.
name|peek
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|trace
argument_list|(
literal|"Recovered queue started with log "
operator|+
name|this
operator|.
name|queue
operator|.
name|peek
argument_list|()
operator|+
literal|" at position "
operator|+
name|this
operator|.
name|repLogReader
operator|.
name|getPosition
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|ReplicationException
name|e
parameter_list|)
block|{
name|this
operator|.
name|terminate
argument_list|(
literal|"Couldn't get the position of this recovered queue "
operator|+
name|this
operator|.
name|peerClusterZnode
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
block|}
comment|// Loop until we close down
while|while
condition|(
name|isActive
argument_list|()
condition|)
block|{
comment|// Sleep until replication is enabled again
if|if
condition|(
operator|!
name|isPeerEnabled
argument_list|()
condition|)
block|{
if|if
condition|(
name|sleepForRetries
argument_list|(
literal|"Replication is disabled"
argument_list|,
name|sleepMultiplier
argument_list|)
condition|)
block|{
name|sleepMultiplier
operator|++
expr_stmt|;
block|}
continue|continue;
block|}
name|Path
name|oldPath
init|=
name|getCurrentPath
argument_list|()
decl_stmt|;
comment|//note that in the current scenario,
comment|//oldPath will be null when a log roll
comment|//happens.
comment|// Get a new path
name|boolean
name|hasCurrentPath
init|=
name|getNextPath
argument_list|()
decl_stmt|;
if|if
condition|(
name|getCurrentPath
argument_list|()
operator|!=
literal|null
operator|&&
name|oldPath
operator|==
literal|null
condition|)
block|{
name|sleepMultiplier
operator|=
literal|1
expr_stmt|;
comment|//reset the sleepMultiplier on a path change
block|}
if|if
condition|(
operator|!
name|hasCurrentPath
condition|)
block|{
if|if
condition|(
name|sleepForRetries
argument_list|(
literal|"No log to process"
argument_list|,
name|sleepMultiplier
argument_list|)
condition|)
block|{
name|sleepMultiplier
operator|++
expr_stmt|;
block|}
continue|continue;
block|}
name|boolean
name|currentWALisBeingWrittenTo
init|=
literal|false
decl_stmt|;
comment|//For WAL files we own (rather than recovered), take a snapshot of whether the
comment|//current WAL file (this.currentPath) is in use (for writing) NOW!
comment|//Since the new WAL paths are enqueued only after the prev WAL file
comment|//is 'closed', presence of an element in the queue means that
comment|//the previous WAL file was closed, else the file is in use (currentPath)
comment|//We take the snapshot now so that we are protected against races
comment|//where a new file gets enqueued while the current file is being processed
comment|//(and where we just finished reading the current file).
if|if
condition|(
operator|!
name|this
operator|.
name|replicationQueueInfo
operator|.
name|isQueueRecovered
argument_list|()
operator|&&
name|queue
operator|.
name|size
argument_list|()
operator|==
literal|0
condition|)
block|{
name|currentWALisBeingWrittenTo
operator|=
literal|true
expr_stmt|;
block|}
comment|// Open a reader on it
if|if
condition|(
operator|!
name|openReader
argument_list|(
name|sleepMultiplier
argument_list|)
condition|)
block|{
comment|// Reset the sleep multiplier, else it'd be reused for the next file
name|sleepMultiplier
operator|=
literal|1
expr_stmt|;
continue|continue;
block|}
comment|// If we got a null reader but didn't continue, then sleep and continue
if|if
condition|(
name|this
operator|.
name|reader
operator|==
literal|null
condition|)
block|{
if|if
condition|(
name|sleepForRetries
argument_list|(
literal|"Unable to open a reader"
argument_list|,
name|sleepMultiplier
argument_list|)
condition|)
block|{
name|sleepMultiplier
operator|++
expr_stmt|;
block|}
continue|continue;
block|}
name|boolean
name|gotIOE
init|=
literal|false
decl_stmt|;
name|currentNbOperations
operator|=
literal|0
expr_stmt|;
name|List
argument_list|<
name|HLog
operator|.
name|Entry
argument_list|>
name|entries
init|=
operator|new
name|ArrayList
argument_list|<
name|HLog
operator|.
name|Entry
argument_list|>
argument_list|(
literal|1
argument_list|)
decl_stmt|;
name|currentSize
operator|=
literal|0
expr_stmt|;
try|try
block|{
if|if
condition|(
name|readAllEntriesToReplicateOrNextFile
argument_list|(
name|currentWALisBeingWrittenTo
argument_list|,
name|entries
argument_list|)
condition|)
block|{
continue|continue;
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|ioe
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
name|this
operator|.
name|peerClusterZnode
operator|+
literal|" Got: "
argument_list|,
name|ioe
argument_list|)
expr_stmt|;
name|gotIOE
operator|=
literal|true
expr_stmt|;
if|if
condition|(
name|ioe
operator|.
name|getCause
argument_list|()
operator|instanceof
name|EOFException
condition|)
block|{
name|boolean
name|considerDumping
init|=
literal|false
decl_stmt|;
if|if
condition|(
name|this
operator|.
name|replicationQueueInfo
operator|.
name|isQueueRecovered
argument_list|()
condition|)
block|{
try|try
block|{
name|FileStatus
name|stat
init|=
name|this
operator|.
name|fs
operator|.
name|getFileStatus
argument_list|(
name|this
operator|.
name|currentPath
argument_list|)
decl_stmt|;
if|if
condition|(
name|stat
operator|.
name|getLen
argument_list|()
operator|==
literal|0
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
name|this
operator|.
name|peerClusterZnode
operator|+
literal|" Got EOF and the file was empty"
argument_list|)
expr_stmt|;
block|}
name|considerDumping
operator|=
literal|true
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
name|this
operator|.
name|peerClusterZnode
operator|+
literal|" Got while getting file size: "
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|considerDumping
operator|&&
name|sleepMultiplier
operator|==
name|this
operator|.
name|maxRetriesMultiplier
operator|&&
name|processEndOfFile
argument_list|()
condition|)
block|{
continue|continue;
block|}
block|}
block|}
finally|finally
block|{
try|try
block|{
name|this
operator|.
name|reader
operator|=
literal|null
expr_stmt|;
name|this
operator|.
name|repLogReader
operator|.
name|closeReader
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|gotIOE
operator|=
literal|true
expr_stmt|;
name|LOG
operator|.
name|warn
argument_list|(
literal|"Unable to finalize the tailing of a file"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
block|}
comment|// If we didn't get anything to replicate, or if we hit a IOE,
comment|// wait a bit and retry.
comment|// But if we need to stop, don't bother sleeping
if|if
condition|(
name|this
operator|.
name|isActive
argument_list|()
operator|&&
operator|(
name|gotIOE
operator|||
name|entries
operator|.
name|isEmpty
argument_list|()
operator|)
condition|)
block|{
if|if
condition|(
name|this
operator|.
name|lastLoggedPosition
operator|!=
name|this
operator|.
name|repLogReader
operator|.
name|getPosition
argument_list|()
condition|)
block|{
name|this
operator|.
name|manager
operator|.
name|logPositionAndCleanOldLogs
argument_list|(
name|this
operator|.
name|currentPath
argument_list|,
name|this
operator|.
name|peerClusterZnode
argument_list|,
name|this
operator|.
name|repLogReader
operator|.
name|getPosition
argument_list|()
argument_list|,
name|this
operator|.
name|replicationQueueInfo
operator|.
name|isQueueRecovered
argument_list|()
argument_list|,
name|currentWALisBeingWrittenTo
argument_list|)
expr_stmt|;
name|this
operator|.
name|lastLoggedPosition
operator|=
name|this
operator|.
name|repLogReader
operator|.
name|getPosition
argument_list|()
expr_stmt|;
block|}
comment|// Reset the sleep multiplier if nothing has actually gone wrong
if|if
condition|(
operator|!
name|gotIOE
condition|)
block|{
name|sleepMultiplier
operator|=
literal|1
expr_stmt|;
comment|// if there was nothing to ship and it's not an error
comment|// set "ageOfLastShippedOp" to<now> to indicate that we're current
name|this
operator|.
name|metrics
operator|.
name|setAgeOfLastShippedOp
argument_list|(
name|System
operator|.
name|currentTimeMillis
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|sleepForRetries
argument_list|(
literal|"Nothing to replicate"
argument_list|,
name|sleepMultiplier
argument_list|)
condition|)
block|{
name|sleepMultiplier
operator|++
expr_stmt|;
block|}
continue|continue;
block|}
name|sleepMultiplier
operator|=
literal|1
expr_stmt|;
name|shipEdits
argument_list|(
name|currentWALisBeingWrittenTo
argument_list|,
name|entries
argument_list|)
expr_stmt|;
block|}
name|uninitialize
argument_list|()
expr_stmt|;
block|}
comment|/**    * Read all the entries from the current log files and retain those    * that need to be replicated. Else, process the end of the current file.    * @param currentWALisBeingWrittenTo is the current WAL being written to    * @param entries resulting entries to be replicated    * @return true if we got nothing and went to the next file, false if we got    * entries    * @throws IOException    */
specifier|protected
name|boolean
name|readAllEntriesToReplicateOrNextFile
parameter_list|(
name|boolean
name|currentWALisBeingWrittenTo
parameter_list|,
name|List
argument_list|<
name|HLog
operator|.
name|Entry
argument_list|>
name|entries
parameter_list|)
throws|throws
name|IOException
block|{
name|long
name|seenEntries
init|=
literal|0
decl_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|trace
argument_list|(
literal|"Seeking in "
operator|+
name|this
operator|.
name|currentPath
operator|+
literal|" at position "
operator|+
name|this
operator|.
name|repLogReader
operator|.
name|getPosition
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|this
operator|.
name|repLogReader
operator|.
name|seek
argument_list|()
expr_stmt|;
name|long
name|positionBeforeRead
init|=
name|this
operator|.
name|repLogReader
operator|.
name|getPosition
argument_list|()
decl_stmt|;
name|HLog
operator|.
name|Entry
name|entry
init|=
name|this
operator|.
name|repLogReader
operator|.
name|readNextAndSetPosition
argument_list|()
decl_stmt|;
while|while
condition|(
name|entry
operator|!=
literal|null
condition|)
block|{
name|this
operator|.
name|metrics
operator|.
name|incrLogEditsRead
argument_list|()
expr_stmt|;
name|seenEntries
operator|++
expr_stmt|;
comment|// don't replicate if the log entries have already been consumed by the cluster
if|if
condition|(
name|replicationEndpoint
operator|.
name|canReplicateToSameCluster
argument_list|()
operator|||
operator|!
name|entry
operator|.
name|getKey
argument_list|()
operator|.
name|getClusterIds
argument_list|()
operator|.
name|contains
argument_list|(
name|peerClusterId
argument_list|)
condition|)
block|{
comment|// Remove all KVs that should not be replicated
name|entry
operator|=
name|walEntryFilter
operator|.
name|filter
argument_list|(
name|entry
argument_list|)
expr_stmt|;
name|WALEdit
name|edit
init|=
literal|null
decl_stmt|;
name|HLogKey
name|logKey
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|entry
operator|!=
literal|null
condition|)
block|{
name|edit
operator|=
name|entry
operator|.
name|getEdit
argument_list|()
expr_stmt|;
name|logKey
operator|=
name|entry
operator|.
name|getKey
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|edit
operator|!=
literal|null
operator|&&
name|edit
operator|.
name|size
argument_list|()
operator|!=
literal|0
condition|)
block|{
comment|//Mark that the current cluster has the change
name|logKey
operator|.
name|addClusterId
argument_list|(
name|clusterId
argument_list|)
expr_stmt|;
name|currentNbOperations
operator|+=
name|countDistinctRowKeys
argument_list|(
name|edit
argument_list|)
expr_stmt|;
name|entries
operator|.
name|add
argument_list|(
name|entry
argument_list|)
expr_stmt|;
name|currentSize
operator|+=
name|entry
operator|.
name|getEdit
argument_list|()
operator|.
name|heapSize
argument_list|()
expr_stmt|;
block|}
else|else
block|{
name|this
operator|.
name|metrics
operator|.
name|incrLogEditsFiltered
argument_list|()
expr_stmt|;
block|}
block|}
comment|// Stop if too many entries or too big
if|if
condition|(
name|currentSize
operator|>=
name|this
operator|.
name|replicationQueueSizeCapacity
operator|||
name|entries
operator|.
name|size
argument_list|()
operator|>=
name|this
operator|.
name|replicationQueueNbCapacity
condition|)
block|{
break|break;
block|}
try|try
block|{
name|entry
operator|=
name|this
operator|.
name|repLogReader
operator|.
name|readNextAndSetPosition
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ie
parameter_list|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Break on IOE: "
operator|+
name|ie
operator|.
name|getMessage
argument_list|()
argument_list|)
expr_stmt|;
break|break;
block|}
block|}
name|metrics
operator|.
name|incrLogReadInBytes
argument_list|(
name|this
operator|.
name|repLogReader
operator|.
name|getPosition
argument_list|()
operator|-
name|positionBeforeRead
argument_list|)
expr_stmt|;
if|if
condition|(
name|currentWALisBeingWrittenTo
condition|)
block|{
return|return
literal|false
return|;
block|}
comment|// If we didn't get anything and the queue has an object, it means we
comment|// hit the end of the file for sure
return|return
name|seenEntries
operator|==
literal|0
operator|&&
name|processEndOfFile
argument_list|()
return|;
block|}
comment|/**    * Poll for the next path    * @return true if a path was obtained, false if not    */
specifier|protected
name|boolean
name|getNextPath
parameter_list|()
block|{
try|try
block|{
if|if
condition|(
name|this
operator|.
name|currentPath
operator|==
literal|null
condition|)
block|{
name|this
operator|.
name|currentPath
operator|=
name|queue
operator|.
name|poll
argument_list|(
name|this
operator|.
name|sleepForRetries
argument_list|,
name|TimeUnit
operator|.
name|MILLISECONDS
argument_list|)
expr_stmt|;
name|this
operator|.
name|metrics
operator|.
name|setSizeOfLogQueue
argument_list|(
name|queue
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|this
operator|.
name|currentPath
operator|!=
literal|null
condition|)
block|{
name|this
operator|.
name|manager
operator|.
name|cleanOldLogs
argument_list|(
name|this
operator|.
name|currentPath
operator|.
name|getName
argument_list|()
argument_list|,
name|this
operator|.
name|peerId
argument_list|,
name|this
operator|.
name|replicationQueueInfo
operator|.
name|isQueueRecovered
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|trace
argument_list|(
literal|"New log: "
operator|+
name|this
operator|.
name|currentPath
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Interrupted while reading edits"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
return|return
name|this
operator|.
name|currentPath
operator|!=
literal|null
return|;
block|}
comment|/**    * Open a reader on the current path    *    * @param sleepMultiplier by how many times the default sleeping time is augmented    * @return true if we should continue with that file, false if we are over with it    */
specifier|protected
name|boolean
name|openReader
parameter_list|(
name|int
name|sleepMultiplier
parameter_list|)
block|{
try|try
block|{
try|try
block|{
if|if
condition|(
name|LOG
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|trace
argument_list|(
literal|"Opening log "
operator|+
name|this
operator|.
name|currentPath
argument_list|)
expr_stmt|;
block|}
name|this
operator|.
name|reader
operator|=
name|repLogReader
operator|.
name|openReader
argument_list|(
name|this
operator|.
name|currentPath
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|FileNotFoundException
name|fnfe
parameter_list|)
block|{
if|if
condition|(
name|this
operator|.
name|replicationQueueInfo
operator|.
name|isQueueRecovered
argument_list|()
condition|)
block|{
comment|// We didn't find the log in the archive directory, look if it still
comment|// exists in the dead RS folder (there could be a chain of failures
comment|// to look at)
name|List
argument_list|<
name|String
argument_list|>
name|deadRegionServers
init|=
name|this
operator|.
name|replicationQueueInfo
operator|.
name|getDeadRegionServers
argument_list|()
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"NB dead servers : "
operator|+
name|deadRegionServers
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
for|for
control|(
name|String
name|curDeadServerName
range|:
name|deadRegionServers
control|)
block|{
name|Path
name|deadRsDirectory
init|=
operator|new
name|Path
argument_list|(
name|manager
operator|.
name|getLogDir
argument_list|()
operator|.
name|getParent
argument_list|()
argument_list|,
name|curDeadServerName
argument_list|)
decl_stmt|;
name|Path
index|[]
name|locs
init|=
operator|new
name|Path
index|[]
block|{
operator|new
name|Path
argument_list|(
name|deadRsDirectory
argument_list|,
name|currentPath
operator|.
name|getName
argument_list|()
argument_list|)
block|,
operator|new
name|Path
argument_list|(
name|deadRsDirectory
operator|.
name|suffix
argument_list|(
name|HLog
operator|.
name|SPLITTING_EXT
argument_list|)
argument_list|,
name|currentPath
operator|.
name|getName
argument_list|()
argument_list|)
block|,             }
decl_stmt|;
for|for
control|(
name|Path
name|possibleLogLocation
range|:
name|locs
control|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Possible location "
operator|+
name|possibleLogLocation
operator|.
name|toUri
argument_list|()
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|this
operator|.
name|manager
operator|.
name|getFs
argument_list|()
operator|.
name|exists
argument_list|(
name|possibleLogLocation
argument_list|)
condition|)
block|{
comment|// We found the right new location
name|LOG
operator|.
name|info
argument_list|(
literal|"Log "
operator|+
name|this
operator|.
name|currentPath
operator|+
literal|" still exists at "
operator|+
name|possibleLogLocation
argument_list|)
expr_stmt|;
comment|// Breaking here will make us sleep since reader is null
return|return
literal|true
return|;
block|}
block|}
block|}
comment|// In the case of disaster/recovery, HMaster may be shutdown/crashed before flush data
comment|// from .logs to .oldlogs. Loop into .logs folders and check whether a match exists
if|if
condition|(
name|stopper
operator|instanceof
name|ReplicationSyncUp
operator|.
name|DummyServer
condition|)
block|{
name|FileStatus
index|[]
name|rss
init|=
name|fs
operator|.
name|listStatus
argument_list|(
name|manager
operator|.
name|getLogDir
argument_list|()
argument_list|)
decl_stmt|;
for|for
control|(
name|FileStatus
name|rs
range|:
name|rss
control|)
block|{
name|Path
name|p
init|=
name|rs
operator|.
name|getPath
argument_list|()
decl_stmt|;
name|FileStatus
index|[]
name|logs
init|=
name|fs
operator|.
name|listStatus
argument_list|(
name|p
argument_list|)
decl_stmt|;
for|for
control|(
name|FileStatus
name|log
range|:
name|logs
control|)
block|{
name|p
operator|=
operator|new
name|Path
argument_list|(
name|p
argument_list|,
name|log
operator|.
name|getPath
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|p
operator|.
name|getName
argument_list|()
operator|.
name|equals
argument_list|(
name|currentPath
operator|.
name|getName
argument_list|()
argument_list|)
condition|)
block|{
name|currentPath
operator|=
name|p
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Log "
operator|+
name|this
operator|.
name|currentPath
operator|+
literal|" exists under "
operator|+
name|manager
operator|.
name|getLogDir
argument_list|()
argument_list|)
expr_stmt|;
comment|// Open the log at the new location
name|this
operator|.
name|openReader
argument_list|(
name|sleepMultiplier
argument_list|)
expr_stmt|;
return|return
literal|true
return|;
block|}
block|}
block|}
block|}
comment|// TODO What happens if the log was missing from every single location?
comment|// Although we need to check a couple of times as the log could have
comment|// been moved by the master between the checks
comment|// It can also happen if a recovered queue wasn't properly cleaned,
comment|// such that the znode pointing to a log exists but the log was
comment|// deleted a long time ago.
comment|// For the moment, we'll throw the IO and processEndOfFile
throw|throw
operator|new
name|IOException
argument_list|(
literal|"File from recovered queue is "
operator|+
literal|"nowhere to be found"
argument_list|,
name|fnfe
argument_list|)
throw|;
block|}
else|else
block|{
comment|// If the log was archived, continue reading from there
name|Path
name|archivedLogLocation
init|=
operator|new
name|Path
argument_list|(
name|manager
operator|.
name|getOldLogDir
argument_list|()
argument_list|,
name|currentPath
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|this
operator|.
name|manager
operator|.
name|getFs
argument_list|()
operator|.
name|exists
argument_list|(
name|archivedLogLocation
argument_list|)
condition|)
block|{
name|currentPath
operator|=
name|archivedLogLocation
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Log "
operator|+
name|this
operator|.
name|currentPath
operator|+
literal|" was moved to "
operator|+
name|archivedLogLocation
argument_list|)
expr_stmt|;
comment|// Open the log at the new location
name|this
operator|.
name|openReader
argument_list|(
name|sleepMultiplier
argument_list|)
expr_stmt|;
block|}
comment|// TODO What happens the log is missing in both places?
block|}
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|ioe
parameter_list|)
block|{
if|if
condition|(
name|ioe
operator|instanceof
name|EOFException
operator|&&
name|isCurrentLogEmpty
argument_list|()
condition|)
return|return
literal|true
return|;
name|LOG
operator|.
name|warn
argument_list|(
name|this
operator|.
name|peerClusterZnode
operator|+
literal|" Got: "
argument_list|,
name|ioe
argument_list|)
expr_stmt|;
name|this
operator|.
name|reader
operator|=
literal|null
expr_stmt|;
if|if
condition|(
name|ioe
operator|.
name|getCause
argument_list|()
operator|instanceof
name|NullPointerException
condition|)
block|{
comment|// Workaround for race condition in HDFS-4380
comment|// which throws a NPE if we open a file before any data node has the most recent block
comment|// Just sleep and retry. Will require re-reading compressed HLogs for compressionContext.
name|LOG
operator|.
name|warn
argument_list|(
literal|"Got NPE opening reader, will retry."
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|sleepMultiplier
operator|==
name|this
operator|.
name|maxRetriesMultiplier
condition|)
block|{
comment|// TODO Need a better way to determine if a file is really gone but
comment|// TODO without scanning all logs dir
name|LOG
operator|.
name|warn
argument_list|(
literal|"Waited too long for this file, considering dumping"
argument_list|)
expr_stmt|;
return|return
operator|!
name|processEndOfFile
argument_list|()
return|;
block|}
block|}
return|return
literal|true
return|;
block|}
comment|/*    * Checks whether the current log file is empty, and it is not a recovered queue. This is to    * handle scenario when in an idle cluster, there is no entry in the current log and we keep on    * trying to read the log file and get EOFException. In case of a recovered queue the last log    * file may be empty, and we don't want to retry that.    */
specifier|private
name|boolean
name|isCurrentLogEmpty
parameter_list|()
block|{
return|return
operator|(
name|this
operator|.
name|repLogReader
operator|.
name|getPosition
argument_list|()
operator|==
literal|0
operator|&&
operator|!
name|this
operator|.
name|replicationQueueInfo
operator|.
name|isQueueRecovered
argument_list|()
operator|&&
name|queue
operator|.
name|size
argument_list|()
operator|==
literal|0
operator|)
return|;
block|}
comment|/**    * Do the sleeping logic    * @param msg Why we sleep    * @param sleepMultiplier by how many times the default sleeping time is augmented    * @return True if<code>sleepMultiplier</code> is&lt;<code>maxRetriesMultiplier</code>    */
specifier|protected
name|boolean
name|sleepForRetries
parameter_list|(
name|String
name|msg
parameter_list|,
name|int
name|sleepMultiplier
parameter_list|)
block|{
try|try
block|{
if|if
condition|(
name|LOG
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|trace
argument_list|(
name|msg
operator|+
literal|", sleeping "
operator|+
name|sleepForRetries
operator|+
literal|" times "
operator|+
name|sleepMultiplier
argument_list|)
expr_stmt|;
block|}
name|Thread
operator|.
name|sleep
argument_list|(
name|this
operator|.
name|sleepForRetries
operator|*
name|sleepMultiplier
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Interrupted while sleeping between retries"
argument_list|)
expr_stmt|;
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|interrupt
argument_list|()
expr_stmt|;
block|}
return|return
name|sleepMultiplier
operator|<
name|maxRetriesMultiplier
return|;
block|}
comment|/**    * Count the number of different row keys in the given edit because of    * mini-batching. We assume that there's at least one Cell in the WALEdit.    * @param edit edit to count row keys from    * @return number of different row keys    */
specifier|private
name|int
name|countDistinctRowKeys
parameter_list|(
name|WALEdit
name|edit
parameter_list|)
block|{
name|List
argument_list|<
name|Cell
argument_list|>
name|cells
init|=
name|edit
operator|.
name|getCells
argument_list|()
decl_stmt|;
name|int
name|distinctRowKeys
init|=
literal|1
decl_stmt|;
name|Cell
name|lastCell
init|=
name|cells
operator|.
name|get
argument_list|(
literal|0
argument_list|)
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|edit
operator|.
name|size
argument_list|()
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
operator|!
name|CellUtil
operator|.
name|matchingRow
argument_list|(
name|cells
operator|.
name|get
argument_list|(
name|i
argument_list|)
argument_list|,
name|lastCell
argument_list|)
condition|)
block|{
name|distinctRowKeys
operator|++
expr_stmt|;
block|}
block|}
return|return
name|distinctRowKeys
return|;
block|}
comment|/**    * Do the shipping logic    * @param currentWALisBeingWrittenTo was the current WAL being (seemingly)    * written to when this method was called    */
specifier|protected
name|void
name|shipEdits
parameter_list|(
name|boolean
name|currentWALisBeingWrittenTo
parameter_list|,
name|List
argument_list|<
name|HLog
operator|.
name|Entry
argument_list|>
name|entries
parameter_list|)
block|{
name|int
name|sleepMultiplier
init|=
literal|1
decl_stmt|;
if|if
condition|(
name|entries
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Was given 0 edits to ship"
argument_list|)
expr_stmt|;
return|return;
block|}
while|while
condition|(
name|this
operator|.
name|isActive
argument_list|()
condition|)
block|{
try|try
block|{
if|if
condition|(
name|this
operator|.
name|throttler
operator|.
name|isEnabled
argument_list|()
condition|)
block|{
name|long
name|sleepTicks
init|=
name|this
operator|.
name|throttler
operator|.
name|getNextSleepInterval
argument_list|(
name|currentSize
argument_list|)
decl_stmt|;
if|if
condition|(
name|sleepTicks
operator|>
literal|0
condition|)
block|{
try|try
block|{
if|if
condition|(
name|LOG
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|trace
argument_list|(
literal|"To sleep "
operator|+
name|sleepTicks
operator|+
literal|"ms for throttling control"
argument_list|)
expr_stmt|;
block|}
name|Thread
operator|.
name|sleep
argument_list|(
name|sleepTicks
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Interrupted while sleeping for throttling control"
argument_list|)
expr_stmt|;
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|interrupt
argument_list|()
expr_stmt|;
comment|// current thread might be interrupted to terminate
comment|// directly go back to while() for confirm this
continue|continue;
block|}
comment|// reset throttler's cycle start tick when sleep for throttling occurs
name|this
operator|.
name|throttler
operator|.
name|resetStartTick
argument_list|()
expr_stmt|;
block|}
block|}
name|replicateContext
operator|.
name|setEntries
argument_list|(
name|entries
argument_list|)
operator|.
name|setSize
argument_list|(
name|currentSize
argument_list|)
expr_stmt|;
comment|// send the edits to the endpoint. Will block until the edits are shipped and acknowledged
name|boolean
name|replicated
init|=
name|replicationEndpoint
operator|.
name|replicate
argument_list|(
name|replicateContext
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|replicated
condition|)
block|{
continue|continue;
block|}
if|if
condition|(
name|this
operator|.
name|lastLoggedPosition
operator|!=
name|this
operator|.
name|repLogReader
operator|.
name|getPosition
argument_list|()
condition|)
block|{
name|this
operator|.
name|manager
operator|.
name|logPositionAndCleanOldLogs
argument_list|(
name|this
operator|.
name|currentPath
argument_list|,
name|this
operator|.
name|peerClusterZnode
argument_list|,
name|this
operator|.
name|repLogReader
operator|.
name|getPosition
argument_list|()
argument_list|,
name|this
operator|.
name|replicationQueueInfo
operator|.
name|isQueueRecovered
argument_list|()
argument_list|,
name|currentWALisBeingWrittenTo
argument_list|)
expr_stmt|;
name|this
operator|.
name|lastLoggedPosition
operator|=
name|this
operator|.
name|repLogReader
operator|.
name|getPosition
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|this
operator|.
name|throttler
operator|.
name|isEnabled
argument_list|()
condition|)
block|{
name|this
operator|.
name|throttler
operator|.
name|addPushSize
argument_list|(
name|currentSize
argument_list|)
expr_stmt|;
block|}
name|this
operator|.
name|totalReplicatedEdits
operator|+=
name|entries
operator|.
name|size
argument_list|()
expr_stmt|;
name|this
operator|.
name|totalReplicatedOperations
operator|+=
name|currentNbOperations
expr_stmt|;
name|this
operator|.
name|metrics
operator|.
name|shipBatch
argument_list|(
name|this
operator|.
name|currentNbOperations
argument_list|,
name|this
operator|.
name|currentSize
operator|/
literal|1024
argument_list|)
expr_stmt|;
name|this
operator|.
name|metrics
operator|.
name|setAgeOfLastShippedOp
argument_list|(
name|entries
operator|.
name|get
argument_list|(
name|entries
operator|.
name|size
argument_list|()
operator|-
literal|1
argument_list|)
operator|.
name|getKey
argument_list|()
operator|.
name|getWriteTime
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|trace
argument_list|(
literal|"Replicated "
operator|+
name|this
operator|.
name|totalReplicatedEdits
operator|+
literal|" entries in total, or "
operator|+
name|this
operator|.
name|totalReplicatedOperations
operator|+
literal|" operations"
argument_list|)
expr_stmt|;
block|}
break|break;
block|}
catch|catch
parameter_list|(
name|Exception
name|ex
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
name|replicationEndpoint
operator|.
name|getClass
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|" threw unknown exception:"
operator|+
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|StringUtils
operator|.
name|stringifyException
argument_list|(
name|ex
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|sleepForRetries
argument_list|(
literal|"ReplicationEndpoint threw exception"
argument_list|,
name|sleepMultiplier
argument_list|)
condition|)
block|{
name|sleepMultiplier
operator|++
expr_stmt|;
block|}
block|}
block|}
block|}
comment|/**    * check whether the peer is enabled or not    *    * @return true if the peer is enabled, otherwise false    */
specifier|protected
name|boolean
name|isPeerEnabled
parameter_list|()
block|{
return|return
name|this
operator|.
name|replicationPeers
operator|.
name|getStatusOfPeer
argument_list|(
name|this
operator|.
name|peerId
argument_list|)
return|;
block|}
comment|/**    * If the queue isn't empty, switch to the next one    * Else if this is a recovered queue, it means we're done!    * Else we'll just continue to try reading the log file    * @return true if we're done with the current file, false if we should    * continue trying to read from it    */
specifier|protected
name|boolean
name|processEndOfFile
parameter_list|()
block|{
if|if
condition|(
name|this
operator|.
name|queue
operator|.
name|size
argument_list|()
operator|!=
literal|0
condition|)
block|{
if|if
condition|(
name|LOG
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|String
name|filesize
init|=
literal|"N/A"
decl_stmt|;
try|try
block|{
name|FileStatus
name|stat
init|=
name|this
operator|.
name|fs
operator|.
name|getFileStatus
argument_list|(
name|this
operator|.
name|currentPath
argument_list|)
decl_stmt|;
name|filesize
operator|=
name|stat
operator|.
name|getLen
argument_list|()
operator|+
literal|""
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ex
parameter_list|)
block|{}
name|LOG
operator|.
name|trace
argument_list|(
literal|"Reached the end of a log, stats: "
operator|+
name|getStats
argument_list|()
operator|+
literal|", and the length of the file is "
operator|+
name|filesize
argument_list|)
expr_stmt|;
block|}
name|this
operator|.
name|currentPath
operator|=
literal|null
expr_stmt|;
name|this
operator|.
name|repLogReader
operator|.
name|finishCurrentFile
argument_list|()
expr_stmt|;
name|this
operator|.
name|reader
operator|=
literal|null
expr_stmt|;
return|return
literal|true
return|;
block|}
elseif|else
if|if
condition|(
name|this
operator|.
name|replicationQueueInfo
operator|.
name|isQueueRecovered
argument_list|()
condition|)
block|{
name|this
operator|.
name|manager
operator|.
name|closeRecoveredQueue
argument_list|(
name|this
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Finished recovering the queue with the following stats "
operator|+
name|getStats
argument_list|()
argument_list|)
expr_stmt|;
name|this
operator|.
name|running
operator|=
literal|false
expr_stmt|;
return|return
literal|true
return|;
block|}
return|return
literal|false
return|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|startup
parameter_list|()
block|{
name|String
name|n
init|=
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|getName
argument_list|()
decl_stmt|;
name|Thread
operator|.
name|UncaughtExceptionHandler
name|handler
init|=
operator|new
name|Thread
operator|.
name|UncaughtExceptionHandler
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|void
name|uncaughtException
parameter_list|(
specifier|final
name|Thread
name|t
parameter_list|,
specifier|final
name|Throwable
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Unexpected exception in ReplicationSource,"
operator|+
literal|" currentPath="
operator|+
name|currentPath
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
block|}
decl_stmt|;
name|Threads
operator|.
name|setDaemonThreadRunning
argument_list|(
name|this
argument_list|,
name|n
operator|+
literal|".replicationSource,"
operator|+
name|this
operator|.
name|peerClusterZnode
argument_list|,
name|handler
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|terminate
parameter_list|(
name|String
name|reason
parameter_list|)
block|{
name|terminate
argument_list|(
name|reason
argument_list|,
literal|null
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|terminate
parameter_list|(
name|String
name|reason
parameter_list|,
name|Exception
name|cause
parameter_list|)
block|{
name|terminate
argument_list|(
name|reason
argument_list|,
name|cause
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
specifier|public
name|void
name|terminate
parameter_list|(
name|String
name|reason
parameter_list|,
name|Exception
name|cause
parameter_list|,
name|boolean
name|join
parameter_list|)
block|{
if|if
condition|(
name|cause
operator|==
literal|null
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Closing source "
operator|+
name|this
operator|.
name|peerClusterZnode
operator|+
literal|" because: "
operator|+
name|reason
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Closing source "
operator|+
name|this
operator|.
name|peerClusterZnode
operator|+
literal|" because an error occurred: "
operator|+
name|reason
argument_list|,
name|cause
argument_list|)
expr_stmt|;
block|}
name|this
operator|.
name|running
operator|=
literal|false
expr_stmt|;
name|this
operator|.
name|interrupt
argument_list|()
expr_stmt|;
name|ListenableFuture
argument_list|<
name|Service
operator|.
name|State
argument_list|>
name|future
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|this
operator|.
name|replicationEndpoint
operator|!=
literal|null
condition|)
block|{
name|future
operator|=
name|this
operator|.
name|replicationEndpoint
operator|.
name|stop
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|join
condition|)
block|{
name|Threads
operator|.
name|shutdown
argument_list|(
name|this
argument_list|,
name|this
operator|.
name|sleepForRetries
argument_list|)
expr_stmt|;
if|if
condition|(
name|future
operator|!=
literal|null
condition|)
block|{
try|try
block|{
name|future
operator|.
name|get
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Got exception:"
operator|+
name|e
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
annotation|@
name|Override
specifier|public
name|String
name|getPeerClusterZnode
parameter_list|()
block|{
return|return
name|this
operator|.
name|peerClusterZnode
return|;
block|}
annotation|@
name|Override
specifier|public
name|String
name|getPeerClusterId
parameter_list|()
block|{
return|return
name|this
operator|.
name|peerId
return|;
block|}
annotation|@
name|Override
specifier|public
name|Path
name|getCurrentPath
parameter_list|()
block|{
return|return
name|this
operator|.
name|currentPath
return|;
block|}
specifier|private
name|boolean
name|isActive
parameter_list|()
block|{
return|return
operator|!
name|this
operator|.
name|stopper
operator|.
name|isStopped
argument_list|()
operator|&&
name|this
operator|.
name|running
operator|&&
operator|!
name|isInterrupted
argument_list|()
return|;
block|}
comment|/**    * Comparator used to compare logs together based on their start time    */
specifier|public
specifier|static
class|class
name|LogsComparator
implements|implements
name|Comparator
argument_list|<
name|Path
argument_list|>
block|{
annotation|@
name|Override
specifier|public
name|int
name|compare
parameter_list|(
name|Path
name|o1
parameter_list|,
name|Path
name|o2
parameter_list|)
block|{
return|return
name|Long
operator|.
name|valueOf
argument_list|(
name|getTS
argument_list|(
name|o1
argument_list|)
argument_list|)
operator|.
name|compareTo
argument_list|(
name|getTS
argument_list|(
name|o2
argument_list|)
argument_list|)
return|;
block|}
comment|/**      * Split a path to get the start time      * For example: 10.20.20.171%3A60020.1277499063250      * @param p path to split      * @return start time      */
specifier|private
name|long
name|getTS
parameter_list|(
name|Path
name|p
parameter_list|)
block|{
name|String
index|[]
name|parts
init|=
name|p
operator|.
name|getName
argument_list|()
operator|.
name|split
argument_list|(
literal|"\\."
argument_list|)
decl_stmt|;
return|return
name|Long
operator|.
name|parseLong
argument_list|(
name|parts
index|[
name|parts
operator|.
name|length
operator|-
literal|1
index|]
argument_list|)
return|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|String
name|getStats
parameter_list|()
block|{
name|long
name|position
init|=
name|this
operator|.
name|repLogReader
operator|.
name|getPosition
argument_list|()
decl_stmt|;
return|return
literal|"Total replicated edits: "
operator|+
name|totalReplicatedEdits
operator|+
literal|", currently replicating from: "
operator|+
name|this
operator|.
name|currentPath
operator|+
literal|" at position: "
operator|+
name|position
return|;
block|}
block|}
end_class

end_unit

