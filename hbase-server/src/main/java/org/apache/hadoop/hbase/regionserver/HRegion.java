begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/*  *  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|EOFException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|FileNotFoundException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|InterruptedIOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|UnsupportedEncodingException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|lang
operator|.
name|reflect
operator|.
name|Constructor
import|;
end_import

begin_import
import|import
name|java
operator|.
name|text
operator|.
name|ParseException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|AbstractList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Arrays
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collection
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collections
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|NavigableMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|NavigableSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Random
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Set
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|TreeMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|UUID
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|Callable
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|CompletionService
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ConcurrentHashMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ConcurrentSkipListMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|CountDownLatch
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ExecutionException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ExecutorCompletionService
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ExecutorService
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|Executors
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|Future
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|FutureTask
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ThreadFactory
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ThreadPoolExecutor
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|TimeUnit
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|TimeoutException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|atomic
operator|.
name|AtomicBoolean
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|atomic
operator|.
name|AtomicInteger
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|atomic
operator|.
name|AtomicLong
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|locks
operator|.
name|Lock
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|locks
operator|.
name|ReentrantReadWriteLock
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|Log
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|LogFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|classification
operator|.
name|InterfaceAudience
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FSDataInputStream
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FSDataOutputStream
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileStatus
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|permission
operator|.
name|FsPermission
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|CompoundConfiguration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|DoNotRetryIOException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|DroppedSnapshotException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|FailedSanityCheckException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HBaseConfiguration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HColumnDescriptor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HConstants
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HConstants
operator|.
name|OperationStatusCode
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HDFSBlocksDistribution
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HRegionInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HTableDescriptor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|KeyValue
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|NotServingRegionException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|RegionTooBusyException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|UnknownScannerException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|backup
operator|.
name|HFileArchiver
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|Append
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|Delete
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|Get
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|Increment
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|IsolationLevel
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|Mutation
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|Put
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|Result
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|Row
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|RowMutations
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|Scan
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|filter
operator|.
name|ByteArrayComparable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|filter
operator|.
name|CompareFilter
operator|.
name|CompareOp
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|filter
operator|.
name|Filter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|filter
operator|.
name|FilterWrapper
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|filter
operator|.
name|IncompatibleFilterException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|HeapSize
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|TimeRange
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|hfile
operator|.
name|BlockCache
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|hfile
operator|.
name|CacheConfig
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|ipc
operator|.
name|HBaseServer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|ipc
operator|.
name|RpcCallContext
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|ipc
operator|.
name|UnknownProtocolException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|monitoring
operator|.
name|MonitoredTask
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|monitoring
operator|.
name|TaskMonitor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|protobuf
operator|.
name|generated
operator|.
name|ClientProtos
operator|.
name|CoprocessorServiceCall
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|MultiVersionConsistencyControl
operator|.
name|WriteEntry
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|compactions
operator|.
name|CompactionRequest
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|wal
operator|.
name|HLog
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|wal
operator|.
name|HLogFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|wal
operator|.
name|HLogKey
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|wal
operator|.
name|HLogUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|wal
operator|.
name|WALEdit
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|Bytes
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|CancelableProgressable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|ClassSize
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|CompressionTest
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|EnvironmentEdgeManager
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|FSUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|HashedBytes
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|Pair
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|Threads
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|MultipleIOException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|StringUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|cliffc
operator|.
name|high_scale_lib
operator|.
name|Counter
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Preconditions
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|ImmutableList
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|Lists
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|Maps
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|io
operator|.
name|Closeables
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|protobuf
operator|.
name|Descriptors
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|protobuf
operator|.
name|Message
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|protobuf
operator|.
name|RpcCallback
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|protobuf
operator|.
name|RpcController
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|protobuf
operator|.
name|Service
import|;
end_import

begin_comment
comment|/**  * HRegion stores data for a certain region of a table.  It stores all columns  * for each row. A given table consists of one or more HRegions.  *  *<p>We maintain multiple HStores for a single HRegion.  *  *<p>An Store is a set of rows with some column data; together,  * they make up all the data for the rows.  *  *<p>Each HRegion has a 'startKey' and 'endKey'.  *<p>The first is inclusive, the second is exclusive (except for  * the final region)  The endKey of region 0 is the same as  * startKey for region 1 (if it exists).  The startKey for the  * first region is null. The endKey for the final region is null.  *  *<p>Locking at the HRegion level serves only one purpose: preventing the  * region from being closed (and consequently split) while other operations  * are ongoing. Each row level operation obtains both a row lock and a region  * read lock for the duration of the operation. While a scanner is being  * constructed, getScanner holds a read lock. If the scanner is successfully  * constructed, it holds a read lock until it is closed. A close takes out a  * write lock and consequently will block for ongoing operations and will block  * new operations from starting while the close is in progress.  *  *<p>An HRegion is defined by its table and its key extent.  *  *<p>It consists of at least one Store.  The number of Stores should be  * configurable, so that data which is accessed together is stored in the same  * Store.  Right now, we approximate that by building a single Store for  * each column family.  (This config info will be communicated via the  * tabledesc.)  *  *<p>The HTableDescriptor contains metainfo about the HRegion's table.  * regionName is a unique identifier for this HRegion. (startKey, endKey]  * defines the keyspace for this HRegion.  */
end_comment

begin_class
annotation|@
name|InterfaceAudience
operator|.
name|Private
specifier|public
class|class
name|HRegion
implements|implements
name|HeapSize
block|{
comment|// , Writable{
specifier|public
specifier|static
specifier|final
name|Log
name|LOG
init|=
name|LogFactory
operator|.
name|getLog
argument_list|(
name|HRegion
operator|.
name|class
argument_list|)
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|String
name|MERGEDIR
init|=
literal|".merges"
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|String
name|LOAD_CFS_ON_DEMAND_CONFIG_KEY
init|=
literal|"hbase.hregion.scan.loadColumnFamiliesOnDemand"
decl_stmt|;
specifier|final
name|AtomicBoolean
name|closed
init|=
operator|new
name|AtomicBoolean
argument_list|(
literal|false
argument_list|)
decl_stmt|;
comment|/* Closing can take some time; use the closing flag if there is stuff we don't    * want to do while in closing state; e.g. like offer this region up to the    * master as a region to close if the carrying regionserver is overloaded.    * Once set, it is never cleared.    */
specifier|final
name|AtomicBoolean
name|closing
init|=
operator|new
name|AtomicBoolean
argument_list|(
literal|false
argument_list|)
decl_stmt|;
specifier|protected
name|long
name|completeSequenceId
init|=
operator|-
literal|1L
decl_stmt|;
comment|//////////////////////////////////////////////////////////////////////////////
comment|// Members
comment|//////////////////////////////////////////////////////////////////////////////
specifier|private
specifier|final
name|ConcurrentHashMap
argument_list|<
name|HashedBytes
argument_list|,
name|CountDownLatch
argument_list|>
name|lockedRows
init|=
operator|new
name|ConcurrentHashMap
argument_list|<
name|HashedBytes
argument_list|,
name|CountDownLatch
argument_list|>
argument_list|()
decl_stmt|;
specifier|private
specifier|final
name|ConcurrentHashMap
argument_list|<
name|Integer
argument_list|,
name|HashedBytes
argument_list|>
name|lockIds
init|=
operator|new
name|ConcurrentHashMap
argument_list|<
name|Integer
argument_list|,
name|HashedBytes
argument_list|>
argument_list|()
decl_stmt|;
specifier|private
specifier|final
name|AtomicInteger
name|lockIdGenerator
init|=
operator|new
name|AtomicInteger
argument_list|(
literal|1
argument_list|)
decl_stmt|;
specifier|static
specifier|private
name|Random
name|rand
init|=
operator|new
name|Random
argument_list|()
decl_stmt|;
specifier|protected
specifier|final
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|Store
argument_list|>
name|stores
init|=
operator|new
name|ConcurrentSkipListMap
argument_list|<
name|byte
index|[]
argument_list|,
name|Store
argument_list|>
argument_list|(
name|Bytes
operator|.
name|BYTES_RAWCOMPARATOR
argument_list|)
decl_stmt|;
comment|// TODO: account for each registered handler in HeapSize computation
specifier|private
name|Map
argument_list|<
name|String
argument_list|,
name|Service
argument_list|>
name|coprocessorServiceHandlers
init|=
name|Maps
operator|.
name|newHashMap
argument_list|()
decl_stmt|;
comment|/**    * Temporary subdirectory of the region directory used for compaction output.    */
specifier|public
specifier|static
specifier|final
name|String
name|REGION_TEMP_SUBDIR
init|=
literal|".tmp"
decl_stmt|;
comment|//These variable are just used for getting data out of the region, to test on
comment|//client side
comment|// private int numStores = 0;
comment|// private int [] storeSize = null;
comment|// private byte [] name = null;
specifier|public
specifier|final
name|AtomicLong
name|memstoreSize
init|=
operator|new
name|AtomicLong
argument_list|(
literal|0
argument_list|)
decl_stmt|;
comment|// Debug possible data loss due to WAL off
specifier|final
name|Counter
name|numPutsWithoutWAL
init|=
operator|new
name|Counter
argument_list|()
decl_stmt|;
specifier|final
name|Counter
name|dataInMemoryWithoutWAL
init|=
operator|new
name|Counter
argument_list|()
decl_stmt|;
comment|// Debug why CAS operations are taking a while.
specifier|final
name|Counter
name|checkAndMutateChecksPassed
init|=
operator|new
name|Counter
argument_list|()
decl_stmt|;
specifier|final
name|Counter
name|checkAndMutateChecksFailed
init|=
operator|new
name|Counter
argument_list|()
decl_stmt|;
comment|//Number of requests
specifier|final
name|Counter
name|readRequestsCount
init|=
operator|new
name|Counter
argument_list|()
decl_stmt|;
specifier|final
name|Counter
name|writeRequestsCount
init|=
operator|new
name|Counter
argument_list|()
decl_stmt|;
comment|//How long operations were blocked by a memstore over highwater.
specifier|final
name|Counter
name|updatesBlockedMs
init|=
operator|new
name|Counter
argument_list|()
decl_stmt|;
comment|/**    * The directory for the table this region is part of.    * This directory contains the directory for this region.    */
specifier|private
specifier|final
name|Path
name|tableDir
decl_stmt|;
specifier|private
specifier|final
name|HLog
name|log
decl_stmt|;
specifier|private
specifier|final
name|FileSystem
name|fs
decl_stmt|;
specifier|private
specifier|final
name|Configuration
name|conf
decl_stmt|;
specifier|private
specifier|final
name|Configuration
name|baseConf
decl_stmt|;
specifier|private
specifier|final
name|int
name|rowLockWaitDuration
decl_stmt|;
specifier|static
specifier|final
name|int
name|DEFAULT_ROWLOCK_WAIT_DURATION
init|=
literal|30000
decl_stmt|;
comment|// The internal wait duration to acquire a lock before read/update
comment|// from the region. It is not per row. The purpose of this wait time
comment|// is to avoid waiting a long time while the region is busy, so that
comment|// we can release the IPC handler soon enough to improve the
comment|// availability of the region server. It can be adjusted by
comment|// tuning configuration "hbase.busy.wait.duration".
specifier|final
name|long
name|busyWaitDuration
decl_stmt|;
specifier|static
specifier|final
name|long
name|DEFAULT_BUSY_WAIT_DURATION
init|=
name|HConstants
operator|.
name|DEFAULT_HBASE_RPC_TIMEOUT
decl_stmt|;
comment|// If updating multiple rows in one call, wait longer,
comment|// i.e. waiting for busyWaitDuration * # of rows. However,
comment|// we can limit the max multiplier.
specifier|final
name|int
name|maxBusyWaitMultiplier
decl_stmt|;
comment|// Max busy wait duration. There is no point to wait longer than the RPC
comment|// purge timeout, when a RPC call will be terminated by the RPC engine.
specifier|final
name|long
name|maxBusyWaitDuration
decl_stmt|;
comment|// negative number indicates infinite timeout
specifier|static
specifier|final
name|long
name|DEFAULT_ROW_PROCESSOR_TIMEOUT
init|=
literal|60
operator|*
literal|1000L
decl_stmt|;
specifier|final
name|ExecutorService
name|rowProcessorExecutor
init|=
name|Executors
operator|.
name|newCachedThreadPool
argument_list|()
decl_stmt|;
specifier|private
specifier|final
name|HRegionInfo
name|regionInfo
decl_stmt|;
specifier|private
specifier|final
name|Path
name|regiondir
decl_stmt|;
name|KeyValue
operator|.
name|KVComparator
name|comparator
decl_stmt|;
specifier|private
specifier|final
name|ConcurrentHashMap
argument_list|<
name|RegionScanner
argument_list|,
name|Long
argument_list|>
name|scannerReadPoints
decl_stmt|;
comment|/**    * The sequence ID that was encountered when this region was opened.    */
specifier|private
name|long
name|openSeqNum
init|=
name|HConstants
operator|.
name|NO_SEQNUM
decl_stmt|;
comment|/**    * The default setting for whether to enable on-demand CF loading for    * scan requests to this region. Requests can override it.    */
specifier|private
name|boolean
name|isLoadingCfsOnDemandDefault
init|=
literal|false
decl_stmt|;
comment|/**    * @return The smallest mvcc readPoint across all the scanners in this    * region. Writes older than this readPoint, are included  in every    * read operation.    */
specifier|public
name|long
name|getSmallestReadPoint
parameter_list|()
block|{
name|long
name|minimumReadPoint
decl_stmt|;
comment|// We need to ensure that while we are calculating the smallestReadPoint
comment|// no new RegionScanners can grab a readPoint that we are unaware of.
comment|// We achieve this by synchronizing on the scannerReadPoints object.
synchronized|synchronized
init|(
name|scannerReadPoints
init|)
block|{
name|minimumReadPoint
operator|=
name|mvcc
operator|.
name|memstoreReadPoint
argument_list|()
expr_stmt|;
for|for
control|(
name|Long
name|readPoint
range|:
name|this
operator|.
name|scannerReadPoints
operator|.
name|values
argument_list|()
control|)
block|{
if|if
condition|(
name|readPoint
operator|<
name|minimumReadPoint
condition|)
block|{
name|minimumReadPoint
operator|=
name|readPoint
expr_stmt|;
block|}
block|}
block|}
return|return
name|minimumReadPoint
return|;
block|}
comment|/*    * Data structure of write state flags used coordinating flushes,    * compactions and closes.    */
specifier|static
class|class
name|WriteState
block|{
comment|// Set while a memstore flush is happening.
specifier|volatile
name|boolean
name|flushing
init|=
literal|false
decl_stmt|;
comment|// Set when a flush has been requested.
specifier|volatile
name|boolean
name|flushRequested
init|=
literal|false
decl_stmt|;
comment|// Number of compactions running.
specifier|volatile
name|int
name|compacting
init|=
literal|0
decl_stmt|;
comment|// Gets set in close. If set, cannot compact or flush again.
specifier|volatile
name|boolean
name|writesEnabled
init|=
literal|true
decl_stmt|;
comment|// Set if region is read-only
specifier|volatile
name|boolean
name|readOnly
init|=
literal|false
decl_stmt|;
comment|/**      * Set flags that make this region read-only.      *      * @param onOff flip value for region r/o setting      */
specifier|synchronized
name|void
name|setReadOnly
parameter_list|(
specifier|final
name|boolean
name|onOff
parameter_list|)
block|{
name|this
operator|.
name|writesEnabled
operator|=
operator|!
name|onOff
expr_stmt|;
name|this
operator|.
name|readOnly
operator|=
name|onOff
expr_stmt|;
block|}
name|boolean
name|isReadOnly
parameter_list|()
block|{
return|return
name|this
operator|.
name|readOnly
return|;
block|}
name|boolean
name|isFlushRequested
parameter_list|()
block|{
return|return
name|this
operator|.
name|flushRequested
return|;
block|}
specifier|static
specifier|final
name|long
name|HEAP_SIZE
init|=
name|ClassSize
operator|.
name|align
argument_list|(
name|ClassSize
operator|.
name|OBJECT
operator|+
literal|5
operator|*
name|Bytes
operator|.
name|SIZEOF_BOOLEAN
argument_list|)
decl_stmt|;
block|}
specifier|final
name|WriteState
name|writestate
init|=
operator|new
name|WriteState
argument_list|()
decl_stmt|;
name|long
name|memstoreFlushSize
decl_stmt|;
specifier|final
name|long
name|timestampSlop
decl_stmt|;
specifier|final
name|long
name|rowProcessorTimeout
decl_stmt|;
specifier|private
specifier|volatile
name|long
name|lastFlushTime
decl_stmt|;
specifier|final
name|RegionServerServices
name|rsServices
decl_stmt|;
specifier|private
name|RegionServerAccounting
name|rsAccounting
decl_stmt|;
specifier|private
name|List
argument_list|<
name|Pair
argument_list|<
name|Long
argument_list|,
name|Long
argument_list|>
argument_list|>
name|recentFlushes
init|=
operator|new
name|ArrayList
argument_list|<
name|Pair
argument_list|<
name|Long
argument_list|,
name|Long
argument_list|>
argument_list|>
argument_list|()
decl_stmt|;
specifier|private
name|long
name|blockingMemStoreSize
decl_stmt|;
specifier|final
name|long
name|threadWakeFrequency
decl_stmt|;
comment|// Used to guard closes
specifier|final
name|ReentrantReadWriteLock
name|lock
init|=
operator|new
name|ReentrantReadWriteLock
argument_list|()
decl_stmt|;
comment|// Stop updates lock
specifier|private
specifier|final
name|ReentrantReadWriteLock
name|updatesLock
init|=
operator|new
name|ReentrantReadWriteLock
argument_list|()
decl_stmt|;
specifier|private
name|boolean
name|splitRequest
decl_stmt|;
specifier|private
name|byte
index|[]
name|explicitSplitPoint
init|=
literal|null
decl_stmt|;
specifier|private
specifier|final
name|MultiVersionConsistencyControl
name|mvcc
init|=
operator|new
name|MultiVersionConsistencyControl
argument_list|()
decl_stmt|;
comment|// Coprocessor host
specifier|private
name|RegionCoprocessorHost
name|coprocessorHost
decl_stmt|;
comment|/**    * Name of the region info file that resides just under the region directory.    */
specifier|public
specifier|final
specifier|static
name|String
name|REGIONINFO_FILE
init|=
literal|".regioninfo"
decl_stmt|;
specifier|private
name|HTableDescriptor
name|htableDescriptor
init|=
literal|null
decl_stmt|;
specifier|private
name|RegionSplitPolicy
name|splitPolicy
decl_stmt|;
specifier|private
specifier|final
name|MetricsRegion
name|metricsRegion
decl_stmt|;
specifier|private
specifier|final
name|MetricsRegionWrapperImpl
name|metricsRegionWrapper
decl_stmt|;
comment|/**    * HRegion copy constructor. Useful when reopening a closed region (normally    * for unit tests)    * @param other original object    */
specifier|public
name|HRegion
parameter_list|(
name|HRegion
name|other
parameter_list|)
block|{
name|this
argument_list|(
name|other
operator|.
name|getTableDir
argument_list|()
argument_list|,
name|other
operator|.
name|getLog
argument_list|()
argument_list|,
name|other
operator|.
name|getFilesystem
argument_list|()
argument_list|,
name|other
operator|.
name|baseConf
argument_list|,
name|other
operator|.
name|getRegionInfo
argument_list|()
argument_list|,
name|other
operator|.
name|getTableDesc
argument_list|()
argument_list|,
literal|null
argument_list|)
expr_stmt|;
block|}
comment|/**    * HRegion constructor.  his constructor should only be used for testing and    * extensions.  Instances of HRegion should be instantiated with the    * {@link HRegion#newHRegion(Path, HLog, FileSystem, Configuration, HRegionInfo, HTableDescriptor, RegionServerServices)} method.    *    *    * @param tableDir qualified path of directory where region should be located,    * usually the table directory.    * @param log The HLog is the outbound log for any updates to the HRegion    * (There's a single HLog for all the HRegions on a single HRegionServer.)    * The log file is a logfile from the previous execution that's    * custom-computed for this HRegion. The HRegionServer computes and sorts the    * appropriate log info for this HRegion. If there is a previous log file    * (implying that the HRegion has been written-to before), then read it from    * the supplied path.    * @param fs is the filesystem.    * @param confParam is global configuration settings.    * @param regionInfo - HRegionInfo that describes the region    * is new), then read them from the supplied path.    * @param rsServices reference to {@link RegionServerServices} or null    *    * @see HRegion#newHRegion(Path, HLog, FileSystem, Configuration, HRegionInfo, HTableDescriptor, RegionServerServices)    */
specifier|public
name|HRegion
parameter_list|(
name|Path
name|tableDir
parameter_list|,
name|HLog
name|log
parameter_list|,
name|FileSystem
name|fs
parameter_list|,
name|Configuration
name|confParam
parameter_list|,
specifier|final
name|HRegionInfo
name|regionInfo
parameter_list|,
specifier|final
name|HTableDescriptor
name|htd
parameter_list|,
name|RegionServerServices
name|rsServices
parameter_list|)
block|{
if|if
condition|(
name|htd
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"Need table descriptor"
argument_list|)
throw|;
block|}
name|this
operator|.
name|tableDir
operator|=
name|tableDir
expr_stmt|;
name|this
operator|.
name|comparator
operator|=
name|regionInfo
operator|.
name|getComparator
argument_list|()
expr_stmt|;
name|this
operator|.
name|log
operator|=
name|log
expr_stmt|;
name|this
operator|.
name|fs
operator|=
name|fs
expr_stmt|;
if|if
condition|(
name|confParam
operator|instanceof
name|CompoundConfiguration
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"Need original base configuration"
argument_list|)
throw|;
block|}
comment|// 'conf' renamed to 'confParam' b/c we use this.conf in the constructor
name|this
operator|.
name|baseConf
operator|=
name|confParam
expr_stmt|;
name|this
operator|.
name|conf
operator|=
operator|new
name|CompoundConfiguration
argument_list|()
operator|.
name|add
argument_list|(
name|confParam
argument_list|)
operator|.
name|addStringMap
argument_list|(
name|htd
operator|.
name|getConfiguration
argument_list|()
argument_list|)
operator|.
name|addWritableMap
argument_list|(
name|htd
operator|.
name|getValues
argument_list|()
argument_list|)
expr_stmt|;
name|this
operator|.
name|rowLockWaitDuration
operator|=
name|conf
operator|.
name|getInt
argument_list|(
literal|"hbase.rowlock.wait.duration"
argument_list|,
name|DEFAULT_ROWLOCK_WAIT_DURATION
argument_list|)
expr_stmt|;
name|this
operator|.
name|isLoadingCfsOnDemandDefault
operator|=
name|conf
operator|.
name|getBoolean
argument_list|(
name|LOAD_CFS_ON_DEMAND_CONFIG_KEY
argument_list|,
literal|false
argument_list|)
expr_stmt|;
name|this
operator|.
name|regionInfo
operator|=
name|regionInfo
expr_stmt|;
name|this
operator|.
name|htableDescriptor
operator|=
name|htd
expr_stmt|;
name|this
operator|.
name|rsServices
operator|=
name|rsServices
expr_stmt|;
name|this
operator|.
name|threadWakeFrequency
operator|=
name|conf
operator|.
name|getLong
argument_list|(
name|HConstants
operator|.
name|THREAD_WAKE_FREQUENCY
argument_list|,
literal|10
operator|*
literal|1000
argument_list|)
expr_stmt|;
name|String
name|encodedNameStr
init|=
name|this
operator|.
name|regionInfo
operator|.
name|getEncodedName
argument_list|()
decl_stmt|;
name|setHTableSpecificConf
argument_list|()
expr_stmt|;
name|this
operator|.
name|regiondir
operator|=
name|getRegionDir
argument_list|(
name|this
operator|.
name|tableDir
argument_list|,
name|encodedNameStr
argument_list|)
expr_stmt|;
name|this
operator|.
name|scannerReadPoints
operator|=
operator|new
name|ConcurrentHashMap
argument_list|<
name|RegionScanner
argument_list|,
name|Long
argument_list|>
argument_list|()
expr_stmt|;
name|this
operator|.
name|busyWaitDuration
operator|=
name|conf
operator|.
name|getLong
argument_list|(
literal|"hbase.busy.wait.duration"
argument_list|,
name|DEFAULT_BUSY_WAIT_DURATION
argument_list|)
expr_stmt|;
name|this
operator|.
name|maxBusyWaitMultiplier
operator|=
name|conf
operator|.
name|getInt
argument_list|(
literal|"hbase.busy.wait.multiplier.max"
argument_list|,
literal|2
argument_list|)
expr_stmt|;
if|if
condition|(
name|busyWaitDuration
operator|*
name|maxBusyWaitMultiplier
operator|<=
literal|0L
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"Invalid hbase.busy.wait.duration ("
operator|+
name|busyWaitDuration
operator|+
literal|") or hbase.busy.wait.multiplier.max ("
operator|+
name|maxBusyWaitMultiplier
operator|+
literal|"). Their product should be positive"
argument_list|)
throw|;
block|}
name|this
operator|.
name|maxBusyWaitDuration
operator|=
name|conf
operator|.
name|getLong
argument_list|(
literal|"ipc.client.call.purge.timeout"
argument_list|,
literal|2
operator|*
name|HConstants
operator|.
name|DEFAULT_HBASE_RPC_TIMEOUT
argument_list|)
expr_stmt|;
comment|/*      * timestamp.slop provides a server-side constraint on the timestamp. This      * assumes that you base your TS around currentTimeMillis(). In this case,      * throw an error to the user if the user-specified TS is newer than now +      * slop. LATEST_TIMESTAMP == don't use this functionality      */
name|this
operator|.
name|timestampSlop
operator|=
name|conf
operator|.
name|getLong
argument_list|(
literal|"hbase.hregion.keyvalue.timestamp.slop.millisecs"
argument_list|,
name|HConstants
operator|.
name|LATEST_TIMESTAMP
argument_list|)
expr_stmt|;
comment|/**      * Timeout for the process time in processRowsWithLocks().      * Use -1 to switch off time bound.      */
name|this
operator|.
name|rowProcessorTimeout
operator|=
name|conf
operator|.
name|getLong
argument_list|(
literal|"hbase.hregion.row.processor.timeout"
argument_list|,
name|DEFAULT_ROW_PROCESSOR_TIMEOUT
argument_list|)
expr_stmt|;
if|if
condition|(
name|rsServices
operator|!=
literal|null
condition|)
block|{
name|this
operator|.
name|rsAccounting
operator|=
name|this
operator|.
name|rsServices
operator|.
name|getRegionServerAccounting
argument_list|()
expr_stmt|;
comment|// don't initialize coprocessors if not running within a regionserver
comment|// TODO: revisit if coprocessors should load in other cases
name|this
operator|.
name|coprocessorHost
operator|=
operator|new
name|RegionCoprocessorHost
argument_list|(
name|this
argument_list|,
name|rsServices
argument_list|,
name|conf
argument_list|)
expr_stmt|;
name|this
operator|.
name|metricsRegionWrapper
operator|=
operator|new
name|MetricsRegionWrapperImpl
argument_list|(
name|this
argument_list|)
expr_stmt|;
name|this
operator|.
name|metricsRegion
operator|=
operator|new
name|MetricsRegion
argument_list|(
name|this
operator|.
name|metricsRegionWrapper
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|this
operator|.
name|metricsRegionWrapper
operator|=
literal|null
expr_stmt|;
name|this
operator|.
name|metricsRegion
operator|=
literal|null
expr_stmt|;
block|}
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
comment|// Write out region name as string and its encoded name.
name|LOG
operator|.
name|debug
argument_list|(
literal|"Instantiated "
operator|+
name|this
argument_list|)
expr_stmt|;
block|}
block|}
name|void
name|setHTableSpecificConf
parameter_list|()
block|{
if|if
condition|(
name|this
operator|.
name|htableDescriptor
operator|==
literal|null
condition|)
return|return;
name|long
name|flushSize
init|=
name|this
operator|.
name|htableDescriptor
operator|.
name|getMemStoreFlushSize
argument_list|()
decl_stmt|;
if|if
condition|(
name|flushSize
operator|<=
literal|0
condition|)
block|{
name|flushSize
operator|=
name|conf
operator|.
name|getLong
argument_list|(
name|HConstants
operator|.
name|HREGION_MEMSTORE_FLUSH_SIZE
argument_list|,
name|HTableDescriptor
operator|.
name|DEFAULT_MEMSTORE_FLUSH_SIZE
argument_list|)
expr_stmt|;
block|}
name|this
operator|.
name|memstoreFlushSize
operator|=
name|flushSize
expr_stmt|;
name|this
operator|.
name|blockingMemStoreSize
operator|=
name|this
operator|.
name|memstoreFlushSize
operator|*
name|conf
operator|.
name|getLong
argument_list|(
literal|"hbase.hregion.memstore.block.multiplier"
argument_list|,
literal|2
argument_list|)
expr_stmt|;
block|}
comment|/**    * Initialize this region.    * @return What the next sequence (edit) id should be.    * @throws IOException e    */
specifier|public
name|long
name|initialize
parameter_list|()
throws|throws
name|IOException
block|{
return|return
name|initialize
argument_list|(
literal|null
argument_list|)
return|;
block|}
comment|/**    * Initialize this region.    *    * @param reporter Tickle every so often if initialize is taking a while.    * @return What the next sequence (edit) id should be.    * @throws IOException e    */
specifier|public
name|long
name|initialize
parameter_list|(
specifier|final
name|CancelableProgressable
name|reporter
parameter_list|)
throws|throws
name|IOException
block|{
name|MonitoredTask
name|status
init|=
name|TaskMonitor
operator|.
name|get
argument_list|()
operator|.
name|createStatus
argument_list|(
literal|"Initializing region "
operator|+
name|this
argument_list|)
decl_stmt|;
name|long
name|nextSeqId
init|=
operator|-
literal|1
decl_stmt|;
try|try
block|{
name|nextSeqId
operator|=
name|initializeRegionInternals
argument_list|(
name|reporter
argument_list|,
name|status
argument_list|)
expr_stmt|;
return|return
name|nextSeqId
return|;
block|}
finally|finally
block|{
comment|// nextSeqid will be -1 if the initialization fails.
comment|// At least it will be 0 otherwise.
if|if
condition|(
name|nextSeqId
operator|==
operator|-
literal|1
condition|)
block|{
name|status
operator|.
name|abort
argument_list|(
literal|"Exception during region "
operator|+
name|this
operator|.
name|getRegionNameAsString
argument_list|()
operator|+
literal|" initialization."
argument_list|)
expr_stmt|;
block|}
block|}
block|}
specifier|private
name|long
name|initializeRegionInternals
parameter_list|(
specifier|final
name|CancelableProgressable
name|reporter
parameter_list|,
name|MonitoredTask
name|status
parameter_list|)
throws|throws
name|IOException
throws|,
name|UnsupportedEncodingException
block|{
if|if
condition|(
name|coprocessorHost
operator|!=
literal|null
condition|)
block|{
name|status
operator|.
name|setStatus
argument_list|(
literal|"Running coprocessor pre-open hook"
argument_list|)
expr_stmt|;
name|coprocessorHost
operator|.
name|preOpen
argument_list|()
expr_stmt|;
block|}
comment|// Write HRI to a file in case we need to recover .META.
name|status
operator|.
name|setStatus
argument_list|(
literal|"Writing region info on filesystem"
argument_list|)
expr_stmt|;
name|checkRegioninfoOnFilesystem
argument_list|()
expr_stmt|;
comment|// Remove temporary data left over from old regions
name|status
operator|.
name|setStatus
argument_list|(
literal|"Cleaning up temporary data from old regions"
argument_list|)
expr_stmt|;
name|cleanupTmpDir
argument_list|()
expr_stmt|;
comment|// Load in all the HStores.
comment|//
comment|// Context: During replay we want to ensure that we do not lose any data. So, we
comment|// have to be conservative in how we replay logs. For each store, we calculate
comment|// the maxSeqId up to which the store was flushed. And, skip the edits which
comment|// is equal to or lower than maxSeqId for each store.
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|Long
argument_list|>
name|maxSeqIdInStores
init|=
operator|new
name|TreeMap
argument_list|<
name|byte
index|[]
argument_list|,
name|Long
argument_list|>
argument_list|(
name|Bytes
operator|.
name|BYTES_COMPARATOR
argument_list|)
decl_stmt|;
name|long
name|maxSeqId
init|=
operator|-
literal|1
decl_stmt|;
comment|// initialized to -1 so that we pick up MemstoreTS from column families
name|long
name|maxMemstoreTS
init|=
operator|-
literal|1
decl_stmt|;
if|if
condition|(
operator|!
name|htableDescriptor
operator|.
name|getFamilies
argument_list|()
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
comment|// initialize the thread pool for opening stores in parallel.
name|ThreadPoolExecutor
name|storeOpenerThreadPool
init|=
name|getStoreOpenAndCloseThreadPool
argument_list|(
literal|"StoreOpenerThread-"
operator|+
name|this
operator|.
name|regionInfo
operator|.
name|getRegionNameAsString
argument_list|()
argument_list|)
decl_stmt|;
name|CompletionService
argument_list|<
name|HStore
argument_list|>
name|completionService
init|=
operator|new
name|ExecutorCompletionService
argument_list|<
name|HStore
argument_list|>
argument_list|(
name|storeOpenerThreadPool
argument_list|)
decl_stmt|;
comment|// initialize each store in parallel
for|for
control|(
specifier|final
name|HColumnDescriptor
name|family
range|:
name|htableDescriptor
operator|.
name|getFamilies
argument_list|()
control|)
block|{
name|status
operator|.
name|setStatus
argument_list|(
literal|"Instantiating store for column family "
operator|+
name|family
argument_list|)
expr_stmt|;
name|completionService
operator|.
name|submit
argument_list|(
operator|new
name|Callable
argument_list|<
name|HStore
argument_list|>
argument_list|()
block|{
specifier|public
name|HStore
name|call
parameter_list|()
throws|throws
name|IOException
block|{
return|return
name|instantiateHStore
argument_list|(
name|tableDir
argument_list|,
name|family
argument_list|)
return|;
block|}
block|}
argument_list|)
expr_stmt|;
block|}
try|try
block|{
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|htableDescriptor
operator|.
name|getFamilies
argument_list|()
operator|.
name|size
argument_list|()
condition|;
name|i
operator|++
control|)
block|{
name|Future
argument_list|<
name|HStore
argument_list|>
name|future
init|=
name|completionService
operator|.
name|take
argument_list|()
decl_stmt|;
name|HStore
name|store
init|=
name|future
operator|.
name|get
argument_list|()
decl_stmt|;
name|this
operator|.
name|stores
operator|.
name|put
argument_list|(
name|store
operator|.
name|getColumnFamilyName
argument_list|()
operator|.
name|getBytes
argument_list|()
argument_list|,
name|store
argument_list|)
expr_stmt|;
comment|// Do not include bulk loaded files when determining seqIdForReplay
name|long
name|storeSeqIdForReplay
init|=
name|store
operator|.
name|getMaxSequenceId
argument_list|(
literal|false
argument_list|)
decl_stmt|;
name|maxSeqIdInStores
operator|.
name|put
argument_list|(
name|store
operator|.
name|getColumnFamilyName
argument_list|()
operator|.
name|getBytes
argument_list|()
argument_list|,
name|storeSeqIdForReplay
argument_list|)
expr_stmt|;
comment|// Include bulk loaded files when determining seqIdForAssignment
name|long
name|storeSeqIdForAssignment
init|=
name|store
operator|.
name|getMaxSequenceId
argument_list|(
literal|true
argument_list|)
decl_stmt|;
if|if
condition|(
name|maxSeqId
operator|==
operator|-
literal|1
operator|||
name|storeSeqIdForAssignment
operator|>
name|maxSeqId
condition|)
block|{
name|maxSeqId
operator|=
name|storeSeqIdForAssignment
expr_stmt|;
block|}
name|long
name|maxStoreMemstoreTS
init|=
name|store
operator|.
name|getMaxMemstoreTS
argument_list|()
decl_stmt|;
if|if
condition|(
name|maxStoreMemstoreTS
operator|>
name|maxMemstoreTS
condition|)
block|{
name|maxMemstoreTS
operator|=
name|maxStoreMemstoreTS
expr_stmt|;
block|}
block|}
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|e
argument_list|)
throw|;
block|}
catch|catch
parameter_list|(
name|ExecutionException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|e
operator|.
name|getCause
argument_list|()
argument_list|)
throw|;
block|}
finally|finally
block|{
name|storeOpenerThreadPool
operator|.
name|shutdownNow
argument_list|()
expr_stmt|;
block|}
block|}
name|mvcc
operator|.
name|initialize
argument_list|(
name|maxMemstoreTS
operator|+
literal|1
argument_list|)
expr_stmt|;
comment|// Recover any edits if available.
name|maxSeqId
operator|=
name|Math
operator|.
name|max
argument_list|(
name|maxSeqId
argument_list|,
name|replayRecoveredEditsIfAny
argument_list|(
name|this
operator|.
name|regiondir
argument_list|,
name|maxSeqIdInStores
argument_list|,
name|reporter
argument_list|,
name|status
argument_list|)
argument_list|)
expr_stmt|;
name|status
operator|.
name|setStatus
argument_list|(
literal|"Cleaning up detritus from prior splits"
argument_list|)
expr_stmt|;
comment|// Get rid of any splits or merges that were lost in-progress.  Clean out
comment|// these directories here on open.  We may be opening a region that was
comment|// being split but we crashed in the middle of it all.
name|SplitTransaction
operator|.
name|cleanupAnySplitDetritus
argument_list|(
name|this
argument_list|)
expr_stmt|;
name|FSUtils
operator|.
name|deleteDirectory
argument_list|(
name|this
operator|.
name|fs
argument_list|,
operator|new
name|Path
argument_list|(
name|regiondir
argument_list|,
name|MERGEDIR
argument_list|)
argument_list|)
expr_stmt|;
name|this
operator|.
name|writestate
operator|.
name|setReadOnly
argument_list|(
name|this
operator|.
name|htableDescriptor
operator|.
name|isReadOnly
argument_list|()
argument_list|)
expr_stmt|;
name|this
operator|.
name|writestate
operator|.
name|flushRequested
operator|=
literal|false
expr_stmt|;
name|this
operator|.
name|writestate
operator|.
name|compacting
operator|=
literal|0
expr_stmt|;
comment|// Initialize split policy
name|this
operator|.
name|splitPolicy
operator|=
name|RegionSplitPolicy
operator|.
name|create
argument_list|(
name|this
argument_list|,
name|conf
argument_list|)
expr_stmt|;
name|this
operator|.
name|lastFlushTime
operator|=
name|EnvironmentEdgeManager
operator|.
name|currentTimeMillis
argument_list|()
expr_stmt|;
comment|// Use maximum of log sequenceid or that which was found in stores
comment|// (particularly if no recovered edits, seqid will be -1).
name|long
name|nextSeqid
init|=
name|maxSeqId
operator|+
literal|1
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Onlined "
operator|+
name|this
operator|.
name|toString
argument_list|()
operator|+
literal|"; next sequenceid="
operator|+
name|nextSeqid
argument_list|)
expr_stmt|;
comment|// A region can be reopened if failed a split; reset flags
name|this
operator|.
name|closing
operator|.
name|set
argument_list|(
literal|false
argument_list|)
expr_stmt|;
name|this
operator|.
name|closed
operator|.
name|set
argument_list|(
literal|false
argument_list|)
expr_stmt|;
if|if
condition|(
name|coprocessorHost
operator|!=
literal|null
condition|)
block|{
name|status
operator|.
name|setStatus
argument_list|(
literal|"Running coprocessor post-open hooks"
argument_list|)
expr_stmt|;
name|coprocessorHost
operator|.
name|postOpen
argument_list|()
expr_stmt|;
block|}
name|status
operator|.
name|markComplete
argument_list|(
literal|"Region opened successfully"
argument_list|)
expr_stmt|;
return|return
name|nextSeqid
return|;
block|}
comment|/*    * Move any passed HStore files into place (if any).  Used to pick up split    * files and any merges from splits and merges dirs.    * @param initialFiles    * @throws IOException    */
specifier|static
name|void
name|moveInitialFilesIntoPlace
parameter_list|(
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Path
name|initialFiles
parameter_list|,
specifier|final
name|Path
name|regiondir
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|initialFiles
operator|!=
literal|null
operator|&&
name|fs
operator|.
name|exists
argument_list|(
name|initialFiles
argument_list|)
condition|)
block|{
if|if
condition|(
operator|!
name|fs
operator|.
name|rename
argument_list|(
name|initialFiles
argument_list|,
name|regiondir
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Unable to rename "
operator|+
name|initialFiles
operator|+
literal|" to "
operator|+
name|regiondir
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|/**    * @return True if this region has references.    */
specifier|public
name|boolean
name|hasReferences
parameter_list|()
block|{
for|for
control|(
name|Store
name|store
range|:
name|this
operator|.
name|stores
operator|.
name|values
argument_list|()
control|)
block|{
for|for
control|(
name|StoreFile
name|sf
range|:
name|store
operator|.
name|getStorefiles
argument_list|()
control|)
block|{
comment|// Found a reference, return.
if|if
condition|(
name|sf
operator|.
name|isReference
argument_list|()
condition|)
return|return
literal|true
return|;
block|}
block|}
return|return
literal|false
return|;
block|}
comment|/**    * This function will return the HDFS blocks distribution based on the data    * captured when HFile is created    * @return The HDFS blocks distribution for the region.    */
specifier|public
name|HDFSBlocksDistribution
name|getHDFSBlocksDistribution
parameter_list|()
block|{
name|HDFSBlocksDistribution
name|hdfsBlocksDistribution
init|=
operator|new
name|HDFSBlocksDistribution
argument_list|()
decl_stmt|;
synchronized|synchronized
init|(
name|this
operator|.
name|stores
init|)
block|{
for|for
control|(
name|Store
name|store
range|:
name|this
operator|.
name|stores
operator|.
name|values
argument_list|()
control|)
block|{
for|for
control|(
name|StoreFile
name|sf
range|:
name|store
operator|.
name|getStorefiles
argument_list|()
control|)
block|{
name|HDFSBlocksDistribution
name|storeFileBlocksDistribution
init|=
name|sf
operator|.
name|getHDFSBlockDistribution
argument_list|()
decl_stmt|;
name|hdfsBlocksDistribution
operator|.
name|add
argument_list|(
name|storeFileBlocksDistribution
argument_list|)
expr_stmt|;
block|}
block|}
block|}
return|return
name|hdfsBlocksDistribution
return|;
block|}
comment|/**    * This is a helper function to compute HDFS block distribution on demand    * @param conf configuration    * @param tableDescriptor HTableDescriptor of the table    * @param regionEncodedName encoded name of the region    * @return The HDFS blocks distribution for the given region.  * @throws IOException    */
specifier|static
specifier|public
name|HDFSBlocksDistribution
name|computeHDFSBlocksDistribution
parameter_list|(
name|Configuration
name|conf
parameter_list|,
name|HTableDescriptor
name|tableDescriptor
parameter_list|,
name|String
name|regionEncodedName
parameter_list|)
throws|throws
name|IOException
block|{
name|HDFSBlocksDistribution
name|hdfsBlocksDistribution
init|=
operator|new
name|HDFSBlocksDistribution
argument_list|()
decl_stmt|;
name|Path
name|tablePath
init|=
name|FSUtils
operator|.
name|getTablePath
argument_list|(
name|FSUtils
operator|.
name|getRootDir
argument_list|(
name|conf
argument_list|)
argument_list|,
name|tableDescriptor
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
name|FileSystem
name|fs
init|=
name|tablePath
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
decl_stmt|;
for|for
control|(
name|HColumnDescriptor
name|family
range|:
name|tableDescriptor
operator|.
name|getFamilies
argument_list|()
control|)
block|{
name|Path
name|storeHomeDir
init|=
name|HStore
operator|.
name|getStoreHomedir
argument_list|(
name|tablePath
argument_list|,
name|regionEncodedName
argument_list|,
name|family
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|fs
operator|.
name|exists
argument_list|(
name|storeHomeDir
argument_list|)
condition|)
continue|continue;
name|FileStatus
index|[]
name|hfilesStatus
init|=
literal|null
decl_stmt|;
name|hfilesStatus
operator|=
name|fs
operator|.
name|listStatus
argument_list|(
name|storeHomeDir
argument_list|)
expr_stmt|;
for|for
control|(
name|FileStatus
name|hfileStatus
range|:
name|hfilesStatus
control|)
block|{
name|HDFSBlocksDistribution
name|storeFileBlocksDistribution
init|=
name|FSUtils
operator|.
name|computeHDFSBlocksDistribution
argument_list|(
name|fs
argument_list|,
name|hfileStatus
argument_list|,
literal|0
argument_list|,
name|hfileStatus
operator|.
name|getLen
argument_list|()
argument_list|)
decl_stmt|;
name|hdfsBlocksDistribution
operator|.
name|add
argument_list|(
name|storeFileBlocksDistribution
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|hdfsBlocksDistribution
return|;
block|}
specifier|public
name|AtomicLong
name|getMemstoreSize
parameter_list|()
block|{
return|return
name|memstoreSize
return|;
block|}
comment|/**    * Increase the size of mem store in this region and the size of global mem    * store    * @param memStoreSize    * @return the size of memstore in this region    */
specifier|public
name|long
name|addAndGetGlobalMemstoreSize
parameter_list|(
name|long
name|memStoreSize
parameter_list|)
block|{
if|if
condition|(
name|this
operator|.
name|rsAccounting
operator|!=
literal|null
condition|)
block|{
name|rsAccounting
operator|.
name|addAndGetGlobalMemstoreSize
argument_list|(
name|memStoreSize
argument_list|)
expr_stmt|;
block|}
return|return
name|this
operator|.
name|memstoreSize
operator|.
name|getAndAdd
argument_list|(
name|memStoreSize
argument_list|)
return|;
block|}
comment|/**    * Write out an info file under the stored region directory. Useful recovering mangled regions.    * @throws IOException    */
specifier|private
name|void
name|checkRegioninfoOnFilesystem
parameter_list|()
throws|throws
name|IOException
block|{
name|checkRegioninfoOnFilesystem
argument_list|(
name|this
operator|.
name|regiondir
argument_list|)
expr_stmt|;
block|}
comment|/**    * Write out an info file under the region directory. Useful recovering mangled regions.    * @param regiondir directory under which to write out the region info    * @throws IOException    */
specifier|private
name|void
name|checkRegioninfoOnFilesystem
parameter_list|(
name|Path
name|regiondir
parameter_list|)
throws|throws
name|IOException
block|{
name|writeRegioninfoOnFilesystem
argument_list|(
name|regionInfo
argument_list|,
name|regiondir
argument_list|,
name|getFilesystem
argument_list|()
argument_list|,
name|conf
argument_list|)
expr_stmt|;
block|}
comment|/**    * Write out an info file under the region directory. Useful recovering mangled regions. If the    * regioninfo already exists on disk and there is information in the file, then we fast exit.    * @param regionInfo information about the region    * @param regiondir directory under which to write out the region info    * @param fs {@link FileSystem} on which to write the region info    * @param conf {@link Configuration} from which to extract specific file locations    * @throws IOException on unexpected error.    */
specifier|public
specifier|static
name|void
name|writeRegioninfoOnFilesystem
parameter_list|(
name|HRegionInfo
name|regionInfo
parameter_list|,
name|Path
name|regiondir
parameter_list|,
name|FileSystem
name|fs
parameter_list|,
name|Configuration
name|conf
parameter_list|)
throws|throws
name|IOException
block|{
name|Path
name|regioninfoPath
init|=
operator|new
name|Path
argument_list|(
name|regiondir
argument_list|,
name|REGIONINFO_FILE
argument_list|)
decl_stmt|;
comment|// Compose the content of the file so we can compare to length in filesystem. If not same,
comment|// rewrite it (it may have been written in the old format using Writables instead of pb). The
comment|// pb version is much shorter -- we write now w/o the toString version -- so checking length
comment|// only should be sufficient. I don't want to read the file every time to check if it pb
comment|// serialized.
name|byte
index|[]
name|content
init|=
name|getDotRegionInfoFileContent
argument_list|(
name|regionInfo
argument_list|)
decl_stmt|;
name|boolean
name|exists
init|=
name|fs
operator|.
name|exists
argument_list|(
name|regioninfoPath
argument_list|)
decl_stmt|;
name|FileStatus
name|status
init|=
name|exists
condition|?
name|fs
operator|.
name|getFileStatus
argument_list|(
name|regioninfoPath
argument_list|)
else|:
literal|null
decl_stmt|;
if|if
condition|(
name|status
operator|!=
literal|null
operator|&&
name|status
operator|.
name|getLen
argument_list|()
operator|==
name|content
operator|.
name|length
condition|)
block|{
comment|// Then assume the content good and move on.
return|return;
block|}
comment|// Create in tmpdir and then move into place in case we crash after
comment|// create but before close. If we don't successfully close the file,
comment|// subsequent region reopens will fail the below because create is
comment|// registered in NN.
comment|// First check to get the permissions
name|FsPermission
name|perms
init|=
name|FSUtils
operator|.
name|getFilePermissions
argument_list|(
name|fs
argument_list|,
name|conf
argument_list|,
name|HConstants
operator|.
name|DATA_FILE_UMASK_KEY
argument_list|)
decl_stmt|;
comment|// And then create the file
name|Path
name|tmpPath
init|=
operator|new
name|Path
argument_list|(
name|getTmpDir
argument_list|(
name|regiondir
argument_list|)
argument_list|,
name|REGIONINFO_FILE
argument_list|)
decl_stmt|;
comment|// If datanode crashes or if the RS goes down just before the close is called while trying to
comment|// close the created regioninfo file in the .tmp directory then on next
comment|// creation we will be getting AlreadyCreatedException.
comment|// Hence delete and create the file if exists.
if|if
condition|(
name|FSUtils
operator|.
name|isExists
argument_list|(
name|fs
argument_list|,
name|tmpPath
argument_list|)
condition|)
block|{
name|FSUtils
operator|.
name|delete
argument_list|(
name|fs
argument_list|,
name|tmpPath
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
name|FSDataOutputStream
name|out
init|=
name|FSUtils
operator|.
name|create
argument_list|(
name|fs
argument_list|,
name|tmpPath
argument_list|,
name|perms
argument_list|)
decl_stmt|;
try|try
block|{
comment|// We used to write out this file as serialized Writable followed by '\n\n' and then the
comment|// toString of the HRegionInfo but now we just write out the pb serialized bytes so we can
comment|// for sure tell whether the content has been pb'd or not just by looking at file length; the
comment|// pb version will be shorter.
name|out
operator|.
name|write
argument_list|(
name|content
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|out
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|exists
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Rewriting .regioninfo file at "
operator|+
name|regioninfoPath
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|fs
operator|.
name|delete
argument_list|(
name|regioninfoPath
argument_list|,
literal|false
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Unable to remove existing "
operator|+
name|regioninfoPath
argument_list|)
throw|;
block|}
block|}
if|if
condition|(
operator|!
name|fs
operator|.
name|rename
argument_list|(
name|tmpPath
argument_list|,
name|regioninfoPath
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Unable to rename "
operator|+
name|tmpPath
operator|+
literal|" to "
operator|+
name|regioninfoPath
argument_list|)
throw|;
block|}
block|}
comment|/**    * @param hri    * @return Content of the file we write out to the filesystem under a region    * @throws IOException    */
specifier|private
specifier|static
name|byte
index|[]
name|getDotRegionInfoFileContent
parameter_list|(
specifier|final
name|HRegionInfo
name|hri
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|hri
operator|.
name|toDelimitedByteArray
argument_list|()
return|;
block|}
comment|/**    * @param fs    * @param dir    * @return An HRegionInfo instance gotten from the<code>.regioninfo</code> file under region dir    * @throws IOException    */
specifier|public
specifier|static
name|HRegionInfo
name|loadDotRegionInfoFileContent
parameter_list|(
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Path
name|dir
parameter_list|)
throws|throws
name|IOException
block|{
name|Path
name|regioninfo
init|=
operator|new
name|Path
argument_list|(
name|dir
argument_list|,
name|HRegion
operator|.
name|REGIONINFO_FILE
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|fs
operator|.
name|exists
argument_list|(
name|regioninfo
argument_list|)
condition|)
throw|throw
operator|new
name|FileNotFoundException
argument_list|(
name|regioninfo
operator|.
name|toString
argument_list|()
argument_list|)
throw|;
name|FSDataInputStream
name|in
init|=
name|fs
operator|.
name|open
argument_list|(
name|regioninfo
argument_list|)
decl_stmt|;
try|try
block|{
return|return
name|HRegionInfo
operator|.
name|parseFrom
argument_list|(
name|in
argument_list|)
return|;
block|}
finally|finally
block|{
name|in
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
block|}
comment|/** @return a HRegionInfo object for this region */
specifier|public
name|HRegionInfo
name|getRegionInfo
parameter_list|()
block|{
return|return
name|this
operator|.
name|regionInfo
return|;
block|}
comment|/**    * @return Instance of {@link RegionServerServices} used by this HRegion.    * Can be null.    */
name|RegionServerServices
name|getRegionServerServices
parameter_list|()
block|{
return|return
name|this
operator|.
name|rsServices
return|;
block|}
comment|/** @return readRequestsCount for this region */
name|long
name|getReadRequestsCount
parameter_list|()
block|{
return|return
name|this
operator|.
name|readRequestsCount
operator|.
name|get
argument_list|()
return|;
block|}
comment|/** @return writeRequestsCount for this region */
name|long
name|getWriteRequestsCount
parameter_list|()
block|{
return|return
name|this
operator|.
name|writeRequestsCount
operator|.
name|get
argument_list|()
return|;
block|}
name|MetricsRegion
name|getMetrics
parameter_list|()
block|{
return|return
name|metricsRegion
return|;
block|}
comment|/** @return true if region is closed */
specifier|public
name|boolean
name|isClosed
parameter_list|()
block|{
return|return
name|this
operator|.
name|closed
operator|.
name|get
argument_list|()
return|;
block|}
comment|/**    * @return True if closing process has started.    */
specifier|public
name|boolean
name|isClosing
parameter_list|()
block|{
return|return
name|this
operator|.
name|closing
operator|.
name|get
argument_list|()
return|;
block|}
comment|/** @return true if region is available (not closed and not closing) */
specifier|public
name|boolean
name|isAvailable
parameter_list|()
block|{
return|return
operator|!
name|isClosed
argument_list|()
operator|&&
operator|!
name|isClosing
argument_list|()
return|;
block|}
comment|/** @return true if region is splittable */
specifier|public
name|boolean
name|isSplittable
parameter_list|()
block|{
return|return
name|isAvailable
argument_list|()
operator|&&
operator|!
name|hasReferences
argument_list|()
return|;
block|}
name|boolean
name|areWritesEnabled
parameter_list|()
block|{
synchronized|synchronized
init|(
name|this
operator|.
name|writestate
init|)
block|{
return|return
name|this
operator|.
name|writestate
operator|.
name|writesEnabled
return|;
block|}
block|}
specifier|public
name|MultiVersionConsistencyControl
name|getMVCC
parameter_list|()
block|{
return|return
name|mvcc
return|;
block|}
specifier|public
name|boolean
name|isLoadingCfsOnDemandDefault
parameter_list|()
block|{
return|return
name|this
operator|.
name|isLoadingCfsOnDemandDefault
return|;
block|}
comment|/**    * Close down this HRegion.  Flush the cache, shut down each HStore, don't    * service any more calls.    *    *<p>This method could take some time to execute, so don't call it from a    * time-sensitive thread.    *    * @return Vector of all the storage files that the HRegion's component    * HStores make use of.  It's a list of all HStoreFile objects. Returns empty    * vector if already closed and null if judged that it should not close.    *    * @throws IOException e    */
specifier|public
name|List
argument_list|<
name|StoreFile
argument_list|>
name|close
parameter_list|()
throws|throws
name|IOException
block|{
return|return
name|close
argument_list|(
literal|false
argument_list|)
return|;
block|}
specifier|private
specifier|final
name|Object
name|closeLock
init|=
operator|new
name|Object
argument_list|()
decl_stmt|;
comment|/**    * Close down this HRegion.  Flush the cache unless abort parameter is true,    * Shut down each HStore, don't service any more calls.    *    * This method could take some time to execute, so don't call it from a    * time-sensitive thread.    *    * @param abort true if server is aborting (only during testing)    * @return Vector of all the storage files that the HRegion's component    * HStores make use of.  It's a list of HStoreFile objects.  Can be null if    * we are not to close at this time or we are already closed.    *    * @throws IOException e    */
specifier|public
name|List
argument_list|<
name|StoreFile
argument_list|>
name|close
parameter_list|(
specifier|final
name|boolean
name|abort
parameter_list|)
throws|throws
name|IOException
block|{
comment|// Only allow one thread to close at a time. Serialize them so dual
comment|// threads attempting to close will run up against each other.
name|MonitoredTask
name|status
init|=
name|TaskMonitor
operator|.
name|get
argument_list|()
operator|.
name|createStatus
argument_list|(
literal|"Closing region "
operator|+
name|this
operator|+
operator|(
name|abort
condition|?
literal|" due to abort"
else|:
literal|""
operator|)
argument_list|)
decl_stmt|;
name|status
operator|.
name|setStatus
argument_list|(
literal|"Waiting for close lock"
argument_list|)
expr_stmt|;
try|try
block|{
synchronized|synchronized
init|(
name|closeLock
init|)
block|{
return|return
name|doClose
argument_list|(
name|abort
argument_list|,
name|status
argument_list|)
return|;
block|}
block|}
finally|finally
block|{
name|status
operator|.
name|cleanup
argument_list|()
expr_stmt|;
block|}
block|}
specifier|private
name|List
argument_list|<
name|StoreFile
argument_list|>
name|doClose
parameter_list|(
specifier|final
name|boolean
name|abort
parameter_list|,
name|MonitoredTask
name|status
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|isClosed
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Region "
operator|+
name|this
operator|+
literal|" already closed"
argument_list|)
expr_stmt|;
return|return
literal|null
return|;
block|}
if|if
condition|(
name|coprocessorHost
operator|!=
literal|null
condition|)
block|{
name|status
operator|.
name|setStatus
argument_list|(
literal|"Running coprocessor pre-close hooks"
argument_list|)
expr_stmt|;
name|this
operator|.
name|coprocessorHost
operator|.
name|preClose
argument_list|(
name|abort
argument_list|)
expr_stmt|;
block|}
name|status
operator|.
name|setStatus
argument_list|(
literal|"Disabling compacts and flushes for region"
argument_list|)
expr_stmt|;
name|boolean
name|wasFlushing
init|=
literal|false
decl_stmt|;
synchronized|synchronized
init|(
name|writestate
init|)
block|{
comment|// Disable compacting and flushing by background threads for this
comment|// region.
name|writestate
operator|.
name|writesEnabled
operator|=
literal|false
expr_stmt|;
name|wasFlushing
operator|=
name|writestate
operator|.
name|flushing
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Closing "
operator|+
name|this
operator|+
literal|": disabling compactions& flushes"
argument_list|)
expr_stmt|;
name|waitForFlushesAndCompactions
argument_list|()
expr_stmt|;
block|}
comment|// If we were not just flushing, is it worth doing a preflush...one
comment|// that will clear out of the bulk of the memstore before we put up
comment|// the close flag?
if|if
condition|(
operator|!
name|abort
operator|&&
operator|!
name|wasFlushing
operator|&&
name|worthPreFlushing
argument_list|()
condition|)
block|{
name|status
operator|.
name|setStatus
argument_list|(
literal|"Pre-flushing region before close"
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Running close preflush of "
operator|+
name|this
operator|.
name|getRegionNameAsString
argument_list|()
argument_list|)
expr_stmt|;
name|internalFlushcache
argument_list|(
name|status
argument_list|)
expr_stmt|;
block|}
name|this
operator|.
name|closing
operator|.
name|set
argument_list|(
literal|true
argument_list|)
expr_stmt|;
name|status
operator|.
name|setStatus
argument_list|(
literal|"Disabling writes for close"
argument_list|)
expr_stmt|;
comment|// block waiting for the lock for closing
name|lock
operator|.
name|writeLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
if|if
condition|(
name|this
operator|.
name|isClosed
argument_list|()
condition|)
block|{
name|status
operator|.
name|abort
argument_list|(
literal|"Already got closed by another process"
argument_list|)
expr_stmt|;
comment|// SplitTransaction handles the null
return|return
literal|null
return|;
block|}
name|LOG
operator|.
name|debug
argument_list|(
literal|"Updates disabled for region "
operator|+
name|this
argument_list|)
expr_stmt|;
comment|// Don't flush the cache if we are aborting
if|if
condition|(
operator|!
name|abort
condition|)
block|{
name|internalFlushcache
argument_list|(
name|status
argument_list|)
expr_stmt|;
block|}
name|List
argument_list|<
name|StoreFile
argument_list|>
name|result
init|=
operator|new
name|ArrayList
argument_list|<
name|StoreFile
argument_list|>
argument_list|()
decl_stmt|;
if|if
condition|(
operator|!
name|stores
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
comment|// initialize the thread pool for closing stores in parallel.
name|ThreadPoolExecutor
name|storeCloserThreadPool
init|=
name|getStoreOpenAndCloseThreadPool
argument_list|(
literal|"StoreCloserThread-"
operator|+
name|this
operator|.
name|regionInfo
operator|.
name|getRegionNameAsString
argument_list|()
argument_list|)
decl_stmt|;
name|CompletionService
argument_list|<
name|ImmutableList
argument_list|<
name|StoreFile
argument_list|>
argument_list|>
name|completionService
init|=
operator|new
name|ExecutorCompletionService
argument_list|<
name|ImmutableList
argument_list|<
name|StoreFile
argument_list|>
argument_list|>
argument_list|(
name|storeCloserThreadPool
argument_list|)
decl_stmt|;
comment|// close each store in parallel
for|for
control|(
specifier|final
name|Store
name|store
range|:
name|stores
operator|.
name|values
argument_list|()
control|)
block|{
name|completionService
operator|.
name|submit
argument_list|(
operator|new
name|Callable
argument_list|<
name|ImmutableList
argument_list|<
name|StoreFile
argument_list|>
argument_list|>
argument_list|()
block|{
specifier|public
name|ImmutableList
argument_list|<
name|StoreFile
argument_list|>
name|call
parameter_list|()
throws|throws
name|IOException
block|{
return|return
name|store
operator|.
name|close
argument_list|()
return|;
block|}
block|}
argument_list|)
expr_stmt|;
block|}
try|try
block|{
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|stores
operator|.
name|size
argument_list|()
condition|;
name|i
operator|++
control|)
block|{
name|Future
argument_list|<
name|ImmutableList
argument_list|<
name|StoreFile
argument_list|>
argument_list|>
name|future
init|=
name|completionService
operator|.
name|take
argument_list|()
decl_stmt|;
name|ImmutableList
argument_list|<
name|StoreFile
argument_list|>
name|storeFileList
init|=
name|future
operator|.
name|get
argument_list|()
decl_stmt|;
name|result
operator|.
name|addAll
argument_list|(
name|storeFileList
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|e
argument_list|)
throw|;
block|}
catch|catch
parameter_list|(
name|ExecutionException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|e
operator|.
name|getCause
argument_list|()
argument_list|)
throw|;
block|}
finally|finally
block|{
name|storeCloserThreadPool
operator|.
name|shutdownNow
argument_list|()
expr_stmt|;
block|}
block|}
name|this
operator|.
name|closed
operator|.
name|set
argument_list|(
literal|true
argument_list|)
expr_stmt|;
if|if
condition|(
name|coprocessorHost
operator|!=
literal|null
condition|)
block|{
name|status
operator|.
name|setStatus
argument_list|(
literal|"Running coprocessor post-close hooks"
argument_list|)
expr_stmt|;
name|this
operator|.
name|coprocessorHost
operator|.
name|postClose
argument_list|(
name|abort
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|this
operator|.
name|metricsRegion
operator|!=
literal|null
condition|)
block|{
name|this
operator|.
name|metricsRegion
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|this
operator|.
name|metricsRegionWrapper
operator|!=
literal|null
condition|)
block|{
name|Closeables
operator|.
name|closeQuietly
argument_list|(
name|this
operator|.
name|metricsRegionWrapper
argument_list|)
expr_stmt|;
block|}
name|status
operator|.
name|markComplete
argument_list|(
literal|"Closed"
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Closed "
operator|+
name|this
argument_list|)
expr_stmt|;
return|return
name|result
return|;
block|}
finally|finally
block|{
name|lock
operator|.
name|writeLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**    * Wait for all current flushes and compactions of the region to complete.    *<p>    * Exposed for TESTING.    */
specifier|public
name|void
name|waitForFlushesAndCompactions
parameter_list|()
block|{
synchronized|synchronized
init|(
name|writestate
init|)
block|{
while|while
condition|(
name|writestate
operator|.
name|compacting
operator|>
literal|0
operator|||
name|writestate
operator|.
name|flushing
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"waiting for "
operator|+
name|writestate
operator|.
name|compacting
operator|+
literal|" compactions"
operator|+
operator|(
name|writestate
operator|.
name|flushing
condition|?
literal|"& cache flush"
else|:
literal|""
operator|)
operator|+
literal|" to complete for region "
operator|+
name|this
argument_list|)
expr_stmt|;
try|try
block|{
name|writestate
operator|.
name|wait
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|iex
parameter_list|)
block|{
comment|// essentially ignore and propagate the interrupt back up
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|interrupt
argument_list|()
expr_stmt|;
block|}
block|}
block|}
block|}
specifier|protected
name|ThreadPoolExecutor
name|getStoreOpenAndCloseThreadPool
parameter_list|(
specifier|final
name|String
name|threadNamePrefix
parameter_list|)
block|{
name|int
name|numStores
init|=
name|Math
operator|.
name|max
argument_list|(
literal|1
argument_list|,
name|this
operator|.
name|htableDescriptor
operator|.
name|getFamilies
argument_list|()
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
name|int
name|maxThreads
init|=
name|Math
operator|.
name|min
argument_list|(
name|numStores
argument_list|,
name|conf
operator|.
name|getInt
argument_list|(
name|HConstants
operator|.
name|HSTORE_OPEN_AND_CLOSE_THREADS_MAX
argument_list|,
name|HConstants
operator|.
name|DEFAULT_HSTORE_OPEN_AND_CLOSE_THREADS_MAX
argument_list|)
argument_list|)
decl_stmt|;
return|return
name|getOpenAndCloseThreadPool
argument_list|(
name|maxThreads
argument_list|,
name|threadNamePrefix
argument_list|)
return|;
block|}
specifier|protected
name|ThreadPoolExecutor
name|getStoreFileOpenAndCloseThreadPool
parameter_list|(
specifier|final
name|String
name|threadNamePrefix
parameter_list|)
block|{
name|int
name|numStores
init|=
name|Math
operator|.
name|max
argument_list|(
literal|1
argument_list|,
name|this
operator|.
name|htableDescriptor
operator|.
name|getFamilies
argument_list|()
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
name|int
name|maxThreads
init|=
name|Math
operator|.
name|max
argument_list|(
literal|1
argument_list|,
name|conf
operator|.
name|getInt
argument_list|(
name|HConstants
operator|.
name|HSTORE_OPEN_AND_CLOSE_THREADS_MAX
argument_list|,
name|HConstants
operator|.
name|DEFAULT_HSTORE_OPEN_AND_CLOSE_THREADS_MAX
argument_list|)
operator|/
name|numStores
argument_list|)
decl_stmt|;
return|return
name|getOpenAndCloseThreadPool
argument_list|(
name|maxThreads
argument_list|,
name|threadNamePrefix
argument_list|)
return|;
block|}
specifier|static
name|ThreadPoolExecutor
name|getOpenAndCloseThreadPool
parameter_list|(
name|int
name|maxThreads
parameter_list|,
specifier|final
name|String
name|threadNamePrefix
parameter_list|)
block|{
return|return
name|Threads
operator|.
name|getBoundedCachedThreadPool
argument_list|(
name|maxThreads
argument_list|,
literal|30L
argument_list|,
name|TimeUnit
operator|.
name|SECONDS
argument_list|,
operator|new
name|ThreadFactory
argument_list|()
block|{
specifier|private
name|int
name|count
init|=
literal|1
decl_stmt|;
specifier|public
name|Thread
name|newThread
parameter_list|(
name|Runnable
name|r
parameter_list|)
block|{
return|return
operator|new
name|Thread
argument_list|(
name|r
argument_list|,
name|threadNamePrefix
operator|+
literal|"-"
operator|+
name|count
operator|++
argument_list|)
return|;
block|}
block|}
argument_list|)
return|;
block|}
comment|/**     * @return True if its worth doing a flush before we put up the close flag.     */
specifier|private
name|boolean
name|worthPreFlushing
parameter_list|()
block|{
return|return
name|this
operator|.
name|memstoreSize
operator|.
name|get
argument_list|()
operator|>
name|this
operator|.
name|conf
operator|.
name|getLong
argument_list|(
literal|"hbase.hregion.preclose.flush.size"
argument_list|,
literal|1024
operator|*
literal|1024
operator|*
literal|5
argument_list|)
return|;
block|}
comment|//////////////////////////////////////////////////////////////////////////////
comment|// HRegion accessors
comment|//////////////////////////////////////////////////////////////////////////////
comment|/** @return start key for region */
specifier|public
name|byte
index|[]
name|getStartKey
parameter_list|()
block|{
return|return
name|this
operator|.
name|regionInfo
operator|.
name|getStartKey
argument_list|()
return|;
block|}
comment|/** @return end key for region */
specifier|public
name|byte
index|[]
name|getEndKey
parameter_list|()
block|{
return|return
name|this
operator|.
name|regionInfo
operator|.
name|getEndKey
argument_list|()
return|;
block|}
comment|/** @return region id */
specifier|public
name|long
name|getRegionId
parameter_list|()
block|{
return|return
name|this
operator|.
name|regionInfo
operator|.
name|getRegionId
argument_list|()
return|;
block|}
comment|/** @return region name */
specifier|public
name|byte
index|[]
name|getRegionName
parameter_list|()
block|{
return|return
name|this
operator|.
name|regionInfo
operator|.
name|getRegionName
argument_list|()
return|;
block|}
comment|/** @return region name as string for logging */
specifier|public
name|String
name|getRegionNameAsString
parameter_list|()
block|{
return|return
name|this
operator|.
name|regionInfo
operator|.
name|getRegionNameAsString
argument_list|()
return|;
block|}
comment|/** @return HTableDescriptor for this region */
specifier|public
name|HTableDescriptor
name|getTableDesc
parameter_list|()
block|{
return|return
name|this
operator|.
name|htableDescriptor
return|;
block|}
comment|/** @return HLog in use for this region */
specifier|public
name|HLog
name|getLog
parameter_list|()
block|{
return|return
name|this
operator|.
name|log
return|;
block|}
comment|/**    * A split takes the config from the parent region& passes it to the daughter    * region's constructor. If 'conf' was passed, you would end up using the HTD    * of the parent region in addition to the new daughter HTD. Pass 'baseConf'    * to the daughter regions to avoid this tricky dedupe problem.    * @return Configuration object    */
name|Configuration
name|getBaseConf
parameter_list|()
block|{
return|return
name|this
operator|.
name|baseConf
return|;
block|}
comment|/** @return region directory Path */
specifier|public
name|Path
name|getRegionDir
parameter_list|()
block|{
return|return
name|this
operator|.
name|regiondir
return|;
block|}
comment|/**    * Computes the Path of the HRegion    *    * @param tabledir qualified path for table    * @param name ENCODED region name    * @return Path of HRegion directory    */
specifier|public
specifier|static
name|Path
name|getRegionDir
parameter_list|(
specifier|final
name|Path
name|tabledir
parameter_list|,
specifier|final
name|String
name|name
parameter_list|)
block|{
return|return
operator|new
name|Path
argument_list|(
name|tabledir
argument_list|,
name|name
argument_list|)
return|;
block|}
comment|/** @return FileSystem being used by this region */
specifier|public
name|FileSystem
name|getFilesystem
parameter_list|()
block|{
return|return
name|this
operator|.
name|fs
return|;
block|}
comment|/** @return the last time the region was flushed */
specifier|public
name|long
name|getLastFlushTime
parameter_list|()
block|{
return|return
name|this
operator|.
name|lastFlushTime
return|;
block|}
comment|//////////////////////////////////////////////////////////////////////////////
comment|// HRegion maintenance.
comment|//
comment|// These methods are meant to be called periodically by the HRegionServer for
comment|// upkeep.
comment|//////////////////////////////////////////////////////////////////////////////
comment|/** @return returns size of largest HStore. */
specifier|public
name|long
name|getLargestHStoreSize
parameter_list|()
block|{
name|long
name|size
init|=
literal|0
decl_stmt|;
for|for
control|(
name|Store
name|h
range|:
name|stores
operator|.
name|values
argument_list|()
control|)
block|{
name|long
name|storeSize
init|=
name|h
operator|.
name|getSize
argument_list|()
decl_stmt|;
if|if
condition|(
name|storeSize
operator|>
name|size
condition|)
block|{
name|size
operator|=
name|storeSize
expr_stmt|;
block|}
block|}
return|return
name|size
return|;
block|}
comment|/*    * Do preparation for pending compaction.    * @throws IOException    */
name|void
name|doRegionCompactionPrep
parameter_list|()
throws|throws
name|IOException
block|{   }
comment|/*    * Removes the temporary directory for this Store.    */
specifier|private
name|void
name|cleanupTmpDir
parameter_list|()
throws|throws
name|IOException
block|{
name|FSUtils
operator|.
name|deleteDirectory
argument_list|(
name|this
operator|.
name|fs
argument_list|,
name|getTmpDir
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|/**    * Get the temporary directory for this region. This directory    * will have its contents removed when the region is reopened.    */
name|Path
name|getTmpDir
parameter_list|()
block|{
return|return
name|getTmpDir
argument_list|(
name|getRegionDir
argument_list|()
argument_list|)
return|;
block|}
comment|/**    * Get the temporary directory for the specified region. This directory    * will have its contents removed when the region is reopened.    */
specifier|static
name|Path
name|getTmpDir
parameter_list|(
name|Path
name|regionDir
parameter_list|)
block|{
return|return
operator|new
name|Path
argument_list|(
name|regionDir
argument_list|,
name|REGION_TEMP_SUBDIR
argument_list|)
return|;
block|}
name|void
name|triggerMajorCompaction
parameter_list|()
block|{
for|for
control|(
name|Store
name|h
range|:
name|stores
operator|.
name|values
argument_list|()
control|)
block|{
name|h
operator|.
name|triggerMajorCompaction
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**    * This is a helper function that compact all the stores synchronously    * It is used by utilities and testing    *    * @param majorCompaction True to force a major compaction regardless of thresholds    * @throws IOException e    */
specifier|public
name|void
name|compactStores
parameter_list|(
specifier|final
name|boolean
name|majorCompaction
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|majorCompaction
condition|)
block|{
name|this
operator|.
name|triggerMajorCompaction
argument_list|()
expr_stmt|;
block|}
name|compactStores
argument_list|()
expr_stmt|;
block|}
comment|/**    * This is a helper function that compact all the stores synchronously    * It is used by utilities and testing    *    * @throws IOException e    */
specifier|public
name|void
name|compactStores
parameter_list|()
throws|throws
name|IOException
block|{
for|for
control|(
name|Store
name|s
range|:
name|getStores
argument_list|()
operator|.
name|values
argument_list|()
control|)
block|{
name|CompactionRequest
name|cr
init|=
name|s
operator|.
name|requestCompaction
argument_list|()
decl_stmt|;
if|if
condition|(
name|cr
operator|!=
literal|null
condition|)
block|{
try|try
block|{
name|compact
argument_list|(
name|cr
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|s
operator|.
name|finishRequest
argument_list|(
name|cr
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
comment|/*    * Called by compaction thread and after region is opened to compact the    * HStores if necessary.    *    *<p>This operation could block for a long time, so don't call it from a    * time-sensitive thread.    *    * Note that no locking is necessary at this level because compaction only    * conflicts with a region split, and that cannot happen because the region    * server does them sequentially and not in parallel.    *    * @param cr Compaction details, obtained by requestCompaction()    * @return whether the compaction completed    * @throws IOException e    */
specifier|public
name|boolean
name|compact
parameter_list|(
name|CompactionRequest
name|cr
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|cr
operator|==
literal|null
condition|)
block|{
return|return
literal|false
return|;
block|}
if|if
condition|(
name|this
operator|.
name|closing
operator|.
name|get
argument_list|()
operator|||
name|this
operator|.
name|closed
operator|.
name|get
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Skipping compaction on "
operator|+
name|this
operator|+
literal|" because closing/closed"
argument_list|)
expr_stmt|;
return|return
literal|false
return|;
block|}
name|Preconditions
operator|.
name|checkArgument
argument_list|(
name|cr
operator|.
name|getHRegion
argument_list|()
operator|.
name|equals
argument_list|(
name|this
argument_list|)
argument_list|)
expr_stmt|;
name|MonitoredTask
name|status
init|=
literal|null
decl_stmt|;
comment|// block waiting for the lock for compaction
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
name|status
operator|=
name|TaskMonitor
operator|.
name|get
argument_list|()
operator|.
name|createStatus
argument_list|(
literal|"Compacting "
operator|+
name|cr
operator|.
name|getStore
argument_list|()
operator|+
literal|" in "
operator|+
name|this
argument_list|)
expr_stmt|;
if|if
condition|(
name|this
operator|.
name|closed
operator|.
name|get
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Skipping compaction on "
operator|+
name|this
operator|+
literal|" because closed"
argument_list|)
expr_stmt|;
return|return
literal|false
return|;
block|}
name|boolean
name|decr
init|=
literal|true
decl_stmt|;
try|try
block|{
synchronized|synchronized
init|(
name|writestate
init|)
block|{
if|if
condition|(
name|writestate
operator|.
name|writesEnabled
condition|)
block|{
operator|++
name|writestate
operator|.
name|compacting
expr_stmt|;
block|}
else|else
block|{
name|String
name|msg
init|=
literal|"NOT compacting region "
operator|+
name|this
operator|+
literal|". Writes disabled."
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
name|msg
argument_list|)
expr_stmt|;
name|status
operator|.
name|abort
argument_list|(
name|msg
argument_list|)
expr_stmt|;
name|decr
operator|=
literal|false
expr_stmt|;
return|return
literal|false
return|;
block|}
block|}
name|LOG
operator|.
name|info
argument_list|(
literal|"Starting compaction on "
operator|+
name|cr
operator|.
name|getStore
argument_list|()
operator|+
literal|" in region "
operator|+
name|this
operator|+
operator|(
name|cr
operator|.
name|getCompactSelection
argument_list|()
operator|.
name|isOffPeakCompaction
argument_list|()
condition|?
literal|" as an off-peak compaction"
else|:
literal|""
operator|)
argument_list|)
expr_stmt|;
name|doRegionCompactionPrep
argument_list|()
expr_stmt|;
try|try
block|{
name|status
operator|.
name|setStatus
argument_list|(
literal|"Compacting store "
operator|+
name|cr
operator|.
name|getStore
argument_list|()
argument_list|)
expr_stmt|;
name|cr
operator|.
name|getStore
argument_list|()
operator|.
name|compact
argument_list|(
name|cr
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedIOException
name|iioe
parameter_list|)
block|{
name|String
name|msg
init|=
literal|"compaction interrupted"
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
name|msg
argument_list|,
name|iioe
argument_list|)
expr_stmt|;
name|status
operator|.
name|abort
argument_list|(
name|msg
argument_list|)
expr_stmt|;
return|return
literal|false
return|;
block|}
block|}
finally|finally
block|{
if|if
condition|(
name|decr
condition|)
block|{
synchronized|synchronized
init|(
name|writestate
init|)
block|{
operator|--
name|writestate
operator|.
name|compacting
expr_stmt|;
if|if
condition|(
name|writestate
operator|.
name|compacting
operator|<=
literal|0
condition|)
block|{
name|writestate
operator|.
name|notifyAll
argument_list|()
expr_stmt|;
block|}
block|}
block|}
block|}
name|status
operator|.
name|markComplete
argument_list|(
literal|"Compaction complete"
argument_list|)
expr_stmt|;
return|return
literal|true
return|;
block|}
finally|finally
block|{
try|try
block|{
if|if
condition|(
name|status
operator|!=
literal|null
condition|)
name|status
operator|.
name|cleanup
argument_list|()
expr_stmt|;
block|}
finally|finally
block|{
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
block|}
comment|/**    * Flush the cache.    *    * When this method is called the cache will be flushed unless:    *<ol>    *<li>the cache is empty</li>    *<li>the region is closed.</li>    *<li>a flush is already in progress</li>    *<li>writes are disabled</li>    *</ol>    *    *<p>This method may block for some time, so it should not be called from a    * time-sensitive thread.    *    * @return true if cache was flushed    *    * @throws IOException general io exceptions    * @throws DroppedSnapshotException Thrown when replay of hlog is required    * because a Snapshot was not properly persisted.    */
specifier|public
name|boolean
name|flushcache
parameter_list|()
throws|throws
name|IOException
block|{
comment|// fail-fast instead of waiting on the lock
if|if
condition|(
name|this
operator|.
name|closing
operator|.
name|get
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Skipping flush on "
operator|+
name|this
operator|+
literal|" because closing"
argument_list|)
expr_stmt|;
return|return
literal|false
return|;
block|}
name|MonitoredTask
name|status
init|=
name|TaskMonitor
operator|.
name|get
argument_list|()
operator|.
name|createStatus
argument_list|(
literal|"Flushing "
operator|+
name|this
argument_list|)
decl_stmt|;
name|status
operator|.
name|setStatus
argument_list|(
literal|"Acquiring readlock on region"
argument_list|)
expr_stmt|;
comment|// block waiting for the lock for flushing cache
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
if|if
condition|(
name|this
operator|.
name|closed
operator|.
name|get
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Skipping flush on "
operator|+
name|this
operator|+
literal|" because closed"
argument_list|)
expr_stmt|;
name|status
operator|.
name|abort
argument_list|(
literal|"Skipped: closed"
argument_list|)
expr_stmt|;
return|return
literal|false
return|;
block|}
if|if
condition|(
name|coprocessorHost
operator|!=
literal|null
condition|)
block|{
name|status
operator|.
name|setStatus
argument_list|(
literal|"Running coprocessor pre-flush hooks"
argument_list|)
expr_stmt|;
name|coprocessorHost
operator|.
name|preFlush
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|numPutsWithoutWAL
operator|.
name|get
argument_list|()
operator|>
literal|0
condition|)
block|{
name|numPutsWithoutWAL
operator|.
name|set
argument_list|(
literal|0
argument_list|)
expr_stmt|;
name|dataInMemoryWithoutWAL
operator|.
name|set
argument_list|(
literal|0
argument_list|)
expr_stmt|;
block|}
synchronized|synchronized
init|(
name|writestate
init|)
block|{
if|if
condition|(
operator|!
name|writestate
operator|.
name|flushing
operator|&&
name|writestate
operator|.
name|writesEnabled
condition|)
block|{
name|this
operator|.
name|writestate
operator|.
name|flushing
operator|=
literal|true
expr_stmt|;
block|}
else|else
block|{
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"NOT flushing memstore for region "
operator|+
name|this
operator|+
literal|", flushing="
operator|+
name|writestate
operator|.
name|flushing
operator|+
literal|", writesEnabled="
operator|+
name|writestate
operator|.
name|writesEnabled
argument_list|)
expr_stmt|;
block|}
name|status
operator|.
name|abort
argument_list|(
literal|"Not flushing since "
operator|+
operator|(
name|writestate
operator|.
name|flushing
condition|?
literal|"already flushing"
else|:
literal|"writes not enabled"
operator|)
argument_list|)
expr_stmt|;
return|return
literal|false
return|;
block|}
block|}
try|try
block|{
name|boolean
name|result
init|=
name|internalFlushcache
argument_list|(
name|status
argument_list|)
decl_stmt|;
if|if
condition|(
name|coprocessorHost
operator|!=
literal|null
condition|)
block|{
name|status
operator|.
name|setStatus
argument_list|(
literal|"Running post-flush coprocessor hooks"
argument_list|)
expr_stmt|;
name|coprocessorHost
operator|.
name|postFlush
argument_list|()
expr_stmt|;
block|}
name|status
operator|.
name|markComplete
argument_list|(
literal|"Flush successful"
argument_list|)
expr_stmt|;
return|return
name|result
return|;
block|}
finally|finally
block|{
synchronized|synchronized
init|(
name|writestate
init|)
block|{
name|writestate
operator|.
name|flushing
operator|=
literal|false
expr_stmt|;
name|this
operator|.
name|writestate
operator|.
name|flushRequested
operator|=
literal|false
expr_stmt|;
name|writestate
operator|.
name|notifyAll
argument_list|()
expr_stmt|;
block|}
block|}
block|}
finally|finally
block|{
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
name|status
operator|.
name|cleanup
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**    * Flush the memstore.    *    * Flushing the memstore is a little tricky. We have a lot of updates in the    * memstore, all of which have also been written to the log. We need to    * write those updates in the memstore out to disk, while being able to    * process reads/writes as much as possible during the flush operation. Also,    * the log has to state clearly the point in time at which the memstore was    * flushed. (That way, during recovery, we know when we can rely on the    * on-disk flushed structures and when we have to recover the memstore from    * the log.)    *    *<p>So, we have a three-step process:    *    *<ul><li>A. Flush the memstore to the on-disk stores, noting the current    * sequence ID for the log.<li>    *    *<li>B. Write a FLUSHCACHE-COMPLETE message to the log, using the sequence    * ID that was current at the time of memstore-flush.</li>    *    *<li>C. Get rid of the memstore structures that are now redundant, as    * they've been flushed to the on-disk HStores.</li>    *</ul>    *<p>This method is protected, but can be accessed via several public    * routes.    *    *<p> This method may block for some time.    * @param status    *    * @return true if the region needs compacting    *    * @throws IOException general io exceptions    * @throws DroppedSnapshotException Thrown when replay of hlog is required    * because a Snapshot was not properly persisted.    */
specifier|protected
name|boolean
name|internalFlushcache
parameter_list|(
name|MonitoredTask
name|status
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|internalFlushcache
argument_list|(
name|this
operator|.
name|log
argument_list|,
operator|-
literal|1
argument_list|,
name|status
argument_list|)
return|;
block|}
comment|/**    * @param wal Null if we're NOT to go via hlog/wal.    * @param myseqid The seqid to use if<code>wal</code> is null writing out    * flush file.    * @param status    * @return true if the region needs compacting    * @throws IOException    * @see #internalFlushcache(MonitoredTask)    */
specifier|protected
name|boolean
name|internalFlushcache
parameter_list|(
specifier|final
name|HLog
name|wal
parameter_list|,
specifier|final
name|long
name|myseqid
parameter_list|,
name|MonitoredTask
name|status
parameter_list|)
throws|throws
name|IOException
block|{
specifier|final
name|long
name|startTime
init|=
name|EnvironmentEdgeManager
operator|.
name|currentTimeMillis
argument_list|()
decl_stmt|;
comment|// Clear flush flag.
comment|// Record latest flush time
name|this
operator|.
name|lastFlushTime
operator|=
name|startTime
expr_stmt|;
comment|// If nothing to flush, return and avoid logging start/stop flush.
if|if
condition|(
name|this
operator|.
name|memstoreSize
operator|.
name|get
argument_list|()
operator|<=
literal|0
condition|)
block|{
return|return
literal|false
return|;
block|}
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Started memstore flush for "
operator|+
name|this
operator|+
literal|", current region memstore size "
operator|+
name|StringUtils
operator|.
name|humanReadableInt
argument_list|(
name|this
operator|.
name|memstoreSize
operator|.
name|get
argument_list|()
argument_list|)
operator|+
operator|(
operator|(
name|wal
operator|!=
literal|null
operator|)
condition|?
literal|""
else|:
literal|"; wal is null, using passed sequenceid="
operator|+
name|myseqid
operator|)
argument_list|)
expr_stmt|;
block|}
comment|// Stop updates while we snapshot the memstore of all stores. We only have
comment|// to do this for a moment.  Its quick.  The subsequent sequence id that
comment|// goes into the HLog after we've flushed all these snapshots also goes
comment|// into the info file that sits beside the flushed files.
comment|// We also set the memstore size to zero here before we allow updates
comment|// again so its value will represent the size of the updates received
comment|// during the flush
name|long
name|sequenceId
init|=
operator|-
literal|1L
decl_stmt|;
name|MultiVersionConsistencyControl
operator|.
name|WriteEntry
name|w
init|=
literal|null
decl_stmt|;
comment|// We have to take a write lock during snapshot, or else a write could
comment|// end up in both snapshot and memstore (makes it difficult to do atomic
comment|// rows then)
name|status
operator|.
name|setStatus
argument_list|(
literal|"Obtaining lock to block concurrent updates"
argument_list|)
expr_stmt|;
comment|// block waiting for the lock for internal flush
name|this
operator|.
name|updatesLock
operator|.
name|writeLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
name|long
name|flushsize
init|=
name|this
operator|.
name|memstoreSize
operator|.
name|get
argument_list|()
decl_stmt|;
name|status
operator|.
name|setStatus
argument_list|(
literal|"Preparing to flush by snapshotting stores"
argument_list|)
expr_stmt|;
name|List
argument_list|<
name|StoreFlusher
argument_list|>
name|storeFlushers
init|=
operator|new
name|ArrayList
argument_list|<
name|StoreFlusher
argument_list|>
argument_list|(
name|stores
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
name|long
name|flushSeqId
init|=
operator|-
literal|1L
decl_stmt|;
try|try
block|{
comment|// Record the mvcc for all transactions in progress.
name|w
operator|=
name|mvcc
operator|.
name|beginMemstoreInsert
argument_list|()
expr_stmt|;
name|mvcc
operator|.
name|advanceMemstore
argument_list|(
name|w
argument_list|)
expr_stmt|;
if|if
condition|(
name|wal
operator|!=
literal|null
condition|)
block|{
name|Long
name|startSeqId
init|=
name|wal
operator|.
name|startCacheFlush
argument_list|(
name|this
operator|.
name|regionInfo
operator|.
name|getEncodedNameAsBytes
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|startSeqId
operator|==
literal|null
condition|)
block|{
name|status
operator|.
name|setStatus
argument_list|(
literal|"Flush will not be started for ["
operator|+
name|this
operator|.
name|regionInfo
operator|.
name|getEncodedName
argument_list|()
operator|+
literal|"] - WAL is going away"
argument_list|)
expr_stmt|;
return|return
literal|false
return|;
block|}
name|flushSeqId
operator|=
name|startSeqId
operator|.
name|longValue
argument_list|()
expr_stmt|;
block|}
else|else
block|{
name|flushSeqId
operator|=
name|myseqid
expr_stmt|;
block|}
for|for
control|(
name|Store
name|s
range|:
name|stores
operator|.
name|values
argument_list|()
control|)
block|{
name|storeFlushers
operator|.
name|add
argument_list|(
name|s
operator|.
name|getStoreFlusher
argument_list|(
name|flushSeqId
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|// prepare flush (take a snapshot)
for|for
control|(
name|StoreFlusher
name|flusher
range|:
name|storeFlushers
control|)
block|{
name|flusher
operator|.
name|prepare
argument_list|()
expr_stmt|;
block|}
block|}
finally|finally
block|{
name|this
operator|.
name|updatesLock
operator|.
name|writeLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
name|String
name|s
init|=
literal|"Finished snapshotting "
operator|+
name|this
operator|+
literal|", commencing wait for mvcc, flushsize="
operator|+
name|flushsize
decl_stmt|;
name|status
operator|.
name|setStatus
argument_list|(
name|s
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
name|s
argument_list|)
expr_stmt|;
comment|// wait for all in-progress transactions to commit to HLog before
comment|// we can start the flush. This prevents
comment|// uncommitted transactions from being written into HFiles.
comment|// We have to block before we start the flush, otherwise keys that
comment|// were removed via a rollbackMemstore could be written to Hfiles.
name|mvcc
operator|.
name|waitForRead
argument_list|(
name|w
argument_list|)
expr_stmt|;
name|status
operator|.
name|setStatus
argument_list|(
literal|"Flushing stores"
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Finished snapshotting, commencing flushing stores"
argument_list|)
expr_stmt|;
comment|// Any failure from here on out will be catastrophic requiring server
comment|// restart so hlog content can be replayed and put back into the memstore.
comment|// Otherwise, the snapshot content while backed up in the hlog, it will not
comment|// be part of the current running servers state.
name|boolean
name|compactionRequested
init|=
literal|false
decl_stmt|;
try|try
block|{
comment|// A.  Flush memstore to all the HStores.
comment|// Keep running vector of all store files that includes both old and the
comment|// just-made new flush store file. The new flushed file is still in the
comment|// tmp directory.
for|for
control|(
name|StoreFlusher
name|flusher
range|:
name|storeFlushers
control|)
block|{
name|flusher
operator|.
name|flushCache
argument_list|(
name|status
argument_list|)
expr_stmt|;
block|}
comment|// Switch snapshot (in memstore) -> new hfile (thus causing
comment|// all the store scanners to reset/reseek).
for|for
control|(
name|StoreFlusher
name|flusher
range|:
name|storeFlushers
control|)
block|{
name|boolean
name|needsCompaction
init|=
name|flusher
operator|.
name|commit
argument_list|(
name|status
argument_list|)
decl_stmt|;
if|if
condition|(
name|needsCompaction
condition|)
block|{
name|compactionRequested
operator|=
literal|true
expr_stmt|;
block|}
block|}
name|storeFlushers
operator|.
name|clear
argument_list|()
expr_stmt|;
comment|// Set down the memstore size by amount of flush.
name|this
operator|.
name|addAndGetGlobalMemstoreSize
argument_list|(
operator|-
name|flushsize
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Throwable
name|t
parameter_list|)
block|{
comment|// An exception here means that the snapshot was not persisted.
comment|// The hlog needs to be replayed so its content is restored to memstore.
comment|// Currently, only a server restart will do this.
comment|// We used to only catch IOEs but its possible that we'd get other
comment|// exceptions -- e.g. HBASE-659 was about an NPE -- so now we catch
comment|// all and sundry.
if|if
condition|(
name|wal
operator|!=
literal|null
condition|)
block|{
name|wal
operator|.
name|abortCacheFlush
argument_list|(
name|this
operator|.
name|regionInfo
operator|.
name|getEncodedNameAsBytes
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|DroppedSnapshotException
name|dse
init|=
operator|new
name|DroppedSnapshotException
argument_list|(
literal|"region: "
operator|+
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|getRegionName
argument_list|()
argument_list|)
argument_list|)
decl_stmt|;
name|dse
operator|.
name|initCause
argument_list|(
name|t
argument_list|)
expr_stmt|;
name|status
operator|.
name|abort
argument_list|(
literal|"Flush failed: "
operator|+
name|StringUtils
operator|.
name|stringifyException
argument_list|(
name|t
argument_list|)
argument_list|)
expr_stmt|;
throw|throw
name|dse
throw|;
block|}
comment|// If we get to here, the HStores have been written.
if|if
condition|(
name|wal
operator|!=
literal|null
condition|)
block|{
name|wal
operator|.
name|completeCacheFlush
argument_list|(
name|this
operator|.
name|regionInfo
operator|.
name|getEncodedNameAsBytes
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|// Update the last flushed sequence id for region
if|if
condition|(
name|this
operator|.
name|rsServices
operator|!=
literal|null
condition|)
block|{
name|completeSequenceId
operator|=
name|flushSeqId
expr_stmt|;
block|}
comment|// C. Finally notify anyone waiting on memstore to clear:
comment|// e.g. checkResources().
synchronized|synchronized
init|(
name|this
init|)
block|{
name|notifyAll
argument_list|()
expr_stmt|;
comment|// FindBugs NN_NAKED_NOTIFY
block|}
name|long
name|time
init|=
name|EnvironmentEdgeManager
operator|.
name|currentTimeMillis
argument_list|()
operator|-
name|startTime
decl_stmt|;
name|long
name|memstoresize
init|=
name|this
operator|.
name|memstoreSize
operator|.
name|get
argument_list|()
decl_stmt|;
name|String
name|msg
init|=
literal|"Finished memstore flush of ~"
operator|+
name|StringUtils
operator|.
name|humanReadableInt
argument_list|(
name|flushsize
argument_list|)
operator|+
literal|"/"
operator|+
name|flushsize
operator|+
literal|", currentsize="
operator|+
name|StringUtils
operator|.
name|humanReadableInt
argument_list|(
name|memstoresize
argument_list|)
operator|+
literal|"/"
operator|+
name|memstoresize
operator|+
literal|" for region "
operator|+
name|this
operator|+
literal|" in "
operator|+
name|time
operator|+
literal|"ms, sequenceid="
operator|+
name|sequenceId
operator|+
literal|", compaction requested="
operator|+
name|compactionRequested
operator|+
operator|(
operator|(
name|wal
operator|==
literal|null
operator|)
condition|?
literal|"; wal=null"
else|:
literal|""
operator|)
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
name|msg
argument_list|)
expr_stmt|;
name|status
operator|.
name|setStatus
argument_list|(
name|msg
argument_list|)
expr_stmt|;
name|this
operator|.
name|recentFlushes
operator|.
name|add
argument_list|(
operator|new
name|Pair
argument_list|<
name|Long
argument_list|,
name|Long
argument_list|>
argument_list|(
name|time
operator|/
literal|1000
argument_list|,
name|flushsize
argument_list|)
argument_list|)
expr_stmt|;
return|return
name|compactionRequested
return|;
block|}
comment|//////////////////////////////////////////////////////////////////////////////
comment|// get() methods for client use.
comment|//////////////////////////////////////////////////////////////////////////////
comment|/**    * Return all the data for the row that matches<i>row</i> exactly,    * or the one that immediately preceeds it, at or immediately before    *<i>ts</i>.    *    * @param row row key    * @return map of values    * @throws IOException    */
name|Result
name|getClosestRowBefore
parameter_list|(
specifier|final
name|byte
index|[]
name|row
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|getClosestRowBefore
argument_list|(
name|row
argument_list|,
name|HConstants
operator|.
name|CATALOG_FAMILY
argument_list|)
return|;
block|}
comment|/**    * Return all the data for the row that matches<i>row</i> exactly,    * or the one that immediately preceeds it, at or immediately before    *<i>ts</i>.    *    * @param row row key    * @param family column family to find on    * @return map of values    * @throws IOException read exceptions    */
specifier|public
name|Result
name|getClosestRowBefore
parameter_list|(
specifier|final
name|byte
index|[]
name|row
parameter_list|,
specifier|final
name|byte
index|[]
name|family
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|coprocessorHost
operator|!=
literal|null
condition|)
block|{
name|Result
name|result
init|=
operator|new
name|Result
argument_list|()
decl_stmt|;
if|if
condition|(
name|coprocessorHost
operator|.
name|preGetClosestRowBefore
argument_list|(
name|row
argument_list|,
name|family
argument_list|,
name|result
argument_list|)
condition|)
block|{
return|return
name|result
return|;
block|}
block|}
comment|// look across all the HStores for this region and determine what the
comment|// closest key is across all column families, since the data may be sparse
name|checkRow
argument_list|(
name|row
argument_list|,
literal|"getClosestRowBefore"
argument_list|)
expr_stmt|;
name|startRegionOperation
argument_list|()
expr_stmt|;
name|this
operator|.
name|readRequestsCount
operator|.
name|increment
argument_list|()
expr_stmt|;
try|try
block|{
name|Store
name|store
init|=
name|getStore
argument_list|(
name|family
argument_list|)
decl_stmt|;
comment|// get the closest key. (HStore.getRowKeyAtOrBefore can return null)
name|KeyValue
name|key
init|=
name|store
operator|.
name|getRowKeyAtOrBefore
argument_list|(
name|row
argument_list|)
decl_stmt|;
name|Result
name|result
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|key
operator|!=
literal|null
condition|)
block|{
name|Get
name|get
init|=
operator|new
name|Get
argument_list|(
name|key
operator|.
name|getRow
argument_list|()
argument_list|)
decl_stmt|;
name|get
operator|.
name|addFamily
argument_list|(
name|family
argument_list|)
expr_stmt|;
name|result
operator|=
name|get
argument_list|(
name|get
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|coprocessorHost
operator|!=
literal|null
condition|)
block|{
name|coprocessorHost
operator|.
name|postGetClosestRowBefore
argument_list|(
name|row
argument_list|,
name|family
argument_list|,
name|result
argument_list|)
expr_stmt|;
block|}
return|return
name|result
return|;
block|}
finally|finally
block|{
name|closeRegionOperation
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**    * Return an iterator that scans over the HRegion, returning the indicated    * columns and rows specified by the {@link Scan}.    *<p>    * This Iterator must be closed by the caller.    *    * @param scan configured {@link Scan}    * @return RegionScanner    * @throws IOException read exceptions    */
specifier|public
name|RegionScanner
name|getScanner
parameter_list|(
name|Scan
name|scan
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|getScanner
argument_list|(
name|scan
argument_list|,
literal|null
argument_list|)
return|;
block|}
name|void
name|prepareScanner
parameter_list|(
name|Scan
name|scan
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
operator|!
name|scan
operator|.
name|hasFamilies
argument_list|()
condition|)
block|{
comment|// Adding all families to scanner
for|for
control|(
name|byte
index|[]
name|family
range|:
name|this
operator|.
name|htableDescriptor
operator|.
name|getFamiliesKeys
argument_list|()
control|)
block|{
name|scan
operator|.
name|addFamily
argument_list|(
name|family
argument_list|)
expr_stmt|;
block|}
block|}
block|}
specifier|protected
name|RegionScanner
name|getScanner
parameter_list|(
name|Scan
name|scan
parameter_list|,
name|List
argument_list|<
name|KeyValueScanner
argument_list|>
name|additionalScanners
parameter_list|)
throws|throws
name|IOException
block|{
name|startRegionOperation
argument_list|()
expr_stmt|;
try|try
block|{
comment|// Verify families are all valid
name|prepareScanner
argument_list|(
name|scan
argument_list|)
expr_stmt|;
if|if
condition|(
name|scan
operator|.
name|hasFamilies
argument_list|()
condition|)
block|{
for|for
control|(
name|byte
index|[]
name|family
range|:
name|scan
operator|.
name|getFamilyMap
argument_list|()
operator|.
name|keySet
argument_list|()
control|)
block|{
name|checkFamily
argument_list|(
name|family
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|instantiateRegionScanner
argument_list|(
name|scan
argument_list|,
name|additionalScanners
argument_list|)
return|;
block|}
finally|finally
block|{
name|closeRegionOperation
argument_list|()
expr_stmt|;
block|}
block|}
specifier|protected
name|RegionScanner
name|instantiateRegionScanner
parameter_list|(
name|Scan
name|scan
parameter_list|,
name|List
argument_list|<
name|KeyValueScanner
argument_list|>
name|additionalScanners
parameter_list|)
throws|throws
name|IOException
block|{
return|return
operator|new
name|RegionScannerImpl
argument_list|(
name|scan
argument_list|,
name|additionalScanners
argument_list|,
name|this
argument_list|)
return|;
block|}
comment|/*    * @param delete The passed delete is modified by this method. WARNING!    */
name|void
name|prepareDelete
parameter_list|(
name|Delete
name|delete
parameter_list|)
throws|throws
name|IOException
block|{
comment|// Check to see if this is a deleteRow insert
if|if
condition|(
name|delete
operator|.
name|getFamilyMap
argument_list|()
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
for|for
control|(
name|byte
index|[]
name|family
range|:
name|this
operator|.
name|htableDescriptor
operator|.
name|getFamiliesKeys
argument_list|()
control|)
block|{
comment|// Don't eat the timestamp
name|delete
operator|.
name|deleteFamily
argument_list|(
name|family
argument_list|,
name|delete
operator|.
name|getTimeStamp
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
for|for
control|(
name|byte
index|[]
name|family
range|:
name|delete
operator|.
name|getFamilyMap
argument_list|()
operator|.
name|keySet
argument_list|()
control|)
block|{
if|if
condition|(
name|family
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|NoSuchColumnFamilyException
argument_list|(
literal|"Empty family is invalid"
argument_list|)
throw|;
block|}
name|checkFamily
argument_list|(
name|family
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|//////////////////////////////////////////////////////////////////////////////
comment|// set() methods for client use.
comment|//////////////////////////////////////////////////////////////////////////////
comment|/**    * @param delete delete object    * @param writeToWAL append to the write ahead lock or not    * @throws IOException read exceptions    */
specifier|public
name|void
name|delete
parameter_list|(
name|Delete
name|delete
parameter_list|,
name|boolean
name|writeToWAL
parameter_list|)
throws|throws
name|IOException
block|{
name|checkReadOnly
argument_list|()
expr_stmt|;
name|checkResources
argument_list|()
expr_stmt|;
name|startRegionOperation
argument_list|()
expr_stmt|;
name|this
operator|.
name|writeRequestsCount
operator|.
name|increment
argument_list|()
expr_stmt|;
try|try
block|{
name|byte
index|[]
name|row
init|=
name|delete
operator|.
name|getRow
argument_list|()
decl_stmt|;
comment|// All edits for the given row (across all column families) must happen atomically.
name|doBatchMutate
argument_list|(
name|delete
argument_list|,
literal|null
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|closeRegionOperation
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**    * This is used only by unit tests. Not required to be a public API.    * @param familyMap map of family to edits for the given family.    * @param writeToWAL    * @throws IOException    */
name|void
name|delete
parameter_list|(
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|List
argument_list|<
name|KeyValue
argument_list|>
argument_list|>
name|familyMap
parameter_list|,
name|UUID
name|clusterId
parameter_list|,
name|boolean
name|writeToWAL
parameter_list|)
throws|throws
name|IOException
block|{
name|Delete
name|delete
init|=
operator|new
name|Delete
argument_list|(
name|HConstants
operator|.
name|EMPTY_BYTE_ARRAY
argument_list|)
decl_stmt|;
name|delete
operator|.
name|setFamilyMap
argument_list|(
name|familyMap
argument_list|)
expr_stmt|;
name|delete
operator|.
name|setClusterId
argument_list|(
name|clusterId
argument_list|)
expr_stmt|;
name|delete
operator|.
name|setWriteToWAL
argument_list|(
name|writeToWAL
argument_list|)
expr_stmt|;
name|doBatchMutate
argument_list|(
name|delete
argument_list|,
literal|null
argument_list|)
expr_stmt|;
block|}
comment|/**    * Setup correct timestamps in the KVs in Delete object.    * Caller should have the row and region locks.    * @param familyMap    * @param byteNow    * @throws IOException    */
name|void
name|prepareDeleteTimestamps
parameter_list|(
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|List
argument_list|<
name|KeyValue
argument_list|>
argument_list|>
name|familyMap
parameter_list|,
name|byte
index|[]
name|byteNow
parameter_list|)
throws|throws
name|IOException
block|{
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|byte
index|[]
argument_list|,
name|List
argument_list|<
name|KeyValue
argument_list|>
argument_list|>
name|e
range|:
name|familyMap
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|byte
index|[]
name|family
init|=
name|e
operator|.
name|getKey
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|KeyValue
argument_list|>
name|kvs
init|=
name|e
operator|.
name|getValue
argument_list|()
decl_stmt|;
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|Integer
argument_list|>
name|kvCount
init|=
operator|new
name|TreeMap
argument_list|<
name|byte
index|[]
argument_list|,
name|Integer
argument_list|>
argument_list|(
name|Bytes
operator|.
name|BYTES_COMPARATOR
argument_list|)
decl_stmt|;
for|for
control|(
name|KeyValue
name|kv
range|:
name|kvs
control|)
block|{
comment|//  Check if time is LATEST, change to time of most recent addition if so
comment|//  This is expensive.
if|if
condition|(
name|kv
operator|.
name|isLatestTimestamp
argument_list|()
operator|&&
name|kv
operator|.
name|isDeleteType
argument_list|()
condition|)
block|{
name|byte
index|[]
name|qual
init|=
name|kv
operator|.
name|getQualifier
argument_list|()
decl_stmt|;
if|if
condition|(
name|qual
operator|==
literal|null
condition|)
name|qual
operator|=
name|HConstants
operator|.
name|EMPTY_BYTE_ARRAY
expr_stmt|;
name|Integer
name|count
init|=
name|kvCount
operator|.
name|get
argument_list|(
name|qual
argument_list|)
decl_stmt|;
if|if
condition|(
name|count
operator|==
literal|null
condition|)
block|{
name|kvCount
operator|.
name|put
argument_list|(
name|qual
argument_list|,
literal|1
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|kvCount
operator|.
name|put
argument_list|(
name|qual
argument_list|,
name|count
operator|+
literal|1
argument_list|)
expr_stmt|;
block|}
name|count
operator|=
name|kvCount
operator|.
name|get
argument_list|(
name|qual
argument_list|)
expr_stmt|;
name|Get
name|get
init|=
operator|new
name|Get
argument_list|(
name|kv
operator|.
name|getRow
argument_list|()
argument_list|)
decl_stmt|;
name|get
operator|.
name|setMaxVersions
argument_list|(
name|count
argument_list|)
expr_stmt|;
name|get
operator|.
name|addColumn
argument_list|(
name|family
argument_list|,
name|qual
argument_list|)
expr_stmt|;
name|List
argument_list|<
name|KeyValue
argument_list|>
name|result
init|=
name|get
argument_list|(
name|get
argument_list|,
literal|false
argument_list|)
decl_stmt|;
if|if
condition|(
name|result
operator|.
name|size
argument_list|()
operator|<
name|count
condition|)
block|{
comment|// Nothing to delete
name|kv
operator|.
name|updateLatestStamp
argument_list|(
name|byteNow
argument_list|)
expr_stmt|;
continue|continue;
block|}
if|if
condition|(
name|result
operator|.
name|size
argument_list|()
operator|>
name|count
condition|)
block|{
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"Unexpected size: "
operator|+
name|result
operator|.
name|size
argument_list|()
argument_list|)
throw|;
block|}
name|KeyValue
name|getkv
init|=
name|result
operator|.
name|get
argument_list|(
name|count
operator|-
literal|1
argument_list|)
decl_stmt|;
name|Bytes
operator|.
name|putBytes
argument_list|(
name|kv
operator|.
name|getBuffer
argument_list|()
argument_list|,
name|kv
operator|.
name|getTimestampOffset
argument_list|()
argument_list|,
name|getkv
operator|.
name|getBuffer
argument_list|()
argument_list|,
name|getkv
operator|.
name|getTimestampOffset
argument_list|()
argument_list|,
name|Bytes
operator|.
name|SIZEOF_LONG
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|kv
operator|.
name|updateLatestStamp
argument_list|(
name|byteNow
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
comment|/**    * @param put    * @throws IOException    */
specifier|public
name|void
name|put
parameter_list|(
name|Put
name|put
parameter_list|)
throws|throws
name|IOException
block|{
name|this
operator|.
name|put
argument_list|(
name|put
argument_list|,
name|put
operator|.
name|getWriteToWAL
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|/**    * @param put    * @param writeToWAL    * @throws IOException    */
specifier|public
name|void
name|put
parameter_list|(
name|Put
name|put
parameter_list|,
name|boolean
name|writeToWAL
parameter_list|)
throws|throws
name|IOException
block|{
name|checkReadOnly
argument_list|()
expr_stmt|;
comment|// Do a rough check that we have resources to accept a write.  The check is
comment|// 'rough' in that between the resource check and the call to obtain a
comment|// read lock, resources may run out.  For now, the thought is that this
comment|// will be extremely rare; we'll deal with it when it happens.
name|checkResources
argument_list|()
expr_stmt|;
name|startRegionOperation
argument_list|()
expr_stmt|;
name|this
operator|.
name|writeRequestsCount
operator|.
name|increment
argument_list|()
expr_stmt|;
try|try
block|{
comment|// We obtain a per-row lock, so other clients will block while one client
comment|// performs an update. The read lock is released by the client calling
comment|// #commit or #abort or if the HRegionServer lease on the lock expires.
comment|// See HRegionServer#RegionListener for how the expire on HRegionServer
comment|// invokes a HRegion#abort.
name|byte
index|[]
name|row
init|=
name|put
operator|.
name|getRow
argument_list|()
decl_stmt|;
comment|// All edits for the given row (across all column families) must happen atomically.
name|doBatchMutate
argument_list|(
name|put
argument_list|,
literal|null
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|closeRegionOperation
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**    * Struct-like class that tracks the progress of a batch operation,    * accumulating status codes and tracking the index at which processing    * is proceeding.    */
specifier|private
specifier|static
class|class
name|BatchOperationInProgress
parameter_list|<
name|T
parameter_list|>
block|{
name|T
index|[]
name|operations
decl_stmt|;
name|int
name|nextIndexToProcess
init|=
literal|0
decl_stmt|;
name|OperationStatus
index|[]
name|retCodeDetails
decl_stmt|;
name|WALEdit
index|[]
name|walEditsFromCoprocessors
decl_stmt|;
specifier|public
name|BatchOperationInProgress
parameter_list|(
name|T
index|[]
name|operations
parameter_list|)
block|{
name|this
operator|.
name|operations
operator|=
name|operations
expr_stmt|;
name|this
operator|.
name|retCodeDetails
operator|=
operator|new
name|OperationStatus
index|[
name|operations
operator|.
name|length
index|]
expr_stmt|;
name|this
operator|.
name|walEditsFromCoprocessors
operator|=
operator|new
name|WALEdit
index|[
name|operations
operator|.
name|length
index|]
expr_stmt|;
name|Arrays
operator|.
name|fill
argument_list|(
name|this
operator|.
name|retCodeDetails
argument_list|,
name|OperationStatus
operator|.
name|NOT_RUN
argument_list|)
expr_stmt|;
block|}
specifier|public
name|boolean
name|isDone
parameter_list|()
block|{
return|return
name|nextIndexToProcess
operator|==
name|operations
operator|.
name|length
return|;
block|}
block|}
comment|/**    * Perform a batch put with no pre-specified locks    * @see HRegion#batchMutate(Pair[])    */
specifier|public
name|OperationStatus
index|[]
name|put
parameter_list|(
name|Put
index|[]
name|puts
parameter_list|)
throws|throws
name|IOException
block|{
annotation|@
name|SuppressWarnings
argument_list|(
literal|"unchecked"
argument_list|)
name|Pair
argument_list|<
name|Mutation
argument_list|,
name|Integer
argument_list|>
name|putsAndLocks
index|[]
init|=
operator|new
name|Pair
index|[
name|puts
operator|.
name|length
index|]
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|puts
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|putsAndLocks
index|[
name|i
index|]
operator|=
operator|new
name|Pair
argument_list|<
name|Mutation
argument_list|,
name|Integer
argument_list|>
argument_list|(
name|puts
index|[
name|i
index|]
argument_list|,
literal|null
argument_list|)
expr_stmt|;
block|}
return|return
name|batchMutate
argument_list|(
name|putsAndLocks
argument_list|)
return|;
block|}
comment|/**    * Perform a batch of mutations.    * It supports only Put and Delete mutations and will ignore other types passed.    * @param mutationsAndLocks    *          the list of mutations paired with their requested lock IDs.    * @return an array of OperationStatus which internally contains the    *         OperationStatusCode and the exceptionMessage if any.    * @throws IOException    */
specifier|public
name|OperationStatus
index|[]
name|batchMutate
parameter_list|(
name|Pair
argument_list|<
name|Mutation
argument_list|,
name|Integer
argument_list|>
index|[]
name|mutationsAndLocks
parameter_list|)
throws|throws
name|IOException
block|{
name|BatchOperationInProgress
argument_list|<
name|Pair
argument_list|<
name|Mutation
argument_list|,
name|Integer
argument_list|>
argument_list|>
name|batchOp
init|=
operator|new
name|BatchOperationInProgress
argument_list|<
name|Pair
argument_list|<
name|Mutation
argument_list|,
name|Integer
argument_list|>
argument_list|>
argument_list|(
name|mutationsAndLocks
argument_list|)
decl_stmt|;
name|boolean
name|initialized
init|=
literal|false
decl_stmt|;
while|while
condition|(
operator|!
name|batchOp
operator|.
name|isDone
argument_list|()
condition|)
block|{
name|checkReadOnly
argument_list|()
expr_stmt|;
name|checkResources
argument_list|()
expr_stmt|;
name|long
name|newSize
decl_stmt|;
name|startRegionOperation
argument_list|()
expr_stmt|;
try|try
block|{
if|if
condition|(
operator|!
name|initialized
condition|)
block|{
name|this
operator|.
name|writeRequestsCount
operator|.
name|increment
argument_list|()
expr_stmt|;
name|doPreMutationHook
argument_list|(
name|batchOp
argument_list|)
expr_stmt|;
name|initialized
operator|=
literal|true
expr_stmt|;
block|}
name|long
name|addedSize
init|=
name|doMiniBatchMutation
argument_list|(
name|batchOp
argument_list|)
decl_stmt|;
name|newSize
operator|=
name|this
operator|.
name|addAndGetGlobalMemstoreSize
argument_list|(
name|addedSize
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|closeRegionOperation
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|isFlushSize
argument_list|(
name|newSize
argument_list|)
condition|)
block|{
name|requestFlush
argument_list|()
expr_stmt|;
block|}
block|}
return|return
name|batchOp
operator|.
name|retCodeDetails
return|;
block|}
specifier|private
name|void
name|doPreMutationHook
parameter_list|(
name|BatchOperationInProgress
argument_list|<
name|Pair
argument_list|<
name|Mutation
argument_list|,
name|Integer
argument_list|>
argument_list|>
name|batchOp
parameter_list|)
throws|throws
name|IOException
block|{
comment|/* Run coprocessor pre hook outside of locks to avoid deadlock */
name|WALEdit
name|walEdit
init|=
operator|new
name|WALEdit
argument_list|()
decl_stmt|;
if|if
condition|(
name|coprocessorHost
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|batchOp
operator|.
name|operations
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|Pair
argument_list|<
name|Mutation
argument_list|,
name|Integer
argument_list|>
name|nextPair
init|=
name|batchOp
operator|.
name|operations
index|[
name|i
index|]
decl_stmt|;
name|Mutation
name|m
init|=
name|nextPair
operator|.
name|getFirst
argument_list|()
decl_stmt|;
if|if
condition|(
name|m
operator|instanceof
name|Put
condition|)
block|{
if|if
condition|(
name|coprocessorHost
operator|.
name|prePut
argument_list|(
operator|(
name|Put
operator|)
name|m
argument_list|,
name|walEdit
argument_list|,
name|m
operator|.
name|getWriteToWAL
argument_list|()
argument_list|)
condition|)
block|{
comment|// pre hook says skip this Put
comment|// mark as success and skip in doMiniBatchMutation
name|batchOp
operator|.
name|retCodeDetails
index|[
name|i
index|]
operator|=
name|OperationStatus
operator|.
name|SUCCESS
expr_stmt|;
block|}
block|}
elseif|else
if|if
condition|(
name|m
operator|instanceof
name|Delete
condition|)
block|{
if|if
condition|(
name|coprocessorHost
operator|.
name|preDelete
argument_list|(
operator|(
name|Delete
operator|)
name|m
argument_list|,
name|walEdit
argument_list|,
name|m
operator|.
name|getWriteToWAL
argument_list|()
argument_list|)
condition|)
block|{
comment|// pre hook says skip this Delete
comment|// mark as success and skip in doMiniBatchMutation
name|batchOp
operator|.
name|retCodeDetails
index|[
name|i
index|]
operator|=
name|OperationStatus
operator|.
name|SUCCESS
expr_stmt|;
block|}
block|}
else|else
block|{
comment|// In case of passing Append mutations along with the Puts and Deletes in batchMutate
comment|// mark the operation return code as failure so that it will not be considered in
comment|// the doMiniBatchMutation
name|batchOp
operator|.
name|retCodeDetails
index|[
name|i
index|]
operator|=
operator|new
name|OperationStatus
argument_list|(
name|OperationStatusCode
operator|.
name|FAILURE
argument_list|,
literal|"Put/Delete mutations only supported in batchMutate() now"
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|!
name|walEdit
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|batchOp
operator|.
name|walEditsFromCoprocessors
index|[
name|i
index|]
operator|=
name|walEdit
expr_stmt|;
name|walEdit
operator|=
operator|new
name|WALEdit
argument_list|()
expr_stmt|;
block|}
block|}
block|}
block|}
annotation|@
name|SuppressWarnings
argument_list|(
literal|"unchecked"
argument_list|)
specifier|private
name|long
name|doMiniBatchMutation
parameter_list|(
name|BatchOperationInProgress
argument_list|<
name|Pair
argument_list|<
name|Mutation
argument_list|,
name|Integer
argument_list|>
argument_list|>
name|batchOp
parameter_list|)
throws|throws
name|IOException
block|{
comment|// variable to note if all Put items are for the same CF -- metrics related
name|boolean
name|putsCfSetConsistent
init|=
literal|true
decl_stmt|;
comment|//The set of columnFamilies first seen for Put.
name|Set
argument_list|<
name|byte
index|[]
argument_list|>
name|putsCfSet
init|=
literal|null
decl_stmt|;
comment|// variable to note if all Delete items are for the same CF -- metrics related
name|boolean
name|deletesCfSetConsistent
init|=
literal|true
decl_stmt|;
comment|//The set of columnFamilies first seen for Delete.
name|Set
argument_list|<
name|byte
index|[]
argument_list|>
name|deletesCfSet
init|=
literal|null
decl_stmt|;
name|WALEdit
name|walEdit
init|=
operator|new
name|WALEdit
argument_list|()
decl_stmt|;
name|MultiVersionConsistencyControl
operator|.
name|WriteEntry
name|w
init|=
literal|null
decl_stmt|;
name|long
name|txid
init|=
literal|0
decl_stmt|;
name|boolean
name|walSyncSuccessful
init|=
literal|false
decl_stmt|;
name|boolean
name|locked
init|=
literal|false
decl_stmt|;
comment|/** Keep track of the locks we hold so we can release them in finally clause */
name|List
argument_list|<
name|Integer
argument_list|>
name|acquiredLocks
init|=
name|Lists
operator|.
name|newArrayListWithCapacity
argument_list|(
name|batchOp
operator|.
name|operations
operator|.
name|length
argument_list|)
decl_stmt|;
comment|// reference family maps directly so coprocessors can mutate them if desired
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|List
argument_list|<
name|KeyValue
argument_list|>
argument_list|>
index|[]
name|familyMaps
init|=
operator|new
name|Map
index|[
name|batchOp
operator|.
name|operations
operator|.
name|length
index|]
decl_stmt|;
comment|// We try to set up a batch in the range [firstIndex,lastIndexExclusive)
name|int
name|firstIndex
init|=
name|batchOp
operator|.
name|nextIndexToProcess
decl_stmt|;
name|int
name|lastIndexExclusive
init|=
name|firstIndex
decl_stmt|;
name|boolean
name|success
init|=
literal|false
decl_stmt|;
name|int
name|noOfPuts
init|=
literal|0
decl_stmt|,
name|noOfDeletes
init|=
literal|0
decl_stmt|;
try|try
block|{
comment|// ------------------------------------
comment|// STEP 1. Try to acquire as many locks as we can, and ensure
comment|// we acquire at least one.
comment|// ----------------------------------
name|int
name|numReadyToWrite
init|=
literal|0
decl_stmt|;
name|long
name|now
init|=
name|EnvironmentEdgeManager
operator|.
name|currentTimeMillis
argument_list|()
decl_stmt|;
while|while
condition|(
name|lastIndexExclusive
operator|<
name|batchOp
operator|.
name|operations
operator|.
name|length
condition|)
block|{
name|Pair
argument_list|<
name|Mutation
argument_list|,
name|Integer
argument_list|>
name|nextPair
init|=
name|batchOp
operator|.
name|operations
index|[
name|lastIndexExclusive
index|]
decl_stmt|;
name|Mutation
name|mutation
init|=
name|nextPair
operator|.
name|getFirst
argument_list|()
decl_stmt|;
name|boolean
name|isPutMutation
init|=
name|mutation
operator|instanceof
name|Put
decl_stmt|;
name|Integer
name|providedLockId
init|=
name|nextPair
operator|.
name|getSecond
argument_list|()
decl_stmt|;
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|List
argument_list|<
name|KeyValue
argument_list|>
argument_list|>
name|familyMap
init|=
name|mutation
operator|.
name|getFamilyMap
argument_list|()
decl_stmt|;
comment|// store the family map reference to allow for mutations
name|familyMaps
index|[
name|lastIndexExclusive
index|]
operator|=
name|familyMap
expr_stmt|;
comment|// skip anything that "ran" already
if|if
condition|(
name|batchOp
operator|.
name|retCodeDetails
index|[
name|lastIndexExclusive
index|]
operator|.
name|getOperationStatusCode
argument_list|()
operator|!=
name|OperationStatusCode
operator|.
name|NOT_RUN
condition|)
block|{
name|lastIndexExclusive
operator|++
expr_stmt|;
continue|continue;
block|}
try|try
block|{
if|if
condition|(
name|isPutMutation
condition|)
block|{
comment|// Check the families in the put. If bad, skip this one.
name|checkFamilies
argument_list|(
name|familyMap
operator|.
name|keySet
argument_list|()
argument_list|)
expr_stmt|;
name|checkTimestamps
argument_list|(
name|mutation
operator|.
name|getFamilyMap
argument_list|()
argument_list|,
name|now
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|prepareDelete
argument_list|(
operator|(
name|Delete
operator|)
name|mutation
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|NoSuchColumnFamilyException
name|nscf
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"No such column family in batch mutation"
argument_list|,
name|nscf
argument_list|)
expr_stmt|;
name|batchOp
operator|.
name|retCodeDetails
index|[
name|lastIndexExclusive
index|]
operator|=
operator|new
name|OperationStatus
argument_list|(
name|OperationStatusCode
operator|.
name|BAD_FAMILY
argument_list|,
name|nscf
operator|.
name|getMessage
argument_list|()
argument_list|)
expr_stmt|;
name|lastIndexExclusive
operator|++
expr_stmt|;
continue|continue;
block|}
catch|catch
parameter_list|(
name|FailedSanityCheckException
name|fsce
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Batch Mutation did not pass sanity check"
argument_list|,
name|fsce
argument_list|)
expr_stmt|;
name|batchOp
operator|.
name|retCodeDetails
index|[
name|lastIndexExclusive
index|]
operator|=
operator|new
name|OperationStatus
argument_list|(
name|OperationStatusCode
operator|.
name|SANITY_CHECK_FAILURE
argument_list|,
name|fsce
operator|.
name|getMessage
argument_list|()
argument_list|)
expr_stmt|;
name|lastIndexExclusive
operator|++
expr_stmt|;
continue|continue;
block|}
comment|// If we haven't got any rows in our batch, we should block to
comment|// get the next one.
name|boolean
name|shouldBlock
init|=
name|numReadyToWrite
operator|==
literal|0
decl_stmt|;
name|Integer
name|acquiredLockId
init|=
literal|null
decl_stmt|;
try|try
block|{
name|acquiredLockId
operator|=
name|getLock
argument_list|(
name|providedLockId
argument_list|,
name|mutation
operator|.
name|getRow
argument_list|()
argument_list|,
name|shouldBlock
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ioe
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failed getting lock in batch put, row="
operator|+
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|mutation
operator|.
name|getRow
argument_list|()
argument_list|)
argument_list|,
name|ioe
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|acquiredLockId
operator|==
literal|null
condition|)
block|{
comment|// We failed to grab another lock
assert|assert
operator|!
name|shouldBlock
operator|:
literal|"Should never fail to get lock when blocking"
assert|;
break|break;
comment|// stop acquiring more rows for this batch
block|}
if|if
condition|(
name|providedLockId
operator|==
literal|null
condition|)
block|{
name|acquiredLocks
operator|.
name|add
argument_list|(
name|acquiredLockId
argument_list|)
expr_stmt|;
block|}
name|lastIndexExclusive
operator|++
expr_stmt|;
name|numReadyToWrite
operator|++
expr_stmt|;
if|if
condition|(
name|isPutMutation
condition|)
block|{
comment|// If Column Families stay consistent through out all of the
comment|// individual puts then metrics can be reported as a mutliput across
comment|// column families in the first put.
if|if
condition|(
name|putsCfSet
operator|==
literal|null
condition|)
block|{
name|putsCfSet
operator|=
name|mutation
operator|.
name|getFamilyMap
argument_list|()
operator|.
name|keySet
argument_list|()
expr_stmt|;
block|}
else|else
block|{
name|putsCfSetConsistent
operator|=
name|putsCfSetConsistent
operator|&&
name|mutation
operator|.
name|getFamilyMap
argument_list|()
operator|.
name|keySet
argument_list|()
operator|.
name|equals
argument_list|(
name|putsCfSet
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
if|if
condition|(
name|deletesCfSet
operator|==
literal|null
condition|)
block|{
name|deletesCfSet
operator|=
name|mutation
operator|.
name|getFamilyMap
argument_list|()
operator|.
name|keySet
argument_list|()
expr_stmt|;
block|}
else|else
block|{
name|deletesCfSetConsistent
operator|=
name|deletesCfSetConsistent
operator|&&
name|mutation
operator|.
name|getFamilyMap
argument_list|()
operator|.
name|keySet
argument_list|()
operator|.
name|equals
argument_list|(
name|deletesCfSet
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|// we should record the timestamp only after we have acquired the rowLock,
comment|// otherwise, newer puts/deletes are not guaranteed to have a newer timestamp
name|now
operator|=
name|EnvironmentEdgeManager
operator|.
name|currentTimeMillis
argument_list|()
expr_stmt|;
name|byte
index|[]
name|byteNow
init|=
name|Bytes
operator|.
name|toBytes
argument_list|(
name|now
argument_list|)
decl_stmt|;
comment|// Nothing to put/delete -- an exception in the above such as NoSuchColumnFamily?
if|if
condition|(
name|numReadyToWrite
operator|<=
literal|0
condition|)
return|return
literal|0L
return|;
comment|// We've now grabbed as many mutations off the list as we can
comment|// ------------------------------------
comment|// STEP 2. Update any LATEST_TIMESTAMP timestamps
comment|// ----------------------------------
for|for
control|(
name|int
name|i
init|=
name|firstIndex
init|;
name|i
operator|<
name|lastIndexExclusive
condition|;
name|i
operator|++
control|)
block|{
comment|// skip invalid
if|if
condition|(
name|batchOp
operator|.
name|retCodeDetails
index|[
name|i
index|]
operator|.
name|getOperationStatusCode
argument_list|()
operator|!=
name|OperationStatusCode
operator|.
name|NOT_RUN
condition|)
continue|continue;
name|Mutation
name|mutation
init|=
name|batchOp
operator|.
name|operations
index|[
name|i
index|]
operator|.
name|getFirst
argument_list|()
decl_stmt|;
if|if
condition|(
name|mutation
operator|instanceof
name|Put
condition|)
block|{
name|updateKVTimestamps
argument_list|(
name|familyMaps
index|[
name|i
index|]
operator|.
name|values
argument_list|()
argument_list|,
name|byteNow
argument_list|)
expr_stmt|;
name|noOfPuts
operator|++
expr_stmt|;
block|}
else|else
block|{
name|prepareDeleteTimestamps
argument_list|(
name|familyMaps
index|[
name|i
index|]
argument_list|,
name|byteNow
argument_list|)
expr_stmt|;
name|noOfDeletes
operator|++
expr_stmt|;
block|}
block|}
name|lock
argument_list|(
name|this
operator|.
name|updatesLock
operator|.
name|readLock
argument_list|()
argument_list|,
name|numReadyToWrite
argument_list|)
expr_stmt|;
name|locked
operator|=
literal|true
expr_stmt|;
comment|//
comment|// ------------------------------------
comment|// Acquire the latest mvcc number
comment|// ----------------------------------
name|w
operator|=
name|mvcc
operator|.
name|beginMemstoreInsert
argument_list|()
expr_stmt|;
comment|// ------------------------------------
comment|// STEP 3. Write back to memstore
comment|// Write to memstore. It is ok to write to memstore
comment|// first without updating the HLog because we do not roll
comment|// forward the memstore MVCC. The MVCC will be moved up when
comment|// the complete operation is done. These changes are not yet
comment|// visible to scanners till we update the MVCC. The MVCC is
comment|// moved only when the sync is complete.
comment|// ----------------------------------
name|long
name|addedSize
init|=
literal|0
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
name|firstIndex
init|;
name|i
operator|<
name|lastIndexExclusive
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|batchOp
operator|.
name|retCodeDetails
index|[
name|i
index|]
operator|.
name|getOperationStatusCode
argument_list|()
operator|!=
name|OperationStatusCode
operator|.
name|NOT_RUN
condition|)
block|{
continue|continue;
block|}
name|addedSize
operator|+=
name|applyFamilyMapToMemstore
argument_list|(
name|familyMaps
index|[
name|i
index|]
argument_list|,
name|w
argument_list|)
expr_stmt|;
block|}
comment|// ------------------------------------
comment|// STEP 4. Build WAL edit
comment|// ----------------------------------
for|for
control|(
name|int
name|i
init|=
name|firstIndex
init|;
name|i
operator|<
name|lastIndexExclusive
condition|;
name|i
operator|++
control|)
block|{
comment|// Skip puts that were determined to be invalid during preprocessing
if|if
condition|(
name|batchOp
operator|.
name|retCodeDetails
index|[
name|i
index|]
operator|.
name|getOperationStatusCode
argument_list|()
operator|!=
name|OperationStatusCode
operator|.
name|NOT_RUN
condition|)
block|{
continue|continue;
block|}
name|batchOp
operator|.
name|retCodeDetails
index|[
name|i
index|]
operator|=
name|OperationStatus
operator|.
name|SUCCESS
expr_stmt|;
name|Mutation
name|m
init|=
name|batchOp
operator|.
name|operations
index|[
name|i
index|]
operator|.
name|getFirst
argument_list|()
decl_stmt|;
if|if
condition|(
operator|!
name|m
operator|.
name|getWriteToWAL
argument_list|()
condition|)
block|{
if|if
condition|(
name|m
operator|instanceof
name|Put
condition|)
block|{
name|recordPutWithoutWal
argument_list|(
name|m
operator|.
name|getFamilyMap
argument_list|()
argument_list|)
expr_stmt|;
block|}
continue|continue;
block|}
comment|// Add WAL edits by CP
name|WALEdit
name|fromCP
init|=
name|batchOp
operator|.
name|walEditsFromCoprocessors
index|[
name|i
index|]
decl_stmt|;
if|if
condition|(
name|fromCP
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|KeyValue
name|kv
range|:
name|fromCP
operator|.
name|getKeyValues
argument_list|()
control|)
block|{
name|walEdit
operator|.
name|add
argument_list|(
name|kv
argument_list|)
expr_stmt|;
block|}
block|}
name|addFamilyMapToWALEdit
argument_list|(
name|familyMaps
index|[
name|i
index|]
argument_list|,
name|walEdit
argument_list|)
expr_stmt|;
block|}
comment|// -------------------------
comment|// STEP 5. Append the edit to WAL. Do not sync wal.
comment|// -------------------------
name|Mutation
name|first
init|=
name|batchOp
operator|.
name|operations
index|[
name|firstIndex
index|]
operator|.
name|getFirst
argument_list|()
decl_stmt|;
name|txid
operator|=
name|this
operator|.
name|log
operator|.
name|appendNoSync
argument_list|(
name|regionInfo
argument_list|,
name|this
operator|.
name|htableDescriptor
operator|.
name|getName
argument_list|()
argument_list|,
name|walEdit
argument_list|,
name|first
operator|.
name|getClusterId
argument_list|()
argument_list|,
name|now
argument_list|,
name|this
operator|.
name|htableDescriptor
argument_list|)
expr_stmt|;
comment|// -------------------------------
comment|// STEP 6. Release row locks, etc.
comment|// -------------------------------
if|if
condition|(
name|locked
condition|)
block|{
name|this
operator|.
name|updatesLock
operator|.
name|readLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
name|locked
operator|=
literal|false
expr_stmt|;
block|}
if|if
condition|(
name|acquiredLocks
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|Integer
name|toRelease
range|:
name|acquiredLocks
control|)
block|{
name|releaseRowLock
argument_list|(
name|toRelease
argument_list|)
expr_stmt|;
block|}
name|acquiredLocks
operator|=
literal|null
expr_stmt|;
block|}
comment|// -------------------------
comment|// STEP 7. Sync wal.
comment|// -------------------------
if|if
condition|(
name|walEdit
operator|.
name|size
argument_list|()
operator|>
literal|0
condition|)
block|{
name|syncOrDefer
argument_list|(
name|txid
argument_list|)
expr_stmt|;
block|}
name|walSyncSuccessful
operator|=
literal|true
expr_stmt|;
comment|// ------------------------------------------------------------------
comment|// STEP 8. Advance mvcc. This will make this put visible to scanners and getters.
comment|// ------------------------------------------------------------------
if|if
condition|(
name|w
operator|!=
literal|null
condition|)
block|{
name|mvcc
operator|.
name|completeMemstoreInsert
argument_list|(
name|w
argument_list|)
expr_stmt|;
name|w
operator|=
literal|null
expr_stmt|;
block|}
comment|// ------------------------------------
comment|// STEP 9. Run coprocessor post hooks. This should be done after the wal is
comment|// synced so that the coprocessor contract is adhered to.
comment|// ------------------------------------
if|if
condition|(
name|coprocessorHost
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|int
name|i
init|=
name|firstIndex
init|;
name|i
operator|<
name|lastIndexExclusive
condition|;
name|i
operator|++
control|)
block|{
comment|// only for successful puts
if|if
condition|(
name|batchOp
operator|.
name|retCodeDetails
index|[
name|i
index|]
operator|.
name|getOperationStatusCode
argument_list|()
operator|!=
name|OperationStatusCode
operator|.
name|SUCCESS
condition|)
block|{
continue|continue;
block|}
name|Mutation
name|m
init|=
name|batchOp
operator|.
name|operations
index|[
name|i
index|]
operator|.
name|getFirst
argument_list|()
decl_stmt|;
if|if
condition|(
name|m
operator|instanceof
name|Put
condition|)
block|{
name|coprocessorHost
operator|.
name|postPut
argument_list|(
operator|(
name|Put
operator|)
name|m
argument_list|,
name|walEdit
argument_list|,
name|m
operator|.
name|getWriteToWAL
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|coprocessorHost
operator|.
name|postDelete
argument_list|(
operator|(
name|Delete
operator|)
name|m
argument_list|,
name|walEdit
argument_list|,
name|m
operator|.
name|getWriteToWAL
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
block|}
name|success
operator|=
literal|true
expr_stmt|;
return|return
name|addedSize
return|;
block|}
finally|finally
block|{
comment|// if the wal sync was unsuccessful, remove keys from memstore
if|if
condition|(
operator|!
name|walSyncSuccessful
condition|)
block|{
name|rollbackMemstore
argument_list|(
name|batchOp
argument_list|,
name|familyMaps
argument_list|,
name|firstIndex
argument_list|,
name|lastIndexExclusive
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|w
operator|!=
literal|null
condition|)
name|mvcc
operator|.
name|completeMemstoreInsert
argument_list|(
name|w
argument_list|)
expr_stmt|;
if|if
condition|(
name|locked
condition|)
block|{
name|this
operator|.
name|updatesLock
operator|.
name|readLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|acquiredLocks
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|Integer
name|toRelease
range|:
name|acquiredLocks
control|)
block|{
name|releaseRowLock
argument_list|(
name|toRelease
argument_list|)
expr_stmt|;
block|}
block|}
comment|// See if the column families were consistent through the whole thing.
comment|// if they were then keep them. If they were not then pass a null.
comment|// null will be treated as unknown.
comment|// Total time taken might be involving Puts and Deletes.
comment|// Split the time for puts and deletes based on the total number of Puts and Deletes.
if|if
condition|(
name|noOfPuts
operator|>
literal|0
condition|)
block|{
comment|// There were some Puts in the batch.
if|if
condition|(
name|this
operator|.
name|metricsRegion
operator|!=
literal|null
condition|)
block|{
name|this
operator|.
name|metricsRegion
operator|.
name|updatePut
argument_list|()
expr_stmt|;
block|}
block|}
if|if
condition|(
name|noOfDeletes
operator|>
literal|0
condition|)
block|{
comment|// There were some Deletes in the batch.
if|if
condition|(
name|this
operator|.
name|metricsRegion
operator|!=
literal|null
condition|)
block|{
name|this
operator|.
name|metricsRegion
operator|.
name|updateDelete
argument_list|()
expr_stmt|;
block|}
block|}
if|if
condition|(
operator|!
name|success
condition|)
block|{
for|for
control|(
name|int
name|i
init|=
name|firstIndex
init|;
name|i
operator|<
name|lastIndexExclusive
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|batchOp
operator|.
name|retCodeDetails
index|[
name|i
index|]
operator|.
name|getOperationStatusCode
argument_list|()
operator|==
name|OperationStatusCode
operator|.
name|NOT_RUN
condition|)
block|{
name|batchOp
operator|.
name|retCodeDetails
index|[
name|i
index|]
operator|=
name|OperationStatus
operator|.
name|FAILURE
expr_stmt|;
block|}
block|}
block|}
name|batchOp
operator|.
name|nextIndexToProcess
operator|=
name|lastIndexExclusive
expr_stmt|;
block|}
block|}
comment|//TODO, Think that gets/puts and deletes should be refactored a bit so that
comment|//the getting of the lock happens before, so that you would just pass it into
comment|//the methods. So in the case of checkAndMutate you could just do lockRow,
comment|//get, put, unlockRow or something
comment|/**    *    * @param row    * @param family    * @param qualifier    * @param compareOp    * @param comparator    * @param w    * @param writeToWAL    * @throws IOException    * @return true if the new put was executed, false otherwise    */
specifier|public
name|boolean
name|checkAndMutate
parameter_list|(
name|byte
index|[]
name|row
parameter_list|,
name|byte
index|[]
name|family
parameter_list|,
name|byte
index|[]
name|qualifier
parameter_list|,
name|CompareOp
name|compareOp
parameter_list|,
name|ByteArrayComparable
name|comparator
parameter_list|,
name|Mutation
name|w
parameter_list|,
name|boolean
name|writeToWAL
parameter_list|)
throws|throws
name|IOException
block|{
name|checkReadOnly
argument_list|()
expr_stmt|;
comment|//TODO, add check for value length or maybe even better move this to the
comment|//client if this becomes a global setting
name|checkResources
argument_list|()
expr_stmt|;
name|boolean
name|isPut
init|=
name|w
operator|instanceof
name|Put
decl_stmt|;
if|if
condition|(
operator|!
name|isPut
operator|&&
operator|!
operator|(
name|w
operator|instanceof
name|Delete
operator|)
condition|)
throw|throw
operator|new
name|DoNotRetryIOException
argument_list|(
literal|"Action must be Put or Delete"
argument_list|)
throw|;
name|Row
name|r
init|=
operator|(
name|Row
operator|)
name|w
decl_stmt|;
if|if
condition|(
operator|!
name|Bytes
operator|.
name|equals
argument_list|(
name|row
argument_list|,
name|r
operator|.
name|getRow
argument_list|()
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|DoNotRetryIOException
argument_list|(
literal|"Action's getRow must match the passed row"
argument_list|)
throw|;
block|}
name|startRegionOperation
argument_list|()
expr_stmt|;
try|try
block|{
name|Get
name|get
init|=
operator|new
name|Get
argument_list|(
name|row
argument_list|)
decl_stmt|;
name|checkFamily
argument_list|(
name|family
argument_list|)
expr_stmt|;
name|get
operator|.
name|addColumn
argument_list|(
name|family
argument_list|,
name|qualifier
argument_list|)
expr_stmt|;
comment|// Lock row
name|Integer
name|lid
init|=
name|getLock
argument_list|(
literal|null
argument_list|,
name|get
operator|.
name|getRow
argument_list|()
argument_list|,
literal|true
argument_list|)
decl_stmt|;
comment|// wait for all previous transactions to complete (with lock held)
name|mvcc
operator|.
name|completeMemstoreInsert
argument_list|(
name|mvcc
operator|.
name|beginMemstoreInsert
argument_list|()
argument_list|)
expr_stmt|;
name|List
argument_list|<
name|KeyValue
argument_list|>
name|result
init|=
literal|null
decl_stmt|;
try|try
block|{
name|result
operator|=
name|get
argument_list|(
name|get
argument_list|,
literal|false
argument_list|)
expr_stmt|;
name|boolean
name|valueIsNull
init|=
name|comparator
operator|.
name|getValue
argument_list|()
operator|==
literal|null
operator|||
name|comparator
operator|.
name|getValue
argument_list|()
operator|.
name|length
operator|==
literal|0
decl_stmt|;
name|boolean
name|matches
init|=
literal|false
decl_stmt|;
if|if
condition|(
name|result
operator|.
name|size
argument_list|()
operator|==
literal|0
operator|&&
name|valueIsNull
condition|)
block|{
name|matches
operator|=
literal|true
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|result
operator|.
name|size
argument_list|()
operator|>
literal|0
operator|&&
name|result
operator|.
name|get
argument_list|(
literal|0
argument_list|)
operator|.
name|getValue
argument_list|()
operator|.
name|length
operator|==
literal|0
operator|&&
name|valueIsNull
condition|)
block|{
name|matches
operator|=
literal|true
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|result
operator|.
name|size
argument_list|()
operator|==
literal|1
operator|&&
operator|!
name|valueIsNull
condition|)
block|{
name|KeyValue
name|kv
init|=
name|result
operator|.
name|get
argument_list|(
literal|0
argument_list|)
decl_stmt|;
name|int
name|compareResult
init|=
name|comparator
operator|.
name|compareTo
argument_list|(
name|kv
operator|.
name|getBuffer
argument_list|()
argument_list|,
name|kv
operator|.
name|getValueOffset
argument_list|()
argument_list|,
name|kv
operator|.
name|getValueLength
argument_list|()
argument_list|)
decl_stmt|;
switch|switch
condition|(
name|compareOp
condition|)
block|{
case|case
name|LESS
case|:
name|matches
operator|=
name|compareResult
operator|<=
literal|0
expr_stmt|;
break|break;
case|case
name|LESS_OR_EQUAL
case|:
name|matches
operator|=
name|compareResult
operator|<
literal|0
expr_stmt|;
break|break;
case|case
name|EQUAL
case|:
name|matches
operator|=
name|compareResult
operator|==
literal|0
expr_stmt|;
break|break;
case|case
name|NOT_EQUAL
case|:
name|matches
operator|=
name|compareResult
operator|!=
literal|0
expr_stmt|;
break|break;
case|case
name|GREATER_OR_EQUAL
case|:
name|matches
operator|=
name|compareResult
operator|>
literal|0
expr_stmt|;
break|break;
case|case
name|GREATER
case|:
name|matches
operator|=
name|compareResult
operator|>=
literal|0
expr_stmt|;
break|break;
default|default:
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"Unknown Compare op "
operator|+
name|compareOp
operator|.
name|name
argument_list|()
argument_list|)
throw|;
block|}
block|}
comment|//If matches put the new put or delete the new delete
if|if
condition|(
name|matches
condition|)
block|{
comment|// All edits for the given row (across all column families) must
comment|// happen atomically.
name|doBatchMutate
argument_list|(
operator|(
name|Mutation
operator|)
name|w
argument_list|,
name|lid
argument_list|)
expr_stmt|;
name|this
operator|.
name|checkAndMutateChecksPassed
operator|.
name|increment
argument_list|()
expr_stmt|;
return|return
literal|true
return|;
block|}
name|this
operator|.
name|checkAndMutateChecksFailed
operator|.
name|increment
argument_list|()
expr_stmt|;
return|return
literal|false
return|;
block|}
finally|finally
block|{
name|releaseRowLock
argument_list|(
name|lid
argument_list|)
expr_stmt|;
block|}
block|}
finally|finally
block|{
name|closeRegionOperation
argument_list|()
expr_stmt|;
block|}
block|}
annotation|@
name|SuppressWarnings
argument_list|(
literal|"unchecked"
argument_list|)
specifier|private
name|void
name|doBatchMutate
parameter_list|(
name|Mutation
name|mutation
parameter_list|,
name|Integer
name|lid
parameter_list|)
throws|throws
name|IOException
throws|,
name|DoNotRetryIOException
block|{
name|Pair
argument_list|<
name|Mutation
argument_list|,
name|Integer
argument_list|>
index|[]
name|mutateWithLocks
init|=
operator|new
name|Pair
index|[]
block|{
operator|new
name|Pair
argument_list|<
name|Mutation
argument_list|,
name|Integer
argument_list|>
argument_list|(
name|mutation
argument_list|,
name|lid
argument_list|)
block|}
decl_stmt|;
name|OperationStatus
index|[]
name|batchMutate
init|=
name|this
operator|.
name|batchMutate
argument_list|(
name|mutateWithLocks
argument_list|)
decl_stmt|;
if|if
condition|(
name|batchMutate
index|[
literal|0
index|]
operator|.
name|getOperationStatusCode
argument_list|()
operator|.
name|equals
argument_list|(
name|OperationStatusCode
operator|.
name|SANITY_CHECK_FAILURE
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|FailedSanityCheckException
argument_list|(
name|batchMutate
index|[
literal|0
index|]
operator|.
name|getExceptionMsg
argument_list|()
argument_list|)
throw|;
block|}
elseif|else
if|if
condition|(
name|batchMutate
index|[
literal|0
index|]
operator|.
name|getOperationStatusCode
argument_list|()
operator|.
name|equals
argument_list|(
name|OperationStatusCode
operator|.
name|BAD_FAMILY
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|NoSuchColumnFamilyException
argument_list|(
name|batchMutate
index|[
literal|0
index|]
operator|.
name|getExceptionMsg
argument_list|()
argument_list|)
throw|;
block|}
block|}
comment|/**    * Replaces any KV timestamps set to {@link HConstants#LATEST_TIMESTAMP}    * with the provided current timestamp.    */
name|void
name|updateKVTimestamps
parameter_list|(
specifier|final
name|Iterable
argument_list|<
name|List
argument_list|<
name|KeyValue
argument_list|>
argument_list|>
name|keyLists
parameter_list|,
specifier|final
name|byte
index|[]
name|now
parameter_list|)
block|{
for|for
control|(
name|List
argument_list|<
name|KeyValue
argument_list|>
name|keys
range|:
name|keyLists
control|)
block|{
if|if
condition|(
name|keys
operator|==
literal|null
condition|)
continue|continue;
for|for
control|(
name|KeyValue
name|key
range|:
name|keys
control|)
block|{
name|key
operator|.
name|updateLatestStamp
argument_list|(
name|now
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|/*    * Check if resources to support an update.    *    * Here we synchronize on HRegion, a broad scoped lock.  Its appropriate    * given we're figuring in here whether this region is able to take on    * writes.  This is only method with a synchronize (at time of writing),    * this and the synchronize on 'this' inside in internalFlushCache to send    * the notify.    */
specifier|private
name|void
name|checkResources
parameter_list|()
throws|throws
name|RegionTooBusyException
throws|,
name|InterruptedIOException
block|{
comment|// If catalog region, do not impose resource constraints or block updates.
if|if
condition|(
name|this
operator|.
name|getRegionInfo
argument_list|()
operator|.
name|isMetaRegion
argument_list|()
condition|)
return|return;
name|boolean
name|blocked
init|=
literal|false
decl_stmt|;
name|long
name|startTime
init|=
literal|0
decl_stmt|;
while|while
condition|(
name|this
operator|.
name|memstoreSize
operator|.
name|get
argument_list|()
operator|>
name|this
operator|.
name|blockingMemStoreSize
condition|)
block|{
name|requestFlush
argument_list|()
expr_stmt|;
if|if
condition|(
operator|!
name|blocked
condition|)
block|{
name|startTime
operator|=
name|EnvironmentEdgeManager
operator|.
name|currentTimeMillis
argument_list|()
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Blocking updates for '"
operator|+
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|"' on region "
operator|+
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|getRegionName
argument_list|()
argument_list|)
operator|+
literal|": memstore size "
operator|+
name|StringUtils
operator|.
name|humanReadableInt
argument_list|(
name|this
operator|.
name|memstoreSize
operator|.
name|get
argument_list|()
argument_list|)
operator|+
literal|" is>= than blocking "
operator|+
name|StringUtils
operator|.
name|humanReadableInt
argument_list|(
name|this
operator|.
name|blockingMemStoreSize
argument_list|)
operator|+
literal|" size"
argument_list|)
expr_stmt|;
block|}
name|long
name|now
init|=
name|EnvironmentEdgeManager
operator|.
name|currentTimeMillis
argument_list|()
decl_stmt|;
name|long
name|timeToWait
init|=
name|startTime
operator|+
name|busyWaitDuration
operator|-
name|now
decl_stmt|;
if|if
condition|(
name|timeToWait
operator|<=
literal|0L
condition|)
block|{
specifier|final
name|long
name|totalTime
init|=
name|now
operator|-
name|startTime
decl_stmt|;
name|this
operator|.
name|updatesBlockedMs
operator|.
name|add
argument_list|(
name|totalTime
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Failed to unblock updates for region "
operator|+
name|this
operator|+
literal|" '"
operator|+
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|"' in "
operator|+
name|totalTime
operator|+
literal|"ms. The region is still busy."
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|RegionTooBusyException
argument_list|(
literal|"region is flushing"
argument_list|)
throw|;
block|}
name|blocked
operator|=
literal|true
expr_stmt|;
synchronized|synchronized
init|(
name|this
init|)
block|{
try|try
block|{
name|wait
argument_list|(
name|Math
operator|.
name|min
argument_list|(
name|timeToWait
argument_list|,
name|threadWakeFrequency
argument_list|)
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|ie
parameter_list|)
block|{
specifier|final
name|long
name|totalTime
init|=
name|EnvironmentEdgeManager
operator|.
name|currentTimeMillis
argument_list|()
operator|-
name|startTime
decl_stmt|;
if|if
condition|(
name|totalTime
operator|>
literal|0
condition|)
block|{
name|this
operator|.
name|updatesBlockedMs
operator|.
name|add
argument_list|(
name|totalTime
argument_list|)
expr_stmt|;
block|}
name|LOG
operator|.
name|info
argument_list|(
literal|"Interrupted while waiting to unblock updates for region "
operator|+
name|this
operator|+
literal|" '"
operator|+
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|"'"
argument_list|)
expr_stmt|;
name|InterruptedIOException
name|iie
init|=
operator|new
name|InterruptedIOException
argument_list|()
decl_stmt|;
name|iie
operator|.
name|initCause
argument_list|(
name|ie
argument_list|)
expr_stmt|;
throw|throw
name|iie
throw|;
block|}
block|}
block|}
if|if
condition|(
name|blocked
condition|)
block|{
comment|// Add in the blocked time if appropriate
specifier|final
name|long
name|totalTime
init|=
name|EnvironmentEdgeManager
operator|.
name|currentTimeMillis
argument_list|()
operator|-
name|startTime
decl_stmt|;
if|if
condition|(
name|totalTime
operator|>
literal|0
condition|)
block|{
name|this
operator|.
name|updatesBlockedMs
operator|.
name|add
argument_list|(
name|totalTime
argument_list|)
expr_stmt|;
block|}
name|LOG
operator|.
name|info
argument_list|(
literal|"Unblocking updates for region "
operator|+
name|this
operator|+
literal|" '"
operator|+
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|"'"
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * @throws IOException Throws exception if region is in read-only mode.    */
specifier|protected
name|void
name|checkReadOnly
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|this
operator|.
name|writestate
operator|.
name|isReadOnly
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"region is read only"
argument_list|)
throw|;
block|}
block|}
comment|/**    * Add updates first to the hlog and then add values to memstore.    * Warning: Assumption is caller has lock on passed in row.    * @param family    * @param edits Cell updates by column    * @praram now    * @throws IOException    */
specifier|private
name|void
name|put
parameter_list|(
specifier|final
name|byte
index|[]
name|row
parameter_list|,
name|byte
index|[]
name|family
parameter_list|,
name|List
argument_list|<
name|KeyValue
argument_list|>
name|edits
parameter_list|)
throws|throws
name|IOException
block|{
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|List
argument_list|<
name|KeyValue
argument_list|>
argument_list|>
name|familyMap
decl_stmt|;
name|familyMap
operator|=
operator|new
name|HashMap
argument_list|<
name|byte
index|[]
argument_list|,
name|List
argument_list|<
name|KeyValue
argument_list|>
argument_list|>
argument_list|()
expr_stmt|;
name|familyMap
operator|.
name|put
argument_list|(
name|family
argument_list|,
name|edits
argument_list|)
expr_stmt|;
name|Put
name|p
init|=
operator|new
name|Put
argument_list|(
name|row
argument_list|)
decl_stmt|;
name|p
operator|.
name|setFamilyMap
argument_list|(
name|familyMap
argument_list|)
expr_stmt|;
name|p
operator|.
name|setClusterId
argument_list|(
name|HConstants
operator|.
name|DEFAULT_CLUSTER_ID
argument_list|)
expr_stmt|;
name|p
operator|.
name|setWriteToWAL
argument_list|(
literal|true
argument_list|)
expr_stmt|;
name|doBatchMutate
argument_list|(
name|p
argument_list|,
literal|null
argument_list|)
expr_stmt|;
block|}
comment|/**    * Atomically apply the given map of family->edits to the memstore.    * This handles the consistency control on its own, but the caller    * should already have locked updatesLock.readLock(). This also does    *<b>not</b> check the families for validity.    *    * @param familyMap Map of kvs per family    * @param localizedWriteEntry The WriteEntry of the MVCC for this transaction.    *        If null, then this method internally creates a mvcc transaction.    * @return the additional memory usage of the memstore caused by the    * new entries.    */
specifier|private
name|long
name|applyFamilyMapToMemstore
parameter_list|(
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|List
argument_list|<
name|KeyValue
argument_list|>
argument_list|>
name|familyMap
parameter_list|,
name|MultiVersionConsistencyControl
operator|.
name|WriteEntry
name|localizedWriteEntry
parameter_list|)
block|{
name|long
name|size
init|=
literal|0
decl_stmt|;
name|boolean
name|freemvcc
init|=
literal|false
decl_stmt|;
try|try
block|{
if|if
condition|(
name|localizedWriteEntry
operator|==
literal|null
condition|)
block|{
name|localizedWriteEntry
operator|=
name|mvcc
operator|.
name|beginMemstoreInsert
argument_list|()
expr_stmt|;
name|freemvcc
operator|=
literal|true
expr_stmt|;
block|}
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|byte
index|[]
argument_list|,
name|List
argument_list|<
name|KeyValue
argument_list|>
argument_list|>
name|e
range|:
name|familyMap
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|byte
index|[]
name|family
init|=
name|e
operator|.
name|getKey
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|KeyValue
argument_list|>
name|edits
init|=
name|e
operator|.
name|getValue
argument_list|()
decl_stmt|;
name|Store
name|store
init|=
name|getStore
argument_list|(
name|family
argument_list|)
decl_stmt|;
for|for
control|(
name|KeyValue
name|kv
range|:
name|edits
control|)
block|{
name|kv
operator|.
name|setMemstoreTS
argument_list|(
name|localizedWriteEntry
operator|.
name|getWriteNumber
argument_list|()
argument_list|)
expr_stmt|;
name|size
operator|+=
name|store
operator|.
name|add
argument_list|(
name|kv
argument_list|)
expr_stmt|;
block|}
block|}
block|}
finally|finally
block|{
if|if
condition|(
name|freemvcc
condition|)
block|{
name|mvcc
operator|.
name|completeMemstoreInsert
argument_list|(
name|localizedWriteEntry
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|size
return|;
block|}
comment|/**    * Remove all the keys listed in the map from the memstore. This method is    * called when a Put/Delete has updated memstore but subequently fails to update    * the wal. This method is then invoked to rollback the memstore.    */
specifier|private
name|void
name|rollbackMemstore
parameter_list|(
name|BatchOperationInProgress
argument_list|<
name|Pair
argument_list|<
name|Mutation
argument_list|,
name|Integer
argument_list|>
argument_list|>
name|batchOp
parameter_list|,
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|List
argument_list|<
name|KeyValue
argument_list|>
argument_list|>
index|[]
name|familyMaps
parameter_list|,
name|int
name|start
parameter_list|,
name|int
name|end
parameter_list|)
block|{
name|int
name|kvsRolledback
init|=
literal|0
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
name|start
init|;
name|i
operator|<
name|end
condition|;
name|i
operator|++
control|)
block|{
comment|// skip over request that never succeeded in the first place.
if|if
condition|(
name|batchOp
operator|.
name|retCodeDetails
index|[
name|i
index|]
operator|.
name|getOperationStatusCode
argument_list|()
operator|!=
name|OperationStatusCode
operator|.
name|SUCCESS
condition|)
block|{
continue|continue;
block|}
comment|// Rollback all the kvs for this row.
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|List
argument_list|<
name|KeyValue
argument_list|>
argument_list|>
name|familyMap
init|=
name|familyMaps
index|[
name|i
index|]
decl_stmt|;
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|byte
index|[]
argument_list|,
name|List
argument_list|<
name|KeyValue
argument_list|>
argument_list|>
name|e
range|:
name|familyMap
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|byte
index|[]
name|family
init|=
name|e
operator|.
name|getKey
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|KeyValue
argument_list|>
name|edits
init|=
name|e
operator|.
name|getValue
argument_list|()
decl_stmt|;
comment|// Remove those keys from the memstore that matches our
comment|// key's (row, cf, cq, timestamp, memstoreTS). The interesting part is
comment|// that even the memstoreTS has to match for keys that will be rolleded-back.
name|Store
name|store
init|=
name|getStore
argument_list|(
name|family
argument_list|)
decl_stmt|;
for|for
control|(
name|KeyValue
name|kv
range|:
name|edits
control|)
block|{
name|store
operator|.
name|rollback
argument_list|(
name|kv
argument_list|)
expr_stmt|;
name|kvsRolledback
operator|++
expr_stmt|;
block|}
block|}
block|}
name|LOG
operator|.
name|debug
argument_list|(
literal|"rollbackMemstore rolled back "
operator|+
name|kvsRolledback
operator|+
literal|" keyvalues from start:"
operator|+
name|start
operator|+
literal|" to end:"
operator|+
name|end
argument_list|)
expr_stmt|;
block|}
comment|/**    * Check the collection of families for validity.    * @throws NoSuchColumnFamilyException if a family does not exist.    */
name|void
name|checkFamilies
parameter_list|(
name|Collection
argument_list|<
name|byte
index|[]
argument_list|>
name|families
parameter_list|)
throws|throws
name|NoSuchColumnFamilyException
block|{
for|for
control|(
name|byte
index|[]
name|family
range|:
name|families
control|)
block|{
name|checkFamily
argument_list|(
name|family
argument_list|)
expr_stmt|;
block|}
block|}
name|void
name|checkTimestamps
parameter_list|(
specifier|final
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|List
argument_list|<
name|KeyValue
argument_list|>
argument_list|>
name|familyMap
parameter_list|,
name|long
name|now
parameter_list|)
throws|throws
name|FailedSanityCheckException
block|{
if|if
condition|(
name|timestampSlop
operator|==
name|HConstants
operator|.
name|LATEST_TIMESTAMP
condition|)
block|{
return|return;
block|}
name|long
name|maxTs
init|=
name|now
operator|+
name|timestampSlop
decl_stmt|;
for|for
control|(
name|List
argument_list|<
name|KeyValue
argument_list|>
name|kvs
range|:
name|familyMap
operator|.
name|values
argument_list|()
control|)
block|{
for|for
control|(
name|KeyValue
name|kv
range|:
name|kvs
control|)
block|{
comment|// see if the user-side TS is out of range. latest = server-side
if|if
condition|(
operator|!
name|kv
operator|.
name|isLatestTimestamp
argument_list|()
operator|&&
name|kv
operator|.
name|getTimestamp
argument_list|()
operator|>
name|maxTs
condition|)
block|{
throw|throw
operator|new
name|FailedSanityCheckException
argument_list|(
literal|"Timestamp for KV out of range "
operator|+
name|kv
operator|+
literal|" (too.new="
operator|+
name|timestampSlop
operator|+
literal|")"
argument_list|)
throw|;
block|}
block|}
block|}
block|}
comment|/**    * Append the given map of family->edits to a WALEdit data structure.    * This does not write to the HLog itself.    * @param familyMap map of family->edits    * @param walEdit the destination entry to append into    */
specifier|private
name|void
name|addFamilyMapToWALEdit
parameter_list|(
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|List
argument_list|<
name|KeyValue
argument_list|>
argument_list|>
name|familyMap
parameter_list|,
name|WALEdit
name|walEdit
parameter_list|)
block|{
for|for
control|(
name|List
argument_list|<
name|KeyValue
argument_list|>
name|edits
range|:
name|familyMap
operator|.
name|values
argument_list|()
control|)
block|{
for|for
control|(
name|KeyValue
name|kv
range|:
name|edits
control|)
block|{
name|walEdit
operator|.
name|add
argument_list|(
name|kv
argument_list|)
expr_stmt|;
block|}
block|}
block|}
specifier|private
name|void
name|requestFlush
parameter_list|()
block|{
if|if
condition|(
name|this
operator|.
name|rsServices
operator|==
literal|null
condition|)
block|{
return|return;
block|}
synchronized|synchronized
init|(
name|writestate
init|)
block|{
if|if
condition|(
name|this
operator|.
name|writestate
operator|.
name|isFlushRequested
argument_list|()
condition|)
block|{
return|return;
block|}
name|writestate
operator|.
name|flushRequested
operator|=
literal|true
expr_stmt|;
block|}
comment|// Make request outside of synchronize block; HBASE-818.
name|this
operator|.
name|rsServices
operator|.
name|getFlushRequester
argument_list|()
operator|.
name|requestFlush
argument_list|(
name|this
argument_list|)
expr_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Flush requested on "
operator|+
name|this
argument_list|)
expr_stmt|;
block|}
block|}
comment|/*    * @param size    * @return True if size is over the flush threshold    */
specifier|private
name|boolean
name|isFlushSize
parameter_list|(
specifier|final
name|long
name|size
parameter_list|)
block|{
return|return
name|size
operator|>
name|this
operator|.
name|memstoreFlushSize
return|;
block|}
comment|/**    * Read the edits log put under this region by wal log splitting process.  Put    * the recovered edits back up into this region.    *    *<p>We can ignore any log message that has a sequence ID that's equal to or    * lower than minSeqId.  (Because we know such log messages are already    * reflected in the HFiles.)    *    *<p>While this is running we are putting pressure on memory yet we are    * outside of our usual accounting because we are not yet an onlined region    * (this stuff is being run as part of Region initialization).  This means    * that if we're up against global memory limits, we'll not be flagged to flush    * because we are not online. We can't be flushed by usual mechanisms anyways;    * we're not yet online so our relative sequenceids are not yet aligned with    * HLog sequenceids -- not till we come up online, post processing of split    * edits.    *    *<p>But to help relieve memory pressure, at least manage our own heap size    * flushing if are in excess of per-region limits.  Flushing, though, we have    * to be careful and avoid using the regionserver/hlog sequenceid.  Its running    * on a different line to whats going on in here in this region context so if we    * crashed replaying these edits, but in the midst had a flush that used the    * regionserver log with a sequenceid in excess of whats going on in here    * in this region and with its split editlogs, then we could miss edits the    * next time we go to recover. So, we have to flush inline, using seqids that    * make sense in a this single region context only -- until we online.    *    * @param regiondir    * @param maxSeqIdInStores Any edit found in split editlogs needs to be in excess of    * the maxSeqId for the store to be applied, else its skipped.    * @param reporter    * @return the sequence id of the last edit added to this region out of the    * recovered edits log or<code>minSeqId</code> if nothing added from editlogs.    * @throws UnsupportedEncodingException    * @throws IOException    */
specifier|protected
name|long
name|replayRecoveredEditsIfAny
parameter_list|(
specifier|final
name|Path
name|regiondir
parameter_list|,
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|Long
argument_list|>
name|maxSeqIdInStores
parameter_list|,
specifier|final
name|CancelableProgressable
name|reporter
parameter_list|,
specifier|final
name|MonitoredTask
name|status
parameter_list|)
throws|throws
name|UnsupportedEncodingException
throws|,
name|IOException
block|{
name|long
name|minSeqIdForTheRegion
init|=
operator|-
literal|1
decl_stmt|;
for|for
control|(
name|Long
name|maxSeqIdInStore
range|:
name|maxSeqIdInStores
operator|.
name|values
argument_list|()
control|)
block|{
if|if
condition|(
name|maxSeqIdInStore
operator|<
name|minSeqIdForTheRegion
operator|||
name|minSeqIdForTheRegion
operator|==
operator|-
literal|1
condition|)
block|{
name|minSeqIdForTheRegion
operator|=
name|maxSeqIdInStore
expr_stmt|;
block|}
block|}
name|long
name|seqid
init|=
name|minSeqIdForTheRegion
decl_stmt|;
name|NavigableSet
argument_list|<
name|Path
argument_list|>
name|files
init|=
name|HLogUtil
operator|.
name|getSplitEditFilesSorted
argument_list|(
name|fs
argument_list|,
name|regiondir
argument_list|)
decl_stmt|;
if|if
condition|(
name|files
operator|==
literal|null
operator|||
name|files
operator|.
name|isEmpty
argument_list|()
condition|)
return|return
name|seqid
return|;
for|for
control|(
name|Path
name|edits
range|:
name|files
control|)
block|{
if|if
condition|(
name|edits
operator|==
literal|null
operator|||
operator|!
name|this
operator|.
name|fs
operator|.
name|exists
argument_list|(
name|edits
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Null or non-existent edits file: "
operator|+
name|edits
argument_list|)
expr_stmt|;
continue|continue;
block|}
if|if
condition|(
name|isZeroLengthThenDelete
argument_list|(
name|this
operator|.
name|fs
argument_list|,
name|edits
argument_list|)
condition|)
continue|continue;
name|long
name|maxSeqId
init|=
name|Long
operator|.
name|MAX_VALUE
decl_stmt|;
name|String
name|fileName
init|=
name|edits
operator|.
name|getName
argument_list|()
decl_stmt|;
name|maxSeqId
operator|=
name|Math
operator|.
name|abs
argument_list|(
name|Long
operator|.
name|parseLong
argument_list|(
name|fileName
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|maxSeqId
operator|<=
name|minSeqIdForTheRegion
condition|)
block|{
name|String
name|msg
init|=
literal|"Maximum sequenceid for this log is "
operator|+
name|maxSeqId
operator|+
literal|" and minimum sequenceid for the region is "
operator|+
name|minSeqIdForTheRegion
operator|+
literal|", skipped the whole file, path="
operator|+
name|edits
decl_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
name|msg
argument_list|)
expr_stmt|;
continue|continue;
block|}
try|try
block|{
name|seqid
operator|=
name|replayRecoveredEdits
argument_list|(
name|edits
argument_list|,
name|maxSeqIdInStores
argument_list|,
name|reporter
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|boolean
name|skipErrors
init|=
name|conf
operator|.
name|getBoolean
argument_list|(
name|HConstants
operator|.
name|HREGION_EDITS_REPLAY_SKIP_ERRORS
argument_list|,
name|conf
operator|.
name|getBoolean
argument_list|(
literal|"hbase.skip.errors"
argument_list|,
name|HConstants
operator|.
name|DEFAULT_HREGION_EDITS_REPLAY_SKIP_ERRORS
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|conf
operator|.
name|get
argument_list|(
literal|"hbase.skip.errors"
argument_list|)
operator|!=
literal|null
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"The property 'hbase.skip.errors' has been deprecated. Please use "
operator|+
name|HConstants
operator|.
name|HREGION_EDITS_REPLAY_SKIP_ERRORS
operator|+
literal|" instead."
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|skipErrors
condition|)
block|{
name|Path
name|p
init|=
name|HLogUtil
operator|.
name|moveAsideBadEditsFile
argument_list|(
name|fs
argument_list|,
name|edits
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|error
argument_list|(
name|HConstants
operator|.
name|HREGION_EDITS_REPLAY_SKIP_ERRORS
operator|+
literal|"=true so continuing. Renamed "
operator|+
name|edits
operator|+
literal|" as "
operator|+
name|p
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
else|else
block|{
throw|throw
name|e
throw|;
block|}
block|}
comment|// The edits size added into rsAccounting during this replaying will not
comment|// be required any more. So just clear it.
if|if
condition|(
name|this
operator|.
name|rsAccounting
operator|!=
literal|null
condition|)
block|{
name|this
operator|.
name|rsAccounting
operator|.
name|clearRegionReplayEditsSize
argument_list|(
name|this
operator|.
name|regionInfo
operator|.
name|getRegionName
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|seqid
operator|>
name|minSeqIdForTheRegion
condition|)
block|{
comment|// Then we added some edits to memory. Flush and cleanup split edit files.
name|internalFlushcache
argument_list|(
literal|null
argument_list|,
name|seqid
argument_list|,
name|status
argument_list|)
expr_stmt|;
block|}
comment|// Now delete the content of recovered edits.  We're done w/ them.
for|for
control|(
name|Path
name|file
range|:
name|files
control|)
block|{
if|if
condition|(
operator|!
name|this
operator|.
name|fs
operator|.
name|delete
argument_list|(
name|file
argument_list|,
literal|false
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Failed delete of "
operator|+
name|file
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Deleted recovered.edits file="
operator|+
name|file
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|seqid
return|;
block|}
comment|/*    * @param edits File of recovered edits.    * @param maxSeqIdInStores Maximum sequenceid found in each store.  Edits in log    * must be larger than this to be replayed for each store.    * @param reporter    * @return the sequence id of the last edit added to this region out of the    * recovered edits log or<code>minSeqId</code> if nothing added from editlogs.    * @throws IOException    */
specifier|private
name|long
name|replayRecoveredEdits
parameter_list|(
specifier|final
name|Path
name|edits
parameter_list|,
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|Long
argument_list|>
name|maxSeqIdInStores
parameter_list|,
specifier|final
name|CancelableProgressable
name|reporter
parameter_list|)
throws|throws
name|IOException
block|{
name|String
name|msg
init|=
literal|"Replaying edits from "
operator|+
name|edits
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
name|msg
argument_list|)
expr_stmt|;
name|MonitoredTask
name|status
init|=
name|TaskMonitor
operator|.
name|get
argument_list|()
operator|.
name|createStatus
argument_list|(
name|msg
argument_list|)
decl_stmt|;
name|status
operator|.
name|setStatus
argument_list|(
literal|"Opening logs"
argument_list|)
expr_stmt|;
name|HLog
operator|.
name|Reader
name|reader
init|=
literal|null
decl_stmt|;
try|try
block|{
name|reader
operator|=
name|HLogFactory
operator|.
name|createReader
argument_list|(
name|this
operator|.
name|fs
argument_list|,
name|edits
argument_list|,
name|conf
argument_list|)
expr_stmt|;
name|long
name|currentEditSeqId
init|=
operator|-
literal|1
decl_stmt|;
name|long
name|firstSeqIdInLog
init|=
operator|-
literal|1
decl_stmt|;
name|long
name|skippedEdits
init|=
literal|0
decl_stmt|;
name|long
name|editsCount
init|=
literal|0
decl_stmt|;
name|long
name|intervalEdits
init|=
literal|0
decl_stmt|;
name|HLog
operator|.
name|Entry
name|entry
decl_stmt|;
name|Store
name|store
init|=
literal|null
decl_stmt|;
name|boolean
name|reported_once
init|=
literal|false
decl_stmt|;
try|try
block|{
comment|// How many edits seen before we check elapsed time
name|int
name|interval
init|=
name|this
operator|.
name|conf
operator|.
name|getInt
argument_list|(
literal|"hbase.hstore.report.interval.edits"
argument_list|,
literal|2000
argument_list|)
decl_stmt|;
comment|// How often to send a progress report (default 1/2 master timeout)
name|int
name|period
init|=
name|this
operator|.
name|conf
operator|.
name|getInt
argument_list|(
literal|"hbase.hstore.report.period"
argument_list|,
name|this
operator|.
name|conf
operator|.
name|getInt
argument_list|(
literal|"hbase.master.assignment.timeoutmonitor.timeout"
argument_list|,
literal|180000
argument_list|)
operator|/
literal|2
argument_list|)
decl_stmt|;
name|long
name|lastReport
init|=
name|EnvironmentEdgeManager
operator|.
name|currentTimeMillis
argument_list|()
decl_stmt|;
while|while
condition|(
operator|(
name|entry
operator|=
name|reader
operator|.
name|next
argument_list|()
operator|)
operator|!=
literal|null
condition|)
block|{
name|HLogKey
name|key
init|=
name|entry
operator|.
name|getKey
argument_list|()
decl_stmt|;
name|WALEdit
name|val
init|=
name|entry
operator|.
name|getEdit
argument_list|()
decl_stmt|;
if|if
condition|(
name|reporter
operator|!=
literal|null
condition|)
block|{
name|intervalEdits
operator|+=
name|val
operator|.
name|size
argument_list|()
expr_stmt|;
if|if
condition|(
name|intervalEdits
operator|>=
name|interval
condition|)
block|{
comment|// Number of edits interval reached
name|intervalEdits
operator|=
literal|0
expr_stmt|;
name|long
name|cur
init|=
name|EnvironmentEdgeManager
operator|.
name|currentTimeMillis
argument_list|()
decl_stmt|;
if|if
condition|(
name|lastReport
operator|+
name|period
operator|<=
name|cur
condition|)
block|{
name|status
operator|.
name|setStatus
argument_list|(
literal|"Replaying edits..."
operator|+
literal|" skipped="
operator|+
name|skippedEdits
operator|+
literal|" edits="
operator|+
name|editsCount
argument_list|)
expr_stmt|;
comment|// Timeout reached
if|if
condition|(
operator|!
name|reporter
operator|.
name|progress
argument_list|()
condition|)
block|{
name|msg
operator|=
literal|"Progressable reporter failed, stopping replay"
expr_stmt|;
name|LOG
operator|.
name|warn
argument_list|(
name|msg
argument_list|)
expr_stmt|;
name|status
operator|.
name|abort
argument_list|(
name|msg
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|IOException
argument_list|(
name|msg
argument_list|)
throw|;
block|}
name|reported_once
operator|=
literal|true
expr_stmt|;
name|lastReport
operator|=
name|cur
expr_stmt|;
block|}
block|}
block|}
comment|// Start coprocessor replay here. The coprocessor is for each WALEdit
comment|// instead of a KeyValue.
if|if
condition|(
name|coprocessorHost
operator|!=
literal|null
condition|)
block|{
name|status
operator|.
name|setStatus
argument_list|(
literal|"Running pre-WAL-restore hook in coprocessors"
argument_list|)
expr_stmt|;
if|if
condition|(
name|coprocessorHost
operator|.
name|preWALRestore
argument_list|(
name|this
operator|.
name|getRegionInfo
argument_list|()
argument_list|,
name|key
argument_list|,
name|val
argument_list|)
condition|)
block|{
comment|// if bypass this log entry, ignore it ...
continue|continue;
block|}
block|}
if|if
condition|(
name|firstSeqIdInLog
operator|==
operator|-
literal|1
condition|)
block|{
name|firstSeqIdInLog
operator|=
name|key
operator|.
name|getLogSeqNum
argument_list|()
expr_stmt|;
block|}
name|boolean
name|flush
init|=
literal|false
decl_stmt|;
for|for
control|(
name|KeyValue
name|kv
range|:
name|val
operator|.
name|getKeyValues
argument_list|()
control|)
block|{
comment|// Check this edit is for me. Also, guard against writing the special
comment|// METACOLUMN info such as HBASE::CACHEFLUSH entries
if|if
condition|(
name|kv
operator|.
name|matchingFamily
argument_list|(
name|HLog
operator|.
name|METAFAMILY
argument_list|)
operator|||
operator|!
name|Bytes
operator|.
name|equals
argument_list|(
name|key
operator|.
name|getEncodedRegionName
argument_list|()
argument_list|,
name|this
operator|.
name|regionInfo
operator|.
name|getEncodedNameAsBytes
argument_list|()
argument_list|)
condition|)
block|{
name|skippedEdits
operator|++
expr_stmt|;
continue|continue;
block|}
comment|// Figure which store the edit is meant for.
if|if
condition|(
name|store
operator|==
literal|null
operator|||
operator|!
name|kv
operator|.
name|matchingFamily
argument_list|(
name|store
operator|.
name|getFamily
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|)
condition|)
block|{
name|store
operator|=
name|this
operator|.
name|stores
operator|.
name|get
argument_list|(
name|kv
operator|.
name|getFamily
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|store
operator|==
literal|null
condition|)
block|{
comment|// This should never happen.  Perhaps schema was changed between
comment|// crash and redeploy?
name|LOG
operator|.
name|warn
argument_list|(
literal|"No family for "
operator|+
name|kv
argument_list|)
expr_stmt|;
name|skippedEdits
operator|++
expr_stmt|;
continue|continue;
block|}
comment|// Now, figure if we should skip this edit.
if|if
condition|(
name|key
operator|.
name|getLogSeqNum
argument_list|()
operator|<=
name|maxSeqIdInStores
operator|.
name|get
argument_list|(
name|store
operator|.
name|getFamily
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|)
condition|)
block|{
name|skippedEdits
operator|++
expr_stmt|;
continue|continue;
block|}
name|currentEditSeqId
operator|=
name|key
operator|.
name|getLogSeqNum
argument_list|()
expr_stmt|;
comment|// Once we are over the limit, restoreEdit will keep returning true to
comment|// flush -- but don't flush until we've played all the kvs that make up
comment|// the WALEdit.
name|flush
operator|=
name|restoreEdit
argument_list|(
name|store
argument_list|,
name|kv
argument_list|)
expr_stmt|;
name|editsCount
operator|++
expr_stmt|;
block|}
if|if
condition|(
name|flush
condition|)
name|internalFlushcache
argument_list|(
literal|null
argument_list|,
name|currentEditSeqId
argument_list|,
name|status
argument_list|)
expr_stmt|;
if|if
condition|(
name|coprocessorHost
operator|!=
literal|null
condition|)
block|{
name|coprocessorHost
operator|.
name|postWALRestore
argument_list|(
name|this
operator|.
name|getRegionInfo
argument_list|()
argument_list|,
name|key
argument_list|,
name|val
argument_list|)
expr_stmt|;
block|}
block|}
block|}
catch|catch
parameter_list|(
name|EOFException
name|eof
parameter_list|)
block|{
name|Path
name|p
init|=
name|HLogUtil
operator|.
name|moveAsideBadEditsFile
argument_list|(
name|fs
argument_list|,
name|edits
argument_list|)
decl_stmt|;
name|msg
operator|=
literal|"Encountered EOF. Most likely due to Master failure during "
operator|+
literal|"log spliting, so we have this data in another edit.  "
operator|+
literal|"Continuing, but renaming "
operator|+
name|edits
operator|+
literal|" as "
operator|+
name|p
expr_stmt|;
name|LOG
operator|.
name|warn
argument_list|(
name|msg
argument_list|,
name|eof
argument_list|)
expr_stmt|;
name|status
operator|.
name|abort
argument_list|(
name|msg
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ioe
parameter_list|)
block|{
comment|// If the IOE resulted from bad file format,
comment|// then this problem is idempotent and retrying won't help
if|if
condition|(
name|ioe
operator|.
name|getCause
argument_list|()
operator|instanceof
name|ParseException
condition|)
block|{
name|Path
name|p
init|=
name|HLogUtil
operator|.
name|moveAsideBadEditsFile
argument_list|(
name|fs
argument_list|,
name|edits
argument_list|)
decl_stmt|;
name|msg
operator|=
literal|"File corruption encountered!  "
operator|+
literal|"Continuing, but renaming "
operator|+
name|edits
operator|+
literal|" as "
operator|+
name|p
expr_stmt|;
name|LOG
operator|.
name|warn
argument_list|(
name|msg
argument_list|,
name|ioe
argument_list|)
expr_stmt|;
name|status
operator|.
name|setStatus
argument_list|(
name|msg
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|status
operator|.
name|abort
argument_list|(
name|StringUtils
operator|.
name|stringifyException
argument_list|(
name|ioe
argument_list|)
argument_list|)
expr_stmt|;
comment|// other IO errors may be transient (bad network connection,
comment|// checksum exception on one datanode, etc).  throw& retry
throw|throw
name|ioe
throw|;
block|}
block|}
if|if
condition|(
name|reporter
operator|!=
literal|null
operator|&&
operator|!
name|reported_once
condition|)
block|{
name|reporter
operator|.
name|progress
argument_list|()
expr_stmt|;
block|}
name|msg
operator|=
literal|"Applied "
operator|+
name|editsCount
operator|+
literal|", skipped "
operator|+
name|skippedEdits
operator|+
literal|", firstSequenceidInLog="
operator|+
name|firstSeqIdInLog
operator|+
literal|", maxSequenceidInLog="
operator|+
name|currentEditSeqId
operator|+
literal|", path="
operator|+
name|edits
expr_stmt|;
name|status
operator|.
name|markComplete
argument_list|(
name|msg
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
name|msg
argument_list|)
expr_stmt|;
return|return
name|currentEditSeqId
return|;
block|}
finally|finally
block|{
name|status
operator|.
name|cleanup
argument_list|()
expr_stmt|;
if|if
condition|(
name|reader
operator|!=
literal|null
condition|)
block|{
name|reader
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
block|}
block|}
comment|/**    * Used by tests    * @param s Store to add edit too.    * @param kv KeyValue to add.    * @return True if we should flush.    */
specifier|protected
name|boolean
name|restoreEdit
parameter_list|(
specifier|final
name|Store
name|s
parameter_list|,
specifier|final
name|KeyValue
name|kv
parameter_list|)
block|{
name|long
name|kvSize
init|=
name|s
operator|.
name|add
argument_list|(
name|kv
argument_list|)
decl_stmt|;
if|if
condition|(
name|this
operator|.
name|rsAccounting
operator|!=
literal|null
condition|)
block|{
name|rsAccounting
operator|.
name|addAndGetRegionReplayEditsSize
argument_list|(
name|this
operator|.
name|regionInfo
operator|.
name|getRegionName
argument_list|()
argument_list|,
name|kvSize
argument_list|)
expr_stmt|;
block|}
return|return
name|isFlushSize
argument_list|(
name|this
operator|.
name|addAndGetGlobalMemstoreSize
argument_list|(
name|kvSize
argument_list|)
argument_list|)
return|;
block|}
comment|/*    * @param fs    * @param p File to check.    * @return True if file was zero-length (and if so, we'll delete it in here).    * @throws IOException    */
specifier|private
specifier|static
name|boolean
name|isZeroLengthThenDelete
parameter_list|(
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Path
name|p
parameter_list|)
throws|throws
name|IOException
block|{
name|FileStatus
name|stat
init|=
name|fs
operator|.
name|getFileStatus
argument_list|(
name|p
argument_list|)
decl_stmt|;
if|if
condition|(
name|stat
operator|.
name|getLen
argument_list|()
operator|>
literal|0
condition|)
return|return
literal|false
return|;
name|LOG
operator|.
name|warn
argument_list|(
literal|"File "
operator|+
name|p
operator|+
literal|" is zero-length, deleting."
argument_list|)
expr_stmt|;
name|fs
operator|.
name|delete
argument_list|(
name|p
argument_list|,
literal|false
argument_list|)
expr_stmt|;
return|return
literal|true
return|;
block|}
specifier|protected
name|HStore
name|instantiateHStore
parameter_list|(
name|Path
name|tableDir
parameter_list|,
name|HColumnDescriptor
name|c
parameter_list|)
throws|throws
name|IOException
block|{
return|return
operator|new
name|HStore
argument_list|(
name|tableDir
argument_list|,
name|this
argument_list|,
name|c
argument_list|,
name|this
operator|.
name|fs
argument_list|,
name|this
operator|.
name|conf
argument_list|)
return|;
block|}
comment|/**    * Return HStore instance.    * Use with caution.  Exposed for use of fixup utilities.    * @param column Name of column family hosted by this region.    * @return Store that goes with the family on passed<code>column</code>.    * TODO: Make this lookup faster.    */
specifier|public
name|Store
name|getStore
parameter_list|(
specifier|final
name|byte
index|[]
name|column
parameter_list|)
block|{
return|return
name|this
operator|.
name|stores
operator|.
name|get
argument_list|(
name|column
argument_list|)
return|;
block|}
specifier|public
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|Store
argument_list|>
name|getStores
parameter_list|()
block|{
return|return
name|this
operator|.
name|stores
return|;
block|}
comment|/**    * Return list of storeFiles for the set of CFs.    * Uses closeLock to prevent the race condition where a region closes    * in between the for loop - closing the stores one by one, some stores    * will return 0 files.    * @return List of storeFiles.    */
specifier|public
name|List
argument_list|<
name|String
argument_list|>
name|getStoreFileList
parameter_list|(
specifier|final
name|byte
index|[]
index|[]
name|columns
parameter_list|)
throws|throws
name|IllegalArgumentException
block|{
name|List
argument_list|<
name|String
argument_list|>
name|storeFileNames
init|=
operator|new
name|ArrayList
argument_list|<
name|String
argument_list|>
argument_list|()
decl_stmt|;
synchronized|synchronized
init|(
name|closeLock
init|)
block|{
for|for
control|(
name|byte
index|[]
name|column
range|:
name|columns
control|)
block|{
name|Store
name|store
init|=
name|this
operator|.
name|stores
operator|.
name|get
argument_list|(
name|column
argument_list|)
decl_stmt|;
if|if
condition|(
name|store
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"No column family : "
operator|+
operator|new
name|String
argument_list|(
name|column
argument_list|)
operator|+
literal|" available"
argument_list|)
throw|;
block|}
name|List
argument_list|<
name|StoreFile
argument_list|>
name|storeFiles
init|=
name|store
operator|.
name|getStorefiles
argument_list|()
decl_stmt|;
for|for
control|(
name|StoreFile
name|storeFile
range|:
name|storeFiles
control|)
block|{
name|storeFileNames
operator|.
name|add
argument_list|(
name|storeFile
operator|.
name|getPath
argument_list|()
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
block|}
return|return
name|storeFileNames
return|;
block|}
comment|//////////////////////////////////////////////////////////////////////////////
comment|// Support code
comment|//////////////////////////////////////////////////////////////////////////////
comment|/** Make sure this is a valid row for the HRegion */
name|void
name|checkRow
parameter_list|(
specifier|final
name|byte
index|[]
name|row
parameter_list|,
name|String
name|op
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
operator|!
name|rowIsInRange
argument_list|(
name|regionInfo
argument_list|,
name|row
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|WrongRegionException
argument_list|(
literal|"Requested row out of range for "
operator|+
name|op
operator|+
literal|" on HRegion "
operator|+
name|this
operator|+
literal|", startKey='"
operator|+
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|regionInfo
operator|.
name|getStartKey
argument_list|()
argument_list|)
operator|+
literal|"', getEndKey()='"
operator|+
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|regionInfo
operator|.
name|getEndKey
argument_list|()
argument_list|)
operator|+
literal|"', row='"
operator|+
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|row
argument_list|)
operator|+
literal|"'"
argument_list|)
throw|;
block|}
block|}
comment|/**    * Obtain a lock on the given row.  Blocks until success.    *    * I know it's strange to have two mappings:    *<pre>    *   ROWS  ==> LOCKS    *</pre>    * as well as    *<pre>    *   LOCKS ==> ROWS    *</pre>    *<p>It would be more memory-efficient to just have one mapping;    * maybe we'll do that in the future.    *    * @param row Name of row to lock.    * @throws IOException    * @return The id of the held lock.    */
specifier|public
name|Integer
name|obtainRowLock
parameter_list|(
specifier|final
name|byte
index|[]
name|row
parameter_list|)
throws|throws
name|IOException
block|{
name|startRegionOperation
argument_list|()
expr_stmt|;
name|this
operator|.
name|writeRequestsCount
operator|.
name|increment
argument_list|()
expr_stmt|;
try|try
block|{
return|return
name|internalObtainRowLock
argument_list|(
name|row
argument_list|,
literal|true
argument_list|)
return|;
block|}
finally|finally
block|{
name|closeRegionOperation
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**    * Obtains or tries to obtain the given row lock.    * @param waitForLock if true, will block until the lock is available.    *        Otherwise, just tries to obtain the lock and returns    *        null if unavailable.    */
specifier|private
name|Integer
name|internalObtainRowLock
parameter_list|(
specifier|final
name|byte
index|[]
name|row
parameter_list|,
name|boolean
name|waitForLock
parameter_list|)
throws|throws
name|IOException
block|{
name|checkRow
argument_list|(
name|row
argument_list|,
literal|"row lock"
argument_list|)
expr_stmt|;
name|startRegionOperation
argument_list|()
expr_stmt|;
try|try
block|{
name|HashedBytes
name|rowKey
init|=
operator|new
name|HashedBytes
argument_list|(
name|row
argument_list|)
decl_stmt|;
name|CountDownLatch
name|rowLatch
init|=
operator|new
name|CountDownLatch
argument_list|(
literal|1
argument_list|)
decl_stmt|;
comment|// loop until we acquire the row lock (unless !waitForLock)
while|while
condition|(
literal|true
condition|)
block|{
name|CountDownLatch
name|existingLatch
init|=
name|lockedRows
operator|.
name|putIfAbsent
argument_list|(
name|rowKey
argument_list|,
name|rowLatch
argument_list|)
decl_stmt|;
if|if
condition|(
name|existingLatch
operator|==
literal|null
condition|)
block|{
break|break;
block|}
else|else
block|{
comment|// row already locked
if|if
condition|(
operator|!
name|waitForLock
condition|)
block|{
return|return
literal|null
return|;
block|}
try|try
block|{
if|if
condition|(
operator|!
name|existingLatch
operator|.
name|await
argument_list|(
name|this
operator|.
name|rowLockWaitDuration
argument_list|,
name|TimeUnit
operator|.
name|MILLISECONDS
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Timed out on getting lock for row="
operator|+
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|row
argument_list|)
argument_list|)
throw|;
block|}
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|ie
parameter_list|)
block|{
comment|// Empty
block|}
block|}
block|}
comment|// loop until we generate an unused lock id
while|while
condition|(
literal|true
condition|)
block|{
name|Integer
name|lockId
init|=
name|lockIdGenerator
operator|.
name|incrementAndGet
argument_list|()
decl_stmt|;
name|HashedBytes
name|existingRowKey
init|=
name|lockIds
operator|.
name|putIfAbsent
argument_list|(
name|lockId
argument_list|,
name|rowKey
argument_list|)
decl_stmt|;
if|if
condition|(
name|existingRowKey
operator|==
literal|null
condition|)
block|{
return|return
name|lockId
return|;
block|}
else|else
block|{
comment|// lockId already in use, jump generator to a new spot
name|lockIdGenerator
operator|.
name|set
argument_list|(
name|rand
operator|.
name|nextInt
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
block|}
finally|finally
block|{
name|closeRegionOperation
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**    * Release the row lock!    * @param lockId  The lock ID to release.    */
specifier|public
name|void
name|releaseRowLock
parameter_list|(
specifier|final
name|Integer
name|lockId
parameter_list|)
block|{
if|if
condition|(
name|lockId
operator|==
literal|null
condition|)
return|return;
comment|// null lock id, do nothing
name|HashedBytes
name|rowKey
init|=
name|lockIds
operator|.
name|remove
argument_list|(
name|lockId
argument_list|)
decl_stmt|;
if|if
condition|(
name|rowKey
operator|==
literal|null
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Release unknown lockId: "
operator|+
name|lockId
argument_list|)
expr_stmt|;
return|return;
block|}
name|CountDownLatch
name|rowLatch
init|=
name|lockedRows
operator|.
name|remove
argument_list|(
name|rowKey
argument_list|)
decl_stmt|;
if|if
condition|(
name|rowLatch
operator|==
literal|null
condition|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Releases row not locked, lockId: "
operator|+
name|lockId
operator|+
literal|" row: "
operator|+
name|rowKey
argument_list|)
expr_stmt|;
return|return;
block|}
name|rowLatch
operator|.
name|countDown
argument_list|()
expr_stmt|;
block|}
comment|/**    * See if row is currently locked.    * @param lockId    * @return boolean    */
name|boolean
name|isRowLocked
parameter_list|(
specifier|final
name|Integer
name|lockId
parameter_list|)
block|{
return|return
name|lockIds
operator|.
name|containsKey
argument_list|(
name|lockId
argument_list|)
return|;
block|}
comment|/**    * Returns existing row lock if found, otherwise    * obtains a new row lock and returns it.    * @param lockid requested by the user, or null if the user didn't already hold lock    * @param row the row to lock    * @param waitForLock if true, will block until the lock is available, otherwise will    * simply return null if it could not acquire the lock.    * @return lockid or null if waitForLock is false and the lock was unavailable.    */
specifier|public
name|Integer
name|getLock
parameter_list|(
name|Integer
name|lockid
parameter_list|,
name|byte
index|[]
name|row
parameter_list|,
name|boolean
name|waitForLock
parameter_list|)
throws|throws
name|IOException
block|{
name|Integer
name|lid
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|lockid
operator|==
literal|null
condition|)
block|{
name|lid
operator|=
name|internalObtainRowLock
argument_list|(
name|row
argument_list|,
name|waitForLock
argument_list|)
expr_stmt|;
block|}
else|else
block|{
if|if
condition|(
operator|!
name|isRowLocked
argument_list|(
name|lockid
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Invalid row lock"
argument_list|)
throw|;
block|}
name|lid
operator|=
name|lockid
expr_stmt|;
block|}
return|return
name|lid
return|;
block|}
comment|/**    * Determines whether multiple column families are present    * Precondition: familyPaths is not null    *    * @param familyPaths List of Pair<byte[] column family, String hfilePath>    */
specifier|private
specifier|static
name|boolean
name|hasMultipleColumnFamilies
parameter_list|(
name|List
argument_list|<
name|Pair
argument_list|<
name|byte
index|[]
argument_list|,
name|String
argument_list|>
argument_list|>
name|familyPaths
parameter_list|)
block|{
name|boolean
name|multipleFamilies
init|=
literal|false
decl_stmt|;
name|byte
index|[]
name|family
init|=
literal|null
decl_stmt|;
for|for
control|(
name|Pair
argument_list|<
name|byte
index|[]
argument_list|,
name|String
argument_list|>
name|pair
range|:
name|familyPaths
control|)
block|{
name|byte
index|[]
name|fam
init|=
name|pair
operator|.
name|getFirst
argument_list|()
decl_stmt|;
if|if
condition|(
name|family
operator|==
literal|null
condition|)
block|{
name|family
operator|=
name|fam
expr_stmt|;
block|}
elseif|else
if|if
condition|(
operator|!
name|Bytes
operator|.
name|equals
argument_list|(
name|family
argument_list|,
name|fam
argument_list|)
condition|)
block|{
name|multipleFamilies
operator|=
literal|true
expr_stmt|;
break|break;
block|}
block|}
return|return
name|multipleFamilies
return|;
block|}
specifier|public
name|boolean
name|bulkLoadHFiles
parameter_list|(
name|List
argument_list|<
name|Pair
argument_list|<
name|byte
index|[]
argument_list|,
name|String
argument_list|>
argument_list|>
name|familyPaths
parameter_list|,
name|boolean
name|assignSeqId
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|bulkLoadHFiles
argument_list|(
name|familyPaths
argument_list|,
name|assignSeqId
argument_list|,
literal|null
argument_list|)
return|;
block|}
comment|/**    * Attempts to atomically load a group of hfiles.  This is critical for loading    * rows with multiple column families atomically.    *    * @param familyPaths List of Pair<byte[] column family, String hfilePath>    * @param bulkLoadListener Internal hooks enabling massaging/preparation of a    * file about to be bulk loaded    * @param assignSeqId    * @return true if successful, false if failed recoverably    * @throws IOException if failed unrecoverably.    */
specifier|public
name|boolean
name|bulkLoadHFiles
parameter_list|(
name|List
argument_list|<
name|Pair
argument_list|<
name|byte
index|[]
argument_list|,
name|String
argument_list|>
argument_list|>
name|familyPaths
parameter_list|,
name|boolean
name|assignSeqId
parameter_list|,
name|BulkLoadListener
name|bulkLoadListener
parameter_list|)
throws|throws
name|IOException
block|{
name|Preconditions
operator|.
name|checkNotNull
argument_list|(
name|familyPaths
argument_list|)
expr_stmt|;
comment|// we need writeLock for multi-family bulk load
name|startBulkRegionOperation
argument_list|(
name|hasMultipleColumnFamilies
argument_list|(
name|familyPaths
argument_list|)
argument_list|)
expr_stmt|;
try|try
block|{
name|this
operator|.
name|writeRequestsCount
operator|.
name|increment
argument_list|()
expr_stmt|;
comment|// There possibly was a split that happend between when the split keys
comment|// were gathered and before the HReiogn's write lock was taken.  We need
comment|// to validate the HFile region before attempting to bulk load all of them
name|List
argument_list|<
name|IOException
argument_list|>
name|ioes
init|=
operator|new
name|ArrayList
argument_list|<
name|IOException
argument_list|>
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|Pair
argument_list|<
name|byte
index|[]
argument_list|,
name|String
argument_list|>
argument_list|>
name|failures
init|=
operator|new
name|ArrayList
argument_list|<
name|Pair
argument_list|<
name|byte
index|[]
argument_list|,
name|String
argument_list|>
argument_list|>
argument_list|()
decl_stmt|;
for|for
control|(
name|Pair
argument_list|<
name|byte
index|[]
argument_list|,
name|String
argument_list|>
name|p
range|:
name|familyPaths
control|)
block|{
name|byte
index|[]
name|familyName
init|=
name|p
operator|.
name|getFirst
argument_list|()
decl_stmt|;
name|String
name|path
init|=
name|p
operator|.
name|getSecond
argument_list|()
decl_stmt|;
name|Store
name|store
init|=
name|getStore
argument_list|(
name|familyName
argument_list|)
decl_stmt|;
if|if
condition|(
name|store
operator|==
literal|null
condition|)
block|{
name|IOException
name|ioe
init|=
operator|new
name|DoNotRetryIOException
argument_list|(
literal|"No such column family "
operator|+
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|familyName
argument_list|)
argument_list|)
decl_stmt|;
name|ioes
operator|.
name|add
argument_list|(
name|ioe
argument_list|)
expr_stmt|;
name|failures
operator|.
name|add
argument_list|(
name|p
argument_list|)
expr_stmt|;
block|}
else|else
block|{
try|try
block|{
name|store
operator|.
name|assertBulkLoadHFileOk
argument_list|(
operator|new
name|Path
argument_list|(
name|path
argument_list|)
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|WrongRegionException
name|wre
parameter_list|)
block|{
comment|// recoverable (file doesn't fit in region)
name|failures
operator|.
name|add
argument_list|(
name|p
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ioe
parameter_list|)
block|{
comment|// unrecoverable (hdfs problem)
name|ioes
operator|.
name|add
argument_list|(
name|ioe
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|// validation failed, bail out before doing anything permanent.
if|if
condition|(
name|failures
operator|.
name|size
argument_list|()
operator|!=
literal|0
condition|)
block|{
name|StringBuilder
name|list
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
for|for
control|(
name|Pair
argument_list|<
name|byte
index|[]
argument_list|,
name|String
argument_list|>
name|p
range|:
name|failures
control|)
block|{
name|list
operator|.
name|append
argument_list|(
literal|"\n"
argument_list|)
operator|.
name|append
argument_list|(
name|Bytes
operator|.
name|toString
argument_list|(
name|p
operator|.
name|getFirst
argument_list|()
argument_list|)
argument_list|)
operator|.
name|append
argument_list|(
literal|" : "
argument_list|)
operator|.
name|append
argument_list|(
name|p
operator|.
name|getSecond
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|// problem when validating
name|LOG
operator|.
name|warn
argument_list|(
literal|"There was a recoverable bulk load failure likely due to a"
operator|+
literal|" split.  These (family, HFile) pairs were not loaded: "
operator|+
name|list
argument_list|)
expr_stmt|;
return|return
literal|false
return|;
block|}
comment|// validation failed because of some sort of IO problem.
if|if
condition|(
name|ioes
operator|.
name|size
argument_list|()
operator|!=
literal|0
condition|)
block|{
name|IOException
name|e
init|=
name|MultipleIOException
operator|.
name|createIOException
argument_list|(
name|ioes
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|error
argument_list|(
literal|"There were one or more IO errors when checking if the bulk load is ok."
argument_list|,
name|e
argument_list|)
expr_stmt|;
throw|throw
name|e
throw|;
block|}
for|for
control|(
name|Pair
argument_list|<
name|byte
index|[]
argument_list|,
name|String
argument_list|>
name|p
range|:
name|familyPaths
control|)
block|{
name|byte
index|[]
name|familyName
init|=
name|p
operator|.
name|getFirst
argument_list|()
decl_stmt|;
name|String
name|path
init|=
name|p
operator|.
name|getSecond
argument_list|()
decl_stmt|;
name|Store
name|store
init|=
name|getStore
argument_list|(
name|familyName
argument_list|)
decl_stmt|;
try|try
block|{
name|String
name|finalPath
init|=
name|path
decl_stmt|;
if|if
condition|(
name|bulkLoadListener
operator|!=
literal|null
condition|)
block|{
name|finalPath
operator|=
name|bulkLoadListener
operator|.
name|prepareBulkLoad
argument_list|(
name|familyName
argument_list|,
name|path
argument_list|)
expr_stmt|;
block|}
name|store
operator|.
name|bulkLoadHFile
argument_list|(
name|finalPath
argument_list|,
name|assignSeqId
condition|?
name|this
operator|.
name|log
operator|.
name|obtainSeqNum
argument_list|()
else|:
operator|-
literal|1
argument_list|)
expr_stmt|;
if|if
condition|(
name|bulkLoadListener
operator|!=
literal|null
condition|)
block|{
name|bulkLoadListener
operator|.
name|doneBulkLoad
argument_list|(
name|familyName
argument_list|,
name|path
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|ioe
parameter_list|)
block|{
comment|// A failure here can cause an atomicity violation that we currently
comment|// cannot recover from since it is likely a failed HDFS operation.
comment|// TODO Need a better story for reverting partial failures due to HDFS.
name|LOG
operator|.
name|error
argument_list|(
literal|"There was a partial failure due to IO when attempting to"
operator|+
literal|" load "
operator|+
name|Bytes
operator|.
name|toString
argument_list|(
name|p
operator|.
name|getFirst
argument_list|()
argument_list|)
operator|+
literal|" : "
operator|+
name|p
operator|.
name|getSecond
argument_list|()
argument_list|,
name|ioe
argument_list|)
expr_stmt|;
if|if
condition|(
name|bulkLoadListener
operator|!=
literal|null
condition|)
block|{
try|try
block|{
name|bulkLoadListener
operator|.
name|failedBulkLoad
argument_list|(
name|familyName
argument_list|,
name|path
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|ex
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Error while calling failedBulkLoad for family "
operator|+
name|Bytes
operator|.
name|toString
argument_list|(
name|familyName
argument_list|)
operator|+
literal|" with path "
operator|+
name|path
argument_list|,
name|ex
argument_list|)
expr_stmt|;
block|}
block|}
throw|throw
name|ioe
throw|;
block|}
block|}
return|return
literal|true
return|;
block|}
finally|finally
block|{
name|closeBulkRegionOperation
argument_list|()
expr_stmt|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|equals
parameter_list|(
name|Object
name|o
parameter_list|)
block|{
if|if
condition|(
operator|!
operator|(
name|o
operator|instanceof
name|HRegion
operator|)
condition|)
block|{
return|return
literal|false
return|;
block|}
return|return
name|Bytes
operator|.
name|equals
argument_list|(
name|this
operator|.
name|getRegionName
argument_list|()
argument_list|,
operator|(
operator|(
name|HRegion
operator|)
name|o
operator|)
operator|.
name|getRegionName
argument_list|()
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|int
name|hashCode
parameter_list|()
block|{
return|return
name|Bytes
operator|.
name|hashCode
argument_list|(
name|this
operator|.
name|getRegionName
argument_list|()
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|String
name|toString
parameter_list|()
block|{
return|return
name|this
operator|.
name|regionInfo
operator|.
name|getRegionNameAsString
argument_list|()
return|;
block|}
comment|/** @return Path of region base directory */
specifier|public
name|Path
name|getTableDir
parameter_list|()
block|{
return|return
name|this
operator|.
name|tableDir
return|;
block|}
comment|/**    * RegionScannerImpl is used to combine scanners from multiple Stores (aka column families).    */
class|class
name|RegionScannerImpl
implements|implements
name|RegionScanner
block|{
comment|// Package local for testability
name|KeyValueHeap
name|storeHeap
init|=
literal|null
decl_stmt|;
comment|/** Heap of key-values that are not essential for the provided filters and are thus read      * on demand, if on-demand column family loading is enabled.*/
name|KeyValueHeap
name|joinedHeap
init|=
literal|null
decl_stmt|;
comment|/**      * If the joined heap data gathering is interrupted due to scan limits, this will      * contain the row for which we are populating the values.*/
specifier|private
name|KeyValue
name|joinedContinuationRow
init|=
literal|null
decl_stmt|;
comment|// KeyValue indicating that limit is reached when scanning
specifier|private
specifier|final
name|KeyValue
name|KV_LIMIT
init|=
operator|new
name|KeyValue
argument_list|()
decl_stmt|;
specifier|private
specifier|final
name|byte
index|[]
name|stopRow
decl_stmt|;
specifier|private
name|Filter
name|filter
decl_stmt|;
specifier|private
name|int
name|batch
decl_stmt|;
specifier|private
name|int
name|isScan
decl_stmt|;
specifier|private
name|boolean
name|filterClosed
init|=
literal|false
decl_stmt|;
specifier|private
name|long
name|readPt
decl_stmt|;
specifier|private
name|long
name|maxResultSize
decl_stmt|;
specifier|private
name|HRegion
name|region
decl_stmt|;
specifier|public
name|HRegionInfo
name|getRegionInfo
parameter_list|()
block|{
return|return
name|regionInfo
return|;
block|}
name|RegionScannerImpl
parameter_list|(
name|Scan
name|scan
parameter_list|,
name|List
argument_list|<
name|KeyValueScanner
argument_list|>
name|additionalScanners
parameter_list|,
name|HRegion
name|region
parameter_list|)
throws|throws
name|IOException
block|{
comment|// DebugPrint.println("HRegionScanner.<init>");
name|this
operator|.
name|region
operator|=
name|region
expr_stmt|;
name|this
operator|.
name|maxResultSize
operator|=
name|scan
operator|.
name|getMaxResultSize
argument_list|()
expr_stmt|;
if|if
condition|(
name|scan
operator|.
name|hasFilter
argument_list|()
condition|)
block|{
name|this
operator|.
name|filter
operator|=
operator|new
name|FilterWrapper
argument_list|(
name|scan
operator|.
name|getFilter
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|this
operator|.
name|filter
operator|=
literal|null
expr_stmt|;
block|}
name|this
operator|.
name|batch
operator|=
name|scan
operator|.
name|getBatch
argument_list|()
expr_stmt|;
if|if
condition|(
name|Bytes
operator|.
name|equals
argument_list|(
name|scan
operator|.
name|getStopRow
argument_list|()
argument_list|,
name|HConstants
operator|.
name|EMPTY_END_ROW
argument_list|)
operator|&&
operator|!
name|scan
operator|.
name|isGetScan
argument_list|()
condition|)
block|{
name|this
operator|.
name|stopRow
operator|=
literal|null
expr_stmt|;
block|}
else|else
block|{
name|this
operator|.
name|stopRow
operator|=
name|scan
operator|.
name|getStopRow
argument_list|()
expr_stmt|;
block|}
comment|// If we are doing a get, we want to be [startRow,endRow] normally
comment|// it is [startRow,endRow) and if startRow=endRow we get nothing.
name|this
operator|.
name|isScan
operator|=
name|scan
operator|.
name|isGetScan
argument_list|()
condition|?
operator|-
literal|1
else|:
literal|0
expr_stmt|;
comment|// synchronize on scannerReadPoints so that nobody calculates
comment|// getSmallestReadPoint, before scannerReadPoints is updated.
name|IsolationLevel
name|isolationLevel
init|=
name|scan
operator|.
name|getIsolationLevel
argument_list|()
decl_stmt|;
synchronized|synchronized
init|(
name|scannerReadPoints
init|)
block|{
if|if
condition|(
name|isolationLevel
operator|==
name|IsolationLevel
operator|.
name|READ_UNCOMMITTED
condition|)
block|{
comment|// This scan can read even uncommitted transactions
name|this
operator|.
name|readPt
operator|=
name|Long
operator|.
name|MAX_VALUE
expr_stmt|;
name|MultiVersionConsistencyControl
operator|.
name|setThreadReadPoint
argument_list|(
name|this
operator|.
name|readPt
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|this
operator|.
name|readPt
operator|=
name|MultiVersionConsistencyControl
operator|.
name|resetThreadReadPoint
argument_list|(
name|mvcc
argument_list|)
expr_stmt|;
block|}
name|scannerReadPoints
operator|.
name|put
argument_list|(
name|this
argument_list|,
name|this
operator|.
name|readPt
argument_list|)
expr_stmt|;
block|}
comment|// Here we separate all scanners into two lists - scanner that provide data required
comment|// by the filter to operate (scanners list) and all others (joinedScanners list).
name|List
argument_list|<
name|KeyValueScanner
argument_list|>
name|scanners
init|=
operator|new
name|ArrayList
argument_list|<
name|KeyValueScanner
argument_list|>
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|KeyValueScanner
argument_list|>
name|joinedScanners
init|=
operator|new
name|ArrayList
argument_list|<
name|KeyValueScanner
argument_list|>
argument_list|()
decl_stmt|;
if|if
condition|(
name|additionalScanners
operator|!=
literal|null
condition|)
block|{
name|scanners
operator|.
name|addAll
argument_list|(
name|additionalScanners
argument_list|)
expr_stmt|;
block|}
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|byte
index|[]
argument_list|,
name|NavigableSet
argument_list|<
name|byte
index|[]
argument_list|>
argument_list|>
name|entry
range|:
name|scan
operator|.
name|getFamilyMap
argument_list|()
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|Store
name|store
init|=
name|stores
operator|.
name|get
argument_list|(
name|entry
operator|.
name|getKey
argument_list|()
argument_list|)
decl_stmt|;
name|KeyValueScanner
name|scanner
init|=
name|store
operator|.
name|getScanner
argument_list|(
name|scan
argument_list|,
name|entry
operator|.
name|getValue
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|this
operator|.
name|filter
operator|==
literal|null
operator|||
operator|!
name|scan
operator|.
name|doLoadColumnFamiliesOnDemand
argument_list|()
operator|||
name|this
operator|.
name|filter
operator|.
name|isFamilyEssential
argument_list|(
name|entry
operator|.
name|getKey
argument_list|()
argument_list|)
condition|)
block|{
name|scanners
operator|.
name|add
argument_list|(
name|scanner
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|joinedScanners
operator|.
name|add
argument_list|(
name|scanner
argument_list|)
expr_stmt|;
block|}
block|}
name|this
operator|.
name|storeHeap
operator|=
operator|new
name|KeyValueHeap
argument_list|(
name|scanners
argument_list|,
name|comparator
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|joinedScanners
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|this
operator|.
name|joinedHeap
operator|=
operator|new
name|KeyValueHeap
argument_list|(
name|joinedScanners
argument_list|,
name|comparator
argument_list|)
expr_stmt|;
block|}
block|}
name|RegionScannerImpl
parameter_list|(
name|Scan
name|scan
parameter_list|,
name|HRegion
name|region
parameter_list|)
throws|throws
name|IOException
block|{
name|this
argument_list|(
name|scan
argument_list|,
literal|null
argument_list|,
name|region
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|getMaxResultSize
parameter_list|()
block|{
return|return
name|maxResultSize
return|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|getMvccReadPoint
parameter_list|()
block|{
return|return
name|this
operator|.
name|readPt
return|;
block|}
comment|/**      * Reset both the filter and the old filter.      */
specifier|protected
name|void
name|resetFilters
parameter_list|()
block|{
if|if
condition|(
name|filter
operator|!=
literal|null
condition|)
block|{
name|filter
operator|.
name|reset
argument_list|()
expr_stmt|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|next
parameter_list|(
name|List
argument_list|<
name|KeyValue
argument_list|>
name|outResults
parameter_list|,
name|int
name|limit
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|next
argument_list|(
name|outResults
argument_list|,
name|limit
argument_list|,
literal|null
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
specifier|synchronized
name|boolean
name|next
parameter_list|(
name|List
argument_list|<
name|KeyValue
argument_list|>
name|outResults
parameter_list|,
name|int
name|limit
parameter_list|,
name|String
name|metric
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|this
operator|.
name|filterClosed
condition|)
block|{
throw|throw
operator|new
name|UnknownScannerException
argument_list|(
literal|"Scanner was closed (timed out?) "
operator|+
literal|"after we renewed it. Could be caused by a very slow scanner "
operator|+
literal|"or a lengthy garbage collection"
argument_list|)
throw|;
block|}
name|startRegionOperation
argument_list|()
expr_stmt|;
name|readRequestsCount
operator|.
name|increment
argument_list|()
expr_stmt|;
try|try
block|{
comment|// This could be a new thread from the last time we called next().
name|MultiVersionConsistencyControl
operator|.
name|setThreadReadPoint
argument_list|(
name|this
operator|.
name|readPt
argument_list|)
expr_stmt|;
return|return
name|nextRaw
argument_list|(
name|outResults
argument_list|,
name|limit
argument_list|,
name|metric
argument_list|)
return|;
block|}
finally|finally
block|{
name|closeRegionOperation
argument_list|()
expr_stmt|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|nextRaw
parameter_list|(
name|List
argument_list|<
name|KeyValue
argument_list|>
name|outResults
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|nextRaw
argument_list|(
name|outResults
argument_list|,
name|batch
argument_list|,
literal|null
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|nextRaw
parameter_list|(
name|List
argument_list|<
name|KeyValue
argument_list|>
name|outResults
parameter_list|,
name|int
name|limit
parameter_list|,
name|String
name|metric
parameter_list|)
throws|throws
name|IOException
block|{
name|boolean
name|returnResult
decl_stmt|;
if|if
condition|(
name|outResults
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
comment|// Usually outResults is empty. This is true when next is called
comment|// to handle scan or get operation.
name|returnResult
operator|=
name|nextInternal
argument_list|(
name|outResults
argument_list|,
name|limit
argument_list|,
name|metric
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|List
argument_list|<
name|KeyValue
argument_list|>
name|tmpList
init|=
operator|new
name|ArrayList
argument_list|<
name|KeyValue
argument_list|>
argument_list|()
decl_stmt|;
name|returnResult
operator|=
name|nextInternal
argument_list|(
name|tmpList
argument_list|,
name|limit
argument_list|,
name|metric
argument_list|)
expr_stmt|;
name|outResults
operator|.
name|addAll
argument_list|(
name|tmpList
argument_list|)
expr_stmt|;
block|}
name|resetFilters
argument_list|()
expr_stmt|;
if|if
condition|(
name|isFilterDone
argument_list|()
condition|)
block|{
return|return
literal|false
return|;
block|}
return|return
name|returnResult
return|;
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|next
parameter_list|(
name|List
argument_list|<
name|KeyValue
argument_list|>
name|outResults
parameter_list|)
throws|throws
name|IOException
block|{
comment|// apply the batching limit by default
return|return
name|next
argument_list|(
name|outResults
argument_list|,
name|batch
argument_list|,
literal|null
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|next
parameter_list|(
name|List
argument_list|<
name|KeyValue
argument_list|>
name|outResults
parameter_list|,
name|String
name|metric
parameter_list|)
throws|throws
name|IOException
block|{
comment|// apply the batching limit by default
return|return
name|next
argument_list|(
name|outResults
argument_list|,
name|batch
argument_list|,
name|metric
argument_list|)
return|;
block|}
specifier|private
name|void
name|populateFromJoinedHeap
parameter_list|(
name|List
argument_list|<
name|KeyValue
argument_list|>
name|results
parameter_list|,
name|int
name|limit
parameter_list|,
name|String
name|metric
parameter_list|)
throws|throws
name|IOException
block|{
assert|assert
name|joinedContinuationRow
operator|!=
literal|null
assert|;
name|KeyValue
name|kv
init|=
name|populateResult
argument_list|(
name|results
argument_list|,
name|this
operator|.
name|joinedHeap
argument_list|,
name|limit
argument_list|,
name|joinedContinuationRow
operator|.
name|getBuffer
argument_list|()
argument_list|,
name|joinedContinuationRow
operator|.
name|getRowOffset
argument_list|()
argument_list|,
name|joinedContinuationRow
operator|.
name|getRowLength
argument_list|()
argument_list|,
name|metric
argument_list|)
decl_stmt|;
if|if
condition|(
name|kv
operator|!=
name|KV_LIMIT
condition|)
block|{
comment|// We are done with this row, reset the continuation.
name|joinedContinuationRow
operator|=
literal|null
expr_stmt|;
block|}
comment|// As the data is obtained from two independent heaps, we need to
comment|// ensure that result list is sorted, because Result relies on that.
name|Collections
operator|.
name|sort
argument_list|(
name|results
argument_list|,
name|comparator
argument_list|)
expr_stmt|;
block|}
comment|/**      * Fetches records with currentRow into results list, until next row or limit (if not -1).      * @param results      * @param heap KeyValueHeap to fetch data from.It must be positioned on correct row before call.      * @param limit Max amount of KVs to place in result list, -1 means no limit.      * @param currentRow Byte array with key we are fetching.      * @param offset offset for currentRow      * @param length length for currentRow      * @param metric Metric key to be passed into KeyValueHeap::next().      * @return KV_LIMIT if limit reached, next KeyValue otherwise.      */
specifier|private
name|KeyValue
name|populateResult
parameter_list|(
name|List
argument_list|<
name|KeyValue
argument_list|>
name|results
parameter_list|,
name|KeyValueHeap
name|heap
parameter_list|,
name|int
name|limit
parameter_list|,
name|byte
index|[]
name|currentRow
parameter_list|,
name|int
name|offset
parameter_list|,
name|short
name|length
parameter_list|,
name|String
name|metric
parameter_list|)
throws|throws
name|IOException
block|{
name|KeyValue
name|nextKv
decl_stmt|;
do|do
block|{
name|heap
operator|.
name|next
argument_list|(
name|results
argument_list|,
name|limit
operator|-
name|results
operator|.
name|size
argument_list|()
argument_list|,
name|metric
argument_list|)
expr_stmt|;
if|if
condition|(
name|limit
operator|>
literal|0
operator|&&
name|results
operator|.
name|size
argument_list|()
operator|==
name|limit
condition|)
block|{
return|return
name|KV_LIMIT
return|;
block|}
name|nextKv
operator|=
name|heap
operator|.
name|peek
argument_list|()
expr_stmt|;
block|}
do|while
condition|(
name|nextKv
operator|!=
literal|null
operator|&&
name|nextKv
operator|.
name|matchingRow
argument_list|(
name|currentRow
argument_list|,
name|offset
argument_list|,
name|length
argument_list|)
condition|)
do|;
return|return
name|nextKv
return|;
block|}
comment|/*      * @return True if a filter rules the scanner is over, done.      */
specifier|public
specifier|synchronized
name|boolean
name|isFilterDone
parameter_list|()
block|{
return|return
name|this
operator|.
name|filter
operator|!=
literal|null
operator|&&
name|this
operator|.
name|filter
operator|.
name|filterAllRemaining
argument_list|()
return|;
block|}
specifier|private
name|boolean
name|nextInternal
parameter_list|(
name|List
argument_list|<
name|KeyValue
argument_list|>
name|results
parameter_list|,
name|int
name|limit
parameter_list|,
name|String
name|metric
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
operator|!
name|results
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"First parameter should be an empty list"
argument_list|)
throw|;
block|}
name|RpcCallContext
name|rpcCall
init|=
name|HBaseServer
operator|.
name|getCurrentCall
argument_list|()
decl_stmt|;
comment|// The loop here is used only when at some point during the next we determine
comment|// that due to effects of filters or otherwise, we have an empty row in the result.
comment|// Then we loop and try again. Otherwise, we must get out on the first iteration via return,
comment|// "true" if there's more data to read, "false" if there isn't (storeHeap is at a stop row,
comment|// and joinedHeap has no more data to read for the last row (if set, joinedContinuationRow).
while|while
condition|(
literal|true
condition|)
block|{
if|if
condition|(
name|rpcCall
operator|!=
literal|null
condition|)
block|{
comment|// If a user specifies a too-restrictive or too-slow scanner, the
comment|// client might time out and disconnect while the server side
comment|// is still processing the request. We should abort aggressively
comment|// in that case.
name|rpcCall
operator|.
name|throwExceptionIfCallerDisconnected
argument_list|()
expr_stmt|;
block|}
comment|// Let's see what we have in the storeHeap.
name|KeyValue
name|current
init|=
name|this
operator|.
name|storeHeap
operator|.
name|peek
argument_list|()
decl_stmt|;
name|byte
index|[]
name|currentRow
init|=
literal|null
decl_stmt|;
name|int
name|offset
init|=
literal|0
decl_stmt|;
name|short
name|length
init|=
literal|0
decl_stmt|;
if|if
condition|(
name|current
operator|!=
literal|null
condition|)
block|{
name|currentRow
operator|=
name|current
operator|.
name|getBuffer
argument_list|()
expr_stmt|;
name|offset
operator|=
name|current
operator|.
name|getRowOffset
argument_list|()
expr_stmt|;
name|length
operator|=
name|current
operator|.
name|getRowLength
argument_list|()
expr_stmt|;
block|}
name|boolean
name|stopRow
init|=
name|isStopRow
argument_list|(
name|currentRow
argument_list|,
name|offset
argument_list|,
name|length
argument_list|)
decl_stmt|;
comment|// Check if we were getting data from the joinedHeap and hit the limit.
comment|// If not, then it's main path - getting results from storeHeap.
if|if
condition|(
name|joinedContinuationRow
operator|==
literal|null
condition|)
block|{
comment|// First, check if we are at a stop row. If so, there are no more results.
if|if
condition|(
name|stopRow
condition|)
block|{
if|if
condition|(
name|filter
operator|!=
literal|null
operator|&&
name|filter
operator|.
name|hasFilterRow
argument_list|()
condition|)
block|{
name|filter
operator|.
name|filterRow
argument_list|(
name|results
argument_list|)
expr_stmt|;
block|}
return|return
literal|false
return|;
block|}
comment|// Check if rowkey filter wants to exclude this row. If so, loop to next.
comment|// Technically, if we hit limits before on this row, we don't need this call.
if|if
condition|(
name|filterRowKey
argument_list|(
name|currentRow
argument_list|,
name|offset
argument_list|,
name|length
argument_list|)
condition|)
block|{
name|boolean
name|moreRows
init|=
name|nextRow
argument_list|(
name|currentRow
argument_list|,
name|offset
argument_list|,
name|length
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|moreRows
condition|)
return|return
literal|false
return|;
name|results
operator|.
name|clear
argument_list|()
expr_stmt|;
continue|continue;
block|}
name|KeyValue
name|nextKv
init|=
name|populateResult
argument_list|(
name|results
argument_list|,
name|this
operator|.
name|storeHeap
argument_list|,
name|limit
argument_list|,
name|currentRow
argument_list|,
name|offset
argument_list|,
name|length
argument_list|,
name|metric
argument_list|)
decl_stmt|;
comment|// Ok, we are good, let's try to get some results from the main heap.
if|if
condition|(
name|nextKv
operator|==
name|KV_LIMIT
condition|)
block|{
if|if
condition|(
name|this
operator|.
name|filter
operator|!=
literal|null
operator|&&
name|filter
operator|.
name|hasFilterRow
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|IncompatibleFilterException
argument_list|(
literal|"Filter whose hasFilterRow() returns true is incompatible with scan with limit!"
argument_list|)
throw|;
block|}
return|return
literal|true
return|;
comment|// We hit the limit.
block|}
name|stopRow
operator|=
name|nextKv
operator|==
literal|null
operator|||
name|isStopRow
argument_list|(
name|nextKv
operator|.
name|getBuffer
argument_list|()
argument_list|,
name|nextKv
operator|.
name|getRowOffset
argument_list|()
argument_list|,
name|nextKv
operator|.
name|getRowLength
argument_list|()
argument_list|)
expr_stmt|;
comment|// save that the row was empty before filters applied to it.
specifier|final
name|boolean
name|isEmptyRow
init|=
name|results
operator|.
name|isEmpty
argument_list|()
decl_stmt|;
comment|// We have the part of the row necessary for filtering (all of it, usually).
comment|// First filter with the filterRow(List).
if|if
condition|(
name|filter
operator|!=
literal|null
operator|&&
name|filter
operator|.
name|hasFilterRow
argument_list|()
condition|)
block|{
name|filter
operator|.
name|filterRow
argument_list|(
name|results
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|isEmptyRow
condition|)
block|{
name|boolean
name|moreRows
init|=
name|nextRow
argument_list|(
name|currentRow
argument_list|,
name|offset
argument_list|,
name|length
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|moreRows
condition|)
return|return
literal|false
return|;
name|results
operator|.
name|clear
argument_list|()
expr_stmt|;
comment|// This row was totally filtered out, if this is NOT the last row,
comment|// we should continue on. Otherwise, nothing else to do.
if|if
condition|(
operator|!
name|stopRow
condition|)
continue|continue;
return|return
literal|false
return|;
block|}
comment|// Ok, we are done with storeHeap for this row.
comment|// Now we may need to fetch additional, non-essential data into row.
comment|// These values are not needed for filter to work, so we postpone their
comment|// fetch to (possibly) reduce amount of data loads from disk.
if|if
condition|(
name|this
operator|.
name|joinedHeap
operator|!=
literal|null
condition|)
block|{
name|KeyValue
name|nextJoinedKv
init|=
name|joinedHeap
operator|.
name|peek
argument_list|()
decl_stmt|;
comment|// If joinedHeap is pointing to some other row, try to seek to a correct one.
comment|// We don't need to recheck that row here - populateResult will take care of that.
name|boolean
name|mayHaveData
init|=
operator|(
name|nextJoinedKv
operator|!=
literal|null
operator|&&
name|nextJoinedKv
operator|.
name|matchingRow
argument_list|(
name|currentRow
argument_list|,
name|offset
argument_list|,
name|length
argument_list|)
operator|)
operator|||
name|this
operator|.
name|joinedHeap
operator|.
name|seek
argument_list|(
name|KeyValue
operator|.
name|createFirstOnRow
argument_list|(
name|currentRow
argument_list|,
name|offset
argument_list|,
name|length
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|mayHaveData
condition|)
block|{
name|joinedContinuationRow
operator|=
name|current
expr_stmt|;
name|populateFromJoinedHeap
argument_list|(
name|results
argument_list|,
name|limit
argument_list|,
name|metric
argument_list|)
expr_stmt|;
block|}
block|}
block|}
else|else
block|{
comment|// Populating from the joined heap was stopped by limits, populate some more.
name|populateFromJoinedHeap
argument_list|(
name|results
argument_list|,
name|limit
argument_list|,
name|metric
argument_list|)
expr_stmt|;
block|}
comment|// We may have just called populateFromJoinedMap and hit the limits. If that is
comment|// the case, we need to call it again on the next next() invocation.
if|if
condition|(
name|joinedContinuationRow
operator|!=
literal|null
condition|)
block|{
return|return
literal|true
return|;
block|}
comment|// Finally, we are done with both joinedHeap and storeHeap.
comment|// Double check to prevent empty rows from appearing in result. It could be
comment|// the case when SingleColumnValueExcludeFilter is used.
if|if
condition|(
name|results
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|boolean
name|moreRows
init|=
name|nextRow
argument_list|(
name|currentRow
argument_list|,
name|offset
argument_list|,
name|length
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|moreRows
condition|)
return|return
literal|false
return|;
if|if
condition|(
operator|!
name|stopRow
condition|)
continue|continue;
block|}
comment|// We are done. Return the result.
return|return
operator|!
name|stopRow
return|;
block|}
block|}
specifier|private
name|boolean
name|filterRowKey
parameter_list|(
name|byte
index|[]
name|row
parameter_list|,
name|int
name|offset
parameter_list|,
name|short
name|length
parameter_list|)
block|{
return|return
name|filter
operator|!=
literal|null
operator|&&
name|filter
operator|.
name|filterRowKey
argument_list|(
name|row
argument_list|,
name|offset
argument_list|,
name|length
argument_list|)
return|;
block|}
specifier|protected
name|boolean
name|nextRow
parameter_list|(
name|byte
index|[]
name|currentRow
parameter_list|,
name|int
name|offset
parameter_list|,
name|short
name|length
parameter_list|)
throws|throws
name|IOException
block|{
assert|assert
name|this
operator|.
name|joinedContinuationRow
operator|==
literal|null
operator|:
literal|"Trying to go to next row during joinedHeap read."
assert|;
name|KeyValue
name|next
decl_stmt|;
while|while
condition|(
operator|(
name|next
operator|=
name|this
operator|.
name|storeHeap
operator|.
name|peek
argument_list|()
operator|)
operator|!=
literal|null
operator|&&
name|next
operator|.
name|matchingRow
argument_list|(
name|currentRow
argument_list|,
name|offset
argument_list|,
name|length
argument_list|)
condition|)
block|{
name|this
operator|.
name|storeHeap
operator|.
name|next
argument_list|(
name|MOCKED_LIST
argument_list|)
expr_stmt|;
block|}
name|resetFilters
argument_list|()
expr_stmt|;
comment|// Calling the hook in CP which allows it to do a fast forward
if|if
condition|(
name|this
operator|.
name|region
operator|.
name|getCoprocessorHost
argument_list|()
operator|!=
literal|null
condition|)
block|{
return|return
name|this
operator|.
name|region
operator|.
name|getCoprocessorHost
argument_list|()
operator|.
name|postScannerFilterRow
argument_list|(
name|this
argument_list|,
name|currentRow
argument_list|)
return|;
block|}
return|return
literal|true
return|;
block|}
specifier|private
name|boolean
name|isStopRow
parameter_list|(
name|byte
index|[]
name|currentRow
parameter_list|,
name|int
name|offset
parameter_list|,
name|short
name|length
parameter_list|)
block|{
return|return
name|currentRow
operator|==
literal|null
operator|||
operator|(
name|stopRow
operator|!=
literal|null
operator|&&
name|comparator
operator|.
name|compareRows
argument_list|(
name|stopRow
argument_list|,
literal|0
argument_list|,
name|stopRow
operator|.
name|length
argument_list|,
name|currentRow
argument_list|,
name|offset
argument_list|,
name|length
argument_list|)
operator|<=
name|isScan
operator|)
return|;
block|}
annotation|@
name|Override
specifier|public
specifier|synchronized
name|void
name|close
parameter_list|()
block|{
if|if
condition|(
name|storeHeap
operator|!=
literal|null
condition|)
block|{
name|storeHeap
operator|.
name|close
argument_list|()
expr_stmt|;
name|storeHeap
operator|=
literal|null
expr_stmt|;
block|}
if|if
condition|(
name|joinedHeap
operator|!=
literal|null
condition|)
block|{
name|joinedHeap
operator|.
name|close
argument_list|()
expr_stmt|;
name|joinedHeap
operator|=
literal|null
expr_stmt|;
block|}
comment|// no need to sychronize here.
name|scannerReadPoints
operator|.
name|remove
argument_list|(
name|this
argument_list|)
expr_stmt|;
name|this
operator|.
name|filterClosed
operator|=
literal|true
expr_stmt|;
block|}
name|KeyValueHeap
name|getStoreHeapForTesting
parameter_list|()
block|{
return|return
name|storeHeap
return|;
block|}
annotation|@
name|Override
specifier|public
specifier|synchronized
name|boolean
name|reseek
parameter_list|(
name|byte
index|[]
name|row
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|row
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"Row cannot be null."
argument_list|)
throw|;
block|}
name|boolean
name|result
init|=
literal|false
decl_stmt|;
name|startRegionOperation
argument_list|()
expr_stmt|;
try|try
block|{
comment|// This could be a new thread from the last time we called next().
name|MultiVersionConsistencyControl
operator|.
name|setThreadReadPoint
argument_list|(
name|this
operator|.
name|readPt
argument_list|)
expr_stmt|;
name|KeyValue
name|kv
init|=
name|KeyValue
operator|.
name|createFirstOnRow
argument_list|(
name|row
argument_list|)
decl_stmt|;
comment|// use request seek to make use of the lazy seek option. See HBASE-5520
name|result
operator|=
name|this
operator|.
name|storeHeap
operator|.
name|requestSeek
argument_list|(
name|kv
argument_list|,
literal|true
argument_list|,
literal|true
argument_list|)
expr_stmt|;
if|if
condition|(
name|this
operator|.
name|joinedHeap
operator|!=
literal|null
condition|)
block|{
name|result
operator|=
name|this
operator|.
name|joinedHeap
operator|.
name|requestSeek
argument_list|(
name|kv
argument_list|,
literal|true
argument_list|,
literal|true
argument_list|)
operator|||
name|result
expr_stmt|;
block|}
block|}
finally|finally
block|{
name|closeRegionOperation
argument_list|()
expr_stmt|;
block|}
return|return
name|result
return|;
block|}
block|}
comment|// Utility methods
comment|/**    * A utility method to create new instances of HRegion based on the    * {@link HConstants#REGION_IMPL} configuration property.    * @param tableDir qualified path of directory where region should be located,    * usually the table directory.    * @param log The HLog is the outbound log for any updates to the HRegion    * (There's a single HLog for all the HRegions on a single HRegionServer.)    * The log file is a logfile from the previous execution that's    * custom-computed for this HRegion. The HRegionServer computes and sorts the    * appropriate log info for this HRegion. If there is a previous log file    * (implying that the HRegion has been written-to before), then read it from    * the supplied path.    * @param fs is the filesystem.    * @param conf is global configuration settings.    * @param regionInfo - HRegionInfo that describes the region    * is new), then read them from the supplied path.    * @param htd    * @param rsServices    * @return the new instance    */
specifier|public
specifier|static
name|HRegion
name|newHRegion
parameter_list|(
name|Path
name|tableDir
parameter_list|,
name|HLog
name|log
parameter_list|,
name|FileSystem
name|fs
parameter_list|,
name|Configuration
name|conf
parameter_list|,
name|HRegionInfo
name|regionInfo
parameter_list|,
specifier|final
name|HTableDescriptor
name|htd
parameter_list|,
name|RegionServerServices
name|rsServices
parameter_list|)
block|{
try|try
block|{
annotation|@
name|SuppressWarnings
argument_list|(
literal|"unchecked"
argument_list|)
name|Class
argument_list|<
name|?
extends|extends
name|HRegion
argument_list|>
name|regionClass
init|=
operator|(
name|Class
argument_list|<
name|?
extends|extends
name|HRegion
argument_list|>
operator|)
name|conf
operator|.
name|getClass
argument_list|(
name|HConstants
operator|.
name|REGION_IMPL
argument_list|,
name|HRegion
operator|.
name|class
argument_list|)
decl_stmt|;
name|Constructor
argument_list|<
name|?
extends|extends
name|HRegion
argument_list|>
name|c
init|=
name|regionClass
operator|.
name|getConstructor
argument_list|(
name|Path
operator|.
name|class
argument_list|,
name|HLog
operator|.
name|class
argument_list|,
name|FileSystem
operator|.
name|class
argument_list|,
name|Configuration
operator|.
name|class
argument_list|,
name|HRegionInfo
operator|.
name|class
argument_list|,
name|HTableDescriptor
operator|.
name|class
argument_list|,
name|RegionServerServices
operator|.
name|class
argument_list|)
decl_stmt|;
return|return
name|c
operator|.
name|newInstance
argument_list|(
name|tableDir
argument_list|,
name|log
argument_list|,
name|fs
argument_list|,
name|conf
argument_list|,
name|regionInfo
argument_list|,
name|htd
argument_list|,
name|rsServices
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|Throwable
name|e
parameter_list|)
block|{
comment|// todo: what should I throw here?
throw|throw
operator|new
name|IllegalStateException
argument_list|(
literal|"Could not instantiate a region instance."
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
comment|/**    * Convenience method creating new HRegions. Used by createTable and by the    * bootstrap code in the HMaster constructor.    * Note, this method creates an {@link HLog} for the created region. It    * needs to be closed explicitly.  Use {@link HRegion#getLog()} to get    * access.<b>When done with a region created using this method, you will    * need to explicitly close the {@link HLog} it created too; it will not be    * done for you.  Not closing the log will leave at least a daemon thread    * running.</b>  Call {@link #closeHRegion(HRegion)} and it will do    * necessary cleanup for you.    * @param info Info for region to create.    * @param rootDir Root directory for HBase instance    * @param conf    * @param hTableDescriptor    * @return new HRegion    *    * @throws IOException    */
specifier|public
specifier|static
name|HRegion
name|createHRegion
parameter_list|(
specifier|final
name|HRegionInfo
name|info
parameter_list|,
specifier|final
name|Path
name|rootDir
parameter_list|,
specifier|final
name|Configuration
name|conf
parameter_list|,
specifier|final
name|HTableDescriptor
name|hTableDescriptor
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|createHRegion
argument_list|(
name|info
argument_list|,
name|rootDir
argument_list|,
name|conf
argument_list|,
name|hTableDescriptor
argument_list|,
literal|null
argument_list|)
return|;
block|}
comment|/**    * This will do the necessary cleanup a call to {@link #createHRegion(HRegionInfo, Path, Configuration, HTableDescriptor)}    * requires.  This method will close the region and then close its    * associated {@link HLog} file.  You use it if you call the other createHRegion,    * the one that takes an {@link HLog} instance but don't be surprised by the    * call to the {@link HLog#closeAndDelete()} on the {@link HLog} the    * HRegion was carrying.    * @param r    * @throws IOException    */
specifier|public
specifier|static
name|void
name|closeHRegion
parameter_list|(
specifier|final
name|HRegion
name|r
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|r
operator|==
literal|null
condition|)
return|return;
name|r
operator|.
name|close
argument_list|()
expr_stmt|;
if|if
condition|(
name|r
operator|.
name|getLog
argument_list|()
operator|==
literal|null
condition|)
return|return;
name|r
operator|.
name|getLog
argument_list|()
operator|.
name|closeAndDelete
argument_list|()
expr_stmt|;
block|}
comment|/**    * Convenience method creating new HRegions. Used by createTable.    * The {@link HLog} for the created region needs to be closed explicitly.    * Use {@link HRegion#getLog()} to get access.    *    * @param info Info for region to create.    * @param rootDir Root directory for HBase instance    * @param conf    * @param hTableDescriptor    * @param hlog shared HLog    * @param initialize - true to initialize the region    * @return new HRegion    *    * @throws IOException    */
specifier|public
specifier|static
name|HRegion
name|createHRegion
parameter_list|(
specifier|final
name|HRegionInfo
name|info
parameter_list|,
specifier|final
name|Path
name|rootDir
parameter_list|,
specifier|final
name|Configuration
name|conf
parameter_list|,
specifier|final
name|HTableDescriptor
name|hTableDescriptor
parameter_list|,
specifier|final
name|HLog
name|hlog
parameter_list|,
specifier|final
name|boolean
name|initialize
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|createHRegion
argument_list|(
name|info
argument_list|,
name|rootDir
argument_list|,
name|conf
argument_list|,
name|hTableDescriptor
argument_list|,
name|hlog
argument_list|,
name|initialize
argument_list|,
literal|false
argument_list|)
return|;
block|}
comment|/**    * Convenience method creating new HRegions. Used by createTable.    * The {@link HLog} for the created region needs to be closed    * explicitly, if it is not null.    * Use {@link HRegion#getLog()} to get access.    *    * @param info Info for region to create.    * @param rootDir Root directory for HBase instance    * @param conf    * @param hTableDescriptor    * @param hlog shared HLog    * @param initialize - true to initialize the region    * @param ignoreHLog - true to skip generate new hlog if it is null, mostly for createTable    * @return new HRegion    * @throws IOException    */
specifier|public
specifier|static
name|HRegion
name|createHRegion
parameter_list|(
specifier|final
name|HRegionInfo
name|info
parameter_list|,
specifier|final
name|Path
name|rootDir
parameter_list|,
specifier|final
name|Configuration
name|conf
parameter_list|,
specifier|final
name|HTableDescriptor
name|hTableDescriptor
parameter_list|,
specifier|final
name|HLog
name|hlog
parameter_list|,
specifier|final
name|boolean
name|initialize
parameter_list|,
specifier|final
name|boolean
name|ignoreHLog
parameter_list|)
throws|throws
name|IOException
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"creating HRegion "
operator|+
name|info
operator|.
name|getTableNameAsString
argument_list|()
operator|+
literal|" HTD == "
operator|+
name|hTableDescriptor
operator|+
literal|" RootDir = "
operator|+
name|rootDir
operator|+
literal|" Table name == "
operator|+
name|info
operator|.
name|getTableNameAsString
argument_list|()
argument_list|)
expr_stmt|;
name|Path
name|tableDir
init|=
name|HTableDescriptor
operator|.
name|getTableDir
argument_list|(
name|rootDir
argument_list|,
name|info
operator|.
name|getTableName
argument_list|()
argument_list|)
decl_stmt|;
name|Path
name|regionDir
init|=
name|HRegion
operator|.
name|getRegionDir
argument_list|(
name|tableDir
argument_list|,
name|info
operator|.
name|getEncodedName
argument_list|()
argument_list|)
decl_stmt|;
name|FileSystem
name|fs
init|=
name|FileSystem
operator|.
name|get
argument_list|(
name|conf
argument_list|)
decl_stmt|;
name|fs
operator|.
name|mkdirs
argument_list|(
name|regionDir
argument_list|)
expr_stmt|;
comment|// Write HRI to a file in case we need to recover .META.
name|writeRegioninfoOnFilesystem
argument_list|(
name|info
argument_list|,
name|regionDir
argument_list|,
name|fs
argument_list|,
name|conf
argument_list|)
expr_stmt|;
name|HLog
name|effectiveHLog
init|=
name|hlog
decl_stmt|;
if|if
condition|(
name|hlog
operator|==
literal|null
operator|&&
operator|!
name|ignoreHLog
condition|)
block|{
name|effectiveHLog
operator|=
name|HLogFactory
operator|.
name|createHLog
argument_list|(
name|fs
argument_list|,
name|regionDir
argument_list|,
name|HConstants
operator|.
name|HREGION_LOGDIR_NAME
argument_list|,
name|conf
argument_list|)
expr_stmt|;
block|}
name|HRegion
name|region
init|=
name|HRegion
operator|.
name|newHRegion
argument_list|(
name|tableDir
argument_list|,
name|effectiveHLog
argument_list|,
name|fs
argument_list|,
name|conf
argument_list|,
name|info
argument_list|,
name|hTableDescriptor
argument_list|,
literal|null
argument_list|)
decl_stmt|;
if|if
condition|(
name|initialize
condition|)
block|{
name|region
operator|.
name|initialize
argument_list|()
expr_stmt|;
block|}
return|return
name|region
return|;
block|}
specifier|public
specifier|static
name|HRegion
name|createHRegion
parameter_list|(
specifier|final
name|HRegionInfo
name|info
parameter_list|,
specifier|final
name|Path
name|rootDir
parameter_list|,
specifier|final
name|Configuration
name|conf
parameter_list|,
specifier|final
name|HTableDescriptor
name|hTableDescriptor
parameter_list|,
specifier|final
name|HLog
name|hlog
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|createHRegion
argument_list|(
name|info
argument_list|,
name|rootDir
argument_list|,
name|conf
argument_list|,
name|hTableDescriptor
argument_list|,
name|hlog
argument_list|,
literal|true
argument_list|)
return|;
block|}
comment|/**    * Open a Region.    * @param info Info for region to be opened.    * @param wal HLog for region to use. This method will call    * HLog#setSequenceNumber(long) passing the result of the call to    * HRegion#getMinSequenceId() to ensure the log id is properly kept    * up.  HRegionStore does this every time it opens a new region.    * @param conf    * @return new HRegion    *    * @throws IOException    */
specifier|public
specifier|static
name|HRegion
name|openHRegion
parameter_list|(
specifier|final
name|HRegionInfo
name|info
parameter_list|,
specifier|final
name|HTableDescriptor
name|htd
parameter_list|,
specifier|final
name|HLog
name|wal
parameter_list|,
specifier|final
name|Configuration
name|conf
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|openHRegion
argument_list|(
name|info
argument_list|,
name|htd
argument_list|,
name|wal
argument_list|,
name|conf
argument_list|,
literal|null
argument_list|,
literal|null
argument_list|)
return|;
block|}
comment|/**    * Open a Region.    * @param info Info for region to be opened    * @param htd    * @param wal HLog for region to use. This method will call    * HLog#setSequenceNumber(long) passing the result of the call to    * HRegion#getMinSequenceId() to ensure the log id is properly kept    * up.  HRegionStore does this every time it opens a new region.    * @param conf    * @param rsServices An interface we can request flushes against.    * @param reporter An interface we can report progress against.    * @return new HRegion    *    * @throws IOException    */
specifier|public
specifier|static
name|HRegion
name|openHRegion
parameter_list|(
specifier|final
name|HRegionInfo
name|info
parameter_list|,
specifier|final
name|HTableDescriptor
name|htd
parameter_list|,
specifier|final
name|HLog
name|wal
parameter_list|,
specifier|final
name|Configuration
name|conf
parameter_list|,
specifier|final
name|RegionServerServices
name|rsServices
parameter_list|,
specifier|final
name|CancelableProgressable
name|reporter
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Opening region: "
operator|+
name|info
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|info
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|NullPointerException
argument_list|(
literal|"Passed region info is null"
argument_list|)
throw|;
block|}
name|Path
name|dir
init|=
name|HTableDescriptor
operator|.
name|getTableDir
argument_list|(
name|FSUtils
operator|.
name|getRootDir
argument_list|(
name|conf
argument_list|)
argument_list|,
name|info
operator|.
name|getTableName
argument_list|()
argument_list|)
decl_stmt|;
name|FileSystem
name|fs
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|rsServices
operator|!=
literal|null
condition|)
block|{
name|fs
operator|=
name|rsServices
operator|.
name|getFileSystem
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|fs
operator|==
literal|null
condition|)
block|{
name|fs
operator|=
name|FileSystem
operator|.
name|get
argument_list|(
name|conf
argument_list|)
expr_stmt|;
block|}
name|HRegion
name|r
init|=
name|HRegion
operator|.
name|newHRegion
argument_list|(
name|dir
argument_list|,
name|wal
argument_list|,
name|fs
argument_list|,
name|conf
argument_list|,
name|info
argument_list|,
name|htd
argument_list|,
name|rsServices
argument_list|)
decl_stmt|;
return|return
name|r
operator|.
name|openHRegion
argument_list|(
name|reporter
argument_list|)
return|;
block|}
specifier|public
specifier|static
name|HRegion
name|openHRegion
parameter_list|(
name|Path
name|rootDir
parameter_list|,
specifier|final
name|HRegionInfo
name|info
parameter_list|,
specifier|final
name|HTableDescriptor
name|htd
parameter_list|,
specifier|final
name|HLog
name|wal
parameter_list|,
specifier|final
name|Configuration
name|conf
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|openHRegion
argument_list|(
name|rootDir
argument_list|,
name|info
argument_list|,
name|htd
argument_list|,
name|wal
argument_list|,
name|conf
argument_list|,
literal|null
argument_list|,
literal|null
argument_list|)
return|;
block|}
comment|/**    * Open a Region.    * @param rootDir Root directory for HBase instance    * @param info Info for region to be opened.    * @param wal HLog for region to use. This method will call    * HLog#setSequenceNumber(long) passing the result of the call to    * HRegion#getMinSequenceId() to ensure the log id is properly kept    * up.  HRegionStore does this every time it opens a new region.    * @param conf    * @param reporter An interface we can report progress against.    * @return new HRegion    *    * @throws IOException    */
specifier|public
specifier|static
name|HRegion
name|openHRegion
parameter_list|(
specifier|final
name|Path
name|rootDir
parameter_list|,
specifier|final
name|HRegionInfo
name|info
parameter_list|,
specifier|final
name|HTableDescriptor
name|htd
parameter_list|,
specifier|final
name|HLog
name|wal
parameter_list|,
specifier|final
name|Configuration
name|conf
parameter_list|,
specifier|final
name|RegionServerServices
name|rsServices
parameter_list|,
specifier|final
name|CancelableProgressable
name|reporter
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|info
operator|==
literal|null
condition|)
throw|throw
operator|new
name|NullPointerException
argument_list|(
literal|"Passed region info is null"
argument_list|)
throw|;
name|LOG
operator|.
name|info
argument_list|(
literal|"HRegion.openHRegion Region name =="
operator|+
name|info
operator|.
name|getRegionNameAsString
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Opening region: "
operator|+
name|info
argument_list|)
expr_stmt|;
block|}
name|Path
name|dir
init|=
name|HTableDescriptor
operator|.
name|getTableDir
argument_list|(
name|rootDir
argument_list|,
name|info
operator|.
name|getTableName
argument_list|()
argument_list|)
decl_stmt|;
name|HRegion
name|r
init|=
name|HRegion
operator|.
name|newHRegion
argument_list|(
name|dir
argument_list|,
name|wal
argument_list|,
name|FileSystem
operator|.
name|get
argument_list|(
name|conf
argument_list|)
argument_list|,
name|conf
argument_list|,
name|info
argument_list|,
name|htd
argument_list|,
name|rsServices
argument_list|)
decl_stmt|;
return|return
name|r
operator|.
name|openHRegion
argument_list|(
name|reporter
argument_list|)
return|;
block|}
comment|/**    * Open HRegion.    * Calls initialize and sets sequenceid.    * @param reporter    * @return Returns<code>this</code>    * @throws IOException    */
specifier|protected
name|HRegion
name|openHRegion
parameter_list|(
specifier|final
name|CancelableProgressable
name|reporter
parameter_list|)
throws|throws
name|IOException
block|{
name|checkCompressionCodecs
argument_list|()
expr_stmt|;
name|this
operator|.
name|openSeqNum
operator|=
name|initialize
argument_list|(
name|reporter
argument_list|)
expr_stmt|;
if|if
condition|(
name|this
operator|.
name|log
operator|!=
literal|null
condition|)
block|{
name|this
operator|.
name|log
operator|.
name|setSequenceNumber
argument_list|(
name|this
operator|.
name|openSeqNum
argument_list|)
expr_stmt|;
block|}
return|return
name|this
return|;
block|}
specifier|private
name|void
name|checkCompressionCodecs
parameter_list|()
throws|throws
name|IOException
block|{
for|for
control|(
name|HColumnDescriptor
name|fam
range|:
name|this
operator|.
name|htableDescriptor
operator|.
name|getColumnFamilies
argument_list|()
control|)
block|{
name|CompressionTest
operator|.
name|testCompression
argument_list|(
name|fam
operator|.
name|getCompression
argument_list|()
argument_list|)
expr_stmt|;
name|CompressionTest
operator|.
name|testCompression
argument_list|(
name|fam
operator|.
name|getCompactionCompression
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Inserts a new region's meta information into the passed    *<code>meta</code> region. Used by the HMaster bootstrap code adding    * new table to ROOT table.    *    * @param meta META HRegion to be updated    * @param r HRegion to add to<code>meta</code>    *    * @throws IOException    */
specifier|public
specifier|static
name|void
name|addRegionToMETA
parameter_list|(
name|HRegion
name|meta
parameter_list|,
name|HRegion
name|r
parameter_list|)
throws|throws
name|IOException
block|{
name|meta
operator|.
name|checkResources
argument_list|()
expr_stmt|;
comment|// The row key is the region name
name|byte
index|[]
name|row
init|=
name|r
operator|.
name|getRegionName
argument_list|()
decl_stmt|;
specifier|final
name|long
name|now
init|=
name|EnvironmentEdgeManager
operator|.
name|currentTimeMillis
argument_list|()
decl_stmt|;
specifier|final
name|List
argument_list|<
name|KeyValue
argument_list|>
name|edits
init|=
operator|new
name|ArrayList
argument_list|<
name|KeyValue
argument_list|>
argument_list|(
literal|2
argument_list|)
decl_stmt|;
name|edits
operator|.
name|add
argument_list|(
operator|new
name|KeyValue
argument_list|(
name|row
argument_list|,
name|HConstants
operator|.
name|CATALOG_FAMILY
argument_list|,
name|HConstants
operator|.
name|REGIONINFO_QUALIFIER
argument_list|,
name|now
argument_list|,
name|r
operator|.
name|getRegionInfo
argument_list|()
operator|.
name|toByteArray
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
comment|// Set into the root table the version of the meta table.
name|edits
operator|.
name|add
argument_list|(
operator|new
name|KeyValue
argument_list|(
name|row
argument_list|,
name|HConstants
operator|.
name|CATALOG_FAMILY
argument_list|,
name|HConstants
operator|.
name|META_VERSION_QUALIFIER
argument_list|,
name|now
argument_list|,
name|Bytes
operator|.
name|toBytes
argument_list|(
name|HConstants
operator|.
name|META_VERSION
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
name|meta
operator|.
name|put
argument_list|(
name|row
argument_list|,
name|HConstants
operator|.
name|CATALOG_FAMILY
argument_list|,
name|edits
argument_list|)
expr_stmt|;
block|}
comment|/**    * Deletes all the files for a HRegion    *    * @param fs the file system object    * @param rootdir qualified path of HBase root directory    * @param info HRegionInfo for region to be deleted    * @throws IOException    */
specifier|public
specifier|static
name|void
name|deleteRegion
parameter_list|(
name|FileSystem
name|fs
parameter_list|,
name|Path
name|rootdir
parameter_list|,
name|HRegionInfo
name|info
parameter_list|)
throws|throws
name|IOException
block|{
name|deleteRegion
argument_list|(
name|fs
argument_list|,
name|HRegion
operator|.
name|getRegionDir
argument_list|(
name|rootdir
argument_list|,
name|info
argument_list|)
argument_list|)
expr_stmt|;
block|}
specifier|private
specifier|static
name|void
name|deleteRegion
parameter_list|(
name|FileSystem
name|fs
parameter_list|,
name|Path
name|regiondir
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"DELETING region "
operator|+
name|regiondir
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|!
name|fs
operator|.
name|delete
argument_list|(
name|regiondir
argument_list|,
literal|true
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failed delete of "
operator|+
name|regiondir
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Computes the Path of the HRegion    *    * @param rootdir qualified path of HBase root directory    * @param info HRegionInfo for the region    * @return qualified path of region directory    */
specifier|public
specifier|static
name|Path
name|getRegionDir
parameter_list|(
specifier|final
name|Path
name|rootdir
parameter_list|,
specifier|final
name|HRegionInfo
name|info
parameter_list|)
block|{
return|return
operator|new
name|Path
argument_list|(
name|HTableDescriptor
operator|.
name|getTableDir
argument_list|(
name|rootdir
argument_list|,
name|info
operator|.
name|getTableName
argument_list|()
argument_list|)
argument_list|,
name|info
operator|.
name|getEncodedName
argument_list|()
argument_list|)
return|;
block|}
comment|/**    * Determines if the specified row is within the row range specified by the    * specified HRegionInfo    *    * @param info HRegionInfo that specifies the row range    * @param row row to be checked    * @return true if the row is within the range specified by the HRegionInfo    */
specifier|public
specifier|static
name|boolean
name|rowIsInRange
parameter_list|(
name|HRegionInfo
name|info
parameter_list|,
specifier|final
name|byte
index|[]
name|row
parameter_list|)
block|{
return|return
operator|(
operator|(
name|info
operator|.
name|getStartKey
argument_list|()
operator|.
name|length
operator|==
literal|0
operator|)
operator|||
operator|(
name|Bytes
operator|.
name|compareTo
argument_list|(
name|info
operator|.
name|getStartKey
argument_list|()
argument_list|,
name|row
argument_list|)
operator|<=
literal|0
operator|)
operator|)
operator|&&
operator|(
operator|(
name|info
operator|.
name|getEndKey
argument_list|()
operator|.
name|length
operator|==
literal|0
operator|)
operator|||
operator|(
name|Bytes
operator|.
name|compareTo
argument_list|(
name|info
operator|.
name|getEndKey
argument_list|()
argument_list|,
name|row
argument_list|)
operator|>
literal|0
operator|)
operator|)
return|;
block|}
comment|/**    * Make the directories for a specific column family    *    * @param fs the file system    * @param tabledir base directory where region will live (usually the table dir)    * @param hri    * @param colFamily the column family    * @throws IOException    */
specifier|public
specifier|static
name|void
name|makeColumnFamilyDirs
parameter_list|(
name|FileSystem
name|fs
parameter_list|,
name|Path
name|tabledir
parameter_list|,
specifier|final
name|HRegionInfo
name|hri
parameter_list|,
name|byte
index|[]
name|colFamily
parameter_list|)
throws|throws
name|IOException
block|{
name|Path
name|dir
init|=
name|HStore
operator|.
name|getStoreHomedir
argument_list|(
name|tabledir
argument_list|,
name|hri
operator|.
name|getEncodedName
argument_list|()
argument_list|,
name|colFamily
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|fs
operator|.
name|mkdirs
argument_list|(
name|dir
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failed to create "
operator|+
name|dir
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Merge two HRegions.  The regions must be adjacent and must not overlap.    *    * @param srcA    * @param srcB    * @return new merged HRegion    * @throws IOException    */
specifier|public
specifier|static
name|HRegion
name|mergeAdjacent
parameter_list|(
specifier|final
name|HRegion
name|srcA
parameter_list|,
specifier|final
name|HRegion
name|srcB
parameter_list|)
throws|throws
name|IOException
block|{
name|HRegion
name|a
init|=
name|srcA
decl_stmt|;
name|HRegion
name|b
init|=
name|srcB
decl_stmt|;
comment|// Make sure that srcA comes first; important for key-ordering during
comment|// write of the merged file.
if|if
condition|(
name|srcA
operator|.
name|getStartKey
argument_list|()
operator|==
literal|null
condition|)
block|{
if|if
condition|(
name|srcB
operator|.
name|getStartKey
argument_list|()
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Cannot merge two regions with null start key"
argument_list|)
throw|;
block|}
comment|// A's start key is null but B's isn't. Assume A comes before B
block|}
elseif|else
if|if
condition|(
operator|(
name|srcB
operator|.
name|getStartKey
argument_list|()
operator|==
literal|null
operator|)
operator|||
operator|(
name|Bytes
operator|.
name|compareTo
argument_list|(
name|srcA
operator|.
name|getStartKey
argument_list|()
argument_list|,
name|srcB
operator|.
name|getStartKey
argument_list|()
argument_list|)
operator|>
literal|0
operator|)
condition|)
block|{
name|a
operator|=
name|srcB
expr_stmt|;
name|b
operator|=
name|srcA
expr_stmt|;
block|}
if|if
condition|(
operator|!
operator|(
name|Bytes
operator|.
name|compareTo
argument_list|(
name|a
operator|.
name|getEndKey
argument_list|()
argument_list|,
name|b
operator|.
name|getStartKey
argument_list|()
argument_list|)
operator|==
literal|0
operator|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Cannot merge non-adjacent regions"
argument_list|)
throw|;
block|}
return|return
name|merge
argument_list|(
name|a
argument_list|,
name|b
argument_list|)
return|;
block|}
comment|/**    * Merge two regions whether they are adjacent or not.    *    * @param a region a    * @param b region b    * @return new merged region    * @throws IOException    */
specifier|public
specifier|static
name|HRegion
name|merge
parameter_list|(
name|HRegion
name|a
parameter_list|,
name|HRegion
name|b
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
operator|!
name|a
operator|.
name|getRegionInfo
argument_list|()
operator|.
name|getTableNameAsString
argument_list|()
operator|.
name|equals
argument_list|(
name|b
operator|.
name|getRegionInfo
argument_list|()
operator|.
name|getTableNameAsString
argument_list|()
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Regions do not belong to the same table"
argument_list|)
throw|;
block|}
name|FileSystem
name|fs
init|=
name|a
operator|.
name|getFilesystem
argument_list|()
decl_stmt|;
comment|// Make sure each region's cache is empty
name|a
operator|.
name|flushcache
argument_list|()
expr_stmt|;
name|b
operator|.
name|flushcache
argument_list|()
expr_stmt|;
comment|// Compact each region so we only have one store file per family
name|a
operator|.
name|compactStores
argument_list|(
literal|true
argument_list|)
expr_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Files for region: "
operator|+
name|a
argument_list|)
expr_stmt|;
name|FSUtils
operator|.
name|logFileSystemState
argument_list|(
name|fs
argument_list|,
name|a
operator|.
name|getRegionDir
argument_list|()
argument_list|,
name|LOG
argument_list|)
expr_stmt|;
block|}
name|b
operator|.
name|compactStores
argument_list|(
literal|true
argument_list|)
expr_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Files for region: "
operator|+
name|b
argument_list|)
expr_stmt|;
name|FSUtils
operator|.
name|logFileSystemState
argument_list|(
name|fs
argument_list|,
name|b
operator|.
name|getRegionDir
argument_list|()
argument_list|,
name|LOG
argument_list|)
expr_stmt|;
block|}
name|Configuration
name|conf
init|=
name|a
operator|.
name|baseConf
decl_stmt|;
name|HTableDescriptor
name|tabledesc
init|=
name|a
operator|.
name|getTableDesc
argument_list|()
decl_stmt|;
name|HLog
name|log
init|=
name|a
operator|.
name|getLog
argument_list|()
decl_stmt|;
name|Path
name|tableDir
init|=
name|a
operator|.
name|getTableDir
argument_list|()
decl_stmt|;
comment|// Presume both are of same region type -- i.e. both user or catalog
comment|// table regions.  This way can use comparator.
specifier|final
name|byte
index|[]
name|startKey
init|=
operator|(
name|a
operator|.
name|comparator
operator|.
name|matchingRows
argument_list|(
name|a
operator|.
name|getStartKey
argument_list|()
argument_list|,
literal|0
argument_list|,
name|a
operator|.
name|getStartKey
argument_list|()
operator|.
name|length
argument_list|,
name|HConstants
operator|.
name|EMPTY_BYTE_ARRAY
argument_list|,
literal|0
argument_list|,
name|HConstants
operator|.
name|EMPTY_BYTE_ARRAY
operator|.
name|length
argument_list|)
operator|||
name|b
operator|.
name|comparator
operator|.
name|matchingRows
argument_list|(
name|b
operator|.
name|getStartKey
argument_list|()
argument_list|,
literal|0
argument_list|,
name|b
operator|.
name|getStartKey
argument_list|()
operator|.
name|length
argument_list|,
name|HConstants
operator|.
name|EMPTY_BYTE_ARRAY
argument_list|,
literal|0
argument_list|,
name|HConstants
operator|.
name|EMPTY_BYTE_ARRAY
operator|.
name|length
argument_list|)
operator|)
condition|?
name|HConstants
operator|.
name|EMPTY_BYTE_ARRAY
else|:
operator|(
name|a
operator|.
name|comparator
operator|.
name|compareRows
argument_list|(
name|a
operator|.
name|getStartKey
argument_list|()
argument_list|,
literal|0
argument_list|,
name|a
operator|.
name|getStartKey
argument_list|()
operator|.
name|length
argument_list|,
name|b
operator|.
name|getStartKey
argument_list|()
argument_list|,
literal|0
argument_list|,
name|b
operator|.
name|getStartKey
argument_list|()
operator|.
name|length
argument_list|)
operator|<=
literal|0
condition|?
name|a
operator|.
name|getStartKey
argument_list|()
else|:
name|b
operator|.
name|getStartKey
argument_list|()
operator|)
decl_stmt|;
specifier|final
name|byte
index|[]
name|endKey
init|=
operator|(
name|a
operator|.
name|comparator
operator|.
name|matchingRows
argument_list|(
name|a
operator|.
name|getEndKey
argument_list|()
argument_list|,
literal|0
argument_list|,
name|a
operator|.
name|getEndKey
argument_list|()
operator|.
name|length
argument_list|,
name|HConstants
operator|.
name|EMPTY_BYTE_ARRAY
argument_list|,
literal|0
argument_list|,
name|HConstants
operator|.
name|EMPTY_BYTE_ARRAY
operator|.
name|length
argument_list|)
operator|||
name|a
operator|.
name|comparator
operator|.
name|matchingRows
argument_list|(
name|b
operator|.
name|getEndKey
argument_list|()
argument_list|,
literal|0
argument_list|,
name|b
operator|.
name|getEndKey
argument_list|()
operator|.
name|length
argument_list|,
name|HConstants
operator|.
name|EMPTY_BYTE_ARRAY
argument_list|,
literal|0
argument_list|,
name|HConstants
operator|.
name|EMPTY_BYTE_ARRAY
operator|.
name|length
argument_list|)
operator|)
condition|?
name|HConstants
operator|.
name|EMPTY_BYTE_ARRAY
else|:
operator|(
name|a
operator|.
name|comparator
operator|.
name|compareRows
argument_list|(
name|a
operator|.
name|getEndKey
argument_list|()
argument_list|,
literal|0
argument_list|,
name|a
operator|.
name|getEndKey
argument_list|()
operator|.
name|length
argument_list|,
name|b
operator|.
name|getEndKey
argument_list|()
argument_list|,
literal|0
argument_list|,
name|b
operator|.
name|getEndKey
argument_list|()
operator|.
name|length
argument_list|)
operator|<=
literal|0
condition|?
name|b
operator|.
name|getEndKey
argument_list|()
else|:
name|a
operator|.
name|getEndKey
argument_list|()
operator|)
decl_stmt|;
name|HRegionInfo
name|newRegionInfo
init|=
operator|new
name|HRegionInfo
argument_list|(
name|tabledesc
operator|.
name|getName
argument_list|()
argument_list|,
name|startKey
argument_list|,
name|endKey
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Creating new region "
operator|+
name|newRegionInfo
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
name|String
name|encodedName
init|=
name|newRegionInfo
operator|.
name|getEncodedName
argument_list|()
decl_stmt|;
name|Path
name|newRegionDir
init|=
name|HRegion
operator|.
name|getRegionDir
argument_list|(
name|a
operator|.
name|getTableDir
argument_list|()
argument_list|,
name|encodedName
argument_list|)
decl_stmt|;
if|if
condition|(
name|fs
operator|.
name|exists
argument_list|(
name|newRegionDir
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Cannot merge; target file collision at "
operator|+
name|newRegionDir
argument_list|)
throw|;
block|}
name|fs
operator|.
name|mkdirs
argument_list|(
name|newRegionDir
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"starting merge of regions: "
operator|+
name|a
operator|+
literal|" and "
operator|+
name|b
operator|+
literal|" into new region "
operator|+
name|newRegionInfo
operator|.
name|toString
argument_list|()
operator|+
literal|" with start key<"
operator|+
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|startKey
argument_list|)
operator|+
literal|"> and end key<"
operator|+
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|endKey
argument_list|)
operator|+
literal|">"
argument_list|)
expr_stmt|;
comment|// Move HStoreFiles under new region directory
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|List
argument_list|<
name|StoreFile
argument_list|>
argument_list|>
name|byFamily
init|=
operator|new
name|TreeMap
argument_list|<
name|byte
index|[]
argument_list|,
name|List
argument_list|<
name|StoreFile
argument_list|>
argument_list|>
argument_list|(
name|Bytes
operator|.
name|BYTES_COMPARATOR
argument_list|)
decl_stmt|;
name|byFamily
operator|=
name|filesByFamily
argument_list|(
name|byFamily
argument_list|,
name|a
operator|.
name|close
argument_list|()
argument_list|)
expr_stmt|;
name|byFamily
operator|=
name|filesByFamily
argument_list|(
name|byFamily
argument_list|,
name|b
operator|.
name|close
argument_list|()
argument_list|)
expr_stmt|;
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|byte
index|[]
argument_list|,
name|List
argument_list|<
name|StoreFile
argument_list|>
argument_list|>
name|es
range|:
name|byFamily
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|byte
index|[]
name|colFamily
init|=
name|es
operator|.
name|getKey
argument_list|()
decl_stmt|;
name|makeColumnFamilyDirs
argument_list|(
name|fs
argument_list|,
name|tableDir
argument_list|,
name|newRegionInfo
argument_list|,
name|colFamily
argument_list|)
expr_stmt|;
comment|// Because we compacted the source regions we should have no more than two
comment|// HStoreFiles per family and there will be no reference store
name|List
argument_list|<
name|StoreFile
argument_list|>
name|srcFiles
init|=
name|es
operator|.
name|getValue
argument_list|()
decl_stmt|;
for|for
control|(
name|StoreFile
name|hsf
range|:
name|srcFiles
control|)
block|{
name|StoreFile
operator|.
name|rename
argument_list|(
name|fs
argument_list|,
name|hsf
operator|.
name|getPath
argument_list|()
argument_list|,
name|StoreFile
operator|.
name|getUniqueFile
argument_list|(
name|fs
argument_list|,
name|HStore
operator|.
name|getStoreHomedir
argument_list|(
name|tableDir
argument_list|,
name|newRegionInfo
operator|.
name|getEncodedName
argument_list|()
argument_list|,
name|colFamily
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Files for new region"
argument_list|)
expr_stmt|;
name|FSUtils
operator|.
name|logFileSystemState
argument_list|(
name|fs
argument_list|,
name|newRegionDir
argument_list|,
name|LOG
argument_list|)
expr_stmt|;
block|}
name|HRegion
name|dstRegion
init|=
name|HRegion
operator|.
name|newHRegion
argument_list|(
name|tableDir
argument_list|,
name|log
argument_list|,
name|fs
argument_list|,
name|conf
argument_list|,
name|newRegionInfo
argument_list|,
name|a
operator|.
name|getTableDesc
argument_list|()
argument_list|,
literal|null
argument_list|)
decl_stmt|;
name|dstRegion
operator|.
name|readRequestsCount
operator|.
name|set
argument_list|(
name|a
operator|.
name|readRequestsCount
operator|.
name|get
argument_list|()
operator|+
name|b
operator|.
name|readRequestsCount
operator|.
name|get
argument_list|()
argument_list|)
expr_stmt|;
name|dstRegion
operator|.
name|writeRequestsCount
operator|.
name|set
argument_list|(
name|a
operator|.
name|writeRequestsCount
operator|.
name|get
argument_list|()
operator|+
name|b
operator|.
name|writeRequestsCount
operator|.
name|get
argument_list|()
argument_list|)
expr_stmt|;
name|dstRegion
operator|.
name|checkAndMutateChecksFailed
operator|.
name|set
argument_list|(
name|a
operator|.
name|checkAndMutateChecksFailed
operator|.
name|get
argument_list|()
operator|+
name|b
operator|.
name|checkAndMutateChecksFailed
operator|.
name|get
argument_list|()
argument_list|)
expr_stmt|;
name|dstRegion
operator|.
name|checkAndMutateChecksPassed
operator|.
name|set
argument_list|(
name|a
operator|.
name|checkAndMutateChecksPassed
operator|.
name|get
argument_list|()
operator|+
name|b
operator|.
name|checkAndMutateChecksPassed
operator|.
name|get
argument_list|()
argument_list|)
expr_stmt|;
name|dstRegion
operator|.
name|initialize
argument_list|()
expr_stmt|;
name|dstRegion
operator|.
name|compactStores
argument_list|()
expr_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Files for new region"
argument_list|)
expr_stmt|;
name|FSUtils
operator|.
name|logFileSystemState
argument_list|(
name|fs
argument_list|,
name|dstRegion
operator|.
name|getRegionDir
argument_list|()
argument_list|,
name|LOG
argument_list|)
expr_stmt|;
block|}
comment|// delete out the 'A' region
name|HFileArchiver
operator|.
name|archiveRegion
argument_list|(
name|a
operator|.
name|getBaseConf
argument_list|()
argument_list|,
name|fs
argument_list|,
name|FSUtils
operator|.
name|getRootDir
argument_list|(
name|a
operator|.
name|getBaseConf
argument_list|()
argument_list|)
argument_list|,
name|a
operator|.
name|getTableDir
argument_list|()
argument_list|,
name|a
operator|.
name|getRegionDir
argument_list|()
argument_list|)
expr_stmt|;
comment|// delete out the 'B' region
name|HFileArchiver
operator|.
name|archiveRegion
argument_list|(
name|a
operator|.
name|getBaseConf
argument_list|()
argument_list|,
name|fs
argument_list|,
name|FSUtils
operator|.
name|getRootDir
argument_list|(
name|b
operator|.
name|getBaseConf
argument_list|()
argument_list|)
argument_list|,
name|b
operator|.
name|getTableDir
argument_list|()
argument_list|,
name|b
operator|.
name|getRegionDir
argument_list|()
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"merge completed. New region is "
operator|+
name|dstRegion
argument_list|)
expr_stmt|;
return|return
name|dstRegion
return|;
block|}
comment|/*    * Fills a map with a vector of store files keyed by column family.    * @param byFamily Map to fill.    * @param storeFiles Store files to process.    * @param family    * @return Returns<code>byFamily</code>    */
specifier|private
specifier|static
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|List
argument_list|<
name|StoreFile
argument_list|>
argument_list|>
name|filesByFamily
parameter_list|(
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|List
argument_list|<
name|StoreFile
argument_list|>
argument_list|>
name|byFamily
parameter_list|,
name|List
argument_list|<
name|StoreFile
argument_list|>
name|storeFiles
parameter_list|)
block|{
for|for
control|(
name|StoreFile
name|src
range|:
name|storeFiles
control|)
block|{
name|byte
index|[]
name|family
init|=
name|src
operator|.
name|getFamily
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|StoreFile
argument_list|>
name|v
init|=
name|byFamily
operator|.
name|get
argument_list|(
name|family
argument_list|)
decl_stmt|;
if|if
condition|(
name|v
operator|==
literal|null
condition|)
block|{
name|v
operator|=
operator|new
name|ArrayList
argument_list|<
name|StoreFile
argument_list|>
argument_list|()
expr_stmt|;
name|byFamily
operator|.
name|put
argument_list|(
name|family
argument_list|,
name|v
argument_list|)
expr_stmt|;
block|}
name|v
operator|.
name|add
argument_list|(
name|src
argument_list|)
expr_stmt|;
block|}
return|return
name|byFamily
return|;
block|}
comment|/**    * @return True if needs a major compaction.    * @throws IOException    */
name|boolean
name|isMajorCompaction
parameter_list|()
throws|throws
name|IOException
block|{
for|for
control|(
name|Store
name|store
range|:
name|this
operator|.
name|stores
operator|.
name|values
argument_list|()
control|)
block|{
if|if
condition|(
name|store
operator|.
name|isMajorCompaction
argument_list|()
condition|)
block|{
return|return
literal|true
return|;
block|}
block|}
return|return
literal|false
return|;
block|}
comment|//
comment|// HBASE-880
comment|//
comment|/**    * @param get get object    * @return result    * @throws IOException read exceptions    */
specifier|public
name|Result
name|get
parameter_list|(
specifier|final
name|Get
name|get
parameter_list|)
throws|throws
name|IOException
block|{
name|checkRow
argument_list|(
name|get
operator|.
name|getRow
argument_list|()
argument_list|,
literal|"Get"
argument_list|)
expr_stmt|;
comment|// Verify families are all valid
if|if
condition|(
name|get
operator|.
name|hasFamilies
argument_list|()
condition|)
block|{
for|for
control|(
name|byte
index|[]
name|family
range|:
name|get
operator|.
name|familySet
argument_list|()
control|)
block|{
name|checkFamily
argument_list|(
name|family
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
comment|// Adding all families to scanner
for|for
control|(
name|byte
index|[]
name|family
range|:
name|this
operator|.
name|htableDescriptor
operator|.
name|getFamiliesKeys
argument_list|()
control|)
block|{
name|get
operator|.
name|addFamily
argument_list|(
name|family
argument_list|)
expr_stmt|;
block|}
block|}
name|List
argument_list|<
name|KeyValue
argument_list|>
name|results
init|=
name|get
argument_list|(
name|get
argument_list|,
literal|true
argument_list|)
decl_stmt|;
return|return
operator|new
name|Result
argument_list|(
name|results
argument_list|)
return|;
block|}
comment|/*    * Do a get based on the get parameter.    * @param withCoprocessor invoke coprocessor or not. We don't want to    * always invoke cp for this private method.    */
specifier|private
name|List
argument_list|<
name|KeyValue
argument_list|>
name|get
parameter_list|(
name|Get
name|get
parameter_list|,
name|boolean
name|withCoprocessor
parameter_list|)
throws|throws
name|IOException
block|{
name|List
argument_list|<
name|KeyValue
argument_list|>
name|results
init|=
operator|new
name|ArrayList
argument_list|<
name|KeyValue
argument_list|>
argument_list|()
decl_stmt|;
comment|// pre-get CP hook
if|if
condition|(
name|withCoprocessor
operator|&&
operator|(
name|coprocessorHost
operator|!=
literal|null
operator|)
condition|)
block|{
if|if
condition|(
name|coprocessorHost
operator|.
name|preGet
argument_list|(
name|get
argument_list|,
name|results
argument_list|)
condition|)
block|{
return|return
name|results
return|;
block|}
block|}
name|Scan
name|scan
init|=
operator|new
name|Scan
argument_list|(
name|get
argument_list|)
decl_stmt|;
name|RegionScanner
name|scanner
init|=
literal|null
decl_stmt|;
try|try
block|{
name|scanner
operator|=
name|getScanner
argument_list|(
name|scan
argument_list|)
expr_stmt|;
name|scanner
operator|.
name|next
argument_list|(
name|results
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
if|if
condition|(
name|scanner
operator|!=
literal|null
condition|)
name|scanner
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
comment|// post-get CP hook
if|if
condition|(
name|withCoprocessor
operator|&&
operator|(
name|coprocessorHost
operator|!=
literal|null
operator|)
condition|)
block|{
name|coprocessorHost
operator|.
name|postGet
argument_list|(
name|get
argument_list|,
name|results
argument_list|)
expr_stmt|;
block|}
comment|// do after lock
if|if
condition|(
name|this
operator|.
name|metricsRegion
operator|!=
literal|null
condition|)
block|{
name|this
operator|.
name|metricsRegion
operator|.
name|updateGet
argument_list|()
expr_stmt|;
block|}
return|return
name|results
return|;
block|}
specifier|public
name|void
name|mutateRow
parameter_list|(
name|RowMutations
name|rm
parameter_list|)
throws|throws
name|IOException
block|{
name|mutateRowsWithLocks
argument_list|(
name|rm
operator|.
name|getMutations
argument_list|()
argument_list|,
name|Collections
operator|.
name|singleton
argument_list|(
name|rm
operator|.
name|getRow
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|/**    * Perform atomic mutations within the region.    * @param mutations The list of mutations to perform.    *<code>mutations</code> can contain operations for multiple rows.    * Caller has to ensure that all rows are contained in this region.    * @param rowsToLock Rows to lock    * If multiple rows are locked care should be taken that    *<code>rowsToLock</code> is sorted in order to avoid deadlocks.    * @throws IOException    */
specifier|public
name|void
name|mutateRowsWithLocks
parameter_list|(
name|Collection
argument_list|<
name|Mutation
argument_list|>
name|mutations
parameter_list|,
name|Collection
argument_list|<
name|byte
index|[]
argument_list|>
name|rowsToLock
parameter_list|)
throws|throws
name|IOException
block|{
name|MultiRowMutationProcessor
name|proc
init|=
operator|new
name|MultiRowMutationProcessor
argument_list|(
name|mutations
argument_list|,
name|rowsToLock
argument_list|)
decl_stmt|;
name|processRowsWithLocks
argument_list|(
name|proc
argument_list|,
operator|-
literal|1
argument_list|)
expr_stmt|;
block|}
comment|/**    * Performs atomic multiple reads and writes on a given row.    *    * @param processor The object defines the reads and writes to a row.    */
specifier|public
name|void
name|processRowsWithLocks
parameter_list|(
name|RowProcessor
argument_list|<
name|?
argument_list|,
name|?
argument_list|>
name|processor
parameter_list|)
throws|throws
name|IOException
block|{
name|processRowsWithLocks
argument_list|(
name|processor
argument_list|,
name|rowProcessorTimeout
argument_list|)
expr_stmt|;
block|}
comment|/**    * Performs atomic multiple reads and writes on a given row.    *    * @param processor The object defines the reads and writes to a row.    * @param timeout The timeout of the processor.process() execution    *                Use a negative number to switch off the time bound    */
specifier|public
name|void
name|processRowsWithLocks
parameter_list|(
name|RowProcessor
argument_list|<
name|?
argument_list|,
name|?
argument_list|>
name|processor
parameter_list|,
name|long
name|timeout
parameter_list|)
throws|throws
name|IOException
block|{
for|for
control|(
name|byte
index|[]
name|row
range|:
name|processor
operator|.
name|getRowsToLock
argument_list|()
control|)
block|{
name|checkRow
argument_list|(
name|row
argument_list|,
literal|"processRowsWithLocks"
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|!
name|processor
operator|.
name|readOnly
argument_list|()
condition|)
block|{
name|checkReadOnly
argument_list|()
expr_stmt|;
block|}
name|checkResources
argument_list|()
expr_stmt|;
name|startRegionOperation
argument_list|()
expr_stmt|;
name|WALEdit
name|walEdit
init|=
operator|new
name|WALEdit
argument_list|()
decl_stmt|;
comment|// 1. Run pre-process hook
name|processor
operator|.
name|preProcess
argument_list|(
name|this
argument_list|,
name|walEdit
argument_list|)
expr_stmt|;
comment|// Short circuit the read only case
if|if
condition|(
name|processor
operator|.
name|readOnly
argument_list|()
condition|)
block|{
try|try
block|{
name|long
name|now
init|=
name|EnvironmentEdgeManager
operator|.
name|currentTimeMillis
argument_list|()
decl_stmt|;
name|doProcessRowWithTimeout
argument_list|(
name|processor
argument_list|,
name|now
argument_list|,
name|this
argument_list|,
literal|null
argument_list|,
literal|null
argument_list|,
name|timeout
argument_list|)
expr_stmt|;
name|processor
operator|.
name|postProcess
argument_list|(
name|this
argument_list|,
name|walEdit
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
throw|throw
name|e
throw|;
block|}
finally|finally
block|{
name|closeRegionOperation
argument_list|()
expr_stmt|;
block|}
return|return;
block|}
name|MultiVersionConsistencyControl
operator|.
name|WriteEntry
name|writeEntry
init|=
literal|null
decl_stmt|;
name|boolean
name|locked
init|=
literal|false
decl_stmt|;
name|boolean
name|walSyncSuccessful
init|=
literal|false
decl_stmt|;
name|List
argument_list|<
name|Integer
argument_list|>
name|acquiredLocks
init|=
literal|null
decl_stmt|;
name|long
name|addedSize
init|=
literal|0
decl_stmt|;
name|List
argument_list|<
name|KeyValue
argument_list|>
name|mutations
init|=
operator|new
name|ArrayList
argument_list|<
name|KeyValue
argument_list|>
argument_list|()
decl_stmt|;
name|Collection
argument_list|<
name|byte
index|[]
argument_list|>
name|rowsToLock
init|=
name|processor
operator|.
name|getRowsToLock
argument_list|()
decl_stmt|;
try|try
block|{
comment|// 2. Acquire the row lock(s)
name|acquiredLocks
operator|=
operator|new
name|ArrayList
argument_list|<
name|Integer
argument_list|>
argument_list|(
name|rowsToLock
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
for|for
control|(
name|byte
index|[]
name|row
range|:
name|rowsToLock
control|)
block|{
comment|// Attempt to lock all involved rows, fail if one lock times out
name|Integer
name|lid
init|=
name|getLock
argument_list|(
literal|null
argument_list|,
name|row
argument_list|,
literal|true
argument_list|)
decl_stmt|;
if|if
condition|(
name|lid
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Failed to acquire lock on "
operator|+
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|row
argument_list|)
argument_list|)
throw|;
block|}
name|acquiredLocks
operator|.
name|add
argument_list|(
name|lid
argument_list|)
expr_stmt|;
block|}
comment|// 3. Region lock
name|lock
argument_list|(
name|this
operator|.
name|updatesLock
operator|.
name|readLock
argument_list|()
argument_list|,
name|acquiredLocks
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
name|locked
operator|=
literal|true
expr_stmt|;
name|long
name|now
init|=
name|EnvironmentEdgeManager
operator|.
name|currentTimeMillis
argument_list|()
decl_stmt|;
try|try
block|{
comment|// 4. Let the processor scan the rows, generate mutations and add
comment|//    waledits
name|doProcessRowWithTimeout
argument_list|(
name|processor
argument_list|,
name|now
argument_list|,
name|this
argument_list|,
name|mutations
argument_list|,
name|walEdit
argument_list|,
name|timeout
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|mutations
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
comment|// 5. Get a mvcc write number
name|writeEntry
operator|=
name|mvcc
operator|.
name|beginMemstoreInsert
argument_list|()
expr_stmt|;
comment|// 6. Apply to memstore
for|for
control|(
name|KeyValue
name|kv
range|:
name|mutations
control|)
block|{
name|kv
operator|.
name|setMemstoreTS
argument_list|(
name|writeEntry
operator|.
name|getWriteNumber
argument_list|()
argument_list|)
expr_stmt|;
name|byte
index|[]
name|family
init|=
name|kv
operator|.
name|getFamily
argument_list|()
decl_stmt|;
name|checkFamily
argument_list|(
name|family
argument_list|)
expr_stmt|;
name|addedSize
operator|+=
name|stores
operator|.
name|get
argument_list|(
name|family
argument_list|)
operator|.
name|add
argument_list|(
name|kv
argument_list|)
expr_stmt|;
block|}
name|long
name|txid
init|=
literal|0
decl_stmt|;
comment|// 7. Append no sync
if|if
condition|(
operator|!
name|walEdit
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|txid
operator|=
name|this
operator|.
name|log
operator|.
name|appendNoSync
argument_list|(
name|this
operator|.
name|regionInfo
argument_list|,
name|this
operator|.
name|htableDescriptor
operator|.
name|getName
argument_list|()
argument_list|,
name|walEdit
argument_list|,
name|processor
operator|.
name|getClusterId
argument_list|()
argument_list|,
name|now
argument_list|,
name|this
operator|.
name|htableDescriptor
argument_list|)
expr_stmt|;
block|}
comment|// 8. Release region lock
if|if
condition|(
name|locked
condition|)
block|{
name|this
operator|.
name|updatesLock
operator|.
name|readLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
name|locked
operator|=
literal|false
expr_stmt|;
block|}
comment|// 9. Release row lock(s)
if|if
condition|(
name|acquiredLocks
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|Integer
name|lid
range|:
name|acquiredLocks
control|)
block|{
name|releaseRowLock
argument_list|(
name|lid
argument_list|)
expr_stmt|;
block|}
name|acquiredLocks
operator|=
literal|null
expr_stmt|;
block|}
comment|// 10. Sync edit log
if|if
condition|(
name|txid
operator|!=
literal|0
condition|)
block|{
name|syncOrDefer
argument_list|(
name|txid
argument_list|)
expr_stmt|;
block|}
name|walSyncSuccessful
operator|=
literal|true
expr_stmt|;
block|}
block|}
finally|finally
block|{
if|if
condition|(
operator|!
name|mutations
operator|.
name|isEmpty
argument_list|()
operator|&&
operator|!
name|walSyncSuccessful
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Wal sync failed. Roll back "
operator|+
name|mutations
operator|.
name|size
argument_list|()
operator|+
literal|" memstore keyvalues for row(s):"
operator|+
name|processor
operator|.
name|getRowsToLock
argument_list|()
operator|.
name|iterator
argument_list|()
operator|.
name|next
argument_list|()
operator|+
literal|"..."
argument_list|)
expr_stmt|;
for|for
control|(
name|KeyValue
name|kv
range|:
name|mutations
control|)
block|{
name|stores
operator|.
name|get
argument_list|(
name|kv
operator|.
name|getFamily
argument_list|()
argument_list|)
operator|.
name|rollback
argument_list|(
name|kv
argument_list|)
expr_stmt|;
block|}
block|}
comment|// 11. Roll mvcc forward
if|if
condition|(
name|writeEntry
operator|!=
literal|null
condition|)
block|{
name|mvcc
operator|.
name|completeMemstoreInsert
argument_list|(
name|writeEntry
argument_list|)
expr_stmt|;
name|writeEntry
operator|=
literal|null
expr_stmt|;
block|}
if|if
condition|(
name|locked
condition|)
block|{
name|this
operator|.
name|updatesLock
operator|.
name|readLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
name|locked
operator|=
literal|false
expr_stmt|;
block|}
if|if
condition|(
name|acquiredLocks
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|Integer
name|lid
range|:
name|acquiredLocks
control|)
block|{
name|releaseRowLock
argument_list|(
name|lid
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|// 12. Run post-process hook
name|processor
operator|.
name|postProcess
argument_list|(
name|this
argument_list|,
name|walEdit
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
throw|throw
name|e
throw|;
block|}
finally|finally
block|{
name|closeRegionOperation
argument_list|()
expr_stmt|;
if|if
condition|(
operator|!
name|mutations
operator|.
name|isEmpty
argument_list|()
operator|&&
name|isFlushSize
argument_list|(
name|this
operator|.
name|addAndGetGlobalMemstoreSize
argument_list|(
name|addedSize
argument_list|)
argument_list|)
condition|)
block|{
name|requestFlush
argument_list|()
expr_stmt|;
block|}
block|}
block|}
specifier|private
name|void
name|doProcessRowWithTimeout
parameter_list|(
specifier|final
name|RowProcessor
argument_list|<
name|?
argument_list|,
name|?
argument_list|>
name|processor
parameter_list|,
specifier|final
name|long
name|now
parameter_list|,
specifier|final
name|HRegion
name|region
parameter_list|,
specifier|final
name|List
argument_list|<
name|KeyValue
argument_list|>
name|mutations
parameter_list|,
specifier|final
name|WALEdit
name|walEdit
parameter_list|,
specifier|final
name|long
name|timeout
parameter_list|)
throws|throws
name|IOException
block|{
comment|// Short circuit the no time bound case.
if|if
condition|(
name|timeout
operator|<
literal|0
condition|)
block|{
try|try
block|{
name|processor
operator|.
name|process
argument_list|(
name|now
argument_list|,
name|region
argument_list|,
name|mutations
argument_list|,
name|walEdit
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"RowProcessor:"
operator|+
name|processor
operator|.
name|getClass
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|" throws Exception on row(s):"
operator|+
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|processor
operator|.
name|getRowsToLock
argument_list|()
operator|.
name|iterator
argument_list|()
operator|.
name|next
argument_list|()
argument_list|)
operator|+
literal|"..."
argument_list|,
name|e
argument_list|)
expr_stmt|;
throw|throw
name|e
throw|;
block|}
return|return;
block|}
comment|// Case with time bound
name|FutureTask
argument_list|<
name|Void
argument_list|>
name|task
init|=
operator|new
name|FutureTask
argument_list|<
name|Void
argument_list|>
argument_list|(
operator|new
name|Callable
argument_list|<
name|Void
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|Void
name|call
parameter_list|()
throws|throws
name|IOException
block|{
try|try
block|{
name|processor
operator|.
name|process
argument_list|(
name|now
argument_list|,
name|region
argument_list|,
name|mutations
argument_list|,
name|walEdit
argument_list|)
expr_stmt|;
return|return
literal|null
return|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"RowProcessor:"
operator|+
name|processor
operator|.
name|getClass
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|" throws Exception on row(s):"
operator|+
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|processor
operator|.
name|getRowsToLock
argument_list|()
operator|.
name|iterator
argument_list|()
operator|.
name|next
argument_list|()
argument_list|)
operator|+
literal|"..."
argument_list|,
name|e
argument_list|)
expr_stmt|;
throw|throw
name|e
throw|;
block|}
block|}
block|}
argument_list|)
decl_stmt|;
name|rowProcessorExecutor
operator|.
name|execute
argument_list|(
name|task
argument_list|)
expr_stmt|;
try|try
block|{
name|task
operator|.
name|get
argument_list|(
name|timeout
argument_list|,
name|TimeUnit
operator|.
name|MILLISECONDS
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|TimeoutException
name|te
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"RowProcessor timeout:"
operator|+
name|timeout
operator|+
literal|" ms on row(s):"
operator|+
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|processor
operator|.
name|getRowsToLock
argument_list|()
operator|.
name|iterator
argument_list|()
operator|.
name|next
argument_list|()
argument_list|)
operator|+
literal|"..."
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|IOException
argument_list|(
name|te
argument_list|)
throw|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
comment|// TODO: There's a lot of boiler plate code identical
comment|// to increment... See how to better unify that.
comment|/**    * Perform one or more append operations on a row.    *    * @param append    * @param writeToWAL    * @return new keyvalues after increment    * @throws IOException    */
specifier|public
name|Result
name|append
parameter_list|(
name|Append
name|append
parameter_list|,
name|boolean
name|writeToWAL
parameter_list|)
throws|throws
name|IOException
block|{
name|byte
index|[]
name|row
init|=
name|append
operator|.
name|getRow
argument_list|()
decl_stmt|;
name|checkRow
argument_list|(
name|row
argument_list|,
literal|"append"
argument_list|)
expr_stmt|;
name|boolean
name|flush
init|=
literal|false
decl_stmt|;
name|WALEdit
name|walEdits
init|=
literal|null
decl_stmt|;
name|List
argument_list|<
name|KeyValue
argument_list|>
name|allKVs
init|=
operator|new
name|ArrayList
argument_list|<
name|KeyValue
argument_list|>
argument_list|(
name|append
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
name|Map
argument_list|<
name|Store
argument_list|,
name|List
argument_list|<
name|KeyValue
argument_list|>
argument_list|>
name|tempMemstore
init|=
operator|new
name|HashMap
argument_list|<
name|Store
argument_list|,
name|List
argument_list|<
name|KeyValue
argument_list|>
argument_list|>
argument_list|()
decl_stmt|;
name|long
name|size
init|=
literal|0
decl_stmt|;
name|long
name|txid
init|=
literal|0
decl_stmt|;
comment|// Lock row
name|startRegionOperation
argument_list|()
expr_stmt|;
name|this
operator|.
name|writeRequestsCount
operator|.
name|increment
argument_list|()
expr_stmt|;
name|WriteEntry
name|w
init|=
literal|null
decl_stmt|;
try|try
block|{
name|Integer
name|lid
init|=
name|getLock
argument_list|(
literal|null
argument_list|,
name|row
argument_list|,
literal|true
argument_list|)
decl_stmt|;
name|lock
argument_list|(
name|this
operator|.
name|updatesLock
operator|.
name|readLock
argument_list|()
argument_list|)
expr_stmt|;
comment|// wait for all prior MVCC transactions to finish - while we hold the row lock
comment|// (so that we are guaranteed to see the latest state)
name|mvcc
operator|.
name|completeMemstoreInsert
argument_list|(
name|mvcc
operator|.
name|beginMemstoreInsert
argument_list|()
argument_list|)
expr_stmt|;
comment|// now start my own transaction
name|w
operator|=
name|mvcc
operator|.
name|beginMemstoreInsert
argument_list|()
expr_stmt|;
try|try
block|{
name|long
name|now
init|=
name|EnvironmentEdgeManager
operator|.
name|currentTimeMillis
argument_list|()
decl_stmt|;
comment|// Process each family
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|byte
index|[]
argument_list|,
name|List
argument_list|<
name|KeyValue
argument_list|>
argument_list|>
name|family
range|:
name|append
operator|.
name|getFamilyMap
argument_list|()
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|Store
name|store
init|=
name|stores
operator|.
name|get
argument_list|(
name|family
operator|.
name|getKey
argument_list|()
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|KeyValue
argument_list|>
name|kvs
init|=
operator|new
name|ArrayList
argument_list|<
name|KeyValue
argument_list|>
argument_list|(
name|family
operator|.
name|getValue
argument_list|()
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
comment|// Get previous values for all columns in this family
name|Get
name|get
init|=
operator|new
name|Get
argument_list|(
name|row
argument_list|)
decl_stmt|;
for|for
control|(
name|KeyValue
name|kv
range|:
name|family
operator|.
name|getValue
argument_list|()
control|)
block|{
name|get
operator|.
name|addColumn
argument_list|(
name|family
operator|.
name|getKey
argument_list|()
argument_list|,
name|kv
operator|.
name|getQualifier
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|List
argument_list|<
name|KeyValue
argument_list|>
name|results
init|=
name|get
argument_list|(
name|get
argument_list|,
literal|false
argument_list|)
decl_stmt|;
comment|// Iterate the input columns and update existing values if they were
comment|// found, otherwise add new column initialized to the append value
comment|// Avoid as much copying as possible. Every byte is copied at most
comment|// once.
comment|// Would be nice if KeyValue had scatter/gather logic
name|int
name|idx
init|=
literal|0
decl_stmt|;
for|for
control|(
name|KeyValue
name|kv
range|:
name|family
operator|.
name|getValue
argument_list|()
control|)
block|{
name|KeyValue
name|newKV
decl_stmt|;
if|if
condition|(
name|idx
operator|<
name|results
operator|.
name|size
argument_list|()
operator|&&
name|results
operator|.
name|get
argument_list|(
name|idx
argument_list|)
operator|.
name|matchingQualifier
argument_list|(
name|kv
operator|.
name|getBuffer
argument_list|()
argument_list|,
name|kv
operator|.
name|getQualifierOffset
argument_list|()
argument_list|,
name|kv
operator|.
name|getQualifierLength
argument_list|()
argument_list|)
condition|)
block|{
name|KeyValue
name|oldKv
init|=
name|results
operator|.
name|get
argument_list|(
name|idx
argument_list|)
decl_stmt|;
comment|// allocate an empty kv once
name|newKV
operator|=
operator|new
name|KeyValue
argument_list|(
name|row
operator|.
name|length
argument_list|,
name|kv
operator|.
name|getFamilyLength
argument_list|()
argument_list|,
name|kv
operator|.
name|getQualifierLength
argument_list|()
argument_list|,
name|now
argument_list|,
name|KeyValue
operator|.
name|Type
operator|.
name|Put
argument_list|,
name|oldKv
operator|.
name|getValueLength
argument_list|()
operator|+
name|kv
operator|.
name|getValueLength
argument_list|()
argument_list|)
expr_stmt|;
comment|// copy in the value
name|System
operator|.
name|arraycopy
argument_list|(
name|oldKv
operator|.
name|getBuffer
argument_list|()
argument_list|,
name|oldKv
operator|.
name|getValueOffset
argument_list|()
argument_list|,
name|newKV
operator|.
name|getBuffer
argument_list|()
argument_list|,
name|newKV
operator|.
name|getValueOffset
argument_list|()
argument_list|,
name|oldKv
operator|.
name|getValueLength
argument_list|()
argument_list|)
expr_stmt|;
name|System
operator|.
name|arraycopy
argument_list|(
name|kv
operator|.
name|getBuffer
argument_list|()
argument_list|,
name|kv
operator|.
name|getValueOffset
argument_list|()
argument_list|,
name|newKV
operator|.
name|getBuffer
argument_list|()
argument_list|,
name|newKV
operator|.
name|getValueOffset
argument_list|()
operator|+
name|oldKv
operator|.
name|getValueLength
argument_list|()
argument_list|,
name|kv
operator|.
name|getValueLength
argument_list|()
argument_list|)
expr_stmt|;
name|idx
operator|++
expr_stmt|;
block|}
else|else
block|{
comment|// allocate an empty kv once
name|newKV
operator|=
operator|new
name|KeyValue
argument_list|(
name|row
operator|.
name|length
argument_list|,
name|kv
operator|.
name|getFamilyLength
argument_list|()
argument_list|,
name|kv
operator|.
name|getQualifierLength
argument_list|()
argument_list|,
name|now
argument_list|,
name|KeyValue
operator|.
name|Type
operator|.
name|Put
argument_list|,
name|kv
operator|.
name|getValueLength
argument_list|()
argument_list|)
expr_stmt|;
comment|// copy in the value
name|System
operator|.
name|arraycopy
argument_list|(
name|kv
operator|.
name|getBuffer
argument_list|()
argument_list|,
name|kv
operator|.
name|getValueOffset
argument_list|()
argument_list|,
name|newKV
operator|.
name|getBuffer
argument_list|()
argument_list|,
name|newKV
operator|.
name|getValueOffset
argument_list|()
argument_list|,
name|kv
operator|.
name|getValueLength
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|// copy in row, family, and qualifier
name|System
operator|.
name|arraycopy
argument_list|(
name|kv
operator|.
name|getBuffer
argument_list|()
argument_list|,
name|kv
operator|.
name|getRowOffset
argument_list|()
argument_list|,
name|newKV
operator|.
name|getBuffer
argument_list|()
argument_list|,
name|newKV
operator|.
name|getRowOffset
argument_list|()
argument_list|,
name|kv
operator|.
name|getRowLength
argument_list|()
argument_list|)
expr_stmt|;
name|System
operator|.
name|arraycopy
argument_list|(
name|kv
operator|.
name|getBuffer
argument_list|()
argument_list|,
name|kv
operator|.
name|getFamilyOffset
argument_list|()
argument_list|,
name|newKV
operator|.
name|getBuffer
argument_list|()
argument_list|,
name|newKV
operator|.
name|getFamilyOffset
argument_list|()
argument_list|,
name|kv
operator|.
name|getFamilyLength
argument_list|()
argument_list|)
expr_stmt|;
name|System
operator|.
name|arraycopy
argument_list|(
name|kv
operator|.
name|getBuffer
argument_list|()
argument_list|,
name|kv
operator|.
name|getQualifierOffset
argument_list|()
argument_list|,
name|newKV
operator|.
name|getBuffer
argument_list|()
argument_list|,
name|newKV
operator|.
name|getQualifierOffset
argument_list|()
argument_list|,
name|kv
operator|.
name|getQualifierLength
argument_list|()
argument_list|)
expr_stmt|;
name|newKV
operator|.
name|setMemstoreTS
argument_list|(
name|w
operator|.
name|getWriteNumber
argument_list|()
argument_list|)
expr_stmt|;
name|kvs
operator|.
name|add
argument_list|(
name|newKV
argument_list|)
expr_stmt|;
comment|// Append update to WAL
if|if
condition|(
name|writeToWAL
condition|)
block|{
if|if
condition|(
name|walEdits
operator|==
literal|null
condition|)
block|{
name|walEdits
operator|=
operator|new
name|WALEdit
argument_list|()
expr_stmt|;
block|}
name|walEdits
operator|.
name|add
argument_list|(
name|newKV
argument_list|)
expr_stmt|;
block|}
block|}
comment|//store the kvs to the temporary memstore before writing HLog
name|tempMemstore
operator|.
name|put
argument_list|(
name|store
argument_list|,
name|kvs
argument_list|)
expr_stmt|;
block|}
comment|// Actually write to WAL now
if|if
condition|(
name|writeToWAL
condition|)
block|{
comment|// Using default cluster id, as this can only happen in the orginating
comment|// cluster. A slave cluster receives the final value (not the delta)
comment|// as a Put.
name|txid
operator|=
name|this
operator|.
name|log
operator|.
name|appendNoSync
argument_list|(
name|regionInfo
argument_list|,
name|this
operator|.
name|htableDescriptor
operator|.
name|getName
argument_list|()
argument_list|,
name|walEdits
argument_list|,
name|HConstants
operator|.
name|DEFAULT_CLUSTER_ID
argument_list|,
name|EnvironmentEdgeManager
operator|.
name|currentTimeMillis
argument_list|()
argument_list|,
name|this
operator|.
name|htableDescriptor
argument_list|)
expr_stmt|;
block|}
comment|//Actually write to Memstore now
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|Store
argument_list|,
name|List
argument_list|<
name|KeyValue
argument_list|>
argument_list|>
name|entry
range|:
name|tempMemstore
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|Store
name|store
init|=
name|entry
operator|.
name|getKey
argument_list|()
decl_stmt|;
if|if
condition|(
name|store
operator|.
name|getFamily
argument_list|()
operator|.
name|getMaxVersions
argument_list|()
operator|==
literal|1
condition|)
block|{
comment|// upsert if VERSIONS for this CF == 1
name|size
operator|+=
name|store
operator|.
name|upsert
argument_list|(
name|entry
operator|.
name|getValue
argument_list|()
argument_list|,
name|getSmallestReadPoint
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// otherwise keep older versions around
for|for
control|(
name|KeyValue
name|kv
range|:
name|entry
operator|.
name|getValue
argument_list|()
control|)
block|{
name|size
operator|+=
name|store
operator|.
name|add
argument_list|(
name|kv
argument_list|)
expr_stmt|;
block|}
block|}
name|allKVs
operator|.
name|addAll
argument_list|(
name|entry
operator|.
name|getValue
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|size
operator|=
name|this
operator|.
name|addAndGetGlobalMemstoreSize
argument_list|(
name|size
argument_list|)
expr_stmt|;
name|flush
operator|=
name|isFlushSize
argument_list|(
name|size
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|this
operator|.
name|updatesLock
operator|.
name|readLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
name|releaseRowLock
argument_list|(
name|lid
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|writeToWAL
condition|)
block|{
name|syncOrDefer
argument_list|(
name|txid
argument_list|)
expr_stmt|;
comment|// sync the transaction log outside the rowlock
block|}
block|}
finally|finally
block|{
if|if
condition|(
name|w
operator|!=
literal|null
condition|)
block|{
name|mvcc
operator|.
name|completeMemstoreInsert
argument_list|(
name|w
argument_list|)
expr_stmt|;
block|}
name|closeRegionOperation
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|this
operator|.
name|metricsRegion
operator|!=
literal|null
condition|)
block|{
name|this
operator|.
name|metricsRegion
operator|.
name|updateAppend
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|flush
condition|)
block|{
comment|// Request a cache flush. Do it outside update lock.
name|requestFlush
argument_list|()
expr_stmt|;
block|}
return|return
name|append
operator|.
name|isReturnResults
argument_list|()
condition|?
operator|new
name|Result
argument_list|(
name|allKVs
argument_list|)
else|:
literal|null
return|;
block|}
comment|/**    * Perform one or more increment operations on a row.    * @param increment    * @param writeToWAL    * @return new keyvalues after increment    * @throws IOException    */
specifier|public
name|Result
name|increment
parameter_list|(
name|Increment
name|increment
parameter_list|,
name|boolean
name|writeToWAL
parameter_list|)
throws|throws
name|IOException
block|{
name|byte
index|[]
name|row
init|=
name|increment
operator|.
name|getRow
argument_list|()
decl_stmt|;
name|checkRow
argument_list|(
name|row
argument_list|,
literal|"increment"
argument_list|)
expr_stmt|;
name|TimeRange
name|tr
init|=
name|increment
operator|.
name|getTimeRange
argument_list|()
decl_stmt|;
name|boolean
name|flush
init|=
literal|false
decl_stmt|;
name|WALEdit
name|walEdits
init|=
literal|null
decl_stmt|;
name|List
argument_list|<
name|KeyValue
argument_list|>
name|allKVs
init|=
operator|new
name|ArrayList
argument_list|<
name|KeyValue
argument_list|>
argument_list|(
name|increment
operator|.
name|numColumns
argument_list|()
argument_list|)
decl_stmt|;
name|Map
argument_list|<
name|Store
argument_list|,
name|List
argument_list|<
name|KeyValue
argument_list|>
argument_list|>
name|tempMemstore
init|=
operator|new
name|HashMap
argument_list|<
name|Store
argument_list|,
name|List
argument_list|<
name|KeyValue
argument_list|>
argument_list|>
argument_list|()
decl_stmt|;
name|long
name|size
init|=
literal|0
decl_stmt|;
name|long
name|txid
init|=
literal|0
decl_stmt|;
comment|// Lock row
name|startRegionOperation
argument_list|()
expr_stmt|;
name|this
operator|.
name|writeRequestsCount
operator|.
name|increment
argument_list|()
expr_stmt|;
name|WriteEntry
name|w
init|=
literal|null
decl_stmt|;
try|try
block|{
name|Integer
name|lid
init|=
name|getLock
argument_list|(
literal|null
argument_list|,
name|row
argument_list|,
literal|true
argument_list|)
decl_stmt|;
name|lock
argument_list|(
name|this
operator|.
name|updatesLock
operator|.
name|readLock
argument_list|()
argument_list|)
expr_stmt|;
comment|// wait for all prior MVCC transactions to finish - while we hold the row lock
comment|// (so that we are guaranteed to see the latest state)
name|mvcc
operator|.
name|completeMemstoreInsert
argument_list|(
name|mvcc
operator|.
name|beginMemstoreInsert
argument_list|()
argument_list|)
expr_stmt|;
comment|// now start my own transaction
name|w
operator|=
name|mvcc
operator|.
name|beginMemstoreInsert
argument_list|()
expr_stmt|;
try|try
block|{
name|long
name|now
init|=
name|EnvironmentEdgeManager
operator|.
name|currentTimeMillis
argument_list|()
decl_stmt|;
comment|// Process each family
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|byte
index|[]
argument_list|,
name|NavigableMap
argument_list|<
name|byte
index|[]
argument_list|,
name|Long
argument_list|>
argument_list|>
name|family
range|:
name|increment
operator|.
name|getFamilyMap
argument_list|()
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|Store
name|store
init|=
name|stores
operator|.
name|get
argument_list|(
name|family
operator|.
name|getKey
argument_list|()
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|KeyValue
argument_list|>
name|kvs
init|=
operator|new
name|ArrayList
argument_list|<
name|KeyValue
argument_list|>
argument_list|(
name|family
operator|.
name|getValue
argument_list|()
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
comment|// Get previous values for all columns in this family
name|Get
name|get
init|=
operator|new
name|Get
argument_list|(
name|row
argument_list|)
decl_stmt|;
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|byte
index|[]
argument_list|,
name|Long
argument_list|>
name|column
range|:
name|family
operator|.
name|getValue
argument_list|()
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|get
operator|.
name|addColumn
argument_list|(
name|family
operator|.
name|getKey
argument_list|()
argument_list|,
name|column
operator|.
name|getKey
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|get
operator|.
name|setTimeRange
argument_list|(
name|tr
operator|.
name|getMin
argument_list|()
argument_list|,
name|tr
operator|.
name|getMax
argument_list|()
argument_list|)
expr_stmt|;
name|List
argument_list|<
name|KeyValue
argument_list|>
name|results
init|=
name|get
argument_list|(
name|get
argument_list|,
literal|false
argument_list|)
decl_stmt|;
comment|// Iterate the input columns and update existing values if they were
comment|// found, otherwise add new column initialized to the increment amount
name|int
name|idx
init|=
literal|0
decl_stmt|;
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|byte
index|[]
argument_list|,
name|Long
argument_list|>
name|column
range|:
name|family
operator|.
name|getValue
argument_list|()
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|long
name|amount
init|=
name|column
operator|.
name|getValue
argument_list|()
decl_stmt|;
if|if
condition|(
name|idx
operator|<
name|results
operator|.
name|size
argument_list|()
operator|&&
name|results
operator|.
name|get
argument_list|(
name|idx
argument_list|)
operator|.
name|matchingQualifier
argument_list|(
name|column
operator|.
name|getKey
argument_list|()
argument_list|)
condition|)
block|{
name|KeyValue
name|kv
init|=
name|results
operator|.
name|get
argument_list|(
name|idx
argument_list|)
decl_stmt|;
if|if
condition|(
name|kv
operator|.
name|getValueLength
argument_list|()
operator|==
name|Bytes
operator|.
name|SIZEOF_LONG
condition|)
block|{
name|amount
operator|+=
name|Bytes
operator|.
name|toLong
argument_list|(
name|kv
operator|.
name|getBuffer
argument_list|()
argument_list|,
name|kv
operator|.
name|getValueOffset
argument_list|()
argument_list|,
name|Bytes
operator|.
name|SIZEOF_LONG
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// throw DoNotRetryIOException instead of IllegalArgumentException
throw|throw
operator|new
name|DoNotRetryIOException
argument_list|(
literal|"Attempted to increment field that isn't 64 bits wide"
argument_list|)
throw|;
block|}
name|idx
operator|++
expr_stmt|;
block|}
comment|// Append new incremented KeyValue to list
name|KeyValue
name|newKV
init|=
operator|new
name|KeyValue
argument_list|(
name|row
argument_list|,
name|family
operator|.
name|getKey
argument_list|()
argument_list|,
name|column
operator|.
name|getKey
argument_list|()
argument_list|,
name|now
argument_list|,
name|Bytes
operator|.
name|toBytes
argument_list|(
name|amount
argument_list|)
argument_list|)
decl_stmt|;
name|newKV
operator|.
name|setMemstoreTS
argument_list|(
name|w
operator|.
name|getWriteNumber
argument_list|()
argument_list|)
expr_stmt|;
name|kvs
operator|.
name|add
argument_list|(
name|newKV
argument_list|)
expr_stmt|;
comment|// Prepare WAL updates
if|if
condition|(
name|writeToWAL
condition|)
block|{
if|if
condition|(
name|walEdits
operator|==
literal|null
condition|)
block|{
name|walEdits
operator|=
operator|new
name|WALEdit
argument_list|()
expr_stmt|;
block|}
name|walEdits
operator|.
name|add
argument_list|(
name|newKV
argument_list|)
expr_stmt|;
block|}
block|}
comment|//store the kvs to the temporary memstore before writing HLog
name|tempMemstore
operator|.
name|put
argument_list|(
name|store
argument_list|,
name|kvs
argument_list|)
expr_stmt|;
block|}
comment|// Actually write to WAL now
if|if
condition|(
name|writeToWAL
condition|)
block|{
comment|// Using default cluster id, as this can only happen in the orginating
comment|// cluster. A slave cluster receives the final value (not the delta)
comment|// as a Put.
name|txid
operator|=
name|this
operator|.
name|log
operator|.
name|appendNoSync
argument_list|(
name|regionInfo
argument_list|,
name|this
operator|.
name|htableDescriptor
operator|.
name|getName
argument_list|()
argument_list|,
name|walEdits
argument_list|,
name|HConstants
operator|.
name|DEFAULT_CLUSTER_ID
argument_list|,
name|EnvironmentEdgeManager
operator|.
name|currentTimeMillis
argument_list|()
argument_list|,
name|this
operator|.
name|htableDescriptor
argument_list|)
expr_stmt|;
block|}
comment|//Actually write to Memstore now
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|Store
argument_list|,
name|List
argument_list|<
name|KeyValue
argument_list|>
argument_list|>
name|entry
range|:
name|tempMemstore
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|Store
name|store
init|=
name|entry
operator|.
name|getKey
argument_list|()
decl_stmt|;
if|if
condition|(
name|store
operator|.
name|getFamily
argument_list|()
operator|.
name|getMaxVersions
argument_list|()
operator|==
literal|1
condition|)
block|{
comment|// upsert if VERSIONS for this CF == 1
name|size
operator|+=
name|store
operator|.
name|upsert
argument_list|(
name|entry
operator|.
name|getValue
argument_list|()
argument_list|,
name|getSmallestReadPoint
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// otherwise keep older versions around
for|for
control|(
name|KeyValue
name|kv
range|:
name|entry
operator|.
name|getValue
argument_list|()
control|)
block|{
name|size
operator|+=
name|store
operator|.
name|add
argument_list|(
name|kv
argument_list|)
expr_stmt|;
block|}
block|}
name|allKVs
operator|.
name|addAll
argument_list|(
name|entry
operator|.
name|getValue
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|size
operator|=
name|this
operator|.
name|addAndGetGlobalMemstoreSize
argument_list|(
name|size
argument_list|)
expr_stmt|;
name|flush
operator|=
name|isFlushSize
argument_list|(
name|size
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|this
operator|.
name|updatesLock
operator|.
name|readLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
name|releaseRowLock
argument_list|(
name|lid
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|writeToWAL
condition|)
block|{
name|syncOrDefer
argument_list|(
name|txid
argument_list|)
expr_stmt|;
comment|// sync the transaction log outside the rowlock
block|}
block|}
finally|finally
block|{
if|if
condition|(
name|w
operator|!=
literal|null
condition|)
block|{
name|mvcc
operator|.
name|completeMemstoreInsert
argument_list|(
name|w
argument_list|)
expr_stmt|;
block|}
name|closeRegionOperation
argument_list|()
expr_stmt|;
if|if
condition|(
name|this
operator|.
name|metricsRegion
operator|!=
literal|null
condition|)
block|{
name|this
operator|.
name|metricsRegion
operator|.
name|updateIncrement
argument_list|()
expr_stmt|;
block|}
block|}
if|if
condition|(
name|flush
condition|)
block|{
comment|// Request a cache flush.  Do it outside update lock.
name|requestFlush
argument_list|()
expr_stmt|;
block|}
return|return
operator|new
name|Result
argument_list|(
name|allKVs
argument_list|)
return|;
block|}
comment|//
comment|// New HBASE-880 Helpers
comment|//
specifier|private
name|void
name|checkFamily
parameter_list|(
specifier|final
name|byte
index|[]
name|family
parameter_list|)
throws|throws
name|NoSuchColumnFamilyException
block|{
if|if
condition|(
operator|!
name|this
operator|.
name|htableDescriptor
operator|.
name|hasFamily
argument_list|(
name|family
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|NoSuchColumnFamilyException
argument_list|(
literal|"Column family "
operator|+
name|Bytes
operator|.
name|toString
argument_list|(
name|family
argument_list|)
operator|+
literal|" does not exist in region "
operator|+
name|this
operator|+
literal|" in table "
operator|+
name|this
operator|.
name|htableDescriptor
argument_list|)
throw|;
block|}
block|}
specifier|public
specifier|static
specifier|final
name|long
name|FIXED_OVERHEAD
init|=
name|ClassSize
operator|.
name|align
argument_list|(
name|ClassSize
operator|.
name|OBJECT
operator|+
name|ClassSize
operator|.
name|ARRAY
operator|+
literal|39
operator|*
name|ClassSize
operator|.
name|REFERENCE
operator|+
literal|2
operator|*
name|Bytes
operator|.
name|SIZEOF_INT
operator|+
operator|(
literal|10
operator|*
name|Bytes
operator|.
name|SIZEOF_LONG
operator|)
operator|+
name|Bytes
operator|.
name|SIZEOF_BOOLEAN
argument_list|)
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|long
name|DEEP_OVERHEAD
init|=
name|FIXED_OVERHEAD
operator|+
name|ClassSize
operator|.
name|OBJECT
operator|+
comment|// closeLock
operator|(
literal|2
operator|*
name|ClassSize
operator|.
name|ATOMIC_BOOLEAN
operator|)
operator|+
comment|// closed, closing
operator|(
literal|3
operator|*
name|ClassSize
operator|.
name|ATOMIC_LONG
operator|)
operator|+
comment|// memStoreSize, numPutsWithoutWAL, dataInMemoryWithoutWAL
name|ClassSize
operator|.
name|ATOMIC_INTEGER
operator|+
comment|// lockIdGenerator
operator|(
literal|3
operator|*
name|ClassSize
operator|.
name|CONCURRENT_HASHMAP
operator|)
operator|+
comment|// lockedRows, lockIds, scannerReadPoints
name|WriteState
operator|.
name|HEAP_SIZE
operator|+
comment|// writestate
name|ClassSize
operator|.
name|CONCURRENT_SKIPLISTMAP
operator|+
name|ClassSize
operator|.
name|CONCURRENT_SKIPLISTMAP_ENTRY
operator|+
comment|// stores
operator|(
literal|2
operator|*
name|ClassSize
operator|.
name|REENTRANT_LOCK
operator|)
operator|+
comment|// lock, updatesLock
name|ClassSize
operator|.
name|ARRAYLIST
operator|+
comment|// recentFlushes
name|MultiVersionConsistencyControl
operator|.
name|FIXED_SIZE
comment|// mvcc
decl_stmt|;
annotation|@
name|Override
specifier|public
name|long
name|heapSize
parameter_list|()
block|{
name|long
name|heapSize
init|=
name|DEEP_OVERHEAD
decl_stmt|;
for|for
control|(
name|Store
name|store
range|:
name|this
operator|.
name|stores
operator|.
name|values
argument_list|()
control|)
block|{
name|heapSize
operator|+=
name|store
operator|.
name|heapSize
argument_list|()
expr_stmt|;
block|}
comment|// this does not take into account row locks, recent flushes, mvcc entries
return|return
name|heapSize
return|;
block|}
comment|/*    * This method calls System.exit.    * @param message Message to print out.  May be null.    */
specifier|private
specifier|static
name|void
name|printUsageAndExit
parameter_list|(
specifier|final
name|String
name|message
parameter_list|)
block|{
if|if
condition|(
name|message
operator|!=
literal|null
operator|&&
name|message
operator|.
name|length
argument_list|()
operator|>
literal|0
condition|)
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
name|message
argument_list|)
expr_stmt|;
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"Usage: HRegion CATLALOG_TABLE_DIR [major_compact]"
argument_list|)
expr_stmt|;
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"Options:"
argument_list|)
expr_stmt|;
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|" major_compact  Pass this option to major compact "
operator|+
literal|"passed region."
argument_list|)
expr_stmt|;
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"Default outputs scan of passed region."
argument_list|)
expr_stmt|;
name|System
operator|.
name|exit
argument_list|(
literal|1
argument_list|)
expr_stmt|;
block|}
comment|/**    * Registers a new protocol buffer {@link Service} subclass as a coprocessor endpoint to    * be available for handling    * {@link HRegion#execService(com.google.protobuf.RpcController, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall)}} calls.    *    *<p>    * Only a single instance may be registered per region for a given {@link Service} subclass (the    * instances are keyed on {@link com.google.protobuf.Descriptors.ServiceDescriptor#getFullName()}.    * After the first registration, subsequent calls with the same service name will fail with    * a return value of {@code false}.    *</p>    * @param instance the {@code Service} subclass instance to expose as a coprocessor endpoint    * @return {@code true} if the registration was successful, {@code false}    * otherwise    */
specifier|public
name|boolean
name|registerService
parameter_list|(
name|Service
name|instance
parameter_list|)
block|{
comment|/*      * No stacking of instances is allowed for a single service name      */
name|Descriptors
operator|.
name|ServiceDescriptor
name|serviceDesc
init|=
name|instance
operator|.
name|getDescriptorForType
argument_list|()
decl_stmt|;
if|if
condition|(
name|coprocessorServiceHandlers
operator|.
name|containsKey
argument_list|(
name|serviceDesc
operator|.
name|getFullName
argument_list|()
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Coprocessor service "
operator|+
name|serviceDesc
operator|.
name|getFullName
argument_list|()
operator|+
literal|" already registered, rejecting request from "
operator|+
name|instance
argument_list|)
expr_stmt|;
return|return
literal|false
return|;
block|}
name|coprocessorServiceHandlers
operator|.
name|put
argument_list|(
name|serviceDesc
operator|.
name|getFullName
argument_list|()
argument_list|,
name|instance
argument_list|)
expr_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Registered coprocessor service: region="
operator|+
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|getRegionName
argument_list|()
argument_list|)
operator|+
literal|" service="
operator|+
name|serviceDesc
operator|.
name|getFullName
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
literal|true
return|;
block|}
comment|/**    * Executes a single protocol buffer coprocessor endpoint {@link Service} method using    * the registered protocol handlers.  {@link Service} implementations must be registered via the    * {@link org.apache.hadoop.hbase.regionserver.HRegion#registerService(com.google.protobuf.Service)}    * method before they are available.    *    * @param controller an {@code RpcContoller} implementation to pass to the invoked service    * @param call a {@code CoprocessorServiceCall} instance identifying the service, method,    *     and parameters for the method invocation    * @return a protocol buffer {@code Message} instance containing the method's result    * @throws IOException if no registered service handler is found or an error    *     occurs during the invocation    * @see org.apache.hadoop.hbase.regionserver.HRegion#registerService(com.google.protobuf.Service)    */
specifier|public
name|Message
name|execService
parameter_list|(
name|RpcController
name|controller
parameter_list|,
name|CoprocessorServiceCall
name|call
parameter_list|)
throws|throws
name|IOException
block|{
name|String
name|serviceName
init|=
name|call
operator|.
name|getServiceName
argument_list|()
decl_stmt|;
name|String
name|methodName
init|=
name|call
operator|.
name|getMethodName
argument_list|()
decl_stmt|;
if|if
condition|(
operator|!
name|coprocessorServiceHandlers
operator|.
name|containsKey
argument_list|(
name|serviceName
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|UnknownProtocolException
argument_list|(
literal|null
argument_list|,
literal|"No registered coprocessor service found for name "
operator|+
name|serviceName
operator|+
literal|" in region "
operator|+
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|getRegionName
argument_list|()
argument_list|)
argument_list|)
throw|;
block|}
name|Service
name|service
init|=
name|coprocessorServiceHandlers
operator|.
name|get
argument_list|(
name|serviceName
argument_list|)
decl_stmt|;
name|Descriptors
operator|.
name|ServiceDescriptor
name|serviceDesc
init|=
name|service
operator|.
name|getDescriptorForType
argument_list|()
decl_stmt|;
name|Descriptors
operator|.
name|MethodDescriptor
name|methodDesc
init|=
name|serviceDesc
operator|.
name|findMethodByName
argument_list|(
name|methodName
argument_list|)
decl_stmt|;
if|if
condition|(
name|methodDesc
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|UnknownProtocolException
argument_list|(
name|service
operator|.
name|getClass
argument_list|()
argument_list|,
literal|"Unknown method "
operator|+
name|methodName
operator|+
literal|" called on service "
operator|+
name|serviceName
operator|+
literal|" in region "
operator|+
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|getRegionName
argument_list|()
argument_list|)
argument_list|)
throw|;
block|}
name|Message
name|request
init|=
name|service
operator|.
name|getRequestPrototype
argument_list|(
name|methodDesc
argument_list|)
operator|.
name|newBuilderForType
argument_list|()
operator|.
name|mergeFrom
argument_list|(
name|call
operator|.
name|getRequest
argument_list|()
argument_list|)
operator|.
name|build
argument_list|()
decl_stmt|;
specifier|final
name|Message
operator|.
name|Builder
name|responseBuilder
init|=
name|service
operator|.
name|getResponsePrototype
argument_list|(
name|methodDesc
argument_list|)
operator|.
name|newBuilderForType
argument_list|()
decl_stmt|;
name|service
operator|.
name|callMethod
argument_list|(
name|methodDesc
argument_list|,
name|controller
argument_list|,
name|request
argument_list|,
operator|new
name|RpcCallback
argument_list|<
name|Message
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|void
name|run
parameter_list|(
name|Message
name|message
parameter_list|)
block|{
if|if
condition|(
name|message
operator|!=
literal|null
condition|)
block|{
name|responseBuilder
operator|.
name|mergeFrom
argument_list|(
name|message
argument_list|)
expr_stmt|;
block|}
block|}
block|}
argument_list|)
expr_stmt|;
return|return
name|responseBuilder
operator|.
name|build
argument_list|()
return|;
block|}
comment|/*    * Process table.    * Do major compaction or list content.    * @param fs    * @param p    * @param log    * @param c    * @param majorCompact    * @throws IOException    */
specifier|private
specifier|static
name|void
name|processTable
parameter_list|(
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Path
name|p
parameter_list|,
specifier|final
name|HLog
name|log
parameter_list|,
specifier|final
name|Configuration
name|c
parameter_list|,
specifier|final
name|boolean
name|majorCompact
parameter_list|)
throws|throws
name|IOException
block|{
name|HRegion
name|region
init|=
literal|null
decl_stmt|;
name|String
name|rootStr
init|=
name|Bytes
operator|.
name|toString
argument_list|(
name|HConstants
operator|.
name|ROOT_TABLE_NAME
argument_list|)
decl_stmt|;
name|String
name|metaStr
init|=
name|Bytes
operator|.
name|toString
argument_list|(
name|HConstants
operator|.
name|META_TABLE_NAME
argument_list|)
decl_stmt|;
comment|// Currently expects tables have one region only.
if|if
condition|(
name|p
operator|.
name|getName
argument_list|()
operator|.
name|startsWith
argument_list|(
name|rootStr
argument_list|)
condition|)
block|{
name|region
operator|=
name|HRegion
operator|.
name|newHRegion
argument_list|(
name|p
argument_list|,
name|log
argument_list|,
name|fs
argument_list|,
name|c
argument_list|,
name|HRegionInfo
operator|.
name|ROOT_REGIONINFO
argument_list|,
name|HTableDescriptor
operator|.
name|ROOT_TABLEDESC
argument_list|,
literal|null
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|p
operator|.
name|getName
argument_list|()
operator|.
name|startsWith
argument_list|(
name|metaStr
argument_list|)
condition|)
block|{
name|region
operator|=
name|HRegion
operator|.
name|newHRegion
argument_list|(
name|p
argument_list|,
name|log
argument_list|,
name|fs
argument_list|,
name|c
argument_list|,
name|HRegionInfo
operator|.
name|FIRST_META_REGIONINFO
argument_list|,
name|HTableDescriptor
operator|.
name|META_TABLEDESC
argument_list|,
literal|null
argument_list|)
expr_stmt|;
block|}
else|else
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Not a known catalog table: "
operator|+
name|p
operator|.
name|toString
argument_list|()
argument_list|)
throw|;
block|}
try|try
block|{
name|region
operator|.
name|initialize
argument_list|()
expr_stmt|;
if|if
condition|(
name|majorCompact
condition|)
block|{
name|region
operator|.
name|compactStores
argument_list|(
literal|true
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// Default behavior
name|Scan
name|scan
init|=
operator|new
name|Scan
argument_list|()
decl_stmt|;
comment|// scan.addFamily(HConstants.CATALOG_FAMILY);
name|RegionScanner
name|scanner
init|=
name|region
operator|.
name|getScanner
argument_list|(
name|scan
argument_list|)
decl_stmt|;
try|try
block|{
name|List
argument_list|<
name|KeyValue
argument_list|>
name|kvs
init|=
operator|new
name|ArrayList
argument_list|<
name|KeyValue
argument_list|>
argument_list|()
decl_stmt|;
name|boolean
name|done
init|=
literal|false
decl_stmt|;
do|do
block|{
name|kvs
operator|.
name|clear
argument_list|()
expr_stmt|;
name|done
operator|=
name|scanner
operator|.
name|next
argument_list|(
name|kvs
argument_list|)
expr_stmt|;
if|if
condition|(
name|kvs
operator|.
name|size
argument_list|()
operator|>
literal|0
condition|)
name|LOG
operator|.
name|info
argument_list|(
name|kvs
argument_list|)
expr_stmt|;
block|}
do|while
condition|(
name|done
condition|)
do|;
block|}
finally|finally
block|{
name|scanner
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
block|}
block|}
finally|finally
block|{
name|region
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
block|}
name|boolean
name|shouldForceSplit
parameter_list|()
block|{
return|return
name|this
operator|.
name|splitRequest
return|;
block|}
name|byte
index|[]
name|getExplicitSplitPoint
parameter_list|()
block|{
return|return
name|this
operator|.
name|explicitSplitPoint
return|;
block|}
name|void
name|forceSplit
parameter_list|(
name|byte
index|[]
name|sp
parameter_list|)
block|{
comment|// NOTE : this HRegion will go away after the forced split is successfull
comment|//        therefore, no reason to clear this value
name|this
operator|.
name|splitRequest
operator|=
literal|true
expr_stmt|;
if|if
condition|(
name|sp
operator|!=
literal|null
condition|)
block|{
name|this
operator|.
name|explicitSplitPoint
operator|=
name|sp
expr_stmt|;
block|}
block|}
name|void
name|clearSplit_TESTS_ONLY
parameter_list|()
block|{
name|this
operator|.
name|splitRequest
operator|=
literal|false
expr_stmt|;
block|}
comment|/**    * Give the region a chance to prepare before it is split.    */
specifier|protected
name|void
name|prepareToSplit
parameter_list|()
block|{
comment|// nothing
block|}
comment|/**    * Return the splitpoint. null indicates the region isn't splittable    * If the splitpoint isn't explicitly specified, it will go over the stores    * to find the best splitpoint. Currently the criteria of best splitpoint    * is based on the size of the store.    */
specifier|public
name|byte
index|[]
name|checkSplit
parameter_list|()
block|{
comment|// Can't split ROOT/META
if|if
condition|(
name|this
operator|.
name|regionInfo
operator|.
name|isMetaTable
argument_list|()
condition|)
block|{
if|if
condition|(
name|shouldForceSplit
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Cannot split root/meta regions in HBase 0.20 and above"
argument_list|)
expr_stmt|;
block|}
return|return
literal|null
return|;
block|}
if|if
condition|(
operator|!
name|splitPolicy
operator|.
name|shouldSplit
argument_list|()
condition|)
block|{
return|return
literal|null
return|;
block|}
name|byte
index|[]
name|ret
init|=
name|splitPolicy
operator|.
name|getSplitPoint
argument_list|()
decl_stmt|;
if|if
condition|(
name|ret
operator|!=
literal|null
condition|)
block|{
try|try
block|{
name|checkRow
argument_list|(
name|ret
argument_list|,
literal|"calculated split"
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Ignoring invalid split"
argument_list|,
name|e
argument_list|)
expr_stmt|;
return|return
literal|null
return|;
block|}
block|}
return|return
name|ret
return|;
block|}
comment|/**    * @return The priority that this region should have in the compaction queue    */
specifier|public
name|int
name|getCompactPriority
parameter_list|()
block|{
name|int
name|count
init|=
name|Integer
operator|.
name|MAX_VALUE
decl_stmt|;
for|for
control|(
name|Store
name|store
range|:
name|stores
operator|.
name|values
argument_list|()
control|)
block|{
name|count
operator|=
name|Math
operator|.
name|min
argument_list|(
name|count
argument_list|,
name|store
operator|.
name|getCompactPriority
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
name|count
return|;
block|}
comment|/**    * Checks every store to see if one has too many    * store files    * @return true if any store has too many store files    */
specifier|public
name|boolean
name|needsCompaction
parameter_list|()
block|{
for|for
control|(
name|Store
name|store
range|:
name|stores
operator|.
name|values
argument_list|()
control|)
block|{
if|if
condition|(
name|store
operator|.
name|needsCompaction
argument_list|()
condition|)
block|{
return|return
literal|true
return|;
block|}
block|}
return|return
literal|false
return|;
block|}
comment|/** @return the coprocessor host */
specifier|public
name|RegionCoprocessorHost
name|getCoprocessorHost
parameter_list|()
block|{
return|return
name|coprocessorHost
return|;
block|}
comment|/** @param coprocessorHost the new coprocessor host */
specifier|public
name|void
name|setCoprocessorHost
parameter_list|(
specifier|final
name|RegionCoprocessorHost
name|coprocessorHost
parameter_list|)
block|{
name|this
operator|.
name|coprocessorHost
operator|=
name|coprocessorHost
expr_stmt|;
block|}
comment|/**    * This method needs to be called before any public call that reads or    * modifies data. It has to be called just before a try.    * #closeRegionOperation needs to be called in the try's finally block    * Acquires a read lock and checks if the region is closing or closed.    * @throws NotServingRegionException when the region is closing or closed    * @throws RegionTooBusyException if failed to get the lock in time    * @throws InterruptedIOException if interrupted while waiting for a lock    */
specifier|public
name|void
name|startRegionOperation
parameter_list|()
throws|throws
name|NotServingRegionException
throws|,
name|RegionTooBusyException
throws|,
name|InterruptedIOException
block|{
if|if
condition|(
name|this
operator|.
name|closing
operator|.
name|get
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|NotServingRegionException
argument_list|(
name|regionInfo
operator|.
name|getRegionNameAsString
argument_list|()
operator|+
literal|" is closing"
argument_list|)
throw|;
block|}
name|lock
argument_list|(
name|lock
operator|.
name|readLock
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|this
operator|.
name|closed
operator|.
name|get
argument_list|()
condition|)
block|{
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
throw|throw
operator|new
name|NotServingRegionException
argument_list|(
name|regionInfo
operator|.
name|getRegionNameAsString
argument_list|()
operator|+
literal|" is closed"
argument_list|)
throw|;
block|}
block|}
comment|/**    * Closes the lock. This needs to be called in the finally block corresponding    * to the try block of #startRegionOperation    */
specifier|public
name|void
name|closeRegionOperation
parameter_list|()
block|{
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
comment|/**    * This method needs to be called before any public call that reads or    * modifies stores in bulk. It has to be called just before a try.    * #closeBulkRegionOperation needs to be called in the try's finally block    * Acquires a writelock and checks if the region is closing or closed.    * @throws NotServingRegionException when the region is closing or closed    * @throws RegionTooBusyException if failed to get the lock in time    * @throws InterruptedIOException if interrupted while waiting for a lock    */
specifier|private
name|void
name|startBulkRegionOperation
parameter_list|(
name|boolean
name|writeLockNeeded
parameter_list|)
throws|throws
name|NotServingRegionException
throws|,
name|RegionTooBusyException
throws|,
name|InterruptedIOException
block|{
if|if
condition|(
name|this
operator|.
name|closing
operator|.
name|get
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|NotServingRegionException
argument_list|(
name|regionInfo
operator|.
name|getRegionNameAsString
argument_list|()
operator|+
literal|" is closing"
argument_list|)
throw|;
block|}
if|if
condition|(
name|writeLockNeeded
condition|)
name|lock
argument_list|(
name|lock
operator|.
name|writeLock
argument_list|()
argument_list|)
expr_stmt|;
else|else
name|lock
argument_list|(
name|lock
operator|.
name|readLock
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|this
operator|.
name|closed
operator|.
name|get
argument_list|()
condition|)
block|{
if|if
condition|(
name|writeLockNeeded
condition|)
name|lock
operator|.
name|writeLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
else|else
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
throw|throw
operator|new
name|NotServingRegionException
argument_list|(
name|regionInfo
operator|.
name|getRegionNameAsString
argument_list|()
operator|+
literal|" is closed"
argument_list|)
throw|;
block|}
block|}
comment|/**    * Closes the lock. This needs to be called in the finally block corresponding    * to the try block of #startRegionOperation    */
specifier|private
name|void
name|closeBulkRegionOperation
parameter_list|()
block|{
if|if
condition|(
name|lock
operator|.
name|writeLock
argument_list|()
operator|.
name|isHeldByCurrentThread
argument_list|()
condition|)
name|lock
operator|.
name|writeLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
else|else
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
comment|/**    * Update counters for numer of puts without wal and the size of possible data loss.    * These information are exposed by the region server metrics.    */
specifier|private
name|void
name|recordPutWithoutWal
parameter_list|(
specifier|final
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|List
argument_list|<
name|KeyValue
argument_list|>
argument_list|>
name|familyMap
parameter_list|)
block|{
name|numPutsWithoutWAL
operator|.
name|increment
argument_list|()
expr_stmt|;
if|if
condition|(
name|numPutsWithoutWAL
operator|.
name|get
argument_list|()
operator|<=
literal|1
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"writing data to region "
operator|+
name|this
operator|+
literal|" with WAL disabled. Data may be lost in the event of a crash."
argument_list|)
expr_stmt|;
block|}
name|long
name|putSize
init|=
literal|0
decl_stmt|;
for|for
control|(
name|List
argument_list|<
name|KeyValue
argument_list|>
name|edits
range|:
name|familyMap
operator|.
name|values
argument_list|()
control|)
block|{
for|for
control|(
name|KeyValue
name|kv
range|:
name|edits
control|)
block|{
name|putSize
operator|+=
name|kv
operator|.
name|getKeyLength
argument_list|()
operator|+
name|kv
operator|.
name|getValueLength
argument_list|()
expr_stmt|;
block|}
block|}
name|dataInMemoryWithoutWAL
operator|.
name|add
argument_list|(
name|putSize
argument_list|)
expr_stmt|;
block|}
specifier|private
name|void
name|lock
parameter_list|(
specifier|final
name|Lock
name|lock
parameter_list|)
throws|throws
name|RegionTooBusyException
throws|,
name|InterruptedIOException
block|{
name|lock
argument_list|(
name|lock
argument_list|,
literal|1
argument_list|)
expr_stmt|;
block|}
comment|/**    * Try to acquire a lock.  Throw RegionTooBusyException    * if failed to get the lock in time. Throw InterruptedIOException    * if interrupted while waiting for the lock.    */
specifier|private
name|void
name|lock
parameter_list|(
specifier|final
name|Lock
name|lock
parameter_list|,
specifier|final
name|int
name|multiplier
parameter_list|)
throws|throws
name|RegionTooBusyException
throws|,
name|InterruptedIOException
block|{
try|try
block|{
specifier|final
name|long
name|waitTime
init|=
name|Math
operator|.
name|min
argument_list|(
name|maxBusyWaitDuration
argument_list|,
name|busyWaitDuration
operator|*
name|Math
operator|.
name|min
argument_list|(
name|multiplier
argument_list|,
name|maxBusyWaitMultiplier
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|lock
operator|.
name|tryLock
argument_list|(
name|waitTime
argument_list|,
name|TimeUnit
operator|.
name|MILLISECONDS
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|RegionTooBusyException
argument_list|(
literal|"failed to get a lock in "
operator|+
name|waitTime
operator|+
literal|"ms"
argument_list|)
throw|;
block|}
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|ie
parameter_list|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Interrupted while waiting for a lock"
argument_list|)
expr_stmt|;
name|InterruptedIOException
name|iie
init|=
operator|new
name|InterruptedIOException
argument_list|()
decl_stmt|;
name|iie
operator|.
name|initCause
argument_list|(
name|ie
argument_list|)
expr_stmt|;
throw|throw
name|iie
throw|;
block|}
block|}
comment|/**    * Calls sync with the given transaction ID if the region's table is not    * deferring it.    * @param txid should sync up to which transaction    * @throws IOException If anything goes wrong with DFS    */
specifier|private
name|void
name|syncOrDefer
parameter_list|(
name|long
name|txid
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|this
operator|.
name|regionInfo
operator|.
name|isMetaRegion
argument_list|()
operator|||
operator|!
name|this
operator|.
name|htableDescriptor
operator|.
name|isDeferredLogFlush
argument_list|()
condition|)
block|{
name|this
operator|.
name|log
operator|.
name|sync
argument_list|(
name|txid
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * A mocked list implementaion - discards all updates.    */
specifier|private
specifier|static
specifier|final
name|List
argument_list|<
name|KeyValue
argument_list|>
name|MOCKED_LIST
init|=
operator|new
name|AbstractList
argument_list|<
name|KeyValue
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|void
name|add
parameter_list|(
name|int
name|index
parameter_list|,
name|KeyValue
name|element
parameter_list|)
block|{
comment|// do nothing
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|addAll
parameter_list|(
name|int
name|index
parameter_list|,
name|Collection
argument_list|<
name|?
extends|extends
name|KeyValue
argument_list|>
name|c
parameter_list|)
block|{
return|return
literal|false
return|;
comment|// this list is never changed as a result of an update
block|}
annotation|@
name|Override
specifier|public
name|KeyValue
name|get
parameter_list|(
name|int
name|index
parameter_list|)
block|{
throw|throw
operator|new
name|UnsupportedOperationException
argument_list|()
throw|;
block|}
annotation|@
name|Override
specifier|public
name|int
name|size
parameter_list|()
block|{
return|return
literal|0
return|;
block|}
block|}
decl_stmt|;
comment|/**    * Facility for dumping and compacting catalog tables.    * Only does catalog tables since these are only tables we for sure know    * schema on.  For usage run:    *<pre>    *   ./bin/hbase org.apache.hadoop.hbase.regionserver.HRegion    *</pre>    * @param args    * @throws IOException    */
specifier|public
specifier|static
name|void
name|main
parameter_list|(
name|String
index|[]
name|args
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|args
operator|.
name|length
operator|<
literal|1
condition|)
block|{
name|printUsageAndExit
argument_list|(
literal|null
argument_list|)
expr_stmt|;
block|}
name|boolean
name|majorCompact
init|=
literal|false
decl_stmt|;
if|if
condition|(
name|args
operator|.
name|length
operator|>
literal|1
condition|)
block|{
if|if
condition|(
operator|!
name|args
index|[
literal|1
index|]
operator|.
name|toLowerCase
argument_list|()
operator|.
name|startsWith
argument_list|(
literal|"major"
argument_list|)
condition|)
block|{
name|printUsageAndExit
argument_list|(
literal|"ERROR: Unrecognized option<"
operator|+
name|args
index|[
literal|1
index|]
operator|+
literal|">"
argument_list|)
expr_stmt|;
block|}
name|majorCompact
operator|=
literal|true
expr_stmt|;
block|}
specifier|final
name|Path
name|tableDir
init|=
operator|new
name|Path
argument_list|(
name|args
index|[
literal|0
index|]
argument_list|)
decl_stmt|;
specifier|final
name|Configuration
name|c
init|=
name|HBaseConfiguration
operator|.
name|create
argument_list|()
decl_stmt|;
specifier|final
name|FileSystem
name|fs
init|=
name|FileSystem
operator|.
name|get
argument_list|(
name|c
argument_list|)
decl_stmt|;
specifier|final
name|Path
name|logdir
init|=
operator|new
name|Path
argument_list|(
name|c
operator|.
name|get
argument_list|(
literal|"hbase.tmp.dir"
argument_list|)
argument_list|)
decl_stmt|;
specifier|final
name|String
name|logname
init|=
literal|"hlog"
operator|+
name|tableDir
operator|.
name|getName
argument_list|()
operator|+
name|EnvironmentEdgeManager
operator|.
name|currentTimeMillis
argument_list|()
decl_stmt|;
specifier|final
name|HLog
name|log
init|=
name|HLogFactory
operator|.
name|createHLog
argument_list|(
name|fs
argument_list|,
name|logdir
argument_list|,
name|logname
argument_list|,
name|c
argument_list|)
decl_stmt|;
try|try
block|{
name|processTable
argument_list|(
name|fs
argument_list|,
name|tableDir
argument_list|,
name|log
argument_list|,
name|c
argument_list|,
name|majorCompact
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|log
operator|.
name|close
argument_list|()
expr_stmt|;
comment|// TODO: is this still right?
name|BlockCache
name|bc
init|=
operator|new
name|CacheConfig
argument_list|(
name|c
argument_list|)
operator|.
name|getBlockCache
argument_list|()
decl_stmt|;
if|if
condition|(
name|bc
operator|!=
literal|null
condition|)
name|bc
operator|.
name|shutdown
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**    * Gets the latest sequence number that was read from storage when this region was opened.    */
specifier|public
name|long
name|getOpenSeqNum
parameter_list|()
block|{
return|return
name|this
operator|.
name|openSeqNum
return|;
block|}
comment|/**    * Listener class to enable callers of    * bulkLoadHFile() to perform any necessary    * pre/post processing of a given bulkload call    */
specifier|public
specifier|static
interface|interface
name|BulkLoadListener
block|{
comment|/**      * Called before an HFile is actually loaded      * @param family family being loaded to      * @param srcPath path of HFile      * @return final path to be used for actual loading      * @throws IOException      */
name|String
name|prepareBulkLoad
parameter_list|(
name|byte
index|[]
name|family
parameter_list|,
name|String
name|srcPath
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**      * Called after a successful HFile load      * @param family family being loaded to      * @param srcPath path of HFile      * @throws IOException      */
name|void
name|doneBulkLoad
parameter_list|(
name|byte
index|[]
name|family
parameter_list|,
name|String
name|srcPath
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**      * Called after a failed HFile load      * @param family family being loaded to      * @param srcPath path of HFile      * @throws IOException      */
name|void
name|failedBulkLoad
parameter_list|(
name|byte
index|[]
name|family
parameter_list|,
name|String
name|srcPath
parameter_list|)
throws|throws
name|IOException
function_decl|;
block|}
block|}
end_class

end_unit

