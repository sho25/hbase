begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/*  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
package|;
end_package

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HConstants
operator|.
name|REPLICATION_SCOPE_LOCAL
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|HStoreFile
operator|.
name|MAJOR_COMPACTION_KEY
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|CollectionUtils
operator|.
name|computeIfAbsent
import|;
end_import

begin_import
import|import
name|edu
operator|.
name|umd
operator|.
name|cs
operator|.
name|findbugs
operator|.
name|annotations
operator|.
name|Nullable
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|EOFException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|FileNotFoundException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|InterruptedIOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|lang
operator|.
name|reflect
operator|.
name|Constructor
import|;
end_import

begin_import
import|import
name|java
operator|.
name|nio
operator|.
name|ByteBuffer
import|;
end_import

begin_import
import|import
name|java
operator|.
name|nio
operator|.
name|charset
operator|.
name|StandardCharsets
import|;
end_import

begin_import
import|import
name|java
operator|.
name|text
operator|.
name|ParseException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|AbstractList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Arrays
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collection
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collections
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Iterator
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
operator|.
name|Entry
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|NavigableMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|NavigableSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Optional
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|RandomAccess
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Set
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|TreeMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|UUID
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|Callable
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|CompletionService
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ConcurrentHashMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ConcurrentMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ConcurrentSkipListMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ExecutionException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ExecutorCompletionService
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ExecutorService
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|Executors
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|Future
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|FutureTask
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ThreadFactory
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ThreadPoolExecutor
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|TimeUnit
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|TimeoutException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|atomic
operator|.
name|AtomicBoolean
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|atomic
operator|.
name|AtomicInteger
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|atomic
operator|.
name|LongAdder
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|locks
operator|.
name|Lock
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|locks
operator|.
name|ReadWriteLock
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|locks
operator|.
name|ReentrantReadWriteLock
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|function
operator|.
name|Function
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileStatus
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|LocatedFileStatus
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|Cell
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|CellBuilderType
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|CellComparator
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|CellComparatorImpl
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|CellScanner
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|CellUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|CompareOperator
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|CompoundConfiguration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|DoNotRetryIOException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|DroppedSnapshotException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|ExtendedCellBuilderFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HConstants
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HConstants
operator|.
name|OperationStatusCode
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HDFSBlocksDistribution
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|KeyValue
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|KeyValueUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|NamespaceDescriptor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|NotServingRegionException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|PrivateCellUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|RegionTooBusyException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|TableName
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|Tag
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|TagUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|UnknownScannerException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|Append
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|ColumnFamilyDescriptor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|CompactionState
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|Delete
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|Durability
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|Get
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|Increment
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|IsolationLevel
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|Mutation
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|PackagePrivateFieldAccessor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|Put
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|RegionInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|RegionInfoBuilder
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|RegionReplicaUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|Result
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|RowMutations
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|Scan
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|TableDescriptor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|TableDescriptorBuilder
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|conf
operator|.
name|ConfigurationManager
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|conf
operator|.
name|PropagatingConfigurationObserver
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|coprocessor
operator|.
name|RegionObserver
operator|.
name|MutationType
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|errorhandling
operator|.
name|ForeignExceptionSnare
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|exceptions
operator|.
name|FailedSanityCheckException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|exceptions
operator|.
name|TimeoutIOException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|exceptions
operator|.
name|UnknownProtocolException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|filter
operator|.
name|ByteArrayComparable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|filter
operator|.
name|FilterWrapper
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|filter
operator|.
name|IncompatibleFilterException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|HFileLink
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|HeapSize
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|TimeRange
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|hfile
operator|.
name|HFile
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|ipc
operator|.
name|CallerDisconnectedException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|ipc
operator|.
name|CoprocessorRpcUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|ipc
operator|.
name|RpcCall
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|ipc
operator|.
name|RpcServer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|monitoring
operator|.
name|MonitoredTask
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|monitoring
operator|.
name|TaskMonitor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|quotas
operator|.
name|RegionServerSpaceQuotaManager
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|MultiVersionConcurrencyControl
operator|.
name|WriteEntry
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|ScannerContext
operator|.
name|LimitScope
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|ScannerContext
operator|.
name|NextState
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|compactions
operator|.
name|CompactionContext
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|compactions
operator|.
name|CompactionLifeCycleTracker
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|throttle
operator|.
name|CompactionThroughputControllerFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|throttle
operator|.
name|NoLimitThroughputController
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|throttle
operator|.
name|StoreHotnessProtector
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|throttle
operator|.
name|ThroughputController
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|wal
operator|.
name|WALUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|security
operator|.
name|User
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|snapshot
operator|.
name|SnapshotDescriptionUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|snapshot
operator|.
name|SnapshotManifest
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|trace
operator|.
name|TraceUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|Bytes
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|CancelableProgressable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|ClassSize
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|CompressionTest
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|EncryptionTest
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|EnvironmentEdgeManager
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|FSUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|HashedBytes
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|NonceKey
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|Pair
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|ServerRegionReplicaUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|Threads
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|wal
operator|.
name|WAL
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|wal
operator|.
name|WALEdit
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|wal
operator|.
name|WALFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|wal
operator|.
name|WALKey
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|wal
operator|.
name|WALKeyImpl
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|wal
operator|.
name|WALSplitter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|wal
operator|.
name|WALSplitter
operator|.
name|MutationReplay
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|MultipleIOException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|StringUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|htrace
operator|.
name|core
operator|.
name|TraceScope
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|yetus
operator|.
name|audience
operator|.
name|InterfaceAudience
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|Logger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|LoggerFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hbase
operator|.
name|thirdparty
operator|.
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|annotations
operator|.
name|VisibleForTesting
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hbase
operator|.
name|thirdparty
operator|.
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Preconditions
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hbase
operator|.
name|thirdparty
operator|.
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|Lists
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hbase
operator|.
name|thirdparty
operator|.
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|Maps
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hbase
operator|.
name|thirdparty
operator|.
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|io
operator|.
name|Closeables
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hbase
operator|.
name|thirdparty
operator|.
name|com
operator|.
name|google
operator|.
name|protobuf
operator|.
name|Service
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hbase
operator|.
name|thirdparty
operator|.
name|com
operator|.
name|google
operator|.
name|protobuf
operator|.
name|TextFormat
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hbase
operator|.
name|thirdparty
operator|.
name|com
operator|.
name|google
operator|.
name|protobuf
operator|.
name|UnsafeByteOperations
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hbase
operator|.
name|thirdparty
operator|.
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|collections4
operator|.
name|CollectionUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|shaded
operator|.
name|protobuf
operator|.
name|ProtobufUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|shaded
operator|.
name|protobuf
operator|.
name|generated
operator|.
name|ClientProtos
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|shaded
operator|.
name|protobuf
operator|.
name|generated
operator|.
name|ClientProtos
operator|.
name|CoprocessorServiceCall
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|shaded
operator|.
name|protobuf
operator|.
name|generated
operator|.
name|ClusterStatusProtos
operator|.
name|RegionLoad
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|shaded
operator|.
name|protobuf
operator|.
name|generated
operator|.
name|ClusterStatusProtos
operator|.
name|StoreSequenceId
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|shaded
operator|.
name|protobuf
operator|.
name|generated
operator|.
name|SnapshotProtos
operator|.
name|SnapshotDescription
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|shaded
operator|.
name|protobuf
operator|.
name|generated
operator|.
name|WALProtos
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|shaded
operator|.
name|protobuf
operator|.
name|generated
operator|.
name|WALProtos
operator|.
name|CompactionDescriptor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|shaded
operator|.
name|protobuf
operator|.
name|generated
operator|.
name|WALProtos
operator|.
name|FlushDescriptor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|shaded
operator|.
name|protobuf
operator|.
name|generated
operator|.
name|WALProtos
operator|.
name|FlushDescriptor
operator|.
name|FlushAction
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|shaded
operator|.
name|protobuf
operator|.
name|generated
operator|.
name|WALProtos
operator|.
name|FlushDescriptor
operator|.
name|StoreFlushDescriptor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|shaded
operator|.
name|protobuf
operator|.
name|generated
operator|.
name|WALProtos
operator|.
name|RegionEventDescriptor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|shaded
operator|.
name|protobuf
operator|.
name|generated
operator|.
name|WALProtos
operator|.
name|RegionEventDescriptor
operator|.
name|EventType
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|shaded
operator|.
name|protobuf
operator|.
name|generated
operator|.
name|WALProtos
operator|.
name|StoreDescriptor
import|;
end_import

begin_comment
comment|/**  * Regions store data for a certain region of a table.  It stores all columns  * for each row. A given table consists of one or more Regions.  *  *<p>An Region is defined by its table and its key extent.  *  *<p>Locking at the Region level serves only one purpose: preventing the  * region from being closed (and consequently split) while other operations  * are ongoing. Each row level operation obtains both a row lock and a region  * read lock for the duration of the operation. While a scanner is being  * constructed, getScanner holds a read lock. If the scanner is successfully  * constructed, it holds a read lock until it is closed. A close takes out a  * write lock and consequently will block for ongoing operations and will block  * new operations from starting while the close is in progress.  */
end_comment

begin_class
annotation|@
name|SuppressWarnings
argument_list|(
literal|"deprecation"
argument_list|)
annotation|@
name|InterfaceAudience
operator|.
name|Private
specifier|public
class|class
name|HRegion
implements|implements
name|HeapSize
implements|,
name|PropagatingConfigurationObserver
implements|,
name|Region
block|{
specifier|private
specifier|static
specifier|final
name|Logger
name|LOG
init|=
name|LoggerFactory
operator|.
name|getLogger
argument_list|(
name|HRegion
operator|.
name|class
argument_list|)
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|String
name|LOAD_CFS_ON_DEMAND_CONFIG_KEY
init|=
literal|"hbase.hregion.scan.loadColumnFamiliesOnDemand"
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|String
name|HBASE_MAX_CELL_SIZE_KEY
init|=
literal|"hbase.server.keyvalue.maxsize"
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|int
name|DEFAULT_MAX_CELL_SIZE
init|=
literal|10485760
decl_stmt|;
comment|/**    * This is the global default value for durability. All tables/mutations not    * defining a durability or using USE_DEFAULT will default to this value.    */
specifier|private
specifier|static
specifier|final
name|Durability
name|DEFAULT_DURABILITY
init|=
name|Durability
operator|.
name|SYNC_WAL
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|String
name|HBASE_REGIONSERVER_MINIBATCH_SIZE
init|=
literal|"hbase.regionserver.minibatch.size"
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|int
name|DEFAULT_HBASE_REGIONSERVER_MINIBATCH_SIZE
init|=
literal|20000
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|String
name|WAL_HSYNC_CONF_KEY
init|=
literal|"hbase.wal.hsync"
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|boolean
name|DEFAULT_WAL_HSYNC
init|=
literal|false
decl_stmt|;
specifier|final
name|AtomicBoolean
name|closed
init|=
operator|new
name|AtomicBoolean
argument_list|(
literal|false
argument_list|)
decl_stmt|;
comment|/* Closing can take some time; use the closing flag if there is stuff we don't    * want to do while in closing state; e.g. like offer this region up to the    * master as a region to close if the carrying regionserver is overloaded.    * Once set, it is never cleared.    */
specifier|final
name|AtomicBoolean
name|closing
init|=
operator|new
name|AtomicBoolean
argument_list|(
literal|false
argument_list|)
decl_stmt|;
comment|/**    * The max sequence id of flushed data on this region. There is no edit in memory that is    * less that this sequence id.    */
specifier|private
specifier|volatile
name|long
name|maxFlushedSeqId
init|=
name|HConstants
operator|.
name|NO_SEQNUM
decl_stmt|;
comment|/**    * Record the sequence id of last flush operation. Can be in advance of    * {@link #maxFlushedSeqId} when flushing a single column family. In this case,    * {@link #maxFlushedSeqId} will be older than the oldest edit in memory.    */
specifier|private
specifier|volatile
name|long
name|lastFlushOpSeqId
init|=
name|HConstants
operator|.
name|NO_SEQNUM
decl_stmt|;
comment|/**    * The sequence id of the last replayed open region event from the primary region. This is used    * to skip entries before this due to the possibility of replay edits coming out of order from    * replication.    */
specifier|protected
specifier|volatile
name|long
name|lastReplayedOpenRegionSeqId
init|=
operator|-
literal|1L
decl_stmt|;
specifier|protected
specifier|volatile
name|long
name|lastReplayedCompactionSeqId
init|=
operator|-
literal|1L
decl_stmt|;
comment|//////////////////////////////////////////////////////////////////////////////
comment|// Members
comment|//////////////////////////////////////////////////////////////////////////////
comment|// map from a locked row to the context for that lock including:
comment|// - CountDownLatch for threads waiting on that row
comment|// - the thread that owns the lock (allow reentrancy)
comment|// - reference count of (reentrant) locks held by the thread
comment|// - the row itself
specifier|private
specifier|final
name|ConcurrentHashMap
argument_list|<
name|HashedBytes
argument_list|,
name|RowLockContext
argument_list|>
name|lockedRows
init|=
operator|new
name|ConcurrentHashMap
argument_list|<>
argument_list|()
decl_stmt|;
specifier|protected
specifier|final
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|HStore
argument_list|>
name|stores
init|=
operator|new
name|ConcurrentSkipListMap
argument_list|<>
argument_list|(
name|Bytes
operator|.
name|BYTES_RAWCOMPARATOR
argument_list|)
decl_stmt|;
comment|// TODO: account for each registered handler in HeapSize computation
specifier|private
name|Map
argument_list|<
name|String
argument_list|,
name|com
operator|.
name|google
operator|.
name|protobuf
operator|.
name|Service
argument_list|>
name|coprocessorServiceHandlers
init|=
name|Maps
operator|.
name|newHashMap
argument_list|()
decl_stmt|;
comment|// Track data size in all memstores
specifier|private
specifier|final
name|MemStoreSizing
name|memStoreSizing
init|=
operator|new
name|ThreadSafeMemStoreSizing
argument_list|()
decl_stmt|;
specifier|private
specifier|final
name|RegionServicesForStores
name|regionServicesForStores
init|=
operator|new
name|RegionServicesForStores
argument_list|(
name|this
argument_list|)
decl_stmt|;
comment|// Debug possible data loss due to WAL off
specifier|final
name|LongAdder
name|numMutationsWithoutWAL
init|=
operator|new
name|LongAdder
argument_list|()
decl_stmt|;
specifier|final
name|LongAdder
name|dataInMemoryWithoutWAL
init|=
operator|new
name|LongAdder
argument_list|()
decl_stmt|;
comment|// Debug why CAS operations are taking a while.
specifier|final
name|LongAdder
name|checkAndMutateChecksPassed
init|=
operator|new
name|LongAdder
argument_list|()
decl_stmt|;
specifier|final
name|LongAdder
name|checkAndMutateChecksFailed
init|=
operator|new
name|LongAdder
argument_list|()
decl_stmt|;
comment|// Number of requests
comment|// Count rows for scan
specifier|final
name|LongAdder
name|readRequestsCount
init|=
operator|new
name|LongAdder
argument_list|()
decl_stmt|;
specifier|final
name|LongAdder
name|cpRequestsCount
init|=
operator|new
name|LongAdder
argument_list|()
decl_stmt|;
specifier|final
name|LongAdder
name|filteredReadRequestsCount
init|=
operator|new
name|LongAdder
argument_list|()
decl_stmt|;
comment|// Count rows for multi row mutations
specifier|final
name|LongAdder
name|writeRequestsCount
init|=
operator|new
name|LongAdder
argument_list|()
decl_stmt|;
comment|// Number of requests blocked by memstore size.
specifier|private
specifier|final
name|LongAdder
name|blockedRequestsCount
init|=
operator|new
name|LongAdder
argument_list|()
decl_stmt|;
comment|// Compaction LongAdders
specifier|final
name|LongAdder
name|compactionsFinished
init|=
operator|new
name|LongAdder
argument_list|()
decl_stmt|;
specifier|final
name|LongAdder
name|compactionsFailed
init|=
operator|new
name|LongAdder
argument_list|()
decl_stmt|;
specifier|final
name|LongAdder
name|compactionNumFilesCompacted
init|=
operator|new
name|LongAdder
argument_list|()
decl_stmt|;
specifier|final
name|LongAdder
name|compactionNumBytesCompacted
init|=
operator|new
name|LongAdder
argument_list|()
decl_stmt|;
specifier|final
name|LongAdder
name|compactionsQueued
init|=
operator|new
name|LongAdder
argument_list|()
decl_stmt|;
specifier|final
name|LongAdder
name|flushesQueued
init|=
operator|new
name|LongAdder
argument_list|()
decl_stmt|;
specifier|private
specifier|final
name|WAL
name|wal
decl_stmt|;
specifier|private
specifier|final
name|HRegionFileSystem
name|fs
decl_stmt|;
specifier|protected
specifier|final
name|Configuration
name|conf
decl_stmt|;
specifier|private
specifier|final
name|Configuration
name|baseConf
decl_stmt|;
specifier|private
specifier|final
name|int
name|rowLockWaitDuration
decl_stmt|;
specifier|static
specifier|final
name|int
name|DEFAULT_ROWLOCK_WAIT_DURATION
init|=
literal|30000
decl_stmt|;
comment|// The internal wait duration to acquire a lock before read/update
comment|// from the region. It is not per row. The purpose of this wait time
comment|// is to avoid waiting a long time while the region is busy, so that
comment|// we can release the IPC handler soon enough to improve the
comment|// availability of the region server. It can be adjusted by
comment|// tuning configuration "hbase.busy.wait.duration".
specifier|final
name|long
name|busyWaitDuration
decl_stmt|;
specifier|static
specifier|final
name|long
name|DEFAULT_BUSY_WAIT_DURATION
init|=
name|HConstants
operator|.
name|DEFAULT_HBASE_RPC_TIMEOUT
decl_stmt|;
comment|// If updating multiple rows in one call, wait longer,
comment|// i.e. waiting for busyWaitDuration * # of rows. However,
comment|// we can limit the max multiplier.
specifier|final
name|int
name|maxBusyWaitMultiplier
decl_stmt|;
comment|// Max busy wait duration. There is no point to wait longer than the RPC
comment|// purge timeout, when a RPC call will be terminated by the RPC engine.
specifier|final
name|long
name|maxBusyWaitDuration
decl_stmt|;
comment|// Max cell size. If nonzero, the maximum allowed size for any given cell
comment|// in bytes
specifier|final
name|long
name|maxCellSize
decl_stmt|;
comment|// Number of mutations for minibatch processing.
specifier|private
specifier|final
name|int
name|miniBatchSize
decl_stmt|;
comment|// negative number indicates infinite timeout
specifier|static
specifier|final
name|long
name|DEFAULT_ROW_PROCESSOR_TIMEOUT
init|=
literal|60
operator|*
literal|1000L
decl_stmt|;
specifier|final
name|ExecutorService
name|rowProcessorExecutor
init|=
name|Executors
operator|.
name|newCachedThreadPool
argument_list|()
decl_stmt|;
specifier|private
specifier|final
name|ConcurrentHashMap
argument_list|<
name|RegionScanner
argument_list|,
name|Long
argument_list|>
name|scannerReadPoints
decl_stmt|;
comment|/**    * The sequence ID that was enLongAddered when this region was opened.    */
specifier|private
name|long
name|openSeqNum
init|=
name|HConstants
operator|.
name|NO_SEQNUM
decl_stmt|;
comment|/**    * The default setting for whether to enable on-demand CF loading for    * scan requests to this region. Requests can override it.    */
specifier|private
name|boolean
name|isLoadingCfsOnDemandDefault
init|=
literal|false
decl_stmt|;
specifier|private
specifier|final
name|AtomicInteger
name|majorInProgress
init|=
operator|new
name|AtomicInteger
argument_list|(
literal|0
argument_list|)
decl_stmt|;
specifier|private
specifier|final
name|AtomicInteger
name|minorInProgress
init|=
operator|new
name|AtomicInteger
argument_list|(
literal|0
argument_list|)
decl_stmt|;
comment|//
comment|// Context: During replay we want to ensure that we do not lose any data. So, we
comment|// have to be conservative in how we replay wals. For each store, we calculate
comment|// the maxSeqId up to which the store was flushed. And, skip the edits which
comment|// are equal to or lower than maxSeqId for each store.
comment|// The following map is populated when opening the region
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|Long
argument_list|>
name|maxSeqIdInStores
init|=
operator|new
name|TreeMap
argument_list|<>
argument_list|(
name|Bytes
operator|.
name|BYTES_COMPARATOR
argument_list|)
decl_stmt|;
comment|/** Saved state from replaying prepare flush cache */
specifier|private
name|PrepareFlushResult
name|prepareFlushResult
init|=
literal|null
decl_stmt|;
specifier|private
specifier|volatile
name|Optional
argument_list|<
name|ConfigurationManager
argument_list|>
name|configurationManager
decl_stmt|;
comment|// Used for testing.
specifier|private
specifier|volatile
name|Long
name|timeoutForWriteLock
init|=
literal|null
decl_stmt|;
comment|/**    * @return The smallest mvcc readPoint across all the scanners in this    * region. Writes older than this readPoint, are included in every    * read operation.    */
specifier|public
name|long
name|getSmallestReadPoint
parameter_list|()
block|{
name|long
name|minimumReadPoint
decl_stmt|;
comment|// We need to ensure that while we are calculating the smallestReadPoint
comment|// no new RegionScanners can grab a readPoint that we are unaware of.
comment|// We achieve this by synchronizing on the scannerReadPoints object.
synchronized|synchronized
init|(
name|scannerReadPoints
init|)
block|{
name|minimumReadPoint
operator|=
name|mvcc
operator|.
name|getReadPoint
argument_list|()
expr_stmt|;
for|for
control|(
name|Long
name|readPoint
range|:
name|this
operator|.
name|scannerReadPoints
operator|.
name|values
argument_list|()
control|)
block|{
if|if
condition|(
name|readPoint
operator|<
name|minimumReadPoint
condition|)
block|{
name|minimumReadPoint
operator|=
name|readPoint
expr_stmt|;
block|}
block|}
block|}
return|return
name|minimumReadPoint
return|;
block|}
comment|/*    * Data structure of write state flags used coordinating flushes,    * compactions and closes.    */
specifier|static
class|class
name|WriteState
block|{
comment|// Set while a memstore flush is happening.
specifier|volatile
name|boolean
name|flushing
init|=
literal|false
decl_stmt|;
comment|// Set when a flush has been requested.
specifier|volatile
name|boolean
name|flushRequested
init|=
literal|false
decl_stmt|;
comment|// Number of compactions running.
name|AtomicInteger
name|compacting
init|=
operator|new
name|AtomicInteger
argument_list|(
literal|0
argument_list|)
decl_stmt|;
comment|// Gets set in close. If set, cannot compact or flush again.
specifier|volatile
name|boolean
name|writesEnabled
init|=
literal|true
decl_stmt|;
comment|// Set if region is read-only
specifier|volatile
name|boolean
name|readOnly
init|=
literal|false
decl_stmt|;
comment|// whether the reads are enabled. This is different than readOnly, because readOnly is
comment|// static in the lifetime of the region, while readsEnabled is dynamic
specifier|volatile
name|boolean
name|readsEnabled
init|=
literal|true
decl_stmt|;
comment|/**      * Set flags that make this region read-only.      *      * @param onOff flip value for region r/o setting      */
specifier|synchronized
name|void
name|setReadOnly
parameter_list|(
specifier|final
name|boolean
name|onOff
parameter_list|)
block|{
name|this
operator|.
name|writesEnabled
operator|=
operator|!
name|onOff
expr_stmt|;
name|this
operator|.
name|readOnly
operator|=
name|onOff
expr_stmt|;
block|}
name|boolean
name|isReadOnly
parameter_list|()
block|{
return|return
name|this
operator|.
name|readOnly
return|;
block|}
name|boolean
name|isFlushRequested
parameter_list|()
block|{
return|return
name|this
operator|.
name|flushRequested
return|;
block|}
name|void
name|setReadsEnabled
parameter_list|(
name|boolean
name|readsEnabled
parameter_list|)
block|{
name|this
operator|.
name|readsEnabled
operator|=
name|readsEnabled
expr_stmt|;
block|}
specifier|static
specifier|final
name|long
name|HEAP_SIZE
init|=
name|ClassSize
operator|.
name|align
argument_list|(
name|ClassSize
operator|.
name|OBJECT
operator|+
literal|5
operator|*
name|Bytes
operator|.
name|SIZEOF_BOOLEAN
argument_list|)
decl_stmt|;
block|}
comment|/**    * Objects from this class are created when flushing to describe all the different states that    * that method ends up in. The Result enum describes those states. The sequence id should only    * be specified if the flush was successful, and the failure message should only be specified    * if it didn't flush.    */
specifier|public
specifier|static
class|class
name|FlushResultImpl
implements|implements
name|FlushResult
block|{
specifier|final
name|Result
name|result
decl_stmt|;
specifier|final
name|String
name|failureReason
decl_stmt|;
specifier|final
name|long
name|flushSequenceId
decl_stmt|;
specifier|final
name|boolean
name|wroteFlushWalMarker
decl_stmt|;
comment|/**      * Convenience constructor to use when the flush is successful, the failure message is set to      * null.      * @param result Expecting FLUSHED_NO_COMPACTION_NEEDED or FLUSHED_COMPACTION_NEEDED.      * @param flushSequenceId Generated sequence id that comes right after the edits in the      *                        memstores.      */
name|FlushResultImpl
parameter_list|(
name|Result
name|result
parameter_list|,
name|long
name|flushSequenceId
parameter_list|)
block|{
name|this
argument_list|(
name|result
argument_list|,
name|flushSequenceId
argument_list|,
literal|null
argument_list|,
literal|false
argument_list|)
expr_stmt|;
assert|assert
name|result
operator|==
name|Result
operator|.
name|FLUSHED_NO_COMPACTION_NEEDED
operator|||
name|result
operator|==
name|Result
operator|.
name|FLUSHED_COMPACTION_NEEDED
assert|;
block|}
comment|/**      * Convenience constructor to use when we cannot flush.      * @param result Expecting CANNOT_FLUSH_MEMSTORE_EMPTY or CANNOT_FLUSH.      * @param failureReason Reason why we couldn't flush.      */
name|FlushResultImpl
parameter_list|(
name|Result
name|result
parameter_list|,
name|String
name|failureReason
parameter_list|,
name|boolean
name|wroteFlushMarker
parameter_list|)
block|{
name|this
argument_list|(
name|result
argument_list|,
operator|-
literal|1
argument_list|,
name|failureReason
argument_list|,
name|wroteFlushMarker
argument_list|)
expr_stmt|;
assert|assert
name|result
operator|==
name|Result
operator|.
name|CANNOT_FLUSH_MEMSTORE_EMPTY
operator|||
name|result
operator|==
name|Result
operator|.
name|CANNOT_FLUSH
assert|;
block|}
comment|/**      * Constructor with all the parameters.      * @param result Any of the Result.      * @param flushSequenceId Generated sequence id if the memstores were flushed else -1.      * @param failureReason Reason why we couldn't flush, or null.      */
name|FlushResultImpl
parameter_list|(
name|Result
name|result
parameter_list|,
name|long
name|flushSequenceId
parameter_list|,
name|String
name|failureReason
parameter_list|,
name|boolean
name|wroteFlushMarker
parameter_list|)
block|{
name|this
operator|.
name|result
operator|=
name|result
expr_stmt|;
name|this
operator|.
name|flushSequenceId
operator|=
name|flushSequenceId
expr_stmt|;
name|this
operator|.
name|failureReason
operator|=
name|failureReason
expr_stmt|;
name|this
operator|.
name|wroteFlushWalMarker
operator|=
name|wroteFlushMarker
expr_stmt|;
block|}
comment|/**      * Convenience method, the equivalent of checking if result is      * FLUSHED_NO_COMPACTION_NEEDED or FLUSHED_NO_COMPACTION_NEEDED.      * @return true if the memstores were flushed, else false.      */
annotation|@
name|Override
specifier|public
name|boolean
name|isFlushSucceeded
parameter_list|()
block|{
return|return
name|result
operator|==
name|Result
operator|.
name|FLUSHED_NO_COMPACTION_NEEDED
operator|||
name|result
operator|==
name|Result
operator|.
name|FLUSHED_COMPACTION_NEEDED
return|;
block|}
comment|/**      * Convenience method, the equivalent of checking if result is FLUSHED_COMPACTION_NEEDED.      * @return True if the flush requested a compaction, else false (doesn't even mean it flushed).      */
annotation|@
name|Override
specifier|public
name|boolean
name|isCompactionNeeded
parameter_list|()
block|{
return|return
name|result
operator|==
name|Result
operator|.
name|FLUSHED_COMPACTION_NEEDED
return|;
block|}
annotation|@
name|Override
specifier|public
name|String
name|toString
parameter_list|()
block|{
return|return
operator|new
name|StringBuilder
argument_list|()
operator|.
name|append
argument_list|(
literal|"flush result:"
argument_list|)
operator|.
name|append
argument_list|(
name|result
argument_list|)
operator|.
name|append
argument_list|(
literal|", "
argument_list|)
operator|.
name|append
argument_list|(
literal|"failureReason:"
argument_list|)
operator|.
name|append
argument_list|(
name|failureReason
argument_list|)
operator|.
name|append
argument_list|(
literal|","
argument_list|)
operator|.
name|append
argument_list|(
literal|"flush seq id"
argument_list|)
operator|.
name|append
argument_list|(
name|flushSequenceId
argument_list|)
operator|.
name|toString
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|Result
name|getResult
parameter_list|()
block|{
return|return
name|result
return|;
block|}
block|}
comment|/** A result object from prepare flush cache stage */
annotation|@
name|VisibleForTesting
specifier|static
class|class
name|PrepareFlushResult
block|{
specifier|final
name|FlushResultImpl
name|result
decl_stmt|;
comment|// indicating a failure result from prepare
specifier|final
name|TreeMap
argument_list|<
name|byte
index|[]
argument_list|,
name|StoreFlushContext
argument_list|>
name|storeFlushCtxs
decl_stmt|;
specifier|final
name|TreeMap
argument_list|<
name|byte
index|[]
argument_list|,
name|List
argument_list|<
name|Path
argument_list|>
argument_list|>
name|committedFiles
decl_stmt|;
specifier|final
name|TreeMap
argument_list|<
name|byte
index|[]
argument_list|,
name|MemStoreSize
argument_list|>
name|storeFlushableSize
decl_stmt|;
specifier|final
name|long
name|startTime
decl_stmt|;
specifier|final
name|long
name|flushOpSeqId
decl_stmt|;
specifier|final
name|long
name|flushedSeqId
decl_stmt|;
specifier|final
name|MemStoreSizing
name|totalFlushableSize
decl_stmt|;
comment|/** Constructs an early exit case */
name|PrepareFlushResult
parameter_list|(
name|FlushResultImpl
name|result
parameter_list|,
name|long
name|flushSeqId
parameter_list|)
block|{
name|this
argument_list|(
name|result
argument_list|,
literal|null
argument_list|,
literal|null
argument_list|,
literal|null
argument_list|,
name|Math
operator|.
name|max
argument_list|(
literal|0
argument_list|,
name|flushSeqId
argument_list|)
argument_list|,
literal|0
argument_list|,
literal|0
argument_list|,
name|MemStoreSizing
operator|.
name|DUD
argument_list|)
expr_stmt|;
block|}
comment|/** Constructs a successful prepare flush result */
name|PrepareFlushResult
parameter_list|(
name|TreeMap
argument_list|<
name|byte
index|[]
argument_list|,
name|StoreFlushContext
argument_list|>
name|storeFlushCtxs
parameter_list|,
name|TreeMap
argument_list|<
name|byte
index|[]
argument_list|,
name|List
argument_list|<
name|Path
argument_list|>
argument_list|>
name|committedFiles
parameter_list|,
name|TreeMap
argument_list|<
name|byte
index|[]
argument_list|,
name|MemStoreSize
argument_list|>
name|storeFlushableSize
parameter_list|,
name|long
name|startTime
parameter_list|,
name|long
name|flushSeqId
parameter_list|,
name|long
name|flushedSeqId
parameter_list|,
name|MemStoreSizing
name|totalFlushableSize
parameter_list|)
block|{
name|this
argument_list|(
literal|null
argument_list|,
name|storeFlushCtxs
argument_list|,
name|committedFiles
argument_list|,
name|storeFlushableSize
argument_list|,
name|startTime
argument_list|,
name|flushSeqId
argument_list|,
name|flushedSeqId
argument_list|,
name|totalFlushableSize
argument_list|)
expr_stmt|;
block|}
specifier|private
name|PrepareFlushResult
parameter_list|(
name|FlushResultImpl
name|result
parameter_list|,
name|TreeMap
argument_list|<
name|byte
index|[]
argument_list|,
name|StoreFlushContext
argument_list|>
name|storeFlushCtxs
parameter_list|,
name|TreeMap
argument_list|<
name|byte
index|[]
argument_list|,
name|List
argument_list|<
name|Path
argument_list|>
argument_list|>
name|committedFiles
parameter_list|,
name|TreeMap
argument_list|<
name|byte
index|[]
argument_list|,
name|MemStoreSize
argument_list|>
name|storeFlushableSize
parameter_list|,
name|long
name|startTime
parameter_list|,
name|long
name|flushSeqId
parameter_list|,
name|long
name|flushedSeqId
parameter_list|,
name|MemStoreSizing
name|totalFlushableSize
parameter_list|)
block|{
name|this
operator|.
name|result
operator|=
name|result
expr_stmt|;
name|this
operator|.
name|storeFlushCtxs
operator|=
name|storeFlushCtxs
expr_stmt|;
name|this
operator|.
name|committedFiles
operator|=
name|committedFiles
expr_stmt|;
name|this
operator|.
name|storeFlushableSize
operator|=
name|storeFlushableSize
expr_stmt|;
name|this
operator|.
name|startTime
operator|=
name|startTime
expr_stmt|;
name|this
operator|.
name|flushOpSeqId
operator|=
name|flushSeqId
expr_stmt|;
name|this
operator|.
name|flushedSeqId
operator|=
name|flushedSeqId
expr_stmt|;
name|this
operator|.
name|totalFlushableSize
operator|=
name|totalFlushableSize
expr_stmt|;
block|}
specifier|public
name|FlushResult
name|getResult
parameter_list|()
block|{
return|return
name|this
operator|.
name|result
return|;
block|}
block|}
comment|/**    * A class that tracks exceptions that have been observed in one batch. Not thread safe.    */
specifier|static
class|class
name|ObservedExceptionsInBatch
block|{
specifier|private
name|boolean
name|wrongRegion
init|=
literal|false
decl_stmt|;
specifier|private
name|boolean
name|failedSanityCheck
init|=
literal|false
decl_stmt|;
specifier|private
name|boolean
name|wrongFamily
init|=
literal|false
decl_stmt|;
comment|/**      * @return If a {@link WrongRegionException} has been observed.      */
name|boolean
name|hasSeenWrongRegion
parameter_list|()
block|{
return|return
name|wrongRegion
return|;
block|}
comment|/**      * Records that a {@link WrongRegionException} has been observed.      */
name|void
name|sawWrongRegion
parameter_list|()
block|{
name|wrongRegion
operator|=
literal|true
expr_stmt|;
block|}
comment|/**      * @return If a {@link FailedSanityCheckException} has been observed.      */
name|boolean
name|hasSeenFailedSanityCheck
parameter_list|()
block|{
return|return
name|failedSanityCheck
return|;
block|}
comment|/**      * Records that a {@link FailedSanityCheckException} has been observed.      */
name|void
name|sawFailedSanityCheck
parameter_list|()
block|{
name|failedSanityCheck
operator|=
literal|true
expr_stmt|;
block|}
comment|/**      * @return If a {@link NoSuchColumnFamilyException} has been observed.      */
name|boolean
name|hasSeenNoSuchFamily
parameter_list|()
block|{
return|return
name|wrongFamily
return|;
block|}
comment|/**      * Records that a {@link NoSuchColumnFamilyException} has been observed.      */
name|void
name|sawNoSuchFamily
parameter_list|()
block|{
name|wrongFamily
operator|=
literal|true
expr_stmt|;
block|}
block|}
specifier|final
name|WriteState
name|writestate
init|=
operator|new
name|WriteState
argument_list|()
decl_stmt|;
name|long
name|memstoreFlushSize
decl_stmt|;
specifier|final
name|long
name|timestampSlop
decl_stmt|;
specifier|final
name|long
name|rowProcessorTimeout
decl_stmt|;
comment|// Last flush time for each Store. Useful when we are flushing for each column
specifier|private
specifier|final
name|ConcurrentMap
argument_list|<
name|HStore
argument_list|,
name|Long
argument_list|>
name|lastStoreFlushTimeMap
init|=
operator|new
name|ConcurrentHashMap
argument_list|<>
argument_list|()
decl_stmt|;
specifier|final
name|RegionServerServices
name|rsServices
decl_stmt|;
specifier|private
name|RegionServerAccounting
name|rsAccounting
decl_stmt|;
specifier|private
name|long
name|flushCheckInterval
decl_stmt|;
comment|// flushPerChanges is to prevent too many changes in memstore
specifier|private
name|long
name|flushPerChanges
decl_stmt|;
specifier|private
name|long
name|blockingMemStoreSize
decl_stmt|;
comment|// Used to guard closes
specifier|final
name|ReentrantReadWriteLock
name|lock
init|=
operator|new
name|ReentrantReadWriteLock
argument_list|()
decl_stmt|;
comment|// Stop updates lock
specifier|private
specifier|final
name|ReentrantReadWriteLock
name|updatesLock
init|=
operator|new
name|ReentrantReadWriteLock
argument_list|()
decl_stmt|;
specifier|private
name|boolean
name|splitRequest
decl_stmt|;
specifier|private
name|byte
index|[]
name|explicitSplitPoint
init|=
literal|null
decl_stmt|;
specifier|private
specifier|final
name|MultiVersionConcurrencyControl
name|mvcc
init|=
operator|new
name|MultiVersionConcurrencyControl
argument_list|()
decl_stmt|;
comment|// Coprocessor host
specifier|private
name|RegionCoprocessorHost
name|coprocessorHost
decl_stmt|;
specifier|private
name|TableDescriptor
name|htableDescriptor
init|=
literal|null
decl_stmt|;
specifier|private
name|RegionSplitPolicy
name|splitPolicy
decl_stmt|;
specifier|private
name|FlushPolicy
name|flushPolicy
decl_stmt|;
specifier|private
specifier|final
name|MetricsRegion
name|metricsRegion
decl_stmt|;
specifier|private
specifier|final
name|MetricsRegionWrapperImpl
name|metricsRegionWrapper
decl_stmt|;
specifier|private
specifier|final
name|Durability
name|regionDurability
decl_stmt|;
specifier|private
specifier|final
name|boolean
name|regionStatsEnabled
decl_stmt|;
comment|// Stores the replication scope of the various column families of the table
comment|// that has non-default scope
specifier|private
specifier|final
name|NavigableMap
argument_list|<
name|byte
index|[]
argument_list|,
name|Integer
argument_list|>
name|replicationScope
init|=
operator|new
name|TreeMap
argument_list|<>
argument_list|(
name|Bytes
operator|.
name|BYTES_COMPARATOR
argument_list|)
decl_stmt|;
specifier|private
specifier|final
name|StoreHotnessProtector
name|storeHotnessProtector
decl_stmt|;
comment|/**    * HRegion constructor. This constructor should only be used for testing and    * extensions.  Instances of HRegion should be instantiated with the    * {@link HRegion#createHRegion} or {@link HRegion#openHRegion} method.    *    * @param tableDir qualified path of directory where region should be located,    * usually the table directory.    * @param wal The WAL is the outbound log for any updates to the HRegion    * The wal file is a logfile from the previous execution that's    * custom-computed for this HRegion. The HRegionServer computes and sorts the    * appropriate wal info for this HRegion. If there is a previous wal file    * (implying that the HRegion has been written-to before), then read it from    * the supplied path.    * @param fs is the filesystem.    * @param confParam is global configuration settings.    * @param regionInfo - RegionInfo that describes the region    * is new), then read them from the supplied path.    * @param htd the table descriptor    * @param rsServices reference to {@link RegionServerServices} or null    * @deprecated Use other constructors.    */
annotation|@
name|Deprecated
annotation|@
name|VisibleForTesting
specifier|public
name|HRegion
parameter_list|(
specifier|final
name|Path
name|tableDir
parameter_list|,
specifier|final
name|WAL
name|wal
parameter_list|,
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Configuration
name|confParam
parameter_list|,
specifier|final
name|RegionInfo
name|regionInfo
parameter_list|,
specifier|final
name|TableDescriptor
name|htd
parameter_list|,
specifier|final
name|RegionServerServices
name|rsServices
parameter_list|)
block|{
name|this
argument_list|(
operator|new
name|HRegionFileSystem
argument_list|(
name|confParam
argument_list|,
name|fs
argument_list|,
name|tableDir
argument_list|,
name|regionInfo
argument_list|)
argument_list|,
name|wal
argument_list|,
name|confParam
argument_list|,
name|htd
argument_list|,
name|rsServices
argument_list|)
expr_stmt|;
block|}
comment|/**    * HRegion constructor. This constructor should only be used for testing and    * extensions.  Instances of HRegion should be instantiated with the    * {@link HRegion#createHRegion} or {@link HRegion#openHRegion} method.    *    * @param fs is the filesystem.    * @param wal The WAL is the outbound log for any updates to the HRegion    * The wal file is a logfile from the previous execution that's    * custom-computed for this HRegion. The HRegionServer computes and sorts the    * appropriate wal info for this HRegion. If there is a previous wal file    * (implying that the HRegion has been written-to before), then read it from    * the supplied path.    * @param confParam is global configuration settings.    * @param htd the table descriptor    * @param rsServices reference to {@link RegionServerServices} or null    */
specifier|public
name|HRegion
parameter_list|(
specifier|final
name|HRegionFileSystem
name|fs
parameter_list|,
specifier|final
name|WAL
name|wal
parameter_list|,
specifier|final
name|Configuration
name|confParam
parameter_list|,
specifier|final
name|TableDescriptor
name|htd
parameter_list|,
specifier|final
name|RegionServerServices
name|rsServices
parameter_list|)
block|{
if|if
condition|(
name|htd
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"Need table descriptor"
argument_list|)
throw|;
block|}
if|if
condition|(
name|confParam
operator|instanceof
name|CompoundConfiguration
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"Need original base configuration"
argument_list|)
throw|;
block|}
name|this
operator|.
name|wal
operator|=
name|wal
expr_stmt|;
name|this
operator|.
name|fs
operator|=
name|fs
expr_stmt|;
comment|// 'conf' renamed to 'confParam' b/c we use this.conf in the constructor
name|this
operator|.
name|baseConf
operator|=
name|confParam
expr_stmt|;
name|this
operator|.
name|conf
operator|=
operator|new
name|CompoundConfiguration
argument_list|()
operator|.
name|add
argument_list|(
name|confParam
argument_list|)
operator|.
name|addBytesMap
argument_list|(
name|htd
operator|.
name|getValues
argument_list|()
argument_list|)
expr_stmt|;
name|this
operator|.
name|flushCheckInterval
operator|=
name|conf
operator|.
name|getInt
argument_list|(
name|MEMSTORE_PERIODIC_FLUSH_INTERVAL
argument_list|,
name|DEFAULT_CACHE_FLUSH_INTERVAL
argument_list|)
expr_stmt|;
name|this
operator|.
name|flushPerChanges
operator|=
name|conf
operator|.
name|getLong
argument_list|(
name|MEMSTORE_FLUSH_PER_CHANGES
argument_list|,
name|DEFAULT_FLUSH_PER_CHANGES
argument_list|)
expr_stmt|;
if|if
condition|(
name|this
operator|.
name|flushPerChanges
operator|>
name|MAX_FLUSH_PER_CHANGES
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
name|MEMSTORE_FLUSH_PER_CHANGES
operator|+
literal|" can not exceed "
operator|+
name|MAX_FLUSH_PER_CHANGES
argument_list|)
throw|;
block|}
name|this
operator|.
name|rowLockWaitDuration
operator|=
name|conf
operator|.
name|getInt
argument_list|(
literal|"hbase.rowlock.wait.duration"
argument_list|,
name|DEFAULT_ROWLOCK_WAIT_DURATION
argument_list|)
expr_stmt|;
name|this
operator|.
name|isLoadingCfsOnDemandDefault
operator|=
name|conf
operator|.
name|getBoolean
argument_list|(
name|LOAD_CFS_ON_DEMAND_CONFIG_KEY
argument_list|,
literal|true
argument_list|)
expr_stmt|;
name|this
operator|.
name|htableDescriptor
operator|=
name|htd
expr_stmt|;
name|Set
argument_list|<
name|byte
index|[]
argument_list|>
name|families
init|=
name|this
operator|.
name|htableDescriptor
operator|.
name|getColumnFamilyNames
argument_list|()
decl_stmt|;
for|for
control|(
name|byte
index|[]
name|family
range|:
name|families
control|)
block|{
if|if
condition|(
operator|!
name|replicationScope
operator|.
name|containsKey
argument_list|(
name|family
argument_list|)
condition|)
block|{
name|int
name|scope
init|=
name|htd
operator|.
name|getColumnFamily
argument_list|(
name|family
argument_list|)
operator|.
name|getScope
argument_list|()
decl_stmt|;
comment|// Only store those families that has NON-DEFAULT scope
if|if
condition|(
name|scope
operator|!=
name|REPLICATION_SCOPE_LOCAL
condition|)
block|{
comment|// Do a copy before storing it here.
name|replicationScope
operator|.
name|put
argument_list|(
name|Bytes
operator|.
name|copy
argument_list|(
name|family
argument_list|)
argument_list|,
name|scope
argument_list|)
expr_stmt|;
block|}
block|}
block|}
name|this
operator|.
name|rsServices
operator|=
name|rsServices
expr_stmt|;
name|setHTableSpecificConf
argument_list|()
expr_stmt|;
name|this
operator|.
name|scannerReadPoints
operator|=
operator|new
name|ConcurrentHashMap
argument_list|<>
argument_list|()
expr_stmt|;
name|this
operator|.
name|busyWaitDuration
operator|=
name|conf
operator|.
name|getLong
argument_list|(
literal|"hbase.busy.wait.duration"
argument_list|,
name|DEFAULT_BUSY_WAIT_DURATION
argument_list|)
expr_stmt|;
name|this
operator|.
name|maxBusyWaitMultiplier
operator|=
name|conf
operator|.
name|getInt
argument_list|(
literal|"hbase.busy.wait.multiplier.max"
argument_list|,
literal|2
argument_list|)
expr_stmt|;
if|if
condition|(
name|busyWaitDuration
operator|*
name|maxBusyWaitMultiplier
operator|<=
literal|0L
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"Invalid hbase.busy.wait.duration ("
operator|+
name|busyWaitDuration
operator|+
literal|") or hbase.busy.wait.multiplier.max ("
operator|+
name|maxBusyWaitMultiplier
operator|+
literal|"). Their product should be positive"
argument_list|)
throw|;
block|}
name|this
operator|.
name|maxBusyWaitDuration
operator|=
name|conf
operator|.
name|getLong
argument_list|(
literal|"hbase.ipc.client.call.purge.timeout"
argument_list|,
literal|2
operator|*
name|HConstants
operator|.
name|DEFAULT_HBASE_RPC_TIMEOUT
argument_list|)
expr_stmt|;
comment|/*      * timestamp.slop provides a server-side constraint on the timestamp. This      * assumes that you base your TS around currentTimeMillis(). In this case,      * throw an error to the user if the user-specified TS is newer than now +      * slop. LATEST_TIMESTAMP == don't use this functionality      */
name|this
operator|.
name|timestampSlop
operator|=
name|conf
operator|.
name|getLong
argument_list|(
literal|"hbase.hregion.keyvalue.timestamp.slop.millisecs"
argument_list|,
name|HConstants
operator|.
name|LATEST_TIMESTAMP
argument_list|)
expr_stmt|;
comment|/**      * Timeout for the process time in processRowsWithLocks().      * Use -1 to switch off time bound.      */
name|this
operator|.
name|rowProcessorTimeout
operator|=
name|conf
operator|.
name|getLong
argument_list|(
literal|"hbase.hregion.row.processor.timeout"
argument_list|,
name|DEFAULT_ROW_PROCESSOR_TIMEOUT
argument_list|)
expr_stmt|;
name|this
operator|.
name|storeHotnessProtector
operator|=
operator|new
name|StoreHotnessProtector
argument_list|(
name|this
argument_list|,
name|conf
argument_list|)
expr_stmt|;
name|boolean
name|forceSync
init|=
name|conf
operator|.
name|getBoolean
argument_list|(
name|WAL_HSYNC_CONF_KEY
argument_list|,
name|DEFAULT_WAL_HSYNC
argument_list|)
decl_stmt|;
comment|/**      * This is the global default value for durability. All tables/mutations not defining a      * durability or using USE_DEFAULT will default to this value.      */
name|Durability
name|defaultDurability
init|=
name|forceSync
condition|?
name|Durability
operator|.
name|FSYNC_WAL
else|:
name|Durability
operator|.
name|SYNC_WAL
decl_stmt|;
name|this
operator|.
name|regionDurability
operator|=
name|this
operator|.
name|htableDescriptor
operator|.
name|getDurability
argument_list|()
operator|==
name|Durability
operator|.
name|USE_DEFAULT
condition|?
name|defaultDurability
else|:
name|this
operator|.
name|htableDescriptor
operator|.
name|getDurability
argument_list|()
expr_stmt|;
if|if
condition|(
name|rsServices
operator|!=
literal|null
condition|)
block|{
name|this
operator|.
name|rsAccounting
operator|=
name|this
operator|.
name|rsServices
operator|.
name|getRegionServerAccounting
argument_list|()
expr_stmt|;
comment|// don't initialize coprocessors if not running within a regionserver
comment|// TODO: revisit if coprocessors should load in other cases
name|this
operator|.
name|coprocessorHost
operator|=
operator|new
name|RegionCoprocessorHost
argument_list|(
name|this
argument_list|,
name|rsServices
argument_list|,
name|conf
argument_list|)
expr_stmt|;
name|this
operator|.
name|metricsRegionWrapper
operator|=
operator|new
name|MetricsRegionWrapperImpl
argument_list|(
name|this
argument_list|)
expr_stmt|;
name|this
operator|.
name|metricsRegion
operator|=
operator|new
name|MetricsRegion
argument_list|(
name|this
operator|.
name|metricsRegionWrapper
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|this
operator|.
name|metricsRegionWrapper
operator|=
literal|null
expr_stmt|;
name|this
operator|.
name|metricsRegion
operator|=
literal|null
expr_stmt|;
block|}
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
comment|// Write out region name, its encoded name and storeHotnessProtector as string.
name|LOG
operator|.
name|debug
argument_list|(
literal|"Instantiated "
operator|+
name|this
operator|+
literal|"; "
operator|+
name|storeHotnessProtector
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|configurationManager
operator|=
name|Optional
operator|.
name|empty
argument_list|()
expr_stmt|;
comment|// disable stats tracking system tables, but check the config for everything else
name|this
operator|.
name|regionStatsEnabled
operator|=
name|htd
operator|.
name|getTableName
argument_list|()
operator|.
name|getNamespaceAsString
argument_list|()
operator|.
name|equals
argument_list|(
name|NamespaceDescriptor
operator|.
name|SYSTEM_NAMESPACE_NAME_STR
argument_list|)
condition|?
literal|false
else|:
name|conf
operator|.
name|getBoolean
argument_list|(
name|HConstants
operator|.
name|ENABLE_CLIENT_BACKPRESSURE
argument_list|,
name|HConstants
operator|.
name|DEFAULT_ENABLE_CLIENT_BACKPRESSURE
argument_list|)
expr_stmt|;
name|this
operator|.
name|maxCellSize
operator|=
name|conf
operator|.
name|getLong
argument_list|(
name|HBASE_MAX_CELL_SIZE_KEY
argument_list|,
name|DEFAULT_MAX_CELL_SIZE
argument_list|)
expr_stmt|;
name|this
operator|.
name|miniBatchSize
operator|=
name|conf
operator|.
name|getInt
argument_list|(
name|HBASE_REGIONSERVER_MINIBATCH_SIZE
argument_list|,
name|DEFAULT_HBASE_REGIONSERVER_MINIBATCH_SIZE
argument_list|)
expr_stmt|;
block|}
name|void
name|setHTableSpecificConf
parameter_list|()
block|{
if|if
condition|(
name|this
operator|.
name|htableDescriptor
operator|==
literal|null
condition|)
return|return;
name|long
name|flushSize
init|=
name|this
operator|.
name|htableDescriptor
operator|.
name|getMemStoreFlushSize
argument_list|()
decl_stmt|;
if|if
condition|(
name|flushSize
operator|<=
literal|0
condition|)
block|{
name|flushSize
operator|=
name|conf
operator|.
name|getLong
argument_list|(
name|HConstants
operator|.
name|HREGION_MEMSTORE_FLUSH_SIZE
argument_list|,
name|TableDescriptorBuilder
operator|.
name|DEFAULT_MEMSTORE_FLUSH_SIZE
argument_list|)
expr_stmt|;
block|}
name|this
operator|.
name|memstoreFlushSize
operator|=
name|flushSize
expr_stmt|;
name|long
name|mult
init|=
name|conf
operator|.
name|getLong
argument_list|(
name|HConstants
operator|.
name|HREGION_MEMSTORE_BLOCK_MULTIPLIER
argument_list|,
name|HConstants
operator|.
name|DEFAULT_HREGION_MEMSTORE_BLOCK_MULTIPLIER
argument_list|)
decl_stmt|;
name|this
operator|.
name|blockingMemStoreSize
operator|=
name|this
operator|.
name|memstoreFlushSize
operator|*
name|mult
expr_stmt|;
block|}
comment|/**    * Initialize this region.    * Used only by tests and SplitTransaction to reopen the region.    * You should use createHRegion() or openHRegion()    * @return What the next sequence (edit) id should be.    * @throws IOException e    * @deprecated use HRegion.createHRegion() or HRegion.openHRegion()    */
annotation|@
name|Deprecated
specifier|public
name|long
name|initialize
parameter_list|()
throws|throws
name|IOException
block|{
return|return
name|initialize
argument_list|(
literal|null
argument_list|)
return|;
block|}
comment|/**    * Initialize this region.    *    * @param reporter Tickle every so often if initialize is taking a while.    * @return What the next sequence (edit) id should be.    * @throws IOException e    */
specifier|private
name|long
name|initialize
parameter_list|(
specifier|final
name|CancelableProgressable
name|reporter
parameter_list|)
throws|throws
name|IOException
block|{
comment|//Refuse to open the region if there is no column family in the table
if|if
condition|(
name|htableDescriptor
operator|.
name|getColumnFamilyCount
argument_list|()
operator|==
literal|0
condition|)
block|{
throw|throw
operator|new
name|DoNotRetryIOException
argument_list|(
literal|"Table "
operator|+
name|htableDescriptor
operator|.
name|getTableName
argument_list|()
operator|.
name|getNameAsString
argument_list|()
operator|+
literal|" should have at least one column family."
argument_list|)
throw|;
block|}
name|MonitoredTask
name|status
init|=
name|TaskMonitor
operator|.
name|get
argument_list|()
operator|.
name|createStatus
argument_list|(
literal|"Initializing region "
operator|+
name|this
argument_list|)
decl_stmt|;
name|long
name|nextSeqId
init|=
operator|-
literal|1
decl_stmt|;
try|try
block|{
name|nextSeqId
operator|=
name|initializeRegionInternals
argument_list|(
name|reporter
argument_list|,
name|status
argument_list|)
expr_stmt|;
return|return
name|nextSeqId
return|;
block|}
finally|finally
block|{
comment|// nextSeqid will be -1 if the initialization fails.
comment|// At least it will be 0 otherwise.
if|if
condition|(
name|nextSeqId
operator|==
operator|-
literal|1
condition|)
block|{
name|status
operator|.
name|abort
argument_list|(
literal|"Exception during region "
operator|+
name|getRegionInfo
argument_list|()
operator|.
name|getRegionNameAsString
argument_list|()
operator|+
literal|" initialization."
argument_list|)
expr_stmt|;
block|}
block|}
block|}
specifier|private
name|long
name|initializeRegionInternals
parameter_list|(
specifier|final
name|CancelableProgressable
name|reporter
parameter_list|,
specifier|final
name|MonitoredTask
name|status
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|coprocessorHost
operator|!=
literal|null
condition|)
block|{
name|status
operator|.
name|setStatus
argument_list|(
literal|"Running coprocessor pre-open hook"
argument_list|)
expr_stmt|;
name|coprocessorHost
operator|.
name|preOpen
argument_list|()
expr_stmt|;
block|}
comment|// Write HRI to a file in case we need to recover hbase:meta
comment|// Only the primary replica should write .regioninfo
if|if
condition|(
name|this
operator|.
name|getRegionInfo
argument_list|()
operator|.
name|getReplicaId
argument_list|()
operator|==
name|RegionInfo
operator|.
name|DEFAULT_REPLICA_ID
condition|)
block|{
name|status
operator|.
name|setStatus
argument_list|(
literal|"Writing region info on filesystem"
argument_list|)
expr_stmt|;
name|fs
operator|.
name|checkRegionInfoOnFilesystem
argument_list|()
expr_stmt|;
block|}
comment|// Initialize all the HStores
name|status
operator|.
name|setStatus
argument_list|(
literal|"Initializing all the Stores"
argument_list|)
expr_stmt|;
name|long
name|maxSeqId
init|=
name|initializeStores
argument_list|(
name|reporter
argument_list|,
name|status
argument_list|)
decl_stmt|;
name|this
operator|.
name|mvcc
operator|.
name|advanceTo
argument_list|(
name|maxSeqId
argument_list|)
expr_stmt|;
if|if
condition|(
name|ServerRegionReplicaUtil
operator|.
name|shouldReplayRecoveredEdits
argument_list|(
name|this
argument_list|)
condition|)
block|{
name|Collection
argument_list|<
name|HStore
argument_list|>
name|stores
init|=
name|this
operator|.
name|stores
operator|.
name|values
argument_list|()
decl_stmt|;
try|try
block|{
comment|// update the stores that we are replaying
name|LOG
operator|.
name|debug
argument_list|(
literal|"replaying wal for "
operator|+
name|this
operator|.
name|getRegionInfo
argument_list|()
operator|.
name|getEncodedName
argument_list|()
argument_list|)
expr_stmt|;
name|stores
operator|.
name|forEach
argument_list|(
name|HStore
operator|::
name|startReplayingFromWAL
argument_list|)
expr_stmt|;
comment|// Recover any edits if available.
name|maxSeqId
operator|=
name|Math
operator|.
name|max
argument_list|(
name|maxSeqId
argument_list|,
name|replayRecoveredEditsIfAny
argument_list|(
name|this
operator|.
name|fs
operator|.
name|getRegionDir
argument_list|()
argument_list|,
name|maxSeqIdInStores
argument_list|,
name|reporter
argument_list|,
name|status
argument_list|)
argument_list|)
expr_stmt|;
comment|// Make sure mvcc is up to max.
name|this
operator|.
name|mvcc
operator|.
name|advanceTo
argument_list|(
name|maxSeqId
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"stopping wal replay for "
operator|+
name|this
operator|.
name|getRegionInfo
argument_list|()
operator|.
name|getEncodedName
argument_list|()
argument_list|)
expr_stmt|;
comment|// update the stores that we are done replaying
name|stores
operator|.
name|forEach
argument_list|(
name|HStore
operator|::
name|stopReplayingFromWAL
argument_list|)
expr_stmt|;
block|}
block|}
name|this
operator|.
name|lastReplayedOpenRegionSeqId
operator|=
name|maxSeqId
expr_stmt|;
name|this
operator|.
name|writestate
operator|.
name|setReadOnly
argument_list|(
name|ServerRegionReplicaUtil
operator|.
name|isReadOnly
argument_list|(
name|this
argument_list|)
argument_list|)
expr_stmt|;
name|this
operator|.
name|writestate
operator|.
name|flushRequested
operator|=
literal|false
expr_stmt|;
name|this
operator|.
name|writestate
operator|.
name|compacting
operator|.
name|set
argument_list|(
literal|0
argument_list|)
expr_stmt|;
if|if
condition|(
name|this
operator|.
name|writestate
operator|.
name|writesEnabled
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Cleaning up temporary data for "
operator|+
name|this
operator|.
name|getRegionInfo
argument_list|()
operator|.
name|getEncodedName
argument_list|()
argument_list|)
expr_stmt|;
comment|// Remove temporary data left over from old regions
name|status
operator|.
name|setStatus
argument_list|(
literal|"Cleaning up temporary data from old regions"
argument_list|)
expr_stmt|;
name|fs
operator|.
name|cleanupTempDir
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|this
operator|.
name|writestate
operator|.
name|writesEnabled
condition|)
block|{
name|status
operator|.
name|setStatus
argument_list|(
literal|"Cleaning up detritus from prior splits"
argument_list|)
expr_stmt|;
comment|// Get rid of any splits or merges that were lost in-progress.  Clean out
comment|// these directories here on open.  We may be opening a region that was
comment|// being split but we crashed in the middle of it all.
name|LOG
operator|.
name|debug
argument_list|(
literal|"Cleaning up detritus for "
operator|+
name|this
operator|.
name|getRegionInfo
argument_list|()
operator|.
name|getEncodedName
argument_list|()
argument_list|)
expr_stmt|;
name|fs
operator|.
name|cleanupAnySplitDetritus
argument_list|()
expr_stmt|;
name|fs
operator|.
name|cleanupMergesDir
argument_list|()
expr_stmt|;
block|}
comment|// Initialize split policy
name|this
operator|.
name|splitPolicy
operator|=
name|RegionSplitPolicy
operator|.
name|create
argument_list|(
name|this
argument_list|,
name|conf
argument_list|)
expr_stmt|;
comment|// Initialize flush policy
name|this
operator|.
name|flushPolicy
operator|=
name|FlushPolicyFactory
operator|.
name|create
argument_list|(
name|this
argument_list|,
name|conf
argument_list|)
expr_stmt|;
name|long
name|lastFlushTime
init|=
name|EnvironmentEdgeManager
operator|.
name|currentTime
argument_list|()
decl_stmt|;
for|for
control|(
name|HStore
name|store
range|:
name|stores
operator|.
name|values
argument_list|()
control|)
block|{
name|this
operator|.
name|lastStoreFlushTimeMap
operator|.
name|put
argument_list|(
name|store
argument_list|,
name|lastFlushTime
argument_list|)
expr_stmt|;
block|}
comment|// Use maximum of log sequenceid or that which was found in stores
comment|// (particularly if no recovered edits, seqid will be -1).
name|long
name|maxSeqIdFromFile
init|=
name|WALSplitter
operator|.
name|getMaxRegionSequenceId
argument_list|(
name|fs
operator|.
name|getFileSystem
argument_list|()
argument_list|,
name|fs
operator|.
name|getRegionDir
argument_list|()
argument_list|)
decl_stmt|;
name|long
name|nextSeqId
init|=
name|Math
operator|.
name|max
argument_list|(
name|maxSeqId
argument_list|,
name|maxSeqIdFromFile
argument_list|)
operator|+
literal|1
decl_stmt|;
if|if
condition|(
name|writestate
operator|.
name|writesEnabled
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"writing seq id for "
operator|+
name|this
operator|.
name|getRegionInfo
argument_list|()
operator|.
name|getEncodedName
argument_list|()
argument_list|)
expr_stmt|;
name|WALSplitter
operator|.
name|writeRegionSequenceIdFile
argument_list|(
name|fs
operator|.
name|getFileSystem
argument_list|()
argument_list|,
name|fs
operator|.
name|getRegionDir
argument_list|()
argument_list|,
name|nextSeqId
operator|-
literal|1
argument_list|)
expr_stmt|;
block|}
name|LOG
operator|.
name|info
argument_list|(
literal|"Opened {}; next sequenceid={}"
argument_list|,
name|this
operator|.
name|getRegionInfo
argument_list|()
operator|.
name|getShortNameToLog
argument_list|()
argument_list|,
name|nextSeqId
argument_list|)
expr_stmt|;
comment|// A region can be reopened if failed a split; reset flags
name|this
operator|.
name|closing
operator|.
name|set
argument_list|(
literal|false
argument_list|)
expr_stmt|;
name|this
operator|.
name|closed
operator|.
name|set
argument_list|(
literal|false
argument_list|)
expr_stmt|;
if|if
condition|(
name|coprocessorHost
operator|!=
literal|null
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Running coprocessor post-open hooks for "
operator|+
name|this
operator|.
name|getRegionInfo
argument_list|()
operator|.
name|getEncodedName
argument_list|()
argument_list|)
expr_stmt|;
name|status
operator|.
name|setStatus
argument_list|(
literal|"Running coprocessor post-open hooks"
argument_list|)
expr_stmt|;
name|coprocessorHost
operator|.
name|postOpen
argument_list|()
expr_stmt|;
block|}
name|status
operator|.
name|markComplete
argument_list|(
literal|"Region opened successfully"
argument_list|)
expr_stmt|;
return|return
name|nextSeqId
return|;
block|}
comment|/**    * Open all Stores.    * @param reporter    * @param status    * @return Highest sequenceId found out in a Store.    * @throws IOException    */
specifier|private
name|long
name|initializeStores
parameter_list|(
name|CancelableProgressable
name|reporter
parameter_list|,
name|MonitoredTask
name|status
parameter_list|)
throws|throws
name|IOException
block|{
comment|// Load in all the HStores.
name|long
name|maxSeqId
init|=
operator|-
literal|1
decl_stmt|;
comment|// initialized to -1 so that we pick up MemstoreTS from column families
name|long
name|maxMemstoreTS
init|=
operator|-
literal|1
decl_stmt|;
if|if
condition|(
name|htableDescriptor
operator|.
name|getColumnFamilyCount
argument_list|()
operator|!=
literal|0
condition|)
block|{
comment|// initialize the thread pool for opening stores in parallel.
name|ThreadPoolExecutor
name|storeOpenerThreadPool
init|=
name|getStoreOpenAndCloseThreadPool
argument_list|(
literal|"StoreOpener-"
operator|+
name|this
operator|.
name|getRegionInfo
argument_list|()
operator|.
name|getShortNameToLog
argument_list|()
argument_list|)
decl_stmt|;
name|CompletionService
argument_list|<
name|HStore
argument_list|>
name|completionService
init|=
operator|new
name|ExecutorCompletionService
argument_list|<>
argument_list|(
name|storeOpenerThreadPool
argument_list|)
decl_stmt|;
comment|// initialize each store in parallel
for|for
control|(
specifier|final
name|ColumnFamilyDescriptor
name|family
range|:
name|htableDescriptor
operator|.
name|getColumnFamilies
argument_list|()
control|)
block|{
name|status
operator|.
name|setStatus
argument_list|(
literal|"Instantiating store for column family "
operator|+
name|family
argument_list|)
expr_stmt|;
name|completionService
operator|.
name|submit
argument_list|(
operator|new
name|Callable
argument_list|<
name|HStore
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|HStore
name|call
parameter_list|()
throws|throws
name|IOException
block|{
return|return
name|instantiateHStore
argument_list|(
name|family
argument_list|)
return|;
block|}
block|}
argument_list|)
expr_stmt|;
block|}
name|boolean
name|allStoresOpened
init|=
literal|false
decl_stmt|;
name|boolean
name|hasSloppyStores
init|=
literal|false
decl_stmt|;
try|try
block|{
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|htableDescriptor
operator|.
name|getColumnFamilyCount
argument_list|()
condition|;
name|i
operator|++
control|)
block|{
name|Future
argument_list|<
name|HStore
argument_list|>
name|future
init|=
name|completionService
operator|.
name|take
argument_list|()
decl_stmt|;
name|HStore
name|store
init|=
name|future
operator|.
name|get
argument_list|()
decl_stmt|;
name|this
operator|.
name|stores
operator|.
name|put
argument_list|(
name|store
operator|.
name|getColumnFamilyDescriptor
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|,
name|store
argument_list|)
expr_stmt|;
if|if
condition|(
name|store
operator|.
name|isSloppyMemStore
argument_list|()
condition|)
block|{
name|hasSloppyStores
operator|=
literal|true
expr_stmt|;
block|}
name|long
name|storeMaxSequenceId
init|=
name|store
operator|.
name|getMaxSequenceId
argument_list|()
operator|.
name|orElse
argument_list|(
literal|0L
argument_list|)
decl_stmt|;
name|maxSeqIdInStores
operator|.
name|put
argument_list|(
name|Bytes
operator|.
name|toBytes
argument_list|(
name|store
operator|.
name|getColumnFamilyName
argument_list|()
argument_list|)
argument_list|,
name|storeMaxSequenceId
argument_list|)
expr_stmt|;
if|if
condition|(
name|maxSeqId
operator|==
operator|-
literal|1
operator|||
name|storeMaxSequenceId
operator|>
name|maxSeqId
condition|)
block|{
name|maxSeqId
operator|=
name|storeMaxSequenceId
expr_stmt|;
block|}
name|long
name|maxStoreMemstoreTS
init|=
name|store
operator|.
name|getMaxMemStoreTS
argument_list|()
operator|.
name|orElse
argument_list|(
literal|0L
argument_list|)
decl_stmt|;
if|if
condition|(
name|maxStoreMemstoreTS
operator|>
name|maxMemstoreTS
condition|)
block|{
name|maxMemstoreTS
operator|=
name|maxStoreMemstoreTS
expr_stmt|;
block|}
block|}
name|allStoresOpened
operator|=
literal|true
expr_stmt|;
if|if
condition|(
name|hasSloppyStores
condition|)
block|{
name|htableDescriptor
operator|=
name|TableDescriptorBuilder
operator|.
name|newBuilder
argument_list|(
name|htableDescriptor
argument_list|)
operator|.
name|setFlushPolicyClassName
argument_list|(
name|FlushNonSloppyStoresFirstPolicy
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|)
operator|.
name|build
argument_list|()
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Setting FlushNonSloppyStoresFirstPolicy for the region="
operator|+
name|this
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
throw|throw
operator|(
name|InterruptedIOException
operator|)
operator|new
name|InterruptedIOException
argument_list|()
operator|.
name|initCause
argument_list|(
name|e
argument_list|)
throw|;
block|}
catch|catch
parameter_list|(
name|ExecutionException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|e
operator|.
name|getCause
argument_list|()
argument_list|)
throw|;
block|}
finally|finally
block|{
name|storeOpenerThreadPool
operator|.
name|shutdownNow
argument_list|()
expr_stmt|;
if|if
condition|(
operator|!
name|allStoresOpened
condition|)
block|{
comment|// something went wrong, close all opened stores
name|LOG
operator|.
name|error
argument_list|(
literal|"Could not initialize all stores for the region="
operator|+
name|this
argument_list|)
expr_stmt|;
for|for
control|(
name|HStore
name|store
range|:
name|this
operator|.
name|stores
operator|.
name|values
argument_list|()
control|)
block|{
try|try
block|{
name|store
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"close store failed"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
block|}
return|return
name|Math
operator|.
name|max
argument_list|(
name|maxSeqId
argument_list|,
name|maxMemstoreTS
operator|+
literal|1
argument_list|)
return|;
block|}
specifier|private
name|void
name|initializeWarmup
parameter_list|(
specifier|final
name|CancelableProgressable
name|reporter
parameter_list|)
throws|throws
name|IOException
block|{
name|MonitoredTask
name|status
init|=
name|TaskMonitor
operator|.
name|get
argument_list|()
operator|.
name|createStatus
argument_list|(
literal|"Initializing region "
operator|+
name|this
argument_list|)
decl_stmt|;
comment|// Initialize all the HStores
name|status
operator|.
name|setStatus
argument_list|(
literal|"Warming up all the Stores"
argument_list|)
expr_stmt|;
try|try
block|{
name|initializeStores
argument_list|(
name|reporter
argument_list|,
name|status
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|status
operator|.
name|markComplete
argument_list|(
literal|"Done warming up."
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * @return Map of StoreFiles by column family    */
specifier|private
name|NavigableMap
argument_list|<
name|byte
index|[]
argument_list|,
name|List
argument_list|<
name|Path
argument_list|>
argument_list|>
name|getStoreFiles
parameter_list|()
block|{
name|NavigableMap
argument_list|<
name|byte
index|[]
argument_list|,
name|List
argument_list|<
name|Path
argument_list|>
argument_list|>
name|allStoreFiles
init|=
operator|new
name|TreeMap
argument_list|<>
argument_list|(
name|Bytes
operator|.
name|BYTES_COMPARATOR
argument_list|)
decl_stmt|;
for|for
control|(
name|HStore
name|store
range|:
name|stores
operator|.
name|values
argument_list|()
control|)
block|{
name|Collection
argument_list|<
name|HStoreFile
argument_list|>
name|storeFiles
init|=
name|store
operator|.
name|getStorefiles
argument_list|()
decl_stmt|;
if|if
condition|(
name|storeFiles
operator|==
literal|null
condition|)
block|{
continue|continue;
block|}
name|List
argument_list|<
name|Path
argument_list|>
name|storeFileNames
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
for|for
control|(
name|HStoreFile
name|storeFile
range|:
name|storeFiles
control|)
block|{
name|storeFileNames
operator|.
name|add
argument_list|(
name|storeFile
operator|.
name|getPath
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|allStoreFiles
operator|.
name|put
argument_list|(
name|store
operator|.
name|getColumnFamilyDescriptor
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|,
name|storeFileNames
argument_list|)
expr_stmt|;
block|}
return|return
name|allStoreFiles
return|;
block|}
annotation|@
name|VisibleForTesting
specifier|protected
name|void
name|writeRegionOpenMarker
parameter_list|(
name|WAL
name|wal
parameter_list|,
name|long
name|openSeqId
parameter_list|)
throws|throws
name|IOException
block|{
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|List
argument_list|<
name|Path
argument_list|>
argument_list|>
name|storeFiles
init|=
name|getStoreFiles
argument_list|()
decl_stmt|;
name|RegionEventDescriptor
name|regionOpenDesc
init|=
name|ProtobufUtil
operator|.
name|toRegionEventDescriptor
argument_list|(
name|RegionEventDescriptor
operator|.
name|EventType
operator|.
name|REGION_OPEN
argument_list|,
name|getRegionInfo
argument_list|()
argument_list|,
name|openSeqId
argument_list|,
name|getRegionServerServices
argument_list|()
operator|.
name|getServerName
argument_list|()
argument_list|,
name|storeFiles
argument_list|)
decl_stmt|;
name|WALUtil
operator|.
name|writeRegionEventMarker
argument_list|(
name|wal
argument_list|,
name|getReplicationScope
argument_list|()
argument_list|,
name|getRegionInfo
argument_list|()
argument_list|,
name|regionOpenDesc
argument_list|,
name|mvcc
argument_list|)
expr_stmt|;
block|}
specifier|private
name|void
name|writeRegionCloseMarker
parameter_list|(
name|WAL
name|wal
parameter_list|)
throws|throws
name|IOException
block|{
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|List
argument_list|<
name|Path
argument_list|>
argument_list|>
name|storeFiles
init|=
name|getStoreFiles
argument_list|()
decl_stmt|;
name|RegionEventDescriptor
name|regionEventDesc
init|=
name|ProtobufUtil
operator|.
name|toRegionEventDescriptor
argument_list|(
name|RegionEventDescriptor
operator|.
name|EventType
operator|.
name|REGION_CLOSE
argument_list|,
name|getRegionInfo
argument_list|()
argument_list|,
name|mvcc
operator|.
name|getReadPoint
argument_list|()
argument_list|,
name|getRegionServerServices
argument_list|()
operator|.
name|getServerName
argument_list|()
argument_list|,
name|storeFiles
argument_list|)
decl_stmt|;
name|WALUtil
operator|.
name|writeRegionEventMarker
argument_list|(
name|wal
argument_list|,
name|getReplicationScope
argument_list|()
argument_list|,
name|getRegionInfo
argument_list|()
argument_list|,
name|regionEventDesc
argument_list|,
name|mvcc
argument_list|)
expr_stmt|;
comment|// Store SeqId in HDFS when a region closes
comment|// checking region folder exists is due to many tests which delete the table folder while a
comment|// table is still online
if|if
condition|(
name|this
operator|.
name|fs
operator|.
name|getFileSystem
argument_list|()
operator|.
name|exists
argument_list|(
name|this
operator|.
name|fs
operator|.
name|getRegionDir
argument_list|()
argument_list|)
condition|)
block|{
name|WALSplitter
operator|.
name|writeRegionSequenceIdFile
argument_list|(
name|this
operator|.
name|fs
operator|.
name|getFileSystem
argument_list|()
argument_list|,
name|this
operator|.
name|fs
operator|.
name|getRegionDir
argument_list|()
argument_list|,
name|mvcc
operator|.
name|getReadPoint
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * @return True if this region has references.    */
specifier|public
name|boolean
name|hasReferences
parameter_list|()
block|{
return|return
name|stores
operator|.
name|values
argument_list|()
operator|.
name|stream
argument_list|()
operator|.
name|anyMatch
argument_list|(
name|HStore
operator|::
name|hasReferences
argument_list|)
return|;
block|}
specifier|public
name|void
name|blockUpdates
parameter_list|()
block|{
name|this
operator|.
name|updatesLock
operator|.
name|writeLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
block|}
specifier|public
name|void
name|unblockUpdates
parameter_list|()
block|{
name|this
operator|.
name|updatesLock
operator|.
name|writeLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
specifier|public
name|HDFSBlocksDistribution
name|getHDFSBlocksDistribution
parameter_list|()
block|{
name|HDFSBlocksDistribution
name|hdfsBlocksDistribution
init|=
operator|new
name|HDFSBlocksDistribution
argument_list|()
decl_stmt|;
name|stores
operator|.
name|values
argument_list|()
operator|.
name|stream
argument_list|()
operator|.
name|filter
argument_list|(
name|s
lambda|->
name|s
operator|.
name|getStorefiles
argument_list|()
operator|!=
literal|null
argument_list|)
operator|.
name|flatMap
argument_list|(
name|s
lambda|->
name|s
operator|.
name|getStorefiles
argument_list|()
operator|.
name|stream
argument_list|()
argument_list|)
operator|.
name|map
argument_list|(
name|HStoreFile
operator|::
name|getHDFSBlockDistribution
argument_list|)
operator|.
name|forEachOrdered
argument_list|(
name|hdfsBlocksDistribution
operator|::
name|add
argument_list|)
expr_stmt|;
return|return
name|hdfsBlocksDistribution
return|;
block|}
comment|/**    * This is a helper function to compute HDFS block distribution on demand    * @param conf configuration    * @param tableDescriptor TableDescriptor of the table    * @param regionInfo encoded name of the region    * @return The HDFS blocks distribution for the given region.    * @throws IOException    */
specifier|public
specifier|static
name|HDFSBlocksDistribution
name|computeHDFSBlocksDistribution
parameter_list|(
name|Configuration
name|conf
parameter_list|,
name|TableDescriptor
name|tableDescriptor
parameter_list|,
name|RegionInfo
name|regionInfo
parameter_list|)
throws|throws
name|IOException
block|{
name|Path
name|tablePath
init|=
name|FSUtils
operator|.
name|getTableDir
argument_list|(
name|FSUtils
operator|.
name|getRootDir
argument_list|(
name|conf
argument_list|)
argument_list|,
name|tableDescriptor
operator|.
name|getTableName
argument_list|()
argument_list|)
decl_stmt|;
return|return
name|computeHDFSBlocksDistribution
argument_list|(
name|conf
argument_list|,
name|tableDescriptor
argument_list|,
name|regionInfo
argument_list|,
name|tablePath
argument_list|)
return|;
block|}
comment|/**    * This is a helper function to compute HDFS block distribution on demand    * @param conf configuration    * @param tableDescriptor TableDescriptor of the table    * @param regionInfo encoded name of the region    * @param tablePath the table directory    * @return The HDFS blocks distribution for the given region.    * @throws IOException    */
specifier|public
specifier|static
name|HDFSBlocksDistribution
name|computeHDFSBlocksDistribution
parameter_list|(
name|Configuration
name|conf
parameter_list|,
name|TableDescriptor
name|tableDescriptor
parameter_list|,
name|RegionInfo
name|regionInfo
parameter_list|,
name|Path
name|tablePath
parameter_list|)
throws|throws
name|IOException
block|{
name|HDFSBlocksDistribution
name|hdfsBlocksDistribution
init|=
operator|new
name|HDFSBlocksDistribution
argument_list|()
decl_stmt|;
name|FileSystem
name|fs
init|=
name|tablePath
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
decl_stmt|;
name|HRegionFileSystem
name|regionFs
init|=
operator|new
name|HRegionFileSystem
argument_list|(
name|conf
argument_list|,
name|fs
argument_list|,
name|tablePath
argument_list|,
name|regionInfo
argument_list|)
decl_stmt|;
for|for
control|(
name|ColumnFamilyDescriptor
name|family
range|:
name|tableDescriptor
operator|.
name|getColumnFamilies
argument_list|()
control|)
block|{
name|List
argument_list|<
name|LocatedFileStatus
argument_list|>
name|locatedFileStatusList
init|=
name|HRegionFileSystem
operator|.
name|getStoreFilesLocatedStatus
argument_list|(
name|regionFs
argument_list|,
name|family
operator|.
name|getNameAsString
argument_list|()
argument_list|,
literal|true
argument_list|)
decl_stmt|;
if|if
condition|(
name|locatedFileStatusList
operator|==
literal|null
condition|)
block|{
continue|continue;
block|}
for|for
control|(
name|LocatedFileStatus
name|status
range|:
name|locatedFileStatusList
control|)
block|{
name|Path
name|p
init|=
name|status
operator|.
name|getPath
argument_list|()
decl_stmt|;
if|if
condition|(
name|StoreFileInfo
operator|.
name|isReference
argument_list|(
name|p
argument_list|)
operator|||
name|HFileLink
operator|.
name|isHFileLink
argument_list|(
name|p
argument_list|)
condition|)
block|{
comment|// Only construct StoreFileInfo object if its not a hfile, save obj
comment|// creation
name|StoreFileInfo
name|storeFileInfo
init|=
operator|new
name|StoreFileInfo
argument_list|(
name|conf
argument_list|,
name|fs
argument_list|,
name|status
argument_list|)
decl_stmt|;
name|hdfsBlocksDistribution
operator|.
name|add
argument_list|(
name|storeFileInfo
operator|.
name|computeHDFSBlocksDistribution
argument_list|(
name|fs
argument_list|)
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|StoreFileInfo
operator|.
name|isHFile
argument_list|(
name|p
argument_list|)
condition|)
block|{
comment|// If its a HFile, then lets just add to the block distribution
comment|// lets not create more objects here, not even another HDFSBlocksDistribution
name|FSUtils
operator|.
name|addToHDFSBlocksDistribution
argument_list|(
name|hdfsBlocksDistribution
argument_list|,
name|status
operator|.
name|getBlockLocations
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"path="
operator|+
name|p
operator|+
literal|" doesn't look like a valid StoreFile"
argument_list|)
throw|;
block|}
block|}
block|}
return|return
name|hdfsBlocksDistribution
return|;
block|}
comment|/**    * Increase the size of mem store in this region and the size of global mem    * store    */
name|void
name|incMemStoreSize
parameter_list|(
name|MemStoreSize
name|mss
parameter_list|)
block|{
name|incMemStoreSize
argument_list|(
name|mss
operator|.
name|getDataSize
argument_list|()
argument_list|,
name|mss
operator|.
name|getHeapSize
argument_list|()
argument_list|,
name|mss
operator|.
name|getOffHeapSize
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|void
name|incMemStoreSize
parameter_list|(
name|long
name|dataSizeDelta
parameter_list|,
name|long
name|heapSizeDelta
parameter_list|,
name|long
name|offHeapSizeDelta
parameter_list|)
block|{
if|if
condition|(
name|this
operator|.
name|rsAccounting
operator|!=
literal|null
condition|)
block|{
name|rsAccounting
operator|.
name|incGlobalMemStoreSize
argument_list|(
name|dataSizeDelta
argument_list|,
name|heapSizeDelta
argument_list|,
name|offHeapSizeDelta
argument_list|)
expr_stmt|;
block|}
name|long
name|dataSize
init|=
name|this
operator|.
name|memStoreSizing
operator|.
name|incMemStoreSize
argument_list|(
name|dataSizeDelta
argument_list|,
name|heapSizeDelta
argument_list|,
name|offHeapSizeDelta
argument_list|)
decl_stmt|;
name|checkNegativeMemStoreDataSize
argument_list|(
name|dataSize
argument_list|,
name|dataSizeDelta
argument_list|)
expr_stmt|;
block|}
name|void
name|decrMemStoreSize
parameter_list|(
name|MemStoreSize
name|mss
parameter_list|)
block|{
name|decrMemStoreSize
argument_list|(
name|mss
operator|.
name|getDataSize
argument_list|()
argument_list|,
name|mss
operator|.
name|getHeapSize
argument_list|()
argument_list|,
name|mss
operator|.
name|getOffHeapSize
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|void
name|decrMemStoreSize
parameter_list|(
name|long
name|dataSizeDelta
parameter_list|,
name|long
name|heapSizeDelta
parameter_list|,
name|long
name|offHeapSizeDelta
parameter_list|)
block|{
if|if
condition|(
name|this
operator|.
name|rsAccounting
operator|!=
literal|null
condition|)
block|{
name|rsAccounting
operator|.
name|decGlobalMemStoreSize
argument_list|(
name|dataSizeDelta
argument_list|,
name|heapSizeDelta
argument_list|,
name|offHeapSizeDelta
argument_list|)
expr_stmt|;
block|}
name|long
name|dataSize
init|=
name|this
operator|.
name|memStoreSizing
operator|.
name|decMemStoreSize
argument_list|(
name|dataSizeDelta
argument_list|,
name|heapSizeDelta
argument_list|,
name|offHeapSizeDelta
argument_list|)
decl_stmt|;
name|checkNegativeMemStoreDataSize
argument_list|(
name|dataSize
argument_list|,
operator|-
name|dataSizeDelta
argument_list|)
expr_stmt|;
block|}
specifier|private
name|void
name|checkNegativeMemStoreDataSize
parameter_list|(
name|long
name|memStoreDataSize
parameter_list|,
name|long
name|delta
parameter_list|)
block|{
comment|// This is extremely bad if we make memStoreSizing negative. Log as much info on the offending
comment|// caller as possible. (memStoreSizing might be a negative value already -- freeing memory)
if|if
condition|(
name|memStoreDataSize
operator|<
literal|0
condition|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Asked to modify this region's ("
operator|+
name|this
operator|.
name|toString
argument_list|()
operator|+
literal|") memStoreSizing to a negative value which is incorrect. Current memStoreSizing="
operator|+
operator|(
name|memStoreDataSize
operator|-
name|delta
operator|)
operator|+
literal|", delta="
operator|+
name|delta
argument_list|,
operator|new
name|Exception
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|RegionInfo
name|getRegionInfo
parameter_list|()
block|{
return|return
name|this
operator|.
name|fs
operator|.
name|getRegionInfo
argument_list|()
return|;
block|}
comment|/**    * @return Instance of {@link RegionServerServices} used by this HRegion.    * Can be null.    */
name|RegionServerServices
name|getRegionServerServices
parameter_list|()
block|{
return|return
name|this
operator|.
name|rsServices
return|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|getReadRequestsCount
parameter_list|()
block|{
return|return
name|readRequestsCount
operator|.
name|sum
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|getCpRequestsCount
parameter_list|()
block|{
return|return
name|cpRequestsCount
operator|.
name|sum
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|getFilteredReadRequestsCount
parameter_list|()
block|{
return|return
name|filteredReadRequestsCount
operator|.
name|sum
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|getWriteRequestsCount
parameter_list|()
block|{
return|return
name|writeRequestsCount
operator|.
name|sum
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|getMemStoreDataSize
parameter_list|()
block|{
return|return
name|memStoreSizing
operator|.
name|getDataSize
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|getMemStoreHeapSize
parameter_list|()
block|{
return|return
name|memStoreSizing
operator|.
name|getHeapSize
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|getMemStoreOffHeapSize
parameter_list|()
block|{
return|return
name|memStoreSizing
operator|.
name|getOffHeapSize
argument_list|()
return|;
block|}
comment|/** @return store services for this region, to access services required by store level needs */
specifier|public
name|RegionServicesForStores
name|getRegionServicesForStores
parameter_list|()
block|{
return|return
name|regionServicesForStores
return|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|getNumMutationsWithoutWAL
parameter_list|()
block|{
return|return
name|numMutationsWithoutWAL
operator|.
name|sum
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|getDataInMemoryWithoutWAL
parameter_list|()
block|{
return|return
name|dataInMemoryWithoutWAL
operator|.
name|sum
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|getBlockedRequestsCount
parameter_list|()
block|{
return|return
name|blockedRequestsCount
operator|.
name|sum
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|getCheckAndMutateChecksPassed
parameter_list|()
block|{
return|return
name|checkAndMutateChecksPassed
operator|.
name|sum
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|getCheckAndMutateChecksFailed
parameter_list|()
block|{
return|return
name|checkAndMutateChecksFailed
operator|.
name|sum
argument_list|()
return|;
block|}
comment|// TODO Needs to check whether we should expose our metrics system to CPs. If CPs themselves doing
comment|// the op and bypassing the core, this might be needed? Should be stop supporting the bypass
comment|// feature?
specifier|public
name|MetricsRegion
name|getMetrics
parameter_list|()
block|{
return|return
name|metricsRegion
return|;
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|isClosed
parameter_list|()
block|{
return|return
name|this
operator|.
name|closed
operator|.
name|get
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|isClosing
parameter_list|()
block|{
return|return
name|this
operator|.
name|closing
operator|.
name|get
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|isReadOnly
parameter_list|()
block|{
return|return
name|this
operator|.
name|writestate
operator|.
name|isReadOnly
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|isAvailable
parameter_list|()
block|{
return|return
operator|!
name|isClosed
argument_list|()
operator|&&
operator|!
name|isClosing
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|isSplittable
parameter_list|()
block|{
return|return
name|isAvailable
argument_list|()
operator|&&
operator|!
name|hasReferences
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|isMergeable
parameter_list|()
block|{
if|if
condition|(
operator|!
name|isAvailable
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Region "
operator|+
name|this
operator|+
literal|" is not mergeable because it is closing or closed"
argument_list|)
expr_stmt|;
return|return
literal|false
return|;
block|}
if|if
condition|(
name|hasReferences
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Region "
operator|+
name|this
operator|+
literal|" is not mergeable because it has references"
argument_list|)
expr_stmt|;
return|return
literal|false
return|;
block|}
return|return
literal|true
return|;
block|}
specifier|public
name|boolean
name|areWritesEnabled
parameter_list|()
block|{
synchronized|synchronized
init|(
name|this
operator|.
name|writestate
init|)
block|{
return|return
name|this
operator|.
name|writestate
operator|.
name|writesEnabled
return|;
block|}
block|}
annotation|@
name|VisibleForTesting
specifier|public
name|MultiVersionConcurrencyControl
name|getMVCC
parameter_list|()
block|{
return|return
name|mvcc
return|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|getMaxFlushedSeqId
parameter_list|()
block|{
return|return
name|maxFlushedSeqId
return|;
block|}
comment|/**    * @return readpoint considering given IsolationLevel. Pass {@code null} for default    */
specifier|public
name|long
name|getReadPoint
parameter_list|(
name|IsolationLevel
name|isolationLevel
parameter_list|)
block|{
if|if
condition|(
name|isolationLevel
operator|!=
literal|null
operator|&&
name|isolationLevel
operator|==
name|IsolationLevel
operator|.
name|READ_UNCOMMITTED
condition|)
block|{
comment|// This scan can read even uncommitted transactions
return|return
name|Long
operator|.
name|MAX_VALUE
return|;
block|}
return|return
name|mvcc
operator|.
name|getReadPoint
argument_list|()
return|;
block|}
specifier|public
name|boolean
name|isLoadingCfsOnDemandDefault
parameter_list|()
block|{
return|return
name|this
operator|.
name|isLoadingCfsOnDemandDefault
return|;
block|}
comment|/**    * Close down this HRegion.  Flush the cache, shut down each HStore, don't    * service any more calls.    *    *<p>This method could take some time to execute, so don't call it from a    * time-sensitive thread.    *    * @return Vector of all the storage files that the HRegion's component    * HStores make use of.  It's a list of all StoreFile objects. Returns empty    * vector if already closed and null if judged that it should not close.    *    * @throws IOException e    * @throws DroppedSnapshotException Thrown when replay of wal is required    * because a Snapshot was not properly persisted. The region is put in closing mode, and the    * caller MUST abort after this.    */
specifier|public
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|List
argument_list|<
name|HStoreFile
argument_list|>
argument_list|>
name|close
parameter_list|()
throws|throws
name|IOException
block|{
return|return
name|close
argument_list|(
literal|false
argument_list|)
return|;
block|}
specifier|private
specifier|final
name|Object
name|closeLock
init|=
operator|new
name|Object
argument_list|()
decl_stmt|;
comment|/** Conf key for the periodic flush interval */
specifier|public
specifier|static
specifier|final
name|String
name|MEMSTORE_PERIODIC_FLUSH_INTERVAL
init|=
literal|"hbase.regionserver.optionalcacheflushinterval"
decl_stmt|;
comment|/** Default interval for the memstore flush */
specifier|public
specifier|static
specifier|final
name|int
name|DEFAULT_CACHE_FLUSH_INTERVAL
init|=
literal|3600000
decl_stmt|;
comment|/** Default interval for System tables memstore flush */
specifier|public
specifier|static
specifier|final
name|int
name|SYSTEM_CACHE_FLUSH_INTERVAL
init|=
literal|300000
decl_stmt|;
comment|// 5 minutes
comment|/** Conf key to force a flush if there are already enough changes for one region in memstore */
specifier|public
specifier|static
specifier|final
name|String
name|MEMSTORE_FLUSH_PER_CHANGES
init|=
literal|"hbase.regionserver.flush.per.changes"
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|long
name|DEFAULT_FLUSH_PER_CHANGES
init|=
literal|30000000
decl_stmt|;
comment|// 30 millions
comment|/**    * The following MAX_FLUSH_PER_CHANGES is large enough because each KeyValue has 20+ bytes    * overhead. Therefore, even 1G empty KVs occupy at least 20GB memstore size for a single region    */
specifier|public
specifier|static
specifier|final
name|long
name|MAX_FLUSH_PER_CHANGES
init|=
literal|1000000000
decl_stmt|;
comment|// 1G
comment|/**    * Close down this HRegion.  Flush the cache unless abort parameter is true,    * Shut down each HStore, don't service any more calls.    *    * This method could take some time to execute, so don't call it from a    * time-sensitive thread.    *    * @param abort true if server is aborting (only during testing)    * @return Vector of all the storage files that the HRegion's component    * HStores make use of.  It's a list of StoreFile objects.  Can be null if    * we are not to close at this time or we are already closed.    *    * @throws IOException e    * @throws DroppedSnapshotException Thrown when replay of wal is required    * because a Snapshot was not properly persisted. The region is put in closing mode, and the    * caller MUST abort after this.    */
specifier|public
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|List
argument_list|<
name|HStoreFile
argument_list|>
argument_list|>
name|close
parameter_list|(
name|boolean
name|abort
parameter_list|)
throws|throws
name|IOException
block|{
comment|// Only allow one thread to close at a time. Serialize them so dual
comment|// threads attempting to close will run up against each other.
name|MonitoredTask
name|status
init|=
name|TaskMonitor
operator|.
name|get
argument_list|()
operator|.
name|createStatus
argument_list|(
literal|"Closing region "
operator|+
name|this
operator|.
name|getRegionInfo
argument_list|()
operator|.
name|getEncodedName
argument_list|()
operator|+
operator|(
name|abort
condition|?
literal|" due to abort"
else|:
literal|""
operator|)
argument_list|)
decl_stmt|;
name|status
operator|.
name|setStatus
argument_list|(
literal|"Waiting for close lock"
argument_list|)
expr_stmt|;
try|try
block|{
synchronized|synchronized
init|(
name|closeLock
init|)
block|{
return|return
name|doClose
argument_list|(
name|abort
argument_list|,
name|status
argument_list|)
return|;
block|}
block|}
finally|finally
block|{
name|status
operator|.
name|cleanup
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**    * Exposed for some very specific unit tests.    */
annotation|@
name|VisibleForTesting
specifier|public
name|void
name|setClosing
parameter_list|(
name|boolean
name|closing
parameter_list|)
block|{
name|this
operator|.
name|closing
operator|.
name|set
argument_list|(
name|closing
argument_list|)
expr_stmt|;
block|}
comment|/**    * The {@link HRegion#doClose} will block forever if someone tries proving the dead lock via the unit test.    * Instead of blocking, the {@link HRegion#doClose} will throw exception if you set the timeout.    * @param timeoutForWriteLock the second time to wait for the write lock in {@link HRegion#doClose}    */
annotation|@
name|VisibleForTesting
specifier|public
name|void
name|setTimeoutForWriteLock
parameter_list|(
name|long
name|timeoutForWriteLock
parameter_list|)
block|{
assert|assert
name|timeoutForWriteLock
operator|>=
literal|0
assert|;
name|this
operator|.
name|timeoutForWriteLock
operator|=
name|timeoutForWriteLock
expr_stmt|;
block|}
annotation|@
name|edu
operator|.
name|umd
operator|.
name|cs
operator|.
name|findbugs
operator|.
name|annotations
operator|.
name|SuppressWarnings
argument_list|(
name|value
operator|=
literal|"UL_UNRELEASED_LOCK_EXCEPTION_PATH"
argument_list|,
name|justification
operator|=
literal|"I think FindBugs is confused"
argument_list|)
specifier|private
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|List
argument_list|<
name|HStoreFile
argument_list|>
argument_list|>
name|doClose
parameter_list|(
name|boolean
name|abort
parameter_list|,
name|MonitoredTask
name|status
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|isClosed
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Region "
operator|+
name|this
operator|+
literal|" already closed"
argument_list|)
expr_stmt|;
return|return
literal|null
return|;
block|}
if|if
condition|(
name|coprocessorHost
operator|!=
literal|null
condition|)
block|{
name|status
operator|.
name|setStatus
argument_list|(
literal|"Running coprocessor pre-close hooks"
argument_list|)
expr_stmt|;
name|this
operator|.
name|coprocessorHost
operator|.
name|preClose
argument_list|(
name|abort
argument_list|)
expr_stmt|;
block|}
name|status
operator|.
name|setStatus
argument_list|(
literal|"Disabling compacts and flushes for region"
argument_list|)
expr_stmt|;
name|boolean
name|canFlush
init|=
literal|true
decl_stmt|;
synchronized|synchronized
init|(
name|writestate
init|)
block|{
comment|// Disable compacting and flushing by background threads for this
comment|// region.
name|canFlush
operator|=
operator|!
name|writestate
operator|.
name|readOnly
expr_stmt|;
name|writestate
operator|.
name|writesEnabled
operator|=
literal|false
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Closing {}, disabling compactions& flushes"
argument_list|,
name|this
operator|.
name|getRegionInfo
argument_list|()
operator|.
name|getEncodedName
argument_list|()
argument_list|)
expr_stmt|;
name|waitForFlushesAndCompactions
argument_list|()
expr_stmt|;
block|}
comment|// If we were not just flushing, is it worth doing a preflush...one
comment|// that will clear out of the bulk of the memstore before we put up
comment|// the close flag?
if|if
condition|(
operator|!
name|abort
operator|&&
name|worthPreFlushing
argument_list|()
operator|&&
name|canFlush
condition|)
block|{
name|status
operator|.
name|setStatus
argument_list|(
literal|"Pre-flushing region before close"
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Running close preflush of {}"
operator|+
name|this
operator|.
name|getRegionInfo
argument_list|()
operator|.
name|getEncodedName
argument_list|()
argument_list|)
expr_stmt|;
try|try
block|{
name|internalFlushcache
argument_list|(
name|status
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ioe
parameter_list|)
block|{
comment|// Failed to flush the region. Keep going.
name|status
operator|.
name|setStatus
argument_list|(
literal|"Failed pre-flush "
operator|+
name|this
operator|+
literal|"; "
operator|+
name|ioe
operator|.
name|getMessage
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|timeoutForWriteLock
operator|==
literal|null
operator|||
name|timeoutForWriteLock
operator|==
name|Long
operator|.
name|MAX_VALUE
condition|)
block|{
comment|// block waiting for the lock for closing
name|lock
operator|.
name|writeLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
comment|// FindBugs: Complains UL_UNRELEASED_LOCK_EXCEPTION_PATH but seems fine
block|}
else|else
block|{
try|try
block|{
name|boolean
name|succeed
init|=
name|lock
operator|.
name|writeLock
argument_list|()
operator|.
name|tryLock
argument_list|(
name|timeoutForWriteLock
argument_list|,
name|TimeUnit
operator|.
name|SECONDS
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|succeed
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Failed to get write lock when closing region"
argument_list|)
throw|;
block|}
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
throw|throw
operator|(
name|InterruptedIOException
operator|)
operator|new
name|InterruptedIOException
argument_list|()
operator|.
name|initCause
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
name|this
operator|.
name|closing
operator|.
name|set
argument_list|(
literal|true
argument_list|)
expr_stmt|;
name|status
operator|.
name|setStatus
argument_list|(
literal|"Disabling writes for close"
argument_list|)
expr_stmt|;
try|try
block|{
if|if
condition|(
name|this
operator|.
name|isClosed
argument_list|()
condition|)
block|{
name|status
operator|.
name|abort
argument_list|(
literal|"Already got closed by another process"
argument_list|)
expr_stmt|;
comment|// SplitTransaction handles the null
return|return
literal|null
return|;
block|}
name|LOG
operator|.
name|debug
argument_list|(
literal|"Updates disabled for region "
operator|+
name|this
argument_list|)
expr_stmt|;
comment|// Don't flush the cache if we are aborting
if|if
condition|(
operator|!
name|abort
operator|&&
name|canFlush
condition|)
block|{
name|int
name|failedfFlushCount
init|=
literal|0
decl_stmt|;
name|int
name|flushCount
init|=
literal|0
decl_stmt|;
name|long
name|tmp
init|=
literal|0
decl_stmt|;
name|long
name|remainingSize
init|=
name|this
operator|.
name|memStoreSizing
operator|.
name|getDataSize
argument_list|()
decl_stmt|;
while|while
condition|(
name|remainingSize
operator|>
literal|0
condition|)
block|{
try|try
block|{
name|internalFlushcache
argument_list|(
name|status
argument_list|)
expr_stmt|;
if|if
condition|(
name|flushCount
operator|>
literal|0
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Running extra flush, "
operator|+
name|flushCount
operator|+
literal|" (carrying snapshot?) "
operator|+
name|this
argument_list|)
expr_stmt|;
block|}
name|flushCount
operator|++
expr_stmt|;
name|tmp
operator|=
name|this
operator|.
name|memStoreSizing
operator|.
name|getDataSize
argument_list|()
expr_stmt|;
if|if
condition|(
name|tmp
operator|>=
name|remainingSize
condition|)
block|{
name|failedfFlushCount
operator|++
expr_stmt|;
block|}
name|remainingSize
operator|=
name|tmp
expr_stmt|;
if|if
condition|(
name|failedfFlushCount
operator|>
literal|5
condition|)
block|{
comment|// If we failed 5 times and are unable to clear memory, abort
comment|// so we do not lose data
throw|throw
operator|new
name|DroppedSnapshotException
argument_list|(
literal|"Failed clearing memory after "
operator|+
name|flushCount
operator|+
literal|" attempts on region: "
operator|+
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|getRegionInfo
argument_list|()
operator|.
name|getRegionName
argument_list|()
argument_list|)
argument_list|)
throw|;
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|ioe
parameter_list|)
block|{
name|status
operator|.
name|setStatus
argument_list|(
literal|"Failed flush "
operator|+
name|this
operator|+
literal|", putting online again"
argument_list|)
expr_stmt|;
synchronized|synchronized
init|(
name|writestate
init|)
block|{
name|writestate
operator|.
name|writesEnabled
operator|=
literal|true
expr_stmt|;
block|}
comment|// Have to throw to upper layers.  I can't abort server from here.
throw|throw
name|ioe
throw|;
block|}
block|}
block|}
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|List
argument_list|<
name|HStoreFile
argument_list|>
argument_list|>
name|result
init|=
operator|new
name|TreeMap
argument_list|<>
argument_list|(
name|Bytes
operator|.
name|BYTES_COMPARATOR
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|stores
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
comment|// initialize the thread pool for closing stores in parallel.
name|ThreadPoolExecutor
name|storeCloserThreadPool
init|=
name|getStoreOpenAndCloseThreadPool
argument_list|(
literal|"StoreCloserThread-"
operator|+
name|getRegionInfo
argument_list|()
operator|.
name|getRegionNameAsString
argument_list|()
argument_list|)
decl_stmt|;
name|CompletionService
argument_list|<
name|Pair
argument_list|<
name|byte
index|[]
argument_list|,
name|Collection
argument_list|<
name|HStoreFile
argument_list|>
argument_list|>
argument_list|>
name|completionService
init|=
operator|new
name|ExecutorCompletionService
argument_list|<>
argument_list|(
name|storeCloserThreadPool
argument_list|)
decl_stmt|;
comment|// close each store in parallel
for|for
control|(
name|HStore
name|store
range|:
name|stores
operator|.
name|values
argument_list|()
control|)
block|{
name|MemStoreSize
name|mss
init|=
name|store
operator|.
name|getFlushableSize
argument_list|()
decl_stmt|;
if|if
condition|(
operator|!
operator|(
name|abort
operator|||
name|mss
operator|.
name|getDataSize
argument_list|()
operator|==
literal|0
operator|||
name|writestate
operator|.
name|readOnly
operator|)
condition|)
block|{
if|if
condition|(
name|getRegionServerServices
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|getRegionServerServices
argument_list|()
operator|.
name|abort
argument_list|(
literal|"Assertion failed while closing store "
operator|+
name|getRegionInfo
argument_list|()
operator|.
name|getRegionNameAsString
argument_list|()
operator|+
literal|" "
operator|+
name|store
operator|+
literal|". flushableSize expected=0, actual={"
operator|+
name|mss
operator|+
literal|"}. Current memStoreSize="
operator|+
name|this
operator|.
name|memStoreSizing
operator|.
name|getMemStoreSize
argument_list|()
operator|+
literal|". Maybe a coprocessor "
operator|+
literal|"operation failed and left the memstore in a partially updated state."
argument_list|,
literal|null
argument_list|)
expr_stmt|;
block|}
block|}
name|completionService
operator|.
name|submit
argument_list|(
operator|new
name|Callable
argument_list|<
name|Pair
argument_list|<
name|byte
index|[]
argument_list|,
name|Collection
argument_list|<
name|HStoreFile
argument_list|>
argument_list|>
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|Pair
argument_list|<
name|byte
index|[]
argument_list|,
name|Collection
argument_list|<
name|HStoreFile
argument_list|>
argument_list|>
name|call
parameter_list|()
throws|throws
name|IOException
block|{
return|return
operator|new
name|Pair
argument_list|<>
argument_list|(
name|store
operator|.
name|getColumnFamilyDescriptor
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|,
name|store
operator|.
name|close
argument_list|()
argument_list|)
return|;
block|}
block|}
argument_list|)
expr_stmt|;
block|}
try|try
block|{
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|stores
operator|.
name|size
argument_list|()
condition|;
name|i
operator|++
control|)
block|{
name|Future
argument_list|<
name|Pair
argument_list|<
name|byte
index|[]
argument_list|,
name|Collection
argument_list|<
name|HStoreFile
argument_list|>
argument_list|>
argument_list|>
name|future
init|=
name|completionService
operator|.
name|take
argument_list|()
decl_stmt|;
name|Pair
argument_list|<
name|byte
index|[]
argument_list|,
name|Collection
argument_list|<
name|HStoreFile
argument_list|>
argument_list|>
name|storeFiles
init|=
name|future
operator|.
name|get
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|HStoreFile
argument_list|>
name|familyFiles
init|=
name|result
operator|.
name|get
argument_list|(
name|storeFiles
operator|.
name|getFirst
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|familyFiles
operator|==
literal|null
condition|)
block|{
name|familyFiles
operator|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
expr_stmt|;
name|result
operator|.
name|put
argument_list|(
name|storeFiles
operator|.
name|getFirst
argument_list|()
argument_list|,
name|familyFiles
argument_list|)
expr_stmt|;
block|}
name|familyFiles
operator|.
name|addAll
argument_list|(
name|storeFiles
operator|.
name|getSecond
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
throw|throw
operator|(
name|InterruptedIOException
operator|)
operator|new
name|InterruptedIOException
argument_list|()
operator|.
name|initCause
argument_list|(
name|e
argument_list|)
throw|;
block|}
catch|catch
parameter_list|(
name|ExecutionException
name|e
parameter_list|)
block|{
name|Throwable
name|cause
init|=
name|e
operator|.
name|getCause
argument_list|()
decl_stmt|;
if|if
condition|(
name|cause
operator|instanceof
name|IOException
condition|)
block|{
throw|throw
operator|(
name|IOException
operator|)
name|cause
throw|;
block|}
throw|throw
operator|new
name|IOException
argument_list|(
name|cause
argument_list|)
throw|;
block|}
finally|finally
block|{
name|storeCloserThreadPool
operator|.
name|shutdownNow
argument_list|()
expr_stmt|;
block|}
block|}
name|status
operator|.
name|setStatus
argument_list|(
literal|"Writing region close event to WAL"
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|abort
operator|&&
name|wal
operator|!=
literal|null
operator|&&
name|getRegionServerServices
argument_list|()
operator|!=
literal|null
operator|&&
operator|!
name|writestate
operator|.
name|readOnly
condition|)
block|{
name|writeRegionCloseMarker
argument_list|(
name|wal
argument_list|)
expr_stmt|;
block|}
name|this
operator|.
name|closed
operator|.
name|set
argument_list|(
literal|true
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|canFlush
condition|)
block|{
name|decrMemStoreSize
argument_list|(
name|this
operator|.
name|memStoreSizing
operator|.
name|getMemStoreSize
argument_list|()
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|this
operator|.
name|memStoreSizing
operator|.
name|getDataSize
argument_list|()
operator|!=
literal|0
condition|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Memstore data size is {}"
argument_list|,
name|this
operator|.
name|memStoreSizing
operator|.
name|getDataSize
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|coprocessorHost
operator|!=
literal|null
condition|)
block|{
name|status
operator|.
name|setStatus
argument_list|(
literal|"Running coprocessor post-close hooks"
argument_list|)
expr_stmt|;
name|this
operator|.
name|coprocessorHost
operator|.
name|postClose
argument_list|(
name|abort
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|this
operator|.
name|metricsRegion
operator|!=
literal|null
condition|)
block|{
name|this
operator|.
name|metricsRegion
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|this
operator|.
name|metricsRegionWrapper
operator|!=
literal|null
condition|)
block|{
name|Closeables
operator|.
name|close
argument_list|(
name|this
operator|.
name|metricsRegionWrapper
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
name|status
operator|.
name|markComplete
argument_list|(
literal|"Closed"
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Closed "
operator|+
name|this
argument_list|)
expr_stmt|;
return|return
name|result
return|;
block|}
finally|finally
block|{
name|lock
operator|.
name|writeLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
comment|/** Wait for all current flushes and compactions of the region to complete */
comment|// TODO HBASE-18906. Check the usage (if any) in Phoenix and expose this or give alternate way for
comment|// Phoenix needs.
specifier|public
name|void
name|waitForFlushesAndCompactions
parameter_list|()
block|{
synchronized|synchronized
init|(
name|writestate
init|)
block|{
if|if
condition|(
name|this
operator|.
name|writestate
operator|.
name|readOnly
condition|)
block|{
comment|// we should not wait for replayed flushed if we are read only (for example in case the
comment|// region is a secondary replica).
return|return;
block|}
name|boolean
name|interrupted
init|=
literal|false
decl_stmt|;
try|try
block|{
while|while
condition|(
name|writestate
operator|.
name|compacting
operator|.
name|get
argument_list|()
operator|>
literal|0
operator|||
name|writestate
operator|.
name|flushing
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"waiting for "
operator|+
name|writestate
operator|.
name|compacting
operator|+
literal|" compactions"
operator|+
operator|(
name|writestate
operator|.
name|flushing
condition|?
literal|"& cache flush"
else|:
literal|""
operator|)
operator|+
literal|" to complete for region "
operator|+
name|this
argument_list|)
expr_stmt|;
try|try
block|{
name|writestate
operator|.
name|wait
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|iex
parameter_list|)
block|{
comment|// essentially ignore and propagate the interrupt back up
name|LOG
operator|.
name|warn
argument_list|(
literal|"Interrupted while waiting"
argument_list|)
expr_stmt|;
name|interrupted
operator|=
literal|true
expr_stmt|;
break|break;
block|}
block|}
block|}
finally|finally
block|{
if|if
condition|(
name|interrupted
condition|)
block|{
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|interrupt
argument_list|()
expr_stmt|;
block|}
block|}
block|}
block|}
comment|/**    * Wait for all current flushes of the region to complete    */
specifier|public
name|void
name|waitForFlushes
parameter_list|()
block|{
name|waitForFlushes
argument_list|(
literal|0
argument_list|)
expr_stmt|;
comment|// Unbound wait
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|waitForFlushes
parameter_list|(
name|long
name|timeout
parameter_list|)
block|{
synchronized|synchronized
init|(
name|writestate
init|)
block|{
if|if
condition|(
name|this
operator|.
name|writestate
operator|.
name|readOnly
condition|)
block|{
comment|// we should not wait for replayed flushed if we are read only (for example in case the
comment|// region is a secondary replica).
return|return
literal|true
return|;
block|}
if|if
condition|(
operator|!
name|writestate
operator|.
name|flushing
condition|)
return|return
literal|true
return|;
name|long
name|start
init|=
name|System
operator|.
name|currentTimeMillis
argument_list|()
decl_stmt|;
name|long
name|duration
init|=
literal|0
decl_stmt|;
name|boolean
name|interrupted
init|=
literal|false
decl_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"waiting for cache flush to complete for region "
operator|+
name|this
argument_list|)
expr_stmt|;
try|try
block|{
while|while
condition|(
name|writestate
operator|.
name|flushing
condition|)
block|{
if|if
condition|(
name|timeout
operator|>
literal|0
operator|&&
name|duration
operator|>=
name|timeout
condition|)
break|break;
try|try
block|{
name|long
name|toWait
init|=
name|timeout
operator|==
literal|0
condition|?
literal|0
else|:
operator|(
name|timeout
operator|-
name|duration
operator|)
decl_stmt|;
name|writestate
operator|.
name|wait
argument_list|(
name|toWait
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|iex
parameter_list|)
block|{
comment|// essentially ignore and propagate the interrupt back up
name|LOG
operator|.
name|warn
argument_list|(
literal|"Interrupted while waiting"
argument_list|)
expr_stmt|;
name|interrupted
operator|=
literal|true
expr_stmt|;
break|break;
block|}
finally|finally
block|{
name|duration
operator|=
name|System
operator|.
name|currentTimeMillis
argument_list|()
operator|-
name|start
expr_stmt|;
block|}
block|}
block|}
finally|finally
block|{
if|if
condition|(
name|interrupted
condition|)
block|{
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|interrupt
argument_list|()
expr_stmt|;
block|}
block|}
name|LOG
operator|.
name|debug
argument_list|(
literal|"Waited "
operator|+
name|duration
operator|+
literal|" ms for flush to complete"
argument_list|)
expr_stmt|;
return|return
operator|!
operator|(
name|writestate
operator|.
name|flushing
operator|)
return|;
block|}
block|}
specifier|protected
name|ThreadPoolExecutor
name|getStoreOpenAndCloseThreadPool
parameter_list|(
specifier|final
name|String
name|threadNamePrefix
parameter_list|)
block|{
name|int
name|numStores
init|=
name|Math
operator|.
name|max
argument_list|(
literal|1
argument_list|,
name|this
operator|.
name|htableDescriptor
operator|.
name|getColumnFamilyCount
argument_list|()
argument_list|)
decl_stmt|;
name|int
name|maxThreads
init|=
name|Math
operator|.
name|min
argument_list|(
name|numStores
argument_list|,
name|conf
operator|.
name|getInt
argument_list|(
name|HConstants
operator|.
name|HSTORE_OPEN_AND_CLOSE_THREADS_MAX
argument_list|,
name|HConstants
operator|.
name|DEFAULT_HSTORE_OPEN_AND_CLOSE_THREADS_MAX
argument_list|)
argument_list|)
decl_stmt|;
return|return
name|getOpenAndCloseThreadPool
argument_list|(
name|maxThreads
argument_list|,
name|threadNamePrefix
argument_list|)
return|;
block|}
specifier|protected
name|ThreadPoolExecutor
name|getStoreFileOpenAndCloseThreadPool
parameter_list|(
specifier|final
name|String
name|threadNamePrefix
parameter_list|)
block|{
name|int
name|numStores
init|=
name|Math
operator|.
name|max
argument_list|(
literal|1
argument_list|,
name|this
operator|.
name|htableDescriptor
operator|.
name|getColumnFamilyCount
argument_list|()
argument_list|)
decl_stmt|;
name|int
name|maxThreads
init|=
name|Math
operator|.
name|max
argument_list|(
literal|1
argument_list|,
name|conf
operator|.
name|getInt
argument_list|(
name|HConstants
operator|.
name|HSTORE_OPEN_AND_CLOSE_THREADS_MAX
argument_list|,
name|HConstants
operator|.
name|DEFAULT_HSTORE_OPEN_AND_CLOSE_THREADS_MAX
argument_list|)
operator|/
name|numStores
argument_list|)
decl_stmt|;
return|return
name|getOpenAndCloseThreadPool
argument_list|(
name|maxThreads
argument_list|,
name|threadNamePrefix
argument_list|)
return|;
block|}
specifier|static
name|ThreadPoolExecutor
name|getOpenAndCloseThreadPool
parameter_list|(
name|int
name|maxThreads
parameter_list|,
specifier|final
name|String
name|threadNamePrefix
parameter_list|)
block|{
return|return
name|Threads
operator|.
name|getBoundedCachedThreadPool
argument_list|(
name|maxThreads
argument_list|,
literal|30L
argument_list|,
name|TimeUnit
operator|.
name|SECONDS
argument_list|,
operator|new
name|ThreadFactory
argument_list|()
block|{
specifier|private
name|int
name|count
init|=
literal|1
decl_stmt|;
annotation|@
name|Override
specifier|public
name|Thread
name|newThread
parameter_list|(
name|Runnable
name|r
parameter_list|)
block|{
return|return
operator|new
name|Thread
argument_list|(
name|r
argument_list|,
name|threadNamePrefix
operator|+
literal|"-"
operator|+
name|count
operator|++
argument_list|)
return|;
block|}
block|}
argument_list|)
return|;
block|}
comment|/**     * @return True if its worth doing a flush before we put up the close flag.     */
specifier|private
name|boolean
name|worthPreFlushing
parameter_list|()
block|{
return|return
name|this
operator|.
name|memStoreSizing
operator|.
name|getDataSize
argument_list|()
operator|>
name|this
operator|.
name|conf
operator|.
name|getLong
argument_list|(
literal|"hbase.hregion.preclose.flush.size"
argument_list|,
literal|1024
operator|*
literal|1024
operator|*
literal|5
argument_list|)
return|;
block|}
comment|//////////////////////////////////////////////////////////////////////////////
comment|// HRegion accessors
comment|//////////////////////////////////////////////////////////////////////////////
annotation|@
name|Override
specifier|public
name|TableDescriptor
name|getTableDescriptor
parameter_list|()
block|{
return|return
name|this
operator|.
name|htableDescriptor
return|;
block|}
annotation|@
name|VisibleForTesting
name|void
name|setTableDescriptor
parameter_list|(
name|TableDescriptor
name|desc
parameter_list|)
block|{
name|htableDescriptor
operator|=
name|desc
expr_stmt|;
block|}
comment|/** @return WAL in use for this region */
specifier|public
name|WAL
name|getWAL
parameter_list|()
block|{
return|return
name|this
operator|.
name|wal
return|;
block|}
comment|/**    * @return split policy for this region.    */
specifier|public
name|RegionSplitPolicy
name|getSplitPolicy
parameter_list|()
block|{
return|return
name|this
operator|.
name|splitPolicy
return|;
block|}
comment|/**    * A split takes the config from the parent region& passes it to the daughter    * region's constructor. If 'conf' was passed, you would end up using the HTD    * of the parent region in addition to the new daughter HTD. Pass 'baseConf'    * to the daughter regions to avoid this tricky dedupe problem.    * @return Configuration object    */
name|Configuration
name|getBaseConf
parameter_list|()
block|{
return|return
name|this
operator|.
name|baseConf
return|;
block|}
comment|/** @return {@link FileSystem} being used by this region */
specifier|public
name|FileSystem
name|getFilesystem
parameter_list|()
block|{
return|return
name|fs
operator|.
name|getFileSystem
argument_list|()
return|;
block|}
comment|/** @return the {@link HRegionFileSystem} used by this region */
specifier|public
name|HRegionFileSystem
name|getRegionFileSystem
parameter_list|()
block|{
return|return
name|this
operator|.
name|fs
return|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|getEarliestFlushTimeForAllStores
parameter_list|()
block|{
return|return
name|Collections
operator|.
name|min
argument_list|(
name|lastStoreFlushTimeMap
operator|.
name|values
argument_list|()
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|getOldestHfileTs
parameter_list|(
name|boolean
name|majorCompactionOnly
parameter_list|)
throws|throws
name|IOException
block|{
name|long
name|result
init|=
name|Long
operator|.
name|MAX_VALUE
decl_stmt|;
for|for
control|(
name|HStore
name|store
range|:
name|stores
operator|.
name|values
argument_list|()
control|)
block|{
name|Collection
argument_list|<
name|HStoreFile
argument_list|>
name|storeFiles
init|=
name|store
operator|.
name|getStorefiles
argument_list|()
decl_stmt|;
if|if
condition|(
name|storeFiles
operator|==
literal|null
condition|)
block|{
continue|continue;
block|}
for|for
control|(
name|HStoreFile
name|file
range|:
name|storeFiles
control|)
block|{
name|StoreFileReader
name|sfReader
init|=
name|file
operator|.
name|getReader
argument_list|()
decl_stmt|;
if|if
condition|(
name|sfReader
operator|==
literal|null
condition|)
block|{
continue|continue;
block|}
name|HFile
operator|.
name|Reader
name|reader
init|=
name|sfReader
operator|.
name|getHFileReader
argument_list|()
decl_stmt|;
if|if
condition|(
name|reader
operator|==
literal|null
condition|)
block|{
continue|continue;
block|}
if|if
condition|(
name|majorCompactionOnly
condition|)
block|{
name|byte
index|[]
name|val
init|=
name|reader
operator|.
name|loadFileInfo
argument_list|()
operator|.
name|get
argument_list|(
name|MAJOR_COMPACTION_KEY
argument_list|)
decl_stmt|;
if|if
condition|(
name|val
operator|==
literal|null
operator|||
operator|!
name|Bytes
operator|.
name|toBoolean
argument_list|(
name|val
argument_list|)
condition|)
block|{
continue|continue;
block|}
block|}
name|result
operator|=
name|Math
operator|.
name|min
argument_list|(
name|result
argument_list|,
name|reader
operator|.
name|getFileContext
argument_list|()
operator|.
name|getFileCreateTime
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|result
operator|==
name|Long
operator|.
name|MAX_VALUE
condition|?
literal|0
else|:
name|result
return|;
block|}
name|RegionLoad
operator|.
name|Builder
name|setCompleteSequenceId
parameter_list|(
name|RegionLoad
operator|.
name|Builder
name|regionLoadBldr
parameter_list|)
block|{
name|long
name|lastFlushOpSeqIdLocal
init|=
name|this
operator|.
name|lastFlushOpSeqId
decl_stmt|;
name|byte
index|[]
name|encodedRegionName
init|=
name|this
operator|.
name|getRegionInfo
argument_list|()
operator|.
name|getEncodedNameAsBytes
argument_list|()
decl_stmt|;
name|regionLoadBldr
operator|.
name|clearStoreCompleteSequenceId
argument_list|()
expr_stmt|;
for|for
control|(
name|byte
index|[]
name|familyName
range|:
name|this
operator|.
name|stores
operator|.
name|keySet
argument_list|()
control|)
block|{
name|long
name|earliest
init|=
name|this
operator|.
name|wal
operator|.
name|getEarliestMemStoreSeqNum
argument_list|(
name|encodedRegionName
argument_list|,
name|familyName
argument_list|)
decl_stmt|;
comment|// Subtract - 1 to go earlier than the current oldest, unflushed edit in memstore; this will
comment|// give us a sequence id that is for sure flushed. We want edit replay to start after this
comment|// sequence id in this region. If NO_SEQNUM, use the regions maximum flush id.
name|long
name|csid
init|=
operator|(
name|earliest
operator|==
name|HConstants
operator|.
name|NO_SEQNUM
operator|)
condition|?
name|lastFlushOpSeqIdLocal
else|:
name|earliest
operator|-
literal|1
decl_stmt|;
name|regionLoadBldr
operator|.
name|addStoreCompleteSequenceId
argument_list|(
name|StoreSequenceId
operator|.
name|newBuilder
argument_list|()
operator|.
name|setFamilyName
argument_list|(
name|UnsafeByteOperations
operator|.
name|unsafeWrap
argument_list|(
name|familyName
argument_list|)
argument_list|)
operator|.
name|setSequenceId
argument_list|(
name|csid
argument_list|)
operator|.
name|build
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
name|regionLoadBldr
operator|.
name|setCompleteSequenceId
argument_list|(
name|getMaxFlushedSeqId
argument_list|()
argument_list|)
return|;
block|}
comment|//////////////////////////////////////////////////////////////////////////////
comment|// HRegion maintenance.
comment|//
comment|// These methods are meant to be called periodically by the HRegionServer for
comment|// upkeep.
comment|//////////////////////////////////////////////////////////////////////////////
comment|/**    * Do preparation for pending compaction.    * @throws IOException    */
specifier|protected
name|void
name|doRegionCompactionPrep
parameter_list|()
throws|throws
name|IOException
block|{   }
comment|/**    * Synchronously compact all stores in the region.    *<p>This operation could block for a long time, so don't call it from a    * time-sensitive thread.    *<p>Note that no locks are taken to prevent possible conflicts between    * compaction and splitting activities. The regionserver does not normally compact    * and split in parallel. However by calling this method you may introduce    * unexpected and unhandled concurrency. Don't do this unless you know what    * you are doing.    *    * @param majorCompaction True to force a major compaction regardless of thresholds    * @throws IOException    */
specifier|public
name|void
name|compact
parameter_list|(
name|boolean
name|majorCompaction
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|majorCompaction
condition|)
block|{
name|stores
operator|.
name|values
argument_list|()
operator|.
name|forEach
argument_list|(
name|HStore
operator|::
name|triggerMajorCompaction
argument_list|)
expr_stmt|;
block|}
for|for
control|(
name|HStore
name|s
range|:
name|stores
operator|.
name|values
argument_list|()
control|)
block|{
name|Optional
argument_list|<
name|CompactionContext
argument_list|>
name|compaction
init|=
name|s
operator|.
name|requestCompaction
argument_list|()
decl_stmt|;
if|if
condition|(
name|compaction
operator|.
name|isPresent
argument_list|()
condition|)
block|{
name|ThroughputController
name|controller
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|rsServices
operator|!=
literal|null
condition|)
block|{
name|controller
operator|=
name|CompactionThroughputControllerFactory
operator|.
name|create
argument_list|(
name|rsServices
argument_list|,
name|conf
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|controller
operator|==
literal|null
condition|)
block|{
name|controller
operator|=
name|NoLimitThroughputController
operator|.
name|INSTANCE
expr_stmt|;
block|}
name|compact
argument_list|(
name|compaction
operator|.
name|get
argument_list|()
argument_list|,
name|s
argument_list|,
name|controller
argument_list|,
literal|null
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|/**    * This is a helper function that compact all the stores synchronously.    *<p>    * It is used by utilities and testing    */
annotation|@
name|VisibleForTesting
specifier|public
name|void
name|compactStores
parameter_list|()
throws|throws
name|IOException
block|{
for|for
control|(
name|HStore
name|s
range|:
name|stores
operator|.
name|values
argument_list|()
control|)
block|{
name|Optional
argument_list|<
name|CompactionContext
argument_list|>
name|compaction
init|=
name|s
operator|.
name|requestCompaction
argument_list|()
decl_stmt|;
if|if
condition|(
name|compaction
operator|.
name|isPresent
argument_list|()
condition|)
block|{
name|compact
argument_list|(
name|compaction
operator|.
name|get
argument_list|()
argument_list|,
name|s
argument_list|,
name|NoLimitThroughputController
operator|.
name|INSTANCE
argument_list|,
literal|null
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|/**    * This is a helper function that compact the given store.    *<p>    * It is used by utilities and testing    */
annotation|@
name|VisibleForTesting
name|void
name|compactStore
parameter_list|(
name|byte
index|[]
name|family
parameter_list|,
name|ThroughputController
name|throughputController
parameter_list|)
throws|throws
name|IOException
block|{
name|HStore
name|s
init|=
name|getStore
argument_list|(
name|family
argument_list|)
decl_stmt|;
name|Optional
argument_list|<
name|CompactionContext
argument_list|>
name|compaction
init|=
name|s
operator|.
name|requestCompaction
argument_list|()
decl_stmt|;
if|if
condition|(
name|compaction
operator|.
name|isPresent
argument_list|()
condition|)
block|{
name|compact
argument_list|(
name|compaction
operator|.
name|get
argument_list|()
argument_list|,
name|s
argument_list|,
name|throughputController
argument_list|,
literal|null
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Called by compaction thread and after region is opened to compact the    * HStores if necessary.    *    *<p>This operation could block for a long time, so don't call it from a    * time-sensitive thread.    *    * Note that no locking is necessary at this level because compaction only    * conflicts with a region split, and that cannot happen because the region    * server does them sequentially and not in parallel.    *    * @param compaction Compaction details, obtained by requestCompaction()    * @param throughputController    * @return whether the compaction completed    */
specifier|public
name|boolean
name|compact
parameter_list|(
name|CompactionContext
name|compaction
parameter_list|,
name|HStore
name|store
parameter_list|,
name|ThroughputController
name|throughputController
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|compact
argument_list|(
name|compaction
argument_list|,
name|store
argument_list|,
name|throughputController
argument_list|,
literal|null
argument_list|)
return|;
block|}
specifier|public
name|boolean
name|compact
parameter_list|(
name|CompactionContext
name|compaction
parameter_list|,
name|HStore
name|store
parameter_list|,
name|ThroughputController
name|throughputController
parameter_list|,
name|User
name|user
parameter_list|)
throws|throws
name|IOException
block|{
assert|assert
name|compaction
operator|!=
literal|null
operator|&&
name|compaction
operator|.
name|hasSelection
argument_list|()
assert|;
assert|assert
operator|!
name|compaction
operator|.
name|getRequest
argument_list|()
operator|.
name|getFiles
argument_list|()
operator|.
name|isEmpty
argument_list|()
assert|;
if|if
condition|(
name|this
operator|.
name|closing
operator|.
name|get
argument_list|()
operator|||
name|this
operator|.
name|closed
operator|.
name|get
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Skipping compaction on "
operator|+
name|this
operator|+
literal|" because closing/closed"
argument_list|)
expr_stmt|;
name|store
operator|.
name|cancelRequestedCompaction
argument_list|(
name|compaction
argument_list|)
expr_stmt|;
return|return
literal|false
return|;
block|}
name|MonitoredTask
name|status
init|=
literal|null
decl_stmt|;
name|boolean
name|requestNeedsCancellation
init|=
literal|true
decl_stmt|;
comment|/*      * We are trying to remove / relax the region read lock for compaction.      * Let's see what are the potential race conditions among the operations (user scan,      * region split, region close and region bulk load).      *      *  user scan ---> region read lock      *  region split --> region close first --> region write lock      *  region close --> region write lock      *  region bulk load --> region write lock      *      * read lock is compatible with read lock. ---> no problem with user scan/read      * region bulk load does not cause problem for compaction (no consistency problem, store lock      *  will help the store file accounting).      * They can run almost concurrently at the region level.      *      * The only remaining race condition is between the region close and compaction.      * So we will evaluate, below, how region close intervenes with compaction if compaction does      * not acquire region read lock.      *      * Here are the steps for compaction:      * 1. obtain list of StoreFile's      * 2. create StoreFileScanner's based on list from #1      * 3. perform compaction and save resulting files under tmp dir      * 4. swap in compacted files      *      * #1 is guarded by store lock. This patch does not change this --> no worse or better      * For #2, we obtain smallest read point (for region) across all the Scanners (for both default      * compactor and stripe compactor).      * The read points are for user scans. Region keeps the read points for all currently open      * user scanners.      * Compaction needs to know the smallest read point so that during re-write of the hfiles,      * it can remove the mvcc points for the cells if their mvccs are older than the smallest      * since they are not needed anymore.      * This will not conflict with compaction.      * For #3, it can be performed in parallel to other operations.      * For #4 bulk load and compaction don't conflict with each other on the region level      *   (for multi-family atomicy).      * Region close and compaction are guarded pretty well by the 'writestate'.      * In HRegion#doClose(), we have :      * synchronized (writestate) {      *   // Disable compacting and flushing by background threads for this      *   // region.      *   canFlush = !writestate.readOnly;      *   writestate.writesEnabled = false;      *   LOG.debug("Closing " + this + ": disabling compactions& flushes");      *   waitForFlushesAndCompactions();      * }      * waitForFlushesAndCompactions() would wait for writestate.compacting to come down to 0.      * and in HRegion.compact()      *  try {      *    synchronized (writestate) {      *    if (writestate.writesEnabled) {      *      wasStateSet = true;      *      ++writestate.compacting;      *    } else {      *      String msg = "NOT compacting region " + this + ". Writes disabled.";      *      LOG.info(msg);      *      status.abort(msg);      *      return false;      *    }      *  }      * Also in compactor.performCompaction():      * check periodically to see if a system stop is requested      * if (closeCheckInterval> 0) {      *   bytesWritten += len;      *   if (bytesWritten> closeCheckInterval) {      *     bytesWritten = 0;      *     if (!store.areWritesEnabled()) {      *       progress.cancel();      *       return false;      *     }      *   }      * }      */
try|try
block|{
name|byte
index|[]
name|cf
init|=
name|Bytes
operator|.
name|toBytes
argument_list|(
name|store
operator|.
name|getColumnFamilyName
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|stores
operator|.
name|get
argument_list|(
name|cf
argument_list|)
operator|!=
name|store
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Store "
operator|+
name|store
operator|.
name|getColumnFamilyName
argument_list|()
operator|+
literal|" on region "
operator|+
name|this
operator|+
literal|" has been re-instantiated, cancel this compaction request. "
operator|+
literal|" It may be caused by the roll back of split transaction"
argument_list|)
expr_stmt|;
return|return
literal|false
return|;
block|}
name|status
operator|=
name|TaskMonitor
operator|.
name|get
argument_list|()
operator|.
name|createStatus
argument_list|(
literal|"Compacting "
operator|+
name|store
operator|+
literal|" in "
operator|+
name|this
argument_list|)
expr_stmt|;
if|if
condition|(
name|this
operator|.
name|closed
operator|.
name|get
argument_list|()
condition|)
block|{
name|String
name|msg
init|=
literal|"Skipping compaction on "
operator|+
name|this
operator|+
literal|" because closed"
decl_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
name|msg
argument_list|)
expr_stmt|;
name|status
operator|.
name|abort
argument_list|(
name|msg
argument_list|)
expr_stmt|;
return|return
literal|false
return|;
block|}
name|boolean
name|wasStateSet
init|=
literal|false
decl_stmt|;
try|try
block|{
synchronized|synchronized
init|(
name|writestate
init|)
block|{
if|if
condition|(
name|writestate
operator|.
name|writesEnabled
condition|)
block|{
name|wasStateSet
operator|=
literal|true
expr_stmt|;
name|writestate
operator|.
name|compacting
operator|.
name|incrementAndGet
argument_list|()
expr_stmt|;
block|}
else|else
block|{
name|String
name|msg
init|=
literal|"NOT compacting region "
operator|+
name|this
operator|+
literal|". Writes disabled."
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
name|msg
argument_list|)
expr_stmt|;
name|status
operator|.
name|abort
argument_list|(
name|msg
argument_list|)
expr_stmt|;
return|return
literal|false
return|;
block|}
block|}
name|LOG
operator|.
name|info
argument_list|(
literal|"Starting compaction of {} in {}{}"
argument_list|,
name|store
argument_list|,
name|this
argument_list|,
operator|(
name|compaction
operator|.
name|getRequest
argument_list|()
operator|.
name|isOffPeak
argument_list|()
condition|?
literal|" as an off-peak compaction"
else|:
literal|""
operator|)
argument_list|)
expr_stmt|;
name|doRegionCompactionPrep
argument_list|()
expr_stmt|;
try|try
block|{
name|status
operator|.
name|setStatus
argument_list|(
literal|"Compacting store "
operator|+
name|store
argument_list|)
expr_stmt|;
comment|// We no longer need to cancel the request on the way out of this
comment|// method because Store#compact will clean up unconditionally
name|requestNeedsCancellation
operator|=
literal|false
expr_stmt|;
name|store
operator|.
name|compact
argument_list|(
name|compaction
argument_list|,
name|throughputController
argument_list|,
name|user
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedIOException
name|iioe
parameter_list|)
block|{
name|String
name|msg
init|=
literal|"compaction interrupted"
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
name|msg
argument_list|,
name|iioe
argument_list|)
expr_stmt|;
name|status
operator|.
name|abort
argument_list|(
name|msg
argument_list|)
expr_stmt|;
return|return
literal|false
return|;
block|}
block|}
finally|finally
block|{
if|if
condition|(
name|wasStateSet
condition|)
block|{
synchronized|synchronized
init|(
name|writestate
init|)
block|{
name|writestate
operator|.
name|compacting
operator|.
name|decrementAndGet
argument_list|()
expr_stmt|;
if|if
condition|(
name|writestate
operator|.
name|compacting
operator|.
name|get
argument_list|()
operator|<=
literal|0
condition|)
block|{
name|writestate
operator|.
name|notifyAll
argument_list|()
expr_stmt|;
block|}
block|}
block|}
block|}
name|status
operator|.
name|markComplete
argument_list|(
literal|"Compaction complete"
argument_list|)
expr_stmt|;
return|return
literal|true
return|;
block|}
finally|finally
block|{
if|if
condition|(
name|requestNeedsCancellation
condition|)
name|store
operator|.
name|cancelRequestedCompaction
argument_list|(
name|compaction
argument_list|)
expr_stmt|;
if|if
condition|(
name|status
operator|!=
literal|null
condition|)
name|status
operator|.
name|cleanup
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**    * Flush the cache.    *    *<p>When this method is called the cache will be flushed unless:    *<ol>    *<li>the cache is empty</li>    *<li>the region is closed.</li>    *<li>a flush is already in progress</li>    *<li>writes are disabled</li>    *</ol>    *    *<p>This method may block for some time, so it should not be called from a    * time-sensitive thread.    * @param force whether we want to force a flush of all stores    * @return FlushResult indicating whether the flush was successful or not and if    * the region needs compacting    *    * @throws IOException general io exceptions    * because a snapshot was not properly persisted.    */
comment|// TODO HBASE-18905. We might have to expose a requestFlush API for CPs
specifier|public
name|FlushResult
name|flush
parameter_list|(
name|boolean
name|force
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|flushcache
argument_list|(
name|force
argument_list|,
literal|false
argument_list|,
name|FlushLifeCycleTracker
operator|.
name|DUMMY
argument_list|)
return|;
block|}
specifier|public
interface|interface
name|FlushResult
block|{
enum|enum
name|Result
block|{
name|FLUSHED_NO_COMPACTION_NEEDED
block|,
name|FLUSHED_COMPACTION_NEEDED
block|,
comment|// Special case where a flush didn't run because there's nothing in the memstores. Used when
comment|// bulk loading to know when we can still load even if a flush didn't happen.
name|CANNOT_FLUSH_MEMSTORE_EMPTY
block|,
name|CANNOT_FLUSH
block|}
comment|/** @return the detailed result code */
name|Result
name|getResult
parameter_list|()
function_decl|;
comment|/** @return true if the memstores were flushed, else false */
name|boolean
name|isFlushSucceeded
parameter_list|()
function_decl|;
comment|/** @return True if the flush requested a compaction, else false */
name|boolean
name|isCompactionNeeded
parameter_list|()
function_decl|;
block|}
comment|/**    * Flush the cache.    *    * When this method is called the cache will be flushed unless:    *<ol>    *<li>the cache is empty</li>    *<li>the region is closed.</li>    *<li>a flush is already in progress</li>    *<li>writes are disabled</li>    *</ol>    *    *<p>This method may block for some time, so it should not be called from a    * time-sensitive thread.    * @param forceFlushAllStores whether we want to flush all stores    * @param writeFlushRequestWalMarker whether to write the flush request marker to WAL    * @param tracker used to track the life cycle of this flush    * @return whether the flush is success and whether the region needs compacting    *    * @throws IOException general io exceptions    * @throws DroppedSnapshotException Thrown when replay of wal is required    * because a Snapshot was not properly persisted. The region is put in closing mode, and the    * caller MUST abort after this.    */
specifier|public
name|FlushResultImpl
name|flushcache
parameter_list|(
name|boolean
name|forceFlushAllStores
parameter_list|,
name|boolean
name|writeFlushRequestWalMarker
parameter_list|,
name|FlushLifeCycleTracker
name|tracker
parameter_list|)
throws|throws
name|IOException
block|{
comment|// fail-fast instead of waiting on the lock
if|if
condition|(
name|this
operator|.
name|closing
operator|.
name|get
argument_list|()
condition|)
block|{
name|String
name|msg
init|=
literal|"Skipping flush on "
operator|+
name|this
operator|+
literal|" because closing"
decl_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
name|msg
argument_list|)
expr_stmt|;
return|return
operator|new
name|FlushResultImpl
argument_list|(
name|FlushResult
operator|.
name|Result
operator|.
name|CANNOT_FLUSH
argument_list|,
name|msg
argument_list|,
literal|false
argument_list|)
return|;
block|}
name|MonitoredTask
name|status
init|=
name|TaskMonitor
operator|.
name|get
argument_list|()
operator|.
name|createStatus
argument_list|(
literal|"Flushing "
operator|+
name|this
argument_list|)
decl_stmt|;
name|status
operator|.
name|setStatus
argument_list|(
literal|"Acquiring readlock on region"
argument_list|)
expr_stmt|;
comment|// block waiting for the lock for flushing cache
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
if|if
condition|(
name|this
operator|.
name|closed
operator|.
name|get
argument_list|()
condition|)
block|{
name|String
name|msg
init|=
literal|"Skipping flush on "
operator|+
name|this
operator|+
literal|" because closed"
decl_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
name|msg
argument_list|)
expr_stmt|;
name|status
operator|.
name|abort
argument_list|(
name|msg
argument_list|)
expr_stmt|;
return|return
operator|new
name|FlushResultImpl
argument_list|(
name|FlushResult
operator|.
name|Result
operator|.
name|CANNOT_FLUSH
argument_list|,
name|msg
argument_list|,
literal|false
argument_list|)
return|;
block|}
if|if
condition|(
name|coprocessorHost
operator|!=
literal|null
condition|)
block|{
name|status
operator|.
name|setStatus
argument_list|(
literal|"Running coprocessor pre-flush hooks"
argument_list|)
expr_stmt|;
name|coprocessorHost
operator|.
name|preFlush
argument_list|(
name|tracker
argument_list|)
expr_stmt|;
block|}
comment|// TODO: this should be managed within memstore with the snapshot, updated only after flush
comment|// successful
if|if
condition|(
name|numMutationsWithoutWAL
operator|.
name|sum
argument_list|()
operator|>
literal|0
condition|)
block|{
name|numMutationsWithoutWAL
operator|.
name|reset
argument_list|()
expr_stmt|;
name|dataInMemoryWithoutWAL
operator|.
name|reset
argument_list|()
expr_stmt|;
block|}
synchronized|synchronized
init|(
name|writestate
init|)
block|{
if|if
condition|(
operator|!
name|writestate
operator|.
name|flushing
operator|&&
name|writestate
operator|.
name|writesEnabled
condition|)
block|{
name|this
operator|.
name|writestate
operator|.
name|flushing
operator|=
literal|true
expr_stmt|;
block|}
else|else
block|{
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"NOT flushing memstore for region "
operator|+
name|this
operator|+
literal|", flushing="
operator|+
name|writestate
operator|.
name|flushing
operator|+
literal|", writesEnabled="
operator|+
name|writestate
operator|.
name|writesEnabled
argument_list|)
expr_stmt|;
block|}
name|String
name|msg
init|=
literal|"Not flushing since "
operator|+
operator|(
name|writestate
operator|.
name|flushing
condition|?
literal|"already flushing"
else|:
literal|"writes not enabled"
operator|)
decl_stmt|;
name|status
operator|.
name|abort
argument_list|(
name|msg
argument_list|)
expr_stmt|;
return|return
operator|new
name|FlushResultImpl
argument_list|(
name|FlushResult
operator|.
name|Result
operator|.
name|CANNOT_FLUSH
argument_list|,
name|msg
argument_list|,
literal|false
argument_list|)
return|;
block|}
block|}
try|try
block|{
name|Collection
argument_list|<
name|HStore
argument_list|>
name|specificStoresToFlush
init|=
name|forceFlushAllStores
condition|?
name|stores
operator|.
name|values
argument_list|()
else|:
name|flushPolicy
operator|.
name|selectStoresToFlush
argument_list|()
decl_stmt|;
name|FlushResultImpl
name|fs
init|=
name|internalFlushcache
argument_list|(
name|specificStoresToFlush
argument_list|,
name|status
argument_list|,
name|writeFlushRequestWalMarker
argument_list|,
name|tracker
argument_list|)
decl_stmt|;
if|if
condition|(
name|coprocessorHost
operator|!=
literal|null
condition|)
block|{
name|status
operator|.
name|setStatus
argument_list|(
literal|"Running post-flush coprocessor hooks"
argument_list|)
expr_stmt|;
name|coprocessorHost
operator|.
name|postFlush
argument_list|(
name|tracker
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|fs
operator|.
name|isFlushSucceeded
argument_list|()
condition|)
block|{
name|flushesQueued
operator|.
name|reset
argument_list|()
expr_stmt|;
block|}
name|status
operator|.
name|markComplete
argument_list|(
literal|"Flush successful"
argument_list|)
expr_stmt|;
return|return
name|fs
return|;
block|}
finally|finally
block|{
synchronized|synchronized
init|(
name|writestate
init|)
block|{
name|writestate
operator|.
name|flushing
operator|=
literal|false
expr_stmt|;
name|this
operator|.
name|writestate
operator|.
name|flushRequested
operator|=
literal|false
expr_stmt|;
name|writestate
operator|.
name|notifyAll
argument_list|()
expr_stmt|;
block|}
block|}
block|}
finally|finally
block|{
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
name|status
operator|.
name|cleanup
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**    * Should the store be flushed because it is old enough.    *<p>    * Every FlushPolicy should call this to determine whether a store is old enough to flush (except    * that you always flush all stores). Otherwise the method will always    * returns true which will make a lot of flush requests.    */
name|boolean
name|shouldFlushStore
parameter_list|(
name|HStore
name|store
parameter_list|)
block|{
name|long
name|earliest
init|=
name|this
operator|.
name|wal
operator|.
name|getEarliestMemStoreSeqNum
argument_list|(
name|getRegionInfo
argument_list|()
operator|.
name|getEncodedNameAsBytes
argument_list|()
argument_list|,
name|store
operator|.
name|getColumnFamilyDescriptor
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|)
operator|-
literal|1
decl_stmt|;
if|if
condition|(
name|earliest
operator|>
literal|0
operator|&&
name|earliest
operator|+
name|flushPerChanges
operator|<
name|mvcc
operator|.
name|getReadPoint
argument_list|()
condition|)
block|{
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Flush column family "
operator|+
name|store
operator|.
name|getColumnFamilyName
argument_list|()
operator|+
literal|" of "
operator|+
name|getRegionInfo
argument_list|()
operator|.
name|getEncodedName
argument_list|()
operator|+
literal|" because unflushed sequenceid="
operator|+
name|earliest
operator|+
literal|" is> "
operator|+
name|this
operator|.
name|flushPerChanges
operator|+
literal|" from current="
operator|+
name|mvcc
operator|.
name|getReadPoint
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
literal|true
return|;
block|}
if|if
condition|(
name|this
operator|.
name|flushCheckInterval
operator|<=
literal|0
condition|)
block|{
return|return
literal|false
return|;
block|}
name|long
name|now
init|=
name|EnvironmentEdgeManager
operator|.
name|currentTime
argument_list|()
decl_stmt|;
if|if
condition|(
name|store
operator|.
name|timeOfOldestEdit
argument_list|()
operator|<
name|now
operator|-
name|this
operator|.
name|flushCheckInterval
condition|)
block|{
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Flush column family: "
operator|+
name|store
operator|.
name|getColumnFamilyName
argument_list|()
operator|+
literal|" of "
operator|+
name|getRegionInfo
argument_list|()
operator|.
name|getEncodedName
argument_list|()
operator|+
literal|" because time of oldest edit="
operator|+
name|store
operator|.
name|timeOfOldestEdit
argument_list|()
operator|+
literal|" is> "
operator|+
name|this
operator|.
name|flushCheckInterval
operator|+
literal|" from now ="
operator|+
name|now
argument_list|)
expr_stmt|;
block|}
return|return
literal|true
return|;
block|}
return|return
literal|false
return|;
block|}
comment|/**    * Should the memstore be flushed now    */
name|boolean
name|shouldFlush
parameter_list|(
specifier|final
name|StringBuilder
name|whyFlush
parameter_list|)
block|{
name|whyFlush
operator|.
name|setLength
argument_list|(
literal|0
argument_list|)
expr_stmt|;
comment|// This is a rough measure.
if|if
condition|(
name|this
operator|.
name|maxFlushedSeqId
operator|>
literal|0
operator|&&
operator|(
name|this
operator|.
name|maxFlushedSeqId
operator|+
name|this
operator|.
name|flushPerChanges
operator|<
name|this
operator|.
name|mvcc
operator|.
name|getReadPoint
argument_list|()
operator|)
condition|)
block|{
name|whyFlush
operator|.
name|append
argument_list|(
literal|"more than max edits, "
operator|+
name|this
operator|.
name|flushPerChanges
operator|+
literal|", since last flush"
argument_list|)
expr_stmt|;
return|return
literal|true
return|;
block|}
name|long
name|modifiedFlushCheckInterval
init|=
name|flushCheckInterval
decl_stmt|;
if|if
condition|(
name|getRegionInfo
argument_list|()
operator|.
name|getTable
argument_list|()
operator|.
name|isSystemTable
argument_list|()
operator|&&
name|getRegionInfo
argument_list|()
operator|.
name|getReplicaId
argument_list|()
operator|==
name|RegionInfo
operator|.
name|DEFAULT_REPLICA_ID
condition|)
block|{
name|modifiedFlushCheckInterval
operator|=
name|SYSTEM_CACHE_FLUSH_INTERVAL
expr_stmt|;
block|}
if|if
condition|(
name|modifiedFlushCheckInterval
operator|<=
literal|0
condition|)
block|{
comment|//disabled
return|return
literal|false
return|;
block|}
name|long
name|now
init|=
name|EnvironmentEdgeManager
operator|.
name|currentTime
argument_list|()
decl_stmt|;
comment|//if we flushed in the recent past, we don't need to do again now
if|if
condition|(
operator|(
name|now
operator|-
name|getEarliestFlushTimeForAllStores
argument_list|()
operator|<
name|modifiedFlushCheckInterval
operator|)
condition|)
block|{
return|return
literal|false
return|;
block|}
comment|//since we didn't flush in the recent past, flush now if certain conditions
comment|//are met. Return true on first such memstore hit.
for|for
control|(
name|HStore
name|s
range|:
name|stores
operator|.
name|values
argument_list|()
control|)
block|{
if|if
condition|(
name|s
operator|.
name|timeOfOldestEdit
argument_list|()
operator|<
name|now
operator|-
name|modifiedFlushCheckInterval
condition|)
block|{
comment|// we have an old enough edit in the memstore, flush
name|whyFlush
operator|.
name|append
argument_list|(
name|s
operator|.
name|toString
argument_list|()
operator|+
literal|" has an old edit so flush to free WALs"
argument_list|)
expr_stmt|;
return|return
literal|true
return|;
block|}
block|}
return|return
literal|false
return|;
block|}
comment|/**    * Flushing all stores.    * @see #internalFlushcache(Collection, MonitoredTask, boolean, FlushLifeCycleTracker)    */
specifier|private
name|FlushResult
name|internalFlushcache
parameter_list|(
name|MonitoredTask
name|status
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|internalFlushcache
argument_list|(
name|stores
operator|.
name|values
argument_list|()
argument_list|,
name|status
argument_list|,
literal|false
argument_list|,
name|FlushLifeCycleTracker
operator|.
name|DUMMY
argument_list|)
return|;
block|}
comment|/**    * Flushing given stores.    * @see #internalFlushcache(WAL, long, Collection, MonitoredTask, boolean, FlushLifeCycleTracker)    */
specifier|private
name|FlushResultImpl
name|internalFlushcache
parameter_list|(
name|Collection
argument_list|<
name|HStore
argument_list|>
name|storesToFlush
parameter_list|,
name|MonitoredTask
name|status
parameter_list|,
name|boolean
name|writeFlushWalMarker
parameter_list|,
name|FlushLifeCycleTracker
name|tracker
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|internalFlushcache
argument_list|(
name|this
operator|.
name|wal
argument_list|,
name|HConstants
operator|.
name|NO_SEQNUM
argument_list|,
name|storesToFlush
argument_list|,
name|status
argument_list|,
name|writeFlushWalMarker
argument_list|,
name|tracker
argument_list|)
return|;
block|}
comment|/**    * Flush the memstore. Flushing the memstore is a little tricky. We have a lot of updates in the    * memstore, all of which have also been written to the wal. We need to write those updates in the    * memstore out to disk, while being able to process reads/writes as much as possible during the    * flush operation.    *<p>    * This method may block for some time. Every time you call it, we up the regions sequence id even    * if we don't flush; i.e. the returned region id will be at least one larger than the last edit    * applied to this region. The returned id does not refer to an actual edit. The returned id can    * be used for say installing a bulk loaded file just ahead of the last hfile that was the result    * of this flush, etc.    * @param wal Null if we're NOT to go via wal.    * @param myseqid The seqid to use if<code>wal</code> is null writing out flush file.    * @param storesToFlush The list of stores to flush.    * @return object describing the flush's state    * @throws IOException general io exceptions    * @throws DroppedSnapshotException Thrown when replay of WAL is required.    */
specifier|protected
name|FlushResultImpl
name|internalFlushcache
parameter_list|(
name|WAL
name|wal
parameter_list|,
name|long
name|myseqid
parameter_list|,
name|Collection
argument_list|<
name|HStore
argument_list|>
name|storesToFlush
parameter_list|,
name|MonitoredTask
name|status
parameter_list|,
name|boolean
name|writeFlushWalMarker
parameter_list|,
name|FlushLifeCycleTracker
name|tracker
parameter_list|)
throws|throws
name|IOException
block|{
name|PrepareFlushResult
name|result
init|=
name|internalPrepareFlushCache
argument_list|(
name|wal
argument_list|,
name|myseqid
argument_list|,
name|storesToFlush
argument_list|,
name|status
argument_list|,
name|writeFlushWalMarker
argument_list|,
name|tracker
argument_list|)
decl_stmt|;
if|if
condition|(
name|result
operator|.
name|result
operator|==
literal|null
condition|)
block|{
return|return
name|internalFlushCacheAndCommit
argument_list|(
name|wal
argument_list|,
name|status
argument_list|,
name|result
argument_list|,
name|storesToFlush
argument_list|)
return|;
block|}
else|else
block|{
return|return
name|result
operator|.
name|result
return|;
comment|// early exit due to failure from prepare stage
block|}
block|}
annotation|@
name|edu
operator|.
name|umd
operator|.
name|cs
operator|.
name|findbugs
operator|.
name|annotations
operator|.
name|SuppressWarnings
argument_list|(
name|value
operator|=
literal|"DLS_DEAD_LOCAL_STORE"
argument_list|,
name|justification
operator|=
literal|"FindBugs seems confused about trxId"
argument_list|)
specifier|protected
name|PrepareFlushResult
name|internalPrepareFlushCache
parameter_list|(
name|WAL
name|wal
parameter_list|,
name|long
name|myseqid
parameter_list|,
name|Collection
argument_list|<
name|HStore
argument_list|>
name|storesToFlush
parameter_list|,
name|MonitoredTask
name|status
parameter_list|,
name|boolean
name|writeFlushWalMarker
parameter_list|,
name|FlushLifeCycleTracker
name|tracker
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|this
operator|.
name|rsServices
operator|!=
literal|null
operator|&&
name|this
operator|.
name|rsServices
operator|.
name|isAborted
argument_list|()
condition|)
block|{
comment|// Don't flush when server aborting, it's unsafe
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Aborting flush because server is aborted..."
argument_list|)
throw|;
block|}
specifier|final
name|long
name|startTime
init|=
name|EnvironmentEdgeManager
operator|.
name|currentTime
argument_list|()
decl_stmt|;
comment|// If nothing to flush, return, but return with a valid unused sequenceId.
comment|// Its needed by bulk upload IIRC. It flushes until no edits in memory so it can insert a
comment|// bulk loaded file between memory and existing hfiles. It wants a good seqeunceId that belongs
comment|// to no other that it can use to associate with the bulk load. Hence this little dance below
comment|// to go get one.
if|if
condition|(
name|this
operator|.
name|memStoreSizing
operator|.
name|getDataSize
argument_list|()
operator|<=
literal|0
condition|)
block|{
comment|// Take an update lock so no edits can come into memory just yet.
name|this
operator|.
name|updatesLock
operator|.
name|writeLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
name|WriteEntry
name|writeEntry
init|=
literal|null
decl_stmt|;
try|try
block|{
if|if
condition|(
name|this
operator|.
name|memStoreSizing
operator|.
name|getDataSize
argument_list|()
operator|<=
literal|0
condition|)
block|{
comment|// Presume that if there are still no edits in the memstore, then there are no edits for
comment|// this region out in the WAL subsystem so no need to do any trickery clearing out
comment|// edits in the WAL sub-system. Up the sequence number so the resulting flush id is for
comment|// sure just beyond the last appended region edit and not associated with any edit
comment|// (useful as marker when bulk loading, etc.).
if|if
condition|(
name|wal
operator|!=
literal|null
condition|)
block|{
name|writeEntry
operator|=
name|mvcc
operator|.
name|begin
argument_list|()
expr_stmt|;
name|long
name|flushOpSeqId
init|=
name|writeEntry
operator|.
name|getWriteNumber
argument_list|()
decl_stmt|;
name|FlushResultImpl
name|flushResult
init|=
operator|new
name|FlushResultImpl
argument_list|(
name|FlushResult
operator|.
name|Result
operator|.
name|CANNOT_FLUSH_MEMSTORE_EMPTY
argument_list|,
name|flushOpSeqId
argument_list|,
literal|"Nothing to flush"
argument_list|,
name|writeFlushRequestMarkerToWAL
argument_list|(
name|wal
argument_list|,
name|writeFlushWalMarker
argument_list|)
argument_list|)
decl_stmt|;
name|mvcc
operator|.
name|completeAndWait
argument_list|(
name|writeEntry
argument_list|)
expr_stmt|;
comment|// Set to null so we don't complete it again down in finally block.
name|writeEntry
operator|=
literal|null
expr_stmt|;
return|return
operator|new
name|PrepareFlushResult
argument_list|(
name|flushResult
argument_list|,
name|myseqid
argument_list|)
return|;
block|}
else|else
block|{
return|return
operator|new
name|PrepareFlushResult
argument_list|(
operator|new
name|FlushResultImpl
argument_list|(
name|FlushResult
operator|.
name|Result
operator|.
name|CANNOT_FLUSH_MEMSTORE_EMPTY
argument_list|,
literal|"Nothing to flush"
argument_list|,
literal|false
argument_list|)
argument_list|,
name|myseqid
argument_list|)
return|;
block|}
block|}
block|}
finally|finally
block|{
if|if
condition|(
name|writeEntry
operator|!=
literal|null
condition|)
block|{
comment|// If writeEntry is non-null, this operation failed; the mvcc transaction failed...
comment|// but complete it anyways so it doesn't block the mvcc queue.
name|mvcc
operator|.
name|complete
argument_list|(
name|writeEntry
argument_list|)
expr_stmt|;
block|}
name|this
operator|.
name|updatesLock
operator|.
name|writeLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
name|logFatLineOnFlush
argument_list|(
name|storesToFlush
argument_list|,
name|myseqid
argument_list|)
expr_stmt|;
comment|// Stop updates while we snapshot the memstore of all of these regions' stores. We only have
comment|// to do this for a moment.  It is quick. We also set the memstore size to zero here before we
comment|// allow updates again so its value will represent the size of the updates received
comment|// during flush
comment|// We have to take an update lock during snapshot, or else a write could end up in both snapshot
comment|// and memstore (makes it difficult to do atomic rows then)
name|status
operator|.
name|setStatus
argument_list|(
literal|"Obtaining lock to block concurrent updates"
argument_list|)
expr_stmt|;
comment|// block waiting for the lock for internal flush
name|this
operator|.
name|updatesLock
operator|.
name|writeLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
name|status
operator|.
name|setStatus
argument_list|(
literal|"Preparing flush snapshotting stores in "
operator|+
name|getRegionInfo
argument_list|()
operator|.
name|getEncodedName
argument_list|()
argument_list|)
expr_stmt|;
name|MemStoreSizing
name|totalSizeOfFlushableStores
init|=
operator|new
name|NonThreadSafeMemStoreSizing
argument_list|()
decl_stmt|;
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|Long
argument_list|>
name|flushedFamilyNamesToSeq
init|=
operator|new
name|HashMap
argument_list|<>
argument_list|()
decl_stmt|;
for|for
control|(
name|HStore
name|store
range|:
name|storesToFlush
control|)
block|{
name|flushedFamilyNamesToSeq
operator|.
name|put
argument_list|(
name|store
operator|.
name|getColumnFamilyDescriptor
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|,
name|store
operator|.
name|preFlushSeqIDEstimation
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|TreeMap
argument_list|<
name|byte
index|[]
argument_list|,
name|StoreFlushContext
argument_list|>
name|storeFlushCtxs
init|=
operator|new
name|TreeMap
argument_list|<>
argument_list|(
name|Bytes
operator|.
name|BYTES_COMPARATOR
argument_list|)
decl_stmt|;
name|TreeMap
argument_list|<
name|byte
index|[]
argument_list|,
name|List
argument_list|<
name|Path
argument_list|>
argument_list|>
name|committedFiles
init|=
operator|new
name|TreeMap
argument_list|<>
argument_list|(
name|Bytes
operator|.
name|BYTES_COMPARATOR
argument_list|)
decl_stmt|;
name|TreeMap
argument_list|<
name|byte
index|[]
argument_list|,
name|MemStoreSize
argument_list|>
name|storeFlushableSize
init|=
operator|new
name|TreeMap
argument_list|<>
argument_list|(
name|Bytes
operator|.
name|BYTES_COMPARATOR
argument_list|)
decl_stmt|;
comment|// The sequence id of this flush operation which is used to log FlushMarker and pass to
comment|// createFlushContext to use as the store file's sequence id. It can be in advance of edits
comment|// still in the memstore, edits that are in other column families yet to be flushed.
name|long
name|flushOpSeqId
init|=
name|HConstants
operator|.
name|NO_SEQNUM
decl_stmt|;
comment|// The max flushed sequence id after this flush operation completes. All edits in memstore
comment|// will be in advance of this sequence id.
name|long
name|flushedSeqId
init|=
name|HConstants
operator|.
name|NO_SEQNUM
decl_stmt|;
name|byte
index|[]
name|encodedRegionName
init|=
name|getRegionInfo
argument_list|()
operator|.
name|getEncodedNameAsBytes
argument_list|()
decl_stmt|;
try|try
block|{
if|if
condition|(
name|wal
operator|!=
literal|null
condition|)
block|{
name|Long
name|earliestUnflushedSequenceIdForTheRegion
init|=
name|wal
operator|.
name|startCacheFlush
argument_list|(
name|encodedRegionName
argument_list|,
name|flushedFamilyNamesToSeq
argument_list|)
decl_stmt|;
if|if
condition|(
name|earliestUnflushedSequenceIdForTheRegion
operator|==
literal|null
condition|)
block|{
comment|// This should never happen. This is how startCacheFlush signals flush cannot proceed.
name|String
name|msg
init|=
name|this
operator|.
name|getRegionInfo
argument_list|()
operator|.
name|getEncodedName
argument_list|()
operator|+
literal|" flush aborted; WAL closing."
decl_stmt|;
name|status
operator|.
name|setStatus
argument_list|(
name|msg
argument_list|)
expr_stmt|;
return|return
operator|new
name|PrepareFlushResult
argument_list|(
operator|new
name|FlushResultImpl
argument_list|(
name|FlushResult
operator|.
name|Result
operator|.
name|CANNOT_FLUSH
argument_list|,
name|msg
argument_list|,
literal|false
argument_list|)
argument_list|,
name|myseqid
argument_list|)
return|;
block|}
name|flushOpSeqId
operator|=
name|getNextSequenceId
argument_list|(
name|wal
argument_list|)
expr_stmt|;
comment|// Back up 1, minus 1 from oldest sequence id in memstore to get last 'flushed' edit
name|flushedSeqId
operator|=
name|earliestUnflushedSequenceIdForTheRegion
operator|.
name|longValue
argument_list|()
operator|==
name|HConstants
operator|.
name|NO_SEQNUM
condition|?
name|flushOpSeqId
else|:
name|earliestUnflushedSequenceIdForTheRegion
operator|.
name|longValue
argument_list|()
operator|-
literal|1
expr_stmt|;
block|}
else|else
block|{
comment|// use the provided sequence Id as WAL is not being used for this flush.
name|flushedSeqId
operator|=
name|flushOpSeqId
operator|=
name|myseqid
expr_stmt|;
block|}
for|for
control|(
name|HStore
name|s
range|:
name|storesToFlush
control|)
block|{
name|storeFlushCtxs
operator|.
name|put
argument_list|(
name|s
operator|.
name|getColumnFamilyDescriptor
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|,
name|s
operator|.
name|createFlushContext
argument_list|(
name|flushOpSeqId
argument_list|,
name|tracker
argument_list|)
argument_list|)
expr_stmt|;
comment|// for writing stores to WAL
name|committedFiles
operator|.
name|put
argument_list|(
name|s
operator|.
name|getColumnFamilyDescriptor
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|,
literal|null
argument_list|)
expr_stmt|;
block|}
comment|// write the snapshot start to WAL
if|if
condition|(
name|wal
operator|!=
literal|null
operator|&&
operator|!
name|writestate
operator|.
name|readOnly
condition|)
block|{
name|FlushDescriptor
name|desc
init|=
name|ProtobufUtil
operator|.
name|toFlushDescriptor
argument_list|(
name|FlushAction
operator|.
name|START_FLUSH
argument_list|,
name|getRegionInfo
argument_list|()
argument_list|,
name|flushOpSeqId
argument_list|,
name|committedFiles
argument_list|)
decl_stmt|;
comment|// No sync. Sync is below where no updates lock and we do FlushAction.COMMIT_FLUSH
name|WALUtil
operator|.
name|writeFlushMarker
argument_list|(
name|wal
argument_list|,
name|this
operator|.
name|getReplicationScope
argument_list|()
argument_list|,
name|getRegionInfo
argument_list|()
argument_list|,
name|desc
argument_list|,
literal|false
argument_list|,
name|mvcc
argument_list|)
expr_stmt|;
block|}
comment|// Prepare flush (take a snapshot)
name|storeFlushCtxs
operator|.
name|forEach
argument_list|(
parameter_list|(
name|name
parameter_list|,
name|flush
parameter_list|)
lambda|->
block|{
name|MemStoreSize
name|snapshotSize
init|=
name|flush
operator|.
name|prepare
argument_list|()
decl_stmt|;
name|totalSizeOfFlushableStores
operator|.
name|incMemStoreSize
argument_list|(
name|snapshotSize
argument_list|)
expr_stmt|;
name|storeFlushableSize
operator|.
name|put
argument_list|(
name|name
argument_list|,
name|snapshotSize
argument_list|)
expr_stmt|;
block|}
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ex
parameter_list|)
block|{
name|doAbortFlushToWAL
argument_list|(
name|wal
argument_list|,
name|flushOpSeqId
argument_list|,
name|committedFiles
argument_list|)
expr_stmt|;
throw|throw
name|ex
throw|;
block|}
finally|finally
block|{
name|this
operator|.
name|updatesLock
operator|.
name|writeLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
name|String
name|s
init|=
literal|"Finished memstore snapshotting "
operator|+
name|this
operator|+
literal|", syncing WAL and waiting on mvcc, "
operator|+
literal|"flushsize="
operator|+
name|totalSizeOfFlushableStores
decl_stmt|;
name|status
operator|.
name|setStatus
argument_list|(
name|s
argument_list|)
expr_stmt|;
name|doSyncOfUnflushedWALChanges
argument_list|(
name|wal
argument_list|,
name|getRegionInfo
argument_list|()
argument_list|)
expr_stmt|;
return|return
operator|new
name|PrepareFlushResult
argument_list|(
name|storeFlushCtxs
argument_list|,
name|committedFiles
argument_list|,
name|storeFlushableSize
argument_list|,
name|startTime
argument_list|,
name|flushOpSeqId
argument_list|,
name|flushedSeqId
argument_list|,
name|totalSizeOfFlushableStores
argument_list|)
return|;
block|}
comment|/**    * Utility method broken out of internalPrepareFlushCache so that method is smaller.    */
specifier|private
name|void
name|logFatLineOnFlush
parameter_list|(
name|Collection
argument_list|<
name|HStore
argument_list|>
name|storesToFlush
parameter_list|,
name|long
name|sequenceId
parameter_list|)
block|{
if|if
condition|(
operator|!
name|LOG
operator|.
name|isInfoEnabled
argument_list|()
condition|)
block|{
return|return;
block|}
comment|// Log a fat line detailing what is being flushed.
name|StringBuilder
name|perCfExtras
init|=
literal|null
decl_stmt|;
if|if
condition|(
operator|!
name|isAllFamilies
argument_list|(
name|storesToFlush
argument_list|)
condition|)
block|{
name|perCfExtras
operator|=
operator|new
name|StringBuilder
argument_list|()
expr_stmt|;
for|for
control|(
name|HStore
name|store
range|:
name|storesToFlush
control|)
block|{
name|MemStoreSize
name|mss
init|=
name|store
operator|.
name|getFlushableSize
argument_list|()
decl_stmt|;
name|perCfExtras
operator|.
name|append
argument_list|(
literal|"; "
argument_list|)
operator|.
name|append
argument_list|(
name|store
operator|.
name|getColumnFamilyName
argument_list|()
argument_list|)
expr_stmt|;
name|perCfExtras
operator|.
name|append
argument_list|(
literal|"={dataSize="
argument_list|)
operator|.
name|append
argument_list|(
name|StringUtils
operator|.
name|byteDesc
argument_list|(
name|mss
operator|.
name|getDataSize
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
name|perCfExtras
operator|.
name|append
argument_list|(
literal|", heapSize="
argument_list|)
operator|.
name|append
argument_list|(
name|StringUtils
operator|.
name|byteDesc
argument_list|(
name|mss
operator|.
name|getHeapSize
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
name|perCfExtras
operator|.
name|append
argument_list|(
literal|", offHeapSize="
argument_list|)
operator|.
name|append
argument_list|(
name|StringUtils
operator|.
name|byteDesc
argument_list|(
name|mss
operator|.
name|getOffHeapSize
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
name|perCfExtras
operator|.
name|append
argument_list|(
literal|"}"
argument_list|)
expr_stmt|;
block|}
block|}
name|MemStoreSize
name|mss
init|=
name|this
operator|.
name|memStoreSizing
operator|.
name|getMemStoreSize
argument_list|()
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Flushing "
operator|+
operator|+
name|storesToFlush
operator|.
name|size
argument_list|()
operator|+
literal|"/"
operator|+
name|stores
operator|.
name|size
argument_list|()
operator|+
literal|" column families,"
operator|+
literal|" dataSize="
operator|+
name|StringUtils
operator|.
name|byteDesc
argument_list|(
name|mss
operator|.
name|getDataSize
argument_list|()
argument_list|)
operator|+
literal|" heapSize="
operator|+
name|StringUtils
operator|.
name|byteDesc
argument_list|(
name|mss
operator|.
name|getHeapSize
argument_list|()
argument_list|)
operator|+
operator|(
operator|(
name|perCfExtras
operator|!=
literal|null
operator|&&
name|perCfExtras
operator|.
name|length
argument_list|()
operator|>
literal|0
operator|)
condition|?
name|perCfExtras
operator|.
name|toString
argument_list|()
else|:
literal|""
operator|)
operator|+
operator|(
operator|(
name|wal
operator|!=
literal|null
operator|)
condition|?
literal|""
else|:
literal|"; WAL is null, using passed sequenceid="
operator|+
name|sequenceId
operator|)
argument_list|)
expr_stmt|;
block|}
specifier|private
name|void
name|doAbortFlushToWAL
parameter_list|(
specifier|final
name|WAL
name|wal
parameter_list|,
specifier|final
name|long
name|flushOpSeqId
parameter_list|,
specifier|final
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|List
argument_list|<
name|Path
argument_list|>
argument_list|>
name|committedFiles
parameter_list|)
block|{
if|if
condition|(
name|wal
operator|==
literal|null
condition|)
return|return;
try|try
block|{
name|FlushDescriptor
name|desc
init|=
name|ProtobufUtil
operator|.
name|toFlushDescriptor
argument_list|(
name|FlushAction
operator|.
name|ABORT_FLUSH
argument_list|,
name|getRegionInfo
argument_list|()
argument_list|,
name|flushOpSeqId
argument_list|,
name|committedFiles
argument_list|)
decl_stmt|;
name|WALUtil
operator|.
name|writeFlushMarker
argument_list|(
name|wal
argument_list|,
name|this
operator|.
name|getReplicationScope
argument_list|()
argument_list|,
name|getRegionInfo
argument_list|()
argument_list|,
name|desc
argument_list|,
literal|false
argument_list|,
name|mvcc
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Throwable
name|t
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Received unexpected exception trying to write ABORT_FLUSH marker to WAL:"
operator|+
name|StringUtils
operator|.
name|stringifyException
argument_list|(
name|t
argument_list|)
argument_list|)
expr_stmt|;
comment|// ignore this since we will be aborting the RS with DSE.
block|}
comment|// we have called wal.startCacheFlush(), now we have to abort it
name|wal
operator|.
name|abortCacheFlush
argument_list|(
name|this
operator|.
name|getRegionInfo
argument_list|()
operator|.
name|getEncodedNameAsBytes
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|/**    * Sync unflushed WAL changes. See HBASE-8208 for details    */
specifier|private
specifier|static
name|void
name|doSyncOfUnflushedWALChanges
parameter_list|(
specifier|final
name|WAL
name|wal
parameter_list|,
specifier|final
name|RegionInfo
name|hri
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|wal
operator|==
literal|null
condition|)
block|{
return|return;
block|}
try|try
block|{
name|wal
operator|.
name|sync
argument_list|()
expr_stmt|;
comment|// ensure that flush marker is sync'ed
block|}
catch|catch
parameter_list|(
name|IOException
name|ioe
parameter_list|)
block|{
name|wal
operator|.
name|abortCacheFlush
argument_list|(
name|hri
operator|.
name|getEncodedNameAsBytes
argument_list|()
argument_list|)
expr_stmt|;
throw|throw
name|ioe
throw|;
block|}
block|}
comment|/**    * @return True if passed Set is all families in the region.    */
specifier|private
name|boolean
name|isAllFamilies
parameter_list|(
name|Collection
argument_list|<
name|HStore
argument_list|>
name|families
parameter_list|)
block|{
return|return
name|families
operator|==
literal|null
operator|||
name|this
operator|.
name|stores
operator|.
name|size
argument_list|()
operator|==
name|families
operator|.
name|size
argument_list|()
return|;
block|}
comment|/**    * Writes a marker to WAL indicating a flush is requested but cannot be complete due to various    * reasons. Ignores exceptions from WAL. Returns whether the write succeeded.    * @param wal    * @return whether WAL write was successful    */
specifier|private
name|boolean
name|writeFlushRequestMarkerToWAL
parameter_list|(
name|WAL
name|wal
parameter_list|,
name|boolean
name|writeFlushWalMarker
parameter_list|)
block|{
if|if
condition|(
name|writeFlushWalMarker
operator|&&
name|wal
operator|!=
literal|null
operator|&&
operator|!
name|writestate
operator|.
name|readOnly
condition|)
block|{
name|FlushDescriptor
name|desc
init|=
name|ProtobufUtil
operator|.
name|toFlushDescriptor
argument_list|(
name|FlushAction
operator|.
name|CANNOT_FLUSH
argument_list|,
name|getRegionInfo
argument_list|()
argument_list|,
operator|-
literal|1
argument_list|,
operator|new
name|TreeMap
argument_list|<>
argument_list|(
name|Bytes
operator|.
name|BYTES_COMPARATOR
argument_list|)
argument_list|)
decl_stmt|;
try|try
block|{
name|WALUtil
operator|.
name|writeFlushMarker
argument_list|(
name|wal
argument_list|,
name|this
operator|.
name|getReplicationScope
argument_list|()
argument_list|,
name|getRegionInfo
argument_list|()
argument_list|,
name|desc
argument_list|,
literal|true
argument_list|,
name|mvcc
argument_list|)
expr_stmt|;
return|return
literal|true
return|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
name|getRegionInfo
argument_list|()
operator|.
name|getEncodedName
argument_list|()
operator|+
literal|" : "
operator|+
literal|"Received exception while trying to write the flush request to wal"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
block|}
return|return
literal|false
return|;
block|}
annotation|@
name|edu
operator|.
name|umd
operator|.
name|cs
operator|.
name|findbugs
operator|.
name|annotations
operator|.
name|SuppressWarnings
argument_list|(
name|value
operator|=
literal|"NN_NAKED_NOTIFY"
argument_list|,
name|justification
operator|=
literal|"Intentional; notify is about completed flush"
argument_list|)
specifier|protected
name|FlushResultImpl
name|internalFlushCacheAndCommit
parameter_list|(
name|WAL
name|wal
parameter_list|,
name|MonitoredTask
name|status
parameter_list|,
name|PrepareFlushResult
name|prepareResult
parameter_list|,
name|Collection
argument_list|<
name|HStore
argument_list|>
name|storesToFlush
parameter_list|)
throws|throws
name|IOException
block|{
comment|// prepare flush context is carried via PrepareFlushResult
name|TreeMap
argument_list|<
name|byte
index|[]
argument_list|,
name|StoreFlushContext
argument_list|>
name|storeFlushCtxs
init|=
name|prepareResult
operator|.
name|storeFlushCtxs
decl_stmt|;
name|TreeMap
argument_list|<
name|byte
index|[]
argument_list|,
name|List
argument_list|<
name|Path
argument_list|>
argument_list|>
name|committedFiles
init|=
name|prepareResult
operator|.
name|committedFiles
decl_stmt|;
name|long
name|startTime
init|=
name|prepareResult
operator|.
name|startTime
decl_stmt|;
name|long
name|flushOpSeqId
init|=
name|prepareResult
operator|.
name|flushOpSeqId
decl_stmt|;
name|long
name|flushedSeqId
init|=
name|prepareResult
operator|.
name|flushedSeqId
decl_stmt|;
name|String
name|s
init|=
literal|"Flushing stores of "
operator|+
name|this
decl_stmt|;
name|status
operator|.
name|setStatus
argument_list|(
name|s
argument_list|)
expr_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isTraceEnabled
argument_list|()
condition|)
name|LOG
operator|.
name|trace
argument_list|(
name|s
argument_list|)
expr_stmt|;
comment|// Any failure from here on out will be catastrophic requiring server
comment|// restart so wal content can be replayed and put back into the memstore.
comment|// Otherwise, the snapshot content while backed up in the wal, it will not
comment|// be part of the current running servers state.
name|boolean
name|compactionRequested
init|=
literal|false
decl_stmt|;
name|long
name|flushedOutputFileSize
init|=
literal|0
decl_stmt|;
try|try
block|{
comment|// A.  Flush memstore to all the HStores.
comment|// Keep running vector of all store files that includes both old and the
comment|// just-made new flush store file. The new flushed file is still in the
comment|// tmp directory.
for|for
control|(
name|StoreFlushContext
name|flush
range|:
name|storeFlushCtxs
operator|.
name|values
argument_list|()
control|)
block|{
name|flush
operator|.
name|flushCache
argument_list|(
name|status
argument_list|)
expr_stmt|;
block|}
comment|// Switch snapshot (in memstore) -> new hfile (thus causing
comment|// all the store scanners to reset/reseek).
name|Iterator
argument_list|<
name|HStore
argument_list|>
name|it
init|=
name|storesToFlush
operator|.
name|iterator
argument_list|()
decl_stmt|;
comment|// stores.values() and storeFlushCtxs have same order
for|for
control|(
name|StoreFlushContext
name|flush
range|:
name|storeFlushCtxs
operator|.
name|values
argument_list|()
control|)
block|{
name|boolean
name|needsCompaction
init|=
name|flush
operator|.
name|commit
argument_list|(
name|status
argument_list|)
decl_stmt|;
if|if
condition|(
name|needsCompaction
condition|)
block|{
name|compactionRequested
operator|=
literal|true
expr_stmt|;
block|}
name|byte
index|[]
name|storeName
init|=
name|it
operator|.
name|next
argument_list|()
operator|.
name|getColumnFamilyDescriptor
argument_list|()
operator|.
name|getName
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|Path
argument_list|>
name|storeCommittedFiles
init|=
name|flush
operator|.
name|getCommittedFiles
argument_list|()
decl_stmt|;
name|committedFiles
operator|.
name|put
argument_list|(
name|storeName
argument_list|,
name|storeCommittedFiles
argument_list|)
expr_stmt|;
comment|// Flush committed no files, indicating flush is empty or flush was canceled
if|if
condition|(
name|storeCommittedFiles
operator|==
literal|null
operator|||
name|storeCommittedFiles
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|MemStoreSize
name|storeFlushableSize
init|=
name|prepareResult
operator|.
name|storeFlushableSize
operator|.
name|get
argument_list|(
name|storeName
argument_list|)
decl_stmt|;
name|prepareResult
operator|.
name|totalFlushableSize
operator|.
name|decMemStoreSize
argument_list|(
name|storeFlushableSize
argument_list|)
expr_stmt|;
block|}
name|flushedOutputFileSize
operator|+=
name|flush
operator|.
name|getOutputFileSize
argument_list|()
expr_stmt|;
block|}
name|storeFlushCtxs
operator|.
name|clear
argument_list|()
expr_stmt|;
comment|// Set down the memstore size by amount of flush.
name|MemStoreSize
name|mss
init|=
name|prepareResult
operator|.
name|totalFlushableSize
operator|.
name|getMemStoreSize
argument_list|()
decl_stmt|;
name|this
operator|.
name|decrMemStoreSize
argument_list|(
name|mss
operator|.
name|getDataSize
argument_list|()
argument_list|,
name|mss
operator|.
name|getHeapSize
argument_list|()
argument_list|,
name|mss
operator|.
name|getOffHeapSize
argument_list|()
argument_list|)
expr_stmt|;
comment|// Increase the size of this Region for the purposes of quota. Noop if quotas are disabled.
comment|// During startup, quota manager may not be initialized yet.
if|if
condition|(
name|rsServices
operator|!=
literal|null
condition|)
block|{
name|RegionServerSpaceQuotaManager
name|quotaManager
init|=
name|rsServices
operator|.
name|getRegionServerSpaceQuotaManager
argument_list|()
decl_stmt|;
if|if
condition|(
name|quotaManager
operator|!=
literal|null
condition|)
block|{
name|quotaManager
operator|.
name|getRegionSizeStore
argument_list|()
operator|.
name|incrementRegionSize
argument_list|(
name|this
operator|.
name|getRegionInfo
argument_list|()
argument_list|,
name|flushedOutputFileSize
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|wal
operator|!=
literal|null
condition|)
block|{
comment|// write flush marker to WAL. If fail, we should throw DroppedSnapshotException
name|FlushDescriptor
name|desc
init|=
name|ProtobufUtil
operator|.
name|toFlushDescriptor
argument_list|(
name|FlushAction
operator|.
name|COMMIT_FLUSH
argument_list|,
name|getRegionInfo
argument_list|()
argument_list|,
name|flushOpSeqId
argument_list|,
name|committedFiles
argument_list|)
decl_stmt|;
name|WALUtil
operator|.
name|writeFlushMarker
argument_list|(
name|wal
argument_list|,
name|this
operator|.
name|getReplicationScope
argument_list|()
argument_list|,
name|getRegionInfo
argument_list|()
argument_list|,
name|desc
argument_list|,
literal|true
argument_list|,
name|mvcc
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|Throwable
name|t
parameter_list|)
block|{
comment|// An exception here means that the snapshot was not persisted.
comment|// The wal needs to be replayed so its content is restored to memstore.
comment|// Currently, only a server restart will do this.
comment|// We used to only catch IOEs but its possible that we'd get other
comment|// exceptions -- e.g. HBASE-659 was about an NPE -- so now we catch
comment|// all and sundry.
if|if
condition|(
name|wal
operator|!=
literal|null
condition|)
block|{
try|try
block|{
name|FlushDescriptor
name|desc
init|=
name|ProtobufUtil
operator|.
name|toFlushDescriptor
argument_list|(
name|FlushAction
operator|.
name|ABORT_FLUSH
argument_list|,
name|getRegionInfo
argument_list|()
argument_list|,
name|flushOpSeqId
argument_list|,
name|committedFiles
argument_list|)
decl_stmt|;
name|WALUtil
operator|.
name|writeFlushMarker
argument_list|(
name|wal
argument_list|,
name|this
operator|.
name|replicationScope
argument_list|,
name|getRegionInfo
argument_list|()
argument_list|,
name|desc
argument_list|,
literal|false
argument_list|,
name|mvcc
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Throwable
name|ex
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
name|getRegionInfo
argument_list|()
operator|.
name|getEncodedName
argument_list|()
operator|+
literal|" : "
operator|+
literal|"failed writing ABORT_FLUSH marker to WAL"
argument_list|,
name|ex
argument_list|)
expr_stmt|;
comment|// ignore this since we will be aborting the RS with DSE.
block|}
name|wal
operator|.
name|abortCacheFlush
argument_list|(
name|this
operator|.
name|getRegionInfo
argument_list|()
operator|.
name|getEncodedNameAsBytes
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|DroppedSnapshotException
name|dse
init|=
operator|new
name|DroppedSnapshotException
argument_list|(
literal|"region: "
operator|+
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|getRegionInfo
argument_list|()
operator|.
name|getRegionName
argument_list|()
argument_list|)
argument_list|)
decl_stmt|;
name|dse
operator|.
name|initCause
argument_list|(
name|t
argument_list|)
expr_stmt|;
name|status
operator|.
name|abort
argument_list|(
literal|"Flush failed: "
operator|+
name|StringUtils
operator|.
name|stringifyException
argument_list|(
name|t
argument_list|)
argument_list|)
expr_stmt|;
comment|// Callers for flushcache() should catch DroppedSnapshotException and abort the region server.
comment|// However, since we may have the region read lock, we cannot call close(true) here since
comment|// we cannot promote to a write lock. Instead we are setting closing so that all other region
comment|// operations except for close will be rejected.
name|this
operator|.
name|closing
operator|.
name|set
argument_list|(
literal|true
argument_list|)
expr_stmt|;
if|if
condition|(
name|rsServices
operator|!=
literal|null
condition|)
block|{
comment|// This is a safeguard against the case where the caller fails to explicitly handle aborting
name|rsServices
operator|.
name|abort
argument_list|(
literal|"Replay of WAL required. Forcing server shutdown"
argument_list|,
name|dse
argument_list|)
expr_stmt|;
block|}
throw|throw
name|dse
throw|;
block|}
comment|// If we get to here, the HStores have been written.
if|if
condition|(
name|wal
operator|!=
literal|null
condition|)
block|{
name|wal
operator|.
name|completeCacheFlush
argument_list|(
name|this
operator|.
name|getRegionInfo
argument_list|()
operator|.
name|getEncodedNameAsBytes
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|// Record latest flush time
for|for
control|(
name|HStore
name|store
range|:
name|storesToFlush
control|)
block|{
name|this
operator|.
name|lastStoreFlushTimeMap
operator|.
name|put
argument_list|(
name|store
argument_list|,
name|startTime
argument_list|)
expr_stmt|;
block|}
name|this
operator|.
name|maxFlushedSeqId
operator|=
name|flushedSeqId
expr_stmt|;
name|this
operator|.
name|lastFlushOpSeqId
operator|=
name|flushOpSeqId
expr_stmt|;
comment|// C. Finally notify anyone waiting on memstore to clear:
comment|// e.g. checkResources().
synchronized|synchronized
init|(
name|this
init|)
block|{
name|notifyAll
argument_list|()
expr_stmt|;
comment|// FindBugs NN_NAKED_NOTIFY
block|}
name|long
name|time
init|=
name|EnvironmentEdgeManager
operator|.
name|currentTime
argument_list|()
operator|-
name|startTime
decl_stmt|;
name|MemStoreSize
name|mss
init|=
name|prepareResult
operator|.
name|totalFlushableSize
operator|.
name|getMemStoreSize
argument_list|()
decl_stmt|;
name|long
name|memstoresize
init|=
name|this
operator|.
name|memStoreSizing
operator|.
name|getMemStoreSize
argument_list|()
operator|.
name|getDataSize
argument_list|()
decl_stmt|;
name|String
name|msg
init|=
literal|"Finished flush of"
operator|+
literal|" dataSize ~"
operator|+
name|StringUtils
operator|.
name|byteDesc
argument_list|(
name|mss
operator|.
name|getDataSize
argument_list|()
argument_list|)
operator|+
literal|"/"
operator|+
name|mss
operator|.
name|getDataSize
argument_list|()
operator|+
literal|", heapSize ~"
operator|+
name|StringUtils
operator|.
name|byteDesc
argument_list|(
name|mss
operator|.
name|getHeapSize
argument_list|()
argument_list|)
operator|+
literal|"/"
operator|+
name|mss
operator|.
name|getHeapSize
argument_list|()
operator|+
literal|", currentSize="
operator|+
name|StringUtils
operator|.
name|byteDesc
argument_list|(
name|memstoresize
argument_list|)
operator|+
literal|"/"
operator|+
name|memstoresize
operator|+
literal|" for "
operator|+
name|this
operator|.
name|getRegionInfo
argument_list|()
operator|.
name|getEncodedName
argument_list|()
operator|+
literal|" in "
operator|+
name|time
operator|+
literal|"ms, sequenceid="
operator|+
name|flushOpSeqId
operator|+
literal|", compaction requested="
operator|+
name|compactionRequested
operator|+
operator|(
operator|(
name|wal
operator|==
literal|null
operator|)
condition|?
literal|"; wal=null"
else|:
literal|""
operator|)
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
name|msg
argument_list|)
expr_stmt|;
name|status
operator|.
name|setStatus
argument_list|(
name|msg
argument_list|)
expr_stmt|;
if|if
condition|(
name|rsServices
operator|!=
literal|null
operator|&&
name|rsServices
operator|.
name|getMetrics
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|rsServices
operator|.
name|getMetrics
argument_list|()
operator|.
name|updateFlush
argument_list|(
name|time
operator|-
name|startTime
argument_list|,
name|mss
operator|.
name|getDataSize
argument_list|()
argument_list|,
name|flushedOutputFileSize
argument_list|)
expr_stmt|;
block|}
return|return
operator|new
name|FlushResultImpl
argument_list|(
name|compactionRequested
condition|?
name|FlushResult
operator|.
name|Result
operator|.
name|FLUSHED_COMPACTION_NEEDED
else|:
name|FlushResult
operator|.
name|Result
operator|.
name|FLUSHED_NO_COMPACTION_NEEDED
argument_list|,
name|flushOpSeqId
argument_list|)
return|;
block|}
comment|/**    * Method to safely get the next sequence number.    * @return Next sequence number unassociated with any actual edit.    * @throws IOException    */
annotation|@
name|VisibleForTesting
specifier|protected
name|long
name|getNextSequenceId
parameter_list|(
specifier|final
name|WAL
name|wal
parameter_list|)
throws|throws
name|IOException
block|{
name|WriteEntry
name|we
init|=
name|mvcc
operator|.
name|begin
argument_list|()
decl_stmt|;
name|mvcc
operator|.
name|completeAndWait
argument_list|(
name|we
argument_list|)
expr_stmt|;
return|return
name|we
operator|.
name|getWriteNumber
argument_list|()
return|;
block|}
comment|//////////////////////////////////////////////////////////////////////////////
comment|// get() methods for client use.
comment|//////////////////////////////////////////////////////////////////////////////
annotation|@
name|Override
specifier|public
name|RegionScannerImpl
name|getScanner
parameter_list|(
name|Scan
name|scan
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|getScanner
argument_list|(
name|scan
argument_list|,
literal|null
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|RegionScannerImpl
name|getScanner
parameter_list|(
name|Scan
name|scan
parameter_list|,
name|List
argument_list|<
name|KeyValueScanner
argument_list|>
name|additionalScanners
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|getScanner
argument_list|(
name|scan
argument_list|,
name|additionalScanners
argument_list|,
name|HConstants
operator|.
name|NO_NONCE
argument_list|,
name|HConstants
operator|.
name|NO_NONCE
argument_list|)
return|;
block|}
specifier|private
name|RegionScannerImpl
name|getScanner
parameter_list|(
name|Scan
name|scan
parameter_list|,
name|List
argument_list|<
name|KeyValueScanner
argument_list|>
name|additionalScanners
parameter_list|,
name|long
name|nonceGroup
parameter_list|,
name|long
name|nonce
parameter_list|)
throws|throws
name|IOException
block|{
name|startRegionOperation
argument_list|(
name|Operation
operator|.
name|SCAN
argument_list|)
expr_stmt|;
try|try
block|{
comment|// Verify families are all valid
if|if
condition|(
operator|!
name|scan
operator|.
name|hasFamilies
argument_list|()
condition|)
block|{
comment|// Adding all families to scanner
for|for
control|(
name|byte
index|[]
name|family
range|:
name|this
operator|.
name|htableDescriptor
operator|.
name|getColumnFamilyNames
argument_list|()
control|)
block|{
name|scan
operator|.
name|addFamily
argument_list|(
name|family
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
for|for
control|(
name|byte
index|[]
name|family
range|:
name|scan
operator|.
name|getFamilyMap
argument_list|()
operator|.
name|keySet
argument_list|()
control|)
block|{
name|checkFamily
argument_list|(
name|family
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|instantiateRegionScanner
argument_list|(
name|scan
argument_list|,
name|additionalScanners
argument_list|,
name|nonceGroup
argument_list|,
name|nonce
argument_list|)
return|;
block|}
finally|finally
block|{
name|closeRegionOperation
argument_list|(
name|Operation
operator|.
name|SCAN
argument_list|)
expr_stmt|;
block|}
block|}
specifier|protected
name|RegionScanner
name|instantiateRegionScanner
parameter_list|(
name|Scan
name|scan
parameter_list|,
name|List
argument_list|<
name|KeyValueScanner
argument_list|>
name|additionalScanners
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|instantiateRegionScanner
argument_list|(
name|scan
argument_list|,
name|additionalScanners
argument_list|,
name|HConstants
operator|.
name|NO_NONCE
argument_list|,
name|HConstants
operator|.
name|NO_NONCE
argument_list|)
return|;
block|}
specifier|protected
name|RegionScannerImpl
name|instantiateRegionScanner
parameter_list|(
name|Scan
name|scan
parameter_list|,
name|List
argument_list|<
name|KeyValueScanner
argument_list|>
name|additionalScanners
parameter_list|,
name|long
name|nonceGroup
parameter_list|,
name|long
name|nonce
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|scan
operator|.
name|isReversed
argument_list|()
condition|)
block|{
if|if
condition|(
name|scan
operator|.
name|getFilter
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|scan
operator|.
name|getFilter
argument_list|()
operator|.
name|setReversed
argument_list|(
literal|true
argument_list|)
expr_stmt|;
block|}
return|return
operator|new
name|ReversedRegionScannerImpl
argument_list|(
name|scan
argument_list|,
name|additionalScanners
argument_list|,
name|this
argument_list|)
return|;
block|}
return|return
operator|new
name|RegionScannerImpl
argument_list|(
name|scan
argument_list|,
name|additionalScanners
argument_list|,
name|this
argument_list|,
name|nonceGroup
argument_list|,
name|nonce
argument_list|)
return|;
block|}
comment|/**    * Prepare a delete for a row mutation processor    * @param delete The passed delete is modified by this method. WARNING!    * @throws IOException    */
specifier|public
name|void
name|prepareDelete
parameter_list|(
name|Delete
name|delete
parameter_list|)
throws|throws
name|IOException
block|{
comment|// Check to see if this is a deleteRow insert
if|if
condition|(
name|delete
operator|.
name|getFamilyCellMap
argument_list|()
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
for|for
control|(
name|byte
index|[]
name|family
range|:
name|this
operator|.
name|htableDescriptor
operator|.
name|getColumnFamilyNames
argument_list|()
control|)
block|{
comment|// Don't eat the timestamp
name|delete
operator|.
name|addFamily
argument_list|(
name|family
argument_list|,
name|delete
operator|.
name|getTimestamp
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
for|for
control|(
name|byte
index|[]
name|family
range|:
name|delete
operator|.
name|getFamilyCellMap
argument_list|()
operator|.
name|keySet
argument_list|()
control|)
block|{
if|if
condition|(
name|family
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|NoSuchColumnFamilyException
argument_list|(
literal|"Empty family is invalid"
argument_list|)
throw|;
block|}
name|checkFamily
argument_list|(
name|family
argument_list|)
expr_stmt|;
block|}
block|}
block|}
annotation|@
name|Override
specifier|public
name|void
name|delete
parameter_list|(
name|Delete
name|delete
parameter_list|)
throws|throws
name|IOException
block|{
name|checkReadOnly
argument_list|()
expr_stmt|;
name|checkResources
argument_list|()
expr_stmt|;
name|startRegionOperation
argument_list|(
name|Operation
operator|.
name|DELETE
argument_list|)
expr_stmt|;
try|try
block|{
comment|// All edits for the given row (across all column families) must happen atomically.
name|doBatchMutate
argument_list|(
name|delete
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|closeRegionOperation
argument_list|(
name|Operation
operator|.
name|DELETE
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Row needed by below method.    */
specifier|private
specifier|static
specifier|final
name|byte
index|[]
name|FOR_UNIT_TESTS_ONLY
init|=
name|Bytes
operator|.
name|toBytes
argument_list|(
literal|"ForUnitTestsOnly"
argument_list|)
decl_stmt|;
comment|/**    * This is used only by unit tests. Not required to be a public API.    * @param familyMap map of family to edits for the given family.    * @throws IOException    */
name|void
name|delete
parameter_list|(
name|NavigableMap
argument_list|<
name|byte
index|[]
argument_list|,
name|List
argument_list|<
name|Cell
argument_list|>
argument_list|>
name|familyMap
parameter_list|,
name|Durability
name|durability
parameter_list|)
throws|throws
name|IOException
block|{
name|Delete
name|delete
init|=
operator|new
name|Delete
argument_list|(
name|FOR_UNIT_TESTS_ONLY
argument_list|)
decl_stmt|;
name|delete
operator|.
name|setFamilyCellMap
argument_list|(
name|familyMap
argument_list|)
expr_stmt|;
name|delete
operator|.
name|setDurability
argument_list|(
name|durability
argument_list|)
expr_stmt|;
name|doBatchMutate
argument_list|(
name|delete
argument_list|)
expr_stmt|;
block|}
comment|/**    * Set up correct timestamps in the KVs in Delete object.    *<p>Caller should have the row and region locks.    * @param mutation    * @param familyMap    * @param byteNow    * @throws IOException    */
specifier|public
name|void
name|prepareDeleteTimestamps
parameter_list|(
name|Mutation
name|mutation
parameter_list|,
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|List
argument_list|<
name|Cell
argument_list|>
argument_list|>
name|familyMap
parameter_list|,
name|byte
index|[]
name|byteNow
parameter_list|)
throws|throws
name|IOException
block|{
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|byte
index|[]
argument_list|,
name|List
argument_list|<
name|Cell
argument_list|>
argument_list|>
name|e
range|:
name|familyMap
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|byte
index|[]
name|family
init|=
name|e
operator|.
name|getKey
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|Cell
argument_list|>
name|cells
init|=
name|e
operator|.
name|getValue
argument_list|()
decl_stmt|;
assert|assert
name|cells
operator|instanceof
name|RandomAccess
assert|;
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|Integer
argument_list|>
name|kvCount
init|=
operator|new
name|TreeMap
argument_list|<>
argument_list|(
name|Bytes
operator|.
name|BYTES_COMPARATOR
argument_list|)
decl_stmt|;
name|int
name|listSize
init|=
name|cells
operator|.
name|size
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|listSize
condition|;
name|i
operator|++
control|)
block|{
name|Cell
name|cell
init|=
name|cells
operator|.
name|get
argument_list|(
name|i
argument_list|)
decl_stmt|;
comment|//  Check if time is LATEST, change to time of most recent addition if so
comment|//  This is expensive.
if|if
condition|(
name|cell
operator|.
name|getTimestamp
argument_list|()
operator|==
name|HConstants
operator|.
name|LATEST_TIMESTAMP
operator|&&
name|PrivateCellUtil
operator|.
name|isDeleteType
argument_list|(
name|cell
argument_list|)
condition|)
block|{
name|byte
index|[]
name|qual
init|=
name|CellUtil
operator|.
name|cloneQualifier
argument_list|(
name|cell
argument_list|)
decl_stmt|;
name|Integer
name|count
init|=
name|kvCount
operator|.
name|get
argument_list|(
name|qual
argument_list|)
decl_stmt|;
if|if
condition|(
name|count
operator|==
literal|null
condition|)
block|{
name|kvCount
operator|.
name|put
argument_list|(
name|qual
argument_list|,
literal|1
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|kvCount
operator|.
name|put
argument_list|(
name|qual
argument_list|,
name|count
operator|+
literal|1
argument_list|)
expr_stmt|;
block|}
name|count
operator|=
name|kvCount
operator|.
name|get
argument_list|(
name|qual
argument_list|)
expr_stmt|;
name|Get
name|get
init|=
operator|new
name|Get
argument_list|(
name|CellUtil
operator|.
name|cloneRow
argument_list|(
name|cell
argument_list|)
argument_list|)
decl_stmt|;
name|get
operator|.
name|setMaxVersions
argument_list|(
name|count
argument_list|)
expr_stmt|;
name|get
operator|.
name|addColumn
argument_list|(
name|family
argument_list|,
name|qual
argument_list|)
expr_stmt|;
if|if
condition|(
name|coprocessorHost
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
operator|!
name|coprocessorHost
operator|.
name|prePrepareTimeStampForDeleteVersion
argument_list|(
name|mutation
argument_list|,
name|cell
argument_list|,
name|byteNow
argument_list|,
name|get
argument_list|)
condition|)
block|{
name|updateDeleteLatestVersionTimestamp
argument_list|(
name|cell
argument_list|,
name|get
argument_list|,
name|count
argument_list|,
name|byteNow
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
name|updateDeleteLatestVersionTimestamp
argument_list|(
name|cell
argument_list|,
name|get
argument_list|,
name|count
argument_list|,
name|byteNow
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
name|PrivateCellUtil
operator|.
name|updateLatestStamp
argument_list|(
name|cell
argument_list|,
name|byteNow
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
name|void
name|updateDeleteLatestVersionTimestamp
parameter_list|(
name|Cell
name|cell
parameter_list|,
name|Get
name|get
parameter_list|,
name|int
name|count
parameter_list|,
name|byte
index|[]
name|byteNow
parameter_list|)
throws|throws
name|IOException
block|{
name|List
argument_list|<
name|Cell
argument_list|>
name|result
init|=
name|get
argument_list|(
name|get
argument_list|,
literal|false
argument_list|)
decl_stmt|;
if|if
condition|(
name|result
operator|.
name|size
argument_list|()
operator|<
name|count
condition|)
block|{
comment|// Nothing to delete
name|PrivateCellUtil
operator|.
name|updateLatestStamp
argument_list|(
name|cell
argument_list|,
name|byteNow
argument_list|)
expr_stmt|;
return|return;
block|}
if|if
condition|(
name|result
operator|.
name|size
argument_list|()
operator|>
name|count
condition|)
block|{
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"Unexpected size: "
operator|+
name|result
operator|.
name|size
argument_list|()
argument_list|)
throw|;
block|}
name|Cell
name|getCell
init|=
name|result
operator|.
name|get
argument_list|(
name|count
operator|-
literal|1
argument_list|)
decl_stmt|;
name|PrivateCellUtil
operator|.
name|setTimestamp
argument_list|(
name|cell
argument_list|,
name|getCell
operator|.
name|getTimestamp
argument_list|()
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|put
parameter_list|(
name|Put
name|put
parameter_list|)
throws|throws
name|IOException
block|{
name|checkReadOnly
argument_list|()
expr_stmt|;
comment|// Do a rough check that we have resources to accept a write.  The check is
comment|// 'rough' in that between the resource check and the call to obtain a
comment|// read lock, resources may run out.  For now, the thought is that this
comment|// will be extremely rare; we'll deal with it when it happens.
name|checkResources
argument_list|()
expr_stmt|;
name|startRegionOperation
argument_list|(
name|Operation
operator|.
name|PUT
argument_list|)
expr_stmt|;
try|try
block|{
comment|// All edits for the given row (across all column families) must happen atomically.
name|doBatchMutate
argument_list|(
name|put
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|closeRegionOperation
argument_list|(
name|Operation
operator|.
name|PUT
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Class that tracks the progress of a batch operations, accumulating status codes and tracking    * the index at which processing is proceeding. These batch operations may get split into    * mini-batches for processing.    */
specifier|private
specifier|abstract
specifier|static
class|class
name|BatchOperation
parameter_list|<
name|T
parameter_list|>
block|{
specifier|protected
specifier|final
name|T
index|[]
name|operations
decl_stmt|;
specifier|protected
specifier|final
name|OperationStatus
index|[]
name|retCodeDetails
decl_stmt|;
specifier|protected
specifier|final
name|WALEdit
index|[]
name|walEditsFromCoprocessors
decl_stmt|;
comment|// reference family cell maps directly so coprocessors can mutate them if desired
specifier|protected
specifier|final
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|List
argument_list|<
name|Cell
argument_list|>
argument_list|>
index|[]
name|familyCellMaps
decl_stmt|;
specifier|protected
specifier|final
name|HRegion
name|region
decl_stmt|;
specifier|protected
name|int
name|nextIndexToProcess
init|=
literal|0
decl_stmt|;
specifier|protected
specifier|final
name|ObservedExceptionsInBatch
name|observedExceptions
decl_stmt|;
comment|//Durability of the batch (highest durability of all operations)
specifier|protected
name|Durability
name|durability
decl_stmt|;
specifier|protected
name|boolean
name|atomic
init|=
literal|false
decl_stmt|;
specifier|public
name|BatchOperation
parameter_list|(
specifier|final
name|HRegion
name|region
parameter_list|,
name|T
index|[]
name|operations
parameter_list|)
block|{
name|this
operator|.
name|operations
operator|=
name|operations
expr_stmt|;
name|this
operator|.
name|retCodeDetails
operator|=
operator|new
name|OperationStatus
index|[
name|operations
operator|.
name|length
index|]
expr_stmt|;
name|Arrays
operator|.
name|fill
argument_list|(
name|this
operator|.
name|retCodeDetails
argument_list|,
name|OperationStatus
operator|.
name|NOT_RUN
argument_list|)
expr_stmt|;
name|this
operator|.
name|walEditsFromCoprocessors
operator|=
operator|new
name|WALEdit
index|[
name|operations
operator|.
name|length
index|]
expr_stmt|;
name|familyCellMaps
operator|=
operator|new
name|Map
index|[
name|operations
operator|.
name|length
index|]
expr_stmt|;
name|this
operator|.
name|region
operator|=
name|region
expr_stmt|;
name|observedExceptions
operator|=
operator|new
name|ObservedExceptionsInBatch
argument_list|()
expr_stmt|;
name|durability
operator|=
name|Durability
operator|.
name|USE_DEFAULT
expr_stmt|;
block|}
comment|/**      * Visitor interface for batch operations      */
annotation|@
name|FunctionalInterface
specifier|public
interface|interface
name|Visitor
block|{
comment|/**        * @param index operation index        * @return If true continue visiting remaining entries, break otherwise        */
name|boolean
name|visit
parameter_list|(
name|int
name|index
parameter_list|)
throws|throws
name|IOException
function_decl|;
block|}
comment|/**      * Helper method for visiting pending/ all batch operations      */
specifier|public
name|void
name|visitBatchOperations
parameter_list|(
name|boolean
name|pendingOnly
parameter_list|,
name|int
name|lastIndexExclusive
parameter_list|,
name|Visitor
name|visitor
parameter_list|)
throws|throws
name|IOException
block|{
assert|assert
name|lastIndexExclusive
operator|<=
name|this
operator|.
name|size
argument_list|()
assert|;
for|for
control|(
name|int
name|i
init|=
name|nextIndexToProcess
init|;
name|i
operator|<
name|lastIndexExclusive
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
operator|!
name|pendingOnly
operator|||
name|isOperationPending
argument_list|(
name|i
argument_list|)
condition|)
block|{
if|if
condition|(
operator|!
name|visitor
operator|.
name|visit
argument_list|(
name|i
argument_list|)
condition|)
block|{
break|break;
block|}
block|}
block|}
block|}
specifier|public
specifier|abstract
name|Mutation
name|getMutation
parameter_list|(
name|int
name|index
parameter_list|)
function_decl|;
specifier|public
specifier|abstract
name|long
name|getNonceGroup
parameter_list|(
name|int
name|index
parameter_list|)
function_decl|;
specifier|public
specifier|abstract
name|long
name|getNonce
parameter_list|(
name|int
name|index
parameter_list|)
function_decl|;
comment|/**      * This method is potentially expensive and useful mostly for non-replay CP path.      */
specifier|public
specifier|abstract
name|Mutation
index|[]
name|getMutationsForCoprocs
parameter_list|()
function_decl|;
specifier|public
specifier|abstract
name|boolean
name|isInReplay
parameter_list|()
function_decl|;
specifier|public
specifier|abstract
name|long
name|getOrigLogSeqNum
parameter_list|()
function_decl|;
specifier|public
specifier|abstract
name|void
name|startRegionOperation
parameter_list|()
throws|throws
name|IOException
function_decl|;
specifier|public
specifier|abstract
name|void
name|closeRegionOperation
parameter_list|()
throws|throws
name|IOException
function_decl|;
comment|/**      * Validates each mutation and prepares a batch for write. If necessary (non-replay case), runs      * CP prePut()/ preDelete() hooks for all mutations in a batch. This is intended to operate on      * entire batch and will be called from outside of class to check and prepare batch. This can      * be implemented by calling helper method {@link #checkAndPrepareMutation(int, long)} in a      * 'for' loop over mutations.      */
specifier|public
specifier|abstract
name|void
name|checkAndPrepare
parameter_list|()
throws|throws
name|IOException
function_decl|;
comment|/**      * Implement any Put request specific check and prepare logic here. Please refer to      * {@link #checkAndPrepareMutation(Mutation, long)} for how its used.      */
specifier|protected
specifier|abstract
name|void
name|checkAndPreparePut
parameter_list|(
specifier|final
name|Put
name|p
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**      * If necessary, calls preBatchMutate() CP hook for a mini-batch and updates metrics, cell      * count, tags and timestamp for all cells of all operations in a mini-batch.      */
specifier|public
specifier|abstract
name|void
name|prepareMiniBatchOperations
parameter_list|(
name|MiniBatchOperationInProgress
argument_list|<
name|Mutation
argument_list|>
name|miniBatchOp
parameter_list|,
name|long
name|timestamp
parameter_list|,
specifier|final
name|List
argument_list|<
name|RowLock
argument_list|>
name|acquiredRowLocks
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**      * Write mini-batch operations to MemStore      */
specifier|public
specifier|abstract
name|WriteEntry
name|writeMiniBatchOperationsToMemStore
parameter_list|(
specifier|final
name|MiniBatchOperationInProgress
argument_list|<
name|Mutation
argument_list|>
name|miniBatchOp
parameter_list|,
specifier|final
name|WriteEntry
name|writeEntry
parameter_list|)
throws|throws
name|IOException
function_decl|;
specifier|protected
name|void
name|writeMiniBatchOperationsToMemStore
parameter_list|(
specifier|final
name|MiniBatchOperationInProgress
argument_list|<
name|Mutation
argument_list|>
name|miniBatchOp
parameter_list|,
specifier|final
name|long
name|writeNumber
parameter_list|)
throws|throws
name|IOException
block|{
name|MemStoreSizing
name|memStoreAccounting
init|=
operator|new
name|NonThreadSafeMemStoreSizing
argument_list|()
decl_stmt|;
name|visitBatchOperations
argument_list|(
literal|true
argument_list|,
name|miniBatchOp
operator|.
name|getLastIndexExclusive
argument_list|()
argument_list|,
parameter_list|(
name|int
name|index
parameter_list|)
lambda|->
block|{
comment|// We need to update the sequence id for following reasons.
comment|// 1) If the op is in replay mode, FSWALEntry#stampRegionSequenceId won't stamp sequence id.
comment|// 2) If no WAL, FSWALEntry won't be used
comment|// we use durability of the original mutation for the mutation passed by CP.
if|if
condition|(
name|isInReplay
argument_list|()
operator|||
name|getMutation
argument_list|(
name|index
argument_list|)
operator|.
name|getDurability
argument_list|()
operator|==
name|Durability
operator|.
name|SKIP_WAL
condition|)
block|{
name|region
operator|.
name|updateSequenceId
argument_list|(
name|familyCellMaps
index|[
name|index
index|]
operator|.
name|values
argument_list|()
argument_list|,
name|writeNumber
argument_list|)
expr_stmt|;
block|}
name|applyFamilyMapToMemStore
argument_list|(
name|familyCellMaps
index|[
name|index
index|]
argument_list|,
name|memStoreAccounting
argument_list|)
expr_stmt|;
return|return
literal|true
return|;
block|}
argument_list|)
expr_stmt|;
comment|// update memStore size
name|region
operator|.
name|incMemStoreSize
argument_list|(
name|memStoreAccounting
operator|.
name|getDataSize
argument_list|()
argument_list|,
name|memStoreAccounting
operator|.
name|getHeapSize
argument_list|()
argument_list|,
name|memStoreAccounting
operator|.
name|getOffHeapSize
argument_list|()
argument_list|)
expr_stmt|;
block|}
specifier|public
name|boolean
name|isDone
parameter_list|()
block|{
return|return
name|nextIndexToProcess
operator|==
name|operations
operator|.
name|length
return|;
block|}
specifier|public
name|int
name|size
parameter_list|()
block|{
return|return
name|operations
operator|.
name|length
return|;
block|}
specifier|public
name|boolean
name|isOperationPending
parameter_list|(
name|int
name|index
parameter_list|)
block|{
return|return
name|retCodeDetails
index|[
name|index
index|]
operator|.
name|getOperationStatusCode
argument_list|()
operator|==
name|OperationStatusCode
operator|.
name|NOT_RUN
return|;
block|}
specifier|public
name|List
argument_list|<
name|UUID
argument_list|>
name|getClusterIds
parameter_list|()
block|{
assert|assert
name|size
argument_list|()
operator|!=
literal|0
assert|;
return|return
name|getMutation
argument_list|(
literal|0
argument_list|)
operator|.
name|getClusterIds
argument_list|()
return|;
block|}
name|boolean
name|isAtomic
parameter_list|()
block|{
return|return
name|atomic
return|;
block|}
comment|/**      * Helper method that checks and prepares only one mutation. This can be used to implement      * {@link #checkAndPrepare()} for entire Batch.      * NOTE: As CP prePut()/ preDelete() hooks may modify mutations, this method should be called      * after prePut()/ preDelete() CP hooks are run for the mutation      */
specifier|protected
name|void
name|checkAndPrepareMutation
parameter_list|(
name|Mutation
name|mutation
parameter_list|,
specifier|final
name|long
name|timestamp
parameter_list|)
throws|throws
name|IOException
block|{
name|region
operator|.
name|checkRow
argument_list|(
name|mutation
operator|.
name|getRow
argument_list|()
argument_list|,
literal|"batchMutate"
argument_list|)
expr_stmt|;
if|if
condition|(
name|mutation
operator|instanceof
name|Put
condition|)
block|{
comment|// Check the families in the put. If bad, skip this one.
name|checkAndPreparePut
argument_list|(
operator|(
name|Put
operator|)
name|mutation
argument_list|)
expr_stmt|;
name|region
operator|.
name|checkTimestamps
argument_list|(
name|mutation
operator|.
name|getFamilyCellMap
argument_list|()
argument_list|,
name|timestamp
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|region
operator|.
name|prepareDelete
argument_list|(
operator|(
name|Delete
operator|)
name|mutation
argument_list|)
expr_stmt|;
block|}
block|}
specifier|protected
name|void
name|checkAndPrepareMutation
parameter_list|(
name|int
name|index
parameter_list|,
name|long
name|timestamp
parameter_list|)
throws|throws
name|IOException
block|{
name|Mutation
name|mutation
init|=
name|getMutation
argument_list|(
name|index
argument_list|)
decl_stmt|;
try|try
block|{
name|this
operator|.
name|checkAndPrepareMutation
argument_list|(
name|mutation
argument_list|,
name|timestamp
argument_list|)
expr_stmt|;
comment|// store the family map reference to allow for mutations
name|familyCellMaps
index|[
name|index
index|]
operator|=
name|mutation
operator|.
name|getFamilyCellMap
argument_list|()
expr_stmt|;
comment|// store durability for the batch (highest durability of all operations in the batch)
name|Durability
name|tmpDur
init|=
name|region
operator|.
name|getEffectiveDurability
argument_list|(
name|mutation
operator|.
name|getDurability
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|tmpDur
operator|.
name|ordinal
argument_list|()
operator|>
name|durability
operator|.
name|ordinal
argument_list|()
condition|)
block|{
name|durability
operator|=
name|tmpDur
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|NoSuchColumnFamilyException
name|nscfe
parameter_list|)
block|{
specifier|final
name|String
name|msg
init|=
literal|"No such column family in batch mutation. "
decl_stmt|;
if|if
condition|(
name|observedExceptions
operator|.
name|hasSeenNoSuchFamily
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
name|msg
operator|+
name|nscfe
operator|.
name|getMessage
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|LOG
operator|.
name|warn
argument_list|(
name|msg
argument_list|,
name|nscfe
argument_list|)
expr_stmt|;
name|observedExceptions
operator|.
name|sawNoSuchFamily
argument_list|()
expr_stmt|;
block|}
name|retCodeDetails
index|[
name|index
index|]
operator|=
operator|new
name|OperationStatus
argument_list|(
name|OperationStatusCode
operator|.
name|BAD_FAMILY
argument_list|,
name|nscfe
operator|.
name|getMessage
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|isAtomic
argument_list|()
condition|)
block|{
comment|// fail, atomic means all or none
throw|throw
name|nscfe
throw|;
block|}
block|}
catch|catch
parameter_list|(
name|FailedSanityCheckException
name|fsce
parameter_list|)
block|{
specifier|final
name|String
name|msg
init|=
literal|"Batch Mutation did not pass sanity check. "
decl_stmt|;
if|if
condition|(
name|observedExceptions
operator|.
name|hasSeenFailedSanityCheck
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
name|msg
operator|+
name|fsce
operator|.
name|getMessage
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|LOG
operator|.
name|warn
argument_list|(
name|msg
argument_list|,
name|fsce
argument_list|)
expr_stmt|;
name|observedExceptions
operator|.
name|sawFailedSanityCheck
argument_list|()
expr_stmt|;
block|}
name|retCodeDetails
index|[
name|index
index|]
operator|=
operator|new
name|OperationStatus
argument_list|(
name|OperationStatusCode
operator|.
name|SANITY_CHECK_FAILURE
argument_list|,
name|fsce
operator|.
name|getMessage
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|isAtomic
argument_list|()
condition|)
block|{
throw|throw
name|fsce
throw|;
block|}
block|}
catch|catch
parameter_list|(
name|WrongRegionException
name|we
parameter_list|)
block|{
specifier|final
name|String
name|msg
init|=
literal|"Batch mutation had a row that does not belong to this region. "
decl_stmt|;
if|if
condition|(
name|observedExceptions
operator|.
name|hasSeenWrongRegion
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
name|msg
operator|+
name|we
operator|.
name|getMessage
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|LOG
operator|.
name|warn
argument_list|(
name|msg
argument_list|,
name|we
argument_list|)
expr_stmt|;
name|observedExceptions
operator|.
name|sawWrongRegion
argument_list|()
expr_stmt|;
block|}
name|retCodeDetails
index|[
name|index
index|]
operator|=
operator|new
name|OperationStatus
argument_list|(
name|OperationStatusCode
operator|.
name|SANITY_CHECK_FAILURE
argument_list|,
name|we
operator|.
name|getMessage
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|isAtomic
argument_list|()
condition|)
block|{
throw|throw
name|we
throw|;
block|}
block|}
block|}
comment|/**      * Creates Mini-batch of all operations [nextIndexToProcess, lastIndexExclusive) for which      * a row lock can be acquired. All mutations with locked rows are considered to be      * In-progress operations and hence the name {@link MiniBatchOperationInProgress}. Mini batch      * is window over {@link BatchOperation} and contains contiguous pending operations.      *      * @param acquiredRowLocks keeps track of rowLocks acquired.      */
specifier|public
name|MiniBatchOperationInProgress
argument_list|<
name|Mutation
argument_list|>
name|lockRowsAndBuildMiniBatch
parameter_list|(
name|List
argument_list|<
name|RowLock
argument_list|>
name|acquiredRowLocks
parameter_list|)
throws|throws
name|IOException
block|{
name|int
name|readyToWriteCount
init|=
literal|0
decl_stmt|;
name|int
name|lastIndexExclusive
init|=
literal|0
decl_stmt|;
name|RowLock
name|prevRowLock
init|=
literal|null
decl_stmt|;
for|for
control|(
init|;
name|lastIndexExclusive
operator|<
name|size
argument_list|()
condition|;
name|lastIndexExclusive
operator|++
control|)
block|{
comment|// It reaches the miniBatchSize, stop here and process the miniBatch
comment|// This only applies to non-atomic batch operations.
if|if
condition|(
operator|!
name|isAtomic
argument_list|()
operator|&&
operator|(
name|readyToWriteCount
operator|==
name|region
operator|.
name|miniBatchSize
operator|)
condition|)
block|{
break|break;
block|}
if|if
condition|(
operator|!
name|isOperationPending
argument_list|(
name|lastIndexExclusive
argument_list|)
condition|)
block|{
continue|continue;
block|}
comment|// HBASE-19389 Limit concurrency of put with dense (hundreds) columns to avoid exhausting
comment|// RS handlers, covering both MutationBatchOperation and ReplayBatchOperation
comment|// The BAD_FAMILY/SANITY_CHECK_FAILURE cases are handled in checkAndPrepare phase and won't
comment|// pass the isOperationPending check
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|List
argument_list|<
name|Cell
argument_list|>
argument_list|>
name|curFamilyCellMap
init|=
name|getMutation
argument_list|(
name|lastIndexExclusive
argument_list|)
operator|.
name|getFamilyCellMap
argument_list|()
decl_stmt|;
try|try
block|{
comment|// start the protector before acquiring row lock considering performance, and will finish
comment|// it when encountering exception
name|region
operator|.
name|storeHotnessProtector
operator|.
name|start
argument_list|(
name|curFamilyCellMap
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|RegionTooBusyException
name|rtbe
parameter_list|)
block|{
name|region
operator|.
name|storeHotnessProtector
operator|.
name|finish
argument_list|(
name|curFamilyCellMap
argument_list|)
expr_stmt|;
if|if
condition|(
name|isAtomic
argument_list|()
condition|)
block|{
throw|throw
name|rtbe
throw|;
block|}
name|retCodeDetails
index|[
name|lastIndexExclusive
index|]
operator|=
operator|new
name|OperationStatus
argument_list|(
name|OperationStatusCode
operator|.
name|STORE_TOO_BUSY
argument_list|,
name|rtbe
operator|.
name|getMessage
argument_list|()
argument_list|)
expr_stmt|;
continue|continue;
block|}
name|Mutation
name|mutation
init|=
name|getMutation
argument_list|(
name|lastIndexExclusive
argument_list|)
decl_stmt|;
comment|// If we haven't got any rows in our batch, we should block to get the next one.
name|RowLock
name|rowLock
init|=
literal|null
decl_stmt|;
name|boolean
name|throwException
init|=
literal|false
decl_stmt|;
try|try
block|{
comment|// if atomic then get exclusive lock, else shared lock
name|rowLock
operator|=
name|region
operator|.
name|getRowLockInternal
argument_list|(
name|mutation
operator|.
name|getRow
argument_list|()
argument_list|,
operator|!
name|isAtomic
argument_list|()
argument_list|,
name|prevRowLock
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|TimeoutIOException
decl||
name|InterruptedIOException
name|e
parameter_list|)
block|{
comment|// NOTE: We will retry when other exceptions, but we should stop if we receive
comment|// TimeoutIOException or InterruptedIOException as operation has timed out or
comment|// interrupted respectively.
name|throwException
operator|=
literal|true
expr_stmt|;
throw|throw
name|e
throw|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ioe
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failed getting lock, row="
operator|+
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|mutation
operator|.
name|getRow
argument_list|()
argument_list|)
argument_list|,
name|ioe
argument_list|)
expr_stmt|;
if|if
condition|(
name|isAtomic
argument_list|()
condition|)
block|{
comment|// fail, atomic means all or none
name|throwException
operator|=
literal|true
expr_stmt|;
throw|throw
name|ioe
throw|;
block|}
block|}
catch|catch
parameter_list|(
name|Throwable
name|throwable
parameter_list|)
block|{
name|throwException
operator|=
literal|true
expr_stmt|;
throw|throw
name|throwable
throw|;
block|}
finally|finally
block|{
if|if
condition|(
name|throwException
condition|)
block|{
name|region
operator|.
name|storeHotnessProtector
operator|.
name|finish
argument_list|(
name|curFamilyCellMap
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|rowLock
operator|==
literal|null
condition|)
block|{
comment|// We failed to grab another lock
if|if
condition|(
name|isAtomic
argument_list|()
condition|)
block|{
name|region
operator|.
name|storeHotnessProtector
operator|.
name|finish
argument_list|(
name|curFamilyCellMap
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Can't apply all operations atomically!"
argument_list|)
throw|;
block|}
break|break;
comment|// Stop acquiring more rows for this batch
block|}
else|else
block|{
if|if
condition|(
name|rowLock
operator|!=
name|prevRowLock
condition|)
block|{
comment|// It is a different row now, add this to the acquiredRowLocks and
comment|// set prevRowLock to the new returned rowLock
name|acquiredRowLocks
operator|.
name|add
argument_list|(
name|rowLock
argument_list|)
expr_stmt|;
name|prevRowLock
operator|=
name|rowLock
expr_stmt|;
block|}
block|}
name|readyToWriteCount
operator|++
expr_stmt|;
block|}
return|return
name|createMiniBatch
argument_list|(
name|lastIndexExclusive
argument_list|,
name|readyToWriteCount
argument_list|)
return|;
block|}
specifier|protected
name|MiniBatchOperationInProgress
argument_list|<
name|Mutation
argument_list|>
name|createMiniBatch
parameter_list|(
specifier|final
name|int
name|lastIndexExclusive
parameter_list|,
specifier|final
name|int
name|readyToWriteCount
parameter_list|)
block|{
return|return
operator|new
name|MiniBatchOperationInProgress
argument_list|<>
argument_list|(
name|getMutationsForCoprocs
argument_list|()
argument_list|,
name|retCodeDetails
argument_list|,
name|walEditsFromCoprocessors
argument_list|,
name|nextIndexToProcess
argument_list|,
name|lastIndexExclusive
argument_list|,
name|readyToWriteCount
argument_list|)
return|;
block|}
comment|/**      * Builds separate WALEdit per nonce by applying input mutations. If WALEdits from CP are      * present, they are merged to result WALEdit.      */
specifier|public
name|List
argument_list|<
name|Pair
argument_list|<
name|NonceKey
argument_list|,
name|WALEdit
argument_list|>
argument_list|>
name|buildWALEdits
parameter_list|(
specifier|final
name|MiniBatchOperationInProgress
argument_list|<
name|Mutation
argument_list|>
name|miniBatchOp
parameter_list|)
throws|throws
name|IOException
block|{
name|List
argument_list|<
name|Pair
argument_list|<
name|NonceKey
argument_list|,
name|WALEdit
argument_list|>
argument_list|>
name|walEdits
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
name|visitBatchOperations
argument_list|(
literal|true
argument_list|,
name|nextIndexToProcess
operator|+
name|miniBatchOp
operator|.
name|size
argument_list|()
argument_list|,
operator|new
name|Visitor
argument_list|()
block|{
specifier|private
name|Pair
argument_list|<
name|NonceKey
argument_list|,
name|WALEdit
argument_list|>
name|curWALEditForNonce
decl_stmt|;
annotation|@
name|Override
specifier|public
name|boolean
name|visit
parameter_list|(
name|int
name|index
parameter_list|)
throws|throws
name|IOException
block|{
name|Mutation
name|m
init|=
name|getMutation
argument_list|(
name|index
argument_list|)
decl_stmt|;
comment|// we use durability of the original mutation for the mutation passed by CP.
if|if
condition|(
name|region
operator|.
name|getEffectiveDurability
argument_list|(
name|m
operator|.
name|getDurability
argument_list|()
argument_list|)
operator|==
name|Durability
operator|.
name|SKIP_WAL
condition|)
block|{
name|region
operator|.
name|recordMutationWithoutWal
argument_list|(
name|m
operator|.
name|getFamilyCellMap
argument_list|()
argument_list|)
expr_stmt|;
return|return
literal|true
return|;
block|}
comment|// the batch may contain multiple nonce keys (replay case). If so, write WALEdit for each.
comment|// Given how nonce keys are originally written, these should be contiguous.
comment|// They don't have to be, it will still work, just write more WALEdits than needed.
name|long
name|nonceGroup
init|=
name|getNonceGroup
argument_list|(
name|index
argument_list|)
decl_stmt|;
name|long
name|nonce
init|=
name|getNonce
argument_list|(
name|index
argument_list|)
decl_stmt|;
if|if
condition|(
name|curWALEditForNonce
operator|==
literal|null
operator|||
name|curWALEditForNonce
operator|.
name|getFirst
argument_list|()
operator|.
name|getNonceGroup
argument_list|()
operator|!=
name|nonceGroup
operator|||
name|curWALEditForNonce
operator|.
name|getFirst
argument_list|()
operator|.
name|getNonce
argument_list|()
operator|!=
name|nonce
condition|)
block|{
name|curWALEditForNonce
operator|=
operator|new
name|Pair
argument_list|<>
argument_list|(
operator|new
name|NonceKey
argument_list|(
name|nonceGroup
argument_list|,
name|nonce
argument_list|)
argument_list|,
operator|new
name|WALEdit
argument_list|(
name|miniBatchOp
operator|.
name|getCellCount
argument_list|()
argument_list|,
name|isInReplay
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
name|walEdits
operator|.
name|add
argument_list|(
name|curWALEditForNonce
argument_list|)
expr_stmt|;
block|}
name|WALEdit
name|walEdit
init|=
name|curWALEditForNonce
operator|.
name|getSecond
argument_list|()
decl_stmt|;
comment|// Add WAL edits from CPs.
name|WALEdit
name|fromCP
init|=
name|walEditsFromCoprocessors
index|[
name|index
index|]
decl_stmt|;
if|if
condition|(
name|fromCP
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|Cell
name|cell
range|:
name|fromCP
operator|.
name|getCells
argument_list|()
control|)
block|{
name|walEdit
operator|.
name|add
argument_list|(
name|cell
argument_list|)
expr_stmt|;
block|}
block|}
name|walEdit
operator|.
name|add
argument_list|(
name|familyCellMaps
index|[
name|index
index|]
argument_list|)
expr_stmt|;
return|return
literal|true
return|;
block|}
block|}
argument_list|)
expr_stmt|;
return|return
name|walEdits
return|;
block|}
comment|/**      * This method completes mini-batch operations by calling postBatchMutate() CP hook (if      * required) and completing mvcc.      */
specifier|public
name|void
name|completeMiniBatchOperations
parameter_list|(
specifier|final
name|MiniBatchOperationInProgress
argument_list|<
name|Mutation
argument_list|>
name|miniBatchOp
parameter_list|,
specifier|final
name|WriteEntry
name|writeEntry
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|writeEntry
operator|!=
literal|null
condition|)
block|{
name|region
operator|.
name|mvcc
operator|.
name|completeAndWait
argument_list|(
name|writeEntry
argument_list|)
expr_stmt|;
block|}
block|}
specifier|public
name|void
name|doPostOpCleanupForMiniBatch
parameter_list|(
specifier|final
name|MiniBatchOperationInProgress
argument_list|<
name|Mutation
argument_list|>
name|miniBatchOp
parameter_list|,
specifier|final
name|WALEdit
name|walEdit
parameter_list|,
name|boolean
name|success
parameter_list|)
throws|throws
name|IOException
block|{
name|doFinishHotnessProtector
argument_list|(
name|miniBatchOp
argument_list|)
expr_stmt|;
block|}
specifier|private
name|void
name|doFinishHotnessProtector
parameter_list|(
specifier|final
name|MiniBatchOperationInProgress
argument_list|<
name|Mutation
argument_list|>
name|miniBatchOp
parameter_list|)
block|{
comment|// check and return if the protector is not enabled
if|if
condition|(
operator|!
name|region
operator|.
name|storeHotnessProtector
operator|.
name|isEnable
argument_list|()
condition|)
block|{
return|return;
block|}
comment|// miniBatchOp is null, if and only if lockRowsAndBuildMiniBatch throwing exception.
comment|// This case was handled.
if|if
condition|(
name|miniBatchOp
operator|==
literal|null
condition|)
block|{
return|return;
block|}
specifier|final
name|int
name|finalLastIndexExclusive
init|=
name|miniBatchOp
operator|.
name|getLastIndexExclusive
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
name|nextIndexToProcess
init|;
name|i
operator|<
name|finalLastIndexExclusive
condition|;
name|i
operator|++
control|)
block|{
switch|switch
condition|(
name|retCodeDetails
index|[
name|i
index|]
operator|.
name|getOperationStatusCode
argument_list|()
condition|)
block|{
case|case
name|SUCCESS
case|:
case|case
name|FAILURE
case|:
name|region
operator|.
name|storeHotnessProtector
operator|.
name|finish
argument_list|(
name|getMutation
argument_list|(
name|i
argument_list|)
operator|.
name|getFamilyCellMap
argument_list|()
argument_list|)
expr_stmt|;
break|break;
default|default:
comment|// do nothing
comment|// We won't start the protector for NOT_RUN/BAD_FAMILY/SANITY_CHECK_FAILURE and the
comment|// STORE_TOO_BUSY case is handled in StoreHotnessProtector#start
break|break;
block|}
block|}
block|}
comment|/**      * Atomically apply the given map of family->edits to the memstore.      * This handles the consistency control on its own, but the caller      * should already have locked updatesLock.readLock(). This also does      *<b>not</b> check the families for validity.      *      * @param familyMap Map of Cells by family      */
specifier|protected
name|void
name|applyFamilyMapToMemStore
parameter_list|(
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|List
argument_list|<
name|Cell
argument_list|>
argument_list|>
name|familyMap
parameter_list|,
name|MemStoreSizing
name|memstoreAccounting
parameter_list|)
throws|throws
name|IOException
block|{
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|byte
index|[]
argument_list|,
name|List
argument_list|<
name|Cell
argument_list|>
argument_list|>
name|e
range|:
name|familyMap
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|byte
index|[]
name|family
init|=
name|e
operator|.
name|getKey
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|Cell
argument_list|>
name|cells
init|=
name|e
operator|.
name|getValue
argument_list|()
decl_stmt|;
assert|assert
name|cells
operator|instanceof
name|RandomAccess
assert|;
name|region
operator|.
name|applyToMemStore
argument_list|(
name|region
operator|.
name|getStore
argument_list|(
name|family
argument_list|)
argument_list|,
name|cells
argument_list|,
literal|false
argument_list|,
name|memstoreAccounting
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|/**    * Batch of mutation operations. Base class is shared with {@link ReplayBatchOperation} as most    * of the logic is same.    */
specifier|static
class|class
name|MutationBatchOperation
extends|extends
name|BatchOperation
argument_list|<
name|Mutation
argument_list|>
block|{
specifier|private
name|long
name|nonceGroup
decl_stmt|;
specifier|private
name|long
name|nonce
decl_stmt|;
specifier|public
name|MutationBatchOperation
parameter_list|(
specifier|final
name|HRegion
name|region
parameter_list|,
name|Mutation
index|[]
name|operations
parameter_list|,
name|boolean
name|atomic
parameter_list|,
name|long
name|nonceGroup
parameter_list|,
name|long
name|nonce
parameter_list|)
block|{
name|super
argument_list|(
name|region
argument_list|,
name|operations
argument_list|)
expr_stmt|;
name|this
operator|.
name|atomic
operator|=
name|atomic
expr_stmt|;
name|this
operator|.
name|nonceGroup
operator|=
name|nonceGroup
expr_stmt|;
name|this
operator|.
name|nonce
operator|=
name|nonce
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|Mutation
name|getMutation
parameter_list|(
name|int
name|index
parameter_list|)
block|{
return|return
name|this
operator|.
name|operations
index|[
name|index
index|]
return|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|getNonceGroup
parameter_list|(
name|int
name|index
parameter_list|)
block|{
return|return
name|nonceGroup
return|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|getNonce
parameter_list|(
name|int
name|index
parameter_list|)
block|{
return|return
name|nonce
return|;
block|}
annotation|@
name|Override
specifier|public
name|Mutation
index|[]
name|getMutationsForCoprocs
parameter_list|()
block|{
return|return
name|this
operator|.
name|operations
return|;
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|isInReplay
parameter_list|()
block|{
return|return
literal|false
return|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|getOrigLogSeqNum
parameter_list|()
block|{
return|return
name|SequenceId
operator|.
name|NO_SEQUENCE_ID
return|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|startRegionOperation
parameter_list|()
throws|throws
name|IOException
block|{
name|region
operator|.
name|startRegionOperation
argument_list|(
name|Operation
operator|.
name|BATCH_MUTATE
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|closeRegionOperation
parameter_list|()
throws|throws
name|IOException
block|{
name|region
operator|.
name|closeRegionOperation
argument_list|(
name|Operation
operator|.
name|BATCH_MUTATE
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|checkAndPreparePut
parameter_list|(
name|Put
name|p
parameter_list|)
throws|throws
name|IOException
block|{
name|region
operator|.
name|checkFamilies
argument_list|(
name|p
operator|.
name|getFamilyCellMap
argument_list|()
operator|.
name|keySet
argument_list|()
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|checkAndPrepare
parameter_list|()
throws|throws
name|IOException
block|{
specifier|final
name|int
index|[]
name|metrics
init|=
block|{
literal|0
block|,
literal|0
block|}
decl_stmt|;
comment|// index 0: puts, index 1: deletes
name|visitBatchOperations
argument_list|(
literal|true
argument_list|,
name|this
operator|.
name|size
argument_list|()
argument_list|,
operator|new
name|Visitor
argument_list|()
block|{
specifier|private
name|long
name|now
init|=
name|EnvironmentEdgeManager
operator|.
name|currentTime
argument_list|()
decl_stmt|;
specifier|private
name|WALEdit
name|walEdit
decl_stmt|;
annotation|@
name|Override
specifier|public
name|boolean
name|visit
parameter_list|(
name|int
name|index
parameter_list|)
throws|throws
name|IOException
block|{
comment|// Run coprocessor pre hook outside of locks to avoid deadlock
if|if
condition|(
name|region
operator|.
name|coprocessorHost
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
name|walEdit
operator|==
literal|null
condition|)
block|{
name|walEdit
operator|=
operator|new
name|WALEdit
argument_list|()
expr_stmt|;
block|}
name|callPreMutateCPHook
argument_list|(
name|index
argument_list|,
name|walEdit
argument_list|,
name|metrics
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|walEdit
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|walEditsFromCoprocessors
index|[
name|index
index|]
operator|=
name|walEdit
expr_stmt|;
name|walEdit
operator|=
literal|null
expr_stmt|;
block|}
block|}
if|if
condition|(
name|isOperationPending
argument_list|(
name|index
argument_list|)
condition|)
block|{
comment|// TODO: Currently validation is done with current time before acquiring locks and
comment|// updates are done with different timestamps after acquiring locks. This behavior is
comment|// inherited from the code prior to this change. Can this be changed?
name|checkAndPrepareMutation
argument_list|(
name|index
argument_list|,
name|now
argument_list|)
expr_stmt|;
block|}
return|return
literal|true
return|;
block|}
block|}
argument_list|)
expr_stmt|;
comment|// FIXME: we may update metrics twice! here for all operations bypassed by CP and later in
comment|// normal processing.
comment|// Update metrics in same way as it is done when we go the normal processing route (we now
comment|// update general metrics though a Coprocessor did the work).
if|if
condition|(
name|region
operator|.
name|metricsRegion
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
name|metrics
index|[
literal|0
index|]
operator|>
literal|0
condition|)
block|{
comment|// There were some Puts in the batch.
name|region
operator|.
name|metricsRegion
operator|.
name|updatePut
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|metrics
index|[
literal|1
index|]
operator|>
literal|0
condition|)
block|{
comment|// There were some Deletes in the batch.
name|region
operator|.
name|metricsRegion
operator|.
name|updateDelete
argument_list|()
expr_stmt|;
block|}
block|}
block|}
annotation|@
name|Override
specifier|public
name|void
name|prepareMiniBatchOperations
parameter_list|(
name|MiniBatchOperationInProgress
argument_list|<
name|Mutation
argument_list|>
name|miniBatchOp
parameter_list|,
name|long
name|timestamp
parameter_list|,
specifier|final
name|List
argument_list|<
name|RowLock
argument_list|>
name|acquiredRowLocks
parameter_list|)
throws|throws
name|IOException
block|{
name|byte
index|[]
name|byteTS
init|=
name|Bytes
operator|.
name|toBytes
argument_list|(
name|timestamp
argument_list|)
decl_stmt|;
name|visitBatchOperations
argument_list|(
literal|true
argument_list|,
name|miniBatchOp
operator|.
name|getLastIndexExclusive
argument_list|()
argument_list|,
parameter_list|(
name|int
name|index
parameter_list|)
lambda|->
block|{
name|Mutation
name|mutation
init|=
name|getMutation
argument_list|(
name|index
argument_list|)
decl_stmt|;
if|if
condition|(
name|mutation
operator|instanceof
name|Put
condition|)
block|{
name|region
operator|.
name|updateCellTimestamps
argument_list|(
name|familyCellMaps
index|[
name|index
index|]
operator|.
name|values
argument_list|()
argument_list|,
name|byteTS
argument_list|)
expr_stmt|;
name|miniBatchOp
operator|.
name|incrementNumOfPuts
argument_list|()
expr_stmt|;
block|}
else|else
block|{
name|region
operator|.
name|prepareDeleteTimestamps
argument_list|(
name|mutation
argument_list|,
name|familyCellMaps
index|[
name|index
index|]
argument_list|,
name|byteTS
argument_list|)
expr_stmt|;
name|miniBatchOp
operator|.
name|incrementNumOfDeletes
argument_list|()
expr_stmt|;
block|}
name|region
operator|.
name|rewriteCellTags
argument_list|(
name|familyCellMaps
index|[
name|index
index|]
argument_list|,
name|mutation
argument_list|)
expr_stmt|;
comment|// update cell count
if|if
condition|(
name|region
operator|.
name|getEffectiveDurability
argument_list|(
name|mutation
operator|.
name|getDurability
argument_list|()
argument_list|)
operator|!=
name|Durability
operator|.
name|SKIP_WAL
condition|)
block|{
for|for
control|(
name|List
argument_list|<
name|Cell
argument_list|>
name|cells
range|:
name|mutation
operator|.
name|getFamilyCellMap
argument_list|()
operator|.
name|values
argument_list|()
control|)
block|{
name|miniBatchOp
operator|.
name|addCellCount
argument_list|(
name|cells
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
name|WALEdit
name|fromCP
init|=
name|walEditsFromCoprocessors
index|[
name|index
index|]
decl_stmt|;
if|if
condition|(
name|fromCP
operator|!=
literal|null
condition|)
block|{
name|miniBatchOp
operator|.
name|addCellCount
argument_list|(
name|fromCP
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
literal|true
return|;
block|}
argument_list|)
expr_stmt|;
if|if
condition|(
name|region
operator|.
name|coprocessorHost
operator|!=
literal|null
condition|)
block|{
comment|// calling the pre CP hook for batch mutation
name|region
operator|.
name|coprocessorHost
operator|.
name|preBatchMutate
argument_list|(
name|miniBatchOp
argument_list|)
expr_stmt|;
name|checkAndMergeCPMutations
argument_list|(
name|miniBatchOp
argument_list|,
name|acquiredRowLocks
argument_list|,
name|timestamp
argument_list|)
expr_stmt|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|List
argument_list|<
name|Pair
argument_list|<
name|NonceKey
argument_list|,
name|WALEdit
argument_list|>
argument_list|>
name|buildWALEdits
parameter_list|(
specifier|final
name|MiniBatchOperationInProgress
argument_list|<
name|Mutation
argument_list|>
name|miniBatchOp
parameter_list|)
throws|throws
name|IOException
block|{
name|List
argument_list|<
name|Pair
argument_list|<
name|NonceKey
argument_list|,
name|WALEdit
argument_list|>
argument_list|>
name|walEdits
init|=
name|super
operator|.
name|buildWALEdits
argument_list|(
name|miniBatchOp
argument_list|)
decl_stmt|;
comment|// for MutationBatchOperation, more than one nonce is not allowed
if|if
condition|(
name|walEdits
operator|.
name|size
argument_list|()
operator|>
literal|1
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Found multiple nonce keys per batch!"
argument_list|)
throw|;
block|}
return|return
name|walEdits
return|;
block|}
annotation|@
name|Override
specifier|public
name|WriteEntry
name|writeMiniBatchOperationsToMemStore
parameter_list|(
specifier|final
name|MiniBatchOperationInProgress
argument_list|<
name|Mutation
argument_list|>
name|miniBatchOp
parameter_list|,
annotation|@
name|Nullable
name|WriteEntry
name|writeEntry
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|writeEntry
operator|==
literal|null
condition|)
block|{
name|writeEntry
operator|=
name|region
operator|.
name|mvcc
operator|.
name|begin
argument_list|()
expr_stmt|;
block|}
name|super
operator|.
name|writeMiniBatchOperationsToMemStore
argument_list|(
name|miniBatchOp
argument_list|,
name|writeEntry
operator|.
name|getWriteNumber
argument_list|()
argument_list|)
expr_stmt|;
return|return
name|writeEntry
return|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|completeMiniBatchOperations
parameter_list|(
specifier|final
name|MiniBatchOperationInProgress
argument_list|<
name|Mutation
argument_list|>
name|miniBatchOp
parameter_list|,
specifier|final
name|WriteEntry
name|writeEntry
parameter_list|)
throws|throws
name|IOException
block|{
comment|// TODO: can it be done after completing mvcc?
comment|// calling the post CP hook for batch mutation
if|if
condition|(
name|region
operator|.
name|coprocessorHost
operator|!=
literal|null
condition|)
block|{
name|region
operator|.
name|coprocessorHost
operator|.
name|postBatchMutate
argument_list|(
name|miniBatchOp
argument_list|)
expr_stmt|;
block|}
name|super
operator|.
name|completeMiniBatchOperations
argument_list|(
name|miniBatchOp
argument_list|,
name|writeEntry
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|doPostOpCleanupForMiniBatch
parameter_list|(
name|MiniBatchOperationInProgress
argument_list|<
name|Mutation
argument_list|>
name|miniBatchOp
parameter_list|,
specifier|final
name|WALEdit
name|walEdit
parameter_list|,
name|boolean
name|success
parameter_list|)
throws|throws
name|IOException
block|{
name|super
operator|.
name|doPostOpCleanupForMiniBatch
argument_list|(
name|miniBatchOp
argument_list|,
name|walEdit
argument_list|,
name|success
argument_list|)
expr_stmt|;
if|if
condition|(
name|miniBatchOp
operator|!=
literal|null
condition|)
block|{
comment|// synced so that the coprocessor contract is adhered to.
if|if
condition|(
name|region
operator|.
name|coprocessorHost
operator|!=
literal|null
condition|)
block|{
name|visitBatchOperations
argument_list|(
literal|false
argument_list|,
name|miniBatchOp
operator|.
name|getLastIndexExclusive
argument_list|()
argument_list|,
parameter_list|(
name|int
name|i
parameter_list|)
lambda|->
block|{
comment|// only for successful puts
if|if
condition|(
name|retCodeDetails
index|[
name|i
index|]
operator|.
name|getOperationStatusCode
argument_list|()
operator|==
name|OperationStatusCode
operator|.
name|SUCCESS
condition|)
block|{
name|Mutation
name|m
init|=
name|getMutation
argument_list|(
name|i
argument_list|)
decl_stmt|;
if|if
condition|(
name|m
operator|instanceof
name|Put
condition|)
block|{
name|region
operator|.
name|coprocessorHost
operator|.
name|postPut
argument_list|(
operator|(
name|Put
operator|)
name|m
argument_list|,
name|walEdit
argument_list|,
name|m
operator|.
name|getDurability
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|region
operator|.
name|coprocessorHost
operator|.
name|postDelete
argument_list|(
operator|(
name|Delete
operator|)
name|m
argument_list|,
name|walEdit
argument_list|,
name|m
operator|.
name|getDurability
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
return|return
literal|true
return|;
block|}
argument_list|)
expr_stmt|;
block|}
comment|// See if the column families were consistent through the whole thing.
comment|// if they were then keep them. If they were not then pass a null.
comment|// null will be treated as unknown.
comment|// Total time taken might be involving Puts and Deletes.
comment|// Split the time for puts and deletes based on the total number of Puts and Deletes.
if|if
condition|(
name|region
operator|.
name|metricsRegion
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
name|miniBatchOp
operator|.
name|getNumOfPuts
argument_list|()
operator|>
literal|0
condition|)
block|{
comment|// There were some Puts in the batch.
name|region
operator|.
name|metricsRegion
operator|.
name|updatePut
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|miniBatchOp
operator|.
name|getNumOfDeletes
argument_list|()
operator|>
literal|0
condition|)
block|{
comment|// There were some Deletes in the batch.
name|region
operator|.
name|metricsRegion
operator|.
name|updateDelete
argument_list|()
expr_stmt|;
block|}
block|}
block|}
if|if
condition|(
name|region
operator|.
name|coprocessorHost
operator|!=
literal|null
condition|)
block|{
comment|// call the coprocessor hook to do any finalization steps after the put is done
name|region
operator|.
name|coprocessorHost
operator|.
name|postBatchMutateIndispensably
argument_list|(
name|miniBatchOp
operator|!=
literal|null
condition|?
name|miniBatchOp
else|:
name|createMiniBatch
argument_list|(
name|size
argument_list|()
argument_list|,
literal|0
argument_list|)
argument_list|,
name|success
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**      * Runs prePut/ preDelete coprocessor hook for input mutation in a batch      * @param metrics Array of 2 ints. index 0: count of puts and index 1: count of deletes      */
specifier|private
name|void
name|callPreMutateCPHook
parameter_list|(
name|int
name|index
parameter_list|,
specifier|final
name|WALEdit
name|walEdit
parameter_list|,
specifier|final
name|int
index|[]
name|metrics
parameter_list|)
throws|throws
name|IOException
block|{
name|Mutation
name|m
init|=
name|getMutation
argument_list|(
name|index
argument_list|)
decl_stmt|;
if|if
condition|(
name|m
operator|instanceof
name|Put
condition|)
block|{
if|if
condition|(
name|region
operator|.
name|coprocessorHost
operator|.
name|prePut
argument_list|(
operator|(
name|Put
operator|)
name|m
argument_list|,
name|walEdit
argument_list|,
name|m
operator|.
name|getDurability
argument_list|()
argument_list|)
condition|)
block|{
comment|// pre hook says skip this Put
comment|// mark as success and skip in doMiniBatchMutation
name|metrics
index|[
literal|0
index|]
operator|++
expr_stmt|;
name|retCodeDetails
index|[
name|index
index|]
operator|=
name|OperationStatus
operator|.
name|SUCCESS
expr_stmt|;
block|}
block|}
elseif|else
if|if
condition|(
name|m
operator|instanceof
name|Delete
condition|)
block|{
name|Delete
name|curDel
init|=
operator|(
name|Delete
operator|)
name|m
decl_stmt|;
if|if
condition|(
name|curDel
operator|.
name|getFamilyCellMap
argument_list|()
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
comment|// handle deleting a row case
comment|// TODO: prepareDelete() has been called twice, before and after preDelete() CP hook.
comment|// Can this be avoided?
name|region
operator|.
name|prepareDelete
argument_list|(
name|curDel
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|region
operator|.
name|coprocessorHost
operator|.
name|preDelete
argument_list|(
name|curDel
argument_list|,
name|walEdit
argument_list|,
name|m
operator|.
name|getDurability
argument_list|()
argument_list|)
condition|)
block|{
comment|// pre hook says skip this Delete
comment|// mark as success and skip in doMiniBatchMutation
name|metrics
index|[
literal|1
index|]
operator|++
expr_stmt|;
name|retCodeDetails
index|[
name|index
index|]
operator|=
name|OperationStatus
operator|.
name|SUCCESS
expr_stmt|;
block|}
block|}
else|else
block|{
name|String
name|msg
init|=
literal|"Put/Delete mutations only supported in a batch"
decl_stmt|;
comment|// In case of passing Append mutations along with the Puts and Deletes in batchMutate
comment|// mark the operation return code as failure so that it will not be considered in
comment|// the doMiniBatchMutation
name|retCodeDetails
index|[
name|index
index|]
operator|=
operator|new
name|OperationStatus
argument_list|(
name|OperationStatusCode
operator|.
name|FAILURE
argument_list|,
name|msg
argument_list|)
expr_stmt|;
if|if
condition|(
name|isAtomic
argument_list|()
condition|)
block|{
comment|// fail, atomic means all or none
throw|throw
operator|new
name|IOException
argument_list|(
name|msg
argument_list|)
throw|;
block|}
block|}
block|}
specifier|private
name|void
name|checkAndMergeCPMutations
parameter_list|(
specifier|final
name|MiniBatchOperationInProgress
argument_list|<
name|Mutation
argument_list|>
name|miniBatchOp
parameter_list|,
specifier|final
name|List
argument_list|<
name|RowLock
argument_list|>
name|acquiredRowLocks
parameter_list|,
specifier|final
name|long
name|timestamp
parameter_list|)
throws|throws
name|IOException
block|{
name|visitBatchOperations
argument_list|(
literal|true
argument_list|,
name|nextIndexToProcess
operator|+
name|miniBatchOp
operator|.
name|size
argument_list|()
argument_list|,
parameter_list|(
name|int
name|i
parameter_list|)
lambda|->
block|{
comment|// we pass (i - firstIndex) below since the call expects a relative index
name|Mutation
index|[]
name|cpMutations
init|=
name|miniBatchOp
operator|.
name|getOperationsFromCoprocessors
argument_list|(
name|i
operator|-
name|nextIndexToProcess
argument_list|)
decl_stmt|;
if|if
condition|(
name|cpMutations
operator|==
literal|null
condition|)
block|{
return|return
literal|true
return|;
block|}
comment|// Else Coprocessor added more Mutations corresponding to the Mutation at this index.
name|Mutation
name|mutation
init|=
name|getMutation
argument_list|(
name|i
argument_list|)
decl_stmt|;
for|for
control|(
name|Mutation
name|cpMutation
range|:
name|cpMutations
control|)
block|{
name|this
operator|.
name|checkAndPrepareMutation
argument_list|(
name|cpMutation
argument_list|,
name|timestamp
argument_list|)
expr_stmt|;
comment|// Acquire row locks. If not, the whole batch will fail.
name|acquiredRowLocks
operator|.
name|add
argument_list|(
name|region
operator|.
name|getRowLockInternal
argument_list|(
name|cpMutation
operator|.
name|getRow
argument_list|()
argument_list|,
literal|true
argument_list|,
literal|null
argument_list|)
argument_list|)
expr_stmt|;
comment|// Returned mutations from coprocessor correspond to the Mutation at index i. We can
comment|// directly add the cells from those mutations to the familyMaps of this mutation.
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|List
argument_list|<
name|Cell
argument_list|>
argument_list|>
name|cpFamilyMap
init|=
name|cpMutation
operator|.
name|getFamilyCellMap
argument_list|()
decl_stmt|;
comment|// will get added to the memStore later
name|mergeFamilyMaps
argument_list|(
name|familyCellMaps
index|[
name|i
index|]
argument_list|,
name|cpFamilyMap
argument_list|)
expr_stmt|;
comment|// The durability of returned mutation is replaced by the corresponding mutation.
comment|// If the corresponding mutation contains the SKIP_WAL, we shouldn't count the
comment|// cells of returned mutation.
if|if
condition|(
name|region
operator|.
name|getEffectiveDurability
argument_list|(
name|mutation
operator|.
name|getDurability
argument_list|()
argument_list|)
operator|!=
name|Durability
operator|.
name|SKIP_WAL
condition|)
block|{
for|for
control|(
name|List
argument_list|<
name|Cell
argument_list|>
name|cells
range|:
name|cpFamilyMap
operator|.
name|values
argument_list|()
control|)
block|{
name|miniBatchOp
operator|.
name|addCellCount
argument_list|(
name|cells
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
block|}
return|return
literal|true
return|;
block|}
argument_list|)
expr_stmt|;
block|}
specifier|private
name|void
name|mergeFamilyMaps
parameter_list|(
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|List
argument_list|<
name|Cell
argument_list|>
argument_list|>
name|familyMap
parameter_list|,
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|List
argument_list|<
name|Cell
argument_list|>
argument_list|>
name|toBeMerged
parameter_list|)
block|{
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|byte
index|[]
argument_list|,
name|List
argument_list|<
name|Cell
argument_list|>
argument_list|>
name|entry
range|:
name|toBeMerged
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|List
argument_list|<
name|Cell
argument_list|>
name|cells
init|=
name|familyMap
operator|.
name|get
argument_list|(
name|entry
operator|.
name|getKey
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|cells
operator|==
literal|null
condition|)
block|{
name|familyMap
operator|.
name|put
argument_list|(
name|entry
operator|.
name|getKey
argument_list|()
argument_list|,
name|entry
operator|.
name|getValue
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|cells
operator|.
name|addAll
argument_list|(
name|entry
operator|.
name|getValue
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
comment|/**    * Batch of mutations for replay. Base class is shared with {@link MutationBatchOperation} as most    * of the logic is same.    */
specifier|static
class|class
name|ReplayBatchOperation
extends|extends
name|BatchOperation
argument_list|<
name|MutationReplay
argument_list|>
block|{
specifier|private
name|long
name|origLogSeqNum
init|=
literal|0
decl_stmt|;
specifier|public
name|ReplayBatchOperation
parameter_list|(
specifier|final
name|HRegion
name|region
parameter_list|,
name|MutationReplay
index|[]
name|operations
parameter_list|,
name|long
name|origLogSeqNum
parameter_list|)
block|{
name|super
argument_list|(
name|region
argument_list|,
name|operations
argument_list|)
expr_stmt|;
name|this
operator|.
name|origLogSeqNum
operator|=
name|origLogSeqNum
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|Mutation
name|getMutation
parameter_list|(
name|int
name|index
parameter_list|)
block|{
return|return
name|this
operator|.
name|operations
index|[
name|index
index|]
operator|.
name|mutation
return|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|getNonceGroup
parameter_list|(
name|int
name|index
parameter_list|)
block|{
return|return
name|this
operator|.
name|operations
index|[
name|index
index|]
operator|.
name|nonceGroup
return|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|getNonce
parameter_list|(
name|int
name|index
parameter_list|)
block|{
return|return
name|this
operator|.
name|operations
index|[
name|index
index|]
operator|.
name|nonce
return|;
block|}
annotation|@
name|Override
specifier|public
name|Mutation
index|[]
name|getMutationsForCoprocs
parameter_list|()
block|{
return|return
literal|null
return|;
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|isInReplay
parameter_list|()
block|{
return|return
literal|true
return|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|getOrigLogSeqNum
parameter_list|()
block|{
return|return
name|this
operator|.
name|origLogSeqNum
return|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|startRegionOperation
parameter_list|()
throws|throws
name|IOException
block|{
name|region
operator|.
name|startRegionOperation
argument_list|(
name|Operation
operator|.
name|REPLAY_BATCH_MUTATE
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|closeRegionOperation
parameter_list|()
throws|throws
name|IOException
block|{
name|region
operator|.
name|closeRegionOperation
argument_list|(
name|Operation
operator|.
name|REPLAY_BATCH_MUTATE
argument_list|)
expr_stmt|;
block|}
comment|/**      * During replay, there could exist column families which are removed between region server      * failure and replay      */
annotation|@
name|Override
specifier|protected
name|void
name|checkAndPreparePut
parameter_list|(
name|Put
name|p
parameter_list|)
throws|throws
name|IOException
block|{
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|List
argument_list|<
name|Cell
argument_list|>
argument_list|>
name|familyCellMap
init|=
name|p
operator|.
name|getFamilyCellMap
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|byte
index|[]
argument_list|>
name|nonExistentList
init|=
literal|null
decl_stmt|;
for|for
control|(
name|byte
index|[]
name|family
range|:
name|familyCellMap
operator|.
name|keySet
argument_list|()
control|)
block|{
if|if
condition|(
operator|!
name|region
operator|.
name|htableDescriptor
operator|.
name|hasColumnFamily
argument_list|(
name|family
argument_list|)
condition|)
block|{
if|if
condition|(
name|nonExistentList
operator|==
literal|null
condition|)
block|{
name|nonExistentList
operator|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
expr_stmt|;
block|}
name|nonExistentList
operator|.
name|add
argument_list|(
name|family
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|nonExistentList
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|byte
index|[]
name|family
range|:
name|nonExistentList
control|)
block|{
comment|// Perhaps schema was changed between crash and replay
name|LOG
operator|.
name|info
argument_list|(
literal|"No family for "
operator|+
name|Bytes
operator|.
name|toString
argument_list|(
name|family
argument_list|)
operator|+
literal|" omit from reply."
argument_list|)
expr_stmt|;
name|familyCellMap
operator|.
name|remove
argument_list|(
name|family
argument_list|)
expr_stmt|;
block|}
block|}
block|}
annotation|@
name|Override
specifier|public
name|void
name|checkAndPrepare
parameter_list|()
throws|throws
name|IOException
block|{
name|long
name|now
init|=
name|EnvironmentEdgeManager
operator|.
name|currentTime
argument_list|()
decl_stmt|;
name|visitBatchOperations
argument_list|(
literal|true
argument_list|,
name|this
operator|.
name|size
argument_list|()
argument_list|,
parameter_list|(
name|int
name|index
parameter_list|)
lambda|->
block|{
name|checkAndPrepareMutation
argument_list|(
name|index
argument_list|,
name|now
argument_list|)
expr_stmt|;
return|return
literal|true
return|;
block|}
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|prepareMiniBatchOperations
parameter_list|(
name|MiniBatchOperationInProgress
argument_list|<
name|Mutation
argument_list|>
name|miniBatchOp
parameter_list|,
name|long
name|timestamp
parameter_list|,
specifier|final
name|List
argument_list|<
name|RowLock
argument_list|>
name|acquiredRowLocks
parameter_list|)
throws|throws
name|IOException
block|{
name|visitBatchOperations
argument_list|(
literal|true
argument_list|,
name|miniBatchOp
operator|.
name|getLastIndexExclusive
argument_list|()
argument_list|,
parameter_list|(
name|int
name|index
parameter_list|)
lambda|->
block|{
comment|// update cell count
for|for
control|(
name|List
argument_list|<
name|Cell
argument_list|>
name|cells
range|:
name|getMutation
argument_list|(
name|index
argument_list|)
operator|.
name|getFamilyCellMap
argument_list|()
operator|.
name|values
argument_list|()
control|)
block|{
name|miniBatchOp
operator|.
name|addCellCount
argument_list|(
name|cells
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
literal|true
return|;
block|}
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|WriteEntry
name|writeMiniBatchOperationsToMemStore
parameter_list|(
specifier|final
name|MiniBatchOperationInProgress
argument_list|<
name|Mutation
argument_list|>
name|miniBatchOp
parameter_list|,
specifier|final
name|WriteEntry
name|writeEntry
parameter_list|)
throws|throws
name|IOException
block|{
name|super
operator|.
name|writeMiniBatchOperationsToMemStore
argument_list|(
name|miniBatchOp
argument_list|,
name|getOrigLogSeqNum
argument_list|()
argument_list|)
expr_stmt|;
return|return
name|writeEntry
return|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|completeMiniBatchOperations
parameter_list|(
specifier|final
name|MiniBatchOperationInProgress
argument_list|<
name|Mutation
argument_list|>
name|miniBatchOp
parameter_list|,
specifier|final
name|WriteEntry
name|writeEntry
parameter_list|)
throws|throws
name|IOException
block|{
name|super
operator|.
name|completeMiniBatchOperations
argument_list|(
name|miniBatchOp
argument_list|,
name|writeEntry
argument_list|)
expr_stmt|;
name|region
operator|.
name|mvcc
operator|.
name|advanceTo
argument_list|(
name|getOrigLogSeqNum
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
specifier|public
name|OperationStatus
index|[]
name|batchMutate
parameter_list|(
name|Mutation
index|[]
name|mutations
parameter_list|,
name|long
name|nonceGroup
parameter_list|,
name|long
name|nonce
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|batchMutate
argument_list|(
name|mutations
argument_list|,
literal|false
argument_list|,
name|nonceGroup
argument_list|,
name|nonce
argument_list|)
return|;
block|}
specifier|public
name|OperationStatus
index|[]
name|batchMutate
parameter_list|(
name|Mutation
index|[]
name|mutations
parameter_list|,
name|boolean
name|atomic
parameter_list|,
name|long
name|nonceGroup
parameter_list|,
name|long
name|nonce
parameter_list|)
throws|throws
name|IOException
block|{
comment|// As it stands, this is used for 3 things
comment|//  * batchMutate with single mutation - put/delete, separate or from checkAndMutate.
comment|//  * coprocessor calls (see ex. BulkDeleteEndpoint).
comment|// So nonces are not really ever used by HBase. They could be by coprocs, and checkAnd...
return|return
name|batchMutate
argument_list|(
operator|new
name|MutationBatchOperation
argument_list|(
name|this
argument_list|,
name|mutations
argument_list|,
name|atomic
argument_list|,
name|nonceGroup
argument_list|,
name|nonce
argument_list|)
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|OperationStatus
index|[]
name|batchMutate
parameter_list|(
name|Mutation
index|[]
name|mutations
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|batchMutate
argument_list|(
name|mutations
argument_list|,
name|HConstants
operator|.
name|NO_NONCE
argument_list|,
name|HConstants
operator|.
name|NO_NONCE
argument_list|)
return|;
block|}
specifier|public
name|OperationStatus
index|[]
name|batchReplay
parameter_list|(
name|MutationReplay
index|[]
name|mutations
parameter_list|,
name|long
name|replaySeqId
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
operator|!
name|RegionReplicaUtil
operator|.
name|isDefaultReplica
argument_list|(
name|getRegionInfo
argument_list|()
argument_list|)
operator|&&
name|replaySeqId
operator|<
name|lastReplayedOpenRegionSeqId
condition|)
block|{
comment|// if it is a secondary replica we should ignore these entries silently
comment|// since they are coming out of order
if|if
condition|(
name|LOG
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|trace
argument_list|(
name|getRegionInfo
argument_list|()
operator|.
name|getEncodedName
argument_list|()
operator|+
literal|" : "
operator|+
literal|"Skipping "
operator|+
name|mutations
operator|.
name|length
operator|+
literal|" mutations with replaySeqId="
operator|+
name|replaySeqId
operator|+
literal|" which is< than lastReplayedOpenRegionSeqId="
operator|+
name|lastReplayedOpenRegionSeqId
argument_list|)
expr_stmt|;
for|for
control|(
name|MutationReplay
name|mut
range|:
name|mutations
control|)
block|{
name|LOG
operator|.
name|trace
argument_list|(
name|getRegionInfo
argument_list|()
operator|.
name|getEncodedName
argument_list|()
operator|+
literal|" : Skipping : "
operator|+
name|mut
operator|.
name|mutation
argument_list|)
expr_stmt|;
block|}
block|}
name|OperationStatus
index|[]
name|statuses
init|=
operator|new
name|OperationStatus
index|[
name|mutations
operator|.
name|length
index|]
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|statuses
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|statuses
index|[
name|i
index|]
operator|=
name|OperationStatus
operator|.
name|SUCCESS
expr_stmt|;
block|}
return|return
name|statuses
return|;
block|}
return|return
name|batchMutate
argument_list|(
operator|new
name|ReplayBatchOperation
argument_list|(
name|this
argument_list|,
name|mutations
argument_list|,
name|replaySeqId
argument_list|)
argument_list|)
return|;
block|}
comment|/**    * Perform a batch of mutations.    *    * It supports only Put and Delete mutations and will ignore other types passed. Operations in    * a batch are stored with highest durability specified of for all operations in a batch,    * except for {@link Durability#SKIP_WAL}.    *    *<p>This function is called from {@link #batchReplay(MutationReplay[], long)} with    * {@link ReplayBatchOperation} instance and {@link #batchMutate(Mutation[], long, long)} with    * {@link MutationBatchOperation} instance as an argument. As the processing of replay batch    * and mutation batch is very similar, lot of code is shared by providing generic methods in    * base class {@link BatchOperation}. The logic for this method and    * {@link #doMiniBatchMutate(BatchOperation)} is implemented using methods in base class which    * are overridden by derived classes to implement special behavior.    *    * @param batchOp contains the list of mutations    * @return an array of OperationStatus which internally contains the    *         OperationStatusCode and the exceptionMessage if any.    * @throws IOException    */
name|OperationStatus
index|[]
name|batchMutate
parameter_list|(
name|BatchOperation
argument_list|<
name|?
argument_list|>
name|batchOp
parameter_list|)
throws|throws
name|IOException
block|{
name|boolean
name|initialized
init|=
literal|false
decl_stmt|;
name|batchOp
operator|.
name|startRegionOperation
argument_list|()
expr_stmt|;
try|try
block|{
while|while
condition|(
operator|!
name|batchOp
operator|.
name|isDone
argument_list|()
condition|)
block|{
if|if
condition|(
operator|!
name|batchOp
operator|.
name|isInReplay
argument_list|()
condition|)
block|{
name|checkReadOnly
argument_list|()
expr_stmt|;
block|}
name|checkResources
argument_list|()
expr_stmt|;
if|if
condition|(
operator|!
name|initialized
condition|)
block|{
name|this
operator|.
name|writeRequestsCount
operator|.
name|add
argument_list|(
name|batchOp
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
comment|// validate and prepare batch for write, for MutationBatchOperation it also calls CP
comment|// prePut()/ preDelete() hooks
name|batchOp
operator|.
name|checkAndPrepare
argument_list|()
expr_stmt|;
name|initialized
operator|=
literal|true
expr_stmt|;
block|}
name|doMiniBatchMutate
argument_list|(
name|batchOp
argument_list|)
expr_stmt|;
name|requestFlushIfNeeded
argument_list|()
expr_stmt|;
block|}
block|}
finally|finally
block|{
name|batchOp
operator|.
name|closeRegionOperation
argument_list|()
expr_stmt|;
block|}
return|return
name|batchOp
operator|.
name|retCodeDetails
return|;
block|}
comment|/**    * Called to do a piece of the batch that came in to {@link #batchMutate(Mutation[], long, long)}    * In here we also handle replay of edits on region recover.    * @return Change in size brought about by applying<code>batchOp</code>    */
specifier|private
name|void
name|doMiniBatchMutate
parameter_list|(
name|BatchOperation
argument_list|<
name|?
argument_list|>
name|batchOp
parameter_list|)
throws|throws
name|IOException
block|{
name|boolean
name|success
init|=
literal|false
decl_stmt|;
name|WALEdit
name|walEdit
init|=
literal|null
decl_stmt|;
name|WriteEntry
name|writeEntry
init|=
literal|null
decl_stmt|;
name|boolean
name|locked
init|=
literal|false
decl_stmt|;
comment|// We try to set up a batch in the range [batchOp.nextIndexToProcess,lastIndexExclusive)
name|MiniBatchOperationInProgress
argument_list|<
name|Mutation
argument_list|>
name|miniBatchOp
init|=
literal|null
decl_stmt|;
comment|/** Keep track of the locks we hold so we can release them in finally clause */
name|List
argument_list|<
name|RowLock
argument_list|>
name|acquiredRowLocks
init|=
name|Lists
operator|.
name|newArrayListWithCapacity
argument_list|(
name|batchOp
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
try|try
block|{
comment|// STEP 1. Try to acquire as many locks as we can and build mini-batch of operations with
comment|// locked rows
name|miniBatchOp
operator|=
name|batchOp
operator|.
name|lockRowsAndBuildMiniBatch
argument_list|(
name|acquiredRowLocks
argument_list|)
expr_stmt|;
comment|// We've now grabbed as many mutations off the list as we can
comment|// Ensure we acquire at least one.
if|if
condition|(
name|miniBatchOp
operator|.
name|getReadyToWriteCount
argument_list|()
operator|<=
literal|0
condition|)
block|{
comment|// Nothing to put/delete -- an exception in the above such as NoSuchColumnFamily?
return|return;
block|}
name|lock
argument_list|(
name|this
operator|.
name|updatesLock
operator|.
name|readLock
argument_list|()
argument_list|,
name|miniBatchOp
operator|.
name|getReadyToWriteCount
argument_list|()
argument_list|)
expr_stmt|;
name|locked
operator|=
literal|true
expr_stmt|;
comment|// STEP 2. Update mini batch of all operations in progress with  LATEST_TIMESTAMP timestamp
comment|// We should record the timestamp only after we have acquired the rowLock,
comment|// otherwise, newer puts/deletes are not guaranteed to have a newer timestamp
name|long
name|now
init|=
name|EnvironmentEdgeManager
operator|.
name|currentTime
argument_list|()
decl_stmt|;
name|batchOp
operator|.
name|prepareMiniBatchOperations
argument_list|(
name|miniBatchOp
argument_list|,
name|now
argument_list|,
name|acquiredRowLocks
argument_list|)
expr_stmt|;
comment|// STEP 3. Build WAL edit
name|List
argument_list|<
name|Pair
argument_list|<
name|NonceKey
argument_list|,
name|WALEdit
argument_list|>
argument_list|>
name|walEdits
init|=
name|batchOp
operator|.
name|buildWALEdits
argument_list|(
name|miniBatchOp
argument_list|)
decl_stmt|;
comment|// STEP 4. Append the WALEdits to WAL and sync.
for|for
control|(
name|Iterator
argument_list|<
name|Pair
argument_list|<
name|NonceKey
argument_list|,
name|WALEdit
argument_list|>
argument_list|>
name|it
init|=
name|walEdits
operator|.
name|iterator
argument_list|()
init|;
name|it
operator|.
name|hasNext
argument_list|()
condition|;
control|)
block|{
name|Pair
argument_list|<
name|NonceKey
argument_list|,
name|WALEdit
argument_list|>
name|nonceKeyWALEditPair
init|=
name|it
operator|.
name|next
argument_list|()
decl_stmt|;
name|walEdit
operator|=
name|nonceKeyWALEditPair
operator|.
name|getSecond
argument_list|()
expr_stmt|;
name|NonceKey
name|nonceKey
init|=
name|nonceKeyWALEditPair
operator|.
name|getFirst
argument_list|()
decl_stmt|;
if|if
condition|(
name|walEdit
operator|!=
literal|null
operator|&&
operator|!
name|walEdit
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|writeEntry
operator|=
name|doWALAppend
argument_list|(
name|walEdit
argument_list|,
name|batchOp
operator|.
name|durability
argument_list|,
name|batchOp
operator|.
name|getClusterIds
argument_list|()
argument_list|,
name|now
argument_list|,
name|nonceKey
operator|.
name|getNonceGroup
argument_list|()
argument_list|,
name|nonceKey
operator|.
name|getNonce
argument_list|()
argument_list|,
name|batchOp
operator|.
name|getOrigLogSeqNum
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|// Complete mvcc for all but last writeEntry (for replay case)
if|if
condition|(
name|it
operator|.
name|hasNext
argument_list|()
operator|&&
name|writeEntry
operator|!=
literal|null
condition|)
block|{
name|mvcc
operator|.
name|complete
argument_list|(
name|writeEntry
argument_list|)
expr_stmt|;
name|writeEntry
operator|=
literal|null
expr_stmt|;
block|}
block|}
comment|// STEP 5. Write back to memStore
comment|// NOTE: writeEntry can be null here
name|writeEntry
operator|=
name|batchOp
operator|.
name|writeMiniBatchOperationsToMemStore
argument_list|(
name|miniBatchOp
argument_list|,
name|writeEntry
argument_list|)
expr_stmt|;
comment|// STEP 6. Complete MiniBatchOperations: If required calls postBatchMutate() CP hook and
comment|// complete mvcc for last writeEntry
name|batchOp
operator|.
name|completeMiniBatchOperations
argument_list|(
name|miniBatchOp
argument_list|,
name|writeEntry
argument_list|)
expr_stmt|;
name|writeEntry
operator|=
literal|null
expr_stmt|;
name|success
operator|=
literal|true
expr_stmt|;
block|}
finally|finally
block|{
comment|// Call complete rather than completeAndWait because we probably had error if walKey != null
if|if
condition|(
name|writeEntry
operator|!=
literal|null
condition|)
name|mvcc
operator|.
name|complete
argument_list|(
name|writeEntry
argument_list|)
expr_stmt|;
if|if
condition|(
name|locked
condition|)
block|{
name|this
operator|.
name|updatesLock
operator|.
name|readLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
name|releaseRowLocks
argument_list|(
name|acquiredRowLocks
argument_list|)
expr_stmt|;
specifier|final
name|int
name|finalLastIndexExclusive
init|=
name|miniBatchOp
operator|!=
literal|null
condition|?
name|miniBatchOp
operator|.
name|getLastIndexExclusive
argument_list|()
else|:
name|batchOp
operator|.
name|size
argument_list|()
decl_stmt|;
specifier|final
name|boolean
name|finalSuccess
init|=
name|success
decl_stmt|;
name|batchOp
operator|.
name|visitBatchOperations
argument_list|(
literal|true
argument_list|,
name|finalLastIndexExclusive
argument_list|,
parameter_list|(
name|int
name|i
parameter_list|)
lambda|->
block|{
name|batchOp
operator|.
name|retCodeDetails
index|[
name|i
index|]
operator|=
name|finalSuccess
condition|?
name|OperationStatus
operator|.
name|SUCCESS
else|:
name|OperationStatus
operator|.
name|FAILURE
expr_stmt|;
return|return
literal|true
return|;
block|}
argument_list|)
expr_stmt|;
name|batchOp
operator|.
name|doPostOpCleanupForMiniBatch
argument_list|(
name|miniBatchOp
argument_list|,
name|walEdit
argument_list|,
name|finalSuccess
argument_list|)
expr_stmt|;
name|batchOp
operator|.
name|nextIndexToProcess
operator|=
name|finalLastIndexExclusive
expr_stmt|;
block|}
block|}
comment|/**    * Returns effective durability from the passed durability and    * the table descriptor.    */
specifier|protected
name|Durability
name|getEffectiveDurability
parameter_list|(
name|Durability
name|d
parameter_list|)
block|{
return|return
name|d
operator|==
name|Durability
operator|.
name|USE_DEFAULT
condition|?
name|this
operator|.
name|regionDurability
else|:
name|d
return|;
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|checkAndMutate
parameter_list|(
name|byte
index|[]
name|row
parameter_list|,
name|byte
index|[]
name|family
parameter_list|,
name|byte
index|[]
name|qualifier
parameter_list|,
name|CompareOperator
name|op
parameter_list|,
name|ByteArrayComparable
name|comparator
parameter_list|,
name|TimeRange
name|timeRange
parameter_list|,
name|Mutation
name|mutation
parameter_list|)
throws|throws
name|IOException
block|{
name|checkMutationType
argument_list|(
name|mutation
argument_list|,
name|row
argument_list|)
expr_stmt|;
return|return
name|doCheckAndRowMutate
argument_list|(
name|row
argument_list|,
name|family
argument_list|,
name|qualifier
argument_list|,
name|op
argument_list|,
name|comparator
argument_list|,
name|timeRange
argument_list|,
literal|null
argument_list|,
name|mutation
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|checkAndRowMutate
parameter_list|(
name|byte
index|[]
name|row
parameter_list|,
name|byte
index|[]
name|family
parameter_list|,
name|byte
index|[]
name|qualifier
parameter_list|,
name|CompareOperator
name|op
parameter_list|,
name|ByteArrayComparable
name|comparator
parameter_list|,
name|TimeRange
name|timeRange
parameter_list|,
name|RowMutations
name|rm
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|doCheckAndRowMutate
argument_list|(
name|row
argument_list|,
name|family
argument_list|,
name|qualifier
argument_list|,
name|op
argument_list|,
name|comparator
argument_list|,
name|timeRange
argument_list|,
name|rm
argument_list|,
literal|null
argument_list|)
return|;
block|}
comment|/**    * checkAndMutate and checkAndRowMutate are 90% the same. Rather than copy/paste, below has    * switches in the few places where there is deviation.    */
specifier|private
name|boolean
name|doCheckAndRowMutate
parameter_list|(
name|byte
index|[]
name|row
parameter_list|,
name|byte
index|[]
name|family
parameter_list|,
name|byte
index|[]
name|qualifier
parameter_list|,
name|CompareOperator
name|op
parameter_list|,
name|ByteArrayComparable
name|comparator
parameter_list|,
name|TimeRange
name|timeRange
parameter_list|,
name|RowMutations
name|rowMutations
parameter_list|,
name|Mutation
name|mutation
parameter_list|)
throws|throws
name|IOException
block|{
comment|// Could do the below checks but seems wacky with two callers only. Just comment out for now.
comment|// One caller passes a Mutation, the other passes RowMutation. Presume all good so we don't
comment|// need these commented out checks.
comment|// if (rowMutations == null&& mutation == null) throw new DoNotRetryIOException("Both null");
comment|// if (rowMutations != null&& mutation != null) throw new DoNotRetryIOException("Both set");
name|checkReadOnly
argument_list|()
expr_stmt|;
comment|// TODO, add check for value length also move this check to the client
name|checkResources
argument_list|()
expr_stmt|;
name|startRegionOperation
argument_list|()
expr_stmt|;
try|try
block|{
name|Get
name|get
init|=
operator|new
name|Get
argument_list|(
name|row
argument_list|)
decl_stmt|;
name|checkFamily
argument_list|(
name|family
argument_list|)
expr_stmt|;
name|get
operator|.
name|addColumn
argument_list|(
name|family
argument_list|,
name|qualifier
argument_list|)
expr_stmt|;
if|if
condition|(
name|timeRange
operator|!=
literal|null
condition|)
block|{
name|get
operator|.
name|setTimeRange
argument_list|(
name|timeRange
operator|.
name|getMin
argument_list|()
argument_list|,
name|timeRange
operator|.
name|getMax
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|// Lock row - note that doBatchMutate will relock this row if called
name|checkRow
argument_list|(
name|row
argument_list|,
literal|"doCheckAndRowMutate"
argument_list|)
expr_stmt|;
name|RowLock
name|rowLock
init|=
name|getRowLockInternal
argument_list|(
name|get
operator|.
name|getRow
argument_list|()
argument_list|,
literal|false
argument_list|,
literal|null
argument_list|)
decl_stmt|;
try|try
block|{
if|if
condition|(
name|mutation
operator|!=
literal|null
operator|&&
name|this
operator|.
name|getCoprocessorHost
argument_list|()
operator|!=
literal|null
condition|)
block|{
comment|// Call coprocessor.
name|Boolean
name|processed
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|mutation
operator|instanceof
name|Put
condition|)
block|{
name|processed
operator|=
name|this
operator|.
name|getCoprocessorHost
argument_list|()
operator|.
name|preCheckAndPutAfterRowLock
argument_list|(
name|row
argument_list|,
name|family
argument_list|,
name|qualifier
argument_list|,
name|op
argument_list|,
name|comparator
argument_list|,
operator|(
name|Put
operator|)
name|mutation
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|mutation
operator|instanceof
name|Delete
condition|)
block|{
name|processed
operator|=
name|this
operator|.
name|getCoprocessorHost
argument_list|()
operator|.
name|preCheckAndDeleteAfterRowLock
argument_list|(
name|row
argument_list|,
name|family
argument_list|,
name|qualifier
argument_list|,
name|op
argument_list|,
name|comparator
argument_list|,
operator|(
name|Delete
operator|)
name|mutation
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|processed
operator|!=
literal|null
condition|)
block|{
return|return
name|processed
return|;
block|}
block|}
comment|// NOTE: We used to wait here until mvcc caught up:  mvcc.await();
comment|// Supposition is that now all changes are done under row locks, then when we go to read,
comment|// we'll get the latest on this row.
name|List
argument_list|<
name|Cell
argument_list|>
name|result
init|=
name|get
argument_list|(
name|get
argument_list|,
literal|false
argument_list|)
decl_stmt|;
name|boolean
name|valueIsNull
init|=
name|comparator
operator|.
name|getValue
argument_list|()
operator|==
literal|null
operator|||
name|comparator
operator|.
name|getValue
argument_list|()
operator|.
name|length
operator|==
literal|0
decl_stmt|;
name|boolean
name|matches
init|=
literal|false
decl_stmt|;
name|long
name|cellTs
init|=
literal|0
decl_stmt|;
if|if
condition|(
name|result
operator|.
name|isEmpty
argument_list|()
operator|&&
name|valueIsNull
condition|)
block|{
name|matches
operator|=
literal|true
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|result
operator|.
name|size
argument_list|()
operator|>
literal|0
operator|&&
name|result
operator|.
name|get
argument_list|(
literal|0
argument_list|)
operator|.
name|getValueLength
argument_list|()
operator|==
literal|0
operator|&&
name|valueIsNull
condition|)
block|{
name|matches
operator|=
literal|true
expr_stmt|;
name|cellTs
operator|=
name|result
operator|.
name|get
argument_list|(
literal|0
argument_list|)
operator|.
name|getTimestamp
argument_list|()
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|result
operator|.
name|size
argument_list|()
operator|==
literal|1
operator|&&
operator|!
name|valueIsNull
condition|)
block|{
name|Cell
name|kv
init|=
name|result
operator|.
name|get
argument_list|(
literal|0
argument_list|)
decl_stmt|;
name|cellTs
operator|=
name|kv
operator|.
name|getTimestamp
argument_list|()
expr_stmt|;
name|int
name|compareResult
init|=
name|PrivateCellUtil
operator|.
name|compareValue
argument_list|(
name|kv
argument_list|,
name|comparator
argument_list|)
decl_stmt|;
name|matches
operator|=
name|matches
argument_list|(
name|op
argument_list|,
name|compareResult
argument_list|)
expr_stmt|;
block|}
comment|// If matches put the new put or delete the new delete
if|if
condition|(
name|matches
condition|)
block|{
comment|// We have acquired the row lock already. If the system clock is NOT monotonically
comment|// non-decreasing (see HBASE-14070) we should make sure that the mutation has a
comment|// larger timestamp than what was observed via Get. doBatchMutate already does this, but
comment|// there is no way to pass the cellTs. See HBASE-14054.
name|long
name|now
init|=
name|EnvironmentEdgeManager
operator|.
name|currentTime
argument_list|()
decl_stmt|;
name|long
name|ts
init|=
name|Math
operator|.
name|max
argument_list|(
name|now
argument_list|,
name|cellTs
argument_list|)
decl_stmt|;
comment|// ensure write is not eclipsed
name|byte
index|[]
name|byteTs
init|=
name|Bytes
operator|.
name|toBytes
argument_list|(
name|ts
argument_list|)
decl_stmt|;
if|if
condition|(
name|mutation
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
name|mutation
operator|instanceof
name|Put
condition|)
block|{
name|updateCellTimestamps
argument_list|(
name|mutation
operator|.
name|getFamilyCellMap
argument_list|()
operator|.
name|values
argument_list|()
argument_list|,
name|byteTs
argument_list|)
expr_stmt|;
block|}
comment|// And else 'delete' is not needed since it already does a second get, and sets the
comment|// timestamp from get (see prepareDeleteTimestamps).
block|}
else|else
block|{
for|for
control|(
name|Mutation
name|m
range|:
name|rowMutations
operator|.
name|getMutations
argument_list|()
control|)
block|{
if|if
condition|(
name|m
operator|instanceof
name|Put
condition|)
block|{
name|updateCellTimestamps
argument_list|(
name|m
operator|.
name|getFamilyCellMap
argument_list|()
operator|.
name|values
argument_list|()
argument_list|,
name|byteTs
argument_list|)
expr_stmt|;
block|}
block|}
comment|// And else 'delete' is not needed since it already does a second get, and sets the
comment|// timestamp from get (see prepareDeleteTimestamps).
block|}
comment|// All edits for the given row (across all column families) must happen atomically.
if|if
condition|(
name|mutation
operator|!=
literal|null
condition|)
block|{
name|doBatchMutate
argument_list|(
name|mutation
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|mutateRow
argument_list|(
name|rowMutations
argument_list|)
expr_stmt|;
block|}
name|this
operator|.
name|checkAndMutateChecksPassed
operator|.
name|increment
argument_list|()
expr_stmt|;
return|return
literal|true
return|;
block|}
name|this
operator|.
name|checkAndMutateChecksFailed
operator|.
name|increment
argument_list|()
expr_stmt|;
return|return
literal|false
return|;
block|}
finally|finally
block|{
name|rowLock
operator|.
name|release
argument_list|()
expr_stmt|;
block|}
block|}
finally|finally
block|{
name|closeRegionOperation
argument_list|()
expr_stmt|;
block|}
block|}
specifier|private
name|void
name|checkMutationType
parameter_list|(
specifier|final
name|Mutation
name|mutation
parameter_list|,
specifier|final
name|byte
index|[]
name|row
parameter_list|)
throws|throws
name|DoNotRetryIOException
block|{
name|boolean
name|isPut
init|=
name|mutation
operator|instanceof
name|Put
decl_stmt|;
if|if
condition|(
operator|!
name|isPut
operator|&&
operator|!
operator|(
name|mutation
operator|instanceof
name|Delete
operator|)
condition|)
block|{
throw|throw
operator|new
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|DoNotRetryIOException
argument_list|(
literal|"Action must be Put or Delete"
argument_list|)
throw|;
block|}
if|if
condition|(
operator|!
name|Bytes
operator|.
name|equals
argument_list|(
name|row
argument_list|,
name|mutation
operator|.
name|getRow
argument_list|()
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|DoNotRetryIOException
argument_list|(
literal|"Action's getRow must match"
argument_list|)
throw|;
block|}
block|}
specifier|private
name|boolean
name|matches
parameter_list|(
specifier|final
name|CompareOperator
name|op
parameter_list|,
specifier|final
name|int
name|compareResult
parameter_list|)
block|{
name|boolean
name|matches
init|=
literal|false
decl_stmt|;
switch|switch
condition|(
name|op
condition|)
block|{
case|case
name|LESS
case|:
name|matches
operator|=
name|compareResult
operator|<
literal|0
expr_stmt|;
break|break;
case|case
name|LESS_OR_EQUAL
case|:
name|matches
operator|=
name|compareResult
operator|<=
literal|0
expr_stmt|;
break|break;
case|case
name|EQUAL
case|:
name|matches
operator|=
name|compareResult
operator|==
literal|0
expr_stmt|;
break|break;
case|case
name|NOT_EQUAL
case|:
name|matches
operator|=
name|compareResult
operator|!=
literal|0
expr_stmt|;
break|break;
case|case
name|GREATER_OR_EQUAL
case|:
name|matches
operator|=
name|compareResult
operator|>=
literal|0
expr_stmt|;
break|break;
case|case
name|GREATER
case|:
name|matches
operator|=
name|compareResult
operator|>
literal|0
expr_stmt|;
break|break;
default|default:
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"Unknown Compare op "
operator|+
name|op
operator|.
name|name
argument_list|()
argument_list|)
throw|;
block|}
return|return
name|matches
return|;
block|}
specifier|private
name|void
name|doBatchMutate
parameter_list|(
name|Mutation
name|mutation
parameter_list|)
throws|throws
name|IOException
block|{
comment|// Currently this is only called for puts and deletes, so no nonces.
name|OperationStatus
index|[]
name|batchMutate
init|=
name|this
operator|.
name|batchMutate
argument_list|(
operator|new
name|Mutation
index|[]
block|{
name|mutation
block|}
argument_list|)
decl_stmt|;
if|if
condition|(
name|batchMutate
index|[
literal|0
index|]
operator|.
name|getOperationStatusCode
argument_list|()
operator|.
name|equals
argument_list|(
name|OperationStatusCode
operator|.
name|SANITY_CHECK_FAILURE
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|FailedSanityCheckException
argument_list|(
name|batchMutate
index|[
literal|0
index|]
operator|.
name|getExceptionMsg
argument_list|()
argument_list|)
throw|;
block|}
elseif|else
if|if
condition|(
name|batchMutate
index|[
literal|0
index|]
operator|.
name|getOperationStatusCode
argument_list|()
operator|.
name|equals
argument_list|(
name|OperationStatusCode
operator|.
name|BAD_FAMILY
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|NoSuchColumnFamilyException
argument_list|(
name|batchMutate
index|[
literal|0
index|]
operator|.
name|getExceptionMsg
argument_list|()
argument_list|)
throw|;
block|}
elseif|else
if|if
condition|(
name|batchMutate
index|[
literal|0
index|]
operator|.
name|getOperationStatusCode
argument_list|()
operator|.
name|equals
argument_list|(
name|OperationStatusCode
operator|.
name|STORE_TOO_BUSY
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|RegionTooBusyException
argument_list|(
name|batchMutate
index|[
literal|0
index|]
operator|.
name|getExceptionMsg
argument_list|()
argument_list|)
throw|;
block|}
block|}
comment|/**    * Complete taking the snapshot on the region. Writes the region info and adds references to the    * working snapshot directory.    *    * TODO for api consistency, consider adding another version with no {@link ForeignExceptionSnare}    * arg.  (In the future other cancellable HRegion methods could eventually add a    * {@link ForeignExceptionSnare}, or we could do something fancier).    *    * @param desc snapshot description object    * @param exnSnare ForeignExceptionSnare that captures external exceptions in case we need to    *   bail out.  This is allowed to be null and will just be ignored in that case.    * @throws IOException if there is an external or internal error causing the snapshot to fail    */
specifier|public
name|void
name|addRegionToSnapshot
parameter_list|(
name|SnapshotDescription
name|desc
parameter_list|,
name|ForeignExceptionSnare
name|exnSnare
parameter_list|)
throws|throws
name|IOException
block|{
name|Path
name|rootDir
init|=
name|FSUtils
operator|.
name|getRootDir
argument_list|(
name|conf
argument_list|)
decl_stmt|;
name|Path
name|snapshotDir
init|=
name|SnapshotDescriptionUtils
operator|.
name|getWorkingSnapshotDir
argument_list|(
name|desc
argument_list|,
name|rootDir
argument_list|)
decl_stmt|;
name|SnapshotManifest
name|manifest
init|=
name|SnapshotManifest
operator|.
name|create
argument_list|(
name|conf
argument_list|,
name|getFilesystem
argument_list|()
argument_list|,
name|snapshotDir
argument_list|,
name|desc
argument_list|,
name|exnSnare
argument_list|)
decl_stmt|;
name|manifest
operator|.
name|addRegion
argument_list|(
name|this
argument_list|)
expr_stmt|;
block|}
specifier|private
name|void
name|updateSequenceId
parameter_list|(
specifier|final
name|Iterable
argument_list|<
name|List
argument_list|<
name|Cell
argument_list|>
argument_list|>
name|cellItr
parameter_list|,
specifier|final
name|long
name|sequenceId
parameter_list|)
throws|throws
name|IOException
block|{
for|for
control|(
name|List
argument_list|<
name|Cell
argument_list|>
name|cells
range|:
name|cellItr
control|)
block|{
if|if
condition|(
name|cells
operator|==
literal|null
condition|)
return|return;
for|for
control|(
name|Cell
name|cell
range|:
name|cells
control|)
block|{
name|PrivateCellUtil
operator|.
name|setSequenceId
argument_list|(
name|cell
argument_list|,
name|sequenceId
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|/**    * Replace any cell timestamps set to {@link org.apache.hadoop.hbase.HConstants#LATEST_TIMESTAMP}    * provided current timestamp.    * @param cellItr    * @param now    */
specifier|private
specifier|static
name|void
name|updateCellTimestamps
parameter_list|(
specifier|final
name|Iterable
argument_list|<
name|List
argument_list|<
name|Cell
argument_list|>
argument_list|>
name|cellItr
parameter_list|,
specifier|final
name|byte
index|[]
name|now
parameter_list|)
throws|throws
name|IOException
block|{
for|for
control|(
name|List
argument_list|<
name|Cell
argument_list|>
name|cells
range|:
name|cellItr
control|)
block|{
if|if
condition|(
name|cells
operator|==
literal|null
condition|)
continue|continue;
comment|// Optimization: 'foreach' loop is not used. See:
comment|// HBASE-12023 HRegion.applyFamilyMapToMemstore creates too many iterator objects
assert|assert
name|cells
operator|instanceof
name|RandomAccess
assert|;
name|int
name|listSize
init|=
name|cells
operator|.
name|size
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|listSize
condition|;
name|i
operator|++
control|)
block|{
name|PrivateCellUtil
operator|.
name|updateLatestStamp
argument_list|(
name|cells
operator|.
name|get
argument_list|(
name|i
argument_list|)
argument_list|,
name|now
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|/**    * Possibly rewrite incoming cell tags.    */
name|void
name|rewriteCellTags
parameter_list|(
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|List
argument_list|<
name|Cell
argument_list|>
argument_list|>
name|familyMap
parameter_list|,
specifier|final
name|Mutation
name|m
parameter_list|)
block|{
comment|// Check if we have any work to do and early out otherwise
comment|// Update these checks as more logic is added here
if|if
condition|(
name|m
operator|.
name|getTTL
argument_list|()
operator|==
name|Long
operator|.
name|MAX_VALUE
condition|)
block|{
return|return;
block|}
comment|// From this point we know we have some work to do
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|byte
index|[]
argument_list|,
name|List
argument_list|<
name|Cell
argument_list|>
argument_list|>
name|e
range|:
name|familyMap
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|List
argument_list|<
name|Cell
argument_list|>
name|cells
init|=
name|e
operator|.
name|getValue
argument_list|()
decl_stmt|;
assert|assert
name|cells
operator|instanceof
name|RandomAccess
assert|;
name|int
name|listSize
init|=
name|cells
operator|.
name|size
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|listSize
condition|;
name|i
operator|++
control|)
block|{
name|Cell
name|cell
init|=
name|cells
operator|.
name|get
argument_list|(
name|i
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|Tag
argument_list|>
name|newTags
init|=
name|TagUtil
operator|.
name|carryForwardTags
argument_list|(
literal|null
argument_list|,
name|cell
argument_list|)
decl_stmt|;
name|newTags
operator|=
name|TagUtil
operator|.
name|carryForwardTTLTag
argument_list|(
name|newTags
argument_list|,
name|m
operator|.
name|getTTL
argument_list|()
argument_list|)
expr_stmt|;
comment|// Rewrite the cell with the updated set of tags
name|cells
operator|.
name|set
argument_list|(
name|i
argument_list|,
name|PrivateCellUtil
operator|.
name|createCell
argument_list|(
name|cell
argument_list|,
name|newTags
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|/*    * Check if resources to support an update.    *    * We throw RegionTooBusyException if above memstore limit    * and expect client to retry using some kind of backoff   */
name|void
name|checkResources
parameter_list|()
throws|throws
name|RegionTooBusyException
block|{
comment|// If catalog region, do not impose resource constraints or block updates.
if|if
condition|(
name|this
operator|.
name|getRegionInfo
argument_list|()
operator|.
name|isMetaRegion
argument_list|()
condition|)
return|return;
name|MemStoreSize
name|mss
init|=
name|this
operator|.
name|memStoreSizing
operator|.
name|getMemStoreSize
argument_list|()
decl_stmt|;
if|if
condition|(
name|mss
operator|.
name|getHeapSize
argument_list|()
operator|+
name|mss
operator|.
name|getOffHeapSize
argument_list|()
operator|>
name|this
operator|.
name|blockingMemStoreSize
condition|)
block|{
name|blockedRequestsCount
operator|.
name|increment
argument_list|()
expr_stmt|;
name|requestFlush
argument_list|()
expr_stmt|;
comment|// Don't print current limit because it will vary too much. The message is used as a key
comment|// over in RetriesExhaustedWithDetailsException processing.
throw|throw
operator|new
name|RegionTooBusyException
argument_list|(
literal|"Over memstore limit="
operator|+
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|procedure2
operator|.
name|util
operator|.
name|StringUtils
operator|.
name|humanSize
argument_list|(
name|this
operator|.
name|blockingMemStoreSize
argument_list|)
operator|+
literal|", regionName="
operator|+
operator|(
name|this
operator|.
name|getRegionInfo
argument_list|()
operator|==
literal|null
condition|?
literal|"unknown"
else|:
name|this
operator|.
name|getRegionInfo
argument_list|()
operator|.
name|getEncodedName
argument_list|()
operator|)
operator|+
literal|", server="
operator|+
operator|(
name|this
operator|.
name|getRegionServerServices
argument_list|()
operator|==
literal|null
condition|?
literal|"unknown"
else|:
name|this
operator|.
name|getRegionServerServices
argument_list|()
operator|.
name|getServerName
argument_list|()
operator|)
argument_list|)
throw|;
block|}
block|}
comment|/**    * @throws IOException Throws exception if region is in read-only mode.    */
specifier|protected
name|void
name|checkReadOnly
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|isReadOnly
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|DoNotRetryIOException
argument_list|(
literal|"region is read only"
argument_list|)
throw|;
block|}
block|}
specifier|protected
name|void
name|checkReadsEnabled
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
operator|!
name|this
operator|.
name|writestate
operator|.
name|readsEnabled
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|getRegionInfo
argument_list|()
operator|.
name|getEncodedName
argument_list|()
operator|+
literal|": The region's reads are disabled. Cannot serve the request"
argument_list|)
throw|;
block|}
block|}
specifier|public
name|void
name|setReadsEnabled
parameter_list|(
name|boolean
name|readsEnabled
parameter_list|)
block|{
if|if
condition|(
name|readsEnabled
operator|&&
operator|!
name|this
operator|.
name|writestate
operator|.
name|readsEnabled
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
name|getRegionInfo
argument_list|()
operator|.
name|getEncodedName
argument_list|()
operator|+
literal|" : Enabling reads for region."
argument_list|)
expr_stmt|;
block|}
name|this
operator|.
name|writestate
operator|.
name|setReadsEnabled
argument_list|(
name|readsEnabled
argument_list|)
expr_stmt|;
block|}
comment|/**    * Add updates first to the wal and then add values to memstore.    * Warning: Assumption is caller has lock on passed in row.    * @param edits Cell updates by column    * @throws IOException    */
name|void
name|put
parameter_list|(
specifier|final
name|byte
index|[]
name|row
parameter_list|,
name|byte
index|[]
name|family
parameter_list|,
name|List
argument_list|<
name|Cell
argument_list|>
name|edits
parameter_list|)
throws|throws
name|IOException
block|{
name|NavigableMap
argument_list|<
name|byte
index|[]
argument_list|,
name|List
argument_list|<
name|Cell
argument_list|>
argument_list|>
name|familyMap
decl_stmt|;
name|familyMap
operator|=
operator|new
name|TreeMap
argument_list|<>
argument_list|(
name|Bytes
operator|.
name|BYTES_COMPARATOR
argument_list|)
expr_stmt|;
name|familyMap
operator|.
name|put
argument_list|(
name|family
argument_list|,
name|edits
argument_list|)
expr_stmt|;
name|Put
name|p
init|=
operator|new
name|Put
argument_list|(
name|row
argument_list|)
decl_stmt|;
name|p
operator|.
name|setFamilyCellMap
argument_list|(
name|familyMap
argument_list|)
expr_stmt|;
name|doBatchMutate
argument_list|(
name|p
argument_list|)
expr_stmt|;
block|}
comment|/**    * @param delta If we are doing delta changes -- e.g. increment/append -- then this flag will be    *          set; when set we will run operations that make sense in the increment/append scenario    *          but that do not make sense otherwise.    * @see #applyToMemStore(HStore, Cell, MemStoreSizing)    */
specifier|private
name|void
name|applyToMemStore
parameter_list|(
name|HStore
name|store
parameter_list|,
name|List
argument_list|<
name|Cell
argument_list|>
name|cells
parameter_list|,
name|boolean
name|delta
parameter_list|,
name|MemStoreSizing
name|memstoreAccounting
parameter_list|)
throws|throws
name|IOException
block|{
comment|// Any change in how we update Store/MemStore needs to also be done in other applyToMemStore!!!!
name|boolean
name|upsert
init|=
name|delta
operator|&&
name|store
operator|.
name|getColumnFamilyDescriptor
argument_list|()
operator|.
name|getMaxVersions
argument_list|()
operator|==
literal|1
decl_stmt|;
if|if
condition|(
name|upsert
condition|)
block|{
name|store
operator|.
name|upsert
argument_list|(
name|cells
argument_list|,
name|getSmallestReadPoint
argument_list|()
argument_list|,
name|memstoreAccounting
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|store
operator|.
name|add
argument_list|(
name|cells
argument_list|,
name|memstoreAccounting
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * @see #applyToMemStore(HStore, List, boolean, MemStoreSizing)    */
specifier|private
name|void
name|applyToMemStore
parameter_list|(
name|HStore
name|store
parameter_list|,
name|Cell
name|cell
parameter_list|,
name|MemStoreSizing
name|memstoreAccounting
parameter_list|)
throws|throws
name|IOException
block|{
comment|// Any change in how we update Store/MemStore needs to also be done in other applyToMemStore!!!!
if|if
condition|(
name|store
operator|==
literal|null
condition|)
block|{
name|checkFamily
argument_list|(
name|CellUtil
operator|.
name|cloneFamily
argument_list|(
name|cell
argument_list|)
argument_list|)
expr_stmt|;
comment|// Unreachable because checkFamily will throw exception
block|}
name|store
operator|.
name|add
argument_list|(
name|cell
argument_list|,
name|memstoreAccounting
argument_list|)
expr_stmt|;
block|}
comment|/**    * Check the collection of families for validity.    * @param families    * @throws NoSuchColumnFamilyException    */
specifier|public
name|void
name|checkFamilies
parameter_list|(
name|Collection
argument_list|<
name|byte
index|[]
argument_list|>
name|families
parameter_list|)
throws|throws
name|NoSuchColumnFamilyException
block|{
for|for
control|(
name|byte
index|[]
name|family
range|:
name|families
control|)
block|{
name|checkFamily
argument_list|(
name|family
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Check the collection of families for valid timestamps    * @param familyMap    * @param now current timestamp    * @throws FailedSanityCheckException    */
specifier|public
name|void
name|checkTimestamps
parameter_list|(
specifier|final
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|List
argument_list|<
name|Cell
argument_list|>
argument_list|>
name|familyMap
parameter_list|,
name|long
name|now
parameter_list|)
throws|throws
name|FailedSanityCheckException
block|{
if|if
condition|(
name|timestampSlop
operator|==
name|HConstants
operator|.
name|LATEST_TIMESTAMP
condition|)
block|{
return|return;
block|}
name|long
name|maxTs
init|=
name|now
operator|+
name|timestampSlop
decl_stmt|;
for|for
control|(
name|List
argument_list|<
name|Cell
argument_list|>
name|kvs
range|:
name|familyMap
operator|.
name|values
argument_list|()
control|)
block|{
comment|// Optimization: 'foreach' loop is not used. See:
comment|// HBASE-12023 HRegion.applyFamilyMapToMemstore creates too many iterator objects
assert|assert
name|kvs
operator|instanceof
name|RandomAccess
assert|;
name|int
name|listSize
init|=
name|kvs
operator|.
name|size
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|listSize
condition|;
name|i
operator|++
control|)
block|{
name|Cell
name|cell
init|=
name|kvs
operator|.
name|get
argument_list|(
name|i
argument_list|)
decl_stmt|;
comment|// see if the user-side TS is out of range. latest = server-side
name|long
name|ts
init|=
name|cell
operator|.
name|getTimestamp
argument_list|()
decl_stmt|;
if|if
condition|(
name|ts
operator|!=
name|HConstants
operator|.
name|LATEST_TIMESTAMP
operator|&&
name|ts
operator|>
name|maxTs
condition|)
block|{
throw|throw
operator|new
name|FailedSanityCheckException
argument_list|(
literal|"Timestamp for KV out of range "
operator|+
name|cell
operator|+
literal|" (too.new="
operator|+
name|timestampSlop
operator|+
literal|")"
argument_list|)
throw|;
block|}
block|}
block|}
block|}
comment|/*    * @param size    * @return True if size is over the flush threshold    */
specifier|private
name|boolean
name|isFlushSize
parameter_list|(
name|MemStoreSize
name|size
parameter_list|)
block|{
return|return
name|size
operator|.
name|getHeapSize
argument_list|()
operator|+
name|size
operator|.
name|getOffHeapSize
argument_list|()
operator|>
name|getMemStoreFlushSize
argument_list|()
return|;
block|}
comment|/**    * Read the edits put under this region by wal splitting process.  Put    * the recovered edits back up into this region.    *    *<p>We can ignore any wal message that has a sequence ID that's equal to or    * lower than minSeqId.  (Because we know such messages are already    * reflected in the HFiles.)    *    *<p>While this is running we are putting pressure on memory yet we are    * outside of our usual accounting because we are not yet an onlined region    * (this stuff is being run as part of Region initialization).  This means    * that if we're up against global memory limits, we'll not be flagged to flush    * because we are not online. We can't be flushed by usual mechanisms anyways;    * we're not yet online so our relative sequenceids are not yet aligned with    * WAL sequenceids -- not till we come up online, post processing of split    * edits.    *    *<p>But to help relieve memory pressure, at least manage our own heap size    * flushing if are in excess of per-region limits.  Flushing, though, we have    * to be careful and avoid using the regionserver/wal sequenceid.  Its running    * on a different line to whats going on in here in this region context so if we    * crashed replaying these edits, but in the midst had a flush that used the    * regionserver wal with a sequenceid in excess of whats going on in here    * in this region and with its split editlogs, then we could miss edits the    * next time we go to recover. So, we have to flush inline, using seqids that    * make sense in a this single region context only -- until we online.    *    * @param maxSeqIdInStores Any edit found in split editlogs needs to be in excess of    * the maxSeqId for the store to be applied, else its skipped.    * @return the sequence id of the last edit added to this region out of the    * recovered edits log or<code>minSeqId</code> if nothing added from editlogs.    * @throws IOException    */
specifier|protected
name|long
name|replayRecoveredEditsIfAny
parameter_list|(
specifier|final
name|Path
name|regiondir
parameter_list|,
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|Long
argument_list|>
name|maxSeqIdInStores
parameter_list|,
specifier|final
name|CancelableProgressable
name|reporter
parameter_list|,
specifier|final
name|MonitoredTask
name|status
parameter_list|)
throws|throws
name|IOException
block|{
name|long
name|minSeqIdForTheRegion
init|=
operator|-
literal|1
decl_stmt|;
for|for
control|(
name|Long
name|maxSeqIdInStore
range|:
name|maxSeqIdInStores
operator|.
name|values
argument_list|()
control|)
block|{
if|if
condition|(
name|maxSeqIdInStore
operator|<
name|minSeqIdForTheRegion
operator|||
name|minSeqIdForTheRegion
operator|==
operator|-
literal|1
condition|)
block|{
name|minSeqIdForTheRegion
operator|=
name|maxSeqIdInStore
expr_stmt|;
block|}
block|}
name|long
name|seqid
init|=
name|minSeqIdForTheRegion
decl_stmt|;
name|FileSystem
name|fs
init|=
name|this
operator|.
name|fs
operator|.
name|getFileSystem
argument_list|()
decl_stmt|;
name|NavigableSet
argument_list|<
name|Path
argument_list|>
name|files
init|=
name|WALSplitter
operator|.
name|getSplitEditFilesSorted
argument_list|(
name|fs
argument_list|,
name|regiondir
argument_list|)
decl_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Found "
operator|+
operator|(
name|files
operator|==
literal|null
condition|?
literal|0
else|:
name|files
operator|.
name|size
argument_list|()
operator|)
operator|+
literal|" recovered edits file(s) under "
operator|+
name|regiondir
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|files
operator|==
literal|null
operator|||
name|files
operator|.
name|isEmpty
argument_list|()
condition|)
return|return
name|seqid
return|;
for|for
control|(
name|Path
name|edits
range|:
name|files
control|)
block|{
if|if
condition|(
name|edits
operator|==
literal|null
operator|||
operator|!
name|fs
operator|.
name|exists
argument_list|(
name|edits
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Null or non-existent edits file: "
operator|+
name|edits
argument_list|)
expr_stmt|;
continue|continue;
block|}
if|if
condition|(
name|isZeroLengthThenDelete
argument_list|(
name|fs
argument_list|,
name|edits
argument_list|)
condition|)
continue|continue;
name|long
name|maxSeqId
decl_stmt|;
name|String
name|fileName
init|=
name|edits
operator|.
name|getName
argument_list|()
decl_stmt|;
name|maxSeqId
operator|=
name|Math
operator|.
name|abs
argument_list|(
name|Long
operator|.
name|parseLong
argument_list|(
name|fileName
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|maxSeqId
operator|<=
name|minSeqIdForTheRegion
condition|)
block|{
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|String
name|msg
init|=
literal|"Maximum sequenceid for this wal is "
operator|+
name|maxSeqId
operator|+
literal|" and minimum sequenceid for the region is "
operator|+
name|minSeqIdForTheRegion
operator|+
literal|", skipped the whole file, path="
operator|+
name|edits
decl_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
name|msg
argument_list|)
expr_stmt|;
block|}
continue|continue;
block|}
try|try
block|{
comment|// replay the edits. Replay can return -1 if everything is skipped, only update
comment|// if seqId is greater
name|seqid
operator|=
name|Math
operator|.
name|max
argument_list|(
name|seqid
argument_list|,
name|replayRecoveredEdits
argument_list|(
name|edits
argument_list|,
name|maxSeqIdInStores
argument_list|,
name|reporter
argument_list|)
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|boolean
name|skipErrors
init|=
name|conf
operator|.
name|getBoolean
argument_list|(
name|HConstants
operator|.
name|HREGION_EDITS_REPLAY_SKIP_ERRORS
argument_list|,
name|conf
operator|.
name|getBoolean
argument_list|(
literal|"hbase.skip.errors"
argument_list|,
name|HConstants
operator|.
name|DEFAULT_HREGION_EDITS_REPLAY_SKIP_ERRORS
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|conf
operator|.
name|get
argument_list|(
literal|"hbase.skip.errors"
argument_list|)
operator|!=
literal|null
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"The property 'hbase.skip.errors' has been deprecated. Please use "
operator|+
name|HConstants
operator|.
name|HREGION_EDITS_REPLAY_SKIP_ERRORS
operator|+
literal|" instead."
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|skipErrors
condition|)
block|{
name|Path
name|p
init|=
name|WALSplitter
operator|.
name|moveAsideBadEditsFile
argument_list|(
name|fs
argument_list|,
name|edits
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|error
argument_list|(
name|HConstants
operator|.
name|HREGION_EDITS_REPLAY_SKIP_ERRORS
operator|+
literal|"=true so continuing. Renamed "
operator|+
name|edits
operator|+
literal|" as "
operator|+
name|p
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
else|else
block|{
throw|throw
name|e
throw|;
block|}
block|}
block|}
comment|// The edits size added into rsAccounting during this replaying will not
comment|// be required any more. So just clear it.
if|if
condition|(
name|this
operator|.
name|rsAccounting
operator|!=
literal|null
condition|)
block|{
name|this
operator|.
name|rsAccounting
operator|.
name|clearRegionReplayEditsSize
argument_list|(
name|getRegionInfo
argument_list|()
operator|.
name|getRegionName
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|seqid
operator|>
name|minSeqIdForTheRegion
condition|)
block|{
comment|// Then we added some edits to memory. Flush and cleanup split edit files.
name|internalFlushcache
argument_list|(
literal|null
argument_list|,
name|seqid
argument_list|,
name|stores
operator|.
name|values
argument_list|()
argument_list|,
name|status
argument_list|,
literal|false
argument_list|,
name|FlushLifeCycleTracker
operator|.
name|DUMMY
argument_list|)
expr_stmt|;
block|}
comment|// Now delete the content of recovered edits.  We're done w/ them.
if|if
condition|(
name|files
operator|.
name|size
argument_list|()
operator|>
literal|0
operator|&&
name|this
operator|.
name|conf
operator|.
name|getBoolean
argument_list|(
literal|"hbase.region.archive.recovered.edits"
argument_list|,
literal|false
argument_list|)
condition|)
block|{
comment|// For debugging data loss issues!
comment|// If this flag is set, make use of the hfile archiving by making recovered.edits a fake
comment|// column family. Have to fake out file type too by casting our recovered.edits as storefiles
name|String
name|fakeFamilyName
init|=
name|WALSplitter
operator|.
name|getRegionDirRecoveredEditsDir
argument_list|(
name|regiondir
argument_list|)
operator|.
name|getName
argument_list|()
decl_stmt|;
name|Set
argument_list|<
name|HStoreFile
argument_list|>
name|fakeStoreFiles
init|=
operator|new
name|HashSet
argument_list|<>
argument_list|(
name|files
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
for|for
control|(
name|Path
name|file
range|:
name|files
control|)
block|{
name|fakeStoreFiles
operator|.
name|add
argument_list|(
operator|new
name|HStoreFile
argument_list|(
name|getRegionFileSystem
argument_list|()
operator|.
name|getFileSystem
argument_list|()
argument_list|,
name|file
argument_list|,
name|this
operator|.
name|conf
argument_list|,
literal|null
argument_list|,
literal|null
argument_list|,
literal|true
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|getRegionFileSystem
argument_list|()
operator|.
name|removeStoreFiles
argument_list|(
name|fakeFamilyName
argument_list|,
name|fakeStoreFiles
argument_list|)
expr_stmt|;
block|}
else|else
block|{
for|for
control|(
name|Path
name|file
range|:
name|files
control|)
block|{
if|if
condition|(
operator|!
name|fs
operator|.
name|delete
argument_list|(
name|file
argument_list|,
literal|false
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Failed delete of "
operator|+
name|file
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Deleted recovered.edits file="
operator|+
name|file
argument_list|)
expr_stmt|;
block|}
block|}
block|}
return|return
name|seqid
return|;
block|}
comment|/*    * @param edits File of recovered edits.    * @param maxSeqIdInStores Maximum sequenceid found in each store.  Edits in wal    * must be larger than this to be replayed for each store.    * @param reporter    * @return the sequence id of the last edit added to this region out of the    * recovered edits log or<code>minSeqId</code> if nothing added from editlogs.    * @throws IOException    */
specifier|private
name|long
name|replayRecoveredEdits
parameter_list|(
specifier|final
name|Path
name|edits
parameter_list|,
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|Long
argument_list|>
name|maxSeqIdInStores
parameter_list|,
specifier|final
name|CancelableProgressable
name|reporter
parameter_list|)
throws|throws
name|IOException
block|{
name|String
name|msg
init|=
literal|"Replaying edits from "
operator|+
name|edits
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
name|msg
argument_list|)
expr_stmt|;
name|MonitoredTask
name|status
init|=
name|TaskMonitor
operator|.
name|get
argument_list|()
operator|.
name|createStatus
argument_list|(
name|msg
argument_list|)
decl_stmt|;
name|FileSystem
name|fs
init|=
name|this
operator|.
name|fs
operator|.
name|getFileSystem
argument_list|()
decl_stmt|;
name|status
operator|.
name|setStatus
argument_list|(
literal|"Opening recovered edits"
argument_list|)
expr_stmt|;
name|WAL
operator|.
name|Reader
name|reader
init|=
literal|null
decl_stmt|;
try|try
block|{
name|reader
operator|=
name|WALFactory
operator|.
name|createReader
argument_list|(
name|fs
argument_list|,
name|edits
argument_list|,
name|conf
argument_list|)
expr_stmt|;
name|long
name|currentEditSeqId
init|=
operator|-
literal|1
decl_stmt|;
name|long
name|currentReplaySeqId
init|=
operator|-
literal|1
decl_stmt|;
name|long
name|firstSeqIdInLog
init|=
operator|-
literal|1
decl_stmt|;
name|long
name|skippedEdits
init|=
literal|0
decl_stmt|;
name|long
name|editsCount
init|=
literal|0
decl_stmt|;
name|long
name|intervalEdits
init|=
literal|0
decl_stmt|;
name|WAL
operator|.
name|Entry
name|entry
decl_stmt|;
name|HStore
name|store
init|=
literal|null
decl_stmt|;
name|boolean
name|reported_once
init|=
literal|false
decl_stmt|;
name|ServerNonceManager
name|ng
init|=
name|this
operator|.
name|rsServices
operator|==
literal|null
condition|?
literal|null
else|:
name|this
operator|.
name|rsServices
operator|.
name|getNonceManager
argument_list|()
decl_stmt|;
try|try
block|{
comment|// How many edits seen before we check elapsed time
name|int
name|interval
init|=
name|this
operator|.
name|conf
operator|.
name|getInt
argument_list|(
literal|"hbase.hstore.report.interval.edits"
argument_list|,
literal|2000
argument_list|)
decl_stmt|;
comment|// How often to send a progress report (default 1/2 master timeout)
name|int
name|period
init|=
name|this
operator|.
name|conf
operator|.
name|getInt
argument_list|(
literal|"hbase.hstore.report.period"
argument_list|,
literal|300000
argument_list|)
decl_stmt|;
name|long
name|lastReport
init|=
name|EnvironmentEdgeManager
operator|.
name|currentTime
argument_list|()
decl_stmt|;
if|if
condition|(
name|coprocessorHost
operator|!=
literal|null
condition|)
block|{
name|coprocessorHost
operator|.
name|preReplayWALs
argument_list|(
name|this
operator|.
name|getRegionInfo
argument_list|()
argument_list|,
name|edits
argument_list|)
expr_stmt|;
block|}
while|while
condition|(
operator|(
name|entry
operator|=
name|reader
operator|.
name|next
argument_list|()
operator|)
operator|!=
literal|null
condition|)
block|{
name|WALKey
name|key
init|=
name|entry
operator|.
name|getKey
argument_list|()
decl_stmt|;
name|WALEdit
name|val
init|=
name|entry
operator|.
name|getEdit
argument_list|()
decl_stmt|;
if|if
condition|(
name|ng
operator|!=
literal|null
condition|)
block|{
comment|// some test, or nonces disabled
name|ng
operator|.
name|reportOperationFromWal
argument_list|(
name|key
operator|.
name|getNonceGroup
argument_list|()
argument_list|,
name|key
operator|.
name|getNonce
argument_list|()
argument_list|,
name|key
operator|.
name|getWriteTime
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|reporter
operator|!=
literal|null
condition|)
block|{
name|intervalEdits
operator|+=
name|val
operator|.
name|size
argument_list|()
expr_stmt|;
if|if
condition|(
name|intervalEdits
operator|>=
name|interval
condition|)
block|{
comment|// Number of edits interval reached
name|intervalEdits
operator|=
literal|0
expr_stmt|;
name|long
name|cur
init|=
name|EnvironmentEdgeManager
operator|.
name|currentTime
argument_list|()
decl_stmt|;
if|if
condition|(
name|lastReport
operator|+
name|period
operator|<=
name|cur
condition|)
block|{
name|status
operator|.
name|setStatus
argument_list|(
literal|"Replaying edits..."
operator|+
literal|" skipped="
operator|+
name|skippedEdits
operator|+
literal|" edits="
operator|+
name|editsCount
argument_list|)
expr_stmt|;
comment|// Timeout reached
if|if
condition|(
operator|!
name|reporter
operator|.
name|progress
argument_list|()
condition|)
block|{
name|msg
operator|=
literal|"Progressable reporter failed, stopping replay"
expr_stmt|;
name|LOG
operator|.
name|warn
argument_list|(
name|msg
argument_list|)
expr_stmt|;
name|status
operator|.
name|abort
argument_list|(
name|msg
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|IOException
argument_list|(
name|msg
argument_list|)
throw|;
block|}
name|reported_once
operator|=
literal|true
expr_stmt|;
name|lastReport
operator|=
name|cur
expr_stmt|;
block|}
block|}
block|}
if|if
condition|(
name|firstSeqIdInLog
operator|==
operator|-
literal|1
condition|)
block|{
name|firstSeqIdInLog
operator|=
name|key
operator|.
name|getSequenceId
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|currentEditSeqId
operator|>
name|key
operator|.
name|getSequenceId
argument_list|()
condition|)
block|{
comment|// when this condition is true, it means we have a serious defect because we need to
comment|// maintain increasing SeqId for WAL edits per region
name|LOG
operator|.
name|error
argument_list|(
name|getRegionInfo
argument_list|()
operator|.
name|getEncodedName
argument_list|()
operator|+
literal|" : "
operator|+
literal|"Found decreasing SeqId. PreId="
operator|+
name|currentEditSeqId
operator|+
literal|" key="
operator|+
name|key
operator|+
literal|"; edit="
operator|+
name|val
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|currentEditSeqId
operator|=
name|key
operator|.
name|getSequenceId
argument_list|()
expr_stmt|;
block|}
name|currentReplaySeqId
operator|=
operator|(
name|key
operator|.
name|getOrigLogSeqNum
argument_list|()
operator|>
literal|0
operator|)
condition|?
name|key
operator|.
name|getOrigLogSeqNum
argument_list|()
else|:
name|currentEditSeqId
expr_stmt|;
comment|// Start coprocessor replay here. The coprocessor is for each WALEdit
comment|// instead of a KeyValue.
if|if
condition|(
name|coprocessorHost
operator|!=
literal|null
condition|)
block|{
name|status
operator|.
name|setStatus
argument_list|(
literal|"Running pre-WAL-restore hook in coprocessors"
argument_list|)
expr_stmt|;
if|if
condition|(
name|coprocessorHost
operator|.
name|preWALRestore
argument_list|(
name|this
operator|.
name|getRegionInfo
argument_list|()
argument_list|,
name|key
argument_list|,
name|val
argument_list|)
condition|)
block|{
comment|// if bypass this wal entry, ignore it ...
continue|continue;
block|}
block|}
name|boolean
name|checkRowWithinBoundary
init|=
literal|false
decl_stmt|;
comment|// Check this edit is for this region.
if|if
condition|(
operator|!
name|Bytes
operator|.
name|equals
argument_list|(
name|key
operator|.
name|getEncodedRegionName
argument_list|()
argument_list|,
name|this
operator|.
name|getRegionInfo
argument_list|()
operator|.
name|getEncodedNameAsBytes
argument_list|()
argument_list|)
condition|)
block|{
name|checkRowWithinBoundary
operator|=
literal|true
expr_stmt|;
block|}
name|boolean
name|flush
init|=
literal|false
decl_stmt|;
name|MemStoreSizing
name|memStoreSizing
init|=
operator|new
name|NonThreadSafeMemStoreSizing
argument_list|()
decl_stmt|;
for|for
control|(
name|Cell
name|cell
range|:
name|val
operator|.
name|getCells
argument_list|()
control|)
block|{
comment|// Check this edit is for me. Also, guard against writing the special
comment|// METACOLUMN info such as HBASE::CACHEFLUSH entries
if|if
condition|(
name|CellUtil
operator|.
name|matchingFamily
argument_list|(
name|cell
argument_list|,
name|WALEdit
operator|.
name|METAFAMILY
argument_list|)
condition|)
block|{
comment|// if region names don't match, skipp replaying compaction marker
if|if
condition|(
operator|!
name|checkRowWithinBoundary
condition|)
block|{
comment|//this is a special edit, we should handle it
name|CompactionDescriptor
name|compaction
init|=
name|WALEdit
operator|.
name|getCompaction
argument_list|(
name|cell
argument_list|)
decl_stmt|;
if|if
condition|(
name|compaction
operator|!=
literal|null
condition|)
block|{
comment|//replay the compaction
name|replayWALCompactionMarker
argument_list|(
name|compaction
argument_list|,
literal|false
argument_list|,
literal|true
argument_list|,
name|Long
operator|.
name|MAX_VALUE
argument_list|)
expr_stmt|;
block|}
block|}
name|skippedEdits
operator|++
expr_stmt|;
continue|continue;
block|}
comment|// Figure which store the edit is meant for.
if|if
condition|(
name|store
operator|==
literal|null
operator|||
operator|!
name|CellUtil
operator|.
name|matchingFamily
argument_list|(
name|cell
argument_list|,
name|store
operator|.
name|getColumnFamilyDescriptor
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|)
condition|)
block|{
name|store
operator|=
name|getStore
argument_list|(
name|cell
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|store
operator|==
literal|null
condition|)
block|{
comment|// This should never happen.  Perhaps schema was changed between
comment|// crash and redeploy?
name|LOG
operator|.
name|warn
argument_list|(
literal|"No family for "
operator|+
name|cell
argument_list|)
expr_stmt|;
name|skippedEdits
operator|++
expr_stmt|;
continue|continue;
block|}
if|if
condition|(
name|checkRowWithinBoundary
operator|&&
operator|!
name|rowIsInRange
argument_list|(
name|this
operator|.
name|getRegionInfo
argument_list|()
argument_list|,
name|cell
operator|.
name|getRowArray
argument_list|()
argument_list|,
name|cell
operator|.
name|getRowOffset
argument_list|()
argument_list|,
name|cell
operator|.
name|getRowLength
argument_list|()
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Row of "
operator|+
name|cell
operator|+
literal|" is not within region boundary"
argument_list|)
expr_stmt|;
name|skippedEdits
operator|++
expr_stmt|;
continue|continue;
block|}
comment|// Now, figure if we should skip this edit.
if|if
condition|(
name|key
operator|.
name|getSequenceId
argument_list|()
operator|<=
name|maxSeqIdInStores
operator|.
name|get
argument_list|(
name|store
operator|.
name|getColumnFamilyDescriptor
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|)
condition|)
block|{
name|skippedEdits
operator|++
expr_stmt|;
continue|continue;
block|}
name|PrivateCellUtil
operator|.
name|setSequenceId
argument_list|(
name|cell
argument_list|,
name|currentReplaySeqId
argument_list|)
expr_stmt|;
name|restoreEdit
argument_list|(
name|store
argument_list|,
name|cell
argument_list|,
name|memStoreSizing
argument_list|)
expr_stmt|;
name|editsCount
operator|++
expr_stmt|;
block|}
name|MemStoreSize
name|mss
init|=
name|memStoreSizing
operator|.
name|getMemStoreSize
argument_list|()
decl_stmt|;
if|if
condition|(
name|this
operator|.
name|rsAccounting
operator|!=
literal|null
condition|)
block|{
name|rsAccounting
operator|.
name|addRegionReplayEditsSize
argument_list|(
name|getRegionInfo
argument_list|()
operator|.
name|getRegionName
argument_list|()
argument_list|,
name|mss
argument_list|)
expr_stmt|;
block|}
name|incMemStoreSize
argument_list|(
name|mss
argument_list|)
expr_stmt|;
name|flush
operator|=
name|isFlushSize
argument_list|(
name|this
operator|.
name|memStoreSizing
operator|.
name|getMemStoreSize
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|flush
condition|)
block|{
name|internalFlushcache
argument_list|(
literal|null
argument_list|,
name|currentEditSeqId
argument_list|,
name|stores
operator|.
name|values
argument_list|()
argument_list|,
name|status
argument_list|,
literal|false
argument_list|,
name|FlushLifeCycleTracker
operator|.
name|DUMMY
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|coprocessorHost
operator|!=
literal|null
condition|)
block|{
name|coprocessorHost
operator|.
name|postWALRestore
argument_list|(
name|this
operator|.
name|getRegionInfo
argument_list|()
argument_list|,
name|key
argument_list|,
name|val
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|coprocessorHost
operator|!=
literal|null
condition|)
block|{
name|coprocessorHost
operator|.
name|postReplayWALs
argument_list|(
name|this
operator|.
name|getRegionInfo
argument_list|()
argument_list|,
name|edits
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|EOFException
name|eof
parameter_list|)
block|{
name|Path
name|p
init|=
name|WALSplitter
operator|.
name|moveAsideBadEditsFile
argument_list|(
name|fs
argument_list|,
name|edits
argument_list|)
decl_stmt|;
name|msg
operator|=
literal|"EnLongAddered EOF. Most likely due to Master failure during "
operator|+
literal|"wal splitting, so we have this data in another edit.  "
operator|+
literal|"Continuing, but renaming "
operator|+
name|edits
operator|+
literal|" as "
operator|+
name|p
expr_stmt|;
name|LOG
operator|.
name|warn
argument_list|(
name|msg
argument_list|,
name|eof
argument_list|)
expr_stmt|;
name|status
operator|.
name|abort
argument_list|(
name|msg
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ioe
parameter_list|)
block|{
comment|// If the IOE resulted from bad file format,
comment|// then this problem is idempotent and retrying won't help
if|if
condition|(
name|ioe
operator|.
name|getCause
argument_list|()
operator|instanceof
name|ParseException
condition|)
block|{
name|Path
name|p
init|=
name|WALSplitter
operator|.
name|moveAsideBadEditsFile
argument_list|(
name|fs
argument_list|,
name|edits
argument_list|)
decl_stmt|;
name|msg
operator|=
literal|"File corruption enLongAddered!  "
operator|+
literal|"Continuing, but renaming "
operator|+
name|edits
operator|+
literal|" as "
operator|+
name|p
expr_stmt|;
name|LOG
operator|.
name|warn
argument_list|(
name|msg
argument_list|,
name|ioe
argument_list|)
expr_stmt|;
name|status
operator|.
name|setStatus
argument_list|(
name|msg
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|status
operator|.
name|abort
argument_list|(
name|StringUtils
operator|.
name|stringifyException
argument_list|(
name|ioe
argument_list|)
argument_list|)
expr_stmt|;
comment|// other IO errors may be transient (bad network connection,
comment|// checksum exception on one datanode, etc).  throw& retry
throw|throw
name|ioe
throw|;
block|}
block|}
if|if
condition|(
name|reporter
operator|!=
literal|null
operator|&&
operator|!
name|reported_once
condition|)
block|{
name|reporter
operator|.
name|progress
argument_list|()
expr_stmt|;
block|}
name|msg
operator|=
literal|"Applied "
operator|+
name|editsCount
operator|+
literal|", skipped "
operator|+
name|skippedEdits
operator|+
literal|", firstSequenceIdInLog="
operator|+
name|firstSeqIdInLog
operator|+
literal|", maxSequenceIdInLog="
operator|+
name|currentEditSeqId
operator|+
literal|", path="
operator|+
name|edits
expr_stmt|;
name|status
operator|.
name|markComplete
argument_list|(
name|msg
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
name|msg
argument_list|)
expr_stmt|;
return|return
name|currentEditSeqId
return|;
block|}
finally|finally
block|{
name|status
operator|.
name|cleanup
argument_list|()
expr_stmt|;
if|if
condition|(
name|reader
operator|!=
literal|null
condition|)
block|{
name|reader
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
block|}
block|}
comment|/**    * Call to complete a compaction. Its for the case where we find in the WAL a compaction    * that was not finished.  We could find one recovering a WAL after a regionserver crash.    * See HBASE-2331.    */
name|void
name|replayWALCompactionMarker
parameter_list|(
name|CompactionDescriptor
name|compaction
parameter_list|,
name|boolean
name|pickCompactionFiles
parameter_list|,
name|boolean
name|removeFiles
parameter_list|,
name|long
name|replaySeqId
parameter_list|)
throws|throws
name|IOException
block|{
try|try
block|{
name|checkTargetRegion
argument_list|(
name|compaction
operator|.
name|getEncodedRegionName
argument_list|()
operator|.
name|toByteArray
argument_list|()
argument_list|,
literal|"Compaction marker from WAL "
argument_list|,
name|compaction
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|WrongRegionException
name|wre
parameter_list|)
block|{
if|if
condition|(
name|RegionReplicaUtil
operator|.
name|isDefaultReplica
argument_list|(
name|this
operator|.
name|getRegionInfo
argument_list|()
argument_list|)
condition|)
block|{
comment|// skip the compaction marker since it is not for this region
return|return;
block|}
throw|throw
name|wre
throw|;
block|}
synchronized|synchronized
init|(
name|writestate
init|)
block|{
if|if
condition|(
name|replaySeqId
operator|<
name|lastReplayedOpenRegionSeqId
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
name|getRegionInfo
argument_list|()
operator|.
name|getEncodedName
argument_list|()
operator|+
literal|" : "
operator|+
literal|"Skipping replaying compaction event :"
operator|+
name|TextFormat
operator|.
name|shortDebugString
argument_list|(
name|compaction
argument_list|)
operator|+
literal|" because its sequence id "
operator|+
name|replaySeqId
operator|+
literal|" is smaller than this regions "
operator|+
literal|"lastReplayedOpenRegionSeqId of "
operator|+
name|lastReplayedOpenRegionSeqId
argument_list|)
expr_stmt|;
return|return;
block|}
if|if
condition|(
name|replaySeqId
operator|<
name|lastReplayedCompactionSeqId
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
name|getRegionInfo
argument_list|()
operator|.
name|getEncodedName
argument_list|()
operator|+
literal|" : "
operator|+
literal|"Skipping replaying compaction event :"
operator|+
name|TextFormat
operator|.
name|shortDebugString
argument_list|(
name|compaction
argument_list|)
operator|+
literal|" because its sequence id "
operator|+
name|replaySeqId
operator|+
literal|" is smaller than this regions "
operator|+
literal|"lastReplayedCompactionSeqId of "
operator|+
name|lastReplayedCompactionSeqId
argument_list|)
expr_stmt|;
return|return;
block|}
else|else
block|{
name|lastReplayedCompactionSeqId
operator|=
name|replaySeqId
expr_stmt|;
block|}
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
name|getRegionInfo
argument_list|()
operator|.
name|getEncodedName
argument_list|()
operator|+
literal|" : "
operator|+
literal|"Replaying compaction marker "
operator|+
name|TextFormat
operator|.
name|shortDebugString
argument_list|(
name|compaction
argument_list|)
operator|+
literal|" with seqId="
operator|+
name|replaySeqId
operator|+
literal|" and lastReplayedOpenRegionSeqId="
operator|+
name|lastReplayedOpenRegionSeqId
argument_list|)
expr_stmt|;
block|}
name|startRegionOperation
argument_list|(
name|Operation
operator|.
name|REPLAY_EVENT
argument_list|)
expr_stmt|;
try|try
block|{
name|HStore
name|store
init|=
name|this
operator|.
name|getStore
argument_list|(
name|compaction
operator|.
name|getFamilyName
argument_list|()
operator|.
name|toByteArray
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|store
operator|==
literal|null
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
name|getRegionInfo
argument_list|()
operator|.
name|getEncodedName
argument_list|()
operator|+
literal|" : "
operator|+
literal|"Found Compaction WAL edit for deleted family:"
operator|+
name|Bytes
operator|.
name|toString
argument_list|(
name|compaction
operator|.
name|getFamilyName
argument_list|()
operator|.
name|toByteArray
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
return|return;
block|}
name|store
operator|.
name|replayCompactionMarker
argument_list|(
name|compaction
argument_list|,
name|pickCompactionFiles
argument_list|,
name|removeFiles
argument_list|)
expr_stmt|;
name|logRegionFiles
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|FileNotFoundException
name|ex
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
name|getRegionInfo
argument_list|()
operator|.
name|getEncodedName
argument_list|()
operator|+
literal|" : "
operator|+
literal|"At least one of the store files in compaction: "
operator|+
name|TextFormat
operator|.
name|shortDebugString
argument_list|(
name|compaction
argument_list|)
operator|+
literal|" doesn't exist any more. Skip loading the file(s)"
argument_list|,
name|ex
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|closeRegionOperation
argument_list|(
name|Operation
operator|.
name|REPLAY_EVENT
argument_list|)
expr_stmt|;
block|}
block|}
block|}
name|void
name|replayWALFlushMarker
parameter_list|(
name|FlushDescriptor
name|flush
parameter_list|,
name|long
name|replaySeqId
parameter_list|)
throws|throws
name|IOException
block|{
name|checkTargetRegion
argument_list|(
name|flush
operator|.
name|getEncodedRegionName
argument_list|()
operator|.
name|toByteArray
argument_list|()
argument_list|,
literal|"Flush marker from WAL "
argument_list|,
name|flush
argument_list|)
expr_stmt|;
if|if
condition|(
name|ServerRegionReplicaUtil
operator|.
name|isDefaultReplica
argument_list|(
name|this
operator|.
name|getRegionInfo
argument_list|()
argument_list|)
condition|)
block|{
return|return;
comment|// if primary nothing to do
block|}
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
name|getRegionInfo
argument_list|()
operator|.
name|getEncodedName
argument_list|()
operator|+
literal|" : "
operator|+
literal|"Replaying flush marker "
operator|+
name|TextFormat
operator|.
name|shortDebugString
argument_list|(
name|flush
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|startRegionOperation
argument_list|(
name|Operation
operator|.
name|REPLAY_EVENT
argument_list|)
expr_stmt|;
comment|// use region close lock to guard against close
try|try
block|{
name|FlushAction
name|action
init|=
name|flush
operator|.
name|getAction
argument_list|()
decl_stmt|;
switch|switch
condition|(
name|action
condition|)
block|{
case|case
name|START_FLUSH
case|:
name|replayWALFlushStartMarker
argument_list|(
name|flush
argument_list|)
expr_stmt|;
break|break;
case|case
name|COMMIT_FLUSH
case|:
name|replayWALFlushCommitMarker
argument_list|(
name|flush
argument_list|)
expr_stmt|;
break|break;
case|case
name|ABORT_FLUSH
case|:
name|replayWALFlushAbortMarker
argument_list|(
name|flush
argument_list|)
expr_stmt|;
break|break;
case|case
name|CANNOT_FLUSH
case|:
name|replayWALFlushCannotFlushMarker
argument_list|(
name|flush
argument_list|,
name|replaySeqId
argument_list|)
expr_stmt|;
break|break;
default|default:
name|LOG
operator|.
name|warn
argument_list|(
name|getRegionInfo
argument_list|()
operator|.
name|getEncodedName
argument_list|()
operator|+
literal|" : "
operator|+
literal|"Received a flush event with unknown action, ignoring. "
operator|+
name|TextFormat
operator|.
name|shortDebugString
argument_list|(
name|flush
argument_list|)
argument_list|)
expr_stmt|;
break|break;
block|}
name|logRegionFiles
argument_list|()
expr_stmt|;
block|}
finally|finally
block|{
name|closeRegionOperation
argument_list|(
name|Operation
operator|.
name|REPLAY_EVENT
argument_list|)
expr_stmt|;
block|}
block|}
comment|/** Replay the flush marker from primary region by creating a corresponding snapshot of    * the store memstores, only if the memstores do not have a higher seqId from an earlier wal    * edit (because the events may be coming out of order).    */
annotation|@
name|VisibleForTesting
name|PrepareFlushResult
name|replayWALFlushStartMarker
parameter_list|(
name|FlushDescriptor
name|flush
parameter_list|)
throws|throws
name|IOException
block|{
name|long
name|flushSeqId
init|=
name|flush
operator|.
name|getFlushSequenceNumber
argument_list|()
decl_stmt|;
name|HashSet
argument_list|<
name|HStore
argument_list|>
name|storesToFlush
init|=
operator|new
name|HashSet
argument_list|<>
argument_list|()
decl_stmt|;
for|for
control|(
name|StoreFlushDescriptor
name|storeFlush
range|:
name|flush
operator|.
name|getStoreFlushesList
argument_list|()
control|)
block|{
name|byte
index|[]
name|family
init|=
name|storeFlush
operator|.
name|getFamilyName
argument_list|()
operator|.
name|toByteArray
argument_list|()
decl_stmt|;
name|HStore
name|store
init|=
name|getStore
argument_list|(
name|family
argument_list|)
decl_stmt|;
if|if
condition|(
name|store
operator|==
literal|null
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
name|getRegionInfo
argument_list|()
operator|.
name|getEncodedName
argument_list|()
operator|+
literal|" : "
operator|+
literal|"Received a flush start marker from primary, but the family is not found. Ignoring"
operator|+
literal|" StoreFlushDescriptor:"
operator|+
name|TextFormat
operator|.
name|shortDebugString
argument_list|(
name|storeFlush
argument_list|)
argument_list|)
expr_stmt|;
continue|continue;
block|}
name|storesToFlush
operator|.
name|add
argument_list|(
name|store
argument_list|)
expr_stmt|;
block|}
name|MonitoredTask
name|status
init|=
name|TaskMonitor
operator|.
name|get
argument_list|()
operator|.
name|createStatus
argument_list|(
literal|"Preparing flush "
operator|+
name|this
argument_list|)
decl_stmt|;
comment|// we will use writestate as a coarse-grain lock for all the replay events
comment|// (flush, compaction, region open etc)
synchronized|synchronized
init|(
name|writestate
init|)
block|{
try|try
block|{
if|if
condition|(
name|flush
operator|.
name|getFlushSequenceNumber
argument_list|()
operator|<
name|lastReplayedOpenRegionSeqId
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
name|getRegionInfo
argument_list|()
operator|.
name|getEncodedName
argument_list|()
operator|+
literal|" : "
operator|+
literal|"Skipping replaying flush event :"
operator|+
name|TextFormat
operator|.
name|shortDebugString
argument_list|(
name|flush
argument_list|)
operator|+
literal|" because its sequence id is smaller than this regions lastReplayedOpenRegionSeqId "
operator|+
literal|" of "
operator|+
name|lastReplayedOpenRegionSeqId
argument_list|)
expr_stmt|;
return|return
literal|null
return|;
block|}
if|if
condition|(
name|numMutationsWithoutWAL
operator|.
name|sum
argument_list|()
operator|>
literal|0
condition|)
block|{
name|numMutationsWithoutWAL
operator|.
name|reset
argument_list|()
expr_stmt|;
name|dataInMemoryWithoutWAL
operator|.
name|reset
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
operator|!
name|writestate
operator|.
name|flushing
condition|)
block|{
comment|// we do not have an active snapshot and corresponding this.prepareResult. This means
comment|// we can just snapshot our memstores and continue as normal.
comment|// invoke prepareFlushCache. Send null as wal since we do not want the flush events in wal
name|PrepareFlushResult
name|prepareResult
init|=
name|internalPrepareFlushCache
argument_list|(
literal|null
argument_list|,
name|flushSeqId
argument_list|,
name|storesToFlush
argument_list|,
name|status
argument_list|,
literal|false
argument_list|,
name|FlushLifeCycleTracker
operator|.
name|DUMMY
argument_list|)
decl_stmt|;
if|if
condition|(
name|prepareResult
operator|.
name|result
operator|==
literal|null
condition|)
block|{
comment|// save the PrepareFlushResult so that we can use it later from commit flush
name|this
operator|.
name|writestate
operator|.
name|flushing
operator|=
literal|true
expr_stmt|;
name|this
operator|.
name|prepareFlushResult
operator|=
name|prepareResult
expr_stmt|;
name|status
operator|.
name|markComplete
argument_list|(
literal|"Flush prepare successful"
argument_list|)
expr_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
name|getRegionInfo
argument_list|()
operator|.
name|getEncodedName
argument_list|()
operator|+
literal|" : "
operator|+
literal|" Prepared flush with seqId:"
operator|+
name|flush
operator|.
name|getFlushSequenceNumber
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
comment|// special case empty memstore. We will still save the flush result in this case, since
comment|// our memstore ie empty, but the primary is still flushing
if|if
condition|(
name|prepareResult
operator|.
name|getResult
argument_list|()
operator|.
name|getResult
argument_list|()
operator|==
name|FlushResult
operator|.
name|Result
operator|.
name|CANNOT_FLUSH_MEMSTORE_EMPTY
condition|)
block|{
name|this
operator|.
name|writestate
operator|.
name|flushing
operator|=
literal|true
expr_stmt|;
name|this
operator|.
name|prepareFlushResult
operator|=
name|prepareResult
expr_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
name|getRegionInfo
argument_list|()
operator|.
name|getEncodedName
argument_list|()
operator|+
literal|" : "
operator|+
literal|" Prepared empty flush with seqId:"
operator|+
name|flush
operator|.
name|getFlushSequenceNumber
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
name|status
operator|.
name|abort
argument_list|(
literal|"Flush prepare failed with "
operator|+
name|prepareResult
operator|.
name|result
argument_list|)
expr_stmt|;
comment|// nothing much to do. prepare flush failed because of some reason.
block|}
return|return
name|prepareResult
return|;
block|}
else|else
block|{
comment|// we already have an active snapshot.
if|if
condition|(
name|flush
operator|.
name|getFlushSequenceNumber
argument_list|()
operator|==
name|this
operator|.
name|prepareFlushResult
operator|.
name|flushOpSeqId
condition|)
block|{
comment|// They define the same flush. Log and continue.
name|LOG
operator|.
name|warn
argument_list|(
name|getRegionInfo
argument_list|()
operator|.
name|getEncodedName
argument_list|()
operator|+
literal|" : "
operator|+
literal|"Received a flush prepare marker with the same seqId: "
operator|+
operator|+
name|flush
operator|.
name|getFlushSequenceNumber
argument_list|()
operator|+
literal|" before clearing the previous one with seqId: "
operator|+
name|prepareFlushResult
operator|.
name|flushOpSeqId
operator|+
literal|". Ignoring"
argument_list|)
expr_stmt|;
comment|// ignore
block|}
elseif|else
if|if
condition|(
name|flush
operator|.
name|getFlushSequenceNumber
argument_list|()
operator|<
name|this
operator|.
name|prepareFlushResult
operator|.
name|flushOpSeqId
condition|)
block|{
comment|// We received a flush with a smaller seqNum than what we have prepared. We can only
comment|// ignore this prepare flush request.
name|LOG
operator|.
name|warn
argument_list|(
name|getRegionInfo
argument_list|()
operator|.
name|getEncodedName
argument_list|()
operator|+
literal|" : "
operator|+
literal|"Received a flush prepare marker with a smaller seqId: "
operator|+
operator|+
name|flush
operator|.
name|getFlushSequenceNumber
argument_list|()
operator|+
literal|" before clearing the previous one with seqId: "
operator|+
name|prepareFlushResult
operator|.
name|flushOpSeqId
operator|+
literal|". Ignoring"
argument_list|)
expr_stmt|;
comment|// ignore
block|}
else|else
block|{
comment|// We received a flush with a larger seqNum than what we have prepared
name|LOG
operator|.
name|warn
argument_list|(
name|getRegionInfo
argument_list|()
operator|.
name|getEncodedName
argument_list|()
operator|+
literal|" : "
operator|+
literal|"Received a flush prepare marker with a larger seqId: "
operator|+
operator|+
name|flush
operator|.
name|getFlushSequenceNumber
argument_list|()
operator|+
literal|" before clearing the previous one with seqId: "
operator|+
name|prepareFlushResult
operator|.
name|flushOpSeqId
operator|+
literal|". Ignoring"
argument_list|)
expr_stmt|;
comment|// We do not have multiple active snapshots in the memstore or a way to merge current
comment|// memstore snapshot with the contents and resnapshot for now. We cannot take
comment|// another snapshot and drop the previous one because that will cause temporary
comment|// data loss in the secondary. So we ignore this for now, deferring the resolution
comment|// to happen when we see the corresponding flush commit marker. If we have a memstore
comment|// snapshot with x, and later received another prepare snapshot with y (where x< y),
comment|// when we see flush commit for y, we will drop snapshot for x, and can also drop all
comment|// the memstore edits if everything in memstore is< y. This is the usual case for
comment|// RS crash + recovery where we might see consequtive prepare flush wal markers.
comment|// Otherwise, this will cause more memory to be used in secondary replica until a
comment|// further prapare + commit flush is seen and replayed.
block|}
block|}
block|}
finally|finally
block|{
name|status
operator|.
name|cleanup
argument_list|()
expr_stmt|;
name|writestate
operator|.
name|notifyAll
argument_list|()
expr_stmt|;
block|}
block|}
return|return
literal|null
return|;
block|}
annotation|@
name|VisibleForTesting
annotation|@
name|edu
operator|.
name|umd
operator|.
name|cs
operator|.
name|findbugs
operator|.
name|annotations
operator|.
name|SuppressWarnings
argument_list|(
name|value
operator|=
literal|"NN_NAKED_NOTIFY"
argument_list|,
name|justification
operator|=
literal|"Intentional; post memstore flush"
argument_list|)
name|void
name|replayWALFlushCommitMarker
parameter_list|(
name|FlushDescriptor
name|flush
parameter_list|)
throws|throws
name|IOException
block|{
name|MonitoredTask
name|status
init|=
name|TaskMonitor
operator|.
name|get
argument_list|()
operator|.
name|createStatus
argument_list|(
literal|"Committing flush "
operator|+
name|this
argument_list|)
decl_stmt|;
comment|// check whether we have the memstore snapshot with the corresponding seqId. Replay to
comment|// secondary region replicas are in order, except for when the region moves or then the
comment|// region server crashes. In those cases, we may receive replay requests out of order from
comment|// the original seqIds.
synchronized|synchronized
init|(
name|writestate
init|)
block|{
try|try
block|{
if|if
condition|(
name|flush
operator|.
name|getFlushSequenceNumber
argument_list|()
operator|<
name|lastReplayedOpenRegionSeqId
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
name|getRegionInfo
argument_list|()
operator|.
name|getEncodedName
argument_list|()
operator|+
literal|" : "
operator|+
literal|"Skipping replaying flush event :"
operator|+
name|TextFormat
operator|.
name|shortDebugString
argument_list|(
name|flush
argument_list|)
operator|+
literal|" because its sequence id is smaller than this regions lastReplayedOpenRegionSeqId "
operator|+
literal|" of "
operator|+
name|lastReplayedOpenRegionSeqId
argument_list|)
expr_stmt|;
return|return;
block|}
if|if
condition|(
name|writestate
operator|.
name|flushing
condition|)
block|{
name|PrepareFlushResult
name|prepareFlushResult
init|=
name|this
operator|.
name|prepareFlushResult
decl_stmt|;
if|if
condition|(
name|flush
operator|.
name|getFlushSequenceNumber
argument_list|()
operator|==
name|prepareFlushResult
operator|.
name|flushOpSeqId
condition|)
block|{
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
name|getRegionInfo
argument_list|()
operator|.
name|getEncodedName
argument_list|()
operator|+
literal|" : "
operator|+
literal|"Received a flush commit marker with seqId:"
operator|+
name|flush
operator|.
name|getFlushSequenceNumber
argument_list|()
operator|+
literal|" and a previous prepared snapshot was found"
argument_list|)
expr_stmt|;
block|}
comment|// This is the regular case where we received commit flush after prepare flush
comment|// corresponding to the same seqId.
name|replayFlushInStores
argument_list|(
name|flush
argument_list|,
name|prepareFlushResult
argument_list|,
literal|true
argument_list|)
expr_stmt|;
comment|// Set down the memstore size by amount of flush.
name|this
operator|.
name|decrMemStoreSize
argument_list|(
name|prepareFlushResult
operator|.
name|totalFlushableSize
operator|.
name|getMemStoreSize
argument_list|()
argument_list|)
expr_stmt|;
name|this
operator|.
name|prepareFlushResult
operator|=
literal|null
expr_stmt|;
name|writestate
operator|.
name|flushing
operator|=
literal|false
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|flush
operator|.
name|getFlushSequenceNumber
argument_list|()
operator|<
name|prepareFlushResult
operator|.
name|flushOpSeqId
condition|)
block|{
comment|// This should not happen normally. However, lets be safe and guard against these cases
comment|// we received a flush commit with a smaller seqId than what we have prepared
comment|// we will pick the flush file up from this commit (if we have not seen it), but we
comment|// will not drop the memstore
name|LOG
operator|.
name|warn
argument_list|(
name|getRegionInfo
argument_list|()
operator|.
name|getEncodedName
argument_list|()
operator|+
literal|" : "
operator|+
literal|"Received a flush commit marker with smaller seqId: "
operator|+
name|flush
operator|.
name|getFlushSequenceNumber
argument_list|()
operator|+
literal|" than what we have prepared with seqId: "
operator|+
name|prepareFlushResult
operator|.
name|flushOpSeqId
operator|+
literal|". Picking up new file, but not dropping"
operator|+
literal|"  prepared memstore snapshot"
argument_list|)
expr_stmt|;
name|replayFlushInStores
argument_list|(
name|flush
argument_list|,
name|prepareFlushResult
argument_list|,
literal|false
argument_list|)
expr_stmt|;
comment|// snapshot is not dropped, so memstore sizes should not be decremented
comment|// we still have the prepared snapshot, flushing should still be true
block|}
else|else
block|{
comment|// This should not happen normally. However, lets be safe and guard against these cases
comment|// we received a flush commit with a larger seqId than what we have prepared
comment|// we will pick the flush file for this. We will also obtain the updates lock and
comment|// look for contents of the memstore to see whether we have edits after this seqId.
comment|// If not, we will drop all the memstore edits and the snapshot as well.
name|LOG
operator|.
name|warn
argument_list|(
name|getRegionInfo
argument_list|()
operator|.
name|getEncodedName
argument_list|()
operator|+
literal|" : "
operator|+
literal|"Received a flush commit marker with larger seqId: "
operator|+
name|flush
operator|.
name|getFlushSequenceNumber
argument_list|()
operator|+
literal|" than what we have prepared with seqId: "
operator|+
name|prepareFlushResult
operator|.
name|flushOpSeqId
operator|+
literal|". Picking up new file and dropping prepared"
operator|+
literal|" memstore snapshot"
argument_list|)
expr_stmt|;
name|replayFlushInStores
argument_list|(
name|flush
argument_list|,
name|prepareFlushResult
argument_list|,
literal|true
argument_list|)
expr_stmt|;
comment|// Set down the memstore size by amount of flush.
name|this
operator|.
name|decrMemStoreSize
argument_list|(
name|prepareFlushResult
operator|.
name|totalFlushableSize
operator|.
name|getMemStoreSize
argument_list|()
argument_list|)
expr_stmt|;
comment|// Inspect the memstore contents to see whether the memstore contains only edits
comment|// with seqId smaller than the flush seqId. If so, we can discard those edits.
name|dropMemStoreContentsForSeqId
argument_list|(
name|flush
operator|.
name|getFlushSequenceNumber
argument_list|()
argument_list|,
literal|null
argument_list|)
expr_stmt|;
name|this
operator|.
name|prepareFlushResult
operator|=
literal|null
expr_stmt|;
name|writestate
operator|.
name|flushing
operator|=
literal|false
expr_stmt|;
block|}
comment|// If we were waiting for observing a flush or region opening event for not showing
comment|// partial data after a secondary region crash, we can allow reads now. We can only make
comment|// sure that we are not showing partial data (for example skipping some previous edits)
comment|// until we observe a full flush start and flush commit. So if we were not able to find
comment|// a previous flush we will not enable reads now.
name|this
operator|.
name|setReadsEnabled
argument_list|(
literal|true
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|LOG
operator|.
name|warn
argument_list|(
name|getRegionInfo
argument_list|()
operator|.
name|getEncodedName
argument_list|()
operator|+
literal|" : "
operator|+
literal|"Received a flush commit marker with seqId:"
operator|+
name|flush
operator|.
name|getFlushSequenceNumber
argument_list|()
operator|+
literal|", but no previous prepared snapshot was found"
argument_list|)
expr_stmt|;
comment|// There is no corresponding prepare snapshot from before.
comment|// We will pick up the new flushed file
name|replayFlushInStores
argument_list|(
name|flush
argument_list|,
literal|null
argument_list|,
literal|false
argument_list|)
expr_stmt|;
comment|// Inspect the memstore contents to see whether the memstore contains only edits
comment|// with seqId smaller than the flush seqId. If so, we can discard those edits.
name|dropMemStoreContentsForSeqId
argument_list|(
name|flush
operator|.
name|getFlushSequenceNumber
argument_list|()
argument_list|,
literal|null
argument_list|)
expr_stmt|;
block|}
name|status
operator|.
name|markComplete
argument_list|(
literal|"Flush commit successful"
argument_list|)
expr_stmt|;
comment|// Update the last flushed sequence id for region.
name|this
operator|.
name|maxFlushedSeqId
operator|=
name|flush
operator|.
name|getFlushSequenceNumber
argument_list|()
expr_stmt|;
comment|// advance the mvcc read point so that the new flushed file is visible.
name|mvcc
operator|.
name|advanceTo
argument_list|(
name|flush
operator|.
name|getFlushSequenceNumber
argument_list|()
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|FileNotFoundException
name|ex
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
name|getRegionInfo
argument_list|()
operator|.
name|getEncodedName
argument_list|()
operator|+
literal|" : "
operator|+
literal|"At least one of the store files in flush: "
operator|+
name|TextFormat
operator|.
name|shortDebugString
argument_list|(
name|flush
argument_list|)
operator|+
literal|" doesn't exist any more. Skip loading the file(s)"
argument_list|,
name|ex
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|status
operator|.
name|cleanup
argument_list|()
expr_stmt|;
name|writestate
operator|.
name|notifyAll
argument_list|()
expr_stmt|;
block|}
block|}
comment|// C. Finally notify anyone waiting on memstore to clear:
comment|// e.g. checkResources().
synchronized|synchronized
init|(
name|this
init|)
block|{
name|notifyAll
argument_list|()
expr_stmt|;
comment|// FindBugs NN_NAKED_NOTIFY
block|}
block|}
comment|/**    * Replays the given flush descriptor by opening the flush files in stores and dropping the    * memstore snapshots if requested.    * @param flush    * @param prepareFlushResult    * @param dropMemstoreSnapshot    * @throws IOException    */
specifier|private
name|void
name|replayFlushInStores
parameter_list|(
name|FlushDescriptor
name|flush
parameter_list|,
name|PrepareFlushResult
name|prepareFlushResult
parameter_list|,
name|boolean
name|dropMemstoreSnapshot
parameter_list|)
throws|throws
name|IOException
block|{
for|for
control|(
name|StoreFlushDescriptor
name|storeFlush
range|:
name|flush
operator|.
name|getStoreFlushesList
argument_list|()
control|)
block|{
name|byte
index|[]
name|family
init|=
name|storeFlush
operator|.
name|getFamilyName
argument_list|()
operator|.
name|toByteArray
argument_list|()
decl_stmt|;
name|HStore
name|store
init|=
name|getStore
argument_list|(
name|family
argument_list|)
decl_stmt|;
if|if
condition|(
name|store
operator|==
literal|null
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
name|getRegionInfo
argument_list|()
operator|.
name|getEncodedName
argument_list|()
operator|+
literal|" : "
operator|+
literal|"Received a flush commit marker from primary, but the family is not found."
operator|+
literal|"Ignoring StoreFlushDescriptor:"
operator|+
name|storeFlush
argument_list|)
expr_stmt|;
continue|continue;
block|}
name|List
argument_list|<
name|String
argument_list|>
name|flushFiles
init|=
name|storeFlush
operator|.
name|getFlushOutputList
argument_list|()
decl_stmt|;
name|StoreFlushContext
name|ctx
init|=
literal|null
decl_stmt|;
name|long
name|startTime
init|=
name|EnvironmentEdgeManager
operator|.
name|currentTime
argument_list|()
decl_stmt|;
if|if
condition|(
name|prepareFlushResult
operator|==
literal|null
operator|||
name|prepareFlushResult
operator|.
name|storeFlushCtxs
operator|==
literal|null
condition|)
block|{
name|ctx
operator|=
name|store
operator|.
name|createFlushContext
argument_list|(
name|flush
operator|.
name|getFlushSequenceNumber
argument_list|()
argument_list|,
name|FlushLifeCycleTracker
operator|.
name|DUMMY
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|ctx
operator|=
name|prepareFlushResult
operator|.
name|storeFlushCtxs
operator|.
name|get
argument_list|(
name|family
argument_list|)
expr_stmt|;
name|startTime
operator|=
name|prepareFlushResult
operator|.
name|startTime
expr_stmt|;
block|}
if|if
condition|(
name|ctx
operator|==
literal|null
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
name|getRegionInfo
argument_list|()
operator|.
name|getEncodedName
argument_list|()
operator|+
literal|" : "
operator|+
literal|"Unexpected: flush commit marker received from store "
operator|+
name|Bytes
operator|.
name|toString
argument_list|(
name|family
argument_list|)
operator|+
literal|" but no associated flush context. Ignoring"
argument_list|)
expr_stmt|;
continue|continue;
block|}
name|ctx
operator|.
name|replayFlush
argument_list|(
name|flushFiles
argument_list|,
name|dropMemstoreSnapshot
argument_list|)
expr_stmt|;
comment|// replay the flush
comment|// Record latest flush time
name|this
operator|.
name|lastStoreFlushTimeMap
operator|.
name|put
argument_list|(
name|store
argument_list|,
name|startTime
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Drops the memstore contents after replaying a flush descriptor or region open event replay    * if the memstore edits have seqNums smaller than the given seq id    * @throws IOException    */
specifier|private
name|MemStoreSize
name|dropMemStoreContentsForSeqId
parameter_list|(
name|long
name|seqId
parameter_list|,
name|HStore
name|store
parameter_list|)
throws|throws
name|IOException
block|{
name|MemStoreSizing
name|totalFreedSize
init|=
operator|new
name|NonThreadSafeMemStoreSizing
argument_list|()
decl_stmt|;
name|this
operator|.
name|updatesLock
operator|.
name|writeLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
name|long
name|currentSeqId
init|=
name|mvcc
operator|.
name|getReadPoint
argument_list|()
decl_stmt|;
if|if
condition|(
name|seqId
operator|>=
name|currentSeqId
condition|)
block|{
comment|// then we can drop the memstore contents since everything is below this seqId
name|LOG
operator|.
name|info
argument_list|(
name|getRegionInfo
argument_list|()
operator|.
name|getEncodedName
argument_list|()
operator|+
literal|" : "
operator|+
literal|"Dropping memstore contents as well since replayed flush seqId: "
operator|+
name|seqId
operator|+
literal|" is greater than current seqId:"
operator|+
name|currentSeqId
argument_list|)
expr_stmt|;
comment|// Prepare flush (take a snapshot) and then abort (drop the snapshot)
if|if
condition|(
name|store
operator|==
literal|null
condition|)
block|{
for|for
control|(
name|HStore
name|s
range|:
name|stores
operator|.
name|values
argument_list|()
control|)
block|{
name|totalFreedSize
operator|.
name|incMemStoreSize
argument_list|(
name|doDropStoreMemStoreContentsForSeqId
argument_list|(
name|s
argument_list|,
name|currentSeqId
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
name|totalFreedSize
operator|.
name|incMemStoreSize
argument_list|(
name|doDropStoreMemStoreContentsForSeqId
argument_list|(
name|store
argument_list|,
name|currentSeqId
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
name|LOG
operator|.
name|info
argument_list|(
name|getRegionInfo
argument_list|()
operator|.
name|getEncodedName
argument_list|()
operator|+
literal|" : "
operator|+
literal|"Not dropping memstore contents since replayed flush seqId: "
operator|+
name|seqId
operator|+
literal|" is smaller than current seqId:"
operator|+
name|currentSeqId
argument_list|)
expr_stmt|;
block|}
block|}
finally|finally
block|{
name|this
operator|.
name|updatesLock
operator|.
name|writeLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
return|return
name|totalFreedSize
operator|.
name|getMemStoreSize
argument_list|()
return|;
block|}
specifier|private
name|MemStoreSize
name|doDropStoreMemStoreContentsForSeqId
parameter_list|(
name|HStore
name|s
parameter_list|,
name|long
name|currentSeqId
parameter_list|)
throws|throws
name|IOException
block|{
name|MemStoreSize
name|flushableSize
init|=
name|s
operator|.
name|getFlushableSize
argument_list|()
decl_stmt|;
name|this
operator|.
name|decrMemStoreSize
argument_list|(
name|flushableSize
argument_list|)
expr_stmt|;
name|StoreFlushContext
name|ctx
init|=
name|s
operator|.
name|createFlushContext
argument_list|(
name|currentSeqId
argument_list|,
name|FlushLifeCycleTracker
operator|.
name|DUMMY
argument_list|)
decl_stmt|;
name|ctx
operator|.
name|prepare
argument_list|()
expr_stmt|;
name|ctx
operator|.
name|abort
argument_list|()
expr_stmt|;
return|return
name|flushableSize
return|;
block|}
specifier|private
name|void
name|replayWALFlushAbortMarker
parameter_list|(
name|FlushDescriptor
name|flush
parameter_list|)
block|{
comment|// nothing to do for now. A flush abort will cause a RS abort which means that the region
comment|// will be opened somewhere else later. We will see the region open event soon, and replaying
comment|// that will drop the snapshot
block|}
specifier|private
name|void
name|replayWALFlushCannotFlushMarker
parameter_list|(
name|FlushDescriptor
name|flush
parameter_list|,
name|long
name|replaySeqId
parameter_list|)
block|{
synchronized|synchronized
init|(
name|writestate
init|)
block|{
if|if
condition|(
name|this
operator|.
name|lastReplayedOpenRegionSeqId
operator|>
name|replaySeqId
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
name|getRegionInfo
argument_list|()
operator|.
name|getEncodedName
argument_list|()
operator|+
literal|" : "
operator|+
literal|"Skipping replaying flush event :"
operator|+
name|TextFormat
operator|.
name|shortDebugString
argument_list|(
name|flush
argument_list|)
operator|+
literal|" because its sequence id "
operator|+
name|replaySeqId
operator|+
literal|" is smaller than this regions "
operator|+
literal|"lastReplayedOpenRegionSeqId of "
operator|+
name|lastReplayedOpenRegionSeqId
argument_list|)
expr_stmt|;
return|return;
block|}
comment|// If we were waiting for observing a flush or region opening event for not showing partial
comment|// data after a secondary region crash, we can allow reads now. This event means that the
comment|// primary was not able to flush because memstore is empty when we requested flush. By the
comment|// time we observe this, we are guaranteed to have up to date seqId with our previous
comment|// assignment.
name|this
operator|.
name|setReadsEnabled
argument_list|(
literal|true
argument_list|)
expr_stmt|;
block|}
block|}
annotation|@
name|VisibleForTesting
name|PrepareFlushResult
name|getPrepareFlushResult
parameter_list|()
block|{
return|return
name|prepareFlushResult
return|;
block|}
annotation|@
name|edu
operator|.
name|umd
operator|.
name|cs
operator|.
name|findbugs
operator|.
name|annotations
operator|.
name|SuppressWarnings
argument_list|(
name|value
operator|=
literal|"NN_NAKED_NOTIFY"
argument_list|,
name|justification
operator|=
literal|"Intentional; cleared the memstore"
argument_list|)
name|void
name|replayWALRegionEventMarker
parameter_list|(
name|RegionEventDescriptor
name|regionEvent
parameter_list|)
throws|throws
name|IOException
block|{
name|checkTargetRegion
argument_list|(
name|regionEvent
operator|.
name|getEncodedRegionName
argument_list|()
operator|.
name|toByteArray
argument_list|()
argument_list|,
literal|"RegionEvent marker from WAL "
argument_list|,
name|regionEvent
argument_list|)
expr_stmt|;
name|startRegionOperation
argument_list|(
name|Operation
operator|.
name|REPLAY_EVENT
argument_list|)
expr_stmt|;
try|try
block|{
if|if
condition|(
name|ServerRegionReplicaUtil
operator|.
name|isDefaultReplica
argument_list|(
name|this
operator|.
name|getRegionInfo
argument_list|()
argument_list|)
condition|)
block|{
return|return;
comment|// if primary nothing to do
block|}
if|if
condition|(
name|regionEvent
operator|.
name|getEventType
argument_list|()
operator|==
name|EventType
operator|.
name|REGION_CLOSE
condition|)
block|{
comment|// nothing to do on REGION_CLOSE for now.
return|return;
block|}
if|if
condition|(
name|regionEvent
operator|.
name|getEventType
argument_list|()
operator|!=
name|EventType
operator|.
name|REGION_OPEN
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
name|getRegionInfo
argument_list|()
operator|.
name|getEncodedName
argument_list|()
operator|+
literal|" : "
operator|+
literal|"Unknown region event received, ignoring :"
operator|+
name|TextFormat
operator|.
name|shortDebugString
argument_list|(
name|regionEvent
argument_list|)
argument_list|)
expr_stmt|;
return|return;
block|}
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
name|getRegionInfo
argument_list|()
operator|.
name|getEncodedName
argument_list|()
operator|+
literal|" : "
operator|+
literal|"Replaying region open event marker "
operator|+
name|TextFormat
operator|.
name|shortDebugString
argument_list|(
name|regionEvent
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|// we will use writestate as a coarse-grain lock for all the replay events
synchronized|synchronized
init|(
name|writestate
init|)
block|{
comment|// Replication can deliver events out of order when primary region moves or the region
comment|// server crashes, since there is no coordination between replication of different wal files
comment|// belonging to different region servers. We have to safe guard against this case by using
comment|// region open event's seqid. Since this is the first event that the region puts (after
comment|// possibly flushing recovered.edits), after seeing this event, we can ignore every edit
comment|// smaller than this seqId
if|if
condition|(
name|this
operator|.
name|lastReplayedOpenRegionSeqId
operator|<=
name|regionEvent
operator|.
name|getLogSequenceNumber
argument_list|()
condition|)
block|{
name|this
operator|.
name|lastReplayedOpenRegionSeqId
operator|=
name|regionEvent
operator|.
name|getLogSequenceNumber
argument_list|()
expr_stmt|;
block|}
else|else
block|{
name|LOG
operator|.
name|warn
argument_list|(
name|getRegionInfo
argument_list|()
operator|.
name|getEncodedName
argument_list|()
operator|+
literal|" : "
operator|+
literal|"Skipping replaying region event :"
operator|+
name|TextFormat
operator|.
name|shortDebugString
argument_list|(
name|regionEvent
argument_list|)
operator|+
literal|" because its sequence id is smaller than this regions lastReplayedOpenRegionSeqId "
operator|+
literal|" of "
operator|+
name|lastReplayedOpenRegionSeqId
argument_list|)
expr_stmt|;
return|return;
block|}
comment|// region open lists all the files that the region has at the time of the opening. Just pick
comment|// all the files and drop prepared flushes and empty memstores
for|for
control|(
name|StoreDescriptor
name|storeDescriptor
range|:
name|regionEvent
operator|.
name|getStoresList
argument_list|()
control|)
block|{
comment|// stores of primary may be different now
name|byte
index|[]
name|family
init|=
name|storeDescriptor
operator|.
name|getFamilyName
argument_list|()
operator|.
name|toByteArray
argument_list|()
decl_stmt|;
name|HStore
name|store
init|=
name|getStore
argument_list|(
name|family
argument_list|)
decl_stmt|;
if|if
condition|(
name|store
operator|==
literal|null
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
name|getRegionInfo
argument_list|()
operator|.
name|getEncodedName
argument_list|()
operator|+
literal|" : "
operator|+
literal|"Received a region open marker from primary, but the family is not found. "
operator|+
literal|"Ignoring. StoreDescriptor:"
operator|+
name|storeDescriptor
argument_list|)
expr_stmt|;
continue|continue;
block|}
name|long
name|storeSeqId
init|=
name|store
operator|.
name|getMaxSequenceId
argument_list|()
operator|.
name|orElse
argument_list|(
literal|0L
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|String
argument_list|>
name|storeFiles
init|=
name|storeDescriptor
operator|.
name|getStoreFileList
argument_list|()
decl_stmt|;
try|try
block|{
name|store
operator|.
name|refreshStoreFiles
argument_list|(
name|storeFiles
argument_list|)
expr_stmt|;
comment|// replace the files with the new ones
block|}
catch|catch
parameter_list|(
name|FileNotFoundException
name|ex
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
name|getRegionInfo
argument_list|()
operator|.
name|getEncodedName
argument_list|()
operator|+
literal|" : "
operator|+
literal|"At least one of the store files: "
operator|+
name|storeFiles
operator|+
literal|" doesn't exist any more. Skip loading the file(s)"
argument_list|,
name|ex
argument_list|)
expr_stmt|;
continue|continue;
block|}
if|if
condition|(
name|store
operator|.
name|getMaxSequenceId
argument_list|()
operator|.
name|orElse
argument_list|(
literal|0L
argument_list|)
operator|!=
name|storeSeqId
condition|)
block|{
comment|// Record latest flush time if we picked up new files
name|lastStoreFlushTimeMap
operator|.
name|put
argument_list|(
name|store
argument_list|,
name|EnvironmentEdgeManager
operator|.
name|currentTime
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|writestate
operator|.
name|flushing
condition|)
block|{
comment|// only drop memstore snapshots if they are smaller than last flush for the store
if|if
condition|(
name|this
operator|.
name|prepareFlushResult
operator|.
name|flushOpSeqId
operator|<=
name|regionEvent
operator|.
name|getLogSequenceNumber
argument_list|()
condition|)
block|{
name|StoreFlushContext
name|ctx
init|=
name|this
operator|.
name|prepareFlushResult
operator|.
name|storeFlushCtxs
operator|==
literal|null
condition|?
literal|null
else|:
name|this
operator|.
name|prepareFlushResult
operator|.
name|storeFlushCtxs
operator|.
name|get
argument_list|(
name|family
argument_list|)
decl_stmt|;
if|if
condition|(
name|ctx
operator|!=
literal|null
condition|)
block|{
name|MemStoreSize
name|mss
init|=
name|store
operator|.
name|getFlushableSize
argument_list|()
decl_stmt|;
name|ctx
operator|.
name|abort
argument_list|()
expr_stmt|;
name|this
operator|.
name|decrMemStoreSize
argument_list|(
name|mss
argument_list|)
expr_stmt|;
name|this
operator|.
name|prepareFlushResult
operator|.
name|storeFlushCtxs
operator|.
name|remove
argument_list|(
name|family
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|// Drop the memstore contents if they are now smaller than the latest seen flushed file
name|dropMemStoreContentsForSeqId
argument_list|(
name|regionEvent
operator|.
name|getLogSequenceNumber
argument_list|()
argument_list|,
name|store
argument_list|)
expr_stmt|;
if|if
condition|(
name|storeSeqId
operator|>
name|this
operator|.
name|maxFlushedSeqId
condition|)
block|{
name|this
operator|.
name|maxFlushedSeqId
operator|=
name|storeSeqId
expr_stmt|;
block|}
block|}
comment|// if all stores ended up dropping their snapshots, we can safely drop the
comment|// prepareFlushResult
name|dropPrepareFlushIfPossible
argument_list|()
expr_stmt|;
comment|// advance the mvcc read point so that the new flushed file is visible.
name|mvcc
operator|.
name|await
argument_list|()
expr_stmt|;
comment|// If we were waiting for observing a flush or region opening event for not showing partial
comment|// data after a secondary region crash, we can allow reads now.
name|this
operator|.
name|setReadsEnabled
argument_list|(
literal|true
argument_list|)
expr_stmt|;
comment|// C. Finally notify anyone waiting on memstore to clear:
comment|// e.g. checkResources().
synchronized|synchronized
init|(
name|this
init|)
block|{
name|notifyAll
argument_list|()
expr_stmt|;
comment|// FindBugs NN_NAKED_NOTIFY
block|}
block|}
name|logRegionFiles
argument_list|()
expr_stmt|;
block|}
finally|finally
block|{
name|closeRegionOperation
argument_list|(
name|Operation
operator|.
name|REPLAY_EVENT
argument_list|)
expr_stmt|;
block|}
block|}
name|void
name|replayWALBulkLoadEventMarker
parameter_list|(
name|WALProtos
operator|.
name|BulkLoadDescriptor
name|bulkLoadEvent
parameter_list|)
throws|throws
name|IOException
block|{
name|checkTargetRegion
argument_list|(
name|bulkLoadEvent
operator|.
name|getEncodedRegionName
argument_list|()
operator|.
name|toByteArray
argument_list|()
argument_list|,
literal|"BulkLoad marker from WAL "
argument_list|,
name|bulkLoadEvent
argument_list|)
expr_stmt|;
if|if
condition|(
name|ServerRegionReplicaUtil
operator|.
name|isDefaultReplica
argument_list|(
name|this
operator|.
name|getRegionInfo
argument_list|()
argument_list|)
condition|)
block|{
return|return;
comment|// if primary nothing to do
block|}
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
name|getRegionInfo
argument_list|()
operator|.
name|getEncodedName
argument_list|()
operator|+
literal|" : "
operator|+
literal|"Replaying bulkload event marker "
operator|+
name|TextFormat
operator|.
name|shortDebugString
argument_list|(
name|bulkLoadEvent
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|// check if multiple families involved
name|boolean
name|multipleFamilies
init|=
literal|false
decl_stmt|;
name|byte
index|[]
name|family
init|=
literal|null
decl_stmt|;
for|for
control|(
name|StoreDescriptor
name|storeDescriptor
range|:
name|bulkLoadEvent
operator|.
name|getStoresList
argument_list|()
control|)
block|{
name|byte
index|[]
name|fam
init|=
name|storeDescriptor
operator|.
name|getFamilyName
argument_list|()
operator|.
name|toByteArray
argument_list|()
decl_stmt|;
if|if
condition|(
name|family
operator|==
literal|null
condition|)
block|{
name|family
operator|=
name|fam
expr_stmt|;
block|}
elseif|else
if|if
condition|(
operator|!
name|Bytes
operator|.
name|equals
argument_list|(
name|family
argument_list|,
name|fam
argument_list|)
condition|)
block|{
name|multipleFamilies
operator|=
literal|true
expr_stmt|;
break|break;
block|}
block|}
name|startBulkRegionOperation
argument_list|(
name|multipleFamilies
argument_list|)
expr_stmt|;
try|try
block|{
comment|// we will use writestate as a coarse-grain lock for all the replay events
synchronized|synchronized
init|(
name|writestate
init|)
block|{
comment|// Replication can deliver events out of order when primary region moves or the region
comment|// server crashes, since there is no coordination between replication of different wal files
comment|// belonging to different region servers. We have to safe guard against this case by using
comment|// region open event's seqid. Since this is the first event that the region puts (after
comment|// possibly flushing recovered.edits), after seeing this event, we can ignore every edit
comment|// smaller than this seqId
if|if
condition|(
name|bulkLoadEvent
operator|.
name|getBulkloadSeqNum
argument_list|()
operator|>=
literal|0
operator|&&
name|this
operator|.
name|lastReplayedOpenRegionSeqId
operator|>=
name|bulkLoadEvent
operator|.
name|getBulkloadSeqNum
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
name|getRegionInfo
argument_list|()
operator|.
name|getEncodedName
argument_list|()
operator|+
literal|" : "
operator|+
literal|"Skipping replaying bulkload event :"
operator|+
name|TextFormat
operator|.
name|shortDebugString
argument_list|(
name|bulkLoadEvent
argument_list|)
operator|+
literal|" because its sequence id is smaller than this region's lastReplayedOpenRegionSeqId"
operator|+
literal|" ="
operator|+
name|lastReplayedOpenRegionSeqId
argument_list|)
expr_stmt|;
return|return;
block|}
for|for
control|(
name|StoreDescriptor
name|storeDescriptor
range|:
name|bulkLoadEvent
operator|.
name|getStoresList
argument_list|()
control|)
block|{
comment|// stores of primary may be different now
name|family
operator|=
name|storeDescriptor
operator|.
name|getFamilyName
argument_list|()
operator|.
name|toByteArray
argument_list|()
expr_stmt|;
name|HStore
name|store
init|=
name|getStore
argument_list|(
name|family
argument_list|)
decl_stmt|;
if|if
condition|(
name|store
operator|==
literal|null
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
name|getRegionInfo
argument_list|()
operator|.
name|getEncodedName
argument_list|()
operator|+
literal|" : "
operator|+
literal|"Received a bulk load marker from primary, but the family is not found. "
operator|+
literal|"Ignoring. StoreDescriptor:"
operator|+
name|storeDescriptor
argument_list|)
expr_stmt|;
continue|continue;
block|}
name|List
argument_list|<
name|String
argument_list|>
name|storeFiles
init|=
name|storeDescriptor
operator|.
name|getStoreFileList
argument_list|()
decl_stmt|;
for|for
control|(
name|String
name|storeFile
range|:
name|storeFiles
control|)
block|{
name|StoreFileInfo
name|storeFileInfo
init|=
literal|null
decl_stmt|;
try|try
block|{
name|storeFileInfo
operator|=
name|fs
operator|.
name|getStoreFileInfo
argument_list|(
name|Bytes
operator|.
name|toString
argument_list|(
name|family
argument_list|)
argument_list|,
name|storeFile
argument_list|)
expr_stmt|;
name|store
operator|.
name|bulkLoadHFile
argument_list|(
name|storeFileInfo
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|FileNotFoundException
name|ex
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
name|getRegionInfo
argument_list|()
operator|.
name|getEncodedName
argument_list|()
operator|+
literal|" : "
operator|+
operator|(
operator|(
name|storeFileInfo
operator|!=
literal|null
operator|)
condition|?
name|storeFileInfo
operator|.
name|toString
argument_list|()
else|:
operator|(
operator|new
name|Path
argument_list|(
name|Bytes
operator|.
name|toString
argument_list|(
name|family
argument_list|)
argument_list|,
name|storeFile
argument_list|)
operator|)
operator|.
name|toString
argument_list|()
operator|)
operator|+
literal|" doesn't exist any more. Skip loading the file"
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
if|if
condition|(
name|bulkLoadEvent
operator|.
name|getBulkloadSeqNum
argument_list|()
operator|>
literal|0
condition|)
block|{
name|mvcc
operator|.
name|advanceTo
argument_list|(
name|bulkLoadEvent
operator|.
name|getBulkloadSeqNum
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
finally|finally
block|{
name|closeBulkRegionOperation
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**    * If all stores ended up dropping their snapshots, we can safely drop the prepareFlushResult    */
specifier|private
name|void
name|dropPrepareFlushIfPossible
parameter_list|()
block|{
if|if
condition|(
name|writestate
operator|.
name|flushing
condition|)
block|{
name|boolean
name|canDrop
init|=
literal|true
decl_stmt|;
if|if
condition|(
name|prepareFlushResult
operator|.
name|storeFlushCtxs
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|Entry
argument_list|<
name|byte
index|[]
argument_list|,
name|StoreFlushContext
argument_list|>
name|entry
range|:
name|prepareFlushResult
operator|.
name|storeFlushCtxs
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|HStore
name|store
init|=
name|getStore
argument_list|(
name|entry
operator|.
name|getKey
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|store
operator|==
literal|null
condition|)
block|{
continue|continue;
block|}
if|if
condition|(
name|store
operator|.
name|getSnapshotSize
argument_list|()
operator|.
name|getDataSize
argument_list|()
operator|>
literal|0
condition|)
block|{
name|canDrop
operator|=
literal|false
expr_stmt|;
break|break;
block|}
block|}
block|}
comment|// this means that all the stores in the region has finished flushing, but the WAL marker
comment|// may not have been written or we did not receive it yet.
if|if
condition|(
name|canDrop
condition|)
block|{
name|writestate
operator|.
name|flushing
operator|=
literal|false
expr_stmt|;
name|this
operator|.
name|prepareFlushResult
operator|=
literal|null
expr_stmt|;
block|}
block|}
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|refreshStoreFiles
parameter_list|()
throws|throws
name|IOException
block|{
return|return
name|refreshStoreFiles
argument_list|(
literal|false
argument_list|)
return|;
block|}
annotation|@
name|edu
operator|.
name|umd
operator|.
name|cs
operator|.
name|findbugs
operator|.
name|annotations
operator|.
name|SuppressWarnings
argument_list|(
name|value
operator|=
literal|"NN_NAKED_NOTIFY"
argument_list|,
name|justification
operator|=
literal|"Notify is about post replay. Intentional"
argument_list|)
specifier|protected
name|boolean
name|refreshStoreFiles
parameter_list|(
name|boolean
name|force
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
operator|!
name|force
operator|&&
name|ServerRegionReplicaUtil
operator|.
name|isDefaultReplica
argument_list|(
name|this
operator|.
name|getRegionInfo
argument_list|()
argument_list|)
condition|)
block|{
return|return
literal|false
return|;
comment|// if primary nothing to do
block|}
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
name|getRegionInfo
argument_list|()
operator|.
name|getEncodedName
argument_list|()
operator|+
literal|" : "
operator|+
literal|"Refreshing store files to see whether we can free up memstore"
argument_list|)
expr_stmt|;
block|}
name|long
name|totalFreedDataSize
init|=
literal|0
decl_stmt|;
name|long
name|smallestSeqIdInStores
init|=
name|Long
operator|.
name|MAX_VALUE
decl_stmt|;
name|startRegionOperation
argument_list|()
expr_stmt|;
comment|// obtain region close lock
try|try
block|{
name|Map
argument_list|<
name|HStore
argument_list|,
name|Long
argument_list|>
name|map
init|=
operator|new
name|HashMap
argument_list|<>
argument_list|()
decl_stmt|;
synchronized|synchronized
init|(
name|writestate
init|)
block|{
for|for
control|(
name|HStore
name|store
range|:
name|stores
operator|.
name|values
argument_list|()
control|)
block|{
comment|// TODO: some stores might see new data from flush, while others do not which
comment|// MIGHT break atomic edits across column families.
name|long
name|maxSeqIdBefore
init|=
name|store
operator|.
name|getMaxSequenceId
argument_list|()
operator|.
name|orElse
argument_list|(
literal|0L
argument_list|)
decl_stmt|;
comment|// refresh the store files. This is similar to observing a region open wal marker.
name|store
operator|.
name|refreshStoreFiles
argument_list|()
expr_stmt|;
name|long
name|storeSeqId
init|=
name|store
operator|.
name|getMaxSequenceId
argument_list|()
operator|.
name|orElse
argument_list|(
literal|0L
argument_list|)
decl_stmt|;
if|if
condition|(
name|storeSeqId
operator|<
name|smallestSeqIdInStores
condition|)
block|{
name|smallestSeqIdInStores
operator|=
name|storeSeqId
expr_stmt|;
block|}
comment|// see whether we can drop the memstore or the snapshot
if|if
condition|(
name|storeSeqId
operator|>
name|maxSeqIdBefore
condition|)
block|{
if|if
condition|(
name|writestate
operator|.
name|flushing
condition|)
block|{
comment|// only drop memstore snapshots if they are smaller than last flush for the store
if|if
condition|(
name|this
operator|.
name|prepareFlushResult
operator|.
name|flushOpSeqId
operator|<=
name|storeSeqId
condition|)
block|{
name|StoreFlushContext
name|ctx
init|=
name|this
operator|.
name|prepareFlushResult
operator|.
name|storeFlushCtxs
operator|==
literal|null
condition|?
literal|null
else|:
name|this
operator|.
name|prepareFlushResult
operator|.
name|storeFlushCtxs
operator|.
name|get
argument_list|(
name|store
operator|.
name|getColumnFamilyDescriptor
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|ctx
operator|!=
literal|null
condition|)
block|{
name|MemStoreSize
name|mss
init|=
name|store
operator|.
name|getFlushableSize
argument_list|()
decl_stmt|;
name|ctx
operator|.
name|abort
argument_list|()
expr_stmt|;
name|this
operator|.
name|decrMemStoreSize
argument_list|(
name|mss
argument_list|)
expr_stmt|;
name|this
operator|.
name|prepareFlushResult
operator|.
name|storeFlushCtxs
operator|.
name|remove
argument_list|(
name|store
operator|.
name|getColumnFamilyDescriptor
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
name|totalFreedDataSize
operator|+=
name|mss
operator|.
name|getDataSize
argument_list|()
expr_stmt|;
block|}
block|}
block|}
name|map
operator|.
name|put
argument_list|(
name|store
argument_list|,
name|storeSeqId
argument_list|)
expr_stmt|;
block|}
block|}
comment|// if all stores ended up dropping their snapshots, we can safely drop the
comment|// prepareFlushResult
name|dropPrepareFlushIfPossible
argument_list|()
expr_stmt|;
comment|// advance the mvcc read point so that the new flushed files are visible.
comment|// either greater than flush seq number or they were already picked up via flush.
for|for
control|(
name|HStore
name|s
range|:
name|stores
operator|.
name|values
argument_list|()
control|)
block|{
name|mvcc
operator|.
name|advanceTo
argument_list|(
name|s
operator|.
name|getMaxMemStoreTS
argument_list|()
operator|.
name|orElse
argument_list|(
literal|0L
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|// smallestSeqIdInStores is the seqId that we have a corresponding hfile for. We can safely
comment|// skip all edits that are to be replayed in the future with that has a smaller seqId
comment|// than this. We are updating lastReplayedOpenRegionSeqId so that we can skip all edits
comment|// that we have picked the flush files for
if|if
condition|(
name|this
operator|.
name|lastReplayedOpenRegionSeqId
operator|<
name|smallestSeqIdInStores
condition|)
block|{
name|this
operator|.
name|lastReplayedOpenRegionSeqId
operator|=
name|smallestSeqIdInStores
expr_stmt|;
block|}
block|}
if|if
condition|(
operator|!
name|map
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|HStore
argument_list|,
name|Long
argument_list|>
name|entry
range|:
name|map
operator|.
name|entrySet
argument_list|()
control|)
block|{
comment|// Drop the memstore contents if they are now smaller than the latest seen flushed file
name|totalFreedDataSize
operator|+=
name|dropMemStoreContentsForSeqId
argument_list|(
name|entry
operator|.
name|getValue
argument_list|()
argument_list|,
name|entry
operator|.
name|getKey
argument_list|()
argument_list|)
operator|.
name|getDataSize
argument_list|()
expr_stmt|;
block|}
block|}
comment|// C. Finally notify anyone waiting on memstore to clear:
comment|// e.g. checkResources().
synchronized|synchronized
init|(
name|this
init|)
block|{
name|notifyAll
argument_list|()
expr_stmt|;
comment|// FindBugs NN_NAKED_NOTIFY
block|}
return|return
name|totalFreedDataSize
operator|>
literal|0
return|;
block|}
finally|finally
block|{
name|closeRegionOperation
argument_list|()
expr_stmt|;
block|}
block|}
specifier|private
name|void
name|logRegionFiles
parameter_list|()
block|{
if|if
condition|(
name|LOG
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|trace
argument_list|(
name|getRegionInfo
argument_list|()
operator|.
name|getEncodedName
argument_list|()
operator|+
literal|" : Store files for region: "
argument_list|)
expr_stmt|;
name|stores
operator|.
name|values
argument_list|()
operator|.
name|stream
argument_list|()
operator|.
name|filter
argument_list|(
name|s
lambda|->
name|s
operator|.
name|getStorefiles
argument_list|()
operator|!=
literal|null
argument_list|)
operator|.
name|flatMap
argument_list|(
name|s
lambda|->
name|s
operator|.
name|getStorefiles
argument_list|()
operator|.
name|stream
argument_list|()
argument_list|)
operator|.
name|forEachOrdered
argument_list|(
name|sf
lambda|->
name|LOG
operator|.
name|trace
argument_list|(
name|getRegionInfo
argument_list|()
operator|.
name|getEncodedName
argument_list|()
operator|+
literal|" : "
operator|+
name|sf
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
comment|/** Checks whether the given regionName is either equal to our region, or that    * the regionName is the primary region to our corresponding range for the secondary replica.    */
specifier|private
name|void
name|checkTargetRegion
parameter_list|(
name|byte
index|[]
name|encodedRegionName
parameter_list|,
name|String
name|exceptionMsg
parameter_list|,
name|Object
name|payload
parameter_list|)
throws|throws
name|WrongRegionException
block|{
if|if
condition|(
name|Bytes
operator|.
name|equals
argument_list|(
name|this
operator|.
name|getRegionInfo
argument_list|()
operator|.
name|getEncodedNameAsBytes
argument_list|()
argument_list|,
name|encodedRegionName
argument_list|)
condition|)
block|{
return|return;
block|}
if|if
condition|(
operator|!
name|RegionReplicaUtil
operator|.
name|isDefaultReplica
argument_list|(
name|this
operator|.
name|getRegionInfo
argument_list|()
argument_list|)
operator|&&
name|Bytes
operator|.
name|equals
argument_list|(
name|encodedRegionName
argument_list|,
name|this
operator|.
name|fs
operator|.
name|getRegionInfoForFS
argument_list|()
operator|.
name|getEncodedNameAsBytes
argument_list|()
argument_list|)
condition|)
block|{
return|return;
block|}
throw|throw
operator|new
name|WrongRegionException
argument_list|(
name|exceptionMsg
operator|+
name|payload
operator|+
literal|" targetted for region "
operator|+
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|encodedRegionName
argument_list|)
operator|+
literal|" does not match this region: "
operator|+
name|this
operator|.
name|getRegionInfo
argument_list|()
argument_list|)
throw|;
block|}
comment|/**    * Used by tests    * @param s Store to add edit too.    * @param cell Cell to add.    */
annotation|@
name|VisibleForTesting
specifier|protected
name|void
name|restoreEdit
parameter_list|(
name|HStore
name|s
parameter_list|,
name|Cell
name|cell
parameter_list|,
name|MemStoreSizing
name|memstoreAccounting
parameter_list|)
block|{
name|s
operator|.
name|add
argument_list|(
name|cell
argument_list|,
name|memstoreAccounting
argument_list|)
expr_stmt|;
block|}
comment|/**    * @param p File to check.    * @return True if file was zero-length (and if so, we'll delete it in here).    * @throws IOException    */
specifier|private
specifier|static
name|boolean
name|isZeroLengthThenDelete
parameter_list|(
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Path
name|p
parameter_list|)
throws|throws
name|IOException
block|{
name|FileStatus
name|stat
init|=
name|fs
operator|.
name|getFileStatus
argument_list|(
name|p
argument_list|)
decl_stmt|;
if|if
condition|(
name|stat
operator|.
name|getLen
argument_list|()
operator|>
literal|0
condition|)
block|{
return|return
literal|false
return|;
block|}
name|LOG
operator|.
name|warn
argument_list|(
literal|"File "
operator|+
name|p
operator|+
literal|" is zero-length, deleting."
argument_list|)
expr_stmt|;
name|fs
operator|.
name|delete
argument_list|(
name|p
argument_list|,
literal|false
argument_list|)
expr_stmt|;
return|return
literal|true
return|;
block|}
specifier|protected
name|HStore
name|instantiateHStore
parameter_list|(
specifier|final
name|ColumnFamilyDescriptor
name|family
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|family
operator|.
name|isMobEnabled
argument_list|()
condition|)
block|{
if|if
condition|(
name|HFile
operator|.
name|getFormatVersion
argument_list|(
name|this
operator|.
name|conf
argument_list|)
operator|<
name|HFile
operator|.
name|MIN_FORMAT_VERSION_WITH_TAGS
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"A minimum HFile version of "
operator|+
name|HFile
operator|.
name|MIN_FORMAT_VERSION_WITH_TAGS
operator|+
literal|" is required for MOB feature. Consider setting "
operator|+
name|HFile
operator|.
name|FORMAT_VERSION_KEY
operator|+
literal|" accordingly."
argument_list|)
throw|;
block|}
return|return
operator|new
name|HMobStore
argument_list|(
name|this
argument_list|,
name|family
argument_list|,
name|this
operator|.
name|conf
argument_list|)
return|;
block|}
return|return
operator|new
name|HStore
argument_list|(
name|this
argument_list|,
name|family
argument_list|,
name|this
operator|.
name|conf
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|HStore
name|getStore
parameter_list|(
name|byte
index|[]
name|column
parameter_list|)
block|{
return|return
name|this
operator|.
name|stores
operator|.
name|get
argument_list|(
name|column
argument_list|)
return|;
block|}
comment|/**    * Return HStore instance. Does not do any copy: as the number of store is limited, we iterate on    * the list.    */
specifier|private
name|HStore
name|getStore
parameter_list|(
name|Cell
name|cell
parameter_list|)
block|{
return|return
name|stores
operator|.
name|entrySet
argument_list|()
operator|.
name|stream
argument_list|()
operator|.
name|filter
argument_list|(
name|e
lambda|->
name|CellUtil
operator|.
name|matchingFamily
argument_list|(
name|cell
argument_list|,
name|e
operator|.
name|getKey
argument_list|()
argument_list|)
argument_list|)
operator|.
name|map
argument_list|(
name|e
lambda|->
name|e
operator|.
name|getValue
argument_list|()
argument_list|)
operator|.
name|findFirst
argument_list|()
operator|.
name|orElse
argument_list|(
literal|null
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|List
argument_list|<
name|HStore
argument_list|>
name|getStores
parameter_list|()
block|{
return|return
operator|new
name|ArrayList
argument_list|<>
argument_list|(
name|stores
operator|.
name|values
argument_list|()
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|List
argument_list|<
name|String
argument_list|>
name|getStoreFileList
parameter_list|(
name|byte
index|[]
index|[]
name|columns
parameter_list|)
throws|throws
name|IllegalArgumentException
block|{
name|List
argument_list|<
name|String
argument_list|>
name|storeFileNames
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
synchronized|synchronized
init|(
name|closeLock
init|)
block|{
for|for
control|(
name|byte
index|[]
name|column
range|:
name|columns
control|)
block|{
name|HStore
name|store
init|=
name|this
operator|.
name|stores
operator|.
name|get
argument_list|(
name|column
argument_list|)
decl_stmt|;
if|if
condition|(
name|store
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"No column family : "
operator|+
operator|new
name|String
argument_list|(
name|column
argument_list|,
name|StandardCharsets
operator|.
name|UTF_8
argument_list|)
operator|+
literal|" available"
argument_list|)
throw|;
block|}
name|Collection
argument_list|<
name|HStoreFile
argument_list|>
name|storeFiles
init|=
name|store
operator|.
name|getStorefiles
argument_list|()
decl_stmt|;
if|if
condition|(
name|storeFiles
operator|==
literal|null
condition|)
block|{
continue|continue;
block|}
for|for
control|(
name|HStoreFile
name|storeFile
range|:
name|storeFiles
control|)
block|{
name|storeFileNames
operator|.
name|add
argument_list|(
name|storeFile
operator|.
name|getPath
argument_list|()
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|logRegionFiles
argument_list|()
expr_stmt|;
block|}
block|}
return|return
name|storeFileNames
return|;
block|}
comment|//////////////////////////////////////////////////////////////////////////////
comment|// Support code
comment|//////////////////////////////////////////////////////////////////////////////
comment|/** Make sure this is a valid row for the HRegion */
name|void
name|checkRow
parameter_list|(
name|byte
index|[]
name|row
parameter_list|,
name|String
name|op
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
operator|!
name|rowIsInRange
argument_list|(
name|getRegionInfo
argument_list|()
argument_list|,
name|row
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|WrongRegionException
argument_list|(
literal|"Requested row out of range for "
operator|+
name|op
operator|+
literal|" on HRegion "
operator|+
name|this
operator|+
literal|", startKey='"
operator|+
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|getRegionInfo
argument_list|()
operator|.
name|getStartKey
argument_list|()
argument_list|)
operator|+
literal|"', getEndKey()='"
operator|+
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|getRegionInfo
argument_list|()
operator|.
name|getEndKey
argument_list|()
argument_list|)
operator|+
literal|"', row='"
operator|+
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|row
argument_list|)
operator|+
literal|"'"
argument_list|)
throw|;
block|}
block|}
comment|/**    * Get an exclusive ( write lock ) lock on a given row.    * @param row Which row to lock.    * @return A locked RowLock. The lock is exclusive and already aqquired.    * @throws IOException    */
specifier|public
name|RowLock
name|getRowLock
parameter_list|(
name|byte
index|[]
name|row
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|getRowLock
argument_list|(
name|row
argument_list|,
literal|false
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|RowLock
name|getRowLock
parameter_list|(
name|byte
index|[]
name|row
parameter_list|,
name|boolean
name|readLock
parameter_list|)
throws|throws
name|IOException
block|{
name|checkRow
argument_list|(
name|row
argument_list|,
literal|"row lock"
argument_list|)
expr_stmt|;
return|return
name|getRowLockInternal
argument_list|(
name|row
argument_list|,
name|readLock
argument_list|,
literal|null
argument_list|)
return|;
block|}
specifier|protected
name|RowLock
name|getRowLockInternal
parameter_list|(
name|byte
index|[]
name|row
parameter_list|,
name|boolean
name|readLock
parameter_list|,
specifier|final
name|RowLock
name|prevRowLock
parameter_list|)
throws|throws
name|IOException
block|{
comment|// create an object to use a a key in the row lock map
name|HashedBytes
name|rowKey
init|=
operator|new
name|HashedBytes
argument_list|(
name|row
argument_list|)
decl_stmt|;
name|RowLockContext
name|rowLockContext
init|=
literal|null
decl_stmt|;
name|RowLockImpl
name|result
init|=
literal|null
decl_stmt|;
name|boolean
name|success
init|=
literal|false
decl_stmt|;
try|try
init|(
name|TraceScope
name|scope
init|=
name|TraceUtil
operator|.
name|createTrace
argument_list|(
literal|"HRegion.getRowLock"
argument_list|)
init|)
block|{
name|TraceUtil
operator|.
name|addTimelineAnnotation
argument_list|(
literal|"Getting a "
operator|+
operator|(
name|readLock
condition|?
literal|"readLock"
else|:
literal|"writeLock"
operator|)
argument_list|)
expr_stmt|;
comment|// Keep trying until we have a lock or error out.
comment|// TODO: do we need to add a time component here?
while|while
condition|(
name|result
operator|==
literal|null
condition|)
block|{
name|rowLockContext
operator|=
name|computeIfAbsent
argument_list|(
name|lockedRows
argument_list|,
name|rowKey
argument_list|,
parameter_list|()
lambda|->
operator|new
name|RowLockContext
argument_list|(
name|rowKey
argument_list|)
argument_list|)
expr_stmt|;
comment|// Now try an get the lock.
comment|// This can fail as
if|if
condition|(
name|readLock
condition|)
block|{
comment|// For read lock, if the caller has locked the same row previously, it will not try
comment|// to acquire the same read lock. It simply returns the previous row lock.
name|RowLockImpl
name|prevRowLockImpl
init|=
operator|(
name|RowLockImpl
operator|)
name|prevRowLock
decl_stmt|;
if|if
condition|(
operator|(
name|prevRowLockImpl
operator|!=
literal|null
operator|)
operator|&&
operator|(
name|prevRowLockImpl
operator|.
name|getLock
argument_list|()
operator|==
name|rowLockContext
operator|.
name|readWriteLock
operator|.
name|readLock
argument_list|()
operator|)
condition|)
block|{
name|success
operator|=
literal|true
expr_stmt|;
return|return
name|prevRowLock
return|;
block|}
name|result
operator|=
name|rowLockContext
operator|.
name|newReadLock
argument_list|()
expr_stmt|;
block|}
else|else
block|{
name|result
operator|=
name|rowLockContext
operator|.
name|newWriteLock
argument_list|()
expr_stmt|;
block|}
block|}
name|int
name|timeout
init|=
name|rowLockWaitDuration
decl_stmt|;
name|boolean
name|reachDeadlineFirst
init|=
literal|false
decl_stmt|;
name|Optional
argument_list|<
name|RpcCall
argument_list|>
name|call
init|=
name|RpcServer
operator|.
name|getCurrentCall
argument_list|()
decl_stmt|;
if|if
condition|(
name|call
operator|.
name|isPresent
argument_list|()
condition|)
block|{
name|long
name|deadline
init|=
name|call
operator|.
name|get
argument_list|()
operator|.
name|getDeadline
argument_list|()
decl_stmt|;
if|if
condition|(
name|deadline
operator|<
name|Long
operator|.
name|MAX_VALUE
condition|)
block|{
name|int
name|timeToDeadline
init|=
call|(
name|int
call|)
argument_list|(
name|deadline
operator|-
name|System
operator|.
name|currentTimeMillis
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|timeToDeadline
operator|<=
name|this
operator|.
name|rowLockWaitDuration
condition|)
block|{
name|reachDeadlineFirst
operator|=
literal|true
expr_stmt|;
name|timeout
operator|=
name|timeToDeadline
expr_stmt|;
block|}
block|}
block|}
if|if
condition|(
name|timeout
operator|<=
literal|0
operator|||
operator|!
name|result
operator|.
name|getLock
argument_list|()
operator|.
name|tryLock
argument_list|(
name|timeout
argument_list|,
name|TimeUnit
operator|.
name|MILLISECONDS
argument_list|)
condition|)
block|{
name|TraceUtil
operator|.
name|addTimelineAnnotation
argument_list|(
literal|"Failed to get row lock"
argument_list|)
expr_stmt|;
name|String
name|message
init|=
literal|"Timed out waiting for lock for row: "
operator|+
name|rowKey
operator|+
literal|" in region "
operator|+
name|getRegionInfo
argument_list|()
operator|.
name|getEncodedName
argument_list|()
decl_stmt|;
if|if
condition|(
name|reachDeadlineFirst
condition|)
block|{
throw|throw
operator|new
name|TimeoutIOException
argument_list|(
name|message
argument_list|)
throw|;
block|}
else|else
block|{
comment|// If timeToDeadline is larger than rowLockWaitDuration, we can not drop the request.
throw|throw
operator|new
name|IOException
argument_list|(
name|message
argument_list|)
throw|;
block|}
block|}
name|rowLockContext
operator|.
name|setThreadName
argument_list|(
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
name|success
operator|=
literal|true
expr_stmt|;
return|return
name|result
return|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|ie
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Thread interrupted waiting for lock on row: "
operator|+
name|rowKey
argument_list|)
expr_stmt|;
name|InterruptedIOException
name|iie
init|=
operator|new
name|InterruptedIOException
argument_list|()
decl_stmt|;
name|iie
operator|.
name|initCause
argument_list|(
name|ie
argument_list|)
expr_stmt|;
name|TraceUtil
operator|.
name|addTimelineAnnotation
argument_list|(
literal|"Interrupted exception getting row lock"
argument_list|)
expr_stmt|;
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|interrupt
argument_list|()
expr_stmt|;
throw|throw
name|iie
throw|;
block|}
catch|catch
parameter_list|(
name|Error
name|error
parameter_list|)
block|{
comment|// The maximum lock count for read lock is 64K (hardcoded), when this maximum count
comment|// is reached, it will throw out an Error. This Error needs to be caught so it can
comment|// go ahead to process the minibatch with lock acquired.
name|LOG
operator|.
name|warn
argument_list|(
literal|"Error to get row lock for "
operator|+
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|row
argument_list|)
operator|+
literal|", cause: "
operator|+
name|error
argument_list|)
expr_stmt|;
name|IOException
name|ioe
init|=
operator|new
name|IOException
argument_list|()
decl_stmt|;
name|ioe
operator|.
name|initCause
argument_list|(
name|error
argument_list|)
expr_stmt|;
name|TraceUtil
operator|.
name|addTimelineAnnotation
argument_list|(
literal|"Error getting row lock"
argument_list|)
expr_stmt|;
throw|throw
name|ioe
throw|;
block|}
finally|finally
block|{
comment|// Clean up the counts just in case this was the thing keeping the context alive.
if|if
condition|(
operator|!
name|success
operator|&&
name|rowLockContext
operator|!=
literal|null
condition|)
block|{
name|rowLockContext
operator|.
name|cleanUp
argument_list|()
expr_stmt|;
block|}
block|}
block|}
specifier|private
name|void
name|releaseRowLocks
parameter_list|(
name|List
argument_list|<
name|RowLock
argument_list|>
name|rowLocks
parameter_list|)
block|{
if|if
condition|(
name|rowLocks
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|RowLock
name|rowLock
range|:
name|rowLocks
control|)
block|{
name|rowLock
operator|.
name|release
argument_list|()
expr_stmt|;
block|}
name|rowLocks
operator|.
name|clear
argument_list|()
expr_stmt|;
block|}
block|}
annotation|@
name|VisibleForTesting
specifier|public
name|int
name|getReadLockCount
parameter_list|()
block|{
return|return
name|lock
operator|.
name|getReadLockCount
argument_list|()
return|;
block|}
specifier|public
name|ConcurrentHashMap
argument_list|<
name|HashedBytes
argument_list|,
name|RowLockContext
argument_list|>
name|getLockedRows
parameter_list|()
block|{
return|return
name|lockedRows
return|;
block|}
annotation|@
name|VisibleForTesting
class|class
name|RowLockContext
block|{
specifier|private
specifier|final
name|HashedBytes
name|row
decl_stmt|;
specifier|final
name|ReadWriteLock
name|readWriteLock
init|=
operator|new
name|ReentrantReadWriteLock
argument_list|(
literal|true
argument_list|)
decl_stmt|;
specifier|final
name|AtomicBoolean
name|usable
init|=
operator|new
name|AtomicBoolean
argument_list|(
literal|true
argument_list|)
decl_stmt|;
specifier|final
name|AtomicInteger
name|count
init|=
operator|new
name|AtomicInteger
argument_list|(
literal|0
argument_list|)
decl_stmt|;
specifier|final
name|Object
name|lock
init|=
operator|new
name|Object
argument_list|()
decl_stmt|;
specifier|private
name|String
name|threadName
decl_stmt|;
name|RowLockContext
parameter_list|(
name|HashedBytes
name|row
parameter_list|)
block|{
name|this
operator|.
name|row
operator|=
name|row
expr_stmt|;
block|}
name|RowLockImpl
name|newWriteLock
parameter_list|()
block|{
name|Lock
name|l
init|=
name|readWriteLock
operator|.
name|writeLock
argument_list|()
decl_stmt|;
return|return
name|getRowLock
argument_list|(
name|l
argument_list|)
return|;
block|}
name|RowLockImpl
name|newReadLock
parameter_list|()
block|{
name|Lock
name|l
init|=
name|readWriteLock
operator|.
name|readLock
argument_list|()
decl_stmt|;
return|return
name|getRowLock
argument_list|(
name|l
argument_list|)
return|;
block|}
specifier|private
name|RowLockImpl
name|getRowLock
parameter_list|(
name|Lock
name|l
parameter_list|)
block|{
name|count
operator|.
name|incrementAndGet
argument_list|()
expr_stmt|;
synchronized|synchronized
init|(
name|lock
init|)
block|{
if|if
condition|(
name|usable
operator|.
name|get
argument_list|()
condition|)
block|{
return|return
operator|new
name|RowLockImpl
argument_list|(
name|this
argument_list|,
name|l
argument_list|)
return|;
block|}
else|else
block|{
return|return
literal|null
return|;
block|}
block|}
block|}
name|void
name|cleanUp
parameter_list|()
block|{
name|long
name|c
init|=
name|count
operator|.
name|decrementAndGet
argument_list|()
decl_stmt|;
if|if
condition|(
name|c
operator|<=
literal|0
condition|)
block|{
synchronized|synchronized
init|(
name|lock
init|)
block|{
if|if
condition|(
name|count
operator|.
name|get
argument_list|()
operator|<=
literal|0
operator|&&
name|usable
operator|.
name|get
argument_list|()
condition|)
block|{
comment|// Don't attempt to remove row if already removed
name|usable
operator|.
name|set
argument_list|(
literal|false
argument_list|)
expr_stmt|;
name|RowLockContext
name|removed
init|=
name|lockedRows
operator|.
name|remove
argument_list|(
name|row
argument_list|)
decl_stmt|;
assert|assert
name|removed
operator|==
name|this
operator|:
literal|"we should never remove a different context"
assert|;
block|}
block|}
block|}
block|}
specifier|public
name|void
name|setThreadName
parameter_list|(
name|String
name|threadName
parameter_list|)
block|{
name|this
operator|.
name|threadName
operator|=
name|threadName
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|String
name|toString
parameter_list|()
block|{
return|return
literal|"RowLockContext{"
operator|+
literal|"row="
operator|+
name|row
operator|+
literal|", readWriteLock="
operator|+
name|readWriteLock
operator|+
literal|", count="
operator|+
name|count
operator|+
literal|", threadName="
operator|+
name|threadName
operator|+
literal|'}'
return|;
block|}
block|}
comment|/**    * Class used to represent a lock on a row.    */
specifier|public
specifier|static
class|class
name|RowLockImpl
implements|implements
name|RowLock
block|{
specifier|private
specifier|final
name|RowLockContext
name|context
decl_stmt|;
specifier|private
specifier|final
name|Lock
name|lock
decl_stmt|;
specifier|public
name|RowLockImpl
parameter_list|(
name|RowLockContext
name|context
parameter_list|,
name|Lock
name|lock
parameter_list|)
block|{
name|this
operator|.
name|context
operator|=
name|context
expr_stmt|;
name|this
operator|.
name|lock
operator|=
name|lock
expr_stmt|;
block|}
specifier|public
name|Lock
name|getLock
parameter_list|()
block|{
return|return
name|lock
return|;
block|}
annotation|@
name|VisibleForTesting
specifier|public
name|RowLockContext
name|getContext
parameter_list|()
block|{
return|return
name|context
return|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|release
parameter_list|()
block|{
name|lock
operator|.
name|unlock
argument_list|()
expr_stmt|;
name|context
operator|.
name|cleanUp
argument_list|()
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|String
name|toString
parameter_list|()
block|{
return|return
literal|"RowLockImpl{"
operator|+
literal|"context="
operator|+
name|context
operator|+
literal|", lock="
operator|+
name|lock
operator|+
literal|'}'
return|;
block|}
block|}
comment|/**    * Determines whether multiple column families are present    * Precondition: familyPaths is not null    *    * @param familyPaths List of (column family, hfilePath)    */
specifier|private
specifier|static
name|boolean
name|hasMultipleColumnFamilies
parameter_list|(
name|Collection
argument_list|<
name|Pair
argument_list|<
name|byte
index|[]
argument_list|,
name|String
argument_list|>
argument_list|>
name|familyPaths
parameter_list|)
block|{
name|boolean
name|multipleFamilies
init|=
literal|false
decl_stmt|;
name|byte
index|[]
name|family
init|=
literal|null
decl_stmt|;
for|for
control|(
name|Pair
argument_list|<
name|byte
index|[]
argument_list|,
name|String
argument_list|>
name|pair
range|:
name|familyPaths
control|)
block|{
name|byte
index|[]
name|fam
init|=
name|pair
operator|.
name|getFirst
argument_list|()
decl_stmt|;
if|if
condition|(
name|family
operator|==
literal|null
condition|)
block|{
name|family
operator|=
name|fam
expr_stmt|;
block|}
elseif|else
if|if
condition|(
operator|!
name|Bytes
operator|.
name|equals
argument_list|(
name|family
argument_list|,
name|fam
argument_list|)
condition|)
block|{
name|multipleFamilies
operator|=
literal|true
expr_stmt|;
break|break;
block|}
block|}
return|return
name|multipleFamilies
return|;
block|}
comment|/**    * Attempts to atomically load a group of hfiles.  This is critical for loading    * rows with multiple column families atomically.    *    * @param familyPaths List of Pair&lt;byte[] column family, String hfilePath&gt;    * @param bulkLoadListener Internal hooks enabling massaging/preparation of a    * file about to be bulk loaded    * @param assignSeqId    * @return Map from family to List of store file paths if successful, null if failed recoverably    * @throws IOException if failed unrecoverably.    */
specifier|public
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|List
argument_list|<
name|Path
argument_list|>
argument_list|>
name|bulkLoadHFiles
parameter_list|(
name|Collection
argument_list|<
name|Pair
argument_list|<
name|byte
index|[]
argument_list|,
name|String
argument_list|>
argument_list|>
name|familyPaths
parameter_list|,
name|boolean
name|assignSeqId
parameter_list|,
name|BulkLoadListener
name|bulkLoadListener
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|bulkLoadHFiles
argument_list|(
name|familyPaths
argument_list|,
name|assignSeqId
argument_list|,
name|bulkLoadListener
argument_list|,
literal|false
argument_list|)
return|;
block|}
comment|/**    * Listener class to enable callers of    * bulkLoadHFile() to perform any necessary    * pre/post processing of a given bulkload call    */
specifier|public
interface|interface
name|BulkLoadListener
block|{
comment|/**      * Called before an HFile is actually loaded      * @param family family being loaded to      * @param srcPath path of HFile      * @return final path to be used for actual loading      * @throws IOException      */
name|String
name|prepareBulkLoad
parameter_list|(
name|byte
index|[]
name|family
parameter_list|,
name|String
name|srcPath
parameter_list|,
name|boolean
name|copyFile
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**      * Called after a successful HFile load      * @param family family being loaded to      * @param srcPath path of HFile      * @throws IOException      */
name|void
name|doneBulkLoad
parameter_list|(
name|byte
index|[]
name|family
parameter_list|,
name|String
name|srcPath
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**      * Called after a failed HFile load      * @param family family being loaded to      * @param srcPath path of HFile      * @throws IOException      */
name|void
name|failedBulkLoad
parameter_list|(
name|byte
index|[]
name|family
parameter_list|,
name|String
name|srcPath
parameter_list|)
throws|throws
name|IOException
function_decl|;
block|}
comment|/**    * Attempts to atomically load a group of hfiles.  This is critical for loading    * rows with multiple column families atomically.    *    * @param familyPaths List of Pair&lt;byte[] column family, String hfilePath&gt;    * @param assignSeqId    * @param bulkLoadListener Internal hooks enabling massaging/preparation of a    * file about to be bulk loaded    * @param copyFile always copy hfiles if true    * @return Map from family to List of store file paths if successful, null if failed recoverably    * @throws IOException if failed unrecoverably.    */
specifier|public
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|List
argument_list|<
name|Path
argument_list|>
argument_list|>
name|bulkLoadHFiles
parameter_list|(
name|Collection
argument_list|<
name|Pair
argument_list|<
name|byte
index|[]
argument_list|,
name|String
argument_list|>
argument_list|>
name|familyPaths
parameter_list|,
name|boolean
name|assignSeqId
parameter_list|,
name|BulkLoadListener
name|bulkLoadListener
parameter_list|,
name|boolean
name|copyFile
parameter_list|)
throws|throws
name|IOException
block|{
name|long
name|seqId
init|=
operator|-
literal|1
decl_stmt|;
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|List
argument_list|<
name|Path
argument_list|>
argument_list|>
name|storeFiles
init|=
operator|new
name|TreeMap
argument_list|<>
argument_list|(
name|Bytes
operator|.
name|BYTES_COMPARATOR
argument_list|)
decl_stmt|;
name|Map
argument_list|<
name|String
argument_list|,
name|Long
argument_list|>
name|storeFilesSizes
init|=
operator|new
name|HashMap
argument_list|<>
argument_list|()
decl_stmt|;
name|Preconditions
operator|.
name|checkNotNull
argument_list|(
name|familyPaths
argument_list|)
expr_stmt|;
comment|// we need writeLock for multi-family bulk load
name|startBulkRegionOperation
argument_list|(
name|hasMultipleColumnFamilies
argument_list|(
name|familyPaths
argument_list|)
argument_list|)
expr_stmt|;
name|boolean
name|isSuccessful
init|=
literal|false
decl_stmt|;
try|try
block|{
name|this
operator|.
name|writeRequestsCount
operator|.
name|increment
argument_list|()
expr_stmt|;
comment|// There possibly was a split that happened between when the split keys
comment|// were gathered and before the HRegion's write lock was taken.  We need
comment|// to validate the HFile region before attempting to bulk load all of them
name|List
argument_list|<
name|IOException
argument_list|>
name|ioes
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|Pair
argument_list|<
name|byte
index|[]
argument_list|,
name|String
argument_list|>
argument_list|>
name|failures
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
for|for
control|(
name|Pair
argument_list|<
name|byte
index|[]
argument_list|,
name|String
argument_list|>
name|p
range|:
name|familyPaths
control|)
block|{
name|byte
index|[]
name|familyName
init|=
name|p
operator|.
name|getFirst
argument_list|()
decl_stmt|;
name|String
name|path
init|=
name|p
operator|.
name|getSecond
argument_list|()
decl_stmt|;
name|HStore
name|store
init|=
name|getStore
argument_list|(
name|familyName
argument_list|)
decl_stmt|;
if|if
condition|(
name|store
operator|==
literal|null
condition|)
block|{
name|IOException
name|ioe
init|=
operator|new
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|DoNotRetryIOException
argument_list|(
literal|"No such column family "
operator|+
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|familyName
argument_list|)
argument_list|)
decl_stmt|;
name|ioes
operator|.
name|add
argument_list|(
name|ioe
argument_list|)
expr_stmt|;
block|}
else|else
block|{
try|try
block|{
name|store
operator|.
name|assertBulkLoadHFileOk
argument_list|(
operator|new
name|Path
argument_list|(
name|path
argument_list|)
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|WrongRegionException
name|wre
parameter_list|)
block|{
comment|// recoverable (file doesn't fit in region)
name|failures
operator|.
name|add
argument_list|(
name|p
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ioe
parameter_list|)
block|{
comment|// unrecoverable (hdfs problem)
name|ioes
operator|.
name|add
argument_list|(
name|ioe
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|// validation failed because of some sort of IO problem.
if|if
condition|(
name|ioes
operator|.
name|size
argument_list|()
operator|!=
literal|0
condition|)
block|{
name|IOException
name|e
init|=
name|MultipleIOException
operator|.
name|createIOException
argument_list|(
name|ioes
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|error
argument_list|(
literal|"There were one or more IO errors when checking if the bulk load is ok."
argument_list|,
name|e
argument_list|)
expr_stmt|;
throw|throw
name|e
throw|;
block|}
comment|// validation failed, bail out before doing anything permanent.
if|if
condition|(
name|failures
operator|.
name|size
argument_list|()
operator|!=
literal|0
condition|)
block|{
name|StringBuilder
name|list
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
for|for
control|(
name|Pair
argument_list|<
name|byte
index|[]
argument_list|,
name|String
argument_list|>
name|p
range|:
name|failures
control|)
block|{
name|list
operator|.
name|append
argument_list|(
literal|"\n"
argument_list|)
operator|.
name|append
argument_list|(
name|Bytes
operator|.
name|toString
argument_list|(
name|p
operator|.
name|getFirst
argument_list|()
argument_list|)
argument_list|)
operator|.
name|append
argument_list|(
literal|" : "
argument_list|)
operator|.
name|append
argument_list|(
name|p
operator|.
name|getSecond
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|// problem when validating
name|LOG
operator|.
name|warn
argument_list|(
literal|"There was a recoverable bulk load failure likely due to a"
operator|+
literal|" split.  These (family, HFile) pairs were not loaded: "
operator|+
name|list
argument_list|)
expr_stmt|;
return|return
literal|null
return|;
block|}
comment|// We need to assign a sequential ID that's in between two memstores in order to preserve
comment|// the guarantee that all the edits lower than the highest sequential ID from all the
comment|// HFiles are flushed on disk. See HBASE-10958.  The sequence id returned when we flush is
comment|// guaranteed to be one beyond the file made when we flushed (or if nothing to flush, it is
comment|// a sequence id that we can be sure is beyond the last hfile written).
if|if
condition|(
name|assignSeqId
condition|)
block|{
name|FlushResult
name|fs
init|=
name|flushcache
argument_list|(
literal|true
argument_list|,
literal|false
argument_list|,
name|FlushLifeCycleTracker
operator|.
name|DUMMY
argument_list|)
decl_stmt|;
if|if
condition|(
name|fs
operator|.
name|isFlushSucceeded
argument_list|()
condition|)
block|{
name|seqId
operator|=
operator|(
operator|(
name|FlushResultImpl
operator|)
name|fs
operator|)
operator|.
name|flushSequenceId
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|fs
operator|.
name|getResult
argument_list|()
operator|==
name|FlushResult
operator|.
name|Result
operator|.
name|CANNOT_FLUSH_MEMSTORE_EMPTY
condition|)
block|{
name|seqId
operator|=
operator|(
operator|(
name|FlushResultImpl
operator|)
name|fs
operator|)
operator|.
name|flushSequenceId
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|fs
operator|.
name|getResult
argument_list|()
operator|==
name|FlushResult
operator|.
name|Result
operator|.
name|CANNOT_FLUSH
condition|)
block|{
comment|// CANNOT_FLUSH may mean that a flush is already on-going
comment|// we need to wait for that flush to complete
name|waitForFlushes
argument_list|()
expr_stmt|;
block|}
else|else
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Could not bulk load with an assigned sequential ID because the "
operator|+
literal|"flush didn't run. Reason for not flushing: "
operator|+
operator|(
operator|(
name|FlushResultImpl
operator|)
name|fs
operator|)
operator|.
name|failureReason
argument_list|)
throw|;
block|}
block|}
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|List
argument_list|<
name|Pair
argument_list|<
name|Path
argument_list|,
name|Path
argument_list|>
argument_list|>
argument_list|>
name|familyWithFinalPath
init|=
operator|new
name|TreeMap
argument_list|<>
argument_list|(
name|Bytes
operator|.
name|BYTES_COMPARATOR
argument_list|)
decl_stmt|;
for|for
control|(
name|Pair
argument_list|<
name|byte
index|[]
argument_list|,
name|String
argument_list|>
name|p
range|:
name|familyPaths
control|)
block|{
name|byte
index|[]
name|familyName
init|=
name|p
operator|.
name|getFirst
argument_list|()
decl_stmt|;
name|String
name|path
init|=
name|p
operator|.
name|getSecond
argument_list|()
decl_stmt|;
name|HStore
name|store
init|=
name|getStore
argument_list|(
name|familyName
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|familyWithFinalPath
operator|.
name|containsKey
argument_list|(
name|familyName
argument_list|)
condition|)
block|{
name|familyWithFinalPath
operator|.
name|put
argument_list|(
name|familyName
argument_list|,
operator|new
name|ArrayList
argument_list|<>
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|List
argument_list|<
name|Pair
argument_list|<
name|Path
argument_list|,
name|Path
argument_list|>
argument_list|>
name|lst
init|=
name|familyWithFinalPath
operator|.
name|get
argument_list|(
name|familyName
argument_list|)
decl_stmt|;
try|try
block|{
name|String
name|finalPath
init|=
name|path
decl_stmt|;
if|if
condition|(
name|bulkLoadListener
operator|!=
literal|null
condition|)
block|{
name|finalPath
operator|=
name|bulkLoadListener
operator|.
name|prepareBulkLoad
argument_list|(
name|familyName
argument_list|,
name|path
argument_list|,
name|copyFile
argument_list|)
expr_stmt|;
block|}
name|Pair
argument_list|<
name|Path
argument_list|,
name|Path
argument_list|>
name|pair
init|=
name|store
operator|.
name|preBulkLoadHFile
argument_list|(
name|finalPath
argument_list|,
name|seqId
argument_list|)
decl_stmt|;
name|lst
operator|.
name|add
argument_list|(
name|pair
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ioe
parameter_list|)
block|{
comment|// A failure here can cause an atomicity violation that we currently
comment|// cannot recover from since it is likely a failed HDFS operation.
name|LOG
operator|.
name|error
argument_list|(
literal|"There was a partial failure due to IO when attempting to"
operator|+
literal|" load "
operator|+
name|Bytes
operator|.
name|toString
argument_list|(
name|p
operator|.
name|getFirst
argument_list|()
argument_list|)
operator|+
literal|" : "
operator|+
name|p
operator|.
name|getSecond
argument_list|()
argument_list|,
name|ioe
argument_list|)
expr_stmt|;
if|if
condition|(
name|bulkLoadListener
operator|!=
literal|null
condition|)
block|{
try|try
block|{
name|bulkLoadListener
operator|.
name|failedBulkLoad
argument_list|(
name|familyName
argument_list|,
name|path
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|ex
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Error while calling failedBulkLoad for family "
operator|+
name|Bytes
operator|.
name|toString
argument_list|(
name|familyName
argument_list|)
operator|+
literal|" with path "
operator|+
name|path
argument_list|,
name|ex
argument_list|)
expr_stmt|;
block|}
block|}
throw|throw
name|ioe
throw|;
block|}
block|}
if|if
condition|(
name|this
operator|.
name|getCoprocessorHost
argument_list|()
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|byte
index|[]
argument_list|,
name|List
argument_list|<
name|Pair
argument_list|<
name|Path
argument_list|,
name|Path
argument_list|>
argument_list|>
argument_list|>
name|entry
range|:
name|familyWithFinalPath
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|this
operator|.
name|getCoprocessorHost
argument_list|()
operator|.
name|preCommitStoreFile
argument_list|(
name|entry
operator|.
name|getKey
argument_list|()
argument_list|,
name|entry
operator|.
name|getValue
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|byte
index|[]
argument_list|,
name|List
argument_list|<
name|Pair
argument_list|<
name|Path
argument_list|,
name|Path
argument_list|>
argument_list|>
argument_list|>
name|entry
range|:
name|familyWithFinalPath
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|byte
index|[]
name|familyName
init|=
name|entry
operator|.
name|getKey
argument_list|()
decl_stmt|;
for|for
control|(
name|Pair
argument_list|<
name|Path
argument_list|,
name|Path
argument_list|>
name|p
range|:
name|entry
operator|.
name|getValue
argument_list|()
control|)
block|{
name|String
name|path
init|=
name|p
operator|.
name|getFirst
argument_list|()
operator|.
name|toString
argument_list|()
decl_stmt|;
name|Path
name|commitedStoreFile
init|=
name|p
operator|.
name|getSecond
argument_list|()
decl_stmt|;
name|HStore
name|store
init|=
name|getStore
argument_list|(
name|familyName
argument_list|)
decl_stmt|;
try|try
block|{
name|store
operator|.
name|bulkLoadHFile
argument_list|(
name|familyName
argument_list|,
name|path
argument_list|,
name|commitedStoreFile
argument_list|)
expr_stmt|;
comment|// Note the size of the store file
try|try
block|{
name|FileSystem
name|fs
init|=
name|commitedStoreFile
operator|.
name|getFileSystem
argument_list|(
name|baseConf
argument_list|)
decl_stmt|;
name|storeFilesSizes
operator|.
name|put
argument_list|(
name|commitedStoreFile
operator|.
name|getName
argument_list|()
argument_list|,
name|fs
operator|.
name|getFileStatus
argument_list|(
name|commitedStoreFile
argument_list|)
operator|.
name|getLen
argument_list|()
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failed to find the size of hfile "
operator|+
name|commitedStoreFile
argument_list|,
name|e
argument_list|)
expr_stmt|;
name|storeFilesSizes
operator|.
name|put
argument_list|(
name|commitedStoreFile
operator|.
name|getName
argument_list|()
argument_list|,
literal|0L
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|storeFiles
operator|.
name|containsKey
argument_list|(
name|familyName
argument_list|)
condition|)
block|{
name|storeFiles
operator|.
name|get
argument_list|(
name|familyName
argument_list|)
operator|.
name|add
argument_list|(
name|commitedStoreFile
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|List
argument_list|<
name|Path
argument_list|>
name|storeFileNames
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
name|storeFileNames
operator|.
name|add
argument_list|(
name|commitedStoreFile
argument_list|)
expr_stmt|;
name|storeFiles
operator|.
name|put
argument_list|(
name|familyName
argument_list|,
name|storeFileNames
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|bulkLoadListener
operator|!=
literal|null
condition|)
block|{
name|bulkLoadListener
operator|.
name|doneBulkLoad
argument_list|(
name|familyName
argument_list|,
name|path
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|ioe
parameter_list|)
block|{
comment|// A failure here can cause an atomicity violation that we currently
comment|// cannot recover from since it is likely a failed HDFS operation.
comment|// TODO Need a better story for reverting partial failures due to HDFS.
name|LOG
operator|.
name|error
argument_list|(
literal|"There was a partial failure due to IO when attempting to"
operator|+
literal|" load "
operator|+
name|Bytes
operator|.
name|toString
argument_list|(
name|familyName
argument_list|)
operator|+
literal|" : "
operator|+
name|p
operator|.
name|getSecond
argument_list|()
argument_list|,
name|ioe
argument_list|)
expr_stmt|;
if|if
condition|(
name|bulkLoadListener
operator|!=
literal|null
condition|)
block|{
try|try
block|{
name|bulkLoadListener
operator|.
name|failedBulkLoad
argument_list|(
name|familyName
argument_list|,
name|path
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|ex
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Error while calling failedBulkLoad for family "
operator|+
name|Bytes
operator|.
name|toString
argument_list|(
name|familyName
argument_list|)
operator|+
literal|" with path "
operator|+
name|path
argument_list|,
name|ex
argument_list|)
expr_stmt|;
block|}
block|}
throw|throw
name|ioe
throw|;
block|}
block|}
block|}
name|isSuccessful
operator|=
literal|true
expr_stmt|;
block|}
finally|finally
block|{
if|if
condition|(
name|wal
operator|!=
literal|null
operator|&&
operator|!
name|storeFiles
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
comment|// Write a bulk load event for hfiles that are loaded
try|try
block|{
name|WALProtos
operator|.
name|BulkLoadDescriptor
name|loadDescriptor
init|=
name|ProtobufUtil
operator|.
name|toBulkLoadDescriptor
argument_list|(
name|this
operator|.
name|getRegionInfo
argument_list|()
operator|.
name|getTable
argument_list|()
argument_list|,
name|UnsafeByteOperations
operator|.
name|unsafeWrap
argument_list|(
name|this
operator|.
name|getRegionInfo
argument_list|()
operator|.
name|getEncodedNameAsBytes
argument_list|()
argument_list|)
argument_list|,
name|storeFiles
argument_list|,
name|storeFilesSizes
argument_list|,
name|seqId
argument_list|)
decl_stmt|;
name|WALUtil
operator|.
name|writeBulkLoadMarkerAndSync
argument_list|(
name|this
operator|.
name|wal
argument_list|,
name|this
operator|.
name|getReplicationScope
argument_list|()
argument_list|,
name|getRegionInfo
argument_list|()
argument_list|,
name|loadDescriptor
argument_list|,
name|mvcc
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ioe
parameter_list|)
block|{
if|if
condition|(
name|this
operator|.
name|rsServices
operator|!=
literal|null
condition|)
block|{
comment|// Have to abort region server because some hfiles has been loaded but we can't write
comment|// the event into WAL
name|isSuccessful
operator|=
literal|false
expr_stmt|;
name|this
operator|.
name|rsServices
operator|.
name|abort
argument_list|(
literal|"Failed to write bulk load event into WAL."
argument_list|,
name|ioe
argument_list|)
expr_stmt|;
block|}
block|}
block|}
name|closeBulkRegionOperation
argument_list|()
expr_stmt|;
block|}
return|return
name|isSuccessful
condition|?
name|storeFiles
else|:
literal|null
return|;
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|equals
parameter_list|(
name|Object
name|o
parameter_list|)
block|{
return|return
name|o
operator|instanceof
name|HRegion
operator|&&
name|Bytes
operator|.
name|equals
argument_list|(
name|getRegionInfo
argument_list|()
operator|.
name|getRegionName
argument_list|()
argument_list|,
operator|(
operator|(
name|HRegion
operator|)
name|o
operator|)
operator|.
name|getRegionInfo
argument_list|()
operator|.
name|getRegionName
argument_list|()
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|int
name|hashCode
parameter_list|()
block|{
return|return
name|Bytes
operator|.
name|hashCode
argument_list|(
name|getRegionInfo
argument_list|()
operator|.
name|getRegionName
argument_list|()
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|String
name|toString
parameter_list|()
block|{
return|return
name|getRegionInfo
argument_list|()
operator|.
name|getRegionNameAsString
argument_list|()
return|;
block|}
comment|/**    * RegionScannerImpl is used to combine scanners from multiple Stores (aka column families).    */
class|class
name|RegionScannerImpl
implements|implements
name|RegionScanner
implements|,
name|Shipper
implements|,
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|ipc
operator|.
name|RpcCallback
block|{
comment|// Package local for testability
name|KeyValueHeap
name|storeHeap
init|=
literal|null
decl_stmt|;
comment|/** Heap of key-values that are not essential for the provided filters and are thus read      * on demand, if on-demand column family loading is enabled.*/
name|KeyValueHeap
name|joinedHeap
init|=
literal|null
decl_stmt|;
comment|/**      * If the joined heap data gathering is interrupted due to scan limits, this will      * contain the row for which we are populating the values.*/
specifier|protected
name|Cell
name|joinedContinuationRow
init|=
literal|null
decl_stmt|;
specifier|private
name|boolean
name|filterClosed
init|=
literal|false
decl_stmt|;
specifier|protected
specifier|final
name|byte
index|[]
name|stopRow
decl_stmt|;
specifier|protected
specifier|final
name|boolean
name|includeStopRow
decl_stmt|;
specifier|protected
specifier|final
name|HRegion
name|region
decl_stmt|;
specifier|protected
specifier|final
name|CellComparator
name|comparator
decl_stmt|;
specifier|private
specifier|final
name|long
name|readPt
decl_stmt|;
specifier|private
specifier|final
name|long
name|maxResultSize
decl_stmt|;
specifier|private
specifier|final
name|ScannerContext
name|defaultScannerContext
decl_stmt|;
specifier|private
specifier|final
name|FilterWrapper
name|filter
decl_stmt|;
annotation|@
name|Override
specifier|public
name|RegionInfo
name|getRegionInfo
parameter_list|()
block|{
return|return
name|region
operator|.
name|getRegionInfo
argument_list|()
return|;
block|}
name|RegionScannerImpl
parameter_list|(
name|Scan
name|scan
parameter_list|,
name|List
argument_list|<
name|KeyValueScanner
argument_list|>
name|additionalScanners
parameter_list|,
name|HRegion
name|region
parameter_list|)
throws|throws
name|IOException
block|{
name|this
argument_list|(
name|scan
argument_list|,
name|additionalScanners
argument_list|,
name|region
argument_list|,
name|HConstants
operator|.
name|NO_NONCE
argument_list|,
name|HConstants
operator|.
name|NO_NONCE
argument_list|)
expr_stmt|;
block|}
name|RegionScannerImpl
parameter_list|(
name|Scan
name|scan
parameter_list|,
name|List
argument_list|<
name|KeyValueScanner
argument_list|>
name|additionalScanners
parameter_list|,
name|HRegion
name|region
parameter_list|,
name|long
name|nonceGroup
parameter_list|,
name|long
name|nonce
parameter_list|)
throws|throws
name|IOException
block|{
name|this
operator|.
name|region
operator|=
name|region
expr_stmt|;
name|this
operator|.
name|maxResultSize
operator|=
name|scan
operator|.
name|getMaxResultSize
argument_list|()
expr_stmt|;
if|if
condition|(
name|scan
operator|.
name|hasFilter
argument_list|()
condition|)
block|{
name|this
operator|.
name|filter
operator|=
operator|new
name|FilterWrapper
argument_list|(
name|scan
operator|.
name|getFilter
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|this
operator|.
name|filter
operator|=
literal|null
expr_stmt|;
block|}
name|this
operator|.
name|comparator
operator|=
name|region
operator|.
name|getCellComparator
argument_list|()
expr_stmt|;
comment|/**        * By default, calls to next/nextRaw must enforce the batch limit. Thus, construct a default        * scanner context that can be used to enforce the batch limit in the event that a        * ScannerContext is not specified during an invocation of next/nextRaw        */
name|defaultScannerContext
operator|=
name|ScannerContext
operator|.
name|newBuilder
argument_list|()
operator|.
name|setBatchLimit
argument_list|(
name|scan
operator|.
name|getBatch
argument_list|()
argument_list|)
operator|.
name|build
argument_list|()
expr_stmt|;
name|this
operator|.
name|stopRow
operator|=
name|scan
operator|.
name|getStopRow
argument_list|()
expr_stmt|;
name|this
operator|.
name|includeStopRow
operator|=
name|scan
operator|.
name|includeStopRow
argument_list|()
expr_stmt|;
comment|// synchronize on scannerReadPoints so that nobody calculates
comment|// getSmallestReadPoint, before scannerReadPoints is updated.
name|IsolationLevel
name|isolationLevel
init|=
name|scan
operator|.
name|getIsolationLevel
argument_list|()
decl_stmt|;
name|long
name|mvccReadPoint
init|=
name|PackagePrivateFieldAccessor
operator|.
name|getMvccReadPoint
argument_list|(
name|scan
argument_list|)
decl_stmt|;
synchronized|synchronized
init|(
name|scannerReadPoints
init|)
block|{
if|if
condition|(
name|mvccReadPoint
operator|>
literal|0
condition|)
block|{
name|this
operator|.
name|readPt
operator|=
name|mvccReadPoint
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|nonce
operator|==
name|HConstants
operator|.
name|NO_NONCE
operator|||
name|rsServices
operator|==
literal|null
operator|||
name|rsServices
operator|.
name|getNonceManager
argument_list|()
operator|==
literal|null
condition|)
block|{
name|this
operator|.
name|readPt
operator|=
name|getReadPoint
argument_list|(
name|isolationLevel
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|this
operator|.
name|readPt
operator|=
name|rsServices
operator|.
name|getNonceManager
argument_list|()
operator|.
name|getMvccFromOperationContext
argument_list|(
name|nonceGroup
argument_list|,
name|nonce
argument_list|)
expr_stmt|;
block|}
name|scannerReadPoints
operator|.
name|put
argument_list|(
name|this
argument_list|,
name|this
operator|.
name|readPt
argument_list|)
expr_stmt|;
block|}
name|initializeScanners
argument_list|(
name|scan
argument_list|,
name|additionalScanners
argument_list|)
expr_stmt|;
block|}
specifier|protected
name|void
name|initializeScanners
parameter_list|(
name|Scan
name|scan
parameter_list|,
name|List
argument_list|<
name|KeyValueScanner
argument_list|>
name|additionalScanners
parameter_list|)
throws|throws
name|IOException
block|{
comment|// Here we separate all scanners into two lists - scanner that provide data required
comment|// by the filter to operate (scanners list) and all others (joinedScanners list).
name|List
argument_list|<
name|KeyValueScanner
argument_list|>
name|scanners
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
name|scan
operator|.
name|getFamilyMap
argument_list|()
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|KeyValueScanner
argument_list|>
name|joinedScanners
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
name|scan
operator|.
name|getFamilyMap
argument_list|()
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
comment|// Store all already instantiated scanners for exception handling
name|List
argument_list|<
name|KeyValueScanner
argument_list|>
name|instantiatedScanners
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
comment|// handle additionalScanners
if|if
condition|(
name|additionalScanners
operator|!=
literal|null
operator|&&
operator|!
name|additionalScanners
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|scanners
operator|.
name|addAll
argument_list|(
name|additionalScanners
argument_list|)
expr_stmt|;
name|instantiatedScanners
operator|.
name|addAll
argument_list|(
name|additionalScanners
argument_list|)
expr_stmt|;
block|}
try|try
block|{
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|byte
index|[]
argument_list|,
name|NavigableSet
argument_list|<
name|byte
index|[]
argument_list|>
argument_list|>
name|entry
range|:
name|scan
operator|.
name|getFamilyMap
argument_list|()
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|HStore
name|store
init|=
name|stores
operator|.
name|get
argument_list|(
name|entry
operator|.
name|getKey
argument_list|()
argument_list|)
decl_stmt|;
name|KeyValueScanner
name|scanner
init|=
name|store
operator|.
name|getScanner
argument_list|(
name|scan
argument_list|,
name|entry
operator|.
name|getValue
argument_list|()
argument_list|,
name|this
operator|.
name|readPt
argument_list|)
decl_stmt|;
name|instantiatedScanners
operator|.
name|add
argument_list|(
name|scanner
argument_list|)
expr_stmt|;
if|if
condition|(
name|this
operator|.
name|filter
operator|==
literal|null
operator|||
operator|!
name|scan
operator|.
name|doLoadColumnFamiliesOnDemand
argument_list|()
operator|||
name|this
operator|.
name|filter
operator|.
name|isFamilyEssential
argument_list|(
name|entry
operator|.
name|getKey
argument_list|()
argument_list|)
condition|)
block|{
name|scanners
operator|.
name|add
argument_list|(
name|scanner
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|joinedScanners
operator|.
name|add
argument_list|(
name|scanner
argument_list|)
expr_stmt|;
block|}
block|}
name|initializeKVHeap
argument_list|(
name|scanners
argument_list|,
name|joinedScanners
argument_list|,
name|region
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Throwable
name|t
parameter_list|)
block|{
throw|throw
name|handleException
argument_list|(
name|instantiatedScanners
argument_list|,
name|t
argument_list|)
throw|;
block|}
block|}
specifier|protected
name|void
name|initializeKVHeap
parameter_list|(
name|List
argument_list|<
name|KeyValueScanner
argument_list|>
name|scanners
parameter_list|,
name|List
argument_list|<
name|KeyValueScanner
argument_list|>
name|joinedScanners
parameter_list|,
name|HRegion
name|region
parameter_list|)
throws|throws
name|IOException
block|{
name|this
operator|.
name|storeHeap
operator|=
operator|new
name|KeyValueHeap
argument_list|(
name|scanners
argument_list|,
name|comparator
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|joinedScanners
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|this
operator|.
name|joinedHeap
operator|=
operator|new
name|KeyValueHeap
argument_list|(
name|joinedScanners
argument_list|,
name|comparator
argument_list|)
expr_stmt|;
block|}
block|}
specifier|private
name|IOException
name|handleException
parameter_list|(
name|List
argument_list|<
name|KeyValueScanner
argument_list|>
name|instantiatedScanners
parameter_list|,
name|Throwable
name|t
parameter_list|)
block|{
comment|// remove scaner read point before throw the exception
name|scannerReadPoints
operator|.
name|remove
argument_list|(
name|this
argument_list|)
expr_stmt|;
if|if
condition|(
name|storeHeap
operator|!=
literal|null
condition|)
block|{
name|storeHeap
operator|.
name|close
argument_list|()
expr_stmt|;
name|storeHeap
operator|=
literal|null
expr_stmt|;
if|if
condition|(
name|joinedHeap
operator|!=
literal|null
condition|)
block|{
name|joinedHeap
operator|.
name|close
argument_list|()
expr_stmt|;
name|joinedHeap
operator|=
literal|null
expr_stmt|;
block|}
block|}
else|else
block|{
comment|// close all already instantiated scanners before throwing the exception
for|for
control|(
name|KeyValueScanner
name|scanner
range|:
name|instantiatedScanners
control|)
block|{
name|scanner
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
block|}
return|return
name|t
operator|instanceof
name|IOException
condition|?
operator|(
name|IOException
operator|)
name|t
else|:
operator|new
name|IOException
argument_list|(
name|t
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|getMaxResultSize
parameter_list|()
block|{
return|return
name|maxResultSize
return|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|getMvccReadPoint
parameter_list|()
block|{
return|return
name|this
operator|.
name|readPt
return|;
block|}
annotation|@
name|Override
specifier|public
name|int
name|getBatch
parameter_list|()
block|{
return|return
name|this
operator|.
name|defaultScannerContext
operator|.
name|getBatchLimit
argument_list|()
return|;
block|}
comment|/**      * Reset both the filter and the old filter.      *      * @throws IOException in case a filter raises an I/O exception.      */
specifier|protected
name|void
name|resetFilters
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|filter
operator|!=
literal|null
condition|)
block|{
name|filter
operator|.
name|reset
argument_list|()
expr_stmt|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|next
parameter_list|(
name|List
argument_list|<
name|Cell
argument_list|>
name|outResults
parameter_list|)
throws|throws
name|IOException
block|{
comment|// apply the batching limit by default
return|return
name|next
argument_list|(
name|outResults
argument_list|,
name|defaultScannerContext
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
specifier|synchronized
name|boolean
name|next
parameter_list|(
name|List
argument_list|<
name|Cell
argument_list|>
name|outResults
parameter_list|,
name|ScannerContext
name|scannerContext
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|this
operator|.
name|filterClosed
condition|)
block|{
throw|throw
operator|new
name|UnknownScannerException
argument_list|(
literal|"Scanner was closed (timed out?) "
operator|+
literal|"after we renewed it. Could be caused by a very slow scanner "
operator|+
literal|"or a lengthy garbage collection"
argument_list|)
throw|;
block|}
name|startRegionOperation
argument_list|(
name|Operation
operator|.
name|SCAN
argument_list|)
expr_stmt|;
try|try
block|{
return|return
name|nextRaw
argument_list|(
name|outResults
argument_list|,
name|scannerContext
argument_list|)
return|;
block|}
finally|finally
block|{
name|closeRegionOperation
argument_list|(
name|Operation
operator|.
name|SCAN
argument_list|)
expr_stmt|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|nextRaw
parameter_list|(
name|List
argument_list|<
name|Cell
argument_list|>
name|outResults
parameter_list|)
throws|throws
name|IOException
block|{
comment|// Use the RegionScanner's context by default
return|return
name|nextRaw
argument_list|(
name|outResults
argument_list|,
name|defaultScannerContext
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|nextRaw
parameter_list|(
name|List
argument_list|<
name|Cell
argument_list|>
name|outResults
parameter_list|,
name|ScannerContext
name|scannerContext
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|storeHeap
operator|==
literal|null
condition|)
block|{
comment|// scanner is closed
throw|throw
operator|new
name|UnknownScannerException
argument_list|(
literal|"Scanner was closed"
argument_list|)
throw|;
block|}
name|boolean
name|moreValues
init|=
literal|false
decl_stmt|;
if|if
condition|(
name|outResults
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
comment|// Usually outResults is empty. This is true when next is called
comment|// to handle scan or get operation.
name|moreValues
operator|=
name|nextInternal
argument_list|(
name|outResults
argument_list|,
name|scannerContext
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|List
argument_list|<
name|Cell
argument_list|>
name|tmpList
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
name|moreValues
operator|=
name|nextInternal
argument_list|(
name|tmpList
argument_list|,
name|scannerContext
argument_list|)
expr_stmt|;
name|outResults
operator|.
name|addAll
argument_list|(
name|tmpList
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|!
name|outResults
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|readRequestsCount
operator|.
name|increment
argument_list|()
expr_stmt|;
block|}
comment|// If the size limit was reached it means a partial Result is being returned. Returning a
comment|// partial Result means that we should not reset the filters; filters should only be reset in
comment|// between rows
if|if
condition|(
operator|!
name|scannerContext
operator|.
name|mayHaveMoreCellsInRow
argument_list|()
condition|)
block|{
name|resetFilters
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|isFilterDoneInternal
argument_list|()
condition|)
block|{
name|moreValues
operator|=
literal|false
expr_stmt|;
block|}
return|return
name|moreValues
return|;
block|}
comment|/**      * @return true if more cells exist after this batch, false if scanner is done      */
specifier|private
name|boolean
name|populateFromJoinedHeap
parameter_list|(
name|List
argument_list|<
name|Cell
argument_list|>
name|results
parameter_list|,
name|ScannerContext
name|scannerContext
parameter_list|)
throws|throws
name|IOException
block|{
assert|assert
name|joinedContinuationRow
operator|!=
literal|null
assert|;
name|boolean
name|moreValues
init|=
name|populateResult
argument_list|(
name|results
argument_list|,
name|this
operator|.
name|joinedHeap
argument_list|,
name|scannerContext
argument_list|,
name|joinedContinuationRow
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|scannerContext
operator|.
name|checkAnyLimitReached
argument_list|(
name|LimitScope
operator|.
name|BETWEEN_CELLS
argument_list|)
condition|)
block|{
comment|// We are done with this row, reset the continuation.
name|joinedContinuationRow
operator|=
literal|null
expr_stmt|;
block|}
comment|// As the data is obtained from two independent heaps, we need to
comment|// ensure that result list is sorted, because Result relies on that.
name|sort
argument_list|(
name|results
argument_list|,
name|comparator
argument_list|)
expr_stmt|;
return|return
name|moreValues
return|;
block|}
comment|/**      * Fetches records with currentRow into results list, until next row, batchLimit (if not -1) is      * reached, or remainingResultSize (if not -1) is reaced      * @param heap KeyValueHeap to fetch data from.It must be positioned on correct row before call.      * @param scannerContext      * @param currentRowCell      * @return state of last call to {@link KeyValueHeap#next()}      */
specifier|private
name|boolean
name|populateResult
parameter_list|(
name|List
argument_list|<
name|Cell
argument_list|>
name|results
parameter_list|,
name|KeyValueHeap
name|heap
parameter_list|,
name|ScannerContext
name|scannerContext
parameter_list|,
name|Cell
name|currentRowCell
parameter_list|)
throws|throws
name|IOException
block|{
name|Cell
name|nextKv
decl_stmt|;
name|boolean
name|moreCellsInRow
init|=
literal|false
decl_stmt|;
name|boolean
name|tmpKeepProgress
init|=
name|scannerContext
operator|.
name|getKeepProgress
argument_list|()
decl_stmt|;
comment|// Scanning between column families and thus the scope is between cells
name|LimitScope
name|limitScope
init|=
name|LimitScope
operator|.
name|BETWEEN_CELLS
decl_stmt|;
do|do
block|{
comment|// We want to maintain any progress that is made towards the limits while scanning across
comment|// different column families. To do this, we toggle the keep progress flag on during calls
comment|// to the StoreScanner to ensure that any progress made thus far is not wiped away.
name|scannerContext
operator|.
name|setKeepProgress
argument_list|(
literal|true
argument_list|)
expr_stmt|;
name|heap
operator|.
name|next
argument_list|(
name|results
argument_list|,
name|scannerContext
argument_list|)
expr_stmt|;
name|scannerContext
operator|.
name|setKeepProgress
argument_list|(
name|tmpKeepProgress
argument_list|)
expr_stmt|;
name|nextKv
operator|=
name|heap
operator|.
name|peek
argument_list|()
expr_stmt|;
name|moreCellsInRow
operator|=
name|moreCellsInRow
argument_list|(
name|nextKv
argument_list|,
name|currentRowCell
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|moreCellsInRow
condition|)
name|incrementCountOfRowsScannedMetric
argument_list|(
name|scannerContext
argument_list|)
expr_stmt|;
if|if
condition|(
name|moreCellsInRow
operator|&&
name|scannerContext
operator|.
name|checkBatchLimit
argument_list|(
name|limitScope
argument_list|)
condition|)
block|{
return|return
name|scannerContext
operator|.
name|setScannerState
argument_list|(
name|NextState
operator|.
name|BATCH_LIMIT_REACHED
argument_list|)
operator|.
name|hasMoreValues
argument_list|()
return|;
block|}
elseif|else
if|if
condition|(
name|scannerContext
operator|.
name|checkSizeLimit
argument_list|(
name|limitScope
argument_list|)
condition|)
block|{
name|ScannerContext
operator|.
name|NextState
name|state
init|=
name|moreCellsInRow
condition|?
name|NextState
operator|.
name|SIZE_LIMIT_REACHED_MID_ROW
else|:
name|NextState
operator|.
name|SIZE_LIMIT_REACHED
decl_stmt|;
return|return
name|scannerContext
operator|.
name|setScannerState
argument_list|(
name|state
argument_list|)
operator|.
name|hasMoreValues
argument_list|()
return|;
block|}
elseif|else
if|if
condition|(
name|scannerContext
operator|.
name|checkTimeLimit
argument_list|(
name|limitScope
argument_list|)
condition|)
block|{
name|ScannerContext
operator|.
name|NextState
name|state
init|=
name|moreCellsInRow
condition|?
name|NextState
operator|.
name|TIME_LIMIT_REACHED_MID_ROW
else|:
name|NextState
operator|.
name|TIME_LIMIT_REACHED
decl_stmt|;
return|return
name|scannerContext
operator|.
name|setScannerState
argument_list|(
name|state
argument_list|)
operator|.
name|hasMoreValues
argument_list|()
return|;
block|}
block|}
do|while
condition|(
name|moreCellsInRow
condition|)
do|;
return|return
name|nextKv
operator|!=
literal|null
return|;
block|}
comment|/**      * Based on the nextKv in the heap, and the current row, decide whether or not there are more      * cells to be read in the heap. If the row of the nextKv in the heap matches the current row      * then there are more cells to be read in the row.      * @param nextKv      * @param currentRowCell      * @return true When there are more cells in the row to be read      */
specifier|private
name|boolean
name|moreCellsInRow
parameter_list|(
specifier|final
name|Cell
name|nextKv
parameter_list|,
name|Cell
name|currentRowCell
parameter_list|)
block|{
return|return
name|nextKv
operator|!=
literal|null
operator|&&
name|CellUtil
operator|.
name|matchingRows
argument_list|(
name|nextKv
argument_list|,
name|currentRowCell
argument_list|)
return|;
block|}
comment|/*      * @return True if a filter rules the scanner is over, done.      */
annotation|@
name|Override
specifier|public
specifier|synchronized
name|boolean
name|isFilterDone
parameter_list|()
throws|throws
name|IOException
block|{
return|return
name|isFilterDoneInternal
argument_list|()
return|;
block|}
specifier|private
name|boolean
name|isFilterDoneInternal
parameter_list|()
throws|throws
name|IOException
block|{
return|return
name|this
operator|.
name|filter
operator|!=
literal|null
operator|&&
name|this
operator|.
name|filter
operator|.
name|filterAllRemaining
argument_list|()
return|;
block|}
specifier|private
name|boolean
name|nextInternal
parameter_list|(
name|List
argument_list|<
name|Cell
argument_list|>
name|results
parameter_list|,
name|ScannerContext
name|scannerContext
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
operator|!
name|results
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"First parameter should be an empty list"
argument_list|)
throw|;
block|}
if|if
condition|(
name|scannerContext
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"Scanner context cannot be null"
argument_list|)
throw|;
block|}
name|Optional
argument_list|<
name|RpcCall
argument_list|>
name|rpcCall
init|=
name|RpcServer
operator|.
name|getCurrentCall
argument_list|()
decl_stmt|;
comment|// Save the initial progress from the Scanner context in these local variables. The progress
comment|// may need to be reset a few times if rows are being filtered out so we save the initial
comment|// progress.
name|int
name|initialBatchProgress
init|=
name|scannerContext
operator|.
name|getBatchProgress
argument_list|()
decl_stmt|;
name|long
name|initialSizeProgress
init|=
name|scannerContext
operator|.
name|getDataSizeProgress
argument_list|()
decl_stmt|;
name|long
name|initialHeapSizeProgress
init|=
name|scannerContext
operator|.
name|getHeapSizeProgress
argument_list|()
decl_stmt|;
comment|// Used to check time limit
name|LimitScope
name|limitScope
init|=
name|LimitScope
operator|.
name|BETWEEN_CELLS
decl_stmt|;
comment|// The loop here is used only when at some point during the next we determine
comment|// that due to effects of filters or otherwise, we have an empty row in the result.
comment|// Then we loop and try again. Otherwise, we must get out on the first iteration via return,
comment|// "true" if there's more data to read, "false" if there isn't (storeHeap is at a stop row,
comment|// and joinedHeap has no more data to read for the last row (if set, joinedContinuationRow).
while|while
condition|(
literal|true
condition|)
block|{
comment|// Starting to scan a new row. Reset the scanner progress according to whether or not
comment|// progress should be kept.
if|if
condition|(
name|scannerContext
operator|.
name|getKeepProgress
argument_list|()
condition|)
block|{
comment|// Progress should be kept. Reset to initial values seen at start of method invocation.
name|scannerContext
operator|.
name|setProgress
argument_list|(
name|initialBatchProgress
argument_list|,
name|initialSizeProgress
argument_list|,
name|initialHeapSizeProgress
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|scannerContext
operator|.
name|clearProgress
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|rpcCall
operator|.
name|isPresent
argument_list|()
condition|)
block|{
comment|// If a user specifies a too-restrictive or too-slow scanner, the
comment|// client might time out and disconnect while the server side
comment|// is still processing the request. We should abort aggressively
comment|// in that case.
name|long
name|afterTime
init|=
name|rpcCall
operator|.
name|get
argument_list|()
operator|.
name|disconnectSince
argument_list|()
decl_stmt|;
if|if
condition|(
name|afterTime
operator|>=
literal|0
condition|)
block|{
throw|throw
operator|new
name|CallerDisconnectedException
argument_list|(
literal|"Aborting on region "
operator|+
name|getRegionInfo
argument_list|()
operator|.
name|getRegionNameAsString
argument_list|()
operator|+
literal|", call "
operator|+
name|this
operator|+
literal|" after "
operator|+
name|afterTime
operator|+
literal|" ms, since "
operator|+
literal|"caller disconnected"
argument_list|)
throw|;
block|}
block|}
comment|// Let's see what we have in the storeHeap.
name|Cell
name|current
init|=
name|this
operator|.
name|storeHeap
operator|.
name|peek
argument_list|()
decl_stmt|;
name|boolean
name|shouldStop
init|=
name|shouldStop
argument_list|(
name|current
argument_list|)
decl_stmt|;
comment|// When has filter row is true it means that the all the cells for a particular row must be
comment|// read before a filtering decision can be made. This means that filters where hasFilterRow
comment|// run the risk of enLongAddering out of memory errors in the case that they are applied to a
comment|// table that has very large rows.
name|boolean
name|hasFilterRow
init|=
name|this
operator|.
name|filter
operator|!=
literal|null
operator|&&
name|this
operator|.
name|filter
operator|.
name|hasFilterRow
argument_list|()
decl_stmt|;
comment|// If filter#hasFilterRow is true, partial results are not allowed since allowing them
comment|// would prevent the filters from being evaluated. Thus, if it is true, change the
comment|// scope of any limits that could potentially create partial results to
comment|// LimitScope.BETWEEN_ROWS so that those limits are not reached mid-row
if|if
condition|(
name|hasFilterRow
condition|)
block|{
if|if
condition|(
name|LOG
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|trace
argument_list|(
literal|"filter#hasFilterRow is true which prevents partial results from being "
operator|+
literal|" formed. Changing scope of limits that may create partials"
argument_list|)
expr_stmt|;
block|}
name|scannerContext
operator|.
name|setSizeLimitScope
argument_list|(
name|LimitScope
operator|.
name|BETWEEN_ROWS
argument_list|)
expr_stmt|;
name|scannerContext
operator|.
name|setTimeLimitScope
argument_list|(
name|LimitScope
operator|.
name|BETWEEN_ROWS
argument_list|)
expr_stmt|;
name|limitScope
operator|=
name|LimitScope
operator|.
name|BETWEEN_ROWS
expr_stmt|;
block|}
if|if
condition|(
name|scannerContext
operator|.
name|checkTimeLimit
argument_list|(
name|LimitScope
operator|.
name|BETWEEN_CELLS
argument_list|)
condition|)
block|{
if|if
condition|(
name|hasFilterRow
condition|)
block|{
throw|throw
operator|new
name|IncompatibleFilterException
argument_list|(
literal|"Filter whose hasFilterRow() returns true is incompatible with scans that must "
operator|+
literal|" stop mid-row because of a limit. ScannerContext:"
operator|+
name|scannerContext
argument_list|)
throw|;
block|}
return|return
literal|true
return|;
block|}
comment|// Check if we were getting data from the joinedHeap and hit the limit.
comment|// If not, then it's main path - getting results from storeHeap.
if|if
condition|(
name|joinedContinuationRow
operator|==
literal|null
condition|)
block|{
comment|// First, check if we are at a stop row. If so, there are no more results.
if|if
condition|(
name|shouldStop
condition|)
block|{
if|if
condition|(
name|hasFilterRow
condition|)
block|{
name|filter
operator|.
name|filterRowCells
argument_list|(
name|results
argument_list|)
expr_stmt|;
block|}
return|return
name|scannerContext
operator|.
name|setScannerState
argument_list|(
name|NextState
operator|.
name|NO_MORE_VALUES
argument_list|)
operator|.
name|hasMoreValues
argument_list|()
return|;
block|}
comment|// Check if rowkey filter wants to exclude this row. If so, loop to next.
comment|// Technically, if we hit limits before on this row, we don't need this call.
if|if
condition|(
name|filterRowKey
argument_list|(
name|current
argument_list|)
condition|)
block|{
name|incrementCountOfRowsFilteredMetric
argument_list|(
name|scannerContext
argument_list|)
expr_stmt|;
comment|// early check, see HBASE-16296
if|if
condition|(
name|isFilterDoneInternal
argument_list|()
condition|)
block|{
return|return
name|scannerContext
operator|.
name|setScannerState
argument_list|(
name|NextState
operator|.
name|NO_MORE_VALUES
argument_list|)
operator|.
name|hasMoreValues
argument_list|()
return|;
block|}
comment|// Typically the count of rows scanned is incremented inside #populateResult. However,
comment|// here we are filtering a row based purely on its row key, preventing us from calling
comment|// #populateResult. Thus, perform the necessary increment here to rows scanned metric
name|incrementCountOfRowsScannedMetric
argument_list|(
name|scannerContext
argument_list|)
expr_stmt|;
name|boolean
name|moreRows
init|=
name|nextRow
argument_list|(
name|scannerContext
argument_list|,
name|current
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|moreRows
condition|)
block|{
return|return
name|scannerContext
operator|.
name|setScannerState
argument_list|(
name|NextState
operator|.
name|NO_MORE_VALUES
argument_list|)
operator|.
name|hasMoreValues
argument_list|()
return|;
block|}
name|results
operator|.
name|clear
argument_list|()
expr_stmt|;
comment|// Read nothing as the rowkey was filtered, but still need to check time limit
if|if
condition|(
name|scannerContext
operator|.
name|checkTimeLimit
argument_list|(
name|limitScope
argument_list|)
condition|)
block|{
return|return
literal|true
return|;
block|}
continue|continue;
block|}
comment|// Ok, we are good, let's try to get some results from the main heap.
name|populateResult
argument_list|(
name|results
argument_list|,
name|this
operator|.
name|storeHeap
argument_list|,
name|scannerContext
argument_list|,
name|current
argument_list|)
expr_stmt|;
if|if
condition|(
name|scannerContext
operator|.
name|checkAnyLimitReached
argument_list|(
name|LimitScope
operator|.
name|BETWEEN_CELLS
argument_list|)
condition|)
block|{
if|if
condition|(
name|hasFilterRow
condition|)
block|{
throw|throw
operator|new
name|IncompatibleFilterException
argument_list|(
literal|"Filter whose hasFilterRow() returns true is incompatible with scans that must "
operator|+
literal|" stop mid-row because of a limit. ScannerContext:"
operator|+
name|scannerContext
argument_list|)
throw|;
block|}
return|return
literal|true
return|;
block|}
name|Cell
name|nextKv
init|=
name|this
operator|.
name|storeHeap
operator|.
name|peek
argument_list|()
decl_stmt|;
name|shouldStop
operator|=
name|shouldStop
argument_list|(
name|nextKv
argument_list|)
expr_stmt|;
comment|// save that the row was empty before filters applied to it.
specifier|final
name|boolean
name|isEmptyRow
init|=
name|results
operator|.
name|isEmpty
argument_list|()
decl_stmt|;
comment|// We have the part of the row necessary for filtering (all of it, usually).
comment|// First filter with the filterRow(List).
name|FilterWrapper
operator|.
name|FilterRowRetCode
name|ret
init|=
name|FilterWrapper
operator|.
name|FilterRowRetCode
operator|.
name|NOT_CALLED
decl_stmt|;
if|if
condition|(
name|hasFilterRow
condition|)
block|{
name|ret
operator|=
name|filter
operator|.
name|filterRowCellsWithRet
argument_list|(
name|results
argument_list|)
expr_stmt|;
comment|// We don't know how the results have changed after being filtered. Must set progress
comment|// according to contents of results now.
if|if
condition|(
name|scannerContext
operator|.
name|getKeepProgress
argument_list|()
condition|)
block|{
name|scannerContext
operator|.
name|setProgress
argument_list|(
name|initialBatchProgress
argument_list|,
name|initialSizeProgress
argument_list|,
name|initialHeapSizeProgress
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|scannerContext
operator|.
name|clearProgress
argument_list|()
expr_stmt|;
block|}
name|scannerContext
operator|.
name|incrementBatchProgress
argument_list|(
name|results
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
for|for
control|(
name|Cell
name|cell
range|:
name|results
control|)
block|{
name|scannerContext
operator|.
name|incrementSizeProgress
argument_list|(
name|PrivateCellUtil
operator|.
name|estimatedSerializedSizeOf
argument_list|(
name|cell
argument_list|)
argument_list|,
name|PrivateCellUtil
operator|.
name|estimatedSizeOfCell
argument_list|(
name|cell
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|isEmptyRow
operator|||
name|ret
operator|==
name|FilterWrapper
operator|.
name|FilterRowRetCode
operator|.
name|EXCLUDE
operator|||
name|filterRow
argument_list|()
condition|)
block|{
name|incrementCountOfRowsFilteredMetric
argument_list|(
name|scannerContext
argument_list|)
expr_stmt|;
name|results
operator|.
name|clear
argument_list|()
expr_stmt|;
name|boolean
name|moreRows
init|=
name|nextRow
argument_list|(
name|scannerContext
argument_list|,
name|current
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|moreRows
condition|)
block|{
return|return
name|scannerContext
operator|.
name|setScannerState
argument_list|(
name|NextState
operator|.
name|NO_MORE_VALUES
argument_list|)
operator|.
name|hasMoreValues
argument_list|()
return|;
block|}
comment|// This row was totally filtered out, if this is NOT the last row,
comment|// we should continue on. Otherwise, nothing else to do.
if|if
condition|(
operator|!
name|shouldStop
condition|)
block|{
comment|// Read nothing as the cells was filtered, but still need to check time limit
if|if
condition|(
name|scannerContext
operator|.
name|checkTimeLimit
argument_list|(
name|limitScope
argument_list|)
condition|)
block|{
return|return
literal|true
return|;
block|}
continue|continue;
block|}
return|return
name|scannerContext
operator|.
name|setScannerState
argument_list|(
name|NextState
operator|.
name|NO_MORE_VALUES
argument_list|)
operator|.
name|hasMoreValues
argument_list|()
return|;
block|}
comment|// Ok, we are done with storeHeap for this row.
comment|// Now we may need to fetch additional, non-essential data into row.
comment|// These values are not needed for filter to work, so we postpone their
comment|// fetch to (possibly) reduce amount of data loads from disk.
if|if
condition|(
name|this
operator|.
name|joinedHeap
operator|!=
literal|null
condition|)
block|{
name|boolean
name|mayHaveData
init|=
name|joinedHeapMayHaveData
argument_list|(
name|current
argument_list|)
decl_stmt|;
if|if
condition|(
name|mayHaveData
condition|)
block|{
name|joinedContinuationRow
operator|=
name|current
expr_stmt|;
name|populateFromJoinedHeap
argument_list|(
name|results
argument_list|,
name|scannerContext
argument_list|)
expr_stmt|;
if|if
condition|(
name|scannerContext
operator|.
name|checkAnyLimitReached
argument_list|(
name|LimitScope
operator|.
name|BETWEEN_CELLS
argument_list|)
condition|)
block|{
return|return
literal|true
return|;
block|}
block|}
block|}
block|}
else|else
block|{
comment|// Populating from the joined heap was stopped by limits, populate some more.
name|populateFromJoinedHeap
argument_list|(
name|results
argument_list|,
name|scannerContext
argument_list|)
expr_stmt|;
if|if
condition|(
name|scannerContext
operator|.
name|checkAnyLimitReached
argument_list|(
name|LimitScope
operator|.
name|BETWEEN_CELLS
argument_list|)
condition|)
block|{
return|return
literal|true
return|;
block|}
block|}
comment|// We may have just called populateFromJoinedMap and hit the limits. If that is
comment|// the case, we need to call it again on the next next() invocation.
if|if
condition|(
name|joinedContinuationRow
operator|!=
literal|null
condition|)
block|{
return|return
name|scannerContext
operator|.
name|setScannerState
argument_list|(
name|NextState
operator|.
name|MORE_VALUES
argument_list|)
operator|.
name|hasMoreValues
argument_list|()
return|;
block|}
comment|// Finally, we are done with both joinedHeap and storeHeap.
comment|// Double check to prevent empty rows from appearing in result. It could be
comment|// the case when SingleColumnValueExcludeFilter is used.
if|if
condition|(
name|results
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|incrementCountOfRowsFilteredMetric
argument_list|(
name|scannerContext
argument_list|)
expr_stmt|;
name|boolean
name|moreRows
init|=
name|nextRow
argument_list|(
name|scannerContext
argument_list|,
name|current
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|moreRows
condition|)
block|{
return|return
name|scannerContext
operator|.
name|setScannerState
argument_list|(
name|NextState
operator|.
name|NO_MORE_VALUES
argument_list|)
operator|.
name|hasMoreValues
argument_list|()
return|;
block|}
if|if
condition|(
operator|!
name|shouldStop
condition|)
continue|continue;
block|}
if|if
condition|(
name|shouldStop
condition|)
block|{
return|return
name|scannerContext
operator|.
name|setScannerState
argument_list|(
name|NextState
operator|.
name|NO_MORE_VALUES
argument_list|)
operator|.
name|hasMoreValues
argument_list|()
return|;
block|}
else|else
block|{
return|return
name|scannerContext
operator|.
name|setScannerState
argument_list|(
name|NextState
operator|.
name|MORE_VALUES
argument_list|)
operator|.
name|hasMoreValues
argument_list|()
return|;
block|}
block|}
block|}
specifier|protected
name|void
name|incrementCountOfRowsFilteredMetric
parameter_list|(
name|ScannerContext
name|scannerContext
parameter_list|)
block|{
name|filteredReadRequestsCount
operator|.
name|increment
argument_list|()
expr_stmt|;
if|if
condition|(
name|scannerContext
operator|==
literal|null
operator|||
operator|!
name|scannerContext
operator|.
name|isTrackingMetrics
argument_list|()
condition|)
return|return;
name|scannerContext
operator|.
name|getMetrics
argument_list|()
operator|.
name|countOfRowsFiltered
operator|.
name|incrementAndGet
argument_list|()
expr_stmt|;
block|}
specifier|protected
name|void
name|incrementCountOfRowsScannedMetric
parameter_list|(
name|ScannerContext
name|scannerContext
parameter_list|)
block|{
if|if
condition|(
name|scannerContext
operator|==
literal|null
operator|||
operator|!
name|scannerContext
operator|.
name|isTrackingMetrics
argument_list|()
condition|)
return|return;
name|scannerContext
operator|.
name|getMetrics
argument_list|()
operator|.
name|countOfRowsScanned
operator|.
name|incrementAndGet
argument_list|()
expr_stmt|;
block|}
comment|/**      * @param currentRowCell      * @return true when the joined heap may have data for the current row      * @throws IOException      */
specifier|private
name|boolean
name|joinedHeapMayHaveData
parameter_list|(
name|Cell
name|currentRowCell
parameter_list|)
throws|throws
name|IOException
block|{
name|Cell
name|nextJoinedKv
init|=
name|joinedHeap
operator|.
name|peek
argument_list|()
decl_stmt|;
name|boolean
name|matchCurrentRow
init|=
name|nextJoinedKv
operator|!=
literal|null
operator|&&
name|CellUtil
operator|.
name|matchingRows
argument_list|(
name|nextJoinedKv
argument_list|,
name|currentRowCell
argument_list|)
decl_stmt|;
name|boolean
name|matchAfterSeek
init|=
literal|false
decl_stmt|;
comment|// If the next value in the joined heap does not match the current row, try to seek to the
comment|// correct row
if|if
condition|(
operator|!
name|matchCurrentRow
condition|)
block|{
name|Cell
name|firstOnCurrentRow
init|=
name|PrivateCellUtil
operator|.
name|createFirstOnRow
argument_list|(
name|currentRowCell
argument_list|)
decl_stmt|;
name|boolean
name|seekSuccessful
init|=
name|this
operator|.
name|joinedHeap
operator|.
name|requestSeek
argument_list|(
name|firstOnCurrentRow
argument_list|,
literal|true
argument_list|,
literal|true
argument_list|)
decl_stmt|;
name|matchAfterSeek
operator|=
name|seekSuccessful
operator|&&
name|joinedHeap
operator|.
name|peek
argument_list|()
operator|!=
literal|null
operator|&&
name|CellUtil
operator|.
name|matchingRows
argument_list|(
name|joinedHeap
operator|.
name|peek
argument_list|()
argument_list|,
name|currentRowCell
argument_list|)
expr_stmt|;
block|}
return|return
name|matchCurrentRow
operator|||
name|matchAfterSeek
return|;
block|}
comment|/**      * This function is to maintain backward compatibility for 0.94 filters. HBASE-6429 combines      * both filterRow& filterRow({@code List<KeyValue> kvs}) functions. While 0.94 code or older,      * it may not implement hasFilterRow as HBase-6429 expects because 0.94 hasFilterRow() only      * returns true when filterRow({@code List<KeyValue> kvs}) is overridden not the filterRow().      * Therefore, the filterRow() will be skipped.      */
specifier|private
name|boolean
name|filterRow
parameter_list|()
throws|throws
name|IOException
block|{
comment|// when hasFilterRow returns true, filter.filterRow() will be called automatically inside
comment|// filterRowCells(List<Cell> kvs) so we skip that scenario here.
return|return
name|filter
operator|!=
literal|null
operator|&&
operator|(
operator|!
name|filter
operator|.
name|hasFilterRow
argument_list|()
operator|)
operator|&&
name|filter
operator|.
name|filterRow
argument_list|()
return|;
block|}
specifier|private
name|boolean
name|filterRowKey
parameter_list|(
name|Cell
name|current
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|filter
operator|!=
literal|null
operator|&&
name|filter
operator|.
name|filterRowKey
argument_list|(
name|current
argument_list|)
return|;
block|}
specifier|protected
name|boolean
name|nextRow
parameter_list|(
name|ScannerContext
name|scannerContext
parameter_list|,
name|Cell
name|curRowCell
parameter_list|)
throws|throws
name|IOException
block|{
assert|assert
name|this
operator|.
name|joinedContinuationRow
operator|==
literal|null
operator|:
literal|"Trying to go to next row during joinedHeap read."
assert|;
name|Cell
name|next
decl_stmt|;
while|while
condition|(
operator|(
name|next
operator|=
name|this
operator|.
name|storeHeap
operator|.
name|peek
argument_list|()
operator|)
operator|!=
literal|null
operator|&&
name|CellUtil
operator|.
name|matchingRows
argument_list|(
name|next
argument_list|,
name|curRowCell
argument_list|)
condition|)
block|{
name|this
operator|.
name|storeHeap
operator|.
name|next
argument_list|(
name|MOCKED_LIST
argument_list|)
expr_stmt|;
block|}
name|resetFilters
argument_list|()
expr_stmt|;
comment|// Calling the hook in CP which allows it to do a fast forward
return|return
name|this
operator|.
name|region
operator|.
name|getCoprocessorHost
argument_list|()
operator|==
literal|null
operator|||
name|this
operator|.
name|region
operator|.
name|getCoprocessorHost
argument_list|()
operator|.
name|postScannerFilterRow
argument_list|(
name|this
argument_list|,
name|curRowCell
argument_list|)
return|;
block|}
specifier|protected
name|boolean
name|shouldStop
parameter_list|(
name|Cell
name|currentRowCell
parameter_list|)
block|{
if|if
condition|(
name|currentRowCell
operator|==
literal|null
condition|)
block|{
return|return
literal|true
return|;
block|}
if|if
condition|(
name|stopRow
operator|==
literal|null
operator|||
name|Bytes
operator|.
name|equals
argument_list|(
name|stopRow
argument_list|,
name|HConstants
operator|.
name|EMPTY_END_ROW
argument_list|)
condition|)
block|{
return|return
literal|false
return|;
block|}
name|int
name|c
init|=
name|comparator
operator|.
name|compareRows
argument_list|(
name|currentRowCell
argument_list|,
name|stopRow
argument_list|,
literal|0
argument_list|,
name|stopRow
operator|.
name|length
argument_list|)
decl_stmt|;
return|return
name|c
operator|>
literal|0
operator|||
operator|(
name|c
operator|==
literal|0
operator|&&
operator|!
name|includeStopRow
operator|)
return|;
block|}
annotation|@
name|Override
specifier|public
specifier|synchronized
name|void
name|close
parameter_list|()
block|{
if|if
condition|(
name|storeHeap
operator|!=
literal|null
condition|)
block|{
name|storeHeap
operator|.
name|close
argument_list|()
expr_stmt|;
name|storeHeap
operator|=
literal|null
expr_stmt|;
block|}
if|if
condition|(
name|joinedHeap
operator|!=
literal|null
condition|)
block|{
name|joinedHeap
operator|.
name|close
argument_list|()
expr_stmt|;
name|joinedHeap
operator|=
literal|null
expr_stmt|;
block|}
comment|// no need to synchronize here.
name|scannerReadPoints
operator|.
name|remove
argument_list|(
name|this
argument_list|)
expr_stmt|;
name|this
operator|.
name|filterClosed
operator|=
literal|true
expr_stmt|;
block|}
name|KeyValueHeap
name|getStoreHeapForTesting
parameter_list|()
block|{
return|return
name|storeHeap
return|;
block|}
annotation|@
name|Override
specifier|public
specifier|synchronized
name|boolean
name|reseek
parameter_list|(
name|byte
index|[]
name|row
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|row
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"Row cannot be null."
argument_list|)
throw|;
block|}
name|boolean
name|result
init|=
literal|false
decl_stmt|;
name|startRegionOperation
argument_list|()
expr_stmt|;
name|Cell
name|kv
init|=
name|PrivateCellUtil
operator|.
name|createFirstOnRow
argument_list|(
name|row
argument_list|,
literal|0
argument_list|,
operator|(
name|short
operator|)
name|row
operator|.
name|length
argument_list|)
decl_stmt|;
try|try
block|{
comment|// use request seek to make use of the lazy seek option. See HBASE-5520
name|result
operator|=
name|this
operator|.
name|storeHeap
operator|.
name|requestSeek
argument_list|(
name|kv
argument_list|,
literal|true
argument_list|,
literal|true
argument_list|)
expr_stmt|;
if|if
condition|(
name|this
operator|.
name|joinedHeap
operator|!=
literal|null
condition|)
block|{
name|result
operator|=
name|this
operator|.
name|joinedHeap
operator|.
name|requestSeek
argument_list|(
name|kv
argument_list|,
literal|true
argument_list|,
literal|true
argument_list|)
operator|||
name|result
expr_stmt|;
block|}
block|}
finally|finally
block|{
name|closeRegionOperation
argument_list|()
expr_stmt|;
block|}
return|return
name|result
return|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|shipped
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|storeHeap
operator|!=
literal|null
condition|)
block|{
name|storeHeap
operator|.
name|shipped
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|joinedHeap
operator|!=
literal|null
condition|)
block|{
name|joinedHeap
operator|.
name|shipped
argument_list|()
expr_stmt|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|void
name|run
parameter_list|()
throws|throws
name|IOException
block|{
comment|// This is the RPC callback method executed. We do the close in of the scanner in this
comment|// callback
name|this
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
block|}
comment|// Utility methods
comment|/**    * A utility method to create new instances of HRegion based on the    * {@link HConstants#REGION_IMPL} configuration property.    * @param tableDir qualified path of directory where region should be located,    * usually the table directory.    * @param wal The WAL is the outbound log for any updates to the HRegion    * The wal file is a logfile from the previous execution that's    * custom-computed for this HRegion. The HRegionServer computes and sorts the    * appropriate wal info for this HRegion. If there is a previous file    * (implying that the HRegion has been written-to before), then read it from    * the supplied path.    * @param fs is the filesystem.    * @param conf is global configuration settings.    * @param regionInfo - RegionInfo that describes the region    * is new), then read them from the supplied path.    * @param htd the table descriptor    * @return the new instance    */
specifier|static
name|HRegion
name|newHRegion
parameter_list|(
name|Path
name|tableDir
parameter_list|,
name|WAL
name|wal
parameter_list|,
name|FileSystem
name|fs
parameter_list|,
name|Configuration
name|conf
parameter_list|,
name|RegionInfo
name|regionInfo
parameter_list|,
specifier|final
name|TableDescriptor
name|htd
parameter_list|,
name|RegionServerServices
name|rsServices
parameter_list|)
block|{
try|try
block|{
annotation|@
name|SuppressWarnings
argument_list|(
literal|"unchecked"
argument_list|)
name|Class
argument_list|<
name|?
extends|extends
name|HRegion
argument_list|>
name|regionClass
init|=
operator|(
name|Class
argument_list|<
name|?
extends|extends
name|HRegion
argument_list|>
operator|)
name|conf
operator|.
name|getClass
argument_list|(
name|HConstants
operator|.
name|REGION_IMPL
argument_list|,
name|HRegion
operator|.
name|class
argument_list|)
decl_stmt|;
name|Constructor
argument_list|<
name|?
extends|extends
name|HRegion
argument_list|>
name|c
init|=
name|regionClass
operator|.
name|getConstructor
argument_list|(
name|Path
operator|.
name|class
argument_list|,
name|WAL
operator|.
name|class
argument_list|,
name|FileSystem
operator|.
name|class
argument_list|,
name|Configuration
operator|.
name|class
argument_list|,
name|RegionInfo
operator|.
name|class
argument_list|,
name|TableDescriptor
operator|.
name|class
argument_list|,
name|RegionServerServices
operator|.
name|class
argument_list|)
decl_stmt|;
return|return
name|c
operator|.
name|newInstance
argument_list|(
name|tableDir
argument_list|,
name|wal
argument_list|,
name|fs
argument_list|,
name|conf
argument_list|,
name|regionInfo
argument_list|,
name|htd
argument_list|,
name|rsServices
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|Throwable
name|e
parameter_list|)
block|{
comment|// todo: what should I throw here?
throw|throw
operator|new
name|IllegalStateException
argument_list|(
literal|"Could not instantiate a region instance."
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
comment|/**    * Convenience method creating new HRegions. Used by createTable.    *    * @param info Info for region to create.    * @param rootDir Root directory for HBase instance    * @param wal shared WAL    * @param initialize - true to initialize the region    * @return new HRegion    * @throws IOException    */
specifier|public
specifier|static
name|HRegion
name|createHRegion
parameter_list|(
specifier|final
name|RegionInfo
name|info
parameter_list|,
specifier|final
name|Path
name|rootDir
parameter_list|,
specifier|final
name|Configuration
name|conf
parameter_list|,
specifier|final
name|TableDescriptor
name|hTableDescriptor
parameter_list|,
specifier|final
name|WAL
name|wal
parameter_list|,
specifier|final
name|boolean
name|initialize
parameter_list|)
throws|throws
name|IOException
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"creating HRegion "
operator|+
name|info
operator|.
name|getTable
argument_list|()
operator|.
name|getNameAsString
argument_list|()
operator|+
literal|" HTD == "
operator|+
name|hTableDescriptor
operator|+
literal|" RootDir = "
operator|+
name|rootDir
operator|+
literal|" Table name == "
operator|+
name|info
operator|.
name|getTable
argument_list|()
operator|.
name|getNameAsString
argument_list|()
argument_list|)
expr_stmt|;
name|FileSystem
name|fs
init|=
name|FileSystem
operator|.
name|get
argument_list|(
name|conf
argument_list|)
decl_stmt|;
name|Path
name|tableDir
init|=
name|FSUtils
operator|.
name|getTableDir
argument_list|(
name|rootDir
argument_list|,
name|info
operator|.
name|getTable
argument_list|()
argument_list|)
decl_stmt|;
name|HRegionFileSystem
operator|.
name|createRegionOnFileSystem
argument_list|(
name|conf
argument_list|,
name|fs
argument_list|,
name|tableDir
argument_list|,
name|info
argument_list|)
expr_stmt|;
name|HRegion
name|region
init|=
name|HRegion
operator|.
name|newHRegion
argument_list|(
name|tableDir
argument_list|,
name|wal
argument_list|,
name|fs
argument_list|,
name|conf
argument_list|,
name|info
argument_list|,
name|hTableDescriptor
argument_list|,
literal|null
argument_list|)
decl_stmt|;
if|if
condition|(
name|initialize
condition|)
name|region
operator|.
name|initialize
argument_list|(
literal|null
argument_list|)
expr_stmt|;
return|return
name|region
return|;
block|}
specifier|public
specifier|static
name|HRegion
name|createHRegion
parameter_list|(
specifier|final
name|RegionInfo
name|info
parameter_list|,
specifier|final
name|Path
name|rootDir
parameter_list|,
specifier|final
name|Configuration
name|conf
parameter_list|,
specifier|final
name|TableDescriptor
name|hTableDescriptor
parameter_list|,
specifier|final
name|WAL
name|wal
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|createHRegion
argument_list|(
name|info
argument_list|,
name|rootDir
argument_list|,
name|conf
argument_list|,
name|hTableDescriptor
argument_list|,
name|wal
argument_list|,
literal|true
argument_list|)
return|;
block|}
comment|/**    * Open a Region.    * @param info Info for region to be opened.    * @param wal WAL for region to use. This method will call    * WAL#setSequenceNumber(long) passing the result of the call to    * HRegion#getMinSequenceId() to ensure the wal id is properly kept    * up.  HRegionStore does this every time it opens a new region.    * @return new HRegion    *    * @throws IOException    */
specifier|public
specifier|static
name|HRegion
name|openHRegion
parameter_list|(
specifier|final
name|RegionInfo
name|info
parameter_list|,
specifier|final
name|TableDescriptor
name|htd
parameter_list|,
specifier|final
name|WAL
name|wal
parameter_list|,
specifier|final
name|Configuration
name|conf
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|openHRegion
argument_list|(
name|info
argument_list|,
name|htd
argument_list|,
name|wal
argument_list|,
name|conf
argument_list|,
literal|null
argument_list|,
literal|null
argument_list|)
return|;
block|}
comment|/**    * Open a Region.    * @param info Info for region to be opened    * @param htd the table descriptor    * @param wal WAL for region to use. This method will call    * WAL#setSequenceNumber(long) passing the result of the call to    * HRegion#getMinSequenceId() to ensure the wal id is properly kept    * up.  HRegionStore does this every time it opens a new region.    * @param conf The Configuration object to use.    * @param rsServices An interface we can request flushes against.    * @param reporter An interface we can report progress against.    * @return new HRegion    *    * @throws IOException    */
specifier|public
specifier|static
name|HRegion
name|openHRegion
parameter_list|(
specifier|final
name|RegionInfo
name|info
parameter_list|,
specifier|final
name|TableDescriptor
name|htd
parameter_list|,
specifier|final
name|WAL
name|wal
parameter_list|,
specifier|final
name|Configuration
name|conf
parameter_list|,
specifier|final
name|RegionServerServices
name|rsServices
parameter_list|,
specifier|final
name|CancelableProgressable
name|reporter
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|openHRegion
argument_list|(
name|FSUtils
operator|.
name|getRootDir
argument_list|(
name|conf
argument_list|)
argument_list|,
name|info
argument_list|,
name|htd
argument_list|,
name|wal
argument_list|,
name|conf
argument_list|,
name|rsServices
argument_list|,
name|reporter
argument_list|)
return|;
block|}
comment|/**    * Open a Region.    * @param rootDir Root directory for HBase instance    * @param info Info for region to be opened.    * @param htd the table descriptor    * @param wal WAL for region to use. This method will call    * WAL#setSequenceNumber(long) passing the result of the call to    * HRegion#getMinSequenceId() to ensure the wal id is properly kept    * up.  HRegionStore does this every time it opens a new region.    * @param conf The Configuration object to use.    * @return new HRegion    * @throws IOException    */
specifier|public
specifier|static
name|HRegion
name|openHRegion
parameter_list|(
name|Path
name|rootDir
parameter_list|,
specifier|final
name|RegionInfo
name|info
parameter_list|,
specifier|final
name|TableDescriptor
name|htd
parameter_list|,
specifier|final
name|WAL
name|wal
parameter_list|,
specifier|final
name|Configuration
name|conf
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|openHRegion
argument_list|(
name|rootDir
argument_list|,
name|info
argument_list|,
name|htd
argument_list|,
name|wal
argument_list|,
name|conf
argument_list|,
literal|null
argument_list|,
literal|null
argument_list|)
return|;
block|}
comment|/**    * Open a Region.    * @param rootDir Root directory for HBase instance    * @param info Info for region to be opened.    * @param htd the table descriptor    * @param wal WAL for region to use. This method will call    * WAL#setSequenceNumber(long) passing the result of the call to    * HRegion#getMinSequenceId() to ensure the wal id is properly kept    * up.  HRegionStore does this every time it opens a new region.    * @param conf The Configuration object to use.    * @param rsServices An interface we can request flushes against.    * @param reporter An interface we can report progress against.    * @return new HRegion    * @throws IOException    */
specifier|public
specifier|static
name|HRegion
name|openHRegion
parameter_list|(
specifier|final
name|Path
name|rootDir
parameter_list|,
specifier|final
name|RegionInfo
name|info
parameter_list|,
specifier|final
name|TableDescriptor
name|htd
parameter_list|,
specifier|final
name|WAL
name|wal
parameter_list|,
specifier|final
name|Configuration
name|conf
parameter_list|,
specifier|final
name|RegionServerServices
name|rsServices
parameter_list|,
specifier|final
name|CancelableProgressable
name|reporter
parameter_list|)
throws|throws
name|IOException
block|{
name|FileSystem
name|fs
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|rsServices
operator|!=
literal|null
condition|)
block|{
name|fs
operator|=
name|rsServices
operator|.
name|getFileSystem
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|fs
operator|==
literal|null
condition|)
block|{
name|fs
operator|=
name|FileSystem
operator|.
name|get
argument_list|(
name|conf
argument_list|)
expr_stmt|;
block|}
return|return
name|openHRegion
argument_list|(
name|conf
argument_list|,
name|fs
argument_list|,
name|rootDir
argument_list|,
name|info
argument_list|,
name|htd
argument_list|,
name|wal
argument_list|,
name|rsServices
argument_list|,
name|reporter
argument_list|)
return|;
block|}
comment|/**    * Open a Region.    * @param conf The Configuration object to use.    * @param fs Filesystem to use    * @param rootDir Root directory for HBase instance    * @param info Info for region to be opened.    * @param htd the table descriptor    * @param wal WAL for region to use. This method will call    * WAL#setSequenceNumber(long) passing the result of the call to    * HRegion#getMinSequenceId() to ensure the wal id is properly kept    * up.  HRegionStore does this every time it opens a new region.    * @return new HRegion    * @throws IOException    */
specifier|public
specifier|static
name|HRegion
name|openHRegion
parameter_list|(
specifier|final
name|Configuration
name|conf
parameter_list|,
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Path
name|rootDir
parameter_list|,
specifier|final
name|RegionInfo
name|info
parameter_list|,
specifier|final
name|TableDescriptor
name|htd
parameter_list|,
specifier|final
name|WAL
name|wal
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|openHRegion
argument_list|(
name|conf
argument_list|,
name|fs
argument_list|,
name|rootDir
argument_list|,
name|info
argument_list|,
name|htd
argument_list|,
name|wal
argument_list|,
literal|null
argument_list|,
literal|null
argument_list|)
return|;
block|}
comment|/**    * Open a Region.    * @param conf The Configuration object to use.    * @param fs Filesystem to use    * @param rootDir Root directory for HBase instance    * @param info Info for region to be opened.    * @param htd the table descriptor    * @param wal WAL for region to use. This method will call    * WAL#setSequenceNumber(long) passing the result of the call to    * HRegion#getMinSequenceId() to ensure the wal id is properly kept    * up.  HRegionStore does this every time it opens a new region.    * @param rsServices An interface we can request flushes against.    * @param reporter An interface we can report progress against.    * @return new HRegion    * @throws IOException    */
specifier|public
specifier|static
name|HRegion
name|openHRegion
parameter_list|(
specifier|final
name|Configuration
name|conf
parameter_list|,
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Path
name|rootDir
parameter_list|,
specifier|final
name|RegionInfo
name|info
parameter_list|,
specifier|final
name|TableDescriptor
name|htd
parameter_list|,
specifier|final
name|WAL
name|wal
parameter_list|,
specifier|final
name|RegionServerServices
name|rsServices
parameter_list|,
specifier|final
name|CancelableProgressable
name|reporter
parameter_list|)
throws|throws
name|IOException
block|{
name|Path
name|tableDir
init|=
name|FSUtils
operator|.
name|getTableDir
argument_list|(
name|rootDir
argument_list|,
name|info
operator|.
name|getTable
argument_list|()
argument_list|)
decl_stmt|;
return|return
name|openHRegion
argument_list|(
name|conf
argument_list|,
name|fs
argument_list|,
name|rootDir
argument_list|,
name|tableDir
argument_list|,
name|info
argument_list|,
name|htd
argument_list|,
name|wal
argument_list|,
name|rsServices
argument_list|,
name|reporter
argument_list|)
return|;
block|}
comment|/**    * Open a Region.    * @param conf The Configuration object to use.    * @param fs Filesystem to use    * @param rootDir Root directory for HBase instance    * @param info Info for region to be opened.    * @param htd the table descriptor    * @param wal WAL for region to use. This method will call    * WAL#setSequenceNumber(long) passing the result of the call to    * HRegion#getMinSequenceId() to ensure the wal id is properly kept    * up.  HRegionStore does this every time it opens a new region.    * @param rsServices An interface we can request flushes against.    * @param reporter An interface we can report progress against.    * @return new HRegion    * @throws IOException    */
specifier|public
specifier|static
name|HRegion
name|openHRegion
parameter_list|(
specifier|final
name|Configuration
name|conf
parameter_list|,
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Path
name|rootDir
parameter_list|,
specifier|final
name|Path
name|tableDir
parameter_list|,
specifier|final
name|RegionInfo
name|info
parameter_list|,
specifier|final
name|TableDescriptor
name|htd
parameter_list|,
specifier|final
name|WAL
name|wal
parameter_list|,
specifier|final
name|RegionServerServices
name|rsServices
parameter_list|,
specifier|final
name|CancelableProgressable
name|reporter
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|info
operator|==
literal|null
condition|)
throw|throw
operator|new
name|NullPointerException
argument_list|(
literal|"Passed region info is null"
argument_list|)
throw|;
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Opening region: "
operator|+
name|info
argument_list|)
expr_stmt|;
block|}
name|HRegion
name|r
init|=
name|HRegion
operator|.
name|newHRegion
argument_list|(
name|tableDir
argument_list|,
name|wal
argument_list|,
name|fs
argument_list|,
name|conf
argument_list|,
name|info
argument_list|,
name|htd
argument_list|,
name|rsServices
argument_list|)
decl_stmt|;
return|return
name|r
operator|.
name|openHRegion
argument_list|(
name|reporter
argument_list|)
return|;
block|}
annotation|@
name|VisibleForTesting
specifier|public
name|NavigableMap
argument_list|<
name|byte
index|[]
argument_list|,
name|Integer
argument_list|>
name|getReplicationScope
parameter_list|()
block|{
return|return
name|this
operator|.
name|replicationScope
return|;
block|}
comment|/**    * Useful when reopening a closed region (normally for unit tests)    * @param other original object    * @param reporter An interface we can report progress against.    * @return new HRegion    * @throws IOException    */
specifier|public
specifier|static
name|HRegion
name|openHRegion
parameter_list|(
specifier|final
name|HRegion
name|other
parameter_list|,
specifier|final
name|CancelableProgressable
name|reporter
parameter_list|)
throws|throws
name|IOException
block|{
name|HRegionFileSystem
name|regionFs
init|=
name|other
operator|.
name|getRegionFileSystem
argument_list|()
decl_stmt|;
name|HRegion
name|r
init|=
name|newHRegion
argument_list|(
name|regionFs
operator|.
name|getTableDir
argument_list|()
argument_list|,
name|other
operator|.
name|getWAL
argument_list|()
argument_list|,
name|regionFs
operator|.
name|getFileSystem
argument_list|()
argument_list|,
name|other
operator|.
name|baseConf
argument_list|,
name|other
operator|.
name|getRegionInfo
argument_list|()
argument_list|,
name|other
operator|.
name|getTableDescriptor
argument_list|()
argument_list|,
literal|null
argument_list|)
decl_stmt|;
return|return
name|r
operator|.
name|openHRegion
argument_list|(
name|reporter
argument_list|)
return|;
block|}
specifier|public
specifier|static
name|Region
name|openHRegion
parameter_list|(
specifier|final
name|Region
name|other
parameter_list|,
specifier|final
name|CancelableProgressable
name|reporter
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|openHRegion
argument_list|(
operator|(
name|HRegion
operator|)
name|other
argument_list|,
name|reporter
argument_list|)
return|;
block|}
comment|/**    * Open HRegion.    * Calls initialize and sets sequenceId.    * @return Returns<code>this</code>    */
specifier|protected
name|HRegion
name|openHRegion
parameter_list|(
specifier|final
name|CancelableProgressable
name|reporter
parameter_list|)
throws|throws
name|IOException
block|{
comment|// Refuse to open the region if we are missing local compression support
name|checkCompressionCodecs
argument_list|()
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"checking encryption for "
operator|+
name|this
operator|.
name|getRegionInfo
argument_list|()
operator|.
name|getEncodedName
argument_list|()
argument_list|)
expr_stmt|;
comment|// Refuse to open the region if encryption configuration is incorrect or
comment|// codec support is missing
name|checkEncryption
argument_list|()
expr_stmt|;
comment|// Refuse to open the region if a required class cannot be loaded
name|LOG
operator|.
name|debug
argument_list|(
literal|"checking classloading for "
operator|+
name|this
operator|.
name|getRegionInfo
argument_list|()
operator|.
name|getEncodedName
argument_list|()
argument_list|)
expr_stmt|;
name|checkClassLoading
argument_list|()
expr_stmt|;
name|this
operator|.
name|openSeqNum
operator|=
name|initialize
argument_list|(
name|reporter
argument_list|)
expr_stmt|;
name|this
operator|.
name|mvcc
operator|.
name|advanceTo
argument_list|(
name|openSeqNum
argument_list|)
expr_stmt|;
if|if
condition|(
name|wal
operator|!=
literal|null
operator|&&
name|getRegionServerServices
argument_list|()
operator|!=
literal|null
operator|&&
operator|!
name|writestate
operator|.
name|readOnly
condition|)
block|{
comment|// Only write the region open event marker to WAL if we are not read-only.
name|writeRegionOpenMarker
argument_list|(
name|wal
argument_list|,
name|openSeqNum
argument_list|)
expr_stmt|;
block|}
return|return
name|this
return|;
block|}
comment|/**    * Open a Region on a read-only file-system (like hdfs snapshots)    * @param conf The Configuration object to use.    * @param fs Filesystem to use    * @param info Info for region to be opened.    * @param htd the table descriptor    * @return new HRegion    * @throws IOException e    */
specifier|public
specifier|static
name|HRegion
name|openReadOnlyFileSystemHRegion
parameter_list|(
specifier|final
name|Configuration
name|conf
parameter_list|,
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Path
name|tableDir
parameter_list|,
name|RegionInfo
name|info
parameter_list|,
specifier|final
name|TableDescriptor
name|htd
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|info
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|NullPointerException
argument_list|(
literal|"Passed region info is null"
argument_list|)
throw|;
block|}
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Opening region (readOnly filesystem): "
operator|+
name|info
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|info
operator|.
name|getReplicaId
argument_list|()
operator|<=
literal|0
condition|)
block|{
name|info
operator|=
name|RegionInfoBuilder
operator|.
name|newBuilder
argument_list|(
name|info
argument_list|)
operator|.
name|setReplicaId
argument_list|(
literal|1
argument_list|)
operator|.
name|build
argument_list|()
expr_stmt|;
block|}
name|HRegion
name|r
init|=
name|HRegion
operator|.
name|newHRegion
argument_list|(
name|tableDir
argument_list|,
literal|null
argument_list|,
name|fs
argument_list|,
name|conf
argument_list|,
name|info
argument_list|,
name|htd
argument_list|,
literal|null
argument_list|)
decl_stmt|;
name|r
operator|.
name|writestate
operator|.
name|setReadOnly
argument_list|(
literal|true
argument_list|)
expr_stmt|;
return|return
name|r
operator|.
name|openHRegion
argument_list|(
literal|null
argument_list|)
return|;
block|}
specifier|public
specifier|static
name|void
name|warmupHRegion
parameter_list|(
specifier|final
name|RegionInfo
name|info
parameter_list|,
specifier|final
name|TableDescriptor
name|htd
parameter_list|,
specifier|final
name|WAL
name|wal
parameter_list|,
specifier|final
name|Configuration
name|conf
parameter_list|,
specifier|final
name|RegionServerServices
name|rsServices
parameter_list|,
specifier|final
name|CancelableProgressable
name|reporter
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|info
operator|==
literal|null
condition|)
throw|throw
operator|new
name|NullPointerException
argument_list|(
literal|"Passed region info is null"
argument_list|)
throw|;
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"HRegion.Warming up region: "
operator|+
name|info
argument_list|)
expr_stmt|;
block|}
name|Path
name|rootDir
init|=
name|FSUtils
operator|.
name|getRootDir
argument_list|(
name|conf
argument_list|)
decl_stmt|;
name|Path
name|tableDir
init|=
name|FSUtils
operator|.
name|getTableDir
argument_list|(
name|rootDir
argument_list|,
name|info
operator|.
name|getTable
argument_list|()
argument_list|)
decl_stmt|;
name|FileSystem
name|fs
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|rsServices
operator|!=
literal|null
condition|)
block|{
name|fs
operator|=
name|rsServices
operator|.
name|getFileSystem
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|fs
operator|==
literal|null
condition|)
block|{
name|fs
operator|=
name|FileSystem
operator|.
name|get
argument_list|(
name|conf
argument_list|)
expr_stmt|;
block|}
name|HRegion
name|r
init|=
name|HRegion
operator|.
name|newHRegion
argument_list|(
name|tableDir
argument_list|,
name|wal
argument_list|,
name|fs
argument_list|,
name|conf
argument_list|,
name|info
argument_list|,
name|htd
argument_list|,
literal|null
argument_list|)
decl_stmt|;
name|r
operator|.
name|initializeWarmup
argument_list|(
name|reporter
argument_list|)
expr_stmt|;
block|}
specifier|private
name|void
name|checkCompressionCodecs
parameter_list|()
throws|throws
name|IOException
block|{
for|for
control|(
name|ColumnFamilyDescriptor
name|fam
range|:
name|this
operator|.
name|htableDescriptor
operator|.
name|getColumnFamilies
argument_list|()
control|)
block|{
name|CompressionTest
operator|.
name|testCompression
argument_list|(
name|fam
operator|.
name|getCompressionType
argument_list|()
argument_list|)
expr_stmt|;
name|CompressionTest
operator|.
name|testCompression
argument_list|(
name|fam
operator|.
name|getCompactionCompressionType
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
specifier|private
name|void
name|checkEncryption
parameter_list|()
throws|throws
name|IOException
block|{
for|for
control|(
name|ColumnFamilyDescriptor
name|fam
range|:
name|this
operator|.
name|htableDescriptor
operator|.
name|getColumnFamilies
argument_list|()
control|)
block|{
name|EncryptionTest
operator|.
name|testEncryption
argument_list|(
name|conf
argument_list|,
name|fam
operator|.
name|getEncryptionType
argument_list|()
argument_list|,
name|fam
operator|.
name|getEncryptionKey
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
specifier|private
name|void
name|checkClassLoading
parameter_list|()
throws|throws
name|IOException
block|{
name|RegionSplitPolicy
operator|.
name|getSplitPolicyClass
argument_list|(
name|this
operator|.
name|htableDescriptor
argument_list|,
name|conf
argument_list|)
expr_stmt|;
name|RegionCoprocessorHost
operator|.
name|testTableCoprocessorAttrs
argument_list|(
name|conf
argument_list|,
name|this
operator|.
name|htableDescriptor
argument_list|)
expr_stmt|;
block|}
comment|/**    * Computes the Path of the HRegion    *    * @param tabledir qualified path for table    * @param name ENCODED region name    * @return Path of HRegion directory    * @deprecated For tests only; to be removed.    */
annotation|@
name|Deprecated
specifier|public
specifier|static
name|Path
name|getRegionDir
parameter_list|(
specifier|final
name|Path
name|tabledir
parameter_list|,
specifier|final
name|String
name|name
parameter_list|)
block|{
return|return
operator|new
name|Path
argument_list|(
name|tabledir
argument_list|,
name|name
argument_list|)
return|;
block|}
comment|/**    * Computes the Path of the HRegion    *    * @param rootdir qualified path of HBase root directory    * @param info RegionInfo for the region    * @return qualified path of region directory    * @deprecated For tests only; to be removed.    */
annotation|@
name|Deprecated
annotation|@
name|VisibleForTesting
specifier|public
specifier|static
name|Path
name|getRegionDir
parameter_list|(
specifier|final
name|Path
name|rootdir
parameter_list|,
specifier|final
name|RegionInfo
name|info
parameter_list|)
block|{
return|return
operator|new
name|Path
argument_list|(
name|FSUtils
operator|.
name|getTableDir
argument_list|(
name|rootdir
argument_list|,
name|info
operator|.
name|getTable
argument_list|()
argument_list|)
argument_list|,
name|info
operator|.
name|getEncodedName
argument_list|()
argument_list|)
return|;
block|}
comment|/**    * Determines if the specified row is within the row range specified by the    * specified RegionInfo    *    * @param info RegionInfo that specifies the row range    * @param row row to be checked    * @return true if the row is within the range specified by the RegionInfo    */
specifier|public
specifier|static
name|boolean
name|rowIsInRange
parameter_list|(
name|RegionInfo
name|info
parameter_list|,
specifier|final
name|byte
index|[]
name|row
parameter_list|)
block|{
return|return
operator|(
operator|(
name|info
operator|.
name|getStartKey
argument_list|()
operator|.
name|length
operator|==
literal|0
operator|)
operator|||
operator|(
name|Bytes
operator|.
name|compareTo
argument_list|(
name|info
operator|.
name|getStartKey
argument_list|()
argument_list|,
name|row
argument_list|)
operator|<=
literal|0
operator|)
operator|)
operator|&&
operator|(
operator|(
name|info
operator|.
name|getEndKey
argument_list|()
operator|.
name|length
operator|==
literal|0
operator|)
operator|||
operator|(
name|Bytes
operator|.
name|compareTo
argument_list|(
name|info
operator|.
name|getEndKey
argument_list|()
argument_list|,
name|row
argument_list|)
operator|>
literal|0
operator|)
operator|)
return|;
block|}
specifier|public
specifier|static
name|boolean
name|rowIsInRange
parameter_list|(
name|RegionInfo
name|info
parameter_list|,
specifier|final
name|byte
index|[]
name|row
parameter_list|,
specifier|final
name|int
name|offset
parameter_list|,
specifier|final
name|short
name|length
parameter_list|)
block|{
return|return
operator|(
operator|(
name|info
operator|.
name|getStartKey
argument_list|()
operator|.
name|length
operator|==
literal|0
operator|)
operator|||
operator|(
name|Bytes
operator|.
name|compareTo
argument_list|(
name|info
operator|.
name|getStartKey
argument_list|()
argument_list|,
literal|0
argument_list|,
name|info
operator|.
name|getStartKey
argument_list|()
operator|.
name|length
argument_list|,
name|row
argument_list|,
name|offset
argument_list|,
name|length
argument_list|)
operator|<=
literal|0
operator|)
operator|)
operator|&&
operator|(
operator|(
name|info
operator|.
name|getEndKey
argument_list|()
operator|.
name|length
operator|==
literal|0
operator|)
operator|||
operator|(
name|Bytes
operator|.
name|compareTo
argument_list|(
name|info
operator|.
name|getEndKey
argument_list|()
argument_list|,
literal|0
argument_list|,
name|info
operator|.
name|getEndKey
argument_list|()
operator|.
name|length
argument_list|,
name|row
argument_list|,
name|offset
argument_list|,
name|length
argument_list|)
operator|>
literal|0
operator|)
operator|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|Result
name|get
parameter_list|(
specifier|final
name|Get
name|get
parameter_list|)
throws|throws
name|IOException
block|{
name|prepareGet
argument_list|(
name|get
argument_list|)
expr_stmt|;
name|List
argument_list|<
name|Cell
argument_list|>
name|results
init|=
name|get
argument_list|(
name|get
argument_list|,
literal|true
argument_list|)
decl_stmt|;
name|boolean
name|stale
init|=
name|this
operator|.
name|getRegionInfo
argument_list|()
operator|.
name|getReplicaId
argument_list|()
operator|!=
literal|0
decl_stmt|;
return|return
name|Result
operator|.
name|create
argument_list|(
name|results
argument_list|,
name|get
operator|.
name|isCheckExistenceOnly
argument_list|()
condition|?
operator|!
name|results
operator|.
name|isEmpty
argument_list|()
else|:
literal|null
argument_list|,
name|stale
argument_list|)
return|;
block|}
name|void
name|prepareGet
parameter_list|(
specifier|final
name|Get
name|get
parameter_list|)
throws|throws
name|IOException
block|{
name|checkRow
argument_list|(
name|get
operator|.
name|getRow
argument_list|()
argument_list|,
literal|"Get"
argument_list|)
expr_stmt|;
comment|// Verify families are all valid
if|if
condition|(
name|get
operator|.
name|hasFamilies
argument_list|()
condition|)
block|{
for|for
control|(
name|byte
index|[]
name|family
range|:
name|get
operator|.
name|familySet
argument_list|()
control|)
block|{
name|checkFamily
argument_list|(
name|family
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
comment|// Adding all families to scanner
for|for
control|(
name|byte
index|[]
name|family
range|:
name|this
operator|.
name|htableDescriptor
operator|.
name|getColumnFamilyNames
argument_list|()
control|)
block|{
name|get
operator|.
name|addFamily
argument_list|(
name|family
argument_list|)
expr_stmt|;
block|}
block|}
block|}
annotation|@
name|Override
specifier|public
name|List
argument_list|<
name|Cell
argument_list|>
name|get
parameter_list|(
name|Get
name|get
parameter_list|,
name|boolean
name|withCoprocessor
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|get
argument_list|(
name|get
argument_list|,
name|withCoprocessor
argument_list|,
name|HConstants
operator|.
name|NO_NONCE
argument_list|,
name|HConstants
operator|.
name|NO_NONCE
argument_list|)
return|;
block|}
specifier|public
name|List
argument_list|<
name|Cell
argument_list|>
name|get
parameter_list|(
name|Get
name|get
parameter_list|,
name|boolean
name|withCoprocessor
parameter_list|,
name|long
name|nonceGroup
parameter_list|,
name|long
name|nonce
parameter_list|)
throws|throws
name|IOException
block|{
name|List
argument_list|<
name|Cell
argument_list|>
name|results
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
name|long
name|before
init|=
name|EnvironmentEdgeManager
operator|.
name|currentTime
argument_list|()
decl_stmt|;
comment|// pre-get CP hook
if|if
condition|(
name|withCoprocessor
operator|&&
operator|(
name|coprocessorHost
operator|!=
literal|null
operator|)
condition|)
block|{
if|if
condition|(
name|coprocessorHost
operator|.
name|preGet
argument_list|(
name|get
argument_list|,
name|results
argument_list|)
condition|)
block|{
name|metricsUpdateForGet
argument_list|(
name|results
argument_list|,
name|before
argument_list|)
expr_stmt|;
return|return
name|results
return|;
block|}
block|}
name|Scan
name|scan
init|=
operator|new
name|Scan
argument_list|(
name|get
argument_list|)
decl_stmt|;
if|if
condition|(
name|scan
operator|.
name|getLoadColumnFamiliesOnDemandValue
argument_list|()
operator|==
literal|null
condition|)
block|{
name|scan
operator|.
name|setLoadColumnFamiliesOnDemand
argument_list|(
name|isLoadingCfsOnDemandDefault
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|RegionScanner
name|scanner
init|=
literal|null
decl_stmt|;
try|try
block|{
name|scanner
operator|=
name|getScanner
argument_list|(
name|scan
argument_list|,
literal|null
argument_list|,
name|nonceGroup
argument_list|,
name|nonce
argument_list|)
expr_stmt|;
name|scanner
operator|.
name|next
argument_list|(
name|results
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
if|if
condition|(
name|scanner
operator|!=
literal|null
condition|)
name|scanner
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
comment|// post-get CP hook
if|if
condition|(
name|withCoprocessor
operator|&&
operator|(
name|coprocessorHost
operator|!=
literal|null
operator|)
condition|)
block|{
name|coprocessorHost
operator|.
name|postGet
argument_list|(
name|get
argument_list|,
name|results
argument_list|)
expr_stmt|;
block|}
name|metricsUpdateForGet
argument_list|(
name|results
argument_list|,
name|before
argument_list|)
expr_stmt|;
return|return
name|results
return|;
block|}
name|void
name|metricsUpdateForGet
parameter_list|(
name|List
argument_list|<
name|Cell
argument_list|>
name|results
parameter_list|,
name|long
name|before
parameter_list|)
block|{
if|if
condition|(
name|this
operator|.
name|metricsRegion
operator|!=
literal|null
condition|)
block|{
name|this
operator|.
name|metricsRegion
operator|.
name|updateGet
argument_list|(
name|EnvironmentEdgeManager
operator|.
name|currentTime
argument_list|()
operator|-
name|before
argument_list|)
expr_stmt|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|void
name|mutateRow
parameter_list|(
name|RowMutations
name|rm
parameter_list|)
throws|throws
name|IOException
block|{
comment|// Don't need nonces here - RowMutations only supports puts and deletes
specifier|final
name|List
argument_list|<
name|Mutation
argument_list|>
name|m
init|=
name|rm
operator|.
name|getMutations
argument_list|()
decl_stmt|;
name|batchMutate
argument_list|(
name|m
operator|.
name|toArray
argument_list|(
operator|new
name|Mutation
index|[
name|m
operator|.
name|size
argument_list|()
index|]
argument_list|)
argument_list|,
literal|true
argument_list|,
name|HConstants
operator|.
name|NO_NONCE
argument_list|,
name|HConstants
operator|.
name|NO_NONCE
argument_list|)
expr_stmt|;
block|}
comment|/**    * Perform atomic (all or none) mutations within the region.    * @param mutations The list of mutations to perform.    *<code>mutations</code> can contain operations for multiple rows.    * Caller has to ensure that all rows are contained in this region.    * @param rowsToLock Rows to lock    * @param nonceGroup Optional nonce group of the operation (client Id)    * @param nonce Optional nonce of the operation (unique random id to ensure "more idempotence")    * If multiple rows are locked care should be taken that    *<code>rowsToLock</code> is sorted in order to avoid deadlocks.    * @throws IOException    */
annotation|@
name|Override
specifier|public
name|void
name|mutateRowsWithLocks
parameter_list|(
name|Collection
argument_list|<
name|Mutation
argument_list|>
name|mutations
parameter_list|,
name|Collection
argument_list|<
name|byte
index|[]
argument_list|>
name|rowsToLock
parameter_list|,
name|long
name|nonceGroup
parameter_list|,
name|long
name|nonce
parameter_list|)
throws|throws
name|IOException
block|{
name|batchMutate
argument_list|(
operator|new
name|MutationBatchOperation
argument_list|(
name|this
argument_list|,
name|mutations
operator|.
name|toArray
argument_list|(
operator|new
name|Mutation
index|[
name|mutations
operator|.
name|size
argument_list|()
index|]
argument_list|)
argument_list|,
literal|true
argument_list|,
name|nonceGroup
argument_list|,
name|nonce
argument_list|)
block|{
annotation|@
name|Override
specifier|public
name|MiniBatchOperationInProgress
argument_list|<
name|Mutation
argument_list|>
name|lockRowsAndBuildMiniBatch
parameter_list|(
name|List
argument_list|<
name|RowLock
argument_list|>
name|acquiredRowLocks
parameter_list|)
throws|throws
name|IOException
block|{
name|RowLock
name|prevRowLock
init|=
literal|null
decl_stmt|;
for|for
control|(
name|byte
index|[]
name|row
range|:
name|rowsToLock
control|)
block|{
try|try
block|{
name|RowLock
name|rowLock
init|=
name|region
operator|.
name|getRowLockInternal
argument_list|(
name|row
argument_list|,
literal|false
argument_list|,
name|prevRowLock
argument_list|)
decl_stmt|;
comment|// write lock
if|if
condition|(
name|rowLock
operator|!=
name|prevRowLock
condition|)
block|{
name|acquiredRowLocks
operator|.
name|add
argument_list|(
name|rowLock
argument_list|)
expr_stmt|;
name|prevRowLock
operator|=
name|rowLock
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|ioe
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failed getting lock, row="
operator|+
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|row
argument_list|)
argument_list|,
name|ioe
argument_list|)
expr_stmt|;
throw|throw
name|ioe
throw|;
block|}
block|}
return|return
name|createMiniBatch
argument_list|(
name|size
argument_list|()
argument_list|,
name|size
argument_list|()
argument_list|)
return|;
block|}
block|}
argument_list|)
expr_stmt|;
block|}
comment|/**    * @return statistics about the current load of the region    */
specifier|public
name|ClientProtos
operator|.
name|RegionLoadStats
name|getLoadStatistics
parameter_list|()
block|{
if|if
condition|(
operator|!
name|regionStatsEnabled
condition|)
block|{
return|return
literal|null
return|;
block|}
name|ClientProtos
operator|.
name|RegionLoadStats
operator|.
name|Builder
name|stats
init|=
name|ClientProtos
operator|.
name|RegionLoadStats
operator|.
name|newBuilder
argument_list|()
decl_stmt|;
name|stats
operator|.
name|setMemStoreLoad
argument_list|(
call|(
name|int
call|)
argument_list|(
name|Math
operator|.
name|min
argument_list|(
literal|100
argument_list|,
operator|(
name|this
operator|.
name|memStoreSizing
operator|.
name|getMemStoreSize
argument_list|()
operator|.
name|getHeapSize
argument_list|()
operator|*
literal|100
operator|)
operator|/
name|this
operator|.
name|memstoreFlushSize
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|rsServices
operator|.
name|getHeapMemoryManager
argument_list|()
operator|!=
literal|null
condition|)
block|{
comment|// the HeapMemoryManager uses -0.0 to signal a problem asking the JVM,
comment|// so we could just do the calculation below and we'll get a 0.
comment|// treating it as a special case analogous to no HMM instead so that it can be
comment|// programatically treated different from using<1% of heap.
specifier|final
name|float
name|occupancy
init|=
name|rsServices
operator|.
name|getHeapMemoryManager
argument_list|()
operator|.
name|getHeapOccupancyPercent
argument_list|()
decl_stmt|;
if|if
condition|(
name|occupancy
operator|!=
name|HeapMemoryManager
operator|.
name|HEAP_OCCUPANCY_ERROR_VALUE
condition|)
block|{
name|stats
operator|.
name|setHeapOccupancy
argument_list|(
call|(
name|int
call|)
argument_list|(
name|occupancy
operator|*
literal|100
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
name|stats
operator|.
name|setCompactionPressure
argument_list|(
call|(
name|int
call|)
argument_list|(
name|rsServices
operator|.
name|getCompactionPressure
argument_list|()
operator|*
literal|100
operator|>
literal|100
condition|?
literal|100
else|:
name|rsServices
operator|.
name|getCompactionPressure
argument_list|()
operator|*
literal|100
argument_list|)
argument_list|)
expr_stmt|;
return|return
name|stats
operator|.
name|build
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|processRowsWithLocks
parameter_list|(
name|RowProcessor
argument_list|<
name|?
argument_list|,
name|?
argument_list|>
name|processor
parameter_list|)
throws|throws
name|IOException
block|{
name|processRowsWithLocks
argument_list|(
name|processor
argument_list|,
name|rowProcessorTimeout
argument_list|,
name|HConstants
operator|.
name|NO_NONCE
argument_list|,
name|HConstants
operator|.
name|NO_NONCE
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|processRowsWithLocks
parameter_list|(
name|RowProcessor
argument_list|<
name|?
argument_list|,
name|?
argument_list|>
name|processor
parameter_list|,
name|long
name|nonceGroup
parameter_list|,
name|long
name|nonce
parameter_list|)
throws|throws
name|IOException
block|{
name|processRowsWithLocks
argument_list|(
name|processor
argument_list|,
name|rowProcessorTimeout
argument_list|,
name|nonceGroup
argument_list|,
name|nonce
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|processRowsWithLocks
parameter_list|(
name|RowProcessor
argument_list|<
name|?
argument_list|,
name|?
argument_list|>
name|processor
parameter_list|,
name|long
name|timeout
parameter_list|,
name|long
name|nonceGroup
parameter_list|,
name|long
name|nonce
parameter_list|)
throws|throws
name|IOException
block|{
for|for
control|(
name|byte
index|[]
name|row
range|:
name|processor
operator|.
name|getRowsToLock
argument_list|()
control|)
block|{
name|checkRow
argument_list|(
name|row
argument_list|,
literal|"processRowsWithLocks"
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|!
name|processor
operator|.
name|readOnly
argument_list|()
condition|)
block|{
name|checkReadOnly
argument_list|()
expr_stmt|;
block|}
name|checkResources
argument_list|()
expr_stmt|;
name|startRegionOperation
argument_list|()
expr_stmt|;
name|WALEdit
name|walEdit
init|=
operator|new
name|WALEdit
argument_list|()
decl_stmt|;
comment|// STEP 1. Run pre-process hook
name|preProcess
argument_list|(
name|processor
argument_list|,
name|walEdit
argument_list|)
expr_stmt|;
comment|// Short circuit the read only case
if|if
condition|(
name|processor
operator|.
name|readOnly
argument_list|()
condition|)
block|{
try|try
block|{
name|long
name|now
init|=
name|EnvironmentEdgeManager
operator|.
name|currentTime
argument_list|()
decl_stmt|;
name|doProcessRowWithTimeout
argument_list|(
name|processor
argument_list|,
name|now
argument_list|,
name|this
argument_list|,
literal|null
argument_list|,
literal|null
argument_list|,
name|timeout
argument_list|)
expr_stmt|;
name|processor
operator|.
name|postProcess
argument_list|(
name|this
argument_list|,
name|walEdit
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|closeRegionOperation
argument_list|()
expr_stmt|;
block|}
return|return;
block|}
name|boolean
name|locked
init|=
literal|false
decl_stmt|;
name|List
argument_list|<
name|RowLock
argument_list|>
name|acquiredRowLocks
init|=
literal|null
decl_stmt|;
name|List
argument_list|<
name|Mutation
argument_list|>
name|mutations
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
name|Collection
argument_list|<
name|byte
index|[]
argument_list|>
name|rowsToLock
init|=
name|processor
operator|.
name|getRowsToLock
argument_list|()
decl_stmt|;
comment|// This is assigned by mvcc either explicity in the below or in the guts of the WAL append
comment|// when it assigns the edit a sequencedid (A.K.A the mvcc write number).
name|WriteEntry
name|writeEntry
init|=
literal|null
decl_stmt|;
name|MemStoreSizing
name|memstoreAccounting
init|=
operator|new
name|NonThreadSafeMemStoreSizing
argument_list|()
decl_stmt|;
try|try
block|{
name|boolean
name|success
init|=
literal|false
decl_stmt|;
try|try
block|{
comment|// STEP 2. Acquire the row lock(s)
name|acquiredRowLocks
operator|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
name|rowsToLock
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
name|RowLock
name|prevRowLock
init|=
literal|null
decl_stmt|;
for|for
control|(
name|byte
index|[]
name|row
range|:
name|rowsToLock
control|)
block|{
comment|// Attempt to lock all involved rows, throw if any lock times out
comment|// use a writer lock for mixed reads and writes
name|RowLock
name|rowLock
init|=
name|getRowLockInternal
argument_list|(
name|row
argument_list|,
literal|false
argument_list|,
name|prevRowLock
argument_list|)
decl_stmt|;
if|if
condition|(
name|rowLock
operator|!=
name|prevRowLock
condition|)
block|{
name|acquiredRowLocks
operator|.
name|add
argument_list|(
name|rowLock
argument_list|)
expr_stmt|;
name|prevRowLock
operator|=
name|rowLock
expr_stmt|;
block|}
block|}
comment|// STEP 3. Region lock
name|lock
argument_list|(
name|this
operator|.
name|updatesLock
operator|.
name|readLock
argument_list|()
argument_list|,
name|acquiredRowLocks
operator|.
name|isEmpty
argument_list|()
condition|?
literal|1
else|:
name|acquiredRowLocks
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
name|locked
operator|=
literal|true
expr_stmt|;
name|long
name|now
init|=
name|EnvironmentEdgeManager
operator|.
name|currentTime
argument_list|()
decl_stmt|;
comment|// STEP 4. Let the processor scan the rows, generate mutations and add waledits
name|doProcessRowWithTimeout
argument_list|(
name|processor
argument_list|,
name|now
argument_list|,
name|this
argument_list|,
name|mutations
argument_list|,
name|walEdit
argument_list|,
name|timeout
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|mutations
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|writeRequestsCount
operator|.
name|add
argument_list|(
name|mutations
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
comment|// STEP 5. Call the preBatchMutate hook
name|processor
operator|.
name|preBatchMutate
argument_list|(
name|this
argument_list|,
name|walEdit
argument_list|)
expr_stmt|;
comment|// STEP 6. Append and sync if walEdit has data to write out.
if|if
condition|(
operator|!
name|walEdit
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|writeEntry
operator|=
name|doWALAppend
argument_list|(
name|walEdit
argument_list|,
name|getEffectiveDurability
argument_list|(
name|processor
operator|.
name|useDurability
argument_list|()
argument_list|)
argument_list|,
name|processor
operator|.
name|getClusterIds
argument_list|()
argument_list|,
name|now
argument_list|,
name|nonceGroup
argument_list|,
name|nonce
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// We are here if WAL is being skipped.
name|writeEntry
operator|=
name|this
operator|.
name|mvcc
operator|.
name|begin
argument_list|()
expr_stmt|;
block|}
comment|// STEP 7. Apply to memstore
name|long
name|sequenceId
init|=
name|writeEntry
operator|.
name|getWriteNumber
argument_list|()
decl_stmt|;
for|for
control|(
name|Mutation
name|m
range|:
name|mutations
control|)
block|{
comment|// Handle any tag based cell features.
comment|// TODO: Do we need to call rewriteCellTags down in applyToMemStore()? Why not before
comment|// so tags go into WAL?
name|rewriteCellTags
argument_list|(
name|m
operator|.
name|getFamilyCellMap
argument_list|()
argument_list|,
name|m
argument_list|)
expr_stmt|;
for|for
control|(
name|CellScanner
name|cellScanner
init|=
name|m
operator|.
name|cellScanner
argument_list|()
init|;
name|cellScanner
operator|.
name|advance
argument_list|()
condition|;
control|)
block|{
name|Cell
name|cell
init|=
name|cellScanner
operator|.
name|current
argument_list|()
decl_stmt|;
if|if
condition|(
name|walEdit
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
comment|// If walEdit is empty, we put nothing in WAL. WAL stamps Cells with sequence id.
comment|// If no WAL, need to stamp it here.
name|PrivateCellUtil
operator|.
name|setSequenceId
argument_list|(
name|cell
argument_list|,
name|sequenceId
argument_list|)
expr_stmt|;
block|}
name|applyToMemStore
argument_list|(
name|getStore
argument_list|(
name|cell
argument_list|)
argument_list|,
name|cell
argument_list|,
name|memstoreAccounting
argument_list|)
expr_stmt|;
block|}
block|}
comment|// STEP 8. call postBatchMutate hook
name|processor
operator|.
name|postBatchMutate
argument_list|(
name|this
argument_list|)
expr_stmt|;
comment|// STEP 9. Complete mvcc.
name|mvcc
operator|.
name|completeAndWait
argument_list|(
name|writeEntry
argument_list|)
expr_stmt|;
name|writeEntry
operator|=
literal|null
expr_stmt|;
comment|// STEP 10. Release region lock
if|if
condition|(
name|locked
condition|)
block|{
name|this
operator|.
name|updatesLock
operator|.
name|readLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
name|locked
operator|=
literal|false
expr_stmt|;
block|}
comment|// STEP 11. Release row lock(s)
name|releaseRowLocks
argument_list|(
name|acquiredRowLocks
argument_list|)
expr_stmt|;
block|}
name|success
operator|=
literal|true
expr_stmt|;
block|}
finally|finally
block|{
comment|// Call complete rather than completeAndWait because we probably had error if walKey != null
if|if
condition|(
name|writeEntry
operator|!=
literal|null
condition|)
name|mvcc
operator|.
name|complete
argument_list|(
name|writeEntry
argument_list|)
expr_stmt|;
if|if
condition|(
name|locked
condition|)
block|{
name|this
operator|.
name|updatesLock
operator|.
name|readLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
comment|// release locks if some were acquired but another timed out
name|releaseRowLocks
argument_list|(
name|acquiredRowLocks
argument_list|)
expr_stmt|;
block|}
comment|// 12. Run post-process hook
name|processor
operator|.
name|postProcess
argument_list|(
name|this
argument_list|,
name|walEdit
argument_list|,
name|success
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|closeRegionOperation
argument_list|()
expr_stmt|;
if|if
condition|(
operator|!
name|mutations
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|this
operator|.
name|incMemStoreSize
argument_list|(
name|memstoreAccounting
operator|.
name|getMemStoreSize
argument_list|()
argument_list|)
expr_stmt|;
name|requestFlushIfNeeded
argument_list|()
expr_stmt|;
block|}
block|}
block|}
specifier|private
name|void
name|preProcess
parameter_list|(
specifier|final
name|RowProcessor
argument_list|<
name|?
argument_list|,
name|?
argument_list|>
name|processor
parameter_list|,
specifier|final
name|WALEdit
name|walEdit
parameter_list|)
throws|throws
name|IOException
block|{
try|try
block|{
name|processor
operator|.
name|preProcess
argument_list|(
name|this
argument_list|,
name|walEdit
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|closeRegionOperation
argument_list|()
expr_stmt|;
throw|throw
name|e
throw|;
block|}
block|}
specifier|private
name|void
name|doProcessRowWithTimeout
parameter_list|(
specifier|final
name|RowProcessor
argument_list|<
name|?
argument_list|,
name|?
argument_list|>
name|processor
parameter_list|,
specifier|final
name|long
name|now
parameter_list|,
specifier|final
name|HRegion
name|region
parameter_list|,
specifier|final
name|List
argument_list|<
name|Mutation
argument_list|>
name|mutations
parameter_list|,
specifier|final
name|WALEdit
name|walEdit
parameter_list|,
specifier|final
name|long
name|timeout
parameter_list|)
throws|throws
name|IOException
block|{
comment|// Short circuit the no time bound case.
if|if
condition|(
name|timeout
operator|<
literal|0
condition|)
block|{
try|try
block|{
name|processor
operator|.
name|process
argument_list|(
name|now
argument_list|,
name|region
argument_list|,
name|mutations
argument_list|,
name|walEdit
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|String
name|row
init|=
name|processor
operator|.
name|getRowsToLock
argument_list|()
operator|.
name|isEmpty
argument_list|()
condition|?
literal|""
else|:
literal|" on row(s):"
operator|+
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|processor
operator|.
name|getRowsToLock
argument_list|()
operator|.
name|iterator
argument_list|()
operator|.
name|next
argument_list|()
argument_list|)
operator|+
literal|"..."
decl_stmt|;
name|LOG
operator|.
name|warn
argument_list|(
literal|"RowProcessor:"
operator|+
name|processor
operator|.
name|getClass
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|" throws Exception"
operator|+
name|row
argument_list|,
name|e
argument_list|)
expr_stmt|;
throw|throw
name|e
throw|;
block|}
return|return;
block|}
comment|// Case with time bound
name|FutureTask
argument_list|<
name|Void
argument_list|>
name|task
init|=
operator|new
name|FutureTask
argument_list|<>
argument_list|(
operator|new
name|Callable
argument_list|<
name|Void
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|Void
name|call
parameter_list|()
throws|throws
name|IOException
block|{
try|try
block|{
name|processor
operator|.
name|process
argument_list|(
name|now
argument_list|,
name|region
argument_list|,
name|mutations
argument_list|,
name|walEdit
argument_list|)
expr_stmt|;
return|return
literal|null
return|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|String
name|row
init|=
name|processor
operator|.
name|getRowsToLock
argument_list|()
operator|.
name|isEmpty
argument_list|()
condition|?
literal|""
else|:
literal|" on row(s):"
operator|+
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|processor
operator|.
name|getRowsToLock
argument_list|()
operator|.
name|iterator
argument_list|()
operator|.
name|next
argument_list|()
argument_list|)
operator|+
literal|"..."
decl_stmt|;
name|LOG
operator|.
name|warn
argument_list|(
literal|"RowProcessor:"
operator|+
name|processor
operator|.
name|getClass
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|" throws Exception"
operator|+
name|row
argument_list|,
name|e
argument_list|)
expr_stmt|;
throw|throw
name|e
throw|;
block|}
block|}
block|}
argument_list|)
decl_stmt|;
name|rowProcessorExecutor
operator|.
name|execute
argument_list|(
name|task
argument_list|)
expr_stmt|;
try|try
block|{
name|task
operator|.
name|get
argument_list|(
name|timeout
argument_list|,
name|TimeUnit
operator|.
name|MILLISECONDS
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|TimeoutException
name|te
parameter_list|)
block|{
name|String
name|row
init|=
name|processor
operator|.
name|getRowsToLock
argument_list|()
operator|.
name|isEmpty
argument_list|()
condition|?
literal|""
else|:
literal|" on row(s):"
operator|+
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|processor
operator|.
name|getRowsToLock
argument_list|()
operator|.
name|iterator
argument_list|()
operator|.
name|next
argument_list|()
argument_list|)
operator|+
literal|"..."
decl_stmt|;
name|LOG
operator|.
name|error
argument_list|(
literal|"RowProcessor timeout:"
operator|+
name|timeout
operator|+
literal|" ms"
operator|+
name|row
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|IOException
argument_list|(
name|te
argument_list|)
throw|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|Result
name|append
parameter_list|(
name|Append
name|append
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|append
argument_list|(
name|append
argument_list|,
name|HConstants
operator|.
name|NO_NONCE
argument_list|,
name|HConstants
operator|.
name|NO_NONCE
argument_list|)
return|;
block|}
specifier|public
name|Result
name|append
parameter_list|(
name|Append
name|mutation
parameter_list|,
name|long
name|nonceGroup
parameter_list|,
name|long
name|nonce
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|doDelta
argument_list|(
name|Operation
operator|.
name|APPEND
argument_list|,
name|mutation
argument_list|,
name|nonceGroup
argument_list|,
name|nonce
argument_list|,
name|mutation
operator|.
name|isReturnResults
argument_list|()
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|Result
name|increment
parameter_list|(
name|Increment
name|increment
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|increment
argument_list|(
name|increment
argument_list|,
name|HConstants
operator|.
name|NO_NONCE
argument_list|,
name|HConstants
operator|.
name|NO_NONCE
argument_list|)
return|;
block|}
specifier|public
name|Result
name|increment
parameter_list|(
name|Increment
name|mutation
parameter_list|,
name|long
name|nonceGroup
parameter_list|,
name|long
name|nonce
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|doDelta
argument_list|(
name|Operation
operator|.
name|INCREMENT
argument_list|,
name|mutation
argument_list|,
name|nonceGroup
argument_list|,
name|nonce
argument_list|,
name|mutation
operator|.
name|isReturnResults
argument_list|()
argument_list|)
return|;
block|}
comment|/**    * Add "deltas" to Cells. Deltas are increments or appends. Switch on<code>op</code>.    *    *<p>If increment, add deltas to current values or if an append, then    * append the deltas to the current Cell values.    *    *<p>Append and Increment code paths are mostly the same. They differ in just a few places.    * This method does the code path for increment and append and then in key spots, switches    * on the passed in<code>op</code> to do increment or append specific paths.    */
specifier|private
name|Result
name|doDelta
parameter_list|(
name|Operation
name|op
parameter_list|,
name|Mutation
name|mutation
parameter_list|,
name|long
name|nonceGroup
parameter_list|,
name|long
name|nonce
parameter_list|,
name|boolean
name|returnResults
parameter_list|)
throws|throws
name|IOException
block|{
name|checkReadOnly
argument_list|()
expr_stmt|;
name|checkResources
argument_list|()
expr_stmt|;
name|checkRow
argument_list|(
name|mutation
operator|.
name|getRow
argument_list|()
argument_list|,
name|op
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
name|checkFamilies
argument_list|(
name|mutation
operator|.
name|getFamilyCellMap
argument_list|()
operator|.
name|keySet
argument_list|()
argument_list|)
expr_stmt|;
name|this
operator|.
name|writeRequestsCount
operator|.
name|increment
argument_list|()
expr_stmt|;
name|WriteEntry
name|writeEntry
init|=
literal|null
decl_stmt|;
name|startRegionOperation
argument_list|(
name|op
argument_list|)
expr_stmt|;
name|List
argument_list|<
name|Cell
argument_list|>
name|results
init|=
name|returnResults
condition|?
operator|new
name|ArrayList
argument_list|<>
argument_list|(
name|mutation
operator|.
name|size
argument_list|()
argument_list|)
else|:
literal|null
decl_stmt|;
name|RowLock
name|rowLock
init|=
literal|null
decl_stmt|;
name|MemStoreSizing
name|memstoreAccounting
init|=
operator|new
name|NonThreadSafeMemStoreSizing
argument_list|()
decl_stmt|;
try|try
block|{
name|rowLock
operator|=
name|getRowLockInternal
argument_list|(
name|mutation
operator|.
name|getRow
argument_list|()
argument_list|,
literal|false
argument_list|,
literal|null
argument_list|)
expr_stmt|;
name|lock
argument_list|(
name|this
operator|.
name|updatesLock
operator|.
name|readLock
argument_list|()
argument_list|)
expr_stmt|;
try|try
block|{
name|Result
name|cpResult
init|=
name|doCoprocessorPreCall
argument_list|(
name|op
argument_list|,
name|mutation
argument_list|)
decl_stmt|;
if|if
condition|(
name|cpResult
operator|!=
literal|null
condition|)
block|{
comment|// Metrics updated below in the finally block.
return|return
name|returnResults
condition|?
name|cpResult
else|:
literal|null
return|;
block|}
name|Durability
name|effectiveDurability
init|=
name|getEffectiveDurability
argument_list|(
name|mutation
operator|.
name|getDurability
argument_list|()
argument_list|)
decl_stmt|;
name|Map
argument_list|<
name|HStore
argument_list|,
name|List
argument_list|<
name|Cell
argument_list|>
argument_list|>
name|forMemStore
init|=
operator|new
name|HashMap
argument_list|<>
argument_list|(
name|mutation
operator|.
name|getFamilyCellMap
argument_list|()
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
comment|// Reckon Cells to apply to WAL --  in returned walEdit -- and what to add to memstore and
comment|// what to return back to the client (in 'forMemStore' and 'results' respectively).
name|WALEdit
name|walEdit
init|=
name|reckonDeltas
argument_list|(
name|op
argument_list|,
name|mutation
argument_list|,
name|effectiveDurability
argument_list|,
name|forMemStore
argument_list|,
name|results
argument_list|)
decl_stmt|;
comment|// Actually write to WAL now if a walEdit to apply.
if|if
condition|(
name|walEdit
operator|!=
literal|null
operator|&&
operator|!
name|walEdit
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|writeEntry
operator|=
name|doWALAppend
argument_list|(
name|walEdit
argument_list|,
name|effectiveDurability
argument_list|,
name|nonceGroup
argument_list|,
name|nonce
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// If walEdits is empty, it means we skipped the WAL; update LongAdders and start an mvcc
comment|// transaction.
name|recordMutationWithoutWal
argument_list|(
name|mutation
operator|.
name|getFamilyCellMap
argument_list|()
argument_list|)
expr_stmt|;
name|writeEntry
operator|=
name|mvcc
operator|.
name|begin
argument_list|()
expr_stmt|;
name|updateSequenceId
argument_list|(
name|forMemStore
operator|.
name|values
argument_list|()
argument_list|,
name|writeEntry
operator|.
name|getWriteNumber
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|// Now write to MemStore. Do it a column family at a time.
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|HStore
argument_list|,
name|List
argument_list|<
name|Cell
argument_list|>
argument_list|>
name|e
range|:
name|forMemStore
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|applyToMemStore
argument_list|(
name|e
operator|.
name|getKey
argument_list|()
argument_list|,
name|e
operator|.
name|getValue
argument_list|()
argument_list|,
literal|true
argument_list|,
name|memstoreAccounting
argument_list|)
expr_stmt|;
block|}
name|mvcc
operator|.
name|completeAndWait
argument_list|(
name|writeEntry
argument_list|)
expr_stmt|;
if|if
condition|(
name|rsServices
operator|!=
literal|null
operator|&&
name|rsServices
operator|.
name|getNonceManager
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|rsServices
operator|.
name|getNonceManager
argument_list|()
operator|.
name|addMvccToOperationContext
argument_list|(
name|nonceGroup
argument_list|,
name|nonce
argument_list|,
name|writeEntry
operator|.
name|getWriteNumber
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|writeEntry
operator|=
literal|null
expr_stmt|;
block|}
finally|finally
block|{
name|this
operator|.
name|updatesLock
operator|.
name|readLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
comment|// If results is null, then client asked that we not return the calculated results.
return|return
name|results
operator|!=
literal|null
operator|&&
name|returnResults
condition|?
name|Result
operator|.
name|create
argument_list|(
name|results
argument_list|)
else|:
name|Result
operator|.
name|EMPTY_RESULT
return|;
block|}
finally|finally
block|{
comment|// Call complete always, even on success. doDelta is doing a Get READ_UNCOMMITTED when it goes
comment|// to get current value under an exclusive lock so no need so no need to wait to return to
comment|// the client. Means only way to read-your-own-increment or append is to come in with an
comment|// a 0 increment.
if|if
condition|(
name|writeEntry
operator|!=
literal|null
condition|)
name|mvcc
operator|.
name|complete
argument_list|(
name|writeEntry
argument_list|)
expr_stmt|;
if|if
condition|(
name|rowLock
operator|!=
literal|null
condition|)
block|{
name|rowLock
operator|.
name|release
argument_list|()
expr_stmt|;
block|}
comment|// Request a cache flush if over the limit.  Do it outside update lock.
name|incMemStoreSize
argument_list|(
name|memstoreAccounting
operator|.
name|getMemStoreSize
argument_list|()
argument_list|)
expr_stmt|;
name|requestFlushIfNeeded
argument_list|()
expr_stmt|;
name|closeRegionOperation
argument_list|(
name|op
argument_list|)
expr_stmt|;
if|if
condition|(
name|this
operator|.
name|metricsRegion
operator|!=
literal|null
condition|)
block|{
switch|switch
condition|(
name|op
condition|)
block|{
case|case
name|INCREMENT
case|:
name|this
operator|.
name|metricsRegion
operator|.
name|updateIncrement
argument_list|()
expr_stmt|;
break|break;
case|case
name|APPEND
case|:
name|this
operator|.
name|metricsRegion
operator|.
name|updateAppend
argument_list|()
expr_stmt|;
break|break;
default|default:
break|break;
block|}
block|}
block|}
block|}
specifier|private
name|WriteEntry
name|doWALAppend
parameter_list|(
name|WALEdit
name|walEdit
parameter_list|,
name|Durability
name|durability
parameter_list|,
name|long
name|nonceGroup
parameter_list|,
name|long
name|nonce
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|doWALAppend
argument_list|(
name|walEdit
argument_list|,
name|durability
argument_list|,
name|WALKey
operator|.
name|EMPTY_UUIDS
argument_list|,
name|System
operator|.
name|currentTimeMillis
argument_list|()
argument_list|,
name|nonceGroup
argument_list|,
name|nonce
argument_list|)
return|;
block|}
specifier|private
name|WriteEntry
name|doWALAppend
parameter_list|(
name|WALEdit
name|walEdit
parameter_list|,
name|Durability
name|durability
parameter_list|,
name|List
argument_list|<
name|UUID
argument_list|>
name|clusterIds
parameter_list|,
name|long
name|now
parameter_list|,
name|long
name|nonceGroup
parameter_list|,
name|long
name|nonce
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|doWALAppend
argument_list|(
name|walEdit
argument_list|,
name|durability
argument_list|,
name|clusterIds
argument_list|,
name|now
argument_list|,
name|nonceGroup
argument_list|,
name|nonce
argument_list|,
name|SequenceId
operator|.
name|NO_SEQUENCE_ID
argument_list|)
return|;
block|}
comment|/**    * @return writeEntry associated with this append    */
specifier|private
name|WriteEntry
name|doWALAppend
parameter_list|(
name|WALEdit
name|walEdit
parameter_list|,
name|Durability
name|durability
parameter_list|,
name|List
argument_list|<
name|UUID
argument_list|>
name|clusterIds
parameter_list|,
name|long
name|now
parameter_list|,
name|long
name|nonceGroup
parameter_list|,
name|long
name|nonce
parameter_list|,
name|long
name|origLogSeqNum
parameter_list|)
throws|throws
name|IOException
block|{
name|Preconditions
operator|.
name|checkArgument
argument_list|(
name|walEdit
operator|!=
literal|null
operator|&&
operator|!
name|walEdit
operator|.
name|isEmpty
argument_list|()
argument_list|,
literal|"WALEdit is null or empty!"
argument_list|)
expr_stmt|;
name|Preconditions
operator|.
name|checkArgument
argument_list|(
operator|!
name|walEdit
operator|.
name|isReplay
argument_list|()
operator|||
name|origLogSeqNum
operator|!=
name|SequenceId
operator|.
name|NO_SEQUENCE_ID
argument_list|,
literal|"Invalid replay sequence Id for replay WALEdit!"
argument_list|)
expr_stmt|;
comment|// Using default cluster id, as this can only happen in the originating cluster.
comment|// A slave cluster receives the final value (not the delta) as a Put. We use HLogKey
comment|// here instead of WALKeyImpl directly to support legacy coprocessors.
name|WALKeyImpl
name|walKey
init|=
name|walEdit
operator|.
name|isReplay
argument_list|()
condition|?
operator|new
name|WALKeyImpl
argument_list|(
name|this
operator|.
name|getRegionInfo
argument_list|()
operator|.
name|getEncodedNameAsBytes
argument_list|()
argument_list|,
name|this
operator|.
name|htableDescriptor
operator|.
name|getTableName
argument_list|()
argument_list|,
name|SequenceId
operator|.
name|NO_SEQUENCE_ID
argument_list|,
name|now
argument_list|,
name|clusterIds
argument_list|,
name|nonceGroup
argument_list|,
name|nonce
argument_list|,
name|mvcc
argument_list|)
else|:
operator|new
name|WALKeyImpl
argument_list|(
name|this
operator|.
name|getRegionInfo
argument_list|()
operator|.
name|getEncodedNameAsBytes
argument_list|()
argument_list|,
name|this
operator|.
name|htableDescriptor
operator|.
name|getTableName
argument_list|()
argument_list|,
name|SequenceId
operator|.
name|NO_SEQUENCE_ID
argument_list|,
name|now
argument_list|,
name|clusterIds
argument_list|,
name|nonceGroup
argument_list|,
name|nonce
argument_list|,
name|mvcc
argument_list|,
name|this
operator|.
name|getReplicationScope
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|walEdit
operator|.
name|isReplay
argument_list|()
condition|)
block|{
name|walKey
operator|.
name|setOrigLogSeqNum
argument_list|(
name|origLogSeqNum
argument_list|)
expr_stmt|;
block|}
name|WriteEntry
name|writeEntry
init|=
literal|null
decl_stmt|;
try|try
block|{
name|long
name|txid
init|=
name|this
operator|.
name|wal
operator|.
name|append
argument_list|(
name|this
operator|.
name|getRegionInfo
argument_list|()
argument_list|,
name|walKey
argument_list|,
name|walEdit
argument_list|,
literal|true
argument_list|)
decl_stmt|;
comment|// Call sync on our edit.
if|if
condition|(
name|txid
operator|!=
literal|0
condition|)
block|{
name|sync
argument_list|(
name|txid
argument_list|,
name|durability
argument_list|)
expr_stmt|;
block|}
name|writeEntry
operator|=
name|walKey
operator|.
name|getWriteEntry
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ioe
parameter_list|)
block|{
if|if
condition|(
name|walKey
operator|!=
literal|null
operator|&&
name|walKey
operator|.
name|getWriteEntry
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|mvcc
operator|.
name|complete
argument_list|(
name|walKey
operator|.
name|getWriteEntry
argument_list|()
argument_list|)
expr_stmt|;
block|}
throw|throw
name|ioe
throw|;
block|}
return|return
name|writeEntry
return|;
block|}
comment|/**    * Do coprocessor pre-increment or pre-append call.    * @return Result returned out of the coprocessor, which means bypass all further processing and    *  return the proffered Result instead, or null which means proceed.    */
specifier|private
name|Result
name|doCoprocessorPreCall
parameter_list|(
specifier|final
name|Operation
name|op
parameter_list|,
specifier|final
name|Mutation
name|mutation
parameter_list|)
throws|throws
name|IOException
block|{
name|Result
name|result
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|this
operator|.
name|coprocessorHost
operator|!=
literal|null
condition|)
block|{
switch|switch
condition|(
name|op
condition|)
block|{
case|case
name|INCREMENT
case|:
name|result
operator|=
name|this
operator|.
name|coprocessorHost
operator|.
name|preIncrementAfterRowLock
argument_list|(
operator|(
name|Increment
operator|)
name|mutation
argument_list|)
expr_stmt|;
break|break;
case|case
name|APPEND
case|:
name|result
operator|=
name|this
operator|.
name|coprocessorHost
operator|.
name|preAppendAfterRowLock
argument_list|(
operator|(
name|Append
operator|)
name|mutation
argument_list|)
expr_stmt|;
break|break;
default|default:
throw|throw
operator|new
name|UnsupportedOperationException
argument_list|(
name|op
operator|.
name|toString
argument_list|()
argument_list|)
throw|;
block|}
block|}
return|return
name|result
return|;
block|}
comment|/**    * Reckon the Cells to apply to WAL, memstore, and to return to the Client; these Sets are not    * always the same dependent on whether to write WAL or if the amount to increment is zero (in    * this case we write back nothing, just return latest Cell value to the client).    *    * @param results Fill in here what goes back to the Client if it is non-null (if null, client    *  doesn't want results).    * @param forMemStore Fill in here what to apply to the MemStore (by Store).    * @return A WALEdit to apply to WAL or null if we are to skip the WAL.    */
specifier|private
name|WALEdit
name|reckonDeltas
parameter_list|(
name|Operation
name|op
parameter_list|,
name|Mutation
name|mutation
parameter_list|,
name|Durability
name|effectiveDurability
parameter_list|,
name|Map
argument_list|<
name|HStore
argument_list|,
name|List
argument_list|<
name|Cell
argument_list|>
argument_list|>
name|forMemStore
parameter_list|,
name|List
argument_list|<
name|Cell
argument_list|>
name|results
parameter_list|)
throws|throws
name|IOException
block|{
name|WALEdit
name|walEdit
init|=
literal|null
decl_stmt|;
name|long
name|now
init|=
name|EnvironmentEdgeManager
operator|.
name|currentTime
argument_list|()
decl_stmt|;
specifier|final
name|boolean
name|writeToWAL
init|=
name|effectiveDurability
operator|!=
name|Durability
operator|.
name|SKIP_WAL
decl_stmt|;
comment|// Process a Store/family at a time.
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|byte
index|[]
argument_list|,
name|List
argument_list|<
name|Cell
argument_list|>
argument_list|>
name|entry
range|:
name|mutation
operator|.
name|getFamilyCellMap
argument_list|()
operator|.
name|entrySet
argument_list|()
control|)
block|{
specifier|final
name|byte
index|[]
name|columnFamilyName
init|=
name|entry
operator|.
name|getKey
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|Cell
argument_list|>
name|deltas
init|=
name|entry
operator|.
name|getValue
argument_list|()
decl_stmt|;
name|HStore
name|store
init|=
name|this
operator|.
name|stores
operator|.
name|get
argument_list|(
name|columnFamilyName
argument_list|)
decl_stmt|;
comment|// Reckon for the Store what to apply to WAL and MemStore.
name|List
argument_list|<
name|Cell
argument_list|>
name|toApply
init|=
name|reckonDeltasByStore
argument_list|(
name|store
argument_list|,
name|op
argument_list|,
name|mutation
argument_list|,
name|effectiveDurability
argument_list|,
name|now
argument_list|,
name|deltas
argument_list|,
name|results
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|toApply
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|forMemStore
operator|.
name|put
argument_list|(
name|store
argument_list|,
name|toApply
argument_list|)
expr_stmt|;
if|if
condition|(
name|writeToWAL
condition|)
block|{
if|if
condition|(
name|walEdit
operator|==
literal|null
condition|)
block|{
name|walEdit
operator|=
operator|new
name|WALEdit
argument_list|()
expr_stmt|;
block|}
name|walEdit
operator|.
name|getCells
argument_list|()
operator|.
name|addAll
argument_list|(
name|toApply
argument_list|)
expr_stmt|;
block|}
block|}
block|}
return|return
name|walEdit
return|;
block|}
comment|/**    * Reckon the Cells to apply to WAL, memstore, and to return to the Client in passed    * column family/Store.    *    * Does Get of current value and then adds passed in deltas for this Store returning the result.    *    * @param op Whether Increment or Append    * @param mutation The encompassing Mutation object    * @param deltas Changes to apply to this Store; either increment amount or data to append    * @param results In here we accumulate all the Cells we are to return to the client; this List    *  can be larger than what we return in case where delta is zero; i.e. don't write    *  out new values, just return current value. If null, client doesn't want results returned.    * @return Resulting Cells after<code>deltas</code> have been applied to current    *  values. Side effect is our filling out of the<code>results</code> List.    */
specifier|private
name|List
argument_list|<
name|Cell
argument_list|>
name|reckonDeltasByStore
parameter_list|(
name|HStore
name|store
parameter_list|,
name|Operation
name|op
parameter_list|,
name|Mutation
name|mutation
parameter_list|,
name|Durability
name|effectiveDurability
parameter_list|,
name|long
name|now
parameter_list|,
name|List
argument_list|<
name|Cell
argument_list|>
name|deltas
parameter_list|,
name|List
argument_list|<
name|Cell
argument_list|>
name|results
parameter_list|)
throws|throws
name|IOException
block|{
name|byte
index|[]
name|columnFamily
init|=
name|store
operator|.
name|getColumnFamilyDescriptor
argument_list|()
operator|.
name|getName
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|Cell
argument_list|>
name|toApply
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
name|deltas
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
comment|// Get previous values for all columns in this family.
name|TimeRange
name|tr
init|=
literal|null
decl_stmt|;
switch|switch
condition|(
name|op
condition|)
block|{
case|case
name|INCREMENT
case|:
name|tr
operator|=
operator|(
operator|(
name|Increment
operator|)
name|mutation
operator|)
operator|.
name|getTimeRange
argument_list|()
expr_stmt|;
break|break;
case|case
name|APPEND
case|:
name|tr
operator|=
operator|(
operator|(
name|Append
operator|)
name|mutation
operator|)
operator|.
name|getTimeRange
argument_list|()
expr_stmt|;
break|break;
default|default:
break|break;
block|}
name|List
argument_list|<
name|Cell
argument_list|>
name|currentValues
init|=
name|get
argument_list|(
name|mutation
argument_list|,
name|store
argument_list|,
name|deltas
argument_list|,
literal|null
argument_list|,
name|tr
argument_list|)
decl_stmt|;
comment|// Iterate the input columns and update existing values if they were found, otherwise
comment|// add new column initialized to the delta amount
name|int
name|currentValuesIndex
init|=
literal|0
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|deltas
operator|.
name|size
argument_list|()
condition|;
name|i
operator|++
control|)
block|{
name|Cell
name|delta
init|=
name|deltas
operator|.
name|get
argument_list|(
name|i
argument_list|)
decl_stmt|;
name|Cell
name|currentValue
init|=
literal|null
decl_stmt|;
name|boolean
name|firstWrite
init|=
literal|false
decl_stmt|;
if|if
condition|(
name|currentValuesIndex
operator|<
name|currentValues
operator|.
name|size
argument_list|()
operator|&&
name|CellUtil
operator|.
name|matchingQualifier
argument_list|(
name|currentValues
operator|.
name|get
argument_list|(
name|currentValuesIndex
argument_list|)
argument_list|,
name|delta
argument_list|)
condition|)
block|{
name|currentValue
operator|=
name|currentValues
operator|.
name|get
argument_list|(
name|currentValuesIndex
argument_list|)
expr_stmt|;
if|if
condition|(
name|i
operator|<
operator|(
name|deltas
operator|.
name|size
argument_list|()
operator|-
literal|1
operator|)
operator|&&
operator|!
name|CellUtil
operator|.
name|matchingQualifier
argument_list|(
name|delta
argument_list|,
name|deltas
operator|.
name|get
argument_list|(
name|i
operator|+
literal|1
argument_list|)
argument_list|)
condition|)
block|{
name|currentValuesIndex
operator|++
expr_stmt|;
block|}
block|}
else|else
block|{
name|firstWrite
operator|=
literal|true
expr_stmt|;
block|}
comment|// Switch on whether this an increment or an append building the new Cell to apply.
name|Cell
name|newCell
init|=
literal|null
decl_stmt|;
name|MutationType
name|mutationType
init|=
literal|null
decl_stmt|;
name|boolean
name|apply
init|=
literal|true
decl_stmt|;
switch|switch
condition|(
name|op
condition|)
block|{
case|case
name|INCREMENT
case|:
name|mutationType
operator|=
name|MutationType
operator|.
name|INCREMENT
expr_stmt|;
comment|// If delta amount to apply is 0, don't write WAL or MemStore.
name|long
name|deltaAmount
init|=
name|getLongValue
argument_list|(
name|delta
argument_list|)
decl_stmt|;
comment|// TODO: Does zero value mean reset Cell? For example, the ttl.
name|apply
operator|=
name|deltaAmount
operator|!=
literal|0
expr_stmt|;
specifier|final
name|long
name|newValue
init|=
name|currentValue
operator|==
literal|null
condition|?
name|deltaAmount
else|:
name|getLongValue
argument_list|(
name|currentValue
argument_list|)
operator|+
name|deltaAmount
decl_stmt|;
name|newCell
operator|=
name|reckonDelta
argument_list|(
name|delta
argument_list|,
name|currentValue
argument_list|,
name|columnFamily
argument_list|,
name|now
argument_list|,
name|mutation
argument_list|,
parameter_list|(
name|oldCell
parameter_list|)
lambda|->
name|Bytes
operator|.
name|toBytes
argument_list|(
name|newValue
argument_list|)
argument_list|)
expr_stmt|;
break|break;
case|case
name|APPEND
case|:
name|mutationType
operator|=
name|MutationType
operator|.
name|APPEND
expr_stmt|;
comment|// Always apply Append. TODO: Does empty delta value mean reset Cell? It seems to.
name|newCell
operator|=
name|reckonDelta
argument_list|(
name|delta
argument_list|,
name|currentValue
argument_list|,
name|columnFamily
argument_list|,
name|now
argument_list|,
name|mutation
argument_list|,
parameter_list|(
name|oldCell
parameter_list|)
lambda|->
name|ByteBuffer
operator|.
name|wrap
argument_list|(
operator|new
name|byte
index|[
name|delta
operator|.
name|getValueLength
argument_list|()
operator|+
name|oldCell
operator|.
name|getValueLength
argument_list|()
index|]
argument_list|)
operator|.
name|put
argument_list|(
name|oldCell
operator|.
name|getValueArray
argument_list|()
argument_list|,
name|oldCell
operator|.
name|getValueOffset
argument_list|()
argument_list|,
name|oldCell
operator|.
name|getValueLength
argument_list|()
argument_list|)
operator|.
name|put
argument_list|(
name|delta
operator|.
name|getValueArray
argument_list|()
argument_list|,
name|delta
operator|.
name|getValueOffset
argument_list|()
argument_list|,
name|delta
operator|.
name|getValueLength
argument_list|()
argument_list|)
operator|.
name|array
argument_list|()
argument_list|)
expr_stmt|;
break|break;
default|default:
throw|throw
operator|new
name|UnsupportedOperationException
argument_list|(
name|op
operator|.
name|toString
argument_list|()
argument_list|)
throw|;
block|}
comment|// Give coprocessors a chance to update the new cell
if|if
condition|(
name|coprocessorHost
operator|!=
literal|null
condition|)
block|{
name|newCell
operator|=
name|coprocessorHost
operator|.
name|postMutationBeforeWAL
argument_list|(
name|mutationType
argument_list|,
name|mutation
argument_list|,
name|currentValue
argument_list|,
name|newCell
argument_list|)
expr_stmt|;
block|}
comment|// If apply, we need to update memstore/WAL with new value; add it toApply.
if|if
condition|(
name|apply
operator|||
name|firstWrite
condition|)
block|{
name|toApply
operator|.
name|add
argument_list|(
name|newCell
argument_list|)
expr_stmt|;
block|}
comment|// Add to results to get returned to the Client. If null, cilent does not want results.
if|if
condition|(
name|results
operator|!=
literal|null
condition|)
block|{
name|results
operator|.
name|add
argument_list|(
name|newCell
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|toApply
return|;
block|}
specifier|private
specifier|static
name|Cell
name|reckonDelta
parameter_list|(
specifier|final
name|Cell
name|delta
parameter_list|,
specifier|final
name|Cell
name|currentCell
parameter_list|,
specifier|final
name|byte
index|[]
name|columnFamily
parameter_list|,
specifier|final
name|long
name|now
parameter_list|,
name|Mutation
name|mutation
parameter_list|,
name|Function
argument_list|<
name|Cell
argument_list|,
name|byte
index|[]
argument_list|>
name|supplier
parameter_list|)
throws|throws
name|IOException
block|{
comment|// Forward any tags found on the delta.
name|List
argument_list|<
name|Tag
argument_list|>
name|tags
init|=
name|TagUtil
operator|.
name|carryForwardTags
argument_list|(
name|delta
argument_list|)
decl_stmt|;
name|tags
operator|=
name|TagUtil
operator|.
name|carryForwardTTLTag
argument_list|(
name|tags
argument_list|,
name|mutation
operator|.
name|getTTL
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|currentCell
operator|!=
literal|null
condition|)
block|{
name|tags
operator|=
name|TagUtil
operator|.
name|carryForwardTags
argument_list|(
name|tags
argument_list|,
name|currentCell
argument_list|)
expr_stmt|;
name|byte
index|[]
name|newValue
init|=
name|supplier
operator|.
name|apply
argument_list|(
name|currentCell
argument_list|)
decl_stmt|;
return|return
name|ExtendedCellBuilderFactory
operator|.
name|create
argument_list|(
name|CellBuilderType
operator|.
name|SHALLOW_COPY
argument_list|)
operator|.
name|setRow
argument_list|(
name|mutation
operator|.
name|getRow
argument_list|()
argument_list|,
literal|0
argument_list|,
name|mutation
operator|.
name|getRow
argument_list|()
operator|.
name|length
argument_list|)
operator|.
name|setFamily
argument_list|(
name|columnFamily
argument_list|,
literal|0
argument_list|,
name|columnFamily
operator|.
name|length
argument_list|)
comment|// copy the qualifier if the cell is located in shared memory.
operator|.
name|setQualifier
argument_list|(
name|CellUtil
operator|.
name|cloneQualifier
argument_list|(
name|delta
argument_list|)
argument_list|)
operator|.
name|setTimestamp
argument_list|(
name|Math
operator|.
name|max
argument_list|(
name|currentCell
operator|.
name|getTimestamp
argument_list|()
operator|+
literal|1
argument_list|,
name|now
argument_list|)
argument_list|)
operator|.
name|setType
argument_list|(
name|KeyValue
operator|.
name|Type
operator|.
name|Put
operator|.
name|getCode
argument_list|()
argument_list|)
operator|.
name|setValue
argument_list|(
name|newValue
argument_list|,
literal|0
argument_list|,
name|newValue
operator|.
name|length
argument_list|)
operator|.
name|setTags
argument_list|(
name|TagUtil
operator|.
name|fromList
argument_list|(
name|tags
argument_list|)
argument_list|)
operator|.
name|build
argument_list|()
return|;
block|}
else|else
block|{
name|PrivateCellUtil
operator|.
name|updateLatestStamp
argument_list|(
name|delta
argument_list|,
name|now
argument_list|)
expr_stmt|;
return|return
name|CollectionUtils
operator|.
name|isEmpty
argument_list|(
name|tags
argument_list|)
condition|?
name|delta
else|:
name|PrivateCellUtil
operator|.
name|createCell
argument_list|(
name|delta
argument_list|,
name|tags
argument_list|)
return|;
block|}
block|}
comment|/**    * @return Get the long out of the passed in Cell    */
specifier|private
specifier|static
name|long
name|getLongValue
parameter_list|(
specifier|final
name|Cell
name|cell
parameter_list|)
throws|throws
name|DoNotRetryIOException
block|{
name|int
name|len
init|=
name|cell
operator|.
name|getValueLength
argument_list|()
decl_stmt|;
if|if
condition|(
name|len
operator|!=
name|Bytes
operator|.
name|SIZEOF_LONG
condition|)
block|{
comment|// throw DoNotRetryIOException instead of IllegalArgumentException
throw|throw
operator|new
name|DoNotRetryIOException
argument_list|(
literal|"Field is not a long, it's "
operator|+
name|len
operator|+
literal|" bytes wide"
argument_list|)
throw|;
block|}
return|return
name|PrivateCellUtil
operator|.
name|getValueAsLong
argument_list|(
name|cell
argument_list|)
return|;
block|}
comment|/**    * Do a specific Get on passed<code>columnFamily</code> and column qualifiers.    * @param mutation Mutation we are doing this Get for.    * @param store Which column family on row (TODO: Go all Gets in one go)    * @param coordinates Cells from<code>mutation</code> used as coordinates applied to Get.    * @return Return list of Cells found.    */
specifier|private
name|List
argument_list|<
name|Cell
argument_list|>
name|get
parameter_list|(
name|Mutation
name|mutation
parameter_list|,
name|HStore
name|store
parameter_list|,
name|List
argument_list|<
name|Cell
argument_list|>
name|coordinates
parameter_list|,
name|IsolationLevel
name|isolation
parameter_list|,
name|TimeRange
name|tr
parameter_list|)
throws|throws
name|IOException
block|{
comment|// Sort the cells so that they match the order that they appear in the Get results. Otherwise,
comment|// we won't be able to find the existing values if the cells are not specified in order by the
comment|// client since cells are in an array list.
comment|// TODO: I don't get why we are sorting. St.Ack 20150107
name|sort
argument_list|(
name|coordinates
argument_list|,
name|store
operator|.
name|getComparator
argument_list|()
argument_list|)
expr_stmt|;
name|Get
name|get
init|=
operator|new
name|Get
argument_list|(
name|mutation
operator|.
name|getRow
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|isolation
operator|!=
literal|null
condition|)
block|{
name|get
operator|.
name|setIsolationLevel
argument_list|(
name|isolation
argument_list|)
expr_stmt|;
block|}
for|for
control|(
name|Cell
name|cell
range|:
name|coordinates
control|)
block|{
name|get
operator|.
name|addColumn
argument_list|(
name|store
operator|.
name|getColumnFamilyDescriptor
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|,
name|CellUtil
operator|.
name|cloneQualifier
argument_list|(
name|cell
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|// Increments carry time range. If an Increment instance, put it on the Get.
if|if
condition|(
name|tr
operator|!=
literal|null
condition|)
block|{
name|get
operator|.
name|setTimeRange
argument_list|(
name|tr
operator|.
name|getMin
argument_list|()
argument_list|,
name|tr
operator|.
name|getMax
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
name|get
argument_list|(
name|get
argument_list|,
literal|false
argument_list|)
return|;
block|}
comment|/**    * @return Sorted list of<code>cells</code> using<code>comparator</code>    */
specifier|private
specifier|static
name|List
argument_list|<
name|Cell
argument_list|>
name|sort
parameter_list|(
name|List
argument_list|<
name|Cell
argument_list|>
name|cells
parameter_list|,
specifier|final
name|CellComparator
name|comparator
parameter_list|)
block|{
name|cells
operator|.
name|sort
argument_list|(
name|comparator
argument_list|)
expr_stmt|;
return|return
name|cells
return|;
block|}
comment|//
comment|// New HBASE-880 Helpers
comment|//
name|void
name|checkFamily
parameter_list|(
specifier|final
name|byte
index|[]
name|family
parameter_list|)
throws|throws
name|NoSuchColumnFamilyException
block|{
if|if
condition|(
operator|!
name|this
operator|.
name|htableDescriptor
operator|.
name|hasColumnFamily
argument_list|(
name|family
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|NoSuchColumnFamilyException
argument_list|(
literal|"Column family "
operator|+
name|Bytes
operator|.
name|toString
argument_list|(
name|family
argument_list|)
operator|+
literal|" does not exist in region "
operator|+
name|this
operator|+
literal|" in table "
operator|+
name|this
operator|.
name|htableDescriptor
argument_list|)
throw|;
block|}
block|}
specifier|public
specifier|static
specifier|final
name|long
name|FIXED_OVERHEAD
init|=
name|ClassSize
operator|.
name|align
argument_list|(
name|ClassSize
operator|.
name|OBJECT
operator|+
name|ClassSize
operator|.
name|ARRAY
operator|+
literal|51
operator|*
name|ClassSize
operator|.
name|REFERENCE
operator|+
literal|3
operator|*
name|Bytes
operator|.
name|SIZEOF_INT
operator|+
operator|(
literal|15
operator|*
name|Bytes
operator|.
name|SIZEOF_LONG
operator|)
operator|+
literal|3
operator|*
name|Bytes
operator|.
name|SIZEOF_BOOLEAN
argument_list|)
decl_stmt|;
comment|// woefully out of date - currently missing:
comment|// 1 x HashMap - coprocessorServiceHandlers
comment|// 6 x LongAdder - numMutationsWithoutWAL, dataInMemoryWithoutWAL,
comment|//   checkAndMutateChecksPassed, checkAndMutateChecksFailed, readRequestsCount,
comment|//   writeRequestsCount, cpRequestsCount
comment|// 1 x HRegion$WriteState - writestate
comment|// 1 x RegionCoprocessorHost - coprocessorHost
comment|// 1 x RegionSplitPolicy - splitPolicy
comment|// 1 x MetricsRegion - metricsRegion
comment|// 1 x MetricsRegionWrapperImpl - metricsRegionWrapper
specifier|public
specifier|static
specifier|final
name|long
name|DEEP_OVERHEAD
init|=
name|FIXED_OVERHEAD
operator|+
name|ClassSize
operator|.
name|OBJECT
operator|+
comment|// closeLock
operator|(
literal|2
operator|*
name|ClassSize
operator|.
name|ATOMIC_BOOLEAN
operator|)
operator|+
comment|// closed, closing
operator|(
literal|3
operator|*
name|ClassSize
operator|.
name|ATOMIC_LONG
operator|)
operator|+
comment|// numPutsWithoutWAL, dataInMemoryWithoutWAL,
comment|// compactionsFailed
operator|(
literal|2
operator|*
name|ClassSize
operator|.
name|CONCURRENT_HASHMAP
operator|)
operator|+
comment|// lockedRows, scannerReadPoints
name|WriteState
operator|.
name|HEAP_SIZE
operator|+
comment|// writestate
name|ClassSize
operator|.
name|CONCURRENT_SKIPLISTMAP
operator|+
name|ClassSize
operator|.
name|CONCURRENT_SKIPLISTMAP_ENTRY
operator|+
comment|// stores
operator|(
literal|2
operator|*
name|ClassSize
operator|.
name|REENTRANT_LOCK
operator|)
operator|+
comment|// lock, updatesLock
name|MultiVersionConcurrencyControl
operator|.
name|FIXED_SIZE
comment|// mvcc
operator|+
literal|2
operator|*
name|ClassSize
operator|.
name|TREEMAP
comment|// maxSeqIdInStores, replicationScopes
operator|+
literal|2
operator|*
name|ClassSize
operator|.
name|ATOMIC_INTEGER
comment|// majorInProgress, minorInProgress
operator|+
name|ClassSize
operator|.
name|STORE_SERVICES
comment|// store services
operator|+
name|StoreHotnessProtector
operator|.
name|FIXED_SIZE
decl_stmt|;
annotation|@
name|Override
specifier|public
name|long
name|heapSize
parameter_list|()
block|{
comment|// this does not take into account row locks, recent flushes, mvcc entries, and more
return|return
name|DEEP_OVERHEAD
operator|+
name|stores
operator|.
name|values
argument_list|()
operator|.
name|stream
argument_list|()
operator|.
name|mapToLong
argument_list|(
name|HStore
operator|::
name|heapSize
argument_list|)
operator|.
name|sum
argument_list|()
return|;
block|}
comment|/**    * Registers a new protocol buffer {@link Service} subclass as a coprocessor endpoint to    * be available for handling Region#execService(com.google.protobuf.RpcController,    *    org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall) calls.    *    *<p>    * Only a single instance may be registered per region for a given {@link Service} subclass (the    * instances are keyed on {@link com.google.protobuf.Descriptors.ServiceDescriptor#getFullName()}.    * After the first registration, subsequent calls with the same service name will fail with    * a return value of {@code false}.    *</p>    * @param instance the {@code Service} subclass instance to expose as a coprocessor endpoint    * @return {@code true} if the registration was successful, {@code false}    * otherwise    */
specifier|public
name|boolean
name|registerService
parameter_list|(
name|com
operator|.
name|google
operator|.
name|protobuf
operator|.
name|Service
name|instance
parameter_list|)
block|{
comment|/*      * No stacking of instances is allowed for a single service name      */
name|com
operator|.
name|google
operator|.
name|protobuf
operator|.
name|Descriptors
operator|.
name|ServiceDescriptor
name|serviceDesc
init|=
name|instance
operator|.
name|getDescriptorForType
argument_list|()
decl_stmt|;
name|String
name|serviceName
init|=
name|CoprocessorRpcUtils
operator|.
name|getServiceName
argument_list|(
name|serviceDesc
argument_list|)
decl_stmt|;
if|if
condition|(
name|coprocessorServiceHandlers
operator|.
name|containsKey
argument_list|(
name|serviceName
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Coprocessor service "
operator|+
name|serviceName
operator|+
literal|" already registered, rejecting request from "
operator|+
name|instance
argument_list|)
expr_stmt|;
return|return
literal|false
return|;
block|}
name|coprocessorServiceHandlers
operator|.
name|put
argument_list|(
name|serviceName
argument_list|,
name|instance
argument_list|)
expr_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Registered coprocessor service: region="
operator|+
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|getRegionInfo
argument_list|()
operator|.
name|getRegionName
argument_list|()
argument_list|)
operator|+
literal|" service="
operator|+
name|serviceName
argument_list|)
expr_stmt|;
block|}
return|return
literal|true
return|;
block|}
comment|/**    * Executes a single protocol buffer coprocessor endpoint {@link Service} method using    * the registered protocol handlers.  {@link Service} implementations must be registered via the    * {@link #registerService(com.google.protobuf.Service)}    * method before they are available.    *    * @param controller an {@code RpcContoller} implementation to pass to the invoked service    * @param call a {@code CoprocessorServiceCall} instance identifying the service, method,    *     and parameters for the method invocation    * @return a protocol buffer {@code Message} instance containing the method's result    * @throws IOException if no registered service handler is found or an error    *     occurs during the invocation    * @see #registerService(com.google.protobuf.Service)    */
specifier|public
name|com
operator|.
name|google
operator|.
name|protobuf
operator|.
name|Message
name|execService
parameter_list|(
name|com
operator|.
name|google
operator|.
name|protobuf
operator|.
name|RpcController
name|controller
parameter_list|,
name|CoprocessorServiceCall
name|call
parameter_list|)
throws|throws
name|IOException
block|{
name|String
name|serviceName
init|=
name|call
operator|.
name|getServiceName
argument_list|()
decl_stmt|;
name|com
operator|.
name|google
operator|.
name|protobuf
operator|.
name|Service
name|service
init|=
name|coprocessorServiceHandlers
operator|.
name|get
argument_list|(
name|serviceName
argument_list|)
decl_stmt|;
if|if
condition|(
name|service
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|UnknownProtocolException
argument_list|(
literal|null
argument_list|,
literal|"No registered coprocessor service found for "
operator|+
name|serviceName
operator|+
literal|" in region "
operator|+
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|getRegionInfo
argument_list|()
operator|.
name|getRegionName
argument_list|()
argument_list|)
argument_list|)
throw|;
block|}
name|com
operator|.
name|google
operator|.
name|protobuf
operator|.
name|Descriptors
operator|.
name|ServiceDescriptor
name|serviceDesc
init|=
name|service
operator|.
name|getDescriptorForType
argument_list|()
decl_stmt|;
name|cpRequestsCount
operator|.
name|increment
argument_list|()
expr_stmt|;
name|String
name|methodName
init|=
name|call
operator|.
name|getMethodName
argument_list|()
decl_stmt|;
name|com
operator|.
name|google
operator|.
name|protobuf
operator|.
name|Descriptors
operator|.
name|MethodDescriptor
name|methodDesc
init|=
name|CoprocessorRpcUtils
operator|.
name|getMethodDescriptor
argument_list|(
name|methodName
argument_list|,
name|serviceDesc
argument_list|)
decl_stmt|;
name|com
operator|.
name|google
operator|.
name|protobuf
operator|.
name|Message
operator|.
name|Builder
name|builder
init|=
name|service
operator|.
name|getRequestPrototype
argument_list|(
name|methodDesc
argument_list|)
operator|.
name|newBuilderForType
argument_list|()
decl_stmt|;
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|protobuf
operator|.
name|ProtobufUtil
operator|.
name|mergeFrom
argument_list|(
name|builder
argument_list|,
name|call
operator|.
name|getRequest
argument_list|()
operator|.
name|toByteArray
argument_list|()
argument_list|)
expr_stmt|;
name|com
operator|.
name|google
operator|.
name|protobuf
operator|.
name|Message
name|request
init|=
name|CoprocessorRpcUtils
operator|.
name|getRequest
argument_list|(
name|service
argument_list|,
name|methodDesc
argument_list|,
name|call
operator|.
name|getRequest
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|coprocessorHost
operator|!=
literal|null
condition|)
block|{
name|request
operator|=
name|coprocessorHost
operator|.
name|preEndpointInvocation
argument_list|(
name|service
argument_list|,
name|methodName
argument_list|,
name|request
argument_list|)
expr_stmt|;
block|}
specifier|final
name|com
operator|.
name|google
operator|.
name|protobuf
operator|.
name|Message
operator|.
name|Builder
name|responseBuilder
init|=
name|service
operator|.
name|getResponsePrototype
argument_list|(
name|methodDesc
argument_list|)
operator|.
name|newBuilderForType
argument_list|()
decl_stmt|;
name|service
operator|.
name|callMethod
argument_list|(
name|methodDesc
argument_list|,
name|controller
argument_list|,
name|request
argument_list|,
operator|new
name|com
operator|.
name|google
operator|.
name|protobuf
operator|.
name|RpcCallback
argument_list|<
name|com
operator|.
name|google
operator|.
name|protobuf
operator|.
name|Message
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|void
name|run
parameter_list|(
name|com
operator|.
name|google
operator|.
name|protobuf
operator|.
name|Message
name|message
parameter_list|)
block|{
if|if
condition|(
name|message
operator|!=
literal|null
condition|)
block|{
name|responseBuilder
operator|.
name|mergeFrom
argument_list|(
name|message
argument_list|)
expr_stmt|;
block|}
block|}
block|}
argument_list|)
expr_stmt|;
if|if
condition|(
name|coprocessorHost
operator|!=
literal|null
condition|)
block|{
name|coprocessorHost
operator|.
name|postEndpointInvocation
argument_list|(
name|service
argument_list|,
name|methodName
argument_list|,
name|request
argument_list|,
name|responseBuilder
argument_list|)
expr_stmt|;
block|}
name|IOException
name|exception
init|=
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|ipc
operator|.
name|CoprocessorRpcUtils
operator|.
name|getControllerException
argument_list|(
name|controller
argument_list|)
decl_stmt|;
if|if
condition|(
name|exception
operator|!=
literal|null
condition|)
block|{
throw|throw
name|exception
throw|;
block|}
return|return
name|responseBuilder
operator|.
name|build
argument_list|()
return|;
block|}
name|boolean
name|shouldForceSplit
parameter_list|()
block|{
return|return
name|this
operator|.
name|splitRequest
return|;
block|}
name|byte
index|[]
name|getExplicitSplitPoint
parameter_list|()
block|{
return|return
name|this
operator|.
name|explicitSplitPoint
return|;
block|}
name|void
name|forceSplit
parameter_list|(
name|byte
index|[]
name|sp
parameter_list|)
block|{
comment|// This HRegion will go away after the forced split is successful
comment|// But if a forced split fails, we need to clear forced split.
name|this
operator|.
name|splitRequest
operator|=
literal|true
expr_stmt|;
if|if
condition|(
name|sp
operator|!=
literal|null
condition|)
block|{
name|this
operator|.
name|explicitSplitPoint
operator|=
name|sp
expr_stmt|;
block|}
block|}
name|void
name|clearSplit
parameter_list|()
block|{
name|this
operator|.
name|splitRequest
operator|=
literal|false
expr_stmt|;
name|this
operator|.
name|explicitSplitPoint
operator|=
literal|null
expr_stmt|;
block|}
comment|/**    * Return the splitpoint. null indicates the region isn't splittable    * If the splitpoint isn't explicitly specified, it will go over the stores    * to find the best splitpoint. Currently the criteria of best splitpoint    * is based on the size of the store.    */
specifier|public
name|byte
index|[]
name|checkSplit
parameter_list|()
block|{
comment|// Can't split META
if|if
condition|(
name|this
operator|.
name|getRegionInfo
argument_list|()
operator|.
name|isMetaRegion
argument_list|()
operator|||
name|TableName
operator|.
name|NAMESPACE_TABLE_NAME
operator|.
name|equals
argument_list|(
name|this
operator|.
name|getRegionInfo
argument_list|()
operator|.
name|getTable
argument_list|()
argument_list|)
condition|)
block|{
if|if
condition|(
name|shouldForceSplit
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Cannot split meta region in HBase 0.20 and above"
argument_list|)
expr_stmt|;
block|}
return|return
literal|null
return|;
block|}
comment|// Can't split a region that is closing.
if|if
condition|(
name|this
operator|.
name|isClosing
argument_list|()
condition|)
block|{
return|return
literal|null
return|;
block|}
if|if
condition|(
operator|!
name|splitPolicy
operator|.
name|shouldSplit
argument_list|()
condition|)
block|{
return|return
literal|null
return|;
block|}
name|byte
index|[]
name|ret
init|=
name|splitPolicy
operator|.
name|getSplitPoint
argument_list|()
decl_stmt|;
if|if
condition|(
name|ret
operator|!=
literal|null
condition|)
block|{
try|try
block|{
name|checkRow
argument_list|(
name|ret
argument_list|,
literal|"calculated split"
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Ignoring invalid split"
argument_list|,
name|e
argument_list|)
expr_stmt|;
return|return
literal|null
return|;
block|}
block|}
return|return
name|ret
return|;
block|}
comment|/**    * @return The priority that this region should have in the compaction queue    */
specifier|public
name|int
name|getCompactPriority
parameter_list|()
block|{
return|return
name|stores
operator|.
name|values
argument_list|()
operator|.
name|stream
argument_list|()
operator|.
name|mapToInt
argument_list|(
name|HStore
operator|::
name|getCompactPriority
argument_list|)
operator|.
name|min
argument_list|()
operator|.
name|orElse
argument_list|(
name|Store
operator|.
name|NO_PRIORITY
argument_list|)
return|;
block|}
comment|/** @return the coprocessor host */
specifier|public
name|RegionCoprocessorHost
name|getCoprocessorHost
parameter_list|()
block|{
return|return
name|coprocessorHost
return|;
block|}
comment|/** @param coprocessorHost the new coprocessor host */
annotation|@
name|VisibleForTesting
specifier|public
name|void
name|setCoprocessorHost
parameter_list|(
specifier|final
name|RegionCoprocessorHost
name|coprocessorHost
parameter_list|)
block|{
name|this
operator|.
name|coprocessorHost
operator|=
name|coprocessorHost
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|startRegionOperation
parameter_list|()
throws|throws
name|IOException
block|{
name|startRegionOperation
argument_list|(
name|Operation
operator|.
name|ANY
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|startRegionOperation
parameter_list|(
name|Operation
name|op
parameter_list|)
throws|throws
name|IOException
block|{
switch|switch
condition|(
name|op
condition|)
block|{
case|case
name|GET
case|:
comment|// read operations
case|case
name|SCAN
case|:
name|checkReadsEnabled
argument_list|()
expr_stmt|;
break|break;
default|default:
break|break;
block|}
if|if
condition|(
name|op
operator|==
name|Operation
operator|.
name|MERGE_REGION
operator|||
name|op
operator|==
name|Operation
operator|.
name|SPLIT_REGION
operator|||
name|op
operator|==
name|Operation
operator|.
name|COMPACT_REGION
condition|)
block|{
comment|// split, merge or compact region doesn't need to check the closing/closed state or lock the
comment|// region
return|return;
block|}
if|if
condition|(
name|this
operator|.
name|closing
operator|.
name|get
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|NotServingRegionException
argument_list|(
name|getRegionInfo
argument_list|()
operator|.
name|getRegionNameAsString
argument_list|()
operator|+
literal|" is closing"
argument_list|)
throw|;
block|}
name|lock
argument_list|(
name|lock
operator|.
name|readLock
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|this
operator|.
name|closed
operator|.
name|get
argument_list|()
condition|)
block|{
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
throw|throw
operator|new
name|NotServingRegionException
argument_list|(
name|getRegionInfo
argument_list|()
operator|.
name|getRegionNameAsString
argument_list|()
operator|+
literal|" is closed"
argument_list|)
throw|;
block|}
comment|// The unit for snapshot is a region. So, all stores for this region must be
comment|// prepared for snapshot operation before proceeding.
if|if
condition|(
name|op
operator|==
name|Operation
operator|.
name|SNAPSHOT
condition|)
block|{
name|stores
operator|.
name|values
argument_list|()
operator|.
name|forEach
argument_list|(
name|HStore
operator|::
name|preSnapshotOperation
argument_list|)
expr_stmt|;
block|}
try|try
block|{
if|if
condition|(
name|coprocessorHost
operator|!=
literal|null
condition|)
block|{
name|coprocessorHost
operator|.
name|postStartRegionOperation
argument_list|(
name|op
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
throw|throw
operator|new
name|IOException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|void
name|closeRegionOperation
parameter_list|()
throws|throws
name|IOException
block|{
name|closeRegionOperation
argument_list|(
name|Operation
operator|.
name|ANY
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|closeRegionOperation
parameter_list|(
name|Operation
name|operation
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|operation
operator|==
name|Operation
operator|.
name|SNAPSHOT
condition|)
block|{
name|stores
operator|.
name|values
argument_list|()
operator|.
name|forEach
argument_list|(
name|HStore
operator|::
name|postSnapshotOperation
argument_list|)
expr_stmt|;
block|}
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
if|if
condition|(
name|coprocessorHost
operator|!=
literal|null
condition|)
block|{
name|coprocessorHost
operator|.
name|postCloseRegionOperation
argument_list|(
name|operation
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * This method needs to be called before any public call that reads or    * modifies stores in bulk. It has to be called just before a try.    * #closeBulkRegionOperation needs to be called in the try's finally block    * Acquires a writelock and checks if the region is closing or closed.    * @throws NotServingRegionException when the region is closing or closed    * @throws RegionTooBusyException if failed to get the lock in time    * @throws InterruptedIOException if interrupted while waiting for a lock    */
specifier|private
name|void
name|startBulkRegionOperation
parameter_list|(
name|boolean
name|writeLockNeeded
parameter_list|)
throws|throws
name|NotServingRegionException
throws|,
name|RegionTooBusyException
throws|,
name|InterruptedIOException
block|{
if|if
condition|(
name|this
operator|.
name|closing
operator|.
name|get
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|NotServingRegionException
argument_list|(
name|getRegionInfo
argument_list|()
operator|.
name|getRegionNameAsString
argument_list|()
operator|+
literal|" is closing"
argument_list|)
throw|;
block|}
if|if
condition|(
name|writeLockNeeded
condition|)
name|lock
argument_list|(
name|lock
operator|.
name|writeLock
argument_list|()
argument_list|)
expr_stmt|;
else|else
name|lock
argument_list|(
name|lock
operator|.
name|readLock
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|this
operator|.
name|closed
operator|.
name|get
argument_list|()
condition|)
block|{
if|if
condition|(
name|writeLockNeeded
condition|)
name|lock
operator|.
name|writeLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
else|else
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
throw|throw
operator|new
name|NotServingRegionException
argument_list|(
name|getRegionInfo
argument_list|()
operator|.
name|getRegionNameAsString
argument_list|()
operator|+
literal|" is closed"
argument_list|)
throw|;
block|}
block|}
comment|/**    * Closes the lock. This needs to be called in the finally block corresponding    * to the try block of #startRegionOperation    */
specifier|private
name|void
name|closeBulkRegionOperation
parameter_list|()
block|{
if|if
condition|(
name|lock
operator|.
name|writeLock
argument_list|()
operator|.
name|isHeldByCurrentThread
argument_list|()
condition|)
name|lock
operator|.
name|writeLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
else|else
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
comment|/**    * Update LongAdders for number of puts without wal and the size of possible data loss.    * These information are exposed by the region server metrics.    */
specifier|private
name|void
name|recordMutationWithoutWal
parameter_list|(
specifier|final
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|List
argument_list|<
name|Cell
argument_list|>
argument_list|>
name|familyMap
parameter_list|)
block|{
name|numMutationsWithoutWAL
operator|.
name|increment
argument_list|()
expr_stmt|;
if|if
condition|(
name|numMutationsWithoutWAL
operator|.
name|sum
argument_list|()
operator|<=
literal|1
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"writing data to region "
operator|+
name|this
operator|+
literal|" with WAL disabled. Data may be lost in the event of a crash."
argument_list|)
expr_stmt|;
block|}
name|long
name|mutationSize
init|=
literal|0
decl_stmt|;
for|for
control|(
name|List
argument_list|<
name|Cell
argument_list|>
name|cells
range|:
name|familyMap
operator|.
name|values
argument_list|()
control|)
block|{
comment|// Optimization: 'foreach' loop is not used. See:
comment|// HBASE-12023 HRegion.applyFamilyMapToMemstore creates too many iterator objects
assert|assert
name|cells
operator|instanceof
name|RandomAccess
assert|;
name|int
name|listSize
init|=
name|cells
operator|.
name|size
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|listSize
condition|;
name|i
operator|++
control|)
block|{
name|Cell
name|cell
init|=
name|cells
operator|.
name|get
argument_list|(
name|i
argument_list|)
decl_stmt|;
name|mutationSize
operator|+=
name|KeyValueUtil
operator|.
name|length
argument_list|(
name|cell
argument_list|)
expr_stmt|;
block|}
block|}
name|dataInMemoryWithoutWAL
operator|.
name|add
argument_list|(
name|mutationSize
argument_list|)
expr_stmt|;
block|}
specifier|private
name|void
name|lock
parameter_list|(
specifier|final
name|Lock
name|lock
parameter_list|)
throws|throws
name|RegionTooBusyException
throws|,
name|InterruptedIOException
block|{
name|lock
argument_list|(
name|lock
argument_list|,
literal|1
argument_list|)
expr_stmt|;
block|}
comment|/**    * Try to acquire a lock.  Throw RegionTooBusyException    * if failed to get the lock in time. Throw InterruptedIOException    * if interrupted while waiting for the lock.    */
specifier|private
name|void
name|lock
parameter_list|(
specifier|final
name|Lock
name|lock
parameter_list|,
specifier|final
name|int
name|multiplier
parameter_list|)
throws|throws
name|RegionTooBusyException
throws|,
name|InterruptedIOException
block|{
try|try
block|{
specifier|final
name|long
name|waitTime
init|=
name|Math
operator|.
name|min
argument_list|(
name|maxBusyWaitDuration
argument_list|,
name|busyWaitDuration
operator|*
name|Math
operator|.
name|min
argument_list|(
name|multiplier
argument_list|,
name|maxBusyWaitMultiplier
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|lock
operator|.
name|tryLock
argument_list|(
name|waitTime
argument_list|,
name|TimeUnit
operator|.
name|MILLISECONDS
argument_list|)
condition|)
block|{
comment|// Don't print millis. Message is used as a key over in
comment|// RetriesExhaustedWithDetailsException processing.
throw|throw
operator|new
name|RegionTooBusyException
argument_list|(
literal|"Failed to obtain lock; regionName="
operator|+
operator|(
name|this
operator|.
name|getRegionInfo
argument_list|()
operator|==
literal|null
condition|?
literal|"unknown"
else|:
name|this
operator|.
name|getRegionInfo
argument_list|()
operator|.
name|getRegionNameAsString
argument_list|()
operator|)
operator|+
literal|", server="
operator|+
operator|(
name|this
operator|.
name|getRegionServerServices
argument_list|()
operator|==
literal|null
condition|?
literal|"unknown"
else|:
name|this
operator|.
name|getRegionServerServices
argument_list|()
operator|.
name|getServerName
argument_list|()
operator|)
argument_list|)
throw|;
block|}
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|ie
parameter_list|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Interrupted while waiting for a lock"
argument_list|)
expr_stmt|;
name|InterruptedIOException
name|iie
init|=
operator|new
name|InterruptedIOException
argument_list|()
decl_stmt|;
name|iie
operator|.
name|initCause
argument_list|(
name|ie
argument_list|)
expr_stmt|;
throw|throw
name|iie
throw|;
block|}
block|}
comment|/**    * Calls sync with the given transaction ID    * @param txid should sync up to which transaction    * @throws IOException If anything goes wrong with DFS    */
specifier|private
name|void
name|sync
parameter_list|(
name|long
name|txid
parameter_list|,
name|Durability
name|durability
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|this
operator|.
name|getRegionInfo
argument_list|()
operator|.
name|isMetaRegion
argument_list|()
condition|)
block|{
name|this
operator|.
name|wal
operator|.
name|sync
argument_list|(
name|txid
argument_list|)
expr_stmt|;
block|}
else|else
block|{
switch|switch
condition|(
name|durability
condition|)
block|{
case|case
name|USE_DEFAULT
case|:
comment|// do what table defaults to
if|if
condition|(
name|shouldSyncWAL
argument_list|()
condition|)
block|{
name|this
operator|.
name|wal
operator|.
name|sync
argument_list|(
name|txid
argument_list|)
expr_stmt|;
block|}
break|break;
case|case
name|SKIP_WAL
case|:
comment|// nothing do to
break|break;
case|case
name|ASYNC_WAL
case|:
comment|// nothing do to
break|break;
case|case
name|SYNC_WAL
case|:
name|this
operator|.
name|wal
operator|.
name|sync
argument_list|(
name|txid
argument_list|,
literal|false
argument_list|)
expr_stmt|;
break|break;
case|case
name|FSYNC_WAL
case|:
name|this
operator|.
name|wal
operator|.
name|sync
argument_list|(
name|txid
argument_list|,
literal|true
argument_list|)
expr_stmt|;
break|break;
default|default:
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"Unknown durability "
operator|+
name|durability
argument_list|)
throw|;
block|}
block|}
block|}
comment|/**    * Check whether we should sync the wal from the table's durability settings    */
specifier|private
name|boolean
name|shouldSyncWAL
parameter_list|()
block|{
return|return
name|regionDurability
operator|.
name|ordinal
argument_list|()
operator|>
name|Durability
operator|.
name|ASYNC_WAL
operator|.
name|ordinal
argument_list|()
return|;
block|}
comment|/**    * A mocked list implementation - discards all updates.    */
specifier|private
specifier|static
specifier|final
name|List
argument_list|<
name|Cell
argument_list|>
name|MOCKED_LIST
init|=
operator|new
name|AbstractList
argument_list|<
name|Cell
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|void
name|add
parameter_list|(
name|int
name|index
parameter_list|,
name|Cell
name|element
parameter_list|)
block|{
comment|// do nothing
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|addAll
parameter_list|(
name|int
name|index
parameter_list|,
name|Collection
argument_list|<
name|?
extends|extends
name|Cell
argument_list|>
name|c
parameter_list|)
block|{
return|return
literal|false
return|;
comment|// this list is never changed as a result of an update
block|}
annotation|@
name|Override
specifier|public
name|KeyValue
name|get
parameter_list|(
name|int
name|index
parameter_list|)
block|{
throw|throw
operator|new
name|UnsupportedOperationException
argument_list|()
throw|;
block|}
annotation|@
name|Override
specifier|public
name|int
name|size
parameter_list|()
block|{
return|return
literal|0
return|;
block|}
block|}
decl_stmt|;
comment|/** @return the latest sequence number that was read from storage when this region was opened */
specifier|public
name|long
name|getOpenSeqNum
parameter_list|()
block|{
return|return
name|this
operator|.
name|openSeqNum
return|;
block|}
annotation|@
name|Override
specifier|public
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|Long
argument_list|>
name|getMaxStoreSeqId
parameter_list|()
block|{
return|return
name|this
operator|.
name|maxSeqIdInStores
return|;
block|}
specifier|public
name|long
name|getOldestSeqIdOfStore
parameter_list|(
name|byte
index|[]
name|familyName
parameter_list|)
block|{
return|return
name|wal
operator|.
name|getEarliestMemStoreSeqNum
argument_list|(
name|getRegionInfo
argument_list|()
operator|.
name|getEncodedNameAsBytes
argument_list|()
argument_list|,
name|familyName
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|CompactionState
name|getCompactionState
parameter_list|()
block|{
name|boolean
name|hasMajor
init|=
name|majorInProgress
operator|.
name|get
argument_list|()
operator|>
literal|0
decl_stmt|,
name|hasMinor
init|=
name|minorInProgress
operator|.
name|get
argument_list|()
operator|>
literal|0
decl_stmt|;
return|return
operator|(
name|hasMajor
condition|?
operator|(
name|hasMinor
condition|?
name|CompactionState
operator|.
name|MAJOR_AND_MINOR
else|:
name|CompactionState
operator|.
name|MAJOR
operator|)
else|:
operator|(
name|hasMinor
condition|?
name|CompactionState
operator|.
name|MINOR
else|:
name|CompactionState
operator|.
name|NONE
operator|)
operator|)
return|;
block|}
specifier|public
name|void
name|reportCompactionRequestStart
parameter_list|(
name|boolean
name|isMajor
parameter_list|)
block|{
operator|(
name|isMajor
condition|?
name|majorInProgress
else|:
name|minorInProgress
operator|)
operator|.
name|incrementAndGet
argument_list|()
expr_stmt|;
block|}
specifier|public
name|void
name|reportCompactionRequestEnd
parameter_list|(
name|boolean
name|isMajor
parameter_list|,
name|int
name|numFiles
parameter_list|,
name|long
name|filesSizeCompacted
parameter_list|)
block|{
name|int
name|newValue
init|=
operator|(
name|isMajor
condition|?
name|majorInProgress
else|:
name|minorInProgress
operator|)
operator|.
name|decrementAndGet
argument_list|()
decl_stmt|;
comment|// metrics
name|compactionsFinished
operator|.
name|increment
argument_list|()
expr_stmt|;
name|compactionNumFilesCompacted
operator|.
name|add
argument_list|(
name|numFiles
argument_list|)
expr_stmt|;
name|compactionNumBytesCompacted
operator|.
name|add
argument_list|(
name|filesSizeCompacted
argument_list|)
expr_stmt|;
assert|assert
name|newValue
operator|>=
literal|0
assert|;
block|}
specifier|public
name|void
name|reportCompactionRequestFailure
parameter_list|()
block|{
name|compactionsFailed
operator|.
name|increment
argument_list|()
expr_stmt|;
block|}
specifier|public
name|void
name|incrementCompactionsQueuedCount
parameter_list|()
block|{
name|compactionsQueued
operator|.
name|increment
argument_list|()
expr_stmt|;
block|}
specifier|public
name|void
name|decrementCompactionsQueuedCount
parameter_list|()
block|{
name|compactionsQueued
operator|.
name|decrement
argument_list|()
expr_stmt|;
block|}
specifier|public
name|void
name|incrementFlushesQueuedCount
parameter_list|()
block|{
name|flushesQueued
operator|.
name|increment
argument_list|()
expr_stmt|;
block|}
annotation|@
name|VisibleForTesting
specifier|public
name|long
name|getReadPoint
parameter_list|()
block|{
return|return
name|getReadPoint
argument_list|(
name|IsolationLevel
operator|.
name|READ_COMMITTED
argument_list|)
return|;
block|}
comment|/**    * {@inheritDoc}    */
annotation|@
name|Override
specifier|public
name|void
name|onConfigurationChange
parameter_list|(
name|Configuration
name|conf
parameter_list|)
block|{
name|this
operator|.
name|storeHotnessProtector
operator|.
name|update
argument_list|(
name|conf
argument_list|)
expr_stmt|;
block|}
comment|/**    * {@inheritDoc}    */
annotation|@
name|Override
specifier|public
name|void
name|registerChildren
parameter_list|(
name|ConfigurationManager
name|manager
parameter_list|)
block|{
name|configurationManager
operator|=
name|Optional
operator|.
name|of
argument_list|(
name|manager
argument_list|)
expr_stmt|;
name|stores
operator|.
name|values
argument_list|()
operator|.
name|forEach
argument_list|(
name|manager
operator|::
name|registerObserver
argument_list|)
expr_stmt|;
block|}
comment|/**    * {@inheritDoc}    */
annotation|@
name|Override
specifier|public
name|void
name|deregisterChildren
parameter_list|(
name|ConfigurationManager
name|manager
parameter_list|)
block|{
name|stores
operator|.
name|values
argument_list|()
operator|.
name|forEach
argument_list|(
name|configurationManager
operator|.
name|get
argument_list|()
operator|::
name|deregisterObserver
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|CellComparator
name|getCellComparator
parameter_list|()
block|{
return|return
name|this
operator|.
name|getRegionInfo
argument_list|()
operator|.
name|isMetaRegion
argument_list|()
condition|?
name|CellComparatorImpl
operator|.
name|META_COMPARATOR
else|:
name|CellComparatorImpl
operator|.
name|COMPARATOR
return|;
block|}
specifier|public
name|long
name|getMemStoreFlushSize
parameter_list|()
block|{
return|return
name|this
operator|.
name|memstoreFlushSize
return|;
block|}
comment|//// method for debugging tests
name|void
name|throwException
parameter_list|(
name|String
name|title
parameter_list|,
name|String
name|regionName
parameter_list|)
block|{
name|StringBuilder
name|buf
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
name|buf
operator|.
name|append
argument_list|(
name|title
operator|+
literal|", "
argument_list|)
expr_stmt|;
name|buf
operator|.
name|append
argument_list|(
name|getRegionInfo
argument_list|()
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
name|buf
operator|.
name|append
argument_list|(
name|getRegionInfo
argument_list|()
operator|.
name|isMetaRegion
argument_list|()
condition|?
literal|" meta region "
else|:
literal|" "
argument_list|)
expr_stmt|;
name|buf
operator|.
name|append
argument_list|(
literal|"stores: "
argument_list|)
expr_stmt|;
for|for
control|(
name|HStore
name|s
range|:
name|stores
operator|.
name|values
argument_list|()
control|)
block|{
name|buf
operator|.
name|append
argument_list|(
name|s
operator|.
name|getColumnFamilyDescriptor
argument_list|()
operator|.
name|getNameAsString
argument_list|()
argument_list|)
expr_stmt|;
name|buf
operator|.
name|append
argument_list|(
literal|" size: "
argument_list|)
expr_stmt|;
name|buf
operator|.
name|append
argument_list|(
name|s
operator|.
name|getMemStoreSize
argument_list|()
operator|.
name|getDataSize
argument_list|()
argument_list|)
expr_stmt|;
name|buf
operator|.
name|append
argument_list|(
literal|" "
argument_list|)
expr_stmt|;
block|}
name|buf
operator|.
name|append
argument_list|(
literal|"end-of-stores"
argument_list|)
expr_stmt|;
name|buf
operator|.
name|append
argument_list|(
literal|", memstore size "
argument_list|)
expr_stmt|;
name|buf
operator|.
name|append
argument_list|(
name|getMemStoreDataSize
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|getRegionInfo
argument_list|()
operator|.
name|getRegionNameAsString
argument_list|()
operator|.
name|startsWith
argument_list|(
name|regionName
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|RuntimeException
argument_list|(
name|buf
operator|.
name|toString
argument_list|()
argument_list|)
throw|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|void
name|requestCompaction
parameter_list|(
name|String
name|why
parameter_list|,
name|int
name|priority
parameter_list|,
name|boolean
name|major
parameter_list|,
name|CompactionLifeCycleTracker
name|tracker
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|major
condition|)
block|{
name|stores
operator|.
name|values
argument_list|()
operator|.
name|forEach
argument_list|(
name|HStore
operator|::
name|triggerMajorCompaction
argument_list|)
expr_stmt|;
block|}
name|rsServices
operator|.
name|getCompactionRequestor
argument_list|()
operator|.
name|requestCompaction
argument_list|(
name|this
argument_list|,
name|why
argument_list|,
name|priority
argument_list|,
name|tracker
argument_list|,
name|RpcServer
operator|.
name|getRequestUser
argument_list|()
operator|.
name|orElse
argument_list|(
literal|null
argument_list|)
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|requestCompaction
parameter_list|(
name|byte
index|[]
name|family
parameter_list|,
name|String
name|why
parameter_list|,
name|int
name|priority
parameter_list|,
name|boolean
name|major
parameter_list|,
name|CompactionLifeCycleTracker
name|tracker
parameter_list|)
throws|throws
name|IOException
block|{
name|HStore
name|store
init|=
name|stores
operator|.
name|get
argument_list|(
name|family
argument_list|)
decl_stmt|;
if|if
condition|(
name|store
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|NoSuchColumnFamilyException
argument_list|(
literal|"column family "
operator|+
name|Bytes
operator|.
name|toString
argument_list|(
name|family
argument_list|)
operator|+
literal|" does not exist in region "
operator|+
name|getRegionInfo
argument_list|()
operator|.
name|getRegionNameAsString
argument_list|()
argument_list|)
throw|;
block|}
if|if
condition|(
name|major
condition|)
block|{
name|store
operator|.
name|triggerMajorCompaction
argument_list|()
expr_stmt|;
block|}
name|rsServices
operator|.
name|getCompactionRequestor
argument_list|()
operator|.
name|requestCompaction
argument_list|(
name|this
argument_list|,
name|store
argument_list|,
name|why
argument_list|,
name|priority
argument_list|,
name|tracker
argument_list|,
name|RpcServer
operator|.
name|getRequestUser
argument_list|()
operator|.
name|orElse
argument_list|(
literal|null
argument_list|)
argument_list|)
expr_stmt|;
block|}
specifier|private
name|void
name|requestFlushIfNeeded
parameter_list|()
throws|throws
name|RegionTooBusyException
block|{
if|if
condition|(
name|isFlushSize
argument_list|(
name|this
operator|.
name|memStoreSizing
operator|.
name|getMemStoreSize
argument_list|()
argument_list|)
condition|)
block|{
name|requestFlush
argument_list|()
expr_stmt|;
block|}
block|}
specifier|private
name|void
name|requestFlush
parameter_list|()
block|{
if|if
condition|(
name|this
operator|.
name|rsServices
operator|==
literal|null
condition|)
block|{
return|return;
block|}
name|requestFlush0
argument_list|(
name|FlushLifeCycleTracker
operator|.
name|DUMMY
argument_list|)
expr_stmt|;
block|}
specifier|private
name|void
name|requestFlush0
parameter_list|(
name|FlushLifeCycleTracker
name|tracker
parameter_list|)
block|{
name|boolean
name|shouldFlush
init|=
literal|false
decl_stmt|;
synchronized|synchronized
init|(
name|writestate
init|)
block|{
if|if
condition|(
operator|!
name|this
operator|.
name|writestate
operator|.
name|isFlushRequested
argument_list|()
condition|)
block|{
name|shouldFlush
operator|=
literal|true
expr_stmt|;
name|writestate
operator|.
name|flushRequested
operator|=
literal|true
expr_stmt|;
block|}
block|}
if|if
condition|(
name|shouldFlush
condition|)
block|{
comment|// Make request outside of synchronize block; HBASE-818.
name|this
operator|.
name|rsServices
operator|.
name|getFlushRequester
argument_list|()
operator|.
name|requestFlush
argument_list|(
name|this
argument_list|,
literal|false
argument_list|,
name|tracker
argument_list|)
expr_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Flush requested on "
operator|+
name|this
operator|.
name|getRegionInfo
argument_list|()
operator|.
name|getEncodedName
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
name|tracker
operator|.
name|notExecuted
argument_list|(
literal|"Flush already requested on "
operator|+
name|this
argument_list|)
expr_stmt|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|void
name|requestFlush
parameter_list|(
name|FlushLifeCycleTracker
name|tracker
parameter_list|)
throws|throws
name|IOException
block|{
name|requestFlush0
argument_list|(
name|tracker
argument_list|)
expr_stmt|;
block|}
block|}
end_class

end_unit

