begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/*  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|hfile
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|nio
operator|.
name|ByteBuffer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|ChecksumException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|nio
operator|.
name|ByteBuff
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|nio
operator|.
name|SingleByteBuff
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|yetus
operator|.
name|audience
operator|.
name|InterfaceAudience
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|Logger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|LoggerFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|ChecksumType
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|DataChecksum
import|;
end_import

begin_comment
comment|/**  * Utility methods to compute and validate checksums.  */
end_comment

begin_class
annotation|@
name|InterfaceAudience
operator|.
name|Private
specifier|public
class|class
name|ChecksumUtil
block|{
specifier|public
specifier|static
specifier|final
name|Logger
name|LOG
init|=
name|LoggerFactory
operator|.
name|getLogger
argument_list|(
name|ChecksumUtil
operator|.
name|class
argument_list|)
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|int
name|CHECKSUM_BUF_SIZE
init|=
literal|256
decl_stmt|;
comment|/**    * This is used by unit tests to make checksum failures throw an    * exception instead of returning null. Returning a null value from    * checksum validation will cause the higher layer to retry that    * read with hdfs-level checksums. Instead, we would like checksum    * failures to cause the entire unit test to fail.    */
specifier|private
specifier|static
name|boolean
name|generateExceptions
init|=
literal|false
decl_stmt|;
comment|/**    * Generates a checksum for all the data in indata. The checksum is    * written to outdata.    * @param indata input data stream    * @param startOffset starting offset in the indata stream from where to    *                    compute checkums from    * @param endOffset ending offset in the indata stream upto    *                   which checksums needs to be computed    * @param outdata the output buffer where checksum values are written    * @param outOffset the starting offset in the outdata where the    *                  checksum values are written    * @param checksumType type of checksum    * @param bytesPerChecksum number of bytes per checksum value    */
specifier|static
name|void
name|generateChecksums
parameter_list|(
name|byte
index|[]
name|indata
parameter_list|,
name|int
name|startOffset
parameter_list|,
name|int
name|endOffset
parameter_list|,
name|byte
index|[]
name|outdata
parameter_list|,
name|int
name|outOffset
parameter_list|,
name|ChecksumType
name|checksumType
parameter_list|,
name|int
name|bytesPerChecksum
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|checksumType
operator|==
name|ChecksumType
operator|.
name|NULL
condition|)
block|{
return|return;
comment|// No checksum for this block.
block|}
name|DataChecksum
name|checksum
init|=
name|DataChecksum
operator|.
name|newDataChecksum
argument_list|(
name|checksumType
operator|.
name|getDataChecksumType
argument_list|()
argument_list|,
name|bytesPerChecksum
argument_list|)
decl_stmt|;
name|checksum
operator|.
name|calculateChunkedSums
argument_list|(
name|ByteBuffer
operator|.
name|wrap
argument_list|(
name|indata
argument_list|,
name|startOffset
argument_list|,
name|endOffset
operator|-
name|startOffset
argument_list|)
argument_list|,
name|ByteBuffer
operator|.
name|wrap
argument_list|(
name|outdata
argument_list|,
name|outOffset
argument_list|,
name|outdata
operator|.
name|length
operator|-
name|outOffset
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|/**    * Like the hadoop's {@link DataChecksum#verifyChunkedSums(ByteBuffer, ByteBuffer, String, long)},    * this method will also verify checksum of each chunk in data. the difference is: this method can    * accept {@link ByteBuff} as arguments, we can not add it in hadoop-common so defined here.    * @param dataChecksum to calculate the checksum.    * @param data as the input    * @param checksums to compare    * @param pathName indicate that the data is read from which file.    * @return a flag indicate the checksum match or mismatch.    * @see org.apache.hadoop.util.DataChecksum#verifyChunkedSums(ByteBuffer, ByteBuffer, String,    *      long)    */
specifier|private
specifier|static
name|boolean
name|verifyChunkedSums
parameter_list|(
name|DataChecksum
name|dataChecksum
parameter_list|,
name|ByteBuff
name|data
parameter_list|,
name|ByteBuff
name|checksums
parameter_list|,
name|String
name|pathName
parameter_list|)
block|{
comment|// Almost all of the HFile Block are about 64KB, and it would be a SingleByteBuff, use the
comment|// Hadoop's verify checksum directly, because it'll use the native checksum, which has no extra
comment|// byte[] allocation or copying. (HBASE-21917)
if|if
condition|(
name|data
operator|instanceof
name|SingleByteBuff
operator|&&
name|checksums
operator|instanceof
name|SingleByteBuff
condition|)
block|{
comment|// the checksums ByteBuff must also be an SingleByteBuff because it's duplicated from data.
name|ByteBuffer
name|dataBB
init|=
call|(
name|ByteBuffer
call|)
argument_list|(
name|data
operator|.
name|nioByteBuffers
argument_list|()
index|[
literal|0
index|]
argument_list|)
operator|.
name|duplicate
argument_list|()
operator|.
name|position
argument_list|(
name|data
operator|.
name|position
argument_list|()
argument_list|)
operator|.
name|limit
argument_list|(
name|data
operator|.
name|limit
argument_list|()
argument_list|)
decl_stmt|;
name|ByteBuffer
name|checksumBB
init|=
call|(
name|ByteBuffer
call|)
argument_list|(
name|checksums
operator|.
name|nioByteBuffers
argument_list|()
index|[
literal|0
index|]
argument_list|)
operator|.
name|duplicate
argument_list|()
operator|.
name|position
argument_list|(
name|checksums
operator|.
name|position
argument_list|()
argument_list|)
operator|.
name|limit
argument_list|(
name|checksums
operator|.
name|limit
argument_list|()
argument_list|)
decl_stmt|;
try|try
block|{
name|dataChecksum
operator|.
name|verifyChunkedSums
argument_list|(
name|dataBB
argument_list|,
name|checksumBB
argument_list|,
name|pathName
argument_list|,
literal|0
argument_list|)
expr_stmt|;
return|return
literal|true
return|;
block|}
catch|catch
parameter_list|(
name|ChecksumException
name|e
parameter_list|)
block|{
return|return
literal|false
return|;
block|}
block|}
comment|// If the block is a MultiByteBuff. we use a small byte[] to update the checksum many times for
comment|// reducing GC pressure. it's a rare case.
name|int
name|checksumTypeSize
init|=
name|dataChecksum
operator|.
name|getChecksumType
argument_list|()
operator|.
name|size
decl_stmt|;
if|if
condition|(
name|checksumTypeSize
operator|==
literal|0
condition|)
block|{
return|return
literal|true
return|;
block|}
comment|// we have 5 checksum type now: NULL,DEFAULT,MIXED,CRC32,CRC32C. the former three need 0 byte,
comment|// and the other two need 4 bytes.
assert|assert
name|checksumTypeSize
operator|==
literal|4
assert|;
name|int
name|bytesPerChecksum
init|=
name|dataChecksum
operator|.
name|getBytesPerChecksum
argument_list|()
decl_stmt|;
name|int
name|startDataPos
init|=
name|data
operator|.
name|position
argument_list|()
decl_stmt|;
name|data
operator|.
name|mark
argument_list|()
expr_stmt|;
name|checksums
operator|.
name|mark
argument_list|()
expr_stmt|;
try|try
block|{
comment|// allocate an small buffer for reducing young GC (HBASE-21917), and copy 256 bytes from
comment|// ByteBuff to update the checksum each time. if we upgrade to an future JDK and hadoop
comment|// version which support DataCheckSum#update(ByteBuffer), we won't need to update the checksum
comment|// multiple times then.
name|byte
index|[]
name|buf
init|=
operator|new
name|byte
index|[
name|CHECKSUM_BUF_SIZE
index|]
decl_stmt|;
name|byte
index|[]
name|sum
init|=
operator|new
name|byte
index|[
name|checksumTypeSize
index|]
decl_stmt|;
while|while
condition|(
name|data
operator|.
name|remaining
argument_list|()
operator|>
literal|0
condition|)
block|{
name|int
name|n
init|=
name|Math
operator|.
name|min
argument_list|(
name|data
operator|.
name|remaining
argument_list|()
argument_list|,
name|bytesPerChecksum
argument_list|)
decl_stmt|;
name|checksums
operator|.
name|get
argument_list|(
name|sum
argument_list|)
expr_stmt|;
name|dataChecksum
operator|.
name|reset
argument_list|()
expr_stmt|;
for|for
control|(
name|int
name|remain
init|=
name|n
init|,
name|len
init|;
name|remain
operator|>
literal|0
condition|;
name|remain
operator|-=
name|len
control|)
block|{
comment|// Copy 256 bytes from ByteBuff to update the checksum each time, if the remaining
comment|// bytes is less than 256, then just update the remaining bytes.
name|len
operator|=
name|Math
operator|.
name|min
argument_list|(
name|CHECKSUM_BUF_SIZE
argument_list|,
name|remain
argument_list|)
expr_stmt|;
name|data
operator|.
name|get
argument_list|(
name|buf
argument_list|,
literal|0
argument_list|,
name|len
argument_list|)
expr_stmt|;
name|dataChecksum
operator|.
name|update
argument_list|(
name|buf
argument_list|,
literal|0
argument_list|,
name|len
argument_list|)
expr_stmt|;
block|}
name|int
name|calculated
init|=
operator|(
name|int
operator|)
name|dataChecksum
operator|.
name|getValue
argument_list|()
decl_stmt|;
name|int
name|stored
init|=
operator|(
name|sum
index|[
literal|0
index|]
operator|<<
literal|24
operator|&
literal|0xff000000
operator|)
operator||
operator|(
name|sum
index|[
literal|1
index|]
operator|<<
literal|16
operator|&
literal|0xff0000
operator|)
operator||
operator|(
name|sum
index|[
literal|2
index|]
operator|<<
literal|8
operator|&
literal|0xff00
operator|)
operator||
operator|(
name|sum
index|[
literal|3
index|]
operator|&
literal|0xff
operator|)
decl_stmt|;
if|if
condition|(
name|calculated
operator|!=
name|stored
condition|)
block|{
if|if
condition|(
name|LOG
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|long
name|errPos
init|=
name|data
operator|.
name|position
argument_list|()
operator|-
name|startDataPos
operator|-
name|n
decl_stmt|;
name|LOG
operator|.
name|trace
argument_list|(
literal|"Checksum error: {} at {} expected: {} got: {}"
argument_list|,
name|pathName
argument_list|,
name|errPos
argument_list|,
name|stored
argument_list|,
name|calculated
argument_list|)
expr_stmt|;
block|}
return|return
literal|false
return|;
block|}
block|}
block|}
finally|finally
block|{
name|data
operator|.
name|reset
argument_list|()
expr_stmt|;
name|checksums
operator|.
name|reset
argument_list|()
expr_stmt|;
block|}
return|return
literal|true
return|;
block|}
comment|/**    * Validates that the data in the specified HFileBlock matches the checksum. Generates the    * checksums for the data and then validate that it matches those stored in the end of the data.    * @param buf Contains the data in following order: HFileBlock header, data, checksums.    * @param pathName Path of the HFile to which the {@code data} belongs. Only used for logging.    * @param offset offset of the data being validated. Only used for logging.    * @param hdrSize Size of the block header in {@code data}. Only used for logging.    * @return True if checksum matches, else false.    */
specifier|static
name|boolean
name|validateChecksum
parameter_list|(
name|ByteBuff
name|buf
parameter_list|,
name|String
name|pathName
parameter_list|,
name|long
name|offset
parameter_list|,
name|int
name|hdrSize
parameter_list|)
block|{
name|ChecksumType
name|ctype
init|=
name|ChecksumType
operator|.
name|codeToType
argument_list|(
name|buf
operator|.
name|get
argument_list|(
name|HFileBlock
operator|.
name|Header
operator|.
name|CHECKSUM_TYPE_INDEX
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|ctype
operator|==
name|ChecksumType
operator|.
name|NULL
condition|)
block|{
return|return
literal|true
return|;
comment|// No checksum validations needed for this block.
block|}
comment|// read in the stored value of the checksum size from the header.
name|int
name|bytesPerChecksum
init|=
name|buf
operator|.
name|getInt
argument_list|(
name|HFileBlock
operator|.
name|Header
operator|.
name|BYTES_PER_CHECKSUM_INDEX
argument_list|)
decl_stmt|;
name|DataChecksum
name|dataChecksum
init|=
name|DataChecksum
operator|.
name|newDataChecksum
argument_list|(
name|ctype
operator|.
name|getDataChecksumType
argument_list|()
argument_list|,
name|bytesPerChecksum
argument_list|)
decl_stmt|;
assert|assert
name|dataChecksum
operator|!=
literal|null
assert|;
name|int
name|onDiskDataSizeWithHeader
init|=
name|buf
operator|.
name|getInt
argument_list|(
name|HFileBlock
operator|.
name|Header
operator|.
name|ON_DISK_DATA_SIZE_WITH_HEADER_INDEX
argument_list|)
decl_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"dataLength="
operator|+
name|buf
operator|.
name|capacity
argument_list|()
operator|+
literal|", sizeWithHeader="
operator|+
name|onDiskDataSizeWithHeader
operator|+
literal|", checksumType="
operator|+
name|ctype
operator|.
name|getName
argument_list|()
operator|+
literal|", file="
operator|+
name|pathName
operator|+
literal|", offset="
operator|+
name|offset
operator|+
literal|", headerSize="
operator|+
name|hdrSize
operator|+
literal|", bytesPerChecksum="
operator|+
name|bytesPerChecksum
argument_list|)
expr_stmt|;
block|}
name|ByteBuff
name|data
init|=
name|buf
operator|.
name|duplicate
argument_list|()
operator|.
name|position
argument_list|(
literal|0
argument_list|)
operator|.
name|limit
argument_list|(
name|onDiskDataSizeWithHeader
argument_list|)
decl_stmt|;
name|ByteBuff
name|checksums
init|=
name|buf
operator|.
name|duplicate
argument_list|()
operator|.
name|position
argument_list|(
name|onDiskDataSizeWithHeader
argument_list|)
operator|.
name|limit
argument_list|(
name|buf
operator|.
name|limit
argument_list|()
argument_list|)
decl_stmt|;
return|return
name|verifyChunkedSums
argument_list|(
name|dataChecksum
argument_list|,
name|data
argument_list|,
name|checksums
argument_list|,
name|pathName
argument_list|)
return|;
block|}
comment|/**    * Returns the number of bytes needed to store the checksums for    * a specified data size    * @param datasize number of bytes of data    * @param bytesPerChecksum number of bytes in a checksum chunk    * @return The number of bytes needed to store the checksum values    */
specifier|static
name|long
name|numBytes
parameter_list|(
name|long
name|datasize
parameter_list|,
name|int
name|bytesPerChecksum
parameter_list|)
block|{
return|return
name|numChunks
argument_list|(
name|datasize
argument_list|,
name|bytesPerChecksum
argument_list|)
operator|*
name|HFileBlock
operator|.
name|CHECKSUM_SIZE
return|;
block|}
comment|/**    * Returns the number of checksum chunks needed to store the checksums for    * a specified data size    * @param datasize number of bytes of data    * @param bytesPerChecksum number of bytes in a checksum chunk    * @return The number of checksum chunks    */
specifier|static
name|long
name|numChunks
parameter_list|(
name|long
name|datasize
parameter_list|,
name|int
name|bytesPerChecksum
parameter_list|)
block|{
name|long
name|numChunks
init|=
name|datasize
operator|/
name|bytesPerChecksum
decl_stmt|;
if|if
condition|(
name|datasize
operator|%
name|bytesPerChecksum
operator|!=
literal|0
condition|)
block|{
name|numChunks
operator|++
expr_stmt|;
block|}
return|return
name|numChunks
return|;
block|}
comment|/**    * Mechanism to throw an exception in case of hbase checksum    * failure. This is used by unit tests only.    * @param value Setting this to true will cause hbase checksum    *              verification failures to generate exceptions.    */
specifier|public
specifier|static
name|void
name|generateExceptionForChecksumFailureForTest
parameter_list|(
name|boolean
name|value
parameter_list|)
block|{
name|generateExceptions
operator|=
name|value
expr_stmt|;
block|}
block|}
end_class

end_unit

