begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|FileNotFoundException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|InterruptedIOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collection
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Objects
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Optional
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|UUID
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FSDataInputStream
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FSDataOutputStream
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileStatus
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|LocatedFileStatus
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|permission
operator|.
name|FsPermission
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|Cell
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HConstants
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|PrivateCellUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|backup
operator|.
name|HFileArchiver
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|ColumnFamilyDescriptor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|RegionInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|TableDescriptor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|fs
operator|.
name|HFileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|Reference
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|Bytes
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|FSHDFSUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|FSUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|Pair
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|ServerRegionReplicaUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hbase
operator|.
name|thirdparty
operator|.
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|annotations
operator|.
name|VisibleForTesting
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|yetus
operator|.
name|audience
operator|.
name|InterfaceAudience
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|Logger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|LoggerFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hbase
operator|.
name|thirdparty
operator|.
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|Lists
import|;
end_import

begin_import
import|import
name|edu
operator|.
name|umd
operator|.
name|cs
operator|.
name|findbugs
operator|.
name|annotations
operator|.
name|Nullable
import|;
end_import

begin_comment
comment|/**  * View to an on-disk Region.  * Provides the set of methods necessary to interact with the on-disk region data.  */
end_comment

begin_class
annotation|@
name|InterfaceAudience
operator|.
name|Private
specifier|public
class|class
name|HRegionFileSystem
block|{
specifier|private
specifier|static
specifier|final
name|Logger
name|LOG
init|=
name|LoggerFactory
operator|.
name|getLogger
argument_list|(
name|HRegionFileSystem
operator|.
name|class
argument_list|)
decl_stmt|;
comment|/** Name of the region info file that resides just under the region directory. */
specifier|public
specifier|final
specifier|static
name|String
name|REGION_INFO_FILE
init|=
literal|".regioninfo"
decl_stmt|;
comment|/** Temporary subdirectory of the region directory used for merges. */
specifier|public
specifier|static
specifier|final
name|String
name|REGION_MERGES_DIR
init|=
literal|".merges"
decl_stmt|;
comment|/** Temporary subdirectory of the region directory used for splits. */
specifier|public
specifier|static
specifier|final
name|String
name|REGION_SPLITS_DIR
init|=
literal|".splits"
decl_stmt|;
comment|/** Temporary subdirectory of the region directory used for compaction output. */
annotation|@
name|VisibleForTesting
specifier|static
specifier|final
name|String
name|REGION_TEMP_DIR
init|=
literal|".tmp"
decl_stmt|;
specifier|private
specifier|final
name|RegionInfo
name|regionInfo
decl_stmt|;
comment|//regionInfo for interacting with FS (getting encodedName, etc)
specifier|private
specifier|final
name|RegionInfo
name|regionInfoForFs
decl_stmt|;
specifier|private
specifier|final
name|Configuration
name|conf
decl_stmt|;
specifier|private
specifier|final
name|Path
name|tableDir
decl_stmt|;
specifier|private
specifier|final
name|FileSystem
name|fs
decl_stmt|;
specifier|private
specifier|final
name|Path
name|regionDir
decl_stmt|;
comment|/**    * In order to handle NN connectivity hiccups, one need to retry non-idempotent operation at the    * client level.    */
specifier|private
specifier|final
name|int
name|hdfsClientRetriesNumber
decl_stmt|;
specifier|private
specifier|final
name|int
name|baseSleepBeforeRetries
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|int
name|DEFAULT_HDFS_CLIENT_RETRIES_NUMBER
init|=
literal|10
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|int
name|DEFAULT_BASE_SLEEP_BEFORE_RETRIES
init|=
literal|1000
decl_stmt|;
comment|/**    * Create a view to the on-disk region    * @param conf the {@link Configuration} to use    * @param fs {@link FileSystem} that contains the region    * @param tableDir {@link Path} to where the table is being stored    * @param regionInfo {@link RegionInfo} for region    */
name|HRegionFileSystem
parameter_list|(
specifier|final
name|Configuration
name|conf
parameter_list|,
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Path
name|tableDir
parameter_list|,
specifier|final
name|RegionInfo
name|regionInfo
parameter_list|)
block|{
name|this
operator|.
name|fs
operator|=
name|fs
expr_stmt|;
name|this
operator|.
name|conf
operator|=
name|conf
expr_stmt|;
name|this
operator|.
name|tableDir
operator|=
name|Objects
operator|.
name|requireNonNull
argument_list|(
name|tableDir
argument_list|,
literal|"tableDir is null"
argument_list|)
expr_stmt|;
name|this
operator|.
name|regionInfo
operator|=
name|Objects
operator|.
name|requireNonNull
argument_list|(
name|regionInfo
argument_list|,
literal|"regionInfo is null"
argument_list|)
expr_stmt|;
name|this
operator|.
name|regionInfoForFs
operator|=
name|ServerRegionReplicaUtil
operator|.
name|getRegionInfoForFs
argument_list|(
name|regionInfo
argument_list|)
expr_stmt|;
name|this
operator|.
name|regionDir
operator|=
name|FSUtils
operator|.
name|getRegionDirFromTableDir
argument_list|(
name|tableDir
argument_list|,
name|regionInfo
argument_list|)
expr_stmt|;
name|this
operator|.
name|hdfsClientRetriesNumber
operator|=
name|conf
operator|.
name|getInt
argument_list|(
literal|"hdfs.client.retries.number"
argument_list|,
name|DEFAULT_HDFS_CLIENT_RETRIES_NUMBER
argument_list|)
expr_stmt|;
name|this
operator|.
name|baseSleepBeforeRetries
operator|=
name|conf
operator|.
name|getInt
argument_list|(
literal|"hdfs.client.sleep.before.retries"
argument_list|,
name|DEFAULT_BASE_SLEEP_BEFORE_RETRIES
argument_list|)
expr_stmt|;
block|}
comment|/** @return the underlying {@link FileSystem} */
specifier|public
name|FileSystem
name|getFileSystem
parameter_list|()
block|{
return|return
name|this
operator|.
name|fs
return|;
block|}
comment|/** @return the {@link RegionInfo} that describe this on-disk region view */
specifier|public
name|RegionInfo
name|getRegionInfo
parameter_list|()
block|{
return|return
name|this
operator|.
name|regionInfo
return|;
block|}
specifier|public
name|RegionInfo
name|getRegionInfoForFS
parameter_list|()
block|{
return|return
name|this
operator|.
name|regionInfoForFs
return|;
block|}
comment|/** @return {@link Path} to the region's root directory. */
specifier|public
name|Path
name|getTableDir
parameter_list|()
block|{
return|return
name|this
operator|.
name|tableDir
return|;
block|}
comment|/** @return {@link Path} to the region directory. */
specifier|public
name|Path
name|getRegionDir
parameter_list|()
block|{
return|return
name|regionDir
return|;
block|}
comment|// ===========================================================================
comment|//  Temp Helpers
comment|// ===========================================================================
comment|/** @return {@link Path} to the region's temp directory, used for file creations */
name|Path
name|getTempDir
parameter_list|()
block|{
return|return
operator|new
name|Path
argument_list|(
name|getRegionDir
argument_list|()
argument_list|,
name|REGION_TEMP_DIR
argument_list|)
return|;
block|}
comment|/**    * Clean up any temp detritus that may have been left around from previous operation attempts.    */
name|void
name|cleanupTempDir
parameter_list|()
throws|throws
name|IOException
block|{
name|deleteDir
argument_list|(
name|getTempDir
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|// ===========================================================================
comment|//  Store/StoreFile Helpers
comment|// ===========================================================================
comment|/**    * Returns the directory path of the specified family    * @param familyName Column Family Name    * @return {@link Path} to the directory of the specified family    */
specifier|public
name|Path
name|getStoreDir
parameter_list|(
specifier|final
name|String
name|familyName
parameter_list|)
block|{
return|return
operator|new
name|Path
argument_list|(
name|this
operator|.
name|getRegionDir
argument_list|()
argument_list|,
name|familyName
argument_list|)
return|;
block|}
comment|/**    * Create the store directory for the specified family name    * @param familyName Column Family Name    * @return {@link Path} to the directory of the specified family    * @throws IOException if the directory creation fails.    */
name|Path
name|createStoreDir
parameter_list|(
specifier|final
name|String
name|familyName
parameter_list|)
throws|throws
name|IOException
block|{
name|Path
name|storeDir
init|=
name|getStoreDir
argument_list|(
name|familyName
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|fs
operator|.
name|exists
argument_list|(
name|storeDir
argument_list|)
operator|&&
operator|!
name|createDir
argument_list|(
name|storeDir
argument_list|)
condition|)
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Failed creating "
operator|+
name|storeDir
argument_list|)
throw|;
return|return
name|storeDir
return|;
block|}
comment|/**    * Set the directory of CF to the specified storage policy.<br>    *<i>"LAZY_PERSIST"</i>,<i>"ALL_SSD"</i>,<i>"ONE_SSD"</i>,<i>"HOT"</i>,<i>"WARM"</i>,    *<i>"COLD"</i><br>    *<br>    * See {@link org.apache.hadoop.hdfs.protocol.HdfsConstants} for more details.    * @param familyName The name of column family.    * @param policyName The name of the storage policy: 'HOT', 'COLD', etc.    * See see hadoop 2.6+ org.apache.hadoop.hdfs.protocol.HdfsConstants for possible list e.g    * 'COLD', 'WARM', 'HOT', 'ONE_SSD', 'ALL_SSD', 'LAZY_PERSIST'.    */
specifier|public
name|void
name|setStoragePolicy
parameter_list|(
name|String
name|familyName
parameter_list|,
name|String
name|policyName
parameter_list|)
block|{
name|FSUtils
operator|.
name|setStoragePolicy
argument_list|(
name|this
operator|.
name|fs
argument_list|,
name|getStoreDir
argument_list|(
name|familyName
argument_list|)
argument_list|,
name|policyName
argument_list|)
expr_stmt|;
block|}
comment|/**    * Get the storage policy of the directory of CF.    * @param familyName The name of column family.    * @return Storage policy name, or {@code null} if not using {@link HFileSystem} or exception    *         thrown when trying to get policy    */
annotation|@
name|Nullable
specifier|public
name|String
name|getStoragePolicyName
parameter_list|(
name|String
name|familyName
parameter_list|)
block|{
if|if
condition|(
name|this
operator|.
name|fs
operator|instanceof
name|HFileSystem
condition|)
block|{
name|Path
name|storeDir
init|=
name|getStoreDir
argument_list|(
name|familyName
argument_list|)
decl_stmt|;
return|return
operator|(
operator|(
name|HFileSystem
operator|)
name|this
operator|.
name|fs
operator|)
operator|.
name|getStoragePolicyName
argument_list|(
name|storeDir
argument_list|)
return|;
block|}
return|return
literal|null
return|;
block|}
comment|/**    * Returns the store files available for the family.    * This methods performs the filtering based on the valid store files.    * @param familyName Column Family Name    * @return a set of {@link StoreFileInfo} for the specified family.    */
specifier|public
name|Collection
argument_list|<
name|StoreFileInfo
argument_list|>
name|getStoreFiles
parameter_list|(
specifier|final
name|byte
index|[]
name|familyName
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|getStoreFiles
argument_list|(
name|Bytes
operator|.
name|toString
argument_list|(
name|familyName
argument_list|)
argument_list|)
return|;
block|}
specifier|public
name|Collection
argument_list|<
name|StoreFileInfo
argument_list|>
name|getStoreFiles
parameter_list|(
specifier|final
name|String
name|familyName
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|getStoreFiles
argument_list|(
name|familyName
argument_list|,
literal|true
argument_list|)
return|;
block|}
comment|/**    * Returns the store files available for the family.    * This methods performs the filtering based on the valid store files.    * @param familyName Column Family Name    * @return a set of {@link StoreFileInfo} for the specified family.    */
specifier|public
name|Collection
argument_list|<
name|StoreFileInfo
argument_list|>
name|getStoreFiles
parameter_list|(
specifier|final
name|String
name|familyName
parameter_list|,
specifier|final
name|boolean
name|validate
parameter_list|)
throws|throws
name|IOException
block|{
name|Path
name|familyDir
init|=
name|getStoreDir
argument_list|(
name|familyName
argument_list|)
decl_stmt|;
name|FileStatus
index|[]
name|files
init|=
name|FSUtils
operator|.
name|listStatus
argument_list|(
name|this
operator|.
name|fs
argument_list|,
name|familyDir
argument_list|)
decl_stmt|;
if|if
condition|(
name|files
operator|==
literal|null
condition|)
block|{
if|if
condition|(
name|LOG
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|trace
argument_list|(
literal|"No StoreFiles for: "
operator|+
name|familyDir
argument_list|)
expr_stmt|;
block|}
return|return
literal|null
return|;
block|}
name|ArrayList
argument_list|<
name|StoreFileInfo
argument_list|>
name|storeFiles
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
name|files
operator|.
name|length
argument_list|)
decl_stmt|;
for|for
control|(
name|FileStatus
name|status
range|:
name|files
control|)
block|{
if|if
condition|(
name|validate
operator|&&
operator|!
name|StoreFileInfo
operator|.
name|isValid
argument_list|(
name|status
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Invalid StoreFile: "
operator|+
name|status
operator|.
name|getPath
argument_list|()
argument_list|)
expr_stmt|;
continue|continue;
block|}
name|StoreFileInfo
name|info
init|=
name|ServerRegionReplicaUtil
operator|.
name|getStoreFileInfo
argument_list|(
name|conf
argument_list|,
name|fs
argument_list|,
name|regionInfo
argument_list|,
name|regionInfoForFs
argument_list|,
name|familyName
argument_list|,
name|status
operator|.
name|getPath
argument_list|()
argument_list|)
decl_stmt|;
name|storeFiles
operator|.
name|add
argument_list|(
name|info
argument_list|)
expr_stmt|;
block|}
return|return
name|storeFiles
return|;
block|}
comment|/**    * Returns the store files' LocatedFileStatus which available for the family.    * This methods performs the filtering based on the valid store files.    * @param familyName Column Family Name    * @return a list of store files' LocatedFileStatus for the specified family.    */
specifier|public
specifier|static
name|List
argument_list|<
name|LocatedFileStatus
argument_list|>
name|getStoreFilesLocatedStatus
parameter_list|(
specifier|final
name|HRegionFileSystem
name|regionfs
parameter_list|,
specifier|final
name|String
name|familyName
parameter_list|,
specifier|final
name|boolean
name|validate
parameter_list|)
throws|throws
name|IOException
block|{
name|Path
name|familyDir
init|=
name|regionfs
operator|.
name|getStoreDir
argument_list|(
name|familyName
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|LocatedFileStatus
argument_list|>
name|locatedFileStatuses
init|=
name|FSUtils
operator|.
name|listLocatedStatus
argument_list|(
name|regionfs
operator|.
name|getFileSystem
argument_list|()
argument_list|,
name|familyDir
argument_list|)
decl_stmt|;
if|if
condition|(
name|locatedFileStatuses
operator|==
literal|null
condition|)
block|{
if|if
condition|(
name|LOG
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|trace
argument_list|(
literal|"No StoreFiles for: "
operator|+
name|familyDir
argument_list|)
expr_stmt|;
block|}
return|return
literal|null
return|;
block|}
name|List
argument_list|<
name|LocatedFileStatus
argument_list|>
name|validStoreFiles
init|=
name|Lists
operator|.
name|newArrayList
argument_list|()
decl_stmt|;
for|for
control|(
name|LocatedFileStatus
name|status
range|:
name|locatedFileStatuses
control|)
block|{
if|if
condition|(
name|validate
operator|&&
operator|!
name|StoreFileInfo
operator|.
name|isValid
argument_list|(
name|status
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Invalid StoreFile: "
operator|+
name|status
operator|.
name|getPath
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|validStoreFiles
operator|.
name|add
argument_list|(
name|status
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|validStoreFiles
return|;
block|}
comment|/**    * Return Qualified Path of the specified family/file    *    * @param familyName Column Family Name    * @param fileName File Name    * @return The qualified Path for the specified family/file    */
name|Path
name|getStoreFilePath
parameter_list|(
specifier|final
name|String
name|familyName
parameter_list|,
specifier|final
name|String
name|fileName
parameter_list|)
block|{
name|Path
name|familyDir
init|=
name|getStoreDir
argument_list|(
name|familyName
argument_list|)
decl_stmt|;
return|return
operator|new
name|Path
argument_list|(
name|familyDir
argument_list|,
name|fileName
argument_list|)
operator|.
name|makeQualified
argument_list|(
name|fs
operator|.
name|getUri
argument_list|()
argument_list|,
name|fs
operator|.
name|getWorkingDirectory
argument_list|()
argument_list|)
return|;
block|}
comment|/**    * Return the store file information of the specified family/file.    *    * @param familyName Column Family Name    * @param fileName File Name    * @return The {@link StoreFileInfo} for the specified family/file    */
name|StoreFileInfo
name|getStoreFileInfo
parameter_list|(
specifier|final
name|String
name|familyName
parameter_list|,
specifier|final
name|String
name|fileName
parameter_list|)
throws|throws
name|IOException
block|{
name|Path
name|familyDir
init|=
name|getStoreDir
argument_list|(
name|familyName
argument_list|)
decl_stmt|;
return|return
name|ServerRegionReplicaUtil
operator|.
name|getStoreFileInfo
argument_list|(
name|conf
argument_list|,
name|fs
argument_list|,
name|regionInfo
argument_list|,
name|regionInfoForFs
argument_list|,
name|familyName
argument_list|,
operator|new
name|Path
argument_list|(
name|familyDir
argument_list|,
name|fileName
argument_list|)
argument_list|)
return|;
block|}
comment|/**    * Returns true if the specified family has reference files    * @param familyName Column Family Name    * @return true if family contains reference files    * @throws IOException    */
specifier|public
name|boolean
name|hasReferences
parameter_list|(
specifier|final
name|String
name|familyName
parameter_list|)
throws|throws
name|IOException
block|{
name|Path
name|storeDir
init|=
name|getStoreDir
argument_list|(
name|familyName
argument_list|)
decl_stmt|;
name|FileStatus
index|[]
name|files
init|=
name|FSUtils
operator|.
name|listStatus
argument_list|(
name|fs
argument_list|,
name|storeDir
argument_list|)
decl_stmt|;
if|if
condition|(
name|files
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|FileStatus
name|stat
range|:
name|files
control|)
block|{
if|if
condition|(
name|stat
operator|.
name|isDirectory
argument_list|()
condition|)
block|{
continue|continue;
block|}
if|if
condition|(
name|StoreFileInfo
operator|.
name|isReference
argument_list|(
name|stat
operator|.
name|getPath
argument_list|()
argument_list|)
condition|)
block|{
if|if
condition|(
name|LOG
operator|.
name|isTraceEnabled
argument_list|()
condition|)
name|LOG
operator|.
name|trace
argument_list|(
literal|"Reference "
operator|+
name|stat
operator|.
name|getPath
argument_list|()
argument_list|)
expr_stmt|;
return|return
literal|true
return|;
block|}
block|}
block|}
return|return
literal|false
return|;
block|}
comment|/**    * Check whether region has Reference file    * @param htd table desciptor of the region    * @return true if region has reference file    * @throws IOException    */
specifier|public
name|boolean
name|hasReferences
parameter_list|(
specifier|final
name|TableDescriptor
name|htd
parameter_list|)
throws|throws
name|IOException
block|{
for|for
control|(
name|ColumnFamilyDescriptor
name|family
range|:
name|htd
operator|.
name|getColumnFamilies
argument_list|()
control|)
block|{
if|if
condition|(
name|hasReferences
argument_list|(
name|family
operator|.
name|getNameAsString
argument_list|()
argument_list|)
condition|)
block|{
return|return
literal|true
return|;
block|}
block|}
return|return
literal|false
return|;
block|}
comment|/**    * @return the set of families present on disk    * @throws IOException    */
specifier|public
name|Collection
argument_list|<
name|String
argument_list|>
name|getFamilies
parameter_list|()
throws|throws
name|IOException
block|{
name|FileStatus
index|[]
name|fds
init|=
name|FSUtils
operator|.
name|listStatus
argument_list|(
name|fs
argument_list|,
name|getRegionDir
argument_list|()
argument_list|,
operator|new
name|FSUtils
operator|.
name|FamilyDirFilter
argument_list|(
name|fs
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|fds
operator|==
literal|null
condition|)
return|return
literal|null
return|;
name|ArrayList
argument_list|<
name|String
argument_list|>
name|families
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
name|fds
operator|.
name|length
argument_list|)
decl_stmt|;
for|for
control|(
name|FileStatus
name|status
range|:
name|fds
control|)
block|{
name|families
operator|.
name|add
argument_list|(
name|status
operator|.
name|getPath
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
name|families
return|;
block|}
comment|/**    * Remove the region family from disk, archiving the store files.    * @param familyName Column Family Name    * @throws IOException if an error occours during the archiving    */
specifier|public
name|void
name|deleteFamily
parameter_list|(
specifier|final
name|String
name|familyName
parameter_list|)
throws|throws
name|IOException
block|{
comment|// archive family store files
name|HFileArchiver
operator|.
name|archiveFamily
argument_list|(
name|fs
argument_list|,
name|conf
argument_list|,
name|regionInfoForFs
argument_list|,
name|tableDir
argument_list|,
name|Bytes
operator|.
name|toBytes
argument_list|(
name|familyName
argument_list|)
argument_list|)
expr_stmt|;
comment|// delete the family folder
name|Path
name|familyDir
init|=
name|getStoreDir
argument_list|(
name|familyName
argument_list|)
decl_stmt|;
if|if
condition|(
name|fs
operator|.
name|exists
argument_list|(
name|familyDir
argument_list|)
operator|&&
operator|!
name|deleteDir
argument_list|(
name|familyDir
argument_list|)
condition|)
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Could not delete family "
operator|+
name|familyName
operator|+
literal|" from FileSystem for region "
operator|+
name|regionInfoForFs
operator|.
name|getRegionNameAsString
argument_list|()
operator|+
literal|"("
operator|+
name|regionInfoForFs
operator|.
name|getEncodedName
argument_list|()
operator|+
literal|")"
argument_list|)
throw|;
block|}
comment|/**    * Generate a unique file name, used by createTempName() and commitStoreFile()    * @param suffix extra information to append to the generated name    * @return Unique file name    */
specifier|private
specifier|static
name|String
name|generateUniqueName
parameter_list|(
specifier|final
name|String
name|suffix
parameter_list|)
block|{
name|String
name|name
init|=
name|UUID
operator|.
name|randomUUID
argument_list|()
operator|.
name|toString
argument_list|()
operator|.
name|replaceAll
argument_list|(
literal|"-"
argument_list|,
literal|""
argument_list|)
decl_stmt|;
if|if
condition|(
name|suffix
operator|!=
literal|null
condition|)
name|name
operator|+=
name|suffix
expr_stmt|;
return|return
name|name
return|;
block|}
comment|/**    * Generate a unique temporary Path. Used in conjuction with commitStoreFile()    * to get a safer file creation.    *<code>    * Path file = fs.createTempName();    * ...StoreFile.Writer(file)...    * fs.commitStoreFile("family", file);    *</code>    *    * @return Unique {@link Path} of the temporary file    */
specifier|public
name|Path
name|createTempName
parameter_list|()
block|{
return|return
name|createTempName
argument_list|(
literal|null
argument_list|)
return|;
block|}
comment|/**    * Generate a unique temporary Path. Used in conjuction with commitStoreFile()    * to get a safer file creation.    *<code>    * Path file = fs.createTempName();    * ...StoreFile.Writer(file)...    * fs.commitStoreFile("family", file);    *</code>    *    * @param suffix extra information to append to the generated name    * @return Unique {@link Path} of the temporary file    */
specifier|public
name|Path
name|createTempName
parameter_list|(
specifier|final
name|String
name|suffix
parameter_list|)
block|{
return|return
operator|new
name|Path
argument_list|(
name|getTempDir
argument_list|()
argument_list|,
name|generateUniqueName
argument_list|(
name|suffix
argument_list|)
argument_list|)
return|;
block|}
comment|/**    * Move the file from a build/temp location to the main family store directory.    * @param familyName Family that will gain the file    * @param buildPath {@link Path} to the file to commit.    * @return The new {@link Path} of the committed file    * @throws IOException    */
specifier|public
name|Path
name|commitStoreFile
parameter_list|(
specifier|final
name|String
name|familyName
parameter_list|,
specifier|final
name|Path
name|buildPath
parameter_list|)
throws|throws
name|IOException
block|{
name|Path
name|dstPath
init|=
name|preCommitStoreFile
argument_list|(
name|familyName
argument_list|,
name|buildPath
argument_list|,
operator|-
literal|1
argument_list|,
literal|false
argument_list|)
decl_stmt|;
return|return
name|commitStoreFile
argument_list|(
name|buildPath
argument_list|,
name|dstPath
argument_list|)
return|;
block|}
comment|/**    * Generate the filename in the main family store directory for moving the file from a build/temp    *  location.    * @param familyName Family that will gain the file    * @param buildPath {@link Path} to the file to commit.    * @param seqNum Sequence Number to append to the file name (less then 0 if no sequence number)    * @param generateNewName False if you want to keep the buildPath name    * @return The new {@link Path} of the to be committed file    * @throws IOException    */
specifier|private
name|Path
name|preCommitStoreFile
parameter_list|(
specifier|final
name|String
name|familyName
parameter_list|,
specifier|final
name|Path
name|buildPath
parameter_list|,
specifier|final
name|long
name|seqNum
parameter_list|,
specifier|final
name|boolean
name|generateNewName
parameter_list|)
throws|throws
name|IOException
block|{
name|Path
name|storeDir
init|=
name|getStoreDir
argument_list|(
name|familyName
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|fs
operator|.
name|exists
argument_list|(
name|storeDir
argument_list|)
operator|&&
operator|!
name|createDir
argument_list|(
name|storeDir
argument_list|)
condition|)
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Failed creating "
operator|+
name|storeDir
argument_list|)
throw|;
name|String
name|name
init|=
name|buildPath
operator|.
name|getName
argument_list|()
decl_stmt|;
if|if
condition|(
name|generateNewName
condition|)
block|{
name|name
operator|=
name|generateUniqueName
argument_list|(
operator|(
name|seqNum
operator|<
literal|0
operator|)
condition|?
literal|null
else|:
literal|"_SeqId_"
operator|+
name|seqNum
operator|+
literal|"_"
argument_list|)
expr_stmt|;
block|}
name|Path
name|dstPath
init|=
operator|new
name|Path
argument_list|(
name|storeDir
argument_list|,
name|name
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|fs
operator|.
name|exists
argument_list|(
name|buildPath
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|FileNotFoundException
argument_list|(
name|buildPath
operator|.
name|toString
argument_list|()
argument_list|)
throw|;
block|}
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Committing "
operator|+
name|buildPath
operator|+
literal|" as "
operator|+
name|dstPath
argument_list|)
expr_stmt|;
block|}
return|return
name|dstPath
return|;
block|}
comment|/*    * Moves file from staging dir to region dir    * @param buildPath {@link Path} to the file to commit.    * @param dstPath {@link Path} to the file under region dir    * @return The {@link Path} of the committed file    * @throws IOException    */
name|Path
name|commitStoreFile
parameter_list|(
specifier|final
name|Path
name|buildPath
parameter_list|,
name|Path
name|dstPath
parameter_list|)
throws|throws
name|IOException
block|{
comment|// buildPath exists, therefore not doing an exists() check.
if|if
condition|(
operator|!
name|rename
argument_list|(
name|buildPath
argument_list|,
name|dstPath
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Failed rename of "
operator|+
name|buildPath
operator|+
literal|" to "
operator|+
name|dstPath
argument_list|)
throw|;
block|}
return|return
name|dstPath
return|;
block|}
comment|/**    * Archives the specified store file from the specified family.    * @param familyName Family that contains the store files    * @param filePath {@link Path} to the store file to remove    * @throws IOException if the archiving fails    */
specifier|public
name|void
name|removeStoreFile
parameter_list|(
specifier|final
name|String
name|familyName
parameter_list|,
specifier|final
name|Path
name|filePath
parameter_list|)
throws|throws
name|IOException
block|{
name|HFileArchiver
operator|.
name|archiveStoreFile
argument_list|(
name|this
operator|.
name|conf
argument_list|,
name|this
operator|.
name|fs
argument_list|,
name|this
operator|.
name|regionInfoForFs
argument_list|,
name|this
operator|.
name|tableDir
argument_list|,
name|Bytes
operator|.
name|toBytes
argument_list|(
name|familyName
argument_list|)
argument_list|,
name|filePath
argument_list|)
expr_stmt|;
block|}
comment|/**    * Closes and archives the specified store files from the specified family.    * @param familyName Family that contains the store files    * @param storeFiles set of store files to remove    * @throws IOException if the archiving fails    */
specifier|public
name|void
name|removeStoreFiles
parameter_list|(
name|String
name|familyName
parameter_list|,
name|Collection
argument_list|<
name|HStoreFile
argument_list|>
name|storeFiles
parameter_list|)
throws|throws
name|IOException
block|{
name|HFileArchiver
operator|.
name|archiveStoreFiles
argument_list|(
name|this
operator|.
name|conf
argument_list|,
name|this
operator|.
name|fs
argument_list|,
name|this
operator|.
name|regionInfoForFs
argument_list|,
name|this
operator|.
name|tableDir
argument_list|,
name|Bytes
operator|.
name|toBytes
argument_list|(
name|familyName
argument_list|)
argument_list|,
name|storeFiles
argument_list|)
expr_stmt|;
block|}
comment|/**    * Bulk load: Add a specified store file to the specified family.    * If the source file is on the same different file-system is moved from the    * source location to the destination location, otherwise is copied over.    *    * @param familyName Family that will gain the file    * @param srcPath {@link Path} to the file to import    * @param seqNum Bulk Load sequence number    * @return The destination {@link Path} of the bulk loaded file    * @throws IOException    */
name|Pair
argument_list|<
name|Path
argument_list|,
name|Path
argument_list|>
name|bulkLoadStoreFile
parameter_list|(
specifier|final
name|String
name|familyName
parameter_list|,
name|Path
name|srcPath
parameter_list|,
name|long
name|seqNum
parameter_list|)
throws|throws
name|IOException
block|{
comment|// Copy the file if it's on another filesystem
name|FileSystem
name|srcFs
init|=
name|srcPath
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
decl_stmt|;
name|srcPath
operator|=
name|srcFs
operator|.
name|resolvePath
argument_list|(
name|srcPath
argument_list|)
expr_stmt|;
name|FileSystem
name|realSrcFs
init|=
name|srcPath
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
decl_stmt|;
name|FileSystem
name|desFs
init|=
name|fs
operator|instanceof
name|HFileSystem
condition|?
operator|(
operator|(
name|HFileSystem
operator|)
name|fs
operator|)
operator|.
name|getBackingFs
argument_list|()
else|:
name|fs
decl_stmt|;
comment|// We can't compare FileSystem instances as equals() includes UGI instance
comment|// as part of the comparison and won't work when doing SecureBulkLoad
comment|// TODO deal with viewFS
if|if
condition|(
operator|!
name|FSHDFSUtils
operator|.
name|isSameHdfs
argument_list|(
name|conf
argument_list|,
name|realSrcFs
argument_list|,
name|desFs
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Bulk-load file "
operator|+
name|srcPath
operator|+
literal|" is on different filesystem than "
operator|+
literal|"the destination store. Copying file over to destination filesystem."
argument_list|)
expr_stmt|;
name|Path
name|tmpPath
init|=
name|createTempName
argument_list|()
decl_stmt|;
name|FileUtil
operator|.
name|copy
argument_list|(
name|realSrcFs
argument_list|,
name|srcPath
argument_list|,
name|fs
argument_list|,
name|tmpPath
argument_list|,
literal|false
argument_list|,
name|conf
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Copied "
operator|+
name|srcPath
operator|+
literal|" to temporary path on destination filesystem: "
operator|+
name|tmpPath
argument_list|)
expr_stmt|;
name|srcPath
operator|=
name|tmpPath
expr_stmt|;
block|}
return|return
operator|new
name|Pair
argument_list|<>
argument_list|(
name|srcPath
argument_list|,
name|preCommitStoreFile
argument_list|(
name|familyName
argument_list|,
name|srcPath
argument_list|,
name|seqNum
argument_list|,
literal|true
argument_list|)
argument_list|)
return|;
block|}
comment|// ===========================================================================
comment|//  Splits Helpers
comment|// ===========================================================================
comment|/** @return {@link Path} to the temp directory used during split operations */
name|Path
name|getSplitsDir
parameter_list|()
block|{
return|return
operator|new
name|Path
argument_list|(
name|getRegionDir
argument_list|()
argument_list|,
name|REGION_SPLITS_DIR
argument_list|)
return|;
block|}
specifier|public
name|Path
name|getSplitsDir
parameter_list|(
specifier|final
name|RegionInfo
name|hri
parameter_list|)
block|{
return|return
operator|new
name|Path
argument_list|(
name|getSplitsDir
argument_list|()
argument_list|,
name|hri
operator|.
name|getEncodedName
argument_list|()
argument_list|)
return|;
block|}
comment|/**    * Clean up any split detritus that may have been left around from previous split attempts.    */
name|void
name|cleanupSplitsDir
parameter_list|()
throws|throws
name|IOException
block|{
name|deleteDir
argument_list|(
name|getSplitsDir
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|/**    * Clean up any split detritus that may have been left around from previous    * split attempts.    * Call this method on initial region deploy.    * @throws IOException    */
name|void
name|cleanupAnySplitDetritus
parameter_list|()
throws|throws
name|IOException
block|{
name|Path
name|splitdir
init|=
name|this
operator|.
name|getSplitsDir
argument_list|()
decl_stmt|;
if|if
condition|(
operator|!
name|fs
operator|.
name|exists
argument_list|(
name|splitdir
argument_list|)
condition|)
return|return;
comment|// Look at the splitdir.  It could have the encoded names of the daughter
comment|// regions we tried to make.  See if the daughter regions actually got made
comment|// out under the tabledir.  If here under splitdir still, then the split did
comment|// not complete.  Try and do cleanup.  This code WILL NOT catch the case
comment|// where we successfully created daughter a but regionserver crashed during
comment|// the creation of region b.  In this case, there'll be an orphan daughter
comment|// dir in the filesystem.  TOOD: Fix.
name|FileStatus
index|[]
name|daughters
init|=
name|FSUtils
operator|.
name|listStatus
argument_list|(
name|fs
argument_list|,
name|splitdir
argument_list|,
operator|new
name|FSUtils
operator|.
name|DirFilter
argument_list|(
name|fs
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|daughters
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|FileStatus
name|daughter
range|:
name|daughters
control|)
block|{
name|Path
name|daughterDir
init|=
operator|new
name|Path
argument_list|(
name|getTableDir
argument_list|()
argument_list|,
name|daughter
operator|.
name|getPath
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|fs
operator|.
name|exists
argument_list|(
name|daughterDir
argument_list|)
operator|&&
operator|!
name|deleteDir
argument_list|(
name|daughterDir
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Failed delete of "
operator|+
name|daughterDir
argument_list|)
throw|;
block|}
block|}
block|}
name|cleanupSplitsDir
argument_list|()
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Cleaned up old failed split transaction detritus: "
operator|+
name|splitdir
argument_list|)
expr_stmt|;
block|}
comment|/**    * Remove daughter region    * @param regionInfo daughter {@link RegionInfo}    * @throws IOException    */
name|void
name|cleanupDaughterRegion
parameter_list|(
specifier|final
name|RegionInfo
name|regionInfo
parameter_list|)
throws|throws
name|IOException
block|{
name|Path
name|regionDir
init|=
operator|new
name|Path
argument_list|(
name|this
operator|.
name|tableDir
argument_list|,
name|regionInfo
operator|.
name|getEncodedName
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|this
operator|.
name|fs
operator|.
name|exists
argument_list|(
name|regionDir
argument_list|)
operator|&&
operator|!
name|deleteDir
argument_list|(
name|regionDir
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Failed delete of "
operator|+
name|regionDir
argument_list|)
throw|;
block|}
block|}
comment|/**    * Commit a daughter region, moving it from the split temporary directory    * to the proper location in the filesystem.    *    * @param regionInfo daughter {@link org.apache.hadoop.hbase.client.RegionInfo}    * @throws IOException    */
specifier|public
name|Path
name|commitDaughterRegion
parameter_list|(
specifier|final
name|RegionInfo
name|regionInfo
parameter_list|)
throws|throws
name|IOException
block|{
name|Path
name|regionDir
init|=
operator|new
name|Path
argument_list|(
name|this
operator|.
name|tableDir
argument_list|,
name|regionInfo
operator|.
name|getEncodedName
argument_list|()
argument_list|)
decl_stmt|;
name|Path
name|daughterTmpDir
init|=
name|this
operator|.
name|getSplitsDir
argument_list|(
name|regionInfo
argument_list|)
decl_stmt|;
if|if
condition|(
name|fs
operator|.
name|exists
argument_list|(
name|daughterTmpDir
argument_list|)
condition|)
block|{
comment|// Write HRI to a file in case we need to recover hbase:meta
name|Path
name|regionInfoFile
init|=
operator|new
name|Path
argument_list|(
name|daughterTmpDir
argument_list|,
name|REGION_INFO_FILE
argument_list|)
decl_stmt|;
name|byte
index|[]
name|regionInfoContent
init|=
name|getRegionInfoFileContent
argument_list|(
name|regionInfo
argument_list|)
decl_stmt|;
name|writeRegionInfoFileContent
argument_list|(
name|conf
argument_list|,
name|fs
argument_list|,
name|regionInfoFile
argument_list|,
name|regionInfoContent
argument_list|)
expr_stmt|;
comment|// Move the daughter temp dir to the table dir
if|if
condition|(
operator|!
name|rename
argument_list|(
name|daughterTmpDir
argument_list|,
name|regionDir
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Unable to rename "
operator|+
name|daughterTmpDir
operator|+
literal|" to "
operator|+
name|regionDir
argument_list|)
throw|;
block|}
block|}
return|return
name|regionDir
return|;
block|}
comment|/**    * Create the region splits directory.    */
specifier|public
name|void
name|createSplitsDir
parameter_list|(
name|RegionInfo
name|daughterA
parameter_list|,
name|RegionInfo
name|daughterB
parameter_list|)
throws|throws
name|IOException
block|{
name|Path
name|splitdir
init|=
name|getSplitsDir
argument_list|()
decl_stmt|;
if|if
condition|(
name|fs
operator|.
name|exists
argument_list|(
name|splitdir
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"The "
operator|+
name|splitdir
operator|+
literal|" directory exists.  Hence deleting it to recreate it"
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|deleteDir
argument_list|(
name|splitdir
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Failed deletion of "
operator|+
name|splitdir
operator|+
literal|" before creating them again."
argument_list|)
throw|;
block|}
block|}
comment|// splitDir doesn't exists now. No need to do an exists() call for it.
if|if
condition|(
operator|!
name|createDir
argument_list|(
name|splitdir
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Failed create of "
operator|+
name|splitdir
argument_list|)
throw|;
block|}
name|Path
name|daughterATmpDir
init|=
name|getSplitsDir
argument_list|(
name|daughterA
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|createDir
argument_list|(
name|daughterATmpDir
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Failed create of "
operator|+
name|daughterATmpDir
argument_list|)
throw|;
block|}
name|Path
name|daughterBTmpDir
init|=
name|getSplitsDir
argument_list|(
name|daughterB
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|createDir
argument_list|(
name|daughterBTmpDir
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Failed create of "
operator|+
name|daughterBTmpDir
argument_list|)
throw|;
block|}
block|}
comment|/**    * Write out a split reference. Package local so it doesnt leak out of    * regionserver.    * @param hri {@link RegionInfo} of the destination    * @param familyName Column Family Name    * @param f File to split.    * @param splitRow Split Row    * @param top True if we are referring to the top half of the hfile.    * @param splitPolicy A split policy instance; be careful! May not be full populated; e.g. if    *                    this method is invoked on the Master side, then the RegionSplitPolicy will    *                    NOT have a reference to a Region.    * @return Path to created reference.    * @throws IOException    */
specifier|public
name|Path
name|splitStoreFile
parameter_list|(
name|RegionInfo
name|hri
parameter_list|,
name|String
name|familyName
parameter_list|,
name|HStoreFile
name|f
parameter_list|,
name|byte
index|[]
name|splitRow
parameter_list|,
name|boolean
name|top
parameter_list|,
name|RegionSplitPolicy
name|splitPolicy
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|splitPolicy
operator|==
literal|null
operator|||
operator|!
name|splitPolicy
operator|.
name|skipStoreFileRangeCheck
argument_list|(
name|familyName
argument_list|)
condition|)
block|{
comment|// Check whether the split row lies in the range of the store file
comment|// If it is outside the range, return directly.
name|f
operator|.
name|initReader
argument_list|()
expr_stmt|;
try|try
block|{
if|if
condition|(
name|top
condition|)
block|{
comment|//check if larger than last key.
name|Cell
name|splitKey
init|=
name|PrivateCellUtil
operator|.
name|createFirstOnRow
argument_list|(
name|splitRow
argument_list|)
decl_stmt|;
name|Optional
argument_list|<
name|Cell
argument_list|>
name|lastKey
init|=
name|f
operator|.
name|getLastKey
argument_list|()
decl_stmt|;
comment|// If lastKey is null means storefile is empty.
if|if
condition|(
operator|!
name|lastKey
operator|.
name|isPresent
argument_list|()
condition|)
block|{
return|return
literal|null
return|;
block|}
if|if
condition|(
name|f
operator|.
name|getComparator
argument_list|()
operator|.
name|compare
argument_list|(
name|splitKey
argument_list|,
name|lastKey
operator|.
name|get
argument_list|()
argument_list|)
operator|>
literal|0
condition|)
block|{
return|return
literal|null
return|;
block|}
block|}
else|else
block|{
comment|//check if smaller than first key
name|Cell
name|splitKey
init|=
name|PrivateCellUtil
operator|.
name|createLastOnRow
argument_list|(
name|splitRow
argument_list|)
decl_stmt|;
name|Optional
argument_list|<
name|Cell
argument_list|>
name|firstKey
init|=
name|f
operator|.
name|getFirstKey
argument_list|()
decl_stmt|;
comment|// If firstKey is null means storefile is empty.
if|if
condition|(
operator|!
name|firstKey
operator|.
name|isPresent
argument_list|()
condition|)
block|{
return|return
literal|null
return|;
block|}
if|if
condition|(
name|f
operator|.
name|getComparator
argument_list|()
operator|.
name|compare
argument_list|(
name|splitKey
argument_list|,
name|firstKey
operator|.
name|get
argument_list|()
argument_list|)
operator|<
literal|0
condition|)
block|{
return|return
literal|null
return|;
block|}
block|}
block|}
finally|finally
block|{
name|f
operator|.
name|closeStoreFile
argument_list|(
name|f
operator|.
name|getCacheConf
argument_list|()
operator|!=
literal|null
condition|?
name|f
operator|.
name|getCacheConf
argument_list|()
operator|.
name|shouldEvictOnClose
argument_list|()
else|:
literal|true
argument_list|)
expr_stmt|;
block|}
block|}
name|Path
name|splitDir
init|=
operator|new
name|Path
argument_list|(
name|getSplitsDir
argument_list|(
name|hri
argument_list|)
argument_list|,
name|familyName
argument_list|)
decl_stmt|;
comment|// A reference to the bottom half of the hsf store file.
name|Reference
name|r
init|=
name|top
condition|?
name|Reference
operator|.
name|createTopReference
argument_list|(
name|splitRow
argument_list|)
else|:
name|Reference
operator|.
name|createBottomReference
argument_list|(
name|splitRow
argument_list|)
decl_stmt|;
comment|// Add the referred-to regions name as a dot separated suffix.
comment|// See REF_NAME_REGEX regex above.  The referred-to regions name is
comment|// up in the path of the passed in<code>f</code> -- parentdir is family,
comment|// then the directory above is the region name.
name|String
name|parentRegionName
init|=
name|regionInfoForFs
operator|.
name|getEncodedName
argument_list|()
decl_stmt|;
comment|// Write reference with same file id only with the other region name as
comment|// suffix and into the new region location (under same family).
name|Path
name|p
init|=
operator|new
name|Path
argument_list|(
name|splitDir
argument_list|,
name|f
operator|.
name|getPath
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|"."
operator|+
name|parentRegionName
argument_list|)
decl_stmt|;
return|return
name|r
operator|.
name|write
argument_list|(
name|fs
argument_list|,
name|p
argument_list|)
return|;
block|}
comment|// ===========================================================================
comment|//  Merge Helpers
comment|// ===========================================================================
comment|/** @return {@link Path} to the temp directory used during merge operations */
specifier|public
name|Path
name|getMergesDir
parameter_list|()
block|{
return|return
operator|new
name|Path
argument_list|(
name|getRegionDir
argument_list|()
argument_list|,
name|REGION_MERGES_DIR
argument_list|)
return|;
block|}
name|Path
name|getMergesDir
parameter_list|(
specifier|final
name|RegionInfo
name|hri
parameter_list|)
block|{
return|return
operator|new
name|Path
argument_list|(
name|getMergesDir
argument_list|()
argument_list|,
name|hri
operator|.
name|getEncodedName
argument_list|()
argument_list|)
return|;
block|}
comment|/**    * Clean up any merge detritus that may have been left around from previous merge attempts.    */
name|void
name|cleanupMergesDir
parameter_list|()
throws|throws
name|IOException
block|{
name|deleteDir
argument_list|(
name|getMergesDir
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|/**    * Remove merged region    * @param mergedRegion {@link RegionInfo}    * @throws IOException    */
specifier|public
name|void
name|cleanupMergedRegion
parameter_list|(
specifier|final
name|RegionInfo
name|mergedRegion
parameter_list|)
throws|throws
name|IOException
block|{
name|Path
name|regionDir
init|=
operator|new
name|Path
argument_list|(
name|this
operator|.
name|tableDir
argument_list|,
name|mergedRegion
operator|.
name|getEncodedName
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|this
operator|.
name|fs
operator|.
name|exists
argument_list|(
name|regionDir
argument_list|)
operator|&&
operator|!
name|this
operator|.
name|fs
operator|.
name|delete
argument_list|(
name|regionDir
argument_list|,
literal|true
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Failed delete of "
operator|+
name|regionDir
argument_list|)
throw|;
block|}
block|}
specifier|static
name|boolean
name|mkdirs
parameter_list|(
name|FileSystem
name|fs
parameter_list|,
name|Configuration
name|conf
parameter_list|,
name|Path
name|dir
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|FSUtils
operator|.
name|isDistributedFileSystem
argument_list|(
name|fs
argument_list|)
operator|||
operator|!
name|conf
operator|.
name|getBoolean
argument_list|(
name|HConstants
operator|.
name|ENABLE_DATA_FILE_UMASK
argument_list|,
literal|false
argument_list|)
condition|)
block|{
return|return
name|fs
operator|.
name|mkdirs
argument_list|(
name|dir
argument_list|)
return|;
block|}
name|FsPermission
name|perms
init|=
name|FSUtils
operator|.
name|getFilePermissions
argument_list|(
name|fs
argument_list|,
name|conf
argument_list|,
name|HConstants
operator|.
name|DATA_FILE_UMASK_KEY
argument_list|)
decl_stmt|;
return|return
name|fs
operator|.
name|mkdirs
argument_list|(
name|dir
argument_list|,
name|perms
argument_list|)
return|;
block|}
comment|/**    * Create the region merges directory.    * @throws IOException If merges dir already exists or we fail to create it.    * @see HRegionFileSystem#cleanupMergesDir()    */
specifier|public
name|void
name|createMergesDir
parameter_list|()
throws|throws
name|IOException
block|{
name|Path
name|mergesdir
init|=
name|getMergesDir
argument_list|()
decl_stmt|;
if|if
condition|(
name|fs
operator|.
name|exists
argument_list|(
name|mergesdir
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"The "
operator|+
name|mergesdir
operator|+
literal|" directory exists.  Hence deleting it to recreate it"
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|fs
operator|.
name|delete
argument_list|(
name|mergesdir
argument_list|,
literal|true
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Failed deletion of "
operator|+
name|mergesdir
operator|+
literal|" before creating them again."
argument_list|)
throw|;
block|}
block|}
if|if
condition|(
operator|!
name|mkdirs
argument_list|(
name|fs
argument_list|,
name|conf
argument_list|,
name|mergesdir
argument_list|)
condition|)
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Failed create of "
operator|+
name|mergesdir
argument_list|)
throw|;
block|}
comment|/**    * Write out a merge reference under the given merges directory. Package local    * so it doesnt leak out of regionserver.    * @param mergedRegion {@link RegionInfo} of the merged region    * @param familyName Column Family Name    * @param f File to create reference.    * @param mergedDir    * @return Path to created reference.    * @throws IOException    */
specifier|public
name|Path
name|mergeStoreFile
parameter_list|(
name|RegionInfo
name|mergedRegion
parameter_list|,
name|String
name|familyName
parameter_list|,
name|HStoreFile
name|f
parameter_list|,
name|Path
name|mergedDir
parameter_list|)
throws|throws
name|IOException
block|{
name|Path
name|referenceDir
init|=
operator|new
name|Path
argument_list|(
operator|new
name|Path
argument_list|(
name|mergedDir
argument_list|,
name|mergedRegion
operator|.
name|getEncodedName
argument_list|()
argument_list|)
argument_list|,
name|familyName
argument_list|)
decl_stmt|;
comment|// A whole reference to the store file.
name|Reference
name|r
init|=
name|Reference
operator|.
name|createTopReference
argument_list|(
name|regionInfoForFs
operator|.
name|getStartKey
argument_list|()
argument_list|)
decl_stmt|;
comment|// Add the referred-to regions name as a dot separated suffix.
comment|// See REF_NAME_REGEX regex above. The referred-to regions name is
comment|// up in the path of the passed in<code>f</code> -- parentdir is family,
comment|// then the directory above is the region name.
name|String
name|mergingRegionName
init|=
name|regionInfoForFs
operator|.
name|getEncodedName
argument_list|()
decl_stmt|;
comment|// Write reference with same file id only with the other region name as
comment|// suffix and into the new region location (under same family).
name|Path
name|p
init|=
operator|new
name|Path
argument_list|(
name|referenceDir
argument_list|,
name|f
operator|.
name|getPath
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|"."
operator|+
name|mergingRegionName
argument_list|)
decl_stmt|;
return|return
name|r
operator|.
name|write
argument_list|(
name|fs
argument_list|,
name|p
argument_list|)
return|;
block|}
comment|/**    * Commit a merged region, moving it from the merges temporary directory to    * the proper location in the filesystem.    * @param mergedRegionInfo merged region {@link RegionInfo}    * @throws IOException    */
specifier|public
name|void
name|commitMergedRegion
parameter_list|(
specifier|final
name|RegionInfo
name|mergedRegionInfo
parameter_list|)
throws|throws
name|IOException
block|{
name|Path
name|regionDir
init|=
operator|new
name|Path
argument_list|(
name|this
operator|.
name|tableDir
argument_list|,
name|mergedRegionInfo
operator|.
name|getEncodedName
argument_list|()
argument_list|)
decl_stmt|;
name|Path
name|mergedRegionTmpDir
init|=
name|this
operator|.
name|getMergesDir
argument_list|(
name|mergedRegionInfo
argument_list|)
decl_stmt|;
comment|// Move the tmp dir in the expected location
if|if
condition|(
name|mergedRegionTmpDir
operator|!=
literal|null
operator|&&
name|fs
operator|.
name|exists
argument_list|(
name|mergedRegionTmpDir
argument_list|)
condition|)
block|{
comment|// Write HRI to a file in case we need to recover hbase:meta
name|Path
name|regionInfoFile
init|=
operator|new
name|Path
argument_list|(
name|mergedRegionTmpDir
argument_list|,
name|REGION_INFO_FILE
argument_list|)
decl_stmt|;
name|byte
index|[]
name|regionInfoContent
init|=
name|getRegionInfoFileContent
argument_list|(
name|regionInfo
argument_list|)
decl_stmt|;
name|writeRegionInfoFileContent
argument_list|(
name|conf
argument_list|,
name|fs
argument_list|,
name|regionInfoFile
argument_list|,
name|regionInfoContent
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|fs
operator|.
name|rename
argument_list|(
name|mergedRegionTmpDir
argument_list|,
name|regionDir
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Unable to rename "
operator|+
name|mergedRegionTmpDir
operator|+
literal|" to "
operator|+
name|regionDir
argument_list|)
throw|;
block|}
block|}
block|}
comment|// ===========================================================================
comment|//  Create/Open/Delete Helpers
comment|// ===========================================================================
comment|/**    * Log the current state of the region    * @param LOG log to output information    * @throws IOException if an unexpected exception occurs    */
name|void
name|logFileSystemState
parameter_list|(
specifier|final
name|Logger
name|LOG
parameter_list|)
throws|throws
name|IOException
block|{
name|FSUtils
operator|.
name|logFileSystemState
argument_list|(
name|fs
argument_list|,
name|this
operator|.
name|getRegionDir
argument_list|()
argument_list|,
name|LOG
argument_list|)
expr_stmt|;
block|}
comment|/**    * @param hri    * @return Content of the file we write out to the filesystem under a region    * @throws IOException    */
specifier|private
specifier|static
name|byte
index|[]
name|getRegionInfoFileContent
parameter_list|(
specifier|final
name|RegionInfo
name|hri
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|RegionInfo
operator|.
name|toDelimitedByteArray
argument_list|(
name|hri
argument_list|)
return|;
block|}
comment|/**    * Create a {@link RegionInfo} from the serialized version on-disk.    * @param fs {@link FileSystem} that contains the Region Info file    * @param regionDir {@link Path} to the Region Directory that contains the Info file    * @return An {@link RegionInfo} instance gotten from the Region Info file.    * @throws IOException if an error occurred during file open/read operation.    */
specifier|public
specifier|static
name|RegionInfo
name|loadRegionInfoFileContent
parameter_list|(
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Path
name|regionDir
parameter_list|)
throws|throws
name|IOException
block|{
name|FSDataInputStream
name|in
init|=
name|fs
operator|.
name|open
argument_list|(
operator|new
name|Path
argument_list|(
name|regionDir
argument_list|,
name|REGION_INFO_FILE
argument_list|)
argument_list|)
decl_stmt|;
try|try
block|{
return|return
name|RegionInfo
operator|.
name|parseFrom
argument_list|(
name|in
argument_list|)
return|;
block|}
finally|finally
block|{
name|in
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**    * Write the .regioninfo file on-disk.    * Overwrites if exists already.    */
specifier|private
specifier|static
name|void
name|writeRegionInfoFileContent
parameter_list|(
specifier|final
name|Configuration
name|conf
parameter_list|,
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Path
name|regionInfoFile
parameter_list|,
specifier|final
name|byte
index|[]
name|content
parameter_list|)
throws|throws
name|IOException
block|{
comment|// First check to get the permissions
name|FsPermission
name|perms
init|=
name|FSUtils
operator|.
name|getFilePermissions
argument_list|(
name|fs
argument_list|,
name|conf
argument_list|,
name|HConstants
operator|.
name|DATA_FILE_UMASK_KEY
argument_list|)
decl_stmt|;
comment|// Write the RegionInfo file content
name|FSDataOutputStream
name|out
init|=
name|FSUtils
operator|.
name|create
argument_list|(
name|conf
argument_list|,
name|fs
argument_list|,
name|regionInfoFile
argument_list|,
name|perms
argument_list|,
literal|null
argument_list|)
decl_stmt|;
try|try
block|{
name|out
operator|.
name|write
argument_list|(
name|content
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|out
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**    * Write out an info file under the stored region directory. Useful recovering mangled regions.    * If the regionInfo already exists on-disk, then we fast exit.    */
name|void
name|checkRegionInfoOnFilesystem
parameter_list|()
throws|throws
name|IOException
block|{
comment|// Compose the content of the file so we can compare to length in filesystem. If not same,
comment|// rewrite it (it may have been written in the old format using Writables instead of pb). The
comment|// pb version is much shorter -- we write now w/o the toString version -- so checking length
comment|// only should be sufficient. I don't want to read the file every time to check if it pb
comment|// serialized.
name|byte
index|[]
name|content
init|=
name|getRegionInfoFileContent
argument_list|(
name|regionInfoForFs
argument_list|)
decl_stmt|;
comment|// Verify if the region directory exists before opening a region. We need to do this since if
comment|// the region directory doesn't exist we will re-create the region directory and a new HRI
comment|// when HRegion.openHRegion() is called.
try|try
block|{
name|FileStatus
name|status
init|=
name|fs
operator|.
name|getFileStatus
argument_list|(
name|getRegionDir
argument_list|()
argument_list|)
decl_stmt|;
block|}
catch|catch
parameter_list|(
name|FileNotFoundException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
name|getRegionDir
argument_list|()
operator|+
literal|" doesn't exist for region: "
operator|+
name|regionInfoForFs
operator|.
name|getEncodedName
argument_list|()
operator|+
literal|" on table "
operator|+
name|regionInfo
operator|.
name|getTable
argument_list|()
argument_list|)
expr_stmt|;
block|}
try|try
block|{
name|Path
name|regionInfoFile
init|=
operator|new
name|Path
argument_list|(
name|getRegionDir
argument_list|()
argument_list|,
name|REGION_INFO_FILE
argument_list|)
decl_stmt|;
name|FileStatus
name|status
init|=
name|fs
operator|.
name|getFileStatus
argument_list|(
name|regionInfoFile
argument_list|)
decl_stmt|;
if|if
condition|(
name|status
operator|!=
literal|null
operator|&&
name|status
operator|.
name|getLen
argument_list|()
operator|==
name|content
operator|.
name|length
condition|)
block|{
comment|// Then assume the content good and move on.
comment|// NOTE: that the length is not sufficient to define the the content matches.
return|return;
block|}
name|LOG
operator|.
name|info
argument_list|(
literal|"Rewriting .regioninfo file at: "
operator|+
name|regionInfoFile
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|fs
operator|.
name|delete
argument_list|(
name|regionInfoFile
argument_list|,
literal|false
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Unable to remove existing "
operator|+
name|regionInfoFile
argument_list|)
throw|;
block|}
block|}
catch|catch
parameter_list|(
name|FileNotFoundException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
name|REGION_INFO_FILE
operator|+
literal|" file not found for region: "
operator|+
name|regionInfoForFs
operator|.
name|getEncodedName
argument_list|()
operator|+
literal|" on table "
operator|+
name|regionInfo
operator|.
name|getTable
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|// Write HRI to a file in case we need to recover hbase:meta
name|writeRegionInfoOnFilesystem
argument_list|(
name|content
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
comment|/**    * Write out an info file under the region directory. Useful recovering mangled regions.    * @param useTempDir indicate whether or not using the region .tmp dir for a safer file creation.    */
specifier|private
name|void
name|writeRegionInfoOnFilesystem
parameter_list|(
name|boolean
name|useTempDir
parameter_list|)
throws|throws
name|IOException
block|{
name|byte
index|[]
name|content
init|=
name|getRegionInfoFileContent
argument_list|(
name|regionInfoForFs
argument_list|)
decl_stmt|;
name|writeRegionInfoOnFilesystem
argument_list|(
name|content
argument_list|,
name|useTempDir
argument_list|)
expr_stmt|;
block|}
comment|/**    * Write out an info file under the region directory. Useful recovering mangled regions.    * @param regionInfoContent serialized version of the {@link RegionInfo}    * @param useTempDir indicate whether or not using the region .tmp dir for a safer file creation.    */
specifier|private
name|void
name|writeRegionInfoOnFilesystem
parameter_list|(
specifier|final
name|byte
index|[]
name|regionInfoContent
parameter_list|,
specifier|final
name|boolean
name|useTempDir
parameter_list|)
throws|throws
name|IOException
block|{
name|Path
name|regionInfoFile
init|=
operator|new
name|Path
argument_list|(
name|getRegionDir
argument_list|()
argument_list|,
name|REGION_INFO_FILE
argument_list|)
decl_stmt|;
if|if
condition|(
name|useTempDir
condition|)
block|{
comment|// Create in tmpDir and then move into place in case we crash after
comment|// create but before close. If we don't successfully close the file,
comment|// subsequent region reopens will fail the below because create is
comment|// registered in NN.
comment|// And then create the file
name|Path
name|tmpPath
init|=
operator|new
name|Path
argument_list|(
name|getTempDir
argument_list|()
argument_list|,
name|REGION_INFO_FILE
argument_list|)
decl_stmt|;
comment|// If datanode crashes or if the RS goes down just before the close is called while trying to
comment|// close the created regioninfo file in the .tmp directory then on next
comment|// creation we will be getting AlreadyCreatedException.
comment|// Hence delete and create the file if exists.
if|if
condition|(
name|FSUtils
operator|.
name|isExists
argument_list|(
name|fs
argument_list|,
name|tmpPath
argument_list|)
condition|)
block|{
name|FSUtils
operator|.
name|delete
argument_list|(
name|fs
argument_list|,
name|tmpPath
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
comment|// Write HRI to a file in case we need to recover hbase:meta
name|writeRegionInfoFileContent
argument_list|(
name|conf
argument_list|,
name|fs
argument_list|,
name|tmpPath
argument_list|,
name|regionInfoContent
argument_list|)
expr_stmt|;
comment|// Move the created file to the original path
if|if
condition|(
name|fs
operator|.
name|exists
argument_list|(
name|tmpPath
argument_list|)
operator|&&
operator|!
name|rename
argument_list|(
name|tmpPath
argument_list|,
name|regionInfoFile
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Unable to rename "
operator|+
name|tmpPath
operator|+
literal|" to "
operator|+
name|regionInfoFile
argument_list|)
throw|;
block|}
block|}
else|else
block|{
comment|// Write HRI to a file in case we need to recover hbase:meta
name|writeRegionInfoFileContent
argument_list|(
name|conf
argument_list|,
name|fs
argument_list|,
name|regionInfoFile
argument_list|,
name|regionInfoContent
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Create a new Region on file-system.    * @param conf the {@link Configuration} to use    * @param fs {@link FileSystem} from which to add the region    * @param tableDir {@link Path} to where the table is being stored    * @param regionInfo {@link RegionInfo} for region to be added    * @throws IOException if the region creation fails due to a FileSystem exception.    */
specifier|public
specifier|static
name|HRegionFileSystem
name|createRegionOnFileSystem
parameter_list|(
specifier|final
name|Configuration
name|conf
parameter_list|,
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Path
name|tableDir
parameter_list|,
specifier|final
name|RegionInfo
name|regionInfo
parameter_list|)
throws|throws
name|IOException
block|{
name|HRegionFileSystem
name|regionFs
init|=
operator|new
name|HRegionFileSystem
argument_list|(
name|conf
argument_list|,
name|fs
argument_list|,
name|tableDir
argument_list|,
name|regionInfo
argument_list|)
decl_stmt|;
comment|// We only create a .regioninfo and the region directory if this is the default region replica
if|if
condition|(
name|regionInfo
operator|.
name|getReplicaId
argument_list|()
operator|==
name|RegionInfo
operator|.
name|DEFAULT_REPLICA_ID
condition|)
block|{
name|Path
name|regionDir
init|=
name|regionFs
operator|.
name|getRegionDir
argument_list|()
decl_stmt|;
if|if
condition|(
name|fs
operator|.
name|exists
argument_list|(
name|regionDir
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Trying to create a region that already exists on disk: "
operator|+
name|regionDir
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// Create the region directory
if|if
condition|(
operator|!
name|createDirOnFileSystem
argument_list|(
name|fs
argument_list|,
name|conf
argument_list|,
name|regionDir
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Unable to create the region directory: "
operator|+
name|regionDir
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Unable to create region directory: "
operator|+
name|regionDir
argument_list|)
throw|;
block|}
block|}
comment|// Write HRI to a file in case we need to recover hbase:meta
name|regionFs
operator|.
name|writeRegionInfoOnFilesystem
argument_list|(
literal|false
argument_list|)
expr_stmt|;
block|}
else|else
block|{
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
name|LOG
operator|.
name|debug
argument_list|(
literal|"Skipping creation of .regioninfo file for "
operator|+
name|regionInfo
argument_list|)
expr_stmt|;
block|}
return|return
name|regionFs
return|;
block|}
comment|/**    * Open Region from file-system.    * @param conf the {@link Configuration} to use    * @param fs {@link FileSystem} from which to add the region    * @param tableDir {@link Path} to where the table is being stored    * @param regionInfo {@link RegionInfo} for region to be added    * @param readOnly True if you don't want to edit the region data    * @throws IOException if the region creation fails due to a FileSystem exception.    */
specifier|public
specifier|static
name|HRegionFileSystem
name|openRegionFromFileSystem
parameter_list|(
specifier|final
name|Configuration
name|conf
parameter_list|,
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Path
name|tableDir
parameter_list|,
specifier|final
name|RegionInfo
name|regionInfo
parameter_list|,
name|boolean
name|readOnly
parameter_list|)
throws|throws
name|IOException
block|{
name|HRegionFileSystem
name|regionFs
init|=
operator|new
name|HRegionFileSystem
argument_list|(
name|conf
argument_list|,
name|fs
argument_list|,
name|tableDir
argument_list|,
name|regionInfo
argument_list|)
decl_stmt|;
name|Path
name|regionDir
init|=
name|regionFs
operator|.
name|getRegionDir
argument_list|()
decl_stmt|;
if|if
condition|(
operator|!
name|fs
operator|.
name|exists
argument_list|(
name|regionDir
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Trying to open a region that do not exists on disk: "
operator|+
name|regionDir
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|IOException
argument_list|(
literal|"The specified region do not exists on disk: "
operator|+
name|regionDir
argument_list|)
throw|;
block|}
if|if
condition|(
operator|!
name|readOnly
condition|)
block|{
comment|// Cleanup temporary directories
name|regionFs
operator|.
name|cleanupTempDir
argument_list|()
expr_stmt|;
name|regionFs
operator|.
name|cleanupSplitsDir
argument_list|()
expr_stmt|;
name|regionFs
operator|.
name|cleanupMergesDir
argument_list|()
expr_stmt|;
comment|// If it doesn't exists, Write HRI to a file, in case we need to recover hbase:meta
comment|// Only create HRI if we are the default replica
if|if
condition|(
name|regionInfo
operator|.
name|getReplicaId
argument_list|()
operator|==
name|RegionInfo
operator|.
name|DEFAULT_REPLICA_ID
condition|)
block|{
name|regionFs
operator|.
name|checkRegionInfoOnFilesystem
argument_list|()
expr_stmt|;
block|}
else|else
block|{
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Skipping creation of .regioninfo file for "
operator|+
name|regionInfo
argument_list|)
expr_stmt|;
block|}
block|}
block|}
return|return
name|regionFs
return|;
block|}
comment|/**    * Remove the region from the table directory, archiving the region's hfiles.    * @param conf the {@link Configuration} to use    * @param fs {@link FileSystem} from which to remove the region    * @param tableDir {@link Path} to where the table is being stored    * @param regionInfo {@link RegionInfo} for region to be deleted    * @throws IOException if the request cannot be completed    */
specifier|public
specifier|static
name|void
name|deleteRegionFromFileSystem
parameter_list|(
specifier|final
name|Configuration
name|conf
parameter_list|,
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Path
name|tableDir
parameter_list|,
specifier|final
name|RegionInfo
name|regionInfo
parameter_list|)
throws|throws
name|IOException
block|{
name|HRegionFileSystem
name|regionFs
init|=
operator|new
name|HRegionFileSystem
argument_list|(
name|conf
argument_list|,
name|fs
argument_list|,
name|tableDir
argument_list|,
name|regionInfo
argument_list|)
decl_stmt|;
name|Path
name|regionDir
init|=
name|regionFs
operator|.
name|getRegionDir
argument_list|()
decl_stmt|;
if|if
condition|(
operator|!
name|fs
operator|.
name|exists
argument_list|(
name|regionDir
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Trying to delete a region that do not exists on disk: "
operator|+
name|regionDir
argument_list|)
expr_stmt|;
return|return;
block|}
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"DELETING region "
operator|+
name|regionDir
argument_list|)
expr_stmt|;
block|}
comment|// Archive region
name|Path
name|rootDir
init|=
name|FSUtils
operator|.
name|getRootDir
argument_list|(
name|conf
argument_list|)
decl_stmt|;
name|HFileArchiver
operator|.
name|archiveRegion
argument_list|(
name|fs
argument_list|,
name|rootDir
argument_list|,
name|tableDir
argument_list|,
name|regionDir
argument_list|)
expr_stmt|;
comment|// Delete empty region dir
if|if
condition|(
operator|!
name|fs
operator|.
name|delete
argument_list|(
name|regionDir
argument_list|,
literal|true
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failed delete of "
operator|+
name|regionDir
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Creates a directory. Assumes the user has already checked for this directory existence.    * @param dir    * @return the result of fs.mkdirs(). In case underlying fs throws an IOException, it checks    *         whether the directory exists or not, and returns true if it exists.    * @throws IOException    */
name|boolean
name|createDir
parameter_list|(
name|Path
name|dir
parameter_list|)
throws|throws
name|IOException
block|{
name|int
name|i
init|=
literal|0
decl_stmt|;
name|IOException
name|lastIOE
init|=
literal|null
decl_stmt|;
do|do
block|{
try|try
block|{
return|return
name|mkdirs
argument_list|(
name|fs
argument_list|,
name|conf
argument_list|,
name|dir
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ioe
parameter_list|)
block|{
name|lastIOE
operator|=
name|ioe
expr_stmt|;
if|if
condition|(
name|fs
operator|.
name|exists
argument_list|(
name|dir
argument_list|)
condition|)
return|return
literal|true
return|;
comment|// directory is present
try|try
block|{
name|sleepBeforeRetry
argument_list|(
literal|"Create Directory"
argument_list|,
name|i
operator|+
literal|1
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
throw|throw
operator|(
name|InterruptedIOException
operator|)
operator|new
name|InterruptedIOException
argument_list|()
operator|.
name|initCause
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
block|}
do|while
condition|(
operator|++
name|i
operator|<=
name|hdfsClientRetriesNumber
condition|)
do|;
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Exception in createDir"
argument_list|,
name|lastIOE
argument_list|)
throw|;
block|}
comment|/**    * Renames a directory. Assumes the user has already checked for this directory existence.    * @param srcpath    * @param dstPath    * @return true if rename is successful.    * @throws IOException    */
name|boolean
name|rename
parameter_list|(
name|Path
name|srcpath
parameter_list|,
name|Path
name|dstPath
parameter_list|)
throws|throws
name|IOException
block|{
name|IOException
name|lastIOE
init|=
literal|null
decl_stmt|;
name|int
name|i
init|=
literal|0
decl_stmt|;
do|do
block|{
try|try
block|{
return|return
name|fs
operator|.
name|rename
argument_list|(
name|srcpath
argument_list|,
name|dstPath
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ioe
parameter_list|)
block|{
name|lastIOE
operator|=
name|ioe
expr_stmt|;
if|if
condition|(
operator|!
name|fs
operator|.
name|exists
argument_list|(
name|srcpath
argument_list|)
operator|&&
name|fs
operator|.
name|exists
argument_list|(
name|dstPath
argument_list|)
condition|)
return|return
literal|true
return|;
comment|// successful move
comment|// dir is not there, retry after some time.
try|try
block|{
name|sleepBeforeRetry
argument_list|(
literal|"Rename Directory"
argument_list|,
name|i
operator|+
literal|1
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
throw|throw
operator|(
name|InterruptedIOException
operator|)
operator|new
name|InterruptedIOException
argument_list|()
operator|.
name|initCause
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
block|}
do|while
condition|(
operator|++
name|i
operator|<=
name|hdfsClientRetriesNumber
condition|)
do|;
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Exception in rename"
argument_list|,
name|lastIOE
argument_list|)
throw|;
block|}
comment|/**    * Deletes a directory. Assumes the user has already checked for this directory existence.    * @param dir    * @return true if the directory is deleted.    * @throws IOException    */
name|boolean
name|deleteDir
parameter_list|(
name|Path
name|dir
parameter_list|)
throws|throws
name|IOException
block|{
name|IOException
name|lastIOE
init|=
literal|null
decl_stmt|;
name|int
name|i
init|=
literal|0
decl_stmt|;
do|do
block|{
try|try
block|{
return|return
name|fs
operator|.
name|delete
argument_list|(
name|dir
argument_list|,
literal|true
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ioe
parameter_list|)
block|{
name|lastIOE
operator|=
name|ioe
expr_stmt|;
if|if
condition|(
operator|!
name|fs
operator|.
name|exists
argument_list|(
name|dir
argument_list|)
condition|)
return|return
literal|true
return|;
comment|// dir is there, retry deleting after some time.
try|try
block|{
name|sleepBeforeRetry
argument_list|(
literal|"Delete Directory"
argument_list|,
name|i
operator|+
literal|1
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
throw|throw
operator|(
name|InterruptedIOException
operator|)
operator|new
name|InterruptedIOException
argument_list|()
operator|.
name|initCause
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
block|}
do|while
condition|(
operator|++
name|i
operator|<=
name|hdfsClientRetriesNumber
condition|)
do|;
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Exception in DeleteDir"
argument_list|,
name|lastIOE
argument_list|)
throw|;
block|}
comment|/**    * sleeping logic; handles the interrupt exception.    */
specifier|private
name|void
name|sleepBeforeRetry
parameter_list|(
name|String
name|msg
parameter_list|,
name|int
name|sleepMultiplier
parameter_list|)
throws|throws
name|InterruptedException
block|{
name|sleepBeforeRetry
argument_list|(
name|msg
argument_list|,
name|sleepMultiplier
argument_list|,
name|baseSleepBeforeRetries
argument_list|,
name|hdfsClientRetriesNumber
argument_list|)
expr_stmt|;
block|}
comment|/**    * Creates a directory for a filesystem and configuration object. Assumes the user has already    * checked for this directory existence.    * @param fs    * @param conf    * @param dir    * @return the result of fs.mkdirs(). In case underlying fs throws an IOException, it checks    *         whether the directory exists or not, and returns true if it exists.    * @throws IOException    */
specifier|private
specifier|static
name|boolean
name|createDirOnFileSystem
parameter_list|(
name|FileSystem
name|fs
parameter_list|,
name|Configuration
name|conf
parameter_list|,
name|Path
name|dir
parameter_list|)
throws|throws
name|IOException
block|{
name|int
name|i
init|=
literal|0
decl_stmt|;
name|IOException
name|lastIOE
init|=
literal|null
decl_stmt|;
name|int
name|hdfsClientRetriesNumber
init|=
name|conf
operator|.
name|getInt
argument_list|(
literal|"hdfs.client.retries.number"
argument_list|,
name|DEFAULT_HDFS_CLIENT_RETRIES_NUMBER
argument_list|)
decl_stmt|;
name|int
name|baseSleepBeforeRetries
init|=
name|conf
operator|.
name|getInt
argument_list|(
literal|"hdfs.client.sleep.before.retries"
argument_list|,
name|DEFAULT_BASE_SLEEP_BEFORE_RETRIES
argument_list|)
decl_stmt|;
do|do
block|{
try|try
block|{
return|return
name|fs
operator|.
name|mkdirs
argument_list|(
name|dir
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ioe
parameter_list|)
block|{
name|lastIOE
operator|=
name|ioe
expr_stmt|;
if|if
condition|(
name|fs
operator|.
name|exists
argument_list|(
name|dir
argument_list|)
condition|)
return|return
literal|true
return|;
comment|// directory is present
try|try
block|{
name|sleepBeforeRetry
argument_list|(
literal|"Create Directory"
argument_list|,
name|i
operator|+
literal|1
argument_list|,
name|baseSleepBeforeRetries
argument_list|,
name|hdfsClientRetriesNumber
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
throw|throw
operator|(
name|InterruptedIOException
operator|)
operator|new
name|InterruptedIOException
argument_list|()
operator|.
name|initCause
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
block|}
do|while
condition|(
operator|++
name|i
operator|<=
name|hdfsClientRetriesNumber
condition|)
do|;
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Exception in createDir"
argument_list|,
name|lastIOE
argument_list|)
throw|;
block|}
comment|/**    * sleeping logic for static methods; handles the interrupt exception. Keeping a static version    * for this to avoid re-looking for the integer values.    */
specifier|private
specifier|static
name|void
name|sleepBeforeRetry
parameter_list|(
name|String
name|msg
parameter_list|,
name|int
name|sleepMultiplier
parameter_list|,
name|int
name|baseSleepBeforeRetries
parameter_list|,
name|int
name|hdfsClientRetriesNumber
parameter_list|)
throws|throws
name|InterruptedException
block|{
if|if
condition|(
name|sleepMultiplier
operator|>
name|hdfsClientRetriesNumber
condition|)
block|{
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
name|msg
operator|+
literal|", retries exhausted"
argument_list|)
expr_stmt|;
block|}
return|return;
block|}
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
name|msg
operator|+
literal|", sleeping "
operator|+
name|baseSleepBeforeRetries
operator|+
literal|" times "
operator|+
name|sleepMultiplier
argument_list|)
expr_stmt|;
block|}
name|Thread
operator|.
name|sleep
argument_list|(
operator|(
name|long
operator|)
name|baseSleepBeforeRetries
operator|*
name|sleepMultiplier
argument_list|)
expr_stmt|;
block|}
block|}
end_class

end_unit

