begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|backup
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Arrays
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collection
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collections
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|Log
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|LogFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileStatus
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|PathFilter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HRegionInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HTableDescriptor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|HRegion
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|StoreFile
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|Bytes
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|EnvironmentEdgeManager
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|FSUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|HFileArchiveUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|MultipleIOException
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Function
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Preconditions
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|Collections2
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|Lists
import|;
end_import

begin_comment
comment|/**  * Utility class to handle the removal of HFiles (or the respective {@link StoreFile StoreFiles})  * for a HRegion from the {@link FileSystem}. The hfiles will be archived or deleted, depending on  * the state of the system.  */
end_comment

begin_class
specifier|public
class|class
name|HFileArchiver
block|{
specifier|private
specifier|static
specifier|final
name|Log
name|LOG
init|=
name|LogFactory
operator|.
name|getLog
argument_list|(
name|HFileArchiver
operator|.
name|class
argument_list|)
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|String
name|SEPARATOR
init|=
literal|"."
decl_stmt|;
specifier|private
name|HFileArchiver
parameter_list|()
block|{
comment|// hidden ctor since this is just a util
block|}
comment|/**    * Cleans up all the files for a HRegion by archiving the HFiles to the    * archive directory    * @param fs the file system object    * @param info HRegionInfo for region to be deleted    * @throws IOException    */
specifier|public
specifier|static
name|void
name|archiveRegion
parameter_list|(
name|FileSystem
name|fs
parameter_list|,
name|HRegionInfo
name|info
parameter_list|)
throws|throws
name|IOException
block|{
name|Path
name|rootDir
init|=
name|FSUtils
operator|.
name|getRootDir
argument_list|(
name|fs
operator|.
name|getConf
argument_list|()
argument_list|)
decl_stmt|;
name|archiveRegion
argument_list|(
name|fs
argument_list|,
name|rootDir
argument_list|,
name|HTableDescriptor
operator|.
name|getTableDir
argument_list|(
name|rootDir
argument_list|,
name|info
operator|.
name|getTableName
argument_list|()
argument_list|)
argument_list|,
name|HRegion
operator|.
name|getRegionDir
argument_list|(
name|rootDir
argument_list|,
name|info
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|/**    * Remove an entire region from the table directory via archiving the region's hfiles.    * @param fs {@link FileSystem} from which to remove the region    * @param rootdir {@link Path} to the root directory where hbase files are stored (for building    *          the archive path)    * @param tableDir {@link Path} to where the table is being stored (for building the archive path)    * @param regionDir {@link Path} to where a region is being stored (for building the archive path)    * @return<tt>true</tt> if the region was sucessfully deleted.<tt>false</tt> if the filesystem    *         operations could not complete.    * @throws IOException if the request cannot be completed    */
specifier|public
specifier|static
name|boolean
name|archiveRegion
parameter_list|(
name|FileSystem
name|fs
parameter_list|,
name|Path
name|rootdir
parameter_list|,
name|Path
name|tableDir
parameter_list|,
name|Path
name|regionDir
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"ARCHIVING region "
operator|+
name|regionDir
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|// otherwise, we archive the files
comment|// make sure we can archive
if|if
condition|(
name|tableDir
operator|==
literal|null
operator|||
name|regionDir
operator|==
literal|null
condition|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"No archive directory could be found because tabledir ("
operator|+
name|tableDir
operator|+
literal|") or regiondir ("
operator|+
name|regionDir
operator|+
literal|"was null. Deleting files instead."
argument_list|)
expr_stmt|;
name|deleteRegionWithoutArchiving
argument_list|(
name|fs
argument_list|,
name|regionDir
argument_list|)
expr_stmt|;
comment|// we should have archived, but failed to. Doesn't matter if we deleted
comment|// the archived files correctly or not.
return|return
literal|false
return|;
block|}
comment|// make sure the regiondir lives under the tabledir
name|Preconditions
operator|.
name|checkArgument
argument_list|(
name|regionDir
operator|.
name|toString
argument_list|()
operator|.
name|startsWith
argument_list|(
name|tableDir
operator|.
name|toString
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
name|Path
name|regionArchiveDir
init|=
name|HFileArchiveUtil
operator|.
name|getRegionArchiveDir
argument_list|(
name|fs
operator|.
name|getConf
argument_list|()
argument_list|,
name|tableDir
argument_list|,
name|regionDir
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Have an archive directory, preparing to move files"
argument_list|)
expr_stmt|;
name|FileStatusConverter
name|getAsFile
init|=
operator|new
name|FileStatusConverter
argument_list|(
name|fs
argument_list|)
decl_stmt|;
comment|// otherwise, we attempt to archive the store files
comment|// build collection of just the store directories to archive
name|Collection
argument_list|<
name|File
argument_list|>
name|toArchive
init|=
operator|new
name|ArrayList
argument_list|<
name|File
argument_list|>
argument_list|()
decl_stmt|;
specifier|final
name|PathFilter
name|dirFilter
init|=
operator|new
name|FSUtils
operator|.
name|DirFilter
argument_list|(
name|fs
argument_list|)
decl_stmt|;
name|PathFilter
name|nonHidden
init|=
operator|new
name|PathFilter
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|boolean
name|accept
parameter_list|(
name|Path
name|file
parameter_list|)
block|{
return|return
name|dirFilter
operator|.
name|accept
argument_list|(
name|file
argument_list|)
operator|&&
operator|!
name|file
operator|.
name|getName
argument_list|()
operator|.
name|toString
argument_list|()
operator|.
name|startsWith
argument_list|(
literal|"."
argument_list|)
return|;
block|}
block|}
decl_stmt|;
name|FileStatus
index|[]
name|storeDirs
init|=
name|FSUtils
operator|.
name|listStatus
argument_list|(
name|fs
argument_list|,
name|regionDir
argument_list|,
name|nonHidden
argument_list|)
decl_stmt|;
comment|// if there no files, we can just delete the directory and return;
if|if
condition|(
name|storeDirs
operator|==
literal|null
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Region directory ("
operator|+
name|regionDir
operator|+
literal|") was empty, just deleting and returning!"
argument_list|)
expr_stmt|;
return|return
name|deleteRegionWithoutArchiving
argument_list|(
name|fs
argument_list|,
name|regionDir
argument_list|)
return|;
block|}
comment|// convert the files in the region to a File
name|toArchive
operator|.
name|addAll
argument_list|(
name|Lists
operator|.
name|transform
argument_list|(
name|Arrays
operator|.
name|asList
argument_list|(
name|storeDirs
argument_list|)
argument_list|,
name|getAsFile
argument_list|)
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Archiving:"
operator|+
name|toArchive
argument_list|)
expr_stmt|;
name|boolean
name|success
init|=
literal|false
decl_stmt|;
try|try
block|{
name|success
operator|=
name|resolveAndArchive
argument_list|(
name|fs
argument_list|,
name|regionArchiveDir
argument_list|,
name|toArchive
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|success
operator|=
literal|false
expr_stmt|;
block|}
comment|// if that was successful, then we delete the region
if|if
condition|(
name|success
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Successfully resolved and archived, now can just delete region."
argument_list|)
expr_stmt|;
return|return
name|deleteRegionWithoutArchiving
argument_list|(
name|fs
argument_list|,
name|regionDir
argument_list|)
return|;
block|}
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Received error when attempting to archive files ("
operator|+
name|toArchive
operator|+
literal|"), cannot delete region directory."
argument_list|)
throw|;
block|}
comment|/**    * Remove from the specified region the store files of the specified column family,    * either by archiving them or outright deletion    * @param fs the filesystem where the store files live    * @param conf {@link Configuration} to examine to determine the archive directory    * @param parent Parent region hosting the store files    * @param tableDir {@link Path} to where the table is being stored (for building the archive path)    * @param family the family hosting the store files    * @throws IOException if the files could not be correctly disposed.    */
specifier|public
specifier|static
name|void
name|archiveFamily
parameter_list|(
name|FileSystem
name|fs
parameter_list|,
name|Configuration
name|conf
parameter_list|,
name|HRegionInfo
name|parent
parameter_list|,
name|Path
name|tableDir
parameter_list|,
name|byte
index|[]
name|family
parameter_list|)
throws|throws
name|IOException
block|{
name|Path
name|familyDir
init|=
operator|new
name|Path
argument_list|(
name|tableDir
argument_list|,
operator|new
name|Path
argument_list|(
name|parent
operator|.
name|getEncodedName
argument_list|()
argument_list|,
name|Bytes
operator|.
name|toString
argument_list|(
name|family
argument_list|)
argument_list|)
argument_list|)
decl_stmt|;
name|FileStatus
index|[]
name|storeFiles
init|=
name|FSUtils
operator|.
name|listStatus
argument_list|(
name|fs
argument_list|,
name|familyDir
argument_list|)
decl_stmt|;
if|if
condition|(
name|storeFiles
operator|==
literal|null
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"No store files to dispose for region="
operator|+
name|parent
operator|.
name|getRegionNameAsString
argument_list|()
operator|+
literal|", family="
operator|+
name|Bytes
operator|.
name|toString
argument_list|(
name|family
argument_list|)
argument_list|)
expr_stmt|;
return|return;
block|}
name|FileStatusConverter
name|getAsFile
init|=
operator|new
name|FileStatusConverter
argument_list|(
name|fs
argument_list|)
decl_stmt|;
name|Collection
argument_list|<
name|File
argument_list|>
name|toArchive
init|=
name|Lists
operator|.
name|transform
argument_list|(
name|Arrays
operator|.
name|asList
argument_list|(
name|storeFiles
argument_list|)
argument_list|,
name|getAsFile
argument_list|)
decl_stmt|;
name|Path
name|storeArchiveDir
init|=
name|HFileArchiveUtil
operator|.
name|getStoreArchivePath
argument_list|(
name|conf
argument_list|,
name|parent
argument_list|,
name|tableDir
argument_list|,
name|family
argument_list|)
decl_stmt|;
comment|// do the actual archive
if|if
condition|(
operator|!
name|resolveAndArchive
argument_list|(
name|fs
argument_list|,
name|storeArchiveDir
argument_list|,
name|toArchive
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Failed to archive/delete all the files for region:"
operator|+
name|Bytes
operator|.
name|toString
argument_list|(
name|parent
operator|.
name|getRegionName
argument_list|()
argument_list|)
operator|+
literal|", family:"
operator|+
name|Bytes
operator|.
name|toString
argument_list|(
name|family
argument_list|)
operator|+
literal|" into "
operator|+
name|storeArchiveDir
operator|+
literal|". Something is probably awry on the filesystem."
argument_list|)
throw|;
block|}
block|}
comment|/**    * Remove the store files, either by archiving them or outright deletion    * @param fs the filesystem where the store files live    * @param parent Parent region hosting the store files    * @param conf {@link Configuration} to examine to determine the archive directory    * @param family the family hosting the store files    * @param compactedFiles files to be disposed of. No further reading of these files should be    *          attempted; otherwise likely to cause an {@link IOException}    * @throws IOException if the files could not be correctly disposed.    */
specifier|public
specifier|static
name|void
name|archiveStoreFiles
parameter_list|(
name|FileSystem
name|fs
parameter_list|,
name|HRegion
name|parent
parameter_list|,
name|Configuration
name|conf
parameter_list|,
name|byte
index|[]
name|family
parameter_list|,
name|Collection
argument_list|<
name|StoreFile
argument_list|>
name|compactedFiles
parameter_list|)
throws|throws
name|IOException
block|{
comment|// sometimes in testing, we don't have rss, so we need to check for that
if|if
condition|(
name|fs
operator|==
literal|null
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Passed filesystem is null, so just deleting the files without archiving for region:"
operator|+
name|Bytes
operator|.
name|toString
argument_list|(
name|parent
operator|.
name|getRegionName
argument_list|()
argument_list|)
operator|+
literal|", family:"
operator|+
name|Bytes
operator|.
name|toString
argument_list|(
name|family
argument_list|)
argument_list|)
expr_stmt|;
name|deleteStoreFilesWithoutArchiving
argument_list|(
name|compactedFiles
argument_list|)
expr_stmt|;
return|return;
block|}
comment|// short circuit if we don't have any files to delete
if|if
condition|(
name|compactedFiles
operator|.
name|size
argument_list|()
operator|==
literal|0
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"No store files to dispose, done!"
argument_list|)
expr_stmt|;
return|return;
block|}
comment|// build the archive path
if|if
condition|(
name|parent
operator|==
literal|null
operator|||
name|family
operator|==
literal|null
condition|)
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Need to have a parent region and a family to archive from."
argument_list|)
throw|;
name|Path
name|storeArchiveDir
init|=
name|HFileArchiveUtil
operator|.
name|getStoreArchivePath
argument_list|(
name|conf
argument_list|,
name|parent
argument_list|,
name|family
argument_list|)
decl_stmt|;
comment|// make sure we don't archive if we can't and that the archive dir exists
if|if
condition|(
operator|!
name|fs
operator|.
name|mkdirs
argument_list|(
name|storeArchiveDir
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Could not make archive directory ("
operator|+
name|storeArchiveDir
operator|+
literal|") for store:"
operator|+
name|Bytes
operator|.
name|toString
argument_list|(
name|family
argument_list|)
operator|+
literal|", deleting compacted files instead."
argument_list|)
throw|;
block|}
comment|// otherwise we attempt to archive the store files
name|LOG
operator|.
name|debug
argument_list|(
literal|"Archiving compacted store files."
argument_list|)
expr_stmt|;
comment|// wrap the storefile into a File
name|StoreToFile
name|getStorePath
init|=
operator|new
name|StoreToFile
argument_list|(
name|fs
argument_list|)
decl_stmt|;
name|Collection
argument_list|<
name|File
argument_list|>
name|storeFiles
init|=
name|Collections2
operator|.
name|transform
argument_list|(
name|compactedFiles
argument_list|,
name|getStorePath
argument_list|)
decl_stmt|;
comment|// do the actual archive
if|if
condition|(
operator|!
name|resolveAndArchive
argument_list|(
name|fs
argument_list|,
name|storeArchiveDir
argument_list|,
name|storeFiles
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Failed to archive/delete all the files for region:"
operator|+
name|Bytes
operator|.
name|toString
argument_list|(
name|parent
operator|.
name|getRegionName
argument_list|()
argument_list|)
operator|+
literal|", family:"
operator|+
name|Bytes
operator|.
name|toString
argument_list|(
name|family
argument_list|)
operator|+
literal|" into "
operator|+
name|storeArchiveDir
operator|+
literal|". Something is probably awry on the filesystem."
argument_list|)
throw|;
block|}
block|}
comment|/**    * Archive the store file    * @param fs the filesystem where the store files live    * @param regionInfo region hosting the store files    * @param conf {@link Configuration} to examine to determine the archive directory    * @param tableDir {@link Path} to where the table is being stored (for building the archive path)    * @param family the family hosting the store files    * @param storeFile file to be archived    * @throws IOException if the files could not be correctly disposed.    */
specifier|public
specifier|static
name|void
name|archiveStoreFile
parameter_list|(
name|FileSystem
name|fs
parameter_list|,
name|HRegionInfo
name|regionInfo
parameter_list|,
name|Configuration
name|conf
parameter_list|,
name|Path
name|tableDir
parameter_list|,
name|byte
index|[]
name|family
parameter_list|,
name|Path
name|storeFile
parameter_list|)
throws|throws
name|IOException
block|{
name|Path
name|storeArchiveDir
init|=
name|HFileArchiveUtil
operator|.
name|getStoreArchivePath
argument_list|(
name|conf
argument_list|,
name|regionInfo
argument_list|,
name|tableDir
argument_list|,
name|family
argument_list|)
decl_stmt|;
comment|// make sure we don't archive if we can't and that the archive dir exists
if|if
condition|(
operator|!
name|fs
operator|.
name|mkdirs
argument_list|(
name|storeArchiveDir
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Could not make archive directory ("
operator|+
name|storeArchiveDir
operator|+
literal|") for store:"
operator|+
name|Bytes
operator|.
name|toString
argument_list|(
name|family
argument_list|)
operator|+
literal|", deleting compacted files instead."
argument_list|)
throw|;
block|}
name|fs
operator|.
name|rename
argument_list|(
name|storeFile
argument_list|,
operator|new
name|Path
argument_list|(
name|storeArchiveDir
argument_list|,
name|storeFile
operator|.
name|getName
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|/**    * Archive the given files and resolve any conflicts with existing files via appending the time    * archiving started (so all conflicts in the same group have the same timestamp appended).    *<p>    * If any of the passed files to archive are directories, archives all the files under that    * directory. Archive directory structure for children is the base archive directory name + the    * parent directory and is built recursively is passed files are directories themselves.    * @param fs {@link FileSystem} on which to archive the files    * @param baseArchiveDir base archive directory to archive the given files    * @param toArchive files to be archived    * @return<tt>true</tt> on success,<tt>false</tt> otherwise    * @throws IOException on unexpected failure    */
specifier|private
specifier|static
name|boolean
name|resolveAndArchive
parameter_list|(
name|FileSystem
name|fs
parameter_list|,
name|Path
name|baseArchiveDir
parameter_list|,
name|Collection
argument_list|<
name|File
argument_list|>
name|toArchive
parameter_list|)
throws|throws
name|IOException
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Starting to archive files:"
operator|+
name|toArchive
argument_list|)
expr_stmt|;
name|long
name|start
init|=
name|EnvironmentEdgeManager
operator|.
name|currentTimeMillis
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|File
argument_list|>
name|failures
init|=
name|resolveAndArchive
argument_list|(
name|fs
argument_list|,
name|baseArchiveDir
argument_list|,
name|toArchive
argument_list|,
name|start
argument_list|)
decl_stmt|;
comment|// clean out the failures by just deleting them
if|if
condition|(
name|failures
operator|.
name|size
argument_list|()
operator|>
literal|0
condition|)
block|{
try|try
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Failed to complete archive, deleting extra store files."
argument_list|)
expr_stmt|;
name|deleteFilesWithoutArchiving
argument_list|(
name|failures
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failed to delete store file(s) when archiving failed"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
return|return
literal|false
return|;
block|}
return|return
literal|true
return|;
block|}
comment|/**    * Resolve any conflict with an existing archive file via timestamp-append    * renaming of the existing file and then archive the passed in files.    * @param fs {@link FileSystem} on which to archive the files    * @param baseArchiveDir base archive directory to store the files. If any of    *          the files to archive are directories, will append the name of the    *          directory to the base archive directory name, creating a parallel    *          structure.    * @param toArchive files/directories that need to be archvied    * @param start time the archiving started - used for resolving archive    *          conflicts.    * @return the list of failed to archive files.    * @throws IOException if an unexpected file operation exception occured    */
specifier|private
specifier|static
name|List
argument_list|<
name|File
argument_list|>
name|resolveAndArchive
parameter_list|(
name|FileSystem
name|fs
parameter_list|,
name|Path
name|baseArchiveDir
parameter_list|,
name|Collection
argument_list|<
name|File
argument_list|>
name|toArchive
parameter_list|,
name|long
name|start
parameter_list|)
throws|throws
name|IOException
block|{
comment|// short circuit if no files to move
if|if
condition|(
name|toArchive
operator|.
name|size
argument_list|()
operator|==
literal|0
condition|)
return|return
name|Collections
operator|.
name|emptyList
argument_list|()
return|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"moving files to the archive directory: "
operator|+
name|baseArchiveDir
argument_list|)
expr_stmt|;
comment|// make sure the archive directory exists
if|if
condition|(
operator|!
name|fs
operator|.
name|exists
argument_list|(
name|baseArchiveDir
argument_list|)
condition|)
block|{
if|if
condition|(
operator|!
name|fs
operator|.
name|mkdirs
argument_list|(
name|baseArchiveDir
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Failed to create the archive directory:"
operator|+
name|baseArchiveDir
operator|+
literal|", quitting archive attempt."
argument_list|)
throw|;
block|}
name|LOG
operator|.
name|debug
argument_list|(
literal|"Created archive directory:"
operator|+
name|baseArchiveDir
argument_list|)
expr_stmt|;
block|}
name|List
argument_list|<
name|File
argument_list|>
name|failures
init|=
operator|new
name|ArrayList
argument_list|<
name|File
argument_list|>
argument_list|()
decl_stmt|;
name|String
name|startTime
init|=
name|Long
operator|.
name|toString
argument_list|(
name|start
argument_list|)
decl_stmt|;
for|for
control|(
name|File
name|file
range|:
name|toArchive
control|)
block|{
comment|// if its a file archive it
try|try
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Archiving:"
operator|+
name|file
argument_list|)
expr_stmt|;
if|if
condition|(
name|file
operator|.
name|isFile
argument_list|()
condition|)
block|{
comment|// attempt to archive the file
if|if
condition|(
operator|!
name|resolveAndArchiveFile
argument_list|(
name|baseArchiveDir
argument_list|,
name|file
argument_list|,
name|startTime
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Couldn't archive "
operator|+
name|file
operator|+
literal|" into backup directory: "
operator|+
name|baseArchiveDir
argument_list|)
expr_stmt|;
name|failures
operator|.
name|add
argument_list|(
name|file
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
comment|// otherwise its a directory and we need to archive all files
name|LOG
operator|.
name|debug
argument_list|(
name|file
operator|+
literal|" is a directory, archiving children files"
argument_list|)
expr_stmt|;
comment|// so we add the directory name to the one base archive
name|Path
name|parentArchiveDir
init|=
operator|new
name|Path
argument_list|(
name|baseArchiveDir
argument_list|,
name|file
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
comment|// and then get all the files from that directory and attempt to
comment|// archive those too
name|Collection
argument_list|<
name|File
argument_list|>
name|children
init|=
name|file
operator|.
name|getChildren
argument_list|()
decl_stmt|;
name|failures
operator|.
name|addAll
argument_list|(
name|resolveAndArchive
argument_list|(
name|fs
argument_list|,
name|parentArchiveDir
argument_list|,
name|children
argument_list|,
name|start
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failed to archive file: "
operator|+
name|file
argument_list|,
name|e
argument_list|)
expr_stmt|;
name|failures
operator|.
name|add
argument_list|(
name|file
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|failures
return|;
block|}
comment|/**    * Attempt to archive the passed in file to the archive directory.    *<p>    * If the same file already exists in the archive, it is moved to a timestamped directory under    * the archive directory and the new file is put in its place.    * @param archiveDir {@link Path} to the directory that stores the archives of the hfiles    * @param currentFile {@link Path} to the original HFile that will be archived    * @param archiveStartTime time the archiving started, to resolve naming conflicts    * @return<tt>true</tt> if the file is successfully archived.<tt>false</tt> if there was a    *         problem, but the operation still completed.    * @throws IOException on failure to complete {@link FileSystem} operations.    */
specifier|private
specifier|static
name|boolean
name|resolveAndArchiveFile
parameter_list|(
name|Path
name|archiveDir
parameter_list|,
name|File
name|currentFile
parameter_list|,
name|String
name|archiveStartTime
parameter_list|)
throws|throws
name|IOException
block|{
comment|// build path as it should be in the archive
name|String
name|filename
init|=
name|currentFile
operator|.
name|getName
argument_list|()
decl_stmt|;
name|Path
name|archiveFile
init|=
operator|new
name|Path
argument_list|(
name|archiveDir
argument_list|,
name|filename
argument_list|)
decl_stmt|;
name|FileSystem
name|fs
init|=
name|currentFile
operator|.
name|getFileSystem
argument_list|()
decl_stmt|;
comment|// if the file already exists in the archive, move that one to a timestamped backup. This is a
comment|// really, really unlikely situtation, where we get the same name for the existing file, but
comment|// is included just for that 1 in trillion chance.
if|if
condition|(
name|fs
operator|.
name|exists
argument_list|(
name|archiveFile
argument_list|)
condition|)
block|{
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"File:"
operator|+
name|archiveFile
operator|+
literal|" already exists in archive, moving to "
operator|+
literal|"timestamped backup and overwriting current."
argument_list|)
expr_stmt|;
block|}
comment|// move the archive file to the stamped backup
name|Path
name|backedupArchiveFile
init|=
operator|new
name|Path
argument_list|(
name|archiveDir
argument_list|,
name|filename
operator|+
name|SEPARATOR
operator|+
name|archiveStartTime
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|fs
operator|.
name|rename
argument_list|(
name|archiveFile
argument_list|,
name|backedupArchiveFile
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Could not rename archive file to backup: "
operator|+
name|backedupArchiveFile
operator|+
literal|", deleting existing file in favor of newer."
argument_list|)
expr_stmt|;
comment|// try to delete the exisiting file, if we can't rename it
if|if
condition|(
operator|!
name|fs
operator|.
name|delete
argument_list|(
name|archiveFile
argument_list|,
literal|false
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Couldn't delete existing archive file ("
operator|+
name|archiveFile
operator|+
literal|") or rename it to the backup file ("
operator|+
name|backedupArchiveFile
operator|+
literal|")to make room for similarly named file."
argument_list|)
throw|;
block|}
block|}
name|LOG
operator|.
name|debug
argument_list|(
literal|"Backed up archive file from: "
operator|+
name|archiveFile
argument_list|)
expr_stmt|;
block|}
name|LOG
operator|.
name|debug
argument_list|(
literal|"No existing file in archive for:"
operator|+
name|archiveFile
operator|+
literal|", free to archive original file."
argument_list|)
expr_stmt|;
comment|// at this point, we should have a free spot for the archive file
if|if
condition|(
name|currentFile
operator|.
name|moveAndClose
argument_list|(
name|archiveFile
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Failed to archive file:"
operator|+
name|currentFile
argument_list|)
expr_stmt|;
return|return
literal|false
return|;
block|}
elseif|else
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Finished archiving file from: "
operator|+
name|currentFile
operator|+
literal|", to: "
operator|+
name|archiveFile
argument_list|)
expr_stmt|;
block|}
return|return
literal|true
return|;
block|}
comment|/**    * Simple delete of regular files from the {@link FileSystem}.    *<p>    * This method is a more generic implementation that the other deleteXXX    * methods in this class, allowing more code reuse at the cost of a couple    * more, short-lived objects (which should have minimum impact on the jvm).    * @param fs {@link FileSystem} where the files live    * @param files {@link Collection} of files to be deleted    * @throws IOException if a file cannot be deleted. All files will be    *           attempted to deleted before throwing the exception, rather than    *           failing at the first file.    */
specifier|private
specifier|static
name|void
name|deleteFilesWithoutArchiving
parameter_list|(
name|Collection
argument_list|<
name|File
argument_list|>
name|files
parameter_list|)
throws|throws
name|IOException
block|{
name|List
argument_list|<
name|IOException
argument_list|>
name|errors
init|=
operator|new
name|ArrayList
argument_list|<
name|IOException
argument_list|>
argument_list|(
literal|0
argument_list|)
decl_stmt|;
for|for
control|(
name|File
name|file
range|:
name|files
control|)
block|{
try|try
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Deleting region file:"
operator|+
name|file
argument_list|)
expr_stmt|;
name|file
operator|.
name|delete
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Failed to delete file:"
operator|+
name|file
argument_list|)
expr_stmt|;
name|errors
operator|.
name|add
argument_list|(
name|e
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|errors
operator|.
name|size
argument_list|()
operator|>
literal|0
condition|)
block|{
throw|throw
name|MultipleIOException
operator|.
name|createIOException
argument_list|(
name|errors
argument_list|)
throw|;
block|}
block|}
comment|/**    * Without regard for backup, delete a region. Should be used with caution.    * @param regionDir {@link Path} to the region to be deleted.    * @param fs FileSystem from which to delete the region    * @return<tt>true</tt> on successful deletion,<tt>false</tt> otherwise    * @throws IOException on filesystem operation failure    */
specifier|private
specifier|static
name|boolean
name|deleteRegionWithoutArchiving
parameter_list|(
name|FileSystem
name|fs
parameter_list|,
name|Path
name|regionDir
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|fs
operator|.
name|delete
argument_list|(
name|regionDir
argument_list|,
literal|true
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Deleted all region files in: "
operator|+
name|regionDir
argument_list|)
expr_stmt|;
return|return
literal|true
return|;
block|}
name|LOG
operator|.
name|debug
argument_list|(
literal|"Failed to delete region directory:"
operator|+
name|regionDir
argument_list|)
expr_stmt|;
return|return
literal|false
return|;
block|}
comment|/**    * Just do a simple delete of the given store files    *<p>    * A best effort is made to delete each of the files, rather than bailing on the first failure.    *<p>    * This method is preferable to {@link #deleteFilesWithoutArchiving(Collection)} since it consumes    * less resources, but is limited in terms of usefulness    * @param compactedFiles store files to delete from the file system.    * @throws IOException if a file cannot be deleted. All files will be attempted to deleted before    *           throwing the exception, rather than failing at the first file.    */
specifier|private
specifier|static
name|void
name|deleteStoreFilesWithoutArchiving
parameter_list|(
name|Collection
argument_list|<
name|StoreFile
argument_list|>
name|compactedFiles
parameter_list|)
throws|throws
name|IOException
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Deleting store files without archiving."
argument_list|)
expr_stmt|;
name|List
argument_list|<
name|IOException
argument_list|>
name|errors
init|=
operator|new
name|ArrayList
argument_list|<
name|IOException
argument_list|>
argument_list|(
literal|0
argument_list|)
decl_stmt|;
for|for
control|(
name|StoreFile
name|hsf
range|:
name|compactedFiles
control|)
block|{
try|try
block|{
name|hsf
operator|.
name|deleteReader
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Failed to delete store file:"
operator|+
name|hsf
operator|.
name|getPath
argument_list|()
argument_list|)
expr_stmt|;
name|errors
operator|.
name|add
argument_list|(
name|e
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|errors
operator|.
name|size
argument_list|()
operator|>
literal|0
condition|)
block|{
throw|throw
name|MultipleIOException
operator|.
name|createIOException
argument_list|(
name|errors
argument_list|)
throw|;
block|}
block|}
comment|/**    * Adapt a type to match the {@link File} interface, which is used internally for handling    * archival/removal of files    * @param<T> type to adapt to the {@link File} interface    */
specifier|private
specifier|static
specifier|abstract
class|class
name|FileConverter
parameter_list|<
name|T
parameter_list|>
implements|implements
name|Function
argument_list|<
name|T
argument_list|,
name|File
argument_list|>
block|{
specifier|protected
specifier|final
name|FileSystem
name|fs
decl_stmt|;
specifier|public
name|FileConverter
parameter_list|(
name|FileSystem
name|fs
parameter_list|)
block|{
name|this
operator|.
name|fs
operator|=
name|fs
expr_stmt|;
block|}
block|}
comment|/**    * Convert a FileStatus to something we can manage in the archiving    */
specifier|private
specifier|static
class|class
name|FileStatusConverter
extends|extends
name|FileConverter
argument_list|<
name|FileStatus
argument_list|>
block|{
specifier|public
name|FileStatusConverter
parameter_list|(
name|FileSystem
name|fs
parameter_list|)
block|{
name|super
argument_list|(
name|fs
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|File
name|apply
parameter_list|(
name|FileStatus
name|input
parameter_list|)
block|{
return|return
operator|new
name|FileablePath
argument_list|(
name|fs
argument_list|,
name|input
operator|.
name|getPath
argument_list|()
argument_list|)
return|;
block|}
block|}
comment|/**    * Convert the {@link StoreFile} into something we can manage in the archive    * methods    */
specifier|private
specifier|static
class|class
name|StoreToFile
extends|extends
name|FileConverter
argument_list|<
name|StoreFile
argument_list|>
block|{
specifier|public
name|StoreToFile
parameter_list|(
name|FileSystem
name|fs
parameter_list|)
block|{
name|super
argument_list|(
name|fs
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|File
name|apply
parameter_list|(
name|StoreFile
name|input
parameter_list|)
block|{
return|return
operator|new
name|FileableStoreFile
argument_list|(
name|fs
argument_list|,
name|input
argument_list|)
return|;
block|}
block|}
comment|/**    * Wrapper to handle file operations uniformly    */
specifier|private
specifier|static
specifier|abstract
class|class
name|File
block|{
specifier|protected
specifier|final
name|FileSystem
name|fs
decl_stmt|;
specifier|public
name|File
parameter_list|(
name|FileSystem
name|fs
parameter_list|)
block|{
name|this
operator|.
name|fs
operator|=
name|fs
expr_stmt|;
block|}
comment|/**      * Delete the file      * @throws IOException on failure      */
specifier|abstract
name|void
name|delete
parameter_list|()
throws|throws
name|IOException
function_decl|;
comment|/**      * Check to see if this is a file or a directory      * @return<tt>true</tt> if it is a file,<tt>false</tt> otherwise      * @throws IOException on {@link FileSystem} connection error      */
specifier|abstract
name|boolean
name|isFile
parameter_list|()
throws|throws
name|IOException
function_decl|;
comment|/**      * @return if this is a directory, returns all the children in the      *         directory, otherwise returns an empty list      * @throws IOException      */
specifier|abstract
name|Collection
argument_list|<
name|File
argument_list|>
name|getChildren
parameter_list|()
throws|throws
name|IOException
function_decl|;
comment|/**      * close any outside readers of the file      * @throws IOException      */
specifier|abstract
name|void
name|close
parameter_list|()
throws|throws
name|IOException
function_decl|;
comment|/**      * @return the name of the file (not the full fs path, just the individual      *         file name)      */
specifier|abstract
name|String
name|getName
parameter_list|()
function_decl|;
comment|/**      * @return the path to this file      */
specifier|abstract
name|Path
name|getPath
parameter_list|()
function_decl|;
comment|/**      * Move the file to the given destination      * @param dest      * @return<tt>true</tt> on success      * @throws IOException      */
specifier|public
name|boolean
name|moveAndClose
parameter_list|(
name|Path
name|dest
parameter_list|)
throws|throws
name|IOException
block|{
name|this
operator|.
name|close
argument_list|()
expr_stmt|;
name|Path
name|p
init|=
name|this
operator|.
name|getPath
argument_list|()
decl_stmt|;
return|return
operator|!
name|fs
operator|.
name|rename
argument_list|(
name|p
argument_list|,
name|dest
argument_list|)
return|;
block|}
comment|/**      * @return the {@link FileSystem} on which this file resides      */
specifier|public
name|FileSystem
name|getFileSystem
parameter_list|()
block|{
return|return
name|this
operator|.
name|fs
return|;
block|}
annotation|@
name|Override
specifier|public
name|String
name|toString
parameter_list|()
block|{
return|return
name|this
operator|.
name|getClass
argument_list|()
operator|+
literal|", file:"
operator|+
name|getPath
argument_list|()
operator|.
name|toString
argument_list|()
return|;
block|}
block|}
comment|/**    * A {@link File} that wraps a simple {@link Path} on a {@link FileSystem}.    */
specifier|private
specifier|static
class|class
name|FileablePath
extends|extends
name|File
block|{
specifier|private
specifier|final
name|Path
name|file
decl_stmt|;
specifier|private
specifier|final
name|FileStatusConverter
name|getAsFile
decl_stmt|;
specifier|public
name|FileablePath
parameter_list|(
name|FileSystem
name|fs
parameter_list|,
name|Path
name|file
parameter_list|)
block|{
name|super
argument_list|(
name|fs
argument_list|)
expr_stmt|;
name|this
operator|.
name|file
operator|=
name|file
expr_stmt|;
name|this
operator|.
name|getAsFile
operator|=
operator|new
name|FileStatusConverter
argument_list|(
name|fs
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|delete
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
operator|!
name|fs
operator|.
name|delete
argument_list|(
name|file
argument_list|,
literal|true
argument_list|)
condition|)
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Failed to delete:"
operator|+
name|this
operator|.
name|file
argument_list|)
throw|;
block|}
annotation|@
name|Override
specifier|public
name|String
name|getName
parameter_list|()
block|{
return|return
name|file
operator|.
name|getName
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|Collection
argument_list|<
name|File
argument_list|>
name|getChildren
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|fs
operator|.
name|isFile
argument_list|(
name|file
argument_list|)
condition|)
return|return
name|Collections
operator|.
name|emptyList
argument_list|()
return|;
return|return
name|Collections2
operator|.
name|transform
argument_list|(
name|Arrays
operator|.
name|asList
argument_list|(
name|fs
operator|.
name|listStatus
argument_list|(
name|file
argument_list|)
argument_list|)
argument_list|,
name|getAsFile
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|isFile
parameter_list|()
throws|throws
name|IOException
block|{
return|return
name|fs
operator|.
name|isFile
argument_list|(
name|file
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|close
parameter_list|()
throws|throws
name|IOException
block|{
comment|// NOOP - files are implicitly closed on removal
block|}
annotation|@
name|Override
name|Path
name|getPath
parameter_list|()
block|{
return|return
name|file
return|;
block|}
block|}
comment|/**    * {@link File} adapter for a {@link StoreFile} living on a {@link FileSystem}    * .    */
specifier|private
specifier|static
class|class
name|FileableStoreFile
extends|extends
name|File
block|{
name|StoreFile
name|file
decl_stmt|;
specifier|public
name|FileableStoreFile
parameter_list|(
name|FileSystem
name|fs
parameter_list|,
name|StoreFile
name|store
parameter_list|)
block|{
name|super
argument_list|(
name|fs
argument_list|)
expr_stmt|;
name|this
operator|.
name|file
operator|=
name|store
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|delete
parameter_list|()
throws|throws
name|IOException
block|{
name|file
operator|.
name|deleteReader
argument_list|()
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|String
name|getName
parameter_list|()
block|{
return|return
name|file
operator|.
name|getPath
argument_list|()
operator|.
name|getName
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|isFile
parameter_list|()
block|{
return|return
literal|true
return|;
block|}
annotation|@
name|Override
specifier|public
name|Collection
argument_list|<
name|File
argument_list|>
name|getChildren
parameter_list|()
throws|throws
name|IOException
block|{
comment|// storefiles don't have children
return|return
name|Collections
operator|.
name|emptyList
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|close
parameter_list|()
throws|throws
name|IOException
block|{
name|file
operator|.
name|closeReader
argument_list|(
literal|true
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
name|Path
name|getPath
parameter_list|()
block|{
return|return
name|file
operator|.
name|getPath
argument_list|()
return|;
block|}
block|}
block|}
end_class

end_unit

