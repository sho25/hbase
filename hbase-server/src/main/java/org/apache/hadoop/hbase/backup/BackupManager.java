begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|backup
package|;
end_package

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ThreadFactoryBuilder
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Set
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|CancellationException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ExecutionException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ExecutorService
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|Future
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|LinkedBlockingQueue
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ThreadPoolExecutor
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|TimeUnit
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|Log
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|LogFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HConstants
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HTableDescriptor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|backup
operator|.
name|BackupHandler
operator|.
name|BACKUPSTATUS
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|backup
operator|.
name|BackupManifest
operator|.
name|BackupImage
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|backup
operator|.
name|BackupUtil
operator|.
name|BackupCompleteData
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|backup
operator|.
name|master
operator|.
name|BackupLogCleaner
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|classification
operator|.
name|InterfaceAudience
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|classification
operator|.
name|InterfaceStability
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|Connection
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|ConnectionFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|HBaseAdmin
import|;
end_import

begin_comment
comment|/**  * Handles backup requests on server-side, creates backup context records in hbase:backup   * to keep track backup. The timestamps kept in hbase:backup table will be used for future   * incremental backup. Creates BackupContext and DispatchRequest.  *  */
end_comment

begin_class
annotation|@
name|InterfaceAudience
operator|.
name|Private
annotation|@
name|InterfaceStability
operator|.
name|Evolving
specifier|public
class|class
name|BackupManager
block|{
specifier|private
specifier|static
specifier|final
name|Log
name|LOG
init|=
name|LogFactory
operator|.
name|getLog
argument_list|(
name|BackupManager
operator|.
name|class
argument_list|)
decl_stmt|;
specifier|private
name|Configuration
name|conf
init|=
literal|null
decl_stmt|;
specifier|private
name|BackupContext
name|backupContext
init|=
literal|null
decl_stmt|;
specifier|private
name|ExecutorService
name|pool
init|=
literal|null
decl_stmt|;
specifier|private
name|boolean
name|backupComplete
init|=
literal|false
decl_stmt|;
specifier|private
name|BackupSystemTable
name|systemTable
decl_stmt|;
comment|/**    * Backup manager constructor.    * @param conf configuration    * @throws IOException exception    */
specifier|public
name|BackupManager
parameter_list|(
name|Configuration
name|conf
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
operator|!
name|conf
operator|.
name|getBoolean
argument_list|(
name|HConstants
operator|.
name|BACKUP_ENABLE_KEY
argument_list|,
name|HConstants
operator|.
name|BACKUP_ENABLE_DEFAULT
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|BackupException
argument_list|(
literal|"HBase backup is not enabled. Check your "
operator|+
name|HConstants
operator|.
name|BACKUP_ENABLE_KEY
operator|+
literal|" setting."
argument_list|)
throw|;
block|}
name|this
operator|.
name|conf
operator|=
name|conf
expr_stmt|;
name|this
operator|.
name|systemTable
operator|=
name|BackupSystemTable
operator|.
name|getTable
argument_list|(
name|conf
argument_list|)
expr_stmt|;
name|Runtime
operator|.
name|getRuntime
argument_list|()
operator|.
name|addShutdownHook
argument_list|(
operator|new
name|ExitHandler
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|/**    * This method modifies the master's configuration in order to inject backup-related features    * @param conf configuration    */
specifier|public
specifier|static
name|void
name|decorateMasterConfiguration
parameter_list|(
name|Configuration
name|conf
parameter_list|)
block|{
if|if
condition|(
operator|!
name|isBackupEnabled
argument_list|(
name|conf
argument_list|)
condition|)
block|{
return|return;
block|}
name|String
name|plugins
init|=
name|conf
operator|.
name|get
argument_list|(
name|HConstants
operator|.
name|HBASE_MASTER_LOGCLEANER_PLUGINS
argument_list|)
decl_stmt|;
name|String
name|cleanerClass
init|=
name|BackupLogCleaner
operator|.
name|class
operator|.
name|getCanonicalName
argument_list|()
decl_stmt|;
if|if
condition|(
operator|!
name|plugins
operator|.
name|contains
argument_list|(
name|cleanerClass
argument_list|)
condition|)
block|{
name|conf
operator|.
name|set
argument_list|(
name|HConstants
operator|.
name|HBASE_MASTER_LOGCLEANER_PLUGINS
argument_list|,
name|plugins
operator|+
literal|","
operator|+
name|cleanerClass
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Added log cleaner: "
operator|+
name|cleanerClass
argument_list|)
expr_stmt|;
block|}
block|}
specifier|private
specifier|static
name|boolean
name|isBackupEnabled
parameter_list|(
name|Configuration
name|conf
parameter_list|)
block|{
return|return
name|conf
operator|.
name|getBoolean
argument_list|(
name|HConstants
operator|.
name|BACKUP_ENABLE_KEY
argument_list|,
name|HConstants
operator|.
name|BACKUP_ENABLE_DEFAULT
argument_list|)
return|;
block|}
specifier|private
class|class
name|ExitHandler
extends|extends
name|Thread
block|{
specifier|public
name|ExitHandler
parameter_list|()
block|{
name|super
argument_list|(
literal|"Backup Manager Exit Handler"
argument_list|)
expr_stmt|;
block|}
specifier|public
name|void
name|run
parameter_list|()
block|{
if|if
condition|(
name|backupContext
operator|!=
literal|null
operator|&&
operator|!
name|backupComplete
condition|)
block|{
comment|// program exit and backup is not complete, then mark as cancelled to avoid submitted backup
comment|// handler's taking further action
name|backupContext
operator|.
name|markCancel
argument_list|()
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Backup is cancelled due to force program exiting."
argument_list|)
expr_stmt|;
try|try
block|{
name|cancelBackup
argument_list|(
name|backupContext
operator|.
name|getBackupId
argument_list|()
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|String
name|msg
init|=
name|e
operator|.
name|getMessage
argument_list|()
decl_stmt|;
if|if
condition|(
name|msg
operator|==
literal|null
operator|||
name|msg
operator|.
name|equals
argument_list|(
literal|""
argument_list|)
condition|)
block|{
name|msg
operator|=
name|e
operator|.
name|getClass
argument_list|()
operator|.
name|getName
argument_list|()
expr_stmt|;
block|}
name|LOG
operator|.
name|error
argument_list|(
literal|"Failed to cancel backup "
operator|+
name|backupContext
operator|.
name|getBackupId
argument_list|()
operator|+
literal|" due to "
operator|+
name|msg
argument_list|)
expr_stmt|;
block|}
block|}
name|exit
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**    * Cancel the ongoing backup via backup id.    * @param backupId The id of the ongoing backup to be cancelled    * @throws Exception exception    */
specifier|private
name|void
name|cancelBackup
parameter_list|(
name|String
name|backupId
parameter_list|)
throws|throws
name|Exception
block|{
comment|// TODO: will be implemented in Phase 2: HBASE-14125
name|LOG
operator|.
name|debug
argument_list|(
literal|"Try to cancel the backup "
operator|+
name|backupId
operator|+
literal|". the feature is NOT implemented yet"
argument_list|)
expr_stmt|;
block|}
comment|/**    * Stop all the work of backup.    */
specifier|public
name|void
name|exit
parameter_list|()
block|{
comment|// currently, we shutdown now for all ongoing back handlers, we may need to do something like
comment|// record the failed list somewhere later
if|if
condition|(
name|this
operator|.
name|pool
operator|!=
literal|null
condition|)
block|{
name|this
operator|.
name|pool
operator|.
name|shutdownNow
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**    * Create a BackupContext based on input backup request.    * @param backupId backup id    * @param type    type    * @param tablelist table list    * @param targetRootDir root dir    * @param snapshot snapshot name    * @return BackupContext context    * @throws BackupException exception    */
specifier|protected
name|BackupContext
name|createBackupContext
parameter_list|(
name|String
name|backupId
parameter_list|,
name|String
name|type
parameter_list|,
name|String
name|tablelist
parameter_list|,
name|String
name|targetRootDir
parameter_list|,
name|String
name|snapshot
parameter_list|)
throws|throws
name|BackupException
block|{
if|if
condition|(
name|targetRootDir
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|BackupException
argument_list|(
literal|"Wrong backup request parameter: target backup root directory"
argument_list|)
throw|;
block|}
if|if
condition|(
name|type
operator|.
name|equals
argument_list|(
name|BackupRestoreConstants
operator|.
name|BACKUP_TYPE_FULL
argument_list|)
operator|&&
name|tablelist
operator|==
literal|null
condition|)
block|{
comment|// If table list is null for full backup, which means backup all tables. Then fill the table
comment|// list with all user tables from meta. It no table available, throw the request exception.
name|HTableDescriptor
index|[]
name|htds
init|=
literal|null
decl_stmt|;
try|try
init|(
name|Connection
name|conn
init|=
name|ConnectionFactory
operator|.
name|createConnection
argument_list|(
name|conf
argument_list|)
init|;           HBaseAdmin hbadmin = (HBaseAdmin)
name|conn
operator|.
name|getAdmin
argument_list|()
block|)
block|{
name|htds
operator|=
name|hbadmin
operator|.
name|listTables
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|BackupException
argument_list|(
name|e
argument_list|)
throw|;
block|}
if|if
condition|(
name|htds
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|BackupException
argument_list|(
literal|"No table exists for full backup of all tables."
argument_list|)
throw|;
block|}
else|else
block|{
name|StringBuilder
name|sb
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
for|for
control|(
name|HTableDescriptor
name|hTableDescriptor
range|:
name|htds
control|)
block|{
name|sb
operator|.
name|append
argument_list|(
name|hTableDescriptor
operator|.
name|getNameAsString
argument_list|()
operator|+
name|BackupRestoreConstants
operator|.
name|TABLENAME_DELIMITER_IN_COMMAND
argument_list|)
expr_stmt|;
block|}
name|sb
operator|.
name|deleteCharAt
argument_list|(
name|sb
operator|.
name|lastIndexOf
argument_list|(
name|BackupRestoreConstants
operator|.
name|TABLENAME_DELIMITER_IN_COMMAND
argument_list|)
argument_list|)
expr_stmt|;
name|tablelist
operator|=
name|sb
operator|.
name|toString
argument_list|()
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Full backup all the tables available in the cluster: "
operator|+
name|tablelist
argument_list|)
expr_stmt|;
block|}
block|}
comment|// there are one or more tables in the table list
return|return
operator|new
name|BackupContext
argument_list|(
name|backupId
argument_list|,
name|type
argument_list|,
name|tablelist
operator|.
name|split
argument_list|(
name|BackupRestoreConstants
operator|.
name|TABLENAME_DELIMITER_IN_COMMAND
argument_list|)
argument_list|,
name|targetRootDir
argument_list|,
name|snapshot
argument_list|)
return|;
block|}
end_class

begin_comment
comment|/**    * Check if any ongoing backup. Currently, we only reply on checking status in hbase:backup. We    * need to consider to handle the case of orphan records in the future. Otherwise, all the coming    * request will fail.    * @return the ongoing backup id if on going backup exists, otherwise null    * @throws IOException exception    */
end_comment

begin_function
specifier|private
name|String
name|getOngoingBackupId
parameter_list|()
throws|throws
name|IOException
block|{
name|ArrayList
argument_list|<
name|BackupContext
argument_list|>
name|sessions
init|=
name|systemTable
operator|.
name|getBackupContexts
argument_list|(
name|BACKUPSTATUS
operator|.
name|ONGOING
argument_list|)
decl_stmt|;
if|if
condition|(
name|sessions
operator|.
name|size
argument_list|()
operator|==
literal|0
condition|)
block|{
return|return
literal|null
return|;
block|}
return|return
name|sessions
operator|.
name|get
argument_list|(
literal|0
argument_list|)
operator|.
name|getBackupId
argument_list|()
return|;
block|}
end_function

begin_comment
comment|/**    * Start the backup manager service.    * @throws IOException exception    */
end_comment

begin_function
specifier|public
name|void
name|initialize
parameter_list|()
throws|throws
name|IOException
block|{
name|String
name|ongoingBackupId
init|=
name|this
operator|.
name|getOngoingBackupId
argument_list|()
decl_stmt|;
if|if
condition|(
name|ongoingBackupId
operator|!=
literal|null
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"There is a ongoing backup "
operator|+
name|ongoingBackupId
operator|+
literal|". Can not launch new backup until no ongoing backup remains."
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|BackupException
argument_list|(
literal|"There is ongoing backup."
argument_list|)
throw|;
block|}
comment|// Initialize thread pools
name|int
name|nrThreads
init|=
name|this
operator|.
name|conf
operator|.
name|getInt
argument_list|(
literal|"hbase.backup.threads.max"
argument_list|,
literal|1
argument_list|)
decl_stmt|;
name|ThreadFactoryBuilder
name|builder
init|=
operator|new
name|ThreadFactoryBuilder
argument_list|()
decl_stmt|;
name|builder
operator|.
name|setNameFormat
argument_list|(
literal|"BackupHandler-%1$d"
argument_list|)
expr_stmt|;
name|this
operator|.
name|pool
operator|=
operator|new
name|ThreadPoolExecutor
argument_list|(
name|nrThreads
argument_list|,
name|nrThreads
argument_list|,
literal|60
argument_list|,
name|TimeUnit
operator|.
name|SECONDS
argument_list|,
operator|new
name|LinkedBlockingQueue
argument_list|<
name|Runnable
argument_list|>
argument_list|()
argument_list|,
name|builder
operator|.
name|build
argument_list|()
argument_list|)
expr_stmt|;
operator|(
operator|(
name|ThreadPoolExecutor
operator|)
name|pool
operator|)
operator|.
name|allowCoreThreadTimeOut
argument_list|(
literal|true
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/**    * Dispatch and handle a backup request.    * @param backupContext backup context    * @throws BackupException exception    */
end_comment

begin_function
specifier|public
name|void
name|dispatchRequest
parameter_list|(
name|BackupContext
name|backupContext
parameter_list|)
throws|throws
name|BackupException
block|{
name|this
operator|.
name|backupContext
operator|=
name|backupContext
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Got a backup request: "
operator|+
literal|"Type: "
operator|+
name|backupContext
operator|.
name|getType
argument_list|()
operator|+
literal|"; Tables: "
operator|+
name|backupContext
operator|.
name|getTableListAsString
argument_list|()
operator|+
literal|"; TargetRootDir: "
operator|+
name|backupContext
operator|.
name|getTargetRootDir
argument_list|()
argument_list|)
expr_stmt|;
comment|// dispatch the request to a backup handler and put it handler map
name|BackupHandler
name|handler
init|=
operator|new
name|BackupHandler
argument_list|(
name|this
operator|.
name|backupContext
argument_list|,
name|this
argument_list|,
name|conf
argument_list|)
decl_stmt|;
name|Future
argument_list|<
name|Object
argument_list|>
name|future
init|=
name|this
operator|.
name|pool
operator|.
name|submit
argument_list|(
name|handler
argument_list|)
decl_stmt|;
comment|// wait for the execution to complete
try|try
block|{
name|future
operator|.
name|get
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|BackupException
argument_list|(
name|e
argument_list|)
throw|;
block|}
catch|catch
parameter_list|(
name|CancellationException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|BackupException
argument_list|(
name|e
argument_list|)
throw|;
block|}
catch|catch
parameter_list|(
name|ExecutionException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|BackupException
argument_list|(
name|e
argument_list|)
throw|;
block|}
comment|// mark the backup complete for exit handler's processing
name|backupComplete
operator|=
literal|true
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Backup request "
operator|+
name|backupContext
operator|.
name|getBackupId
argument_list|()
operator|+
literal|" has been executed."
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/**    * Get direct ancestors of the current backup.    * @param backupCtx The backup context for the current backup    * @return The ancestors for the current backup    * @throws IOException exception    * @throws BackupException exception    */
end_comment

begin_function
specifier|protected
name|ArrayList
argument_list|<
name|BackupImage
argument_list|>
name|getAncestors
parameter_list|(
name|BackupContext
name|backupCtx
parameter_list|)
throws|throws
name|IOException
throws|,
name|BackupException
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Getting the direct ancestors of the current backup ..."
argument_list|)
expr_stmt|;
name|ArrayList
argument_list|<
name|BackupImage
argument_list|>
name|ancestors
init|=
operator|new
name|ArrayList
argument_list|<
name|BackupImage
argument_list|>
argument_list|()
decl_stmt|;
comment|// full backup does not have ancestor
if|if
condition|(
name|backupCtx
operator|.
name|getType
argument_list|()
operator|.
name|equals
argument_list|(
name|BackupRestoreConstants
operator|.
name|BACKUP_TYPE_FULL
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Current backup is a full backup, no direct ancestor for it."
argument_list|)
expr_stmt|;
return|return
name|ancestors
return|;
block|}
comment|// get all backup history list in descending order
name|ArrayList
argument_list|<
name|BackupCompleteData
argument_list|>
name|allHistoryList
init|=
name|getBackupHistory
argument_list|()
decl_stmt|;
for|for
control|(
name|BackupCompleteData
name|backup
range|:
name|allHistoryList
control|)
block|{
name|BackupImage
name|image
init|=
operator|new
name|BackupImage
argument_list|(
name|backup
operator|.
name|getBackupToken
argument_list|()
argument_list|,
name|backup
operator|.
name|getType
argument_list|()
argument_list|,
name|backup
operator|.
name|getBackupRootPath
argument_list|()
argument_list|,
name|backup
operator|.
name|getTableList
argument_list|()
argument_list|,
name|Long
operator|.
name|parseLong
argument_list|(
name|backup
operator|.
name|getStartTime
argument_list|()
argument_list|)
argument_list|,
name|Long
operator|.
name|parseLong
argument_list|(
name|backup
operator|.
name|getEndTime
argument_list|()
argument_list|)
argument_list|)
decl_stmt|;
comment|// add the full backup image as an ancestor until the last incremental backup
if|if
condition|(
name|backup
operator|.
name|getType
argument_list|()
operator|.
name|equals
argument_list|(
name|BackupRestoreConstants
operator|.
name|BACKUP_TYPE_FULL
argument_list|)
condition|)
block|{
comment|// backup image from existing snapshot does not involve in dependency
if|if
condition|(
name|backup
operator|.
name|fromExistingSnapshot
argument_list|()
condition|)
block|{
continue|continue;
block|}
comment|// check the backup image coverage, if previous image could be covered by the newer ones,
comment|// then no need to add
if|if
condition|(
operator|!
name|BackupManifest
operator|.
name|canCoverImage
argument_list|(
name|ancestors
argument_list|,
name|image
argument_list|)
condition|)
block|{
name|ancestors
operator|.
name|add
argument_list|(
name|image
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
comment|// found last incremental backup, if previously added full backup ancestor images can cover
comment|// it, then this incremental ancestor is not the dependent of the current incremental
comment|// backup, that is to say, this is the backup scope boundary of current table set.
comment|// Otherwise, this incremental backup ancestor is the dependent ancestor of the ongoing
comment|// incremental backup
if|if
condition|(
name|BackupManifest
operator|.
name|canCoverImage
argument_list|(
name|ancestors
argument_list|,
name|image
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Met the backup boundary of the current table set. "
operator|+
literal|"The root full backup images for the current backup scope:"
argument_list|)
expr_stmt|;
for|for
control|(
name|BackupImage
name|image1
range|:
name|ancestors
control|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"  BackupId: "
operator|+
name|image1
operator|.
name|getBackupId
argument_list|()
operator|+
literal|", Backup directory: "
operator|+
name|image1
operator|.
name|getRootDir
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
name|Path
name|logBackupPath
init|=
name|HBackupFileSystem
operator|.
name|getLogBackupPath
argument_list|(
name|backup
operator|.
name|getBackupRootPath
argument_list|()
argument_list|,
name|backup
operator|.
name|getBackupToken
argument_list|()
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Current backup has an incremental backup ancestor, "
operator|+
literal|"touching its image manifest in "
operator|+
name|logBackupPath
operator|.
name|toString
argument_list|()
operator|+
literal|" to construct the dependency."
argument_list|)
expr_stmt|;
name|BackupManifest
name|lastIncrImgManifest
init|=
operator|new
name|BackupManifest
argument_list|(
name|conf
argument_list|,
name|logBackupPath
argument_list|)
decl_stmt|;
name|BackupImage
name|lastIncrImage
init|=
name|lastIncrImgManifest
operator|.
name|getBackupImage
argument_list|()
decl_stmt|;
name|ancestors
operator|.
name|add
argument_list|(
name|lastIncrImage
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Last dependent incremental backup image information:"
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"  Token: "
operator|+
name|lastIncrImage
operator|.
name|getBackupId
argument_list|()
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"  Backup directory: "
operator|+
name|lastIncrImage
operator|.
name|getRootDir
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
block|}
name|LOG
operator|.
name|debug
argument_list|(
literal|"Got "
operator|+
name|ancestors
operator|.
name|size
argument_list|()
operator|+
literal|" ancestors for the current backup."
argument_list|)
expr_stmt|;
return|return
name|ancestors
return|;
block|}
end_function

begin_comment
comment|/**    * Get the direct ancestors of this backup for one table involved.    * @param backupContext backup context    * @param table table    * @return backupImages on the dependency list    * @throws BackupException exception    * @throws IOException exception    */
end_comment

begin_function
specifier|protected
name|ArrayList
argument_list|<
name|BackupImage
argument_list|>
name|getAncestors
parameter_list|(
name|BackupContext
name|backupContext
parameter_list|,
name|String
name|table
parameter_list|)
throws|throws
name|BackupException
throws|,
name|IOException
block|{
name|ArrayList
argument_list|<
name|BackupImage
argument_list|>
name|ancestors
init|=
name|getAncestors
argument_list|(
name|backupContext
argument_list|)
decl_stmt|;
name|ArrayList
argument_list|<
name|BackupImage
argument_list|>
name|tableAncestors
init|=
operator|new
name|ArrayList
argument_list|<
name|BackupImage
argument_list|>
argument_list|()
decl_stmt|;
for|for
control|(
name|BackupImage
name|image
range|:
name|ancestors
control|)
block|{
if|if
condition|(
name|image
operator|.
name|hasTable
argument_list|(
name|table
argument_list|)
condition|)
block|{
name|tableAncestors
operator|.
name|add
argument_list|(
name|image
argument_list|)
expr_stmt|;
if|if
condition|(
name|image
operator|.
name|getType
argument_list|()
operator|.
name|equals
argument_list|(
name|BackupRestoreConstants
operator|.
name|BACKUP_TYPE_FULL
argument_list|)
condition|)
block|{
break|break;
block|}
block|}
block|}
return|return
name|tableAncestors
return|;
block|}
end_function

begin_comment
comment|/**    * hbase:backup operations    */
end_comment

begin_comment
comment|/**    * Updates status (state) of a backup session in a persistent store    * @param context context    * @throws IOException exception    */
end_comment

begin_function
specifier|public
name|void
name|updateBackupStatus
parameter_list|(
name|BackupContext
name|context
parameter_list|)
throws|throws
name|IOException
block|{
name|systemTable
operator|.
name|updateBackupStatus
argument_list|(
name|context
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/**    * Read the last backup start code (timestamp) of last successful backup. Will return null     * if there is no startcode stored in hbase:backup or the value is of length 0. These two     * cases indicate there is no successful backup completed so far.    * @return the timestamp of a last successful backup    * @throws IOException exception    */
end_comment

begin_function
specifier|public
name|String
name|readBackupStartCode
parameter_list|()
throws|throws
name|IOException
block|{
return|return
name|systemTable
operator|.
name|readBackupStartCode
argument_list|()
return|;
block|}
end_function

begin_comment
comment|/**    * Write the start code (timestamp) to hbase:backup. If passed in null, then write 0 byte.    * @param startCode start code    * @throws IOException exception    */
end_comment

begin_function
specifier|public
name|void
name|writeBackupStartCode
parameter_list|(
name|String
name|startCode
parameter_list|)
throws|throws
name|IOException
block|{
name|systemTable
operator|.
name|writeBackupStartCode
argument_list|(
name|startCode
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/**    * Get the RS log information after the last log roll from hbase:backup.    * @return RS log info    * @throws IOException exception    */
end_comment

begin_function
specifier|public
name|HashMap
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|readRegionServerLastLogRollResult
parameter_list|()
throws|throws
name|IOException
block|{
return|return
name|systemTable
operator|.
name|readRegionServerLastLogRollResult
argument_list|()
return|;
block|}
end_function

begin_comment
comment|/**    * Get all completed backup information (in desc order by time)    * @return history info of BackupCompleteData    * @throws IOException exception    */
end_comment

begin_function
specifier|public
name|ArrayList
argument_list|<
name|BackupCompleteData
argument_list|>
name|getBackupHistory
parameter_list|()
throws|throws
name|IOException
block|{
return|return
name|systemTable
operator|.
name|getBackupHistory
argument_list|()
return|;
block|}
end_function

begin_comment
comment|/**    * Write the current timestamps for each regionserver to hbase:backup after a successful full or    * incremental backup. Each table may have a different set of log timestamps. The saved timestamp    * is of the last log file that was backed up already.    * @param tables tables    * @throws IOException exception    */
end_comment

begin_function
specifier|public
name|void
name|writeRegionServerLogTimestamp
parameter_list|(
name|Set
argument_list|<
name|String
argument_list|>
name|tables
parameter_list|,
name|HashMap
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|newTimestamps
parameter_list|)
throws|throws
name|IOException
block|{
name|systemTable
operator|.
name|writeRegionServerLogTimestamp
argument_list|(
name|tables
argument_list|,
name|newTimestamps
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/**    * Read the timestamp for each region server log after the last successful backup. Each table has    * its own set of the timestamps. The info is stored for each table as a concatinated string on ZK    * under //hbase//backup//incr//tablelogtimestamp//table_name    * @return the timestamp for each region server. key: tableName value:    *         RegionServer,PreviousTimeStamp    * @throws IOException exception    */
end_comment

begin_function
specifier|public
name|HashMap
argument_list|<
name|String
argument_list|,
name|HashMap
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
argument_list|>
name|readLogTimestampMap
parameter_list|()
throws|throws
name|IOException
block|{
return|return
name|systemTable
operator|.
name|readLogTimestampMap
argument_list|()
return|;
block|}
end_function

begin_comment
comment|/**    * Return the current tables covered by incremental backup.    * @return set of tableNames    * @throws IOException exception    */
end_comment

begin_function
specifier|public
name|Set
argument_list|<
name|String
argument_list|>
name|getIncrementalBackupTableSet
parameter_list|()
throws|throws
name|IOException
block|{
return|return
name|systemTable
operator|.
name|getIncrementalBackupTableSet
argument_list|()
return|;
block|}
end_function

begin_comment
comment|/**    * Adds set of tables to overall incremental backup table set    * @param tables tables    * @throws IOException exception    */
end_comment

begin_function
specifier|public
name|void
name|addIncrementalBackupTableSet
parameter_list|(
name|Set
argument_list|<
name|String
argument_list|>
name|tables
parameter_list|)
throws|throws
name|IOException
block|{
name|systemTable
operator|.
name|addIncrementalBackupTableSet
argument_list|(
name|tables
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/**    * Saves list of WAL files after incremental backup operation. These files will be stored until    * TTL expiration and are used by Backup Log Cleaner plugin to determine which WAL files can be    * safely purged.    */
end_comment

begin_function
specifier|public
name|void
name|recordWALFiles
parameter_list|(
name|List
argument_list|<
name|String
argument_list|>
name|files
parameter_list|)
throws|throws
name|IOException
block|{
name|systemTable
operator|.
name|addWALFiles
argument_list|(
name|files
argument_list|,
name|backupContext
operator|.
name|getBackupId
argument_list|()
argument_list|)
expr_stmt|;
block|}
end_function

unit|}
end_unit

