begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  *  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|master
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|InterruptedIOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|NavigableMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Set
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|locks
operator|.
name|Lock
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|locks
operator|.
name|ReentrantLock
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|Log
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|LogFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|classification
operator|.
name|InterfaceAudience
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileStatus
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|PathFilter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|ClusterId
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|TableName
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HColumnDescriptor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HConstants
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HRegionInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HTableDescriptor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|InvalidFamilyOperationException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|RemoteExceptionHandler
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|Server
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|ServerName
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|backup
operator|.
name|HFileArchiver
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|catalog
operator|.
name|MetaReader
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|Result
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|exceptions
operator|.
name|DeserializationException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|fs
operator|.
name|HFileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|HRegion
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|wal
operator|.
name|HLog
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|wal
operator|.
name|HLogSplitter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|wal
operator|.
name|HLogUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|Bytes
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|EnvironmentEdgeManager
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|FSTableDescriptors
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|FSUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|zookeeper
operator|.
name|KeeperException
import|;
end_import

begin_comment
comment|/**  * This class abstracts a bunch of operations the HMaster needs to interact with  * the underlying file system, including splitting log files, checking file  * system status, etc.  */
end_comment

begin_class
annotation|@
name|InterfaceAudience
operator|.
name|Private
specifier|public
class|class
name|MasterFileSystem
block|{
specifier|private
specifier|static
specifier|final
name|Log
name|LOG
init|=
name|LogFactory
operator|.
name|getLog
argument_list|(
name|MasterFileSystem
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
comment|// HBase configuration
name|Configuration
name|conf
decl_stmt|;
comment|// master status
name|Server
name|master
decl_stmt|;
comment|// metrics for master
specifier|private
specifier|final
name|MetricsMasterFileSystem
name|metricsMasterFilesystem
init|=
operator|new
name|MetricsMasterFileSystem
argument_list|()
decl_stmt|;
comment|// Persisted unique cluster ID
specifier|private
name|ClusterId
name|clusterId
decl_stmt|;
comment|// Keep around for convenience.
specifier|private
specifier|final
name|FileSystem
name|fs
decl_stmt|;
comment|// Is the fileystem ok?
specifier|private
specifier|volatile
name|boolean
name|fsOk
init|=
literal|true
decl_stmt|;
comment|// The Path to the old logs dir
specifier|private
specifier|final
name|Path
name|oldLogDir
decl_stmt|;
comment|// root hbase directory on the FS
specifier|private
specifier|final
name|Path
name|rootdir
decl_stmt|;
comment|// hbase temp directory used for table construction and deletion
specifier|private
specifier|final
name|Path
name|tempdir
decl_stmt|;
comment|// create the split log lock
specifier|final
name|Lock
name|splitLogLock
init|=
operator|new
name|ReentrantLock
argument_list|()
decl_stmt|;
specifier|final
name|boolean
name|distributedLogReplay
decl_stmt|;
specifier|final
name|SplitLogManager
name|splitLogManager
decl_stmt|;
specifier|private
specifier|final
name|MasterServices
name|services
decl_stmt|;
specifier|final
specifier|static
name|PathFilter
name|META_FILTER
init|=
operator|new
name|PathFilter
argument_list|()
block|{
specifier|public
name|boolean
name|accept
parameter_list|(
name|Path
name|p
parameter_list|)
block|{
return|return
name|HLogUtil
operator|.
name|isMetaFile
argument_list|(
name|p
argument_list|)
return|;
block|}
block|}
decl_stmt|;
specifier|final
specifier|static
name|PathFilter
name|NON_META_FILTER
init|=
operator|new
name|PathFilter
argument_list|()
block|{
specifier|public
name|boolean
name|accept
parameter_list|(
name|Path
name|p
parameter_list|)
block|{
return|return
operator|!
name|HLogUtil
operator|.
name|isMetaFile
argument_list|(
name|p
argument_list|)
return|;
block|}
block|}
decl_stmt|;
specifier|public
name|MasterFileSystem
parameter_list|(
name|Server
name|master
parameter_list|,
name|MasterServices
name|services
parameter_list|)
throws|throws
name|IOException
block|{
name|this
operator|.
name|conf
operator|=
name|master
operator|.
name|getConfiguration
argument_list|()
expr_stmt|;
name|this
operator|.
name|master
operator|=
name|master
expr_stmt|;
name|this
operator|.
name|services
operator|=
name|services
expr_stmt|;
comment|// Set filesystem to be that of this.rootdir else we get complaints about
comment|// mismatched filesystems if hbase.rootdir is hdfs and fs.defaultFS is
comment|// default localfs.  Presumption is that rootdir is fully-qualified before
comment|// we get to here with appropriate fs scheme.
name|this
operator|.
name|rootdir
operator|=
name|FSUtils
operator|.
name|getRootDir
argument_list|(
name|conf
argument_list|)
expr_stmt|;
name|this
operator|.
name|tempdir
operator|=
operator|new
name|Path
argument_list|(
name|this
operator|.
name|rootdir
argument_list|,
name|HConstants
operator|.
name|HBASE_TEMP_DIRECTORY
argument_list|)
expr_stmt|;
comment|// Cover both bases, the old way of setting default fs and the new.
comment|// We're supposed to run on 0.20 and 0.21 anyways.
name|this
operator|.
name|fs
operator|=
name|this
operator|.
name|rootdir
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
expr_stmt|;
name|FSUtils
operator|.
name|setFsDefault
argument_list|(
name|conf
argument_list|,
operator|new
name|Path
argument_list|(
name|this
operator|.
name|fs
operator|.
name|getUri
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
comment|// make sure the fs has the same conf
name|fs
operator|.
name|setConf
argument_list|(
name|conf
argument_list|)
expr_stmt|;
name|this
operator|.
name|distributedLogReplay
operator|=
name|HLogSplitter
operator|.
name|isDistributedLogReplay
argument_list|(
name|this
operator|.
name|conf
argument_list|)
expr_stmt|;
comment|// setup the filesystem variable
comment|// set up the archived logs path
name|this
operator|.
name|oldLogDir
operator|=
name|createInitialFileSystemLayout
argument_list|()
expr_stmt|;
name|HFileSystem
operator|.
name|addLocationsOrderInterceptor
argument_list|(
name|conf
argument_list|)
expr_stmt|;
name|this
operator|.
name|splitLogManager
operator|=
operator|new
name|SplitLogManager
argument_list|(
name|master
operator|.
name|getZooKeeper
argument_list|()
argument_list|,
name|master
operator|.
name|getConfiguration
argument_list|()
argument_list|,
name|master
argument_list|,
name|services
argument_list|,
name|master
operator|.
name|getServerName
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|/**    * Create initial layout in filesystem.    *<ol>    *<li>Check if the meta region exists and is readable, if not create it.    * Create hbase.version and the hbase:meta directory if not one.    *</li>    *<li>Create a log archive directory for RS to put archived logs</li>    *</ol>    * Idempotent.    */
specifier|private
name|Path
name|createInitialFileSystemLayout
parameter_list|()
throws|throws
name|IOException
block|{
comment|// check if the root directory exists
name|checkRootDir
argument_list|(
name|this
operator|.
name|rootdir
argument_list|,
name|conf
argument_list|,
name|this
operator|.
name|fs
argument_list|)
expr_stmt|;
comment|// check if temp directory exists and clean it
name|checkTempDir
argument_list|(
name|this
operator|.
name|tempdir
argument_list|,
name|conf
argument_list|,
name|this
operator|.
name|fs
argument_list|)
expr_stmt|;
name|Path
name|oldLogDir
init|=
operator|new
name|Path
argument_list|(
name|this
operator|.
name|rootdir
argument_list|,
name|HConstants
operator|.
name|HREGION_OLDLOGDIR_NAME
argument_list|)
decl_stmt|;
comment|// Make sure the region servers can archive their old logs
if|if
condition|(
operator|!
name|this
operator|.
name|fs
operator|.
name|exists
argument_list|(
name|oldLogDir
argument_list|)
condition|)
block|{
name|this
operator|.
name|fs
operator|.
name|mkdirs
argument_list|(
name|oldLogDir
argument_list|)
expr_stmt|;
block|}
return|return
name|oldLogDir
return|;
block|}
specifier|public
name|FileSystem
name|getFileSystem
parameter_list|()
block|{
return|return
name|this
operator|.
name|fs
return|;
block|}
comment|/**    * Get the directory where old logs go    * @return the dir    */
specifier|public
name|Path
name|getOldLogDir
parameter_list|()
block|{
return|return
name|this
operator|.
name|oldLogDir
return|;
block|}
comment|/**    * Checks to see if the file system is still accessible.    * If not, sets closed    * @return false if file system is not available    */
specifier|public
name|boolean
name|checkFileSystem
parameter_list|()
block|{
if|if
condition|(
name|this
operator|.
name|fsOk
condition|)
block|{
try|try
block|{
name|FSUtils
operator|.
name|checkFileSystemAvailable
argument_list|(
name|this
operator|.
name|fs
argument_list|)
expr_stmt|;
name|FSUtils
operator|.
name|checkDfsSafeMode
argument_list|(
name|this
operator|.
name|conf
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|master
operator|.
name|abort
argument_list|(
literal|"Shutting down HBase cluster: file system not available"
argument_list|,
name|e
argument_list|)
expr_stmt|;
name|this
operator|.
name|fsOk
operator|=
literal|false
expr_stmt|;
block|}
block|}
return|return
name|this
operator|.
name|fsOk
return|;
block|}
comment|/**    * @return HBase root dir.    */
specifier|public
name|Path
name|getRootDir
parameter_list|()
block|{
return|return
name|this
operator|.
name|rootdir
return|;
block|}
comment|/**    * @return HBase temp dir.    */
specifier|public
name|Path
name|getTempDir
parameter_list|()
block|{
return|return
name|this
operator|.
name|tempdir
return|;
block|}
comment|/**    * @return The unique identifier generated for this cluster    */
specifier|public
name|ClusterId
name|getClusterId
parameter_list|()
block|{
return|return
name|clusterId
return|;
block|}
comment|/**    * Inspect the log directory to find dead servers which need recovery work    * @return A set of ServerNames which aren't running but still have WAL files left in file system    */
name|Set
argument_list|<
name|ServerName
argument_list|>
name|getFailedServersFromLogFolders
parameter_list|()
block|{
name|boolean
name|retrySplitting
init|=
operator|!
name|conf
operator|.
name|getBoolean
argument_list|(
literal|"hbase.hlog.split.skip.errors"
argument_list|,
name|HLog
operator|.
name|SPLIT_SKIP_ERRORS_DEFAULT
argument_list|)
decl_stmt|;
name|Set
argument_list|<
name|ServerName
argument_list|>
name|serverNames
init|=
operator|new
name|HashSet
argument_list|<
name|ServerName
argument_list|>
argument_list|()
decl_stmt|;
name|Path
name|logsDirPath
init|=
operator|new
name|Path
argument_list|(
name|this
operator|.
name|rootdir
argument_list|,
name|HConstants
operator|.
name|HREGION_LOGDIR_NAME
argument_list|)
decl_stmt|;
do|do
block|{
if|if
condition|(
name|master
operator|.
name|isStopped
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Master stopped while trying to get failed servers."
argument_list|)
expr_stmt|;
break|break;
block|}
try|try
block|{
if|if
condition|(
operator|!
name|this
operator|.
name|fs
operator|.
name|exists
argument_list|(
name|logsDirPath
argument_list|)
condition|)
return|return
name|serverNames
return|;
name|FileStatus
index|[]
name|logFolders
init|=
name|FSUtils
operator|.
name|listStatus
argument_list|(
name|this
operator|.
name|fs
argument_list|,
name|logsDirPath
argument_list|,
literal|null
argument_list|)
decl_stmt|;
comment|// Get online servers after getting log folders to avoid log folder deletion of newly
comment|// checked in region servers . see HBASE-5916
name|Set
argument_list|<
name|ServerName
argument_list|>
name|onlineServers
init|=
operator|(
operator|(
name|HMaster
operator|)
name|master
operator|)
operator|.
name|getServerManager
argument_list|()
operator|.
name|getOnlineServers
argument_list|()
operator|.
name|keySet
argument_list|()
decl_stmt|;
if|if
condition|(
name|logFolders
operator|==
literal|null
operator|||
name|logFolders
operator|.
name|length
operator|==
literal|0
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"No log files to split, proceeding..."
argument_list|)
expr_stmt|;
return|return
name|serverNames
return|;
block|}
for|for
control|(
name|FileStatus
name|status
range|:
name|logFolders
control|)
block|{
name|String
name|sn
init|=
name|status
operator|.
name|getPath
argument_list|()
operator|.
name|getName
argument_list|()
decl_stmt|;
comment|// truncate splitting suffix if present (for ServerName parsing)
if|if
condition|(
name|sn
operator|.
name|endsWith
argument_list|(
name|HLog
operator|.
name|SPLITTING_EXT
argument_list|)
condition|)
block|{
name|sn
operator|=
name|sn
operator|.
name|substring
argument_list|(
literal|0
argument_list|,
name|sn
operator|.
name|length
argument_list|()
operator|-
name|HLog
operator|.
name|SPLITTING_EXT
operator|.
name|length
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|ServerName
name|serverName
init|=
name|ServerName
operator|.
name|parseServerName
argument_list|(
name|sn
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|onlineServers
operator|.
name|contains
argument_list|(
name|serverName
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Log folder "
operator|+
name|status
operator|.
name|getPath
argument_list|()
operator|+
literal|" doesn't belong "
operator|+
literal|"to a known region server, splitting"
argument_list|)
expr_stmt|;
name|serverNames
operator|.
name|add
argument_list|(
name|serverName
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Log folder "
operator|+
name|status
operator|.
name|getPath
argument_list|()
operator|+
literal|" belongs to an existing region server"
argument_list|)
expr_stmt|;
block|}
block|}
name|retrySplitting
operator|=
literal|false
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ioe
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failed getting failed servers to be recovered."
argument_list|,
name|ioe
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|checkFileSystem
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Bad Filesystem, exiting"
argument_list|)
expr_stmt|;
name|Runtime
operator|.
name|getRuntime
argument_list|()
operator|.
name|halt
argument_list|(
literal|1
argument_list|)
expr_stmt|;
block|}
try|try
block|{
if|if
condition|(
name|retrySplitting
condition|)
block|{
name|Thread
operator|.
name|sleep
argument_list|(
name|conf
operator|.
name|getInt
argument_list|(
literal|"hbase.hlog.split.failure.retry.interval"
argument_list|,
literal|30
operator|*
literal|1000
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Interrupted, aborting since cannot return w/o splitting"
argument_list|)
expr_stmt|;
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|interrupt
argument_list|()
expr_stmt|;
name|retrySplitting
operator|=
literal|false
expr_stmt|;
name|Runtime
operator|.
name|getRuntime
argument_list|()
operator|.
name|halt
argument_list|(
literal|1
argument_list|)
expr_stmt|;
block|}
block|}
block|}
do|while
condition|(
name|retrySplitting
condition|)
do|;
return|return
name|serverNames
return|;
block|}
specifier|public
name|void
name|splitLog
parameter_list|(
specifier|final
name|ServerName
name|serverName
parameter_list|)
throws|throws
name|IOException
block|{
name|Set
argument_list|<
name|ServerName
argument_list|>
name|serverNames
init|=
operator|new
name|HashSet
argument_list|<
name|ServerName
argument_list|>
argument_list|()
decl_stmt|;
name|serverNames
operator|.
name|add
argument_list|(
name|serverName
argument_list|)
expr_stmt|;
name|splitLog
argument_list|(
name|serverNames
argument_list|)
expr_stmt|;
block|}
comment|/**    * Specialized method to handle the splitting for meta HLog    * @param serverName    * @throws IOException    */
specifier|public
name|void
name|splitMetaLog
parameter_list|(
specifier|final
name|ServerName
name|serverName
parameter_list|)
throws|throws
name|IOException
block|{
name|Set
argument_list|<
name|ServerName
argument_list|>
name|serverNames
init|=
operator|new
name|HashSet
argument_list|<
name|ServerName
argument_list|>
argument_list|()
decl_stmt|;
name|serverNames
operator|.
name|add
argument_list|(
name|serverName
argument_list|)
expr_stmt|;
name|splitMetaLog
argument_list|(
name|serverNames
argument_list|)
expr_stmt|;
block|}
comment|/**    * Specialized method to handle the splitting for meta HLog    * @param serverNames    * @throws IOException    */
specifier|public
name|void
name|splitMetaLog
parameter_list|(
specifier|final
name|Set
argument_list|<
name|ServerName
argument_list|>
name|serverNames
parameter_list|)
throws|throws
name|IOException
block|{
name|splitLog
argument_list|(
name|serverNames
argument_list|,
name|META_FILTER
argument_list|)
expr_stmt|;
block|}
specifier|private
name|List
argument_list|<
name|Path
argument_list|>
name|getLogDirs
parameter_list|(
specifier|final
name|Set
argument_list|<
name|ServerName
argument_list|>
name|serverNames
parameter_list|)
throws|throws
name|IOException
block|{
name|List
argument_list|<
name|Path
argument_list|>
name|logDirs
init|=
operator|new
name|ArrayList
argument_list|<
name|Path
argument_list|>
argument_list|()
decl_stmt|;
name|boolean
name|needReleaseLock
init|=
literal|false
decl_stmt|;
if|if
condition|(
operator|!
name|this
operator|.
name|services
operator|.
name|isInitialized
argument_list|()
condition|)
block|{
comment|// during master initialization, we could have multiple places splitting a same wal
name|this
operator|.
name|splitLogLock
operator|.
name|lock
argument_list|()
expr_stmt|;
name|needReleaseLock
operator|=
literal|true
expr_stmt|;
block|}
try|try
block|{
for|for
control|(
name|ServerName
name|serverName
range|:
name|serverNames
control|)
block|{
name|Path
name|logDir
init|=
operator|new
name|Path
argument_list|(
name|this
operator|.
name|rootdir
argument_list|,
name|HLogUtil
operator|.
name|getHLogDirectoryName
argument_list|(
name|serverName
operator|.
name|toString
argument_list|()
argument_list|)
argument_list|)
decl_stmt|;
name|Path
name|splitDir
init|=
name|logDir
operator|.
name|suffix
argument_list|(
name|HLog
operator|.
name|SPLITTING_EXT
argument_list|)
decl_stmt|;
comment|// Rename the directory so a rogue RS doesn't create more HLogs
if|if
condition|(
name|fs
operator|.
name|exists
argument_list|(
name|logDir
argument_list|)
condition|)
block|{
if|if
condition|(
operator|!
name|this
operator|.
name|fs
operator|.
name|rename
argument_list|(
name|logDir
argument_list|,
name|splitDir
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Failed fs.rename for log split: "
operator|+
name|logDir
argument_list|)
throw|;
block|}
name|logDir
operator|=
name|splitDir
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Renamed region directory: "
operator|+
name|splitDir
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
operator|!
name|fs
operator|.
name|exists
argument_list|(
name|splitDir
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Log dir for server "
operator|+
name|serverName
operator|+
literal|" does not exist"
argument_list|)
expr_stmt|;
continue|continue;
block|}
name|logDirs
operator|.
name|add
argument_list|(
name|splitDir
argument_list|)
expr_stmt|;
block|}
block|}
finally|finally
block|{
if|if
condition|(
name|needReleaseLock
condition|)
block|{
name|this
operator|.
name|splitLogLock
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
return|return
name|logDirs
return|;
block|}
comment|/**    * Mark regions in recovering state when distributedLogReplay are set true    * @param serverNames Set of ServerNames to be replayed wals in order to recover changes contained    *          in them    * @throws IOException    */
specifier|public
name|void
name|prepareLogReplay
parameter_list|(
name|Set
argument_list|<
name|ServerName
argument_list|>
name|serverNames
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
operator|!
name|this
operator|.
name|distributedLogReplay
condition|)
block|{
return|return;
block|}
comment|// mark regions in recovering state
for|for
control|(
name|ServerName
name|serverName
range|:
name|serverNames
control|)
block|{
name|NavigableMap
argument_list|<
name|HRegionInfo
argument_list|,
name|Result
argument_list|>
name|regions
init|=
name|this
operator|.
name|getServerUserRegions
argument_list|(
name|serverName
argument_list|)
decl_stmt|;
if|if
condition|(
name|regions
operator|==
literal|null
condition|)
block|{
continue|continue;
block|}
try|try
block|{
name|this
operator|.
name|splitLogManager
operator|.
name|markRegionsRecoveringInZK
argument_list|(
name|serverName
argument_list|,
name|regions
operator|.
name|keySet
argument_list|()
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|KeeperException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
block|}
comment|/**    * Mark regions in recovering state when distributedLogReplay are set true    * @param serverName Failed region server whose wals to be replayed    * @param regions Set of regions to be recovered    * @throws IOException    */
specifier|public
name|void
name|prepareLogReplay
parameter_list|(
name|ServerName
name|serverName
parameter_list|,
name|Set
argument_list|<
name|HRegionInfo
argument_list|>
name|regions
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
operator|!
name|this
operator|.
name|distributedLogReplay
condition|)
block|{
return|return;
block|}
comment|// mark regions in recovering state
if|if
condition|(
name|regions
operator|==
literal|null
operator|||
name|regions
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
return|return;
block|}
try|try
block|{
name|this
operator|.
name|splitLogManager
operator|.
name|markRegionsRecoveringInZK
argument_list|(
name|serverName
argument_list|,
name|regions
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|KeeperException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
specifier|public
name|void
name|splitLog
parameter_list|(
specifier|final
name|Set
argument_list|<
name|ServerName
argument_list|>
name|serverNames
parameter_list|)
throws|throws
name|IOException
block|{
name|splitLog
argument_list|(
name|serverNames
argument_list|,
name|NON_META_FILTER
argument_list|)
expr_stmt|;
block|}
comment|/**    * Wrapper function on {@link SplitLogManager#removeStaleRecoveringRegionsFromZK(Set)}    * @param failedServers    * @throws KeeperException    */
name|void
name|removeStaleRecoveringRegionsFromZK
parameter_list|(
specifier|final
name|Set
argument_list|<
name|ServerName
argument_list|>
name|failedServers
parameter_list|)
throws|throws
name|KeeperException
throws|,
name|InterruptedIOException
block|{
name|this
operator|.
name|splitLogManager
operator|.
name|removeStaleRecoveringRegionsFromZK
argument_list|(
name|failedServers
argument_list|)
expr_stmt|;
block|}
comment|/**    * This method is the base split method that splits HLog files matching a filter. Callers should    * pass the appropriate filter for meta and non-meta HLogs.    * @param serverNames    * @param filter    * @throws IOException    */
specifier|public
name|void
name|splitLog
parameter_list|(
specifier|final
name|Set
argument_list|<
name|ServerName
argument_list|>
name|serverNames
parameter_list|,
name|PathFilter
name|filter
parameter_list|)
throws|throws
name|IOException
block|{
name|long
name|splitTime
init|=
literal|0
decl_stmt|,
name|splitLogSize
init|=
literal|0
decl_stmt|;
name|List
argument_list|<
name|Path
argument_list|>
name|logDirs
init|=
name|getLogDirs
argument_list|(
name|serverNames
argument_list|)
decl_stmt|;
name|splitLogManager
operator|.
name|handleDeadWorkers
argument_list|(
name|serverNames
argument_list|)
expr_stmt|;
name|splitTime
operator|=
name|EnvironmentEdgeManager
operator|.
name|currentTimeMillis
argument_list|()
expr_stmt|;
name|splitLogSize
operator|=
name|splitLogManager
operator|.
name|splitLogDistributed
argument_list|(
name|serverNames
argument_list|,
name|logDirs
argument_list|,
name|filter
argument_list|)
expr_stmt|;
name|splitTime
operator|=
name|EnvironmentEdgeManager
operator|.
name|currentTimeMillis
argument_list|()
operator|-
name|splitTime
expr_stmt|;
if|if
condition|(
name|this
operator|.
name|metricsMasterFilesystem
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
name|filter
operator|==
name|META_FILTER
condition|)
block|{
name|this
operator|.
name|metricsMasterFilesystem
operator|.
name|addMetaWALSplit
argument_list|(
name|splitTime
argument_list|,
name|splitLogSize
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|this
operator|.
name|metricsMasterFilesystem
operator|.
name|addSplit
argument_list|(
name|splitTime
argument_list|,
name|splitLogSize
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|/**    * Get the rootdir.  Make sure its wholesome and exists before returning.    * @param rd    * @param c    * @param fs    * @return hbase.rootdir (after checks for existence and bootstrapping if    * needed populating the directory with necessary bootup files).    * @throws IOException    */
annotation|@
name|SuppressWarnings
argument_list|(
literal|"deprecation"
argument_list|)
specifier|private
name|Path
name|checkRootDir
parameter_list|(
specifier|final
name|Path
name|rd
parameter_list|,
specifier|final
name|Configuration
name|c
parameter_list|,
specifier|final
name|FileSystem
name|fs
parameter_list|)
throws|throws
name|IOException
block|{
comment|// If FS is in safe mode wait till out of it.
name|FSUtils
operator|.
name|waitOnSafeMode
argument_list|(
name|c
argument_list|,
name|c
operator|.
name|getInt
argument_list|(
name|HConstants
operator|.
name|THREAD_WAKE_FREQUENCY
argument_list|,
literal|10
operator|*
literal|1000
argument_list|)
argument_list|)
expr_stmt|;
comment|// Filesystem is good. Go ahead and check for hbase.rootdir.
try|try
block|{
if|if
condition|(
operator|!
name|fs
operator|.
name|exists
argument_list|(
name|rd
argument_list|)
condition|)
block|{
name|fs
operator|.
name|mkdirs
argument_list|(
name|rd
argument_list|)
expr_stmt|;
comment|// DFS leaves safe mode with 0 DNs when there are 0 blocks.
comment|// We used to handle this by checking the current DN count and waiting until
comment|// it is nonzero. With security, the check for datanode count doesn't work --
comment|// it is a privileged op. So instead we adopt the strategy of the jobtracker
comment|// and simply retry file creation during bootstrap indefinitely. As soon as
comment|// there is one datanode it will succeed. Permission problems should have
comment|// already been caught by mkdirs above.
name|FSUtils
operator|.
name|setVersion
argument_list|(
name|fs
argument_list|,
name|rd
argument_list|,
name|c
operator|.
name|getInt
argument_list|(
name|HConstants
operator|.
name|THREAD_WAKE_FREQUENCY
argument_list|,
literal|10
operator|*
literal|1000
argument_list|)
argument_list|,
name|c
operator|.
name|getInt
argument_list|(
name|HConstants
operator|.
name|VERSION_FILE_WRITE_ATTEMPTS
argument_list|,
name|HConstants
operator|.
name|DEFAULT_VERSION_FILE_WRITE_ATTEMPTS
argument_list|)
argument_list|)
expr_stmt|;
block|}
else|else
block|{
if|if
condition|(
operator|!
name|fs
operator|.
name|isDirectory
argument_list|(
name|rd
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
name|rd
operator|.
name|toString
argument_list|()
operator|+
literal|" is not a directory"
argument_list|)
throw|;
block|}
comment|// as above
name|FSUtils
operator|.
name|checkVersion
argument_list|(
name|fs
argument_list|,
name|rd
argument_list|,
literal|true
argument_list|,
name|c
operator|.
name|getInt
argument_list|(
name|HConstants
operator|.
name|THREAD_WAKE_FREQUENCY
argument_list|,
literal|10
operator|*
literal|1000
argument_list|)
argument_list|,
name|c
operator|.
name|getInt
argument_list|(
name|HConstants
operator|.
name|VERSION_FILE_WRITE_ATTEMPTS
argument_list|,
name|HConstants
operator|.
name|DEFAULT_VERSION_FILE_WRITE_ATTEMPTS
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|DeserializationException
name|de
parameter_list|)
block|{
name|LOG
operator|.
name|fatal
argument_list|(
literal|"Please fix invalid configuration for "
operator|+
name|HConstants
operator|.
name|HBASE_DIR
argument_list|,
name|de
argument_list|)
expr_stmt|;
name|IOException
name|ioe
init|=
operator|new
name|IOException
argument_list|()
decl_stmt|;
name|ioe
operator|.
name|initCause
argument_list|(
name|de
argument_list|)
expr_stmt|;
throw|throw
name|ioe
throw|;
block|}
catch|catch
parameter_list|(
name|IllegalArgumentException
name|iae
parameter_list|)
block|{
name|LOG
operator|.
name|fatal
argument_list|(
literal|"Please fix invalid configuration for "
operator|+
name|HConstants
operator|.
name|HBASE_DIR
operator|+
literal|" "
operator|+
name|rd
operator|.
name|toString
argument_list|()
argument_list|,
name|iae
argument_list|)
expr_stmt|;
throw|throw
name|iae
throw|;
block|}
comment|// Make sure cluster ID exists
if|if
condition|(
operator|!
name|FSUtils
operator|.
name|checkClusterIdExists
argument_list|(
name|fs
argument_list|,
name|rd
argument_list|,
name|c
operator|.
name|getInt
argument_list|(
name|HConstants
operator|.
name|THREAD_WAKE_FREQUENCY
argument_list|,
literal|10
operator|*
literal|1000
argument_list|)
argument_list|)
condition|)
block|{
name|FSUtils
operator|.
name|setClusterId
argument_list|(
name|fs
argument_list|,
name|rd
argument_list|,
operator|new
name|ClusterId
argument_list|()
argument_list|,
name|c
operator|.
name|getInt
argument_list|(
name|HConstants
operator|.
name|THREAD_WAKE_FREQUENCY
argument_list|,
literal|10
operator|*
literal|1000
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|clusterId
operator|=
name|FSUtils
operator|.
name|getClusterId
argument_list|(
name|fs
argument_list|,
name|rd
argument_list|)
expr_stmt|;
comment|// Make sure the meta region directory exists!
if|if
condition|(
operator|!
name|FSUtils
operator|.
name|metaRegionExists
argument_list|(
name|fs
argument_list|,
name|rd
argument_list|)
condition|)
block|{
name|bootstrap
argument_list|(
name|rd
argument_list|,
name|c
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// Migrate table descriptor files if necessary
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|FSTableDescriptorMigrationToSubdir
operator|.
name|migrateFSTableDescriptorsIfNecessary
argument_list|(
name|fs
argument_list|,
name|rd
argument_list|)
expr_stmt|;
block|}
comment|// Create tableinfo-s for hbase:meta if not already there.
operator|new
name|FSTableDescriptors
argument_list|(
name|fs
argument_list|,
name|rd
argument_list|)
operator|.
name|createTableDescriptor
argument_list|(
name|HTableDescriptor
operator|.
name|META_TABLEDESC
argument_list|)
expr_stmt|;
return|return
name|rd
return|;
block|}
comment|/**    * Make sure the hbase temp directory exists and is empty.    * NOTE that this method is only executed once just after the master becomes the active one.    */
specifier|private
name|void
name|checkTempDir
parameter_list|(
specifier|final
name|Path
name|tmpdir
parameter_list|,
specifier|final
name|Configuration
name|c
parameter_list|,
specifier|final
name|FileSystem
name|fs
parameter_list|)
throws|throws
name|IOException
block|{
comment|// If the temp directory exists, clear the content (left over, from the previous run)
if|if
condition|(
name|fs
operator|.
name|exists
argument_list|(
name|tmpdir
argument_list|)
condition|)
block|{
comment|// Archive table in temp, maybe left over from failed deletion,
comment|// if not the cleaner will take care of them.
for|for
control|(
name|Path
name|tabledir
range|:
name|FSUtils
operator|.
name|getTableDirs
argument_list|(
name|fs
argument_list|,
name|tmpdir
argument_list|)
control|)
block|{
for|for
control|(
name|Path
name|regiondir
range|:
name|FSUtils
operator|.
name|getRegionDirs
argument_list|(
name|fs
argument_list|,
name|tabledir
argument_list|)
control|)
block|{
name|HFileArchiver
operator|.
name|archiveRegion
argument_list|(
name|fs
argument_list|,
name|this
operator|.
name|rootdir
argument_list|,
name|tabledir
argument_list|,
name|regiondir
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
operator|!
name|fs
operator|.
name|delete
argument_list|(
name|tmpdir
argument_list|,
literal|true
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Unable to clean the temp directory: "
operator|+
name|tmpdir
argument_list|)
throw|;
block|}
block|}
comment|// Create the temp directory
if|if
condition|(
operator|!
name|fs
operator|.
name|mkdirs
argument_list|(
name|tmpdir
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"HBase temp directory '"
operator|+
name|tmpdir
operator|+
literal|"' creation failure."
argument_list|)
throw|;
block|}
block|}
specifier|private
specifier|static
name|void
name|bootstrap
parameter_list|(
specifier|final
name|Path
name|rd
parameter_list|,
specifier|final
name|Configuration
name|c
parameter_list|)
throws|throws
name|IOException
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"BOOTSTRAP: creating hbase:meta region"
argument_list|)
expr_stmt|;
try|try
block|{
comment|// Bootstrapping, make sure blockcache is off.  Else, one will be
comment|// created here in bootstrap and it'll need to be cleaned up.  Better to
comment|// not make it in first place.  Turn off block caching for bootstrap.
comment|// Enable after.
name|HRegionInfo
name|metaHRI
init|=
operator|new
name|HRegionInfo
argument_list|(
name|HRegionInfo
operator|.
name|FIRST_META_REGIONINFO
argument_list|)
decl_stmt|;
name|setInfoFamilyCachingForMeta
argument_list|(
literal|false
argument_list|)
expr_stmt|;
name|HRegion
name|meta
init|=
name|HRegion
operator|.
name|createHRegion
argument_list|(
name|metaHRI
argument_list|,
name|rd
argument_list|,
name|c
argument_list|,
name|HTableDescriptor
operator|.
name|META_TABLEDESC
argument_list|)
decl_stmt|;
name|setInfoFamilyCachingForMeta
argument_list|(
literal|true
argument_list|)
expr_stmt|;
name|HRegion
operator|.
name|closeHRegion
argument_list|(
name|meta
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|e
operator|=
name|RemoteExceptionHandler
operator|.
name|checkIOException
argument_list|(
name|e
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|error
argument_list|(
literal|"bootstrap"
argument_list|,
name|e
argument_list|)
expr_stmt|;
throw|throw
name|e
throw|;
block|}
block|}
comment|/**    * Enable in memory caching for hbase:meta    */
specifier|public
specifier|static
name|void
name|setInfoFamilyCachingForMeta
parameter_list|(
specifier|final
name|boolean
name|b
parameter_list|)
block|{
for|for
control|(
name|HColumnDescriptor
name|hcd
range|:
name|HTableDescriptor
operator|.
name|META_TABLEDESC
operator|.
name|getColumnFamilies
argument_list|()
control|)
block|{
if|if
condition|(
name|Bytes
operator|.
name|equals
argument_list|(
name|hcd
operator|.
name|getName
argument_list|()
argument_list|,
name|HConstants
operator|.
name|CATALOG_FAMILY
argument_list|)
condition|)
block|{
name|hcd
operator|.
name|setBlockCacheEnabled
argument_list|(
name|b
argument_list|)
expr_stmt|;
name|hcd
operator|.
name|setInMemory
argument_list|(
name|b
argument_list|)
expr_stmt|;
block|}
block|}
block|}
specifier|public
name|void
name|deleteRegion
parameter_list|(
name|HRegionInfo
name|region
parameter_list|)
throws|throws
name|IOException
block|{
name|HFileArchiver
operator|.
name|archiveRegion
argument_list|(
name|conf
argument_list|,
name|fs
argument_list|,
name|region
argument_list|)
expr_stmt|;
block|}
specifier|public
name|void
name|deleteTable
parameter_list|(
name|TableName
name|tableName
parameter_list|)
throws|throws
name|IOException
block|{
name|fs
operator|.
name|delete
argument_list|(
name|FSUtils
operator|.
name|getTableDir
argument_list|(
name|rootdir
argument_list|,
name|tableName
argument_list|)
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
comment|/**    * Move the specified table to the hbase temp directory    * @param tableName Table name to move    * @return The temp location of the table moved    * @throws IOException in case of file-system failure    */
specifier|public
name|Path
name|moveTableToTemp
parameter_list|(
name|TableName
name|tableName
parameter_list|)
throws|throws
name|IOException
block|{
name|Path
name|srcPath
init|=
name|FSUtils
operator|.
name|getTableDir
argument_list|(
name|rootdir
argument_list|,
name|tableName
argument_list|)
decl_stmt|;
name|Path
name|tempPath
init|=
name|FSUtils
operator|.
name|getTableDir
argument_list|(
name|this
operator|.
name|tempdir
argument_list|,
name|tableName
argument_list|)
decl_stmt|;
comment|// Ensure temp exists
if|if
condition|(
operator|!
name|fs
operator|.
name|exists
argument_list|(
name|tempPath
operator|.
name|getParent
argument_list|()
argument_list|)
operator|&&
operator|!
name|fs
operator|.
name|mkdirs
argument_list|(
name|tempPath
operator|.
name|getParent
argument_list|()
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"HBase temp directory '"
operator|+
name|tempPath
operator|.
name|getParent
argument_list|()
operator|+
literal|"' creation failure."
argument_list|)
throw|;
block|}
if|if
condition|(
operator|!
name|fs
operator|.
name|rename
argument_list|(
name|srcPath
argument_list|,
name|tempPath
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Unable to move '"
operator|+
name|srcPath
operator|+
literal|"' to temp '"
operator|+
name|tempPath
operator|+
literal|"'"
argument_list|)
throw|;
block|}
return|return
name|tempPath
return|;
block|}
specifier|public
name|void
name|updateRegionInfo
parameter_list|(
name|HRegionInfo
name|region
parameter_list|)
block|{
comment|// TODO implement this.  i think this is currently broken in trunk i don't
comment|//      see this getting updated.
comment|//      @see HRegion.checkRegioninfoOnFilesystem()
block|}
specifier|public
name|void
name|deleteFamilyFromFS
parameter_list|(
name|HRegionInfo
name|region
parameter_list|,
name|byte
index|[]
name|familyName
parameter_list|)
throws|throws
name|IOException
block|{
comment|// archive family store files
name|Path
name|tableDir
init|=
name|FSUtils
operator|.
name|getTableDir
argument_list|(
name|rootdir
argument_list|,
name|region
operator|.
name|getTable
argument_list|()
argument_list|)
decl_stmt|;
name|HFileArchiver
operator|.
name|archiveFamily
argument_list|(
name|fs
argument_list|,
name|conf
argument_list|,
name|region
argument_list|,
name|tableDir
argument_list|,
name|familyName
argument_list|)
expr_stmt|;
comment|// delete the family folder
name|Path
name|familyDir
init|=
operator|new
name|Path
argument_list|(
name|tableDir
argument_list|,
operator|new
name|Path
argument_list|(
name|region
operator|.
name|getEncodedName
argument_list|()
argument_list|,
name|Bytes
operator|.
name|toString
argument_list|(
name|familyName
argument_list|)
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|fs
operator|.
name|delete
argument_list|(
name|familyDir
argument_list|,
literal|true
argument_list|)
operator|==
literal|false
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Could not delete family "
operator|+
name|Bytes
operator|.
name|toString
argument_list|(
name|familyName
argument_list|)
operator|+
literal|" from FileSystem for region "
operator|+
name|region
operator|.
name|getRegionNameAsString
argument_list|()
operator|+
literal|"("
operator|+
name|region
operator|.
name|getEncodedName
argument_list|()
operator|+
literal|")"
argument_list|)
throw|;
block|}
block|}
specifier|public
name|void
name|stop
parameter_list|()
block|{
if|if
condition|(
name|splitLogManager
operator|!=
literal|null
condition|)
block|{
name|this
operator|.
name|splitLogManager
operator|.
name|stop
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**    * Delete column of a table    * @param tableName    * @param familyName    * @return Modified HTableDescriptor with requested column deleted.    * @throws IOException    */
specifier|public
name|HTableDescriptor
name|deleteColumn
parameter_list|(
name|TableName
name|tableName
parameter_list|,
name|byte
index|[]
name|familyName
parameter_list|)
throws|throws
name|IOException
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"DeleteColumn. Table = "
operator|+
name|tableName
operator|+
literal|" family = "
operator|+
name|Bytes
operator|.
name|toString
argument_list|(
name|familyName
argument_list|)
argument_list|)
expr_stmt|;
name|HTableDescriptor
name|htd
init|=
name|this
operator|.
name|services
operator|.
name|getTableDescriptors
argument_list|()
operator|.
name|get
argument_list|(
name|tableName
argument_list|)
decl_stmt|;
name|htd
operator|.
name|removeFamily
argument_list|(
name|familyName
argument_list|)
expr_stmt|;
name|this
operator|.
name|services
operator|.
name|getTableDescriptors
argument_list|()
operator|.
name|add
argument_list|(
name|htd
argument_list|)
expr_stmt|;
return|return
name|htd
return|;
block|}
comment|/**    * Modify Column of a table    * @param tableName    * @param hcd HColumnDesciptor    * @return Modified HTableDescriptor with the column modified.    * @throws IOException    */
specifier|public
name|HTableDescriptor
name|modifyColumn
parameter_list|(
name|TableName
name|tableName
parameter_list|,
name|HColumnDescriptor
name|hcd
parameter_list|)
throws|throws
name|IOException
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"AddModifyColumn. Table = "
operator|+
name|tableName
operator|+
literal|" HCD = "
operator|+
name|hcd
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
name|HTableDescriptor
name|htd
init|=
name|this
operator|.
name|services
operator|.
name|getTableDescriptors
argument_list|()
operator|.
name|get
argument_list|(
name|tableName
argument_list|)
decl_stmt|;
name|byte
index|[]
name|familyName
init|=
name|hcd
operator|.
name|getName
argument_list|()
decl_stmt|;
if|if
condition|(
operator|!
name|htd
operator|.
name|hasFamily
argument_list|(
name|familyName
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|InvalidFamilyOperationException
argument_list|(
literal|"Family '"
operator|+
name|Bytes
operator|.
name|toString
argument_list|(
name|familyName
argument_list|)
operator|+
literal|"' doesn't exists so cannot be modified"
argument_list|)
throw|;
block|}
name|htd
operator|.
name|addFamily
argument_list|(
name|hcd
argument_list|)
expr_stmt|;
name|this
operator|.
name|services
operator|.
name|getTableDescriptors
argument_list|()
operator|.
name|add
argument_list|(
name|htd
argument_list|)
expr_stmt|;
return|return
name|htd
return|;
block|}
comment|/**    * Add column to a table    * @param tableName    * @param hcd    * @return Modified HTableDescriptor with new column added.    * @throws IOException    */
specifier|public
name|HTableDescriptor
name|addColumn
parameter_list|(
name|TableName
name|tableName
parameter_list|,
name|HColumnDescriptor
name|hcd
parameter_list|)
throws|throws
name|IOException
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"AddColumn. Table = "
operator|+
name|tableName
operator|+
literal|" HCD = "
operator|+
name|hcd
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
name|HTableDescriptor
name|htd
init|=
name|this
operator|.
name|services
operator|.
name|getTableDescriptors
argument_list|()
operator|.
name|get
argument_list|(
name|tableName
argument_list|)
decl_stmt|;
if|if
condition|(
name|htd
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|InvalidFamilyOperationException
argument_list|(
literal|"Family '"
operator|+
name|hcd
operator|.
name|getNameAsString
argument_list|()
operator|+
literal|"' cannot be modified as HTD is null"
argument_list|)
throw|;
block|}
name|htd
operator|.
name|addFamily
argument_list|(
name|hcd
argument_list|)
expr_stmt|;
name|this
operator|.
name|services
operator|.
name|getTableDescriptors
argument_list|()
operator|.
name|add
argument_list|(
name|htd
argument_list|)
expr_stmt|;
return|return
name|htd
return|;
block|}
specifier|private
name|NavigableMap
argument_list|<
name|HRegionInfo
argument_list|,
name|Result
argument_list|>
name|getServerUserRegions
parameter_list|(
name|ServerName
name|serverName
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
operator|!
name|this
operator|.
name|master
operator|.
name|isStopped
argument_list|()
condition|)
block|{
try|try
block|{
name|this
operator|.
name|master
operator|.
name|getCatalogTracker
argument_list|()
operator|.
name|waitForMeta
argument_list|()
expr_stmt|;
return|return
name|MetaReader
operator|.
name|getServerUserRegions
argument_list|(
name|this
operator|.
name|master
operator|.
name|getCatalogTracker
argument_list|()
argument_list|,
name|serverName
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
throw|throw
operator|(
name|InterruptedIOException
operator|)
operator|new
name|InterruptedIOException
argument_list|()
operator|.
name|initCause
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
return|return
literal|null
return|;
block|}
block|}
end_class

end_unit

