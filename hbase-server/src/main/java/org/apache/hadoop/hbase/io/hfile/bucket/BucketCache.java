begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Copyright The Apache Software Foundation  *  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software   * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|hfile
operator|.
name|bucket
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|File
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|FileInputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|FileOutputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|nio
operator|.
name|ByteBuffer
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Comparator
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Iterator
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|NavigableSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|PriorityQueue
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Set
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ArrayBlockingQueue
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|BlockingQueue
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ConcurrentHashMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ConcurrentMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ConcurrentSkipListSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|Executors
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ScheduledExecutorService
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|TimeUnit
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|atomic
operator|.
name|AtomicBoolean
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|atomic
operator|.
name|AtomicLong
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|atomic
operator|.
name|LongAdder
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|locks
operator|.
name|Lock
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|locks
operator|.
name|ReentrantLock
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|locks
operator|.
name|ReentrantReadWriteLock
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|function
operator|.
name|Consumer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HBaseConfiguration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|TableName
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|Admin
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|ByteBuffAllocator
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|ByteBuffAllocator
operator|.
name|Recycler
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|HeapSize
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|hfile
operator|.
name|BlockCache
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|hfile
operator|.
name|BlockCacheKey
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|hfile
operator|.
name|BlockCacheUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|hfile
operator|.
name|BlockPriority
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|hfile
operator|.
name|BlockType
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|hfile
operator|.
name|CacheStats
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|hfile
operator|.
name|Cacheable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|hfile
operator|.
name|CachedBlock
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|hfile
operator|.
name|HFileBlock
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|nio
operator|.
name|ByteBuff
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|nio
operator|.
name|RefCnt
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|protobuf
operator|.
name|ProtobufMagic
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|EnvironmentEdgeManager
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|HasThread
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|IdReadWriteLock
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|IdReadWriteLock
operator|.
name|ReferenceType
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|StringUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|yetus
operator|.
name|audience
operator|.
name|InterfaceAudience
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|Logger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|LoggerFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hbase
operator|.
name|thirdparty
operator|.
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|annotations
operator|.
name|VisibleForTesting
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hbase
operator|.
name|thirdparty
operator|.
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Preconditions
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hbase
operator|.
name|thirdparty
operator|.
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ThreadFactoryBuilder
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|shaded
operator|.
name|protobuf
operator|.
name|generated
operator|.
name|BucketCacheProtos
import|;
end_import

begin_comment
comment|/**  * BucketCache uses {@link BucketAllocator} to allocate/free blocks, and uses  * BucketCache#ramCache and BucketCache#backingMap in order to  * determine if a given element is in the cache. The bucket cache can use on-heap or  * off-heap memory {@link ByteBufferIOEngine} or in a file {@link FileIOEngine} to  * store/read the block data.  *  *<p>Eviction is via a similar algorithm as used in  * {@link org.apache.hadoop.hbase.io.hfile.LruBlockCache}  *  *<p>BucketCache can be used as mainly a block cache (see  * {@link org.apache.hadoop.hbase.io.hfile.CombinedBlockCache}), combined with  * a BlockCache to decrease CMS GC and heap fragmentation.  *  *<p>It also can be used as a secondary cache (e.g. using a file on ssd/fusionio to store  * blocks) to enlarge cache space via a victim cache.  */
end_comment

begin_class
annotation|@
name|InterfaceAudience
operator|.
name|Private
specifier|public
class|class
name|BucketCache
implements|implements
name|BlockCache
implements|,
name|HeapSize
block|{
specifier|private
specifier|static
specifier|final
name|Logger
name|LOG
init|=
name|LoggerFactory
operator|.
name|getLogger
argument_list|(
name|BucketCache
operator|.
name|class
argument_list|)
decl_stmt|;
comment|/** Priority buckets config */
specifier|static
specifier|final
name|String
name|SINGLE_FACTOR_CONFIG_NAME
init|=
literal|"hbase.bucketcache.single.factor"
decl_stmt|;
specifier|static
specifier|final
name|String
name|MULTI_FACTOR_CONFIG_NAME
init|=
literal|"hbase.bucketcache.multi.factor"
decl_stmt|;
specifier|static
specifier|final
name|String
name|MEMORY_FACTOR_CONFIG_NAME
init|=
literal|"hbase.bucketcache.memory.factor"
decl_stmt|;
specifier|static
specifier|final
name|String
name|EXTRA_FREE_FACTOR_CONFIG_NAME
init|=
literal|"hbase.bucketcache.extrafreefactor"
decl_stmt|;
specifier|static
specifier|final
name|String
name|ACCEPT_FACTOR_CONFIG_NAME
init|=
literal|"hbase.bucketcache.acceptfactor"
decl_stmt|;
specifier|static
specifier|final
name|String
name|MIN_FACTOR_CONFIG_NAME
init|=
literal|"hbase.bucketcache.minfactor"
decl_stmt|;
comment|/** Priority buckets */
annotation|@
name|VisibleForTesting
specifier|static
specifier|final
name|float
name|DEFAULT_SINGLE_FACTOR
init|=
literal|0.25f
decl_stmt|;
specifier|static
specifier|final
name|float
name|DEFAULT_MULTI_FACTOR
init|=
literal|0.50f
decl_stmt|;
specifier|static
specifier|final
name|float
name|DEFAULT_MEMORY_FACTOR
init|=
literal|0.25f
decl_stmt|;
specifier|static
specifier|final
name|float
name|DEFAULT_MIN_FACTOR
init|=
literal|0.85f
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|float
name|DEFAULT_EXTRA_FREE_FACTOR
init|=
literal|0.10f
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|float
name|DEFAULT_ACCEPT_FACTOR
init|=
literal|0.95f
decl_stmt|;
comment|// Number of blocks to clear for each of the bucket size that is full
specifier|private
specifier|static
specifier|final
name|int
name|DEFAULT_FREE_ENTIRE_BLOCK_FACTOR
init|=
literal|2
decl_stmt|;
comment|/** Statistics thread */
specifier|private
specifier|static
specifier|final
name|int
name|statThreadPeriod
init|=
literal|5
operator|*
literal|60
decl_stmt|;
specifier|final
specifier|static
name|int
name|DEFAULT_WRITER_THREADS
init|=
literal|3
decl_stmt|;
specifier|final
specifier|static
name|int
name|DEFAULT_WRITER_QUEUE_ITEMS
init|=
literal|64
decl_stmt|;
comment|// Store/read block data
specifier|transient
specifier|final
name|IOEngine
name|ioEngine
decl_stmt|;
comment|// Store the block in this map before writing it to cache
annotation|@
name|VisibleForTesting
specifier|transient
specifier|final
name|RAMCache
name|ramCache
decl_stmt|;
comment|// In this map, store the block's meta data like offset, length
annotation|@
name|VisibleForTesting
specifier|transient
name|ConcurrentHashMap
argument_list|<
name|BlockCacheKey
argument_list|,
name|BucketEntry
argument_list|>
name|backingMap
decl_stmt|;
comment|/**    * Flag if the cache is enabled or not... We shut it off if there are IO    * errors for some time, so that Bucket IO exceptions/errors don't bring down    * the HBase server.    */
specifier|private
specifier|volatile
name|boolean
name|cacheEnabled
decl_stmt|;
comment|/**    * A list of writer queues.  We have a queue per {@link WriterThread} we have running.    * In other words, the work adding blocks to the BucketCache is divided up amongst the    * running WriterThreads.  Its done by taking hash of the cache key modulo queue count.    * WriterThread when it runs takes whatever has been recently added and 'drains' the entries    * to the BucketCache.  It then updates the ramCache and backingMap accordingly.    */
annotation|@
name|VisibleForTesting
specifier|transient
specifier|final
name|ArrayList
argument_list|<
name|BlockingQueue
argument_list|<
name|RAMQueueEntry
argument_list|>
argument_list|>
name|writerQueues
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
annotation|@
name|VisibleForTesting
specifier|transient
specifier|final
name|WriterThread
index|[]
name|writerThreads
decl_stmt|;
comment|/** Volatile boolean to track if free space is in process or not */
specifier|private
specifier|volatile
name|boolean
name|freeInProgress
init|=
literal|false
decl_stmt|;
specifier|private
specifier|transient
specifier|final
name|Lock
name|freeSpaceLock
init|=
operator|new
name|ReentrantLock
argument_list|()
decl_stmt|;
specifier|private
specifier|final
name|LongAdder
name|realCacheSize
init|=
operator|new
name|LongAdder
argument_list|()
decl_stmt|;
specifier|private
specifier|final
name|LongAdder
name|heapSize
init|=
operator|new
name|LongAdder
argument_list|()
decl_stmt|;
comment|/** Current number of cached elements */
specifier|private
specifier|final
name|LongAdder
name|blockNumber
init|=
operator|new
name|LongAdder
argument_list|()
decl_stmt|;
comment|/** Cache access count (sequential ID) */
specifier|private
specifier|final
name|AtomicLong
name|accessCount
init|=
operator|new
name|AtomicLong
argument_list|()
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|int
name|DEFAULT_CACHE_WAIT_TIME
init|=
literal|50
decl_stmt|;
comment|// Used in test now. If the flag is false and the cache speed is very fast,
comment|// bucket cache will skip some blocks when caching. If the flag is true, we
comment|// will wait blocks flushed to IOEngine for some time when caching
name|boolean
name|wait_when_cache
init|=
literal|false
decl_stmt|;
specifier|private
specifier|final
name|BucketCacheStats
name|cacheStats
init|=
operator|new
name|BucketCacheStats
argument_list|()
decl_stmt|;
specifier|private
specifier|final
name|String
name|persistencePath
decl_stmt|;
specifier|private
specifier|final
name|long
name|cacheCapacity
decl_stmt|;
comment|/** Approximate block size */
specifier|private
specifier|final
name|long
name|blockSize
decl_stmt|;
comment|/** Duration of IO errors tolerated before we disable cache, 1 min as default */
specifier|private
specifier|final
name|int
name|ioErrorsTolerationDuration
decl_stmt|;
comment|// 1 min
specifier|public
specifier|static
specifier|final
name|int
name|DEFAULT_ERROR_TOLERATION_DURATION
init|=
literal|60
operator|*
literal|1000
decl_stmt|;
comment|// Start time of first IO error when reading or writing IO Engine, it will be
comment|// reset after a successful read/write.
specifier|private
specifier|volatile
name|long
name|ioErrorStartTime
init|=
operator|-
literal|1
decl_stmt|;
comment|/**    * A ReentrantReadWriteLock to lock on a particular block identified by offset.    * The purpose of this is to avoid freeing the block which is being read.    *<p>    * Key set of offsets in BucketCache is limited so soft reference is the best choice here.    */
annotation|@
name|VisibleForTesting
specifier|transient
specifier|final
name|IdReadWriteLock
argument_list|<
name|Long
argument_list|>
name|offsetLock
init|=
operator|new
name|IdReadWriteLock
argument_list|<>
argument_list|(
name|ReferenceType
operator|.
name|SOFT
argument_list|)
decl_stmt|;
specifier|private
specifier|final
name|NavigableSet
argument_list|<
name|BlockCacheKey
argument_list|>
name|blocksByHFile
init|=
operator|new
name|ConcurrentSkipListSet
argument_list|<>
argument_list|(
parameter_list|(
name|a
parameter_list|,
name|b
parameter_list|)
lambda|->
block|{
name|int
name|nameComparison
init|=
name|a
operator|.
name|getHfileName
argument_list|()
operator|.
name|compareTo
argument_list|(
name|b
operator|.
name|getHfileName
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|nameComparison
operator|!=
literal|0
condition|)
block|{
return|return
name|nameComparison
return|;
block|}
return|return
name|Long
operator|.
name|compare
argument_list|(
name|a
operator|.
name|getOffset
argument_list|()
argument_list|,
name|b
operator|.
name|getOffset
argument_list|()
argument_list|)
return|;
block|}
argument_list|)
decl_stmt|;
comment|/** Statistics thread schedule pool (for heavy debugging, could remove) */
specifier|private
specifier|transient
specifier|final
name|ScheduledExecutorService
name|scheduleThreadPool
init|=
name|Executors
operator|.
name|newScheduledThreadPool
argument_list|(
literal|1
argument_list|,
operator|new
name|ThreadFactoryBuilder
argument_list|()
operator|.
name|setNameFormat
argument_list|(
literal|"BucketCacheStatsExecutor"
argument_list|)
operator|.
name|setDaemon
argument_list|(
literal|true
argument_list|)
operator|.
name|build
argument_list|()
argument_list|)
decl_stmt|;
comment|// Allocate or free space for the block
specifier|private
specifier|transient
name|BucketAllocator
name|bucketAllocator
decl_stmt|;
comment|/** Acceptable size of cache (no evictions if size< acceptable) */
specifier|private
name|float
name|acceptableFactor
decl_stmt|;
comment|/** Minimum threshold of cache (when evicting, evict until size< min) */
specifier|private
name|float
name|minFactor
decl_stmt|;
comment|/** Free this floating point factor of extra blocks when evicting. For example free the number of blocks requested * (1 + extraFreeFactor) */
specifier|private
name|float
name|extraFreeFactor
decl_stmt|;
comment|/** Single access bucket size */
specifier|private
name|float
name|singleFactor
decl_stmt|;
comment|/** Multiple access bucket size */
specifier|private
name|float
name|multiFactor
decl_stmt|;
comment|/** In-memory bucket size */
specifier|private
name|float
name|memoryFactor
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|String
name|FILE_VERIFY_ALGORITHM
init|=
literal|"hbase.bucketcache.persistent.file.integrity.check.algorithm"
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|String
name|DEFAULT_FILE_VERIFY_ALGORITHM
init|=
literal|"MD5"
decl_stmt|;
comment|/**    * Use {@link java.security.MessageDigest} class's encryption algorithms to check    * persistent file integrity, default algorithm is MD5    * */
specifier|private
name|String
name|algorithm
decl_stmt|;
specifier|public
name|BucketCache
parameter_list|(
name|String
name|ioEngineName
parameter_list|,
name|long
name|capacity
parameter_list|,
name|int
name|blockSize
parameter_list|,
name|int
index|[]
name|bucketSizes
parameter_list|,
name|int
name|writerThreadNum
parameter_list|,
name|int
name|writerQLen
parameter_list|,
name|String
name|persistencePath
parameter_list|)
throws|throws
name|IOException
block|{
name|this
argument_list|(
name|ioEngineName
argument_list|,
name|capacity
argument_list|,
name|blockSize
argument_list|,
name|bucketSizes
argument_list|,
name|writerThreadNum
argument_list|,
name|writerQLen
argument_list|,
name|persistencePath
argument_list|,
name|DEFAULT_ERROR_TOLERATION_DURATION
argument_list|,
name|HBaseConfiguration
operator|.
name|create
argument_list|()
argument_list|)
expr_stmt|;
block|}
specifier|public
name|BucketCache
parameter_list|(
name|String
name|ioEngineName
parameter_list|,
name|long
name|capacity
parameter_list|,
name|int
name|blockSize
parameter_list|,
name|int
index|[]
name|bucketSizes
parameter_list|,
name|int
name|writerThreadNum
parameter_list|,
name|int
name|writerQLen
parameter_list|,
name|String
name|persistencePath
parameter_list|,
name|int
name|ioErrorsTolerationDuration
parameter_list|,
name|Configuration
name|conf
parameter_list|)
throws|throws
name|IOException
block|{
name|this
operator|.
name|algorithm
operator|=
name|conf
operator|.
name|get
argument_list|(
name|FILE_VERIFY_ALGORITHM
argument_list|,
name|DEFAULT_FILE_VERIFY_ALGORITHM
argument_list|)
expr_stmt|;
name|this
operator|.
name|ioEngine
operator|=
name|getIOEngineFromName
argument_list|(
name|ioEngineName
argument_list|,
name|capacity
argument_list|,
name|persistencePath
argument_list|)
expr_stmt|;
name|this
operator|.
name|writerThreads
operator|=
operator|new
name|WriterThread
index|[
name|writerThreadNum
index|]
expr_stmt|;
name|long
name|blockNumCapacity
init|=
name|capacity
operator|/
name|blockSize
decl_stmt|;
if|if
condition|(
name|blockNumCapacity
operator|>=
name|Integer
operator|.
name|MAX_VALUE
condition|)
block|{
comment|// Enough for about 32TB of cache!
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"Cache capacity is too large, only support 32TB now"
argument_list|)
throw|;
block|}
name|this
operator|.
name|acceptableFactor
operator|=
name|conf
operator|.
name|getFloat
argument_list|(
name|ACCEPT_FACTOR_CONFIG_NAME
argument_list|,
name|DEFAULT_ACCEPT_FACTOR
argument_list|)
expr_stmt|;
name|this
operator|.
name|minFactor
operator|=
name|conf
operator|.
name|getFloat
argument_list|(
name|MIN_FACTOR_CONFIG_NAME
argument_list|,
name|DEFAULT_MIN_FACTOR
argument_list|)
expr_stmt|;
name|this
operator|.
name|extraFreeFactor
operator|=
name|conf
operator|.
name|getFloat
argument_list|(
name|EXTRA_FREE_FACTOR_CONFIG_NAME
argument_list|,
name|DEFAULT_EXTRA_FREE_FACTOR
argument_list|)
expr_stmt|;
name|this
operator|.
name|singleFactor
operator|=
name|conf
operator|.
name|getFloat
argument_list|(
name|SINGLE_FACTOR_CONFIG_NAME
argument_list|,
name|DEFAULT_SINGLE_FACTOR
argument_list|)
expr_stmt|;
name|this
operator|.
name|multiFactor
operator|=
name|conf
operator|.
name|getFloat
argument_list|(
name|MULTI_FACTOR_CONFIG_NAME
argument_list|,
name|DEFAULT_MULTI_FACTOR
argument_list|)
expr_stmt|;
name|this
operator|.
name|memoryFactor
operator|=
name|conf
operator|.
name|getFloat
argument_list|(
name|MEMORY_FACTOR_CONFIG_NAME
argument_list|,
name|DEFAULT_MEMORY_FACTOR
argument_list|)
expr_stmt|;
name|sanityCheckConfigs
argument_list|()
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Instantiating BucketCache with acceptableFactor: "
operator|+
name|acceptableFactor
operator|+
literal|", minFactor: "
operator|+
name|minFactor
operator|+
literal|", extraFreeFactor: "
operator|+
name|extraFreeFactor
operator|+
literal|", singleFactor: "
operator|+
name|singleFactor
operator|+
literal|", multiFactor: "
operator|+
name|multiFactor
operator|+
literal|", memoryFactor: "
operator|+
name|memoryFactor
argument_list|)
expr_stmt|;
name|this
operator|.
name|cacheCapacity
operator|=
name|capacity
expr_stmt|;
name|this
operator|.
name|persistencePath
operator|=
name|persistencePath
expr_stmt|;
name|this
operator|.
name|blockSize
operator|=
name|blockSize
expr_stmt|;
name|this
operator|.
name|ioErrorsTolerationDuration
operator|=
name|ioErrorsTolerationDuration
expr_stmt|;
name|bucketAllocator
operator|=
operator|new
name|BucketAllocator
argument_list|(
name|capacity
argument_list|,
name|bucketSizes
argument_list|)
expr_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|writerThreads
operator|.
name|length
condition|;
operator|++
name|i
control|)
block|{
name|writerQueues
operator|.
name|add
argument_list|(
operator|new
name|ArrayBlockingQueue
argument_list|<>
argument_list|(
name|writerQLen
argument_list|)
argument_list|)
expr_stmt|;
block|}
assert|assert
name|writerQueues
operator|.
name|size
argument_list|()
operator|==
name|writerThreads
operator|.
name|length
assert|;
name|this
operator|.
name|ramCache
operator|=
operator|new
name|RAMCache
argument_list|()
expr_stmt|;
name|this
operator|.
name|backingMap
operator|=
operator|new
name|ConcurrentHashMap
argument_list|<>
argument_list|(
operator|(
name|int
operator|)
name|blockNumCapacity
argument_list|)
expr_stmt|;
if|if
condition|(
name|ioEngine
operator|.
name|isPersistent
argument_list|()
operator|&&
name|persistencePath
operator|!=
literal|null
condition|)
block|{
try|try
block|{
name|retrieveFromFile
argument_list|(
name|bucketSizes
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ioex
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Can't restore from file["
operator|+
name|persistencePath
operator|+
literal|"] because of "
argument_list|,
name|ioex
argument_list|)
expr_stmt|;
block|}
block|}
specifier|final
name|String
name|threadName
init|=
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|getName
argument_list|()
decl_stmt|;
name|this
operator|.
name|cacheEnabled
operator|=
literal|true
expr_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|writerThreads
operator|.
name|length
condition|;
operator|++
name|i
control|)
block|{
name|writerThreads
index|[
name|i
index|]
operator|=
operator|new
name|WriterThread
argument_list|(
name|writerQueues
operator|.
name|get
argument_list|(
name|i
argument_list|)
argument_list|)
expr_stmt|;
name|writerThreads
index|[
name|i
index|]
operator|.
name|setName
argument_list|(
name|threadName
operator|+
literal|"-BucketCacheWriter-"
operator|+
name|i
argument_list|)
expr_stmt|;
name|writerThreads
index|[
name|i
index|]
operator|.
name|setDaemon
argument_list|(
literal|true
argument_list|)
expr_stmt|;
block|}
name|startWriterThreads
argument_list|()
expr_stmt|;
comment|// Run the statistics thread periodically to print the cache statistics log
comment|// TODO: Add means of turning this off.  Bit obnoxious running thread just to make a log
comment|// every five minutes.
name|this
operator|.
name|scheduleThreadPool
operator|.
name|scheduleAtFixedRate
argument_list|(
operator|new
name|StatisticsThread
argument_list|(
name|this
argument_list|)
argument_list|,
name|statThreadPeriod
argument_list|,
name|statThreadPeriod
argument_list|,
name|TimeUnit
operator|.
name|SECONDS
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Started bucket cache; ioengine="
operator|+
name|ioEngineName
operator|+
literal|", capacity="
operator|+
name|StringUtils
operator|.
name|byteDesc
argument_list|(
name|capacity
argument_list|)
operator|+
literal|", blockSize="
operator|+
name|StringUtils
operator|.
name|byteDesc
argument_list|(
name|blockSize
argument_list|)
operator|+
literal|", writerThreadNum="
operator|+
name|writerThreadNum
operator|+
literal|", writerQLen="
operator|+
name|writerQLen
operator|+
literal|", persistencePath="
operator|+
name|persistencePath
operator|+
literal|", bucketAllocator="
operator|+
name|this
operator|.
name|bucketAllocator
operator|.
name|getClass
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
block|}
specifier|private
name|void
name|sanityCheckConfigs
parameter_list|()
block|{
name|Preconditions
operator|.
name|checkArgument
argument_list|(
name|acceptableFactor
operator|<=
literal|1
operator|&&
name|acceptableFactor
operator|>=
literal|0
argument_list|,
name|ACCEPT_FACTOR_CONFIG_NAME
operator|+
literal|" must be between 0.0 and 1.0"
argument_list|)
expr_stmt|;
name|Preconditions
operator|.
name|checkArgument
argument_list|(
name|minFactor
operator|<=
literal|1
operator|&&
name|minFactor
operator|>=
literal|0
argument_list|,
name|MIN_FACTOR_CONFIG_NAME
operator|+
literal|" must be between 0.0 and 1.0"
argument_list|)
expr_stmt|;
name|Preconditions
operator|.
name|checkArgument
argument_list|(
name|minFactor
operator|<=
name|acceptableFactor
argument_list|,
name|MIN_FACTOR_CONFIG_NAME
operator|+
literal|" must be<= "
operator|+
name|ACCEPT_FACTOR_CONFIG_NAME
argument_list|)
expr_stmt|;
name|Preconditions
operator|.
name|checkArgument
argument_list|(
name|extraFreeFactor
operator|>=
literal|0
argument_list|,
name|EXTRA_FREE_FACTOR_CONFIG_NAME
operator|+
literal|" must be greater than 0.0"
argument_list|)
expr_stmt|;
name|Preconditions
operator|.
name|checkArgument
argument_list|(
name|singleFactor
operator|<=
literal|1
operator|&&
name|singleFactor
operator|>=
literal|0
argument_list|,
name|SINGLE_FACTOR_CONFIG_NAME
operator|+
literal|" must be between 0.0 and 1.0"
argument_list|)
expr_stmt|;
name|Preconditions
operator|.
name|checkArgument
argument_list|(
name|multiFactor
operator|<=
literal|1
operator|&&
name|multiFactor
operator|>=
literal|0
argument_list|,
name|MULTI_FACTOR_CONFIG_NAME
operator|+
literal|" must be between 0.0 and 1.0"
argument_list|)
expr_stmt|;
name|Preconditions
operator|.
name|checkArgument
argument_list|(
name|memoryFactor
operator|<=
literal|1
operator|&&
name|memoryFactor
operator|>=
literal|0
argument_list|,
name|MEMORY_FACTOR_CONFIG_NAME
operator|+
literal|" must be between 0.0 and 1.0"
argument_list|)
expr_stmt|;
name|Preconditions
operator|.
name|checkArgument
argument_list|(
operator|(
name|singleFactor
operator|+
name|multiFactor
operator|+
name|memoryFactor
operator|)
operator|==
literal|1
argument_list|,
name|SINGLE_FACTOR_CONFIG_NAME
operator|+
literal|", "
operator|+
name|MULTI_FACTOR_CONFIG_NAME
operator|+
literal|", and "
operator|+
name|MEMORY_FACTOR_CONFIG_NAME
operator|+
literal|" segments must add up to 1.0"
argument_list|)
expr_stmt|;
block|}
comment|/**    * Called by the constructor to start the writer threads. Used by tests that need to override    * starting the threads.    */
annotation|@
name|VisibleForTesting
specifier|protected
name|void
name|startWriterThreads
parameter_list|()
block|{
for|for
control|(
name|WriterThread
name|thread
range|:
name|writerThreads
control|)
block|{
name|thread
operator|.
name|start
argument_list|()
expr_stmt|;
block|}
block|}
annotation|@
name|VisibleForTesting
name|boolean
name|isCacheEnabled
parameter_list|()
block|{
return|return
name|this
operator|.
name|cacheEnabled
return|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|getMaxSize
parameter_list|()
block|{
return|return
name|this
operator|.
name|cacheCapacity
return|;
block|}
specifier|public
name|String
name|getIoEngine
parameter_list|()
block|{
return|return
name|ioEngine
operator|.
name|toString
argument_list|()
return|;
block|}
comment|/**    * Get the IOEngine from the IO engine name    * @param ioEngineName    * @param capacity    * @param persistencePath    * @return the IOEngine    * @throws IOException    */
specifier|private
name|IOEngine
name|getIOEngineFromName
parameter_list|(
name|String
name|ioEngineName
parameter_list|,
name|long
name|capacity
parameter_list|,
name|String
name|persistencePath
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|ioEngineName
operator|.
name|startsWith
argument_list|(
literal|"file:"
argument_list|)
operator|||
name|ioEngineName
operator|.
name|startsWith
argument_list|(
literal|"files:"
argument_list|)
condition|)
block|{
comment|// In order to make the usage simple, we only need the prefix 'files:' in
comment|// document whether one or multiple file(s), but also support 'file:' for
comment|// the compatibility
name|String
index|[]
name|filePaths
init|=
name|ioEngineName
operator|.
name|substring
argument_list|(
name|ioEngineName
operator|.
name|indexOf
argument_list|(
literal|":"
argument_list|)
operator|+
literal|1
argument_list|)
operator|.
name|split
argument_list|(
name|FileIOEngine
operator|.
name|FILE_DELIMITER
argument_list|)
decl_stmt|;
return|return
operator|new
name|FileIOEngine
argument_list|(
name|capacity
argument_list|,
name|persistencePath
operator|!=
literal|null
argument_list|,
name|filePaths
argument_list|)
return|;
block|}
elseif|else
if|if
condition|(
name|ioEngineName
operator|.
name|startsWith
argument_list|(
literal|"offheap"
argument_list|)
condition|)
block|{
return|return
operator|new
name|ByteBufferIOEngine
argument_list|(
name|capacity
argument_list|)
return|;
block|}
elseif|else
if|if
condition|(
name|ioEngineName
operator|.
name|startsWith
argument_list|(
literal|"mmap:"
argument_list|)
condition|)
block|{
return|return
operator|new
name|ExclusiveMemoryMmapIOEngine
argument_list|(
name|ioEngineName
operator|.
name|substring
argument_list|(
literal|5
argument_list|)
argument_list|,
name|capacity
argument_list|)
return|;
block|}
elseif|else
if|if
condition|(
name|ioEngineName
operator|.
name|startsWith
argument_list|(
literal|"pmem:"
argument_list|)
condition|)
block|{
comment|// This mode of bucket cache creates an IOEngine over a file on the persistent memory
comment|// device. Since the persistent memory device has its own address space the contents
comment|// mapped to this address space does not get swapped out like in the case of mmapping
comment|// on to DRAM. Hence the cells created out of the hfile blocks in the pmem bucket cache
comment|// can be directly referred to without having to copy them onheap. Once the RPC is done,
comment|// the blocks can be returned back as in case of ByteBufferIOEngine.
return|return
operator|new
name|SharedMemoryMmapIOEngine
argument_list|(
name|ioEngineName
operator|.
name|substring
argument_list|(
literal|5
argument_list|)
argument_list|,
name|capacity
argument_list|)
return|;
block|}
else|else
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"Don't understand io engine name for cache- prefix with file:, files:, mmap: or offheap"
argument_list|)
throw|;
block|}
block|}
comment|/**    * Cache the block with the specified name and buffer.    * @param cacheKey block's cache key    * @param buf block buffer    */
annotation|@
name|Override
specifier|public
name|void
name|cacheBlock
parameter_list|(
name|BlockCacheKey
name|cacheKey
parameter_list|,
name|Cacheable
name|buf
parameter_list|)
block|{
name|cacheBlock
argument_list|(
name|cacheKey
argument_list|,
name|buf
argument_list|,
literal|false
argument_list|)
expr_stmt|;
block|}
comment|/**    * Cache the block with the specified name and buffer.    * @param cacheKey block's cache key    * @param cachedItem block buffer    * @param inMemory if block is in-memory    */
annotation|@
name|Override
specifier|public
name|void
name|cacheBlock
parameter_list|(
name|BlockCacheKey
name|cacheKey
parameter_list|,
name|Cacheable
name|cachedItem
parameter_list|,
name|boolean
name|inMemory
parameter_list|)
block|{
name|cacheBlockWithWait
argument_list|(
name|cacheKey
argument_list|,
name|cachedItem
argument_list|,
name|inMemory
argument_list|,
name|wait_when_cache
argument_list|)
expr_stmt|;
block|}
comment|/**    * Cache the block to ramCache    * @param cacheKey block's cache key    * @param cachedItem block buffer    * @param inMemory if block is in-memory    * @param wait if true, blocking wait when queue is full    */
specifier|public
name|void
name|cacheBlockWithWait
parameter_list|(
name|BlockCacheKey
name|cacheKey
parameter_list|,
name|Cacheable
name|cachedItem
parameter_list|,
name|boolean
name|inMemory
parameter_list|,
name|boolean
name|wait
parameter_list|)
block|{
if|if
condition|(
name|cacheEnabled
condition|)
block|{
if|if
condition|(
name|backingMap
operator|.
name|containsKey
argument_list|(
name|cacheKey
argument_list|)
operator|||
name|ramCache
operator|.
name|containsKey
argument_list|(
name|cacheKey
argument_list|)
condition|)
block|{
if|if
condition|(
name|BlockCacheUtil
operator|.
name|shouldReplaceExistingCacheBlock
argument_list|(
name|this
argument_list|,
name|cacheKey
argument_list|,
name|cachedItem
argument_list|)
condition|)
block|{
name|cacheBlockWithWaitInternal
argument_list|(
name|cacheKey
argument_list|,
name|cachedItem
argument_list|,
name|inMemory
argument_list|,
name|wait
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
name|cacheBlockWithWaitInternal
argument_list|(
name|cacheKey
argument_list|,
name|cachedItem
argument_list|,
name|inMemory
argument_list|,
name|wait
argument_list|)
expr_stmt|;
block|}
block|}
block|}
specifier|private
name|void
name|cacheBlockWithWaitInternal
parameter_list|(
name|BlockCacheKey
name|cacheKey
parameter_list|,
name|Cacheable
name|cachedItem
parameter_list|,
name|boolean
name|inMemory
parameter_list|,
name|boolean
name|wait
parameter_list|)
block|{
if|if
condition|(
operator|!
name|cacheEnabled
condition|)
block|{
return|return;
block|}
name|LOG
operator|.
name|trace
argument_list|(
literal|"Caching key={}, item={}"
argument_list|,
name|cacheKey
argument_list|,
name|cachedItem
argument_list|)
expr_stmt|;
comment|// Stuff the entry into the RAM cache so it can get drained to the persistent store
name|RAMQueueEntry
name|re
init|=
operator|new
name|RAMQueueEntry
argument_list|(
name|cacheKey
argument_list|,
name|cachedItem
argument_list|,
name|accessCount
operator|.
name|incrementAndGet
argument_list|()
argument_list|,
name|inMemory
argument_list|,
name|createRecycler
argument_list|(
name|cacheKey
argument_list|)
argument_list|)
decl_stmt|;
comment|/**      * Don't use ramCache.put(cacheKey, re) here. because there may be a existing entry with same      * key in ramCache, the heap size of bucket cache need to update if replacing entry from      * ramCache. But WriterThread will also remove entry from ramCache and update heap size, if      * using ramCache.put(), It's possible that the removed entry in WriterThread is not the correct      * one, then the heap size will mess up (HBASE-20789)      */
if|if
condition|(
name|ramCache
operator|.
name|putIfAbsent
argument_list|(
name|cacheKey
argument_list|,
name|re
argument_list|)
operator|!=
literal|null
condition|)
block|{
return|return;
block|}
name|int
name|queueNum
init|=
operator|(
name|cacheKey
operator|.
name|hashCode
argument_list|()
operator|&
literal|0x7FFFFFFF
operator|)
operator|%
name|writerQueues
operator|.
name|size
argument_list|()
decl_stmt|;
name|BlockingQueue
argument_list|<
name|RAMQueueEntry
argument_list|>
name|bq
init|=
name|writerQueues
operator|.
name|get
argument_list|(
name|queueNum
argument_list|)
decl_stmt|;
name|boolean
name|successfulAddition
init|=
literal|false
decl_stmt|;
if|if
condition|(
name|wait
condition|)
block|{
try|try
block|{
name|successfulAddition
operator|=
name|bq
operator|.
name|offer
argument_list|(
name|re
argument_list|,
name|DEFAULT_CACHE_WAIT_TIME
argument_list|,
name|TimeUnit
operator|.
name|MILLISECONDS
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|interrupt
argument_list|()
expr_stmt|;
block|}
block|}
else|else
block|{
name|successfulAddition
operator|=
name|bq
operator|.
name|offer
argument_list|(
name|re
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|!
name|successfulAddition
condition|)
block|{
name|ramCache
operator|.
name|remove
argument_list|(
name|cacheKey
argument_list|)
expr_stmt|;
name|cacheStats
operator|.
name|failInsert
argument_list|()
expr_stmt|;
block|}
else|else
block|{
name|this
operator|.
name|blockNumber
operator|.
name|increment
argument_list|()
expr_stmt|;
name|this
operator|.
name|heapSize
operator|.
name|add
argument_list|(
name|cachedItem
operator|.
name|heapSize
argument_list|()
argument_list|)
expr_stmt|;
name|blocksByHFile
operator|.
name|add
argument_list|(
name|cacheKey
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Get the buffer of the block with the specified key.    * @param key block's cache key    * @param caching true if the caller caches blocks on cache misses    * @param repeat Whether this is a repeat lookup for the same block    * @param updateCacheMetrics Whether we should update cache metrics or not    * @return buffer of specified cache key, or null if not in cache    */
annotation|@
name|Override
specifier|public
name|Cacheable
name|getBlock
parameter_list|(
name|BlockCacheKey
name|key
parameter_list|,
name|boolean
name|caching
parameter_list|,
name|boolean
name|repeat
parameter_list|,
name|boolean
name|updateCacheMetrics
parameter_list|)
block|{
if|if
condition|(
operator|!
name|cacheEnabled
condition|)
block|{
return|return
literal|null
return|;
block|}
name|RAMQueueEntry
name|re
init|=
name|ramCache
operator|.
name|get
argument_list|(
name|key
argument_list|)
decl_stmt|;
if|if
condition|(
name|re
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
name|updateCacheMetrics
condition|)
block|{
name|cacheStats
operator|.
name|hit
argument_list|(
name|caching
argument_list|,
name|key
operator|.
name|isPrimary
argument_list|()
argument_list|,
name|key
operator|.
name|getBlockType
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|re
operator|.
name|access
argument_list|(
name|accessCount
operator|.
name|incrementAndGet
argument_list|()
argument_list|)
expr_stmt|;
return|return
name|re
operator|.
name|getData
argument_list|()
return|;
block|}
name|BucketEntry
name|bucketEntry
init|=
name|backingMap
operator|.
name|get
argument_list|(
name|key
argument_list|)
decl_stmt|;
if|if
condition|(
name|bucketEntry
operator|!=
literal|null
condition|)
block|{
name|long
name|start
init|=
name|System
operator|.
name|nanoTime
argument_list|()
decl_stmt|;
name|ReentrantReadWriteLock
name|lock
init|=
name|offsetLock
operator|.
name|getLock
argument_list|(
name|bucketEntry
operator|.
name|offset
argument_list|()
argument_list|)
decl_stmt|;
try|try
block|{
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
comment|// We can not read here even if backingMap does contain the given key because its offset
comment|// maybe changed. If we lock BlockCacheKey instead of offset, then we can only check
comment|// existence here.
if|if
condition|(
name|bucketEntry
operator|.
name|equals
argument_list|(
name|backingMap
operator|.
name|get
argument_list|(
name|key
argument_list|)
argument_list|)
condition|)
block|{
comment|// Read the block from IOEngine based on the bucketEntry's offset and length, NOTICE: the
comment|// block will use the refCnt of bucketEntry, which means if two HFileBlock mapping to
comment|// the same BucketEntry, then all of the three will share the same refCnt.
name|Cacheable
name|cachedBlock
init|=
name|ioEngine
operator|.
name|read
argument_list|(
name|bucketEntry
argument_list|)
decl_stmt|;
if|if
condition|(
name|ioEngine
operator|.
name|usesSharedMemory
argument_list|()
condition|)
block|{
comment|// If IOEngine use shared memory, cachedBlock and BucketEntry will share the
comment|// same RefCnt, do retain here, in order to count the number of RPC references
name|cachedBlock
operator|.
name|retain
argument_list|()
expr_stmt|;
block|}
comment|// Update the cache statistics.
if|if
condition|(
name|updateCacheMetrics
condition|)
block|{
name|cacheStats
operator|.
name|hit
argument_list|(
name|caching
argument_list|,
name|key
operator|.
name|isPrimary
argument_list|()
argument_list|,
name|key
operator|.
name|getBlockType
argument_list|()
argument_list|)
expr_stmt|;
name|cacheStats
operator|.
name|ioHit
argument_list|(
name|System
operator|.
name|nanoTime
argument_list|()
operator|-
name|start
argument_list|)
expr_stmt|;
block|}
name|bucketEntry
operator|.
name|access
argument_list|(
name|accessCount
operator|.
name|incrementAndGet
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|this
operator|.
name|ioErrorStartTime
operator|>
literal|0
condition|)
block|{
name|ioErrorStartTime
operator|=
operator|-
literal|1
expr_stmt|;
block|}
return|return
name|cachedBlock
return|;
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|ioex
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Failed reading block "
operator|+
name|key
operator|+
literal|" from bucket cache"
argument_list|,
name|ioex
argument_list|)
expr_stmt|;
name|checkIOErrorIsTolerated
argument_list|()
expr_stmt|;
block|}
finally|finally
block|{
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
if|if
condition|(
operator|!
name|repeat
operator|&&
name|updateCacheMetrics
condition|)
block|{
name|cacheStats
operator|.
name|miss
argument_list|(
name|caching
argument_list|,
name|key
operator|.
name|isPrimary
argument_list|()
argument_list|,
name|key
operator|.
name|getBlockType
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
literal|null
return|;
block|}
annotation|@
name|VisibleForTesting
name|void
name|blockEvicted
parameter_list|(
name|BlockCacheKey
name|cacheKey
parameter_list|,
name|BucketEntry
name|bucketEntry
parameter_list|,
name|boolean
name|decrementBlockNumber
parameter_list|)
block|{
name|bucketAllocator
operator|.
name|freeBlock
argument_list|(
name|bucketEntry
operator|.
name|offset
argument_list|()
argument_list|)
expr_stmt|;
name|realCacheSize
operator|.
name|add
argument_list|(
operator|-
literal|1
operator|*
name|bucketEntry
operator|.
name|getLength
argument_list|()
argument_list|)
expr_stmt|;
name|blocksByHFile
operator|.
name|remove
argument_list|(
name|cacheKey
argument_list|)
expr_stmt|;
if|if
condition|(
name|decrementBlockNumber
condition|)
block|{
name|this
operator|.
name|blockNumber
operator|.
name|decrement
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**    * Try to evict the block from {@link BlockCache} by force. We'll call this in few cases:<br>    * 1. Close an HFile, and clear all cached blocks.<br>    * 2. Call {@link Admin#clearBlockCache(TableName)} to clear all blocks for a given table.<br>    *<p>    * Firstly, we'll try to remove the block from RAMCache. If it doesn't exist in RAMCache, then try    * to evict from backingMap. Here we only need to free the reference from bucket cache by calling    * {@link BucketEntry#markedAsEvicted}. If there're still some RPC referring this block, block can    * only be de-allocated when all of them release the block.    *<p>    * NOTICE: we need to grab the write offset lock firstly before releasing the reference from    * bucket cache. if we don't, we may read an {@link BucketEntry} with refCnt = 0 when    * {@link BucketCache#getBlock(BlockCacheKey, boolean, boolean, boolean)}, it's a memory leak.    * @param cacheKey Block to evict    * @return true to indicate whether we've evicted successfully or not.    */
annotation|@
name|Override
specifier|public
name|boolean
name|evictBlock
parameter_list|(
name|BlockCacheKey
name|cacheKey
parameter_list|)
block|{
if|if
condition|(
operator|!
name|cacheEnabled
condition|)
block|{
return|return
literal|false
return|;
block|}
name|boolean
name|existed
init|=
name|removeFromRamCache
argument_list|(
name|cacheKey
argument_list|)
decl_stmt|;
name|BucketEntry
name|be
init|=
name|backingMap
operator|.
name|get
argument_list|(
name|cacheKey
argument_list|)
decl_stmt|;
if|if
condition|(
name|be
operator|==
literal|null
condition|)
block|{
if|if
condition|(
name|existed
condition|)
block|{
name|cacheStats
operator|.
name|evicted
argument_list|(
literal|0
argument_list|,
name|cacheKey
operator|.
name|isPrimary
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
name|existed
return|;
block|}
else|else
block|{
return|return
name|be
operator|.
name|withWriteLock
argument_list|(
name|offsetLock
argument_list|,
name|be
operator|::
name|markAsEvicted
argument_list|)
return|;
block|}
block|}
specifier|private
name|Recycler
name|createRecycler
parameter_list|(
name|BlockCacheKey
name|cacheKey
parameter_list|)
block|{
return|return
parameter_list|()
lambda|->
block|{
if|if
condition|(
operator|!
name|cacheEnabled
condition|)
block|{
return|return;
block|}
name|boolean
name|existed
init|=
name|removeFromRamCache
argument_list|(
name|cacheKey
argument_list|)
decl_stmt|;
name|BucketEntry
name|be
init|=
name|backingMap
operator|.
name|get
argument_list|(
name|cacheKey
argument_list|)
decl_stmt|;
if|if
condition|(
name|be
operator|==
literal|null
operator|&&
name|existed
condition|)
block|{
name|cacheStats
operator|.
name|evicted
argument_list|(
literal|0
argument_list|,
name|cacheKey
operator|.
name|isPrimary
argument_list|()
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|be
operator|!=
literal|null
condition|)
block|{
name|be
operator|.
name|withWriteLock
argument_list|(
name|offsetLock
argument_list|,
parameter_list|()
lambda|->
block|{
if|if
condition|(
name|backingMap
operator|.
name|remove
argument_list|(
name|cacheKey
argument_list|,
name|be
argument_list|)
condition|)
block|{
name|blockEvicted
argument_list|(
name|cacheKey
argument_list|,
name|be
argument_list|,
operator|!
name|existed
argument_list|)
expr_stmt|;
name|cacheStats
operator|.
name|evicted
argument_list|(
name|be
operator|.
name|getCachedTime
argument_list|()
argument_list|,
name|cacheKey
operator|.
name|isPrimary
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
literal|null
return|;
block|}
argument_list|)
expr_stmt|;
block|}
block|}
return|;
block|}
specifier|private
name|boolean
name|removeFromRamCache
parameter_list|(
name|BlockCacheKey
name|cacheKey
parameter_list|)
block|{
return|return
name|ramCache
operator|.
name|remove
argument_list|(
name|cacheKey
argument_list|,
name|re
lambda|->
block|{
if|if
condition|(
name|re
operator|!=
literal|null
condition|)
block|{
name|this
operator|.
name|blockNumber
operator|.
name|decrement
argument_list|()
expr_stmt|;
name|this
operator|.
name|heapSize
operator|.
name|add
argument_list|(
operator|-
literal|1
operator|*
name|re
operator|.
name|getData
argument_list|()
operator|.
name|heapSize
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
argument_list|)
return|;
block|}
comment|/*    * Statistics thread.  Periodically output cache statistics to the log.    */
specifier|private
specifier|static
class|class
name|StatisticsThread
extends|extends
name|Thread
block|{
specifier|private
specifier|final
name|BucketCache
name|bucketCache
decl_stmt|;
specifier|public
name|StatisticsThread
parameter_list|(
name|BucketCache
name|bucketCache
parameter_list|)
block|{
name|super
argument_list|(
literal|"BucketCacheStatsThread"
argument_list|)
expr_stmt|;
name|setDaemon
argument_list|(
literal|true
argument_list|)
expr_stmt|;
name|this
operator|.
name|bucketCache
operator|=
name|bucketCache
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|run
parameter_list|()
block|{
name|bucketCache
operator|.
name|logStats
argument_list|()
expr_stmt|;
block|}
block|}
specifier|public
name|void
name|logStats
parameter_list|()
block|{
name|long
name|totalSize
init|=
name|bucketAllocator
operator|.
name|getTotalSize
argument_list|()
decl_stmt|;
name|long
name|usedSize
init|=
name|bucketAllocator
operator|.
name|getUsedSize
argument_list|()
decl_stmt|;
name|long
name|freeSize
init|=
name|totalSize
operator|-
name|usedSize
decl_stmt|;
name|long
name|cacheSize
init|=
name|getRealCacheSize
argument_list|()
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"failedBlockAdditions="
operator|+
name|cacheStats
operator|.
name|getFailedInserts
argument_list|()
operator|+
literal|", "
operator|+
literal|"totalSize="
operator|+
name|StringUtils
operator|.
name|byteDesc
argument_list|(
name|totalSize
argument_list|)
operator|+
literal|", "
operator|+
literal|"freeSize="
operator|+
name|StringUtils
operator|.
name|byteDesc
argument_list|(
name|freeSize
argument_list|)
operator|+
literal|", "
operator|+
literal|"usedSize="
operator|+
name|StringUtils
operator|.
name|byteDesc
argument_list|(
name|usedSize
argument_list|)
operator|+
literal|", "
operator|+
literal|"cacheSize="
operator|+
name|StringUtils
operator|.
name|byteDesc
argument_list|(
name|cacheSize
argument_list|)
operator|+
literal|", "
operator|+
literal|"accesses="
operator|+
name|cacheStats
operator|.
name|getRequestCount
argument_list|()
operator|+
literal|", "
operator|+
literal|"hits="
operator|+
name|cacheStats
operator|.
name|getHitCount
argument_list|()
operator|+
literal|", "
operator|+
literal|"IOhitsPerSecond="
operator|+
name|cacheStats
operator|.
name|getIOHitsPerSecond
argument_list|()
operator|+
literal|", "
operator|+
literal|"IOTimePerHit="
operator|+
name|String
operator|.
name|format
argument_list|(
literal|"%.2f"
argument_list|,
name|cacheStats
operator|.
name|getIOTimePerHit
argument_list|()
argument_list|)
operator|+
literal|", "
operator|+
literal|"hitRatio="
operator|+
operator|(
name|cacheStats
operator|.
name|getHitCount
argument_list|()
operator|==
literal|0
condition|?
literal|"0,"
else|:
operator|(
name|StringUtils
operator|.
name|formatPercent
argument_list|(
name|cacheStats
operator|.
name|getHitRatio
argument_list|()
argument_list|,
literal|2
argument_list|)
operator|+
literal|", "
operator|)
operator|)
operator|+
literal|"cachingAccesses="
operator|+
name|cacheStats
operator|.
name|getRequestCachingCount
argument_list|()
operator|+
literal|", "
operator|+
literal|"cachingHits="
operator|+
name|cacheStats
operator|.
name|getHitCachingCount
argument_list|()
operator|+
literal|", "
operator|+
literal|"cachingHitsRatio="
operator|+
operator|(
name|cacheStats
operator|.
name|getHitCachingCount
argument_list|()
operator|==
literal|0
condition|?
literal|"0,"
else|:
operator|(
name|StringUtils
operator|.
name|formatPercent
argument_list|(
name|cacheStats
operator|.
name|getHitCachingRatio
argument_list|()
argument_list|,
literal|2
argument_list|)
operator|+
literal|", "
operator|)
operator|)
operator|+
literal|"evictions="
operator|+
name|cacheStats
operator|.
name|getEvictionCount
argument_list|()
operator|+
literal|", "
operator|+
literal|"evicted="
operator|+
name|cacheStats
operator|.
name|getEvictedCount
argument_list|()
operator|+
literal|", "
operator|+
literal|"evictedPerRun="
operator|+
name|cacheStats
operator|.
name|evictedPerEviction
argument_list|()
argument_list|)
expr_stmt|;
name|cacheStats
operator|.
name|reset
argument_list|()
expr_stmt|;
block|}
specifier|public
name|long
name|getRealCacheSize
parameter_list|()
block|{
return|return
name|this
operator|.
name|realCacheSize
operator|.
name|sum
argument_list|()
return|;
block|}
specifier|public
name|long
name|acceptableSize
parameter_list|()
block|{
return|return
operator|(
name|long
operator|)
name|Math
operator|.
name|floor
argument_list|(
name|bucketAllocator
operator|.
name|getTotalSize
argument_list|()
operator|*
name|acceptableFactor
argument_list|)
return|;
block|}
annotation|@
name|VisibleForTesting
name|long
name|getPartitionSize
parameter_list|(
name|float
name|partitionFactor
parameter_list|)
block|{
return|return
operator|(
name|long
operator|)
name|Math
operator|.
name|floor
argument_list|(
name|bucketAllocator
operator|.
name|getTotalSize
argument_list|()
operator|*
name|partitionFactor
operator|*
name|minFactor
argument_list|)
return|;
block|}
comment|/**    * Return the count of bucketSizeinfos still need free space    */
specifier|private
name|int
name|bucketSizesAboveThresholdCount
parameter_list|(
name|float
name|minFactor
parameter_list|)
block|{
name|BucketAllocator
operator|.
name|IndexStatistics
index|[]
name|stats
init|=
name|bucketAllocator
operator|.
name|getIndexStatistics
argument_list|()
decl_stmt|;
name|int
name|fullCount
init|=
literal|0
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|stats
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|long
name|freeGoal
init|=
operator|(
name|long
operator|)
name|Math
operator|.
name|floor
argument_list|(
name|stats
index|[
name|i
index|]
operator|.
name|totalCount
argument_list|()
operator|*
operator|(
literal|1
operator|-
name|minFactor
operator|)
argument_list|)
decl_stmt|;
name|freeGoal
operator|=
name|Math
operator|.
name|max
argument_list|(
name|freeGoal
argument_list|,
literal|1
argument_list|)
expr_stmt|;
if|if
condition|(
name|stats
index|[
name|i
index|]
operator|.
name|freeCount
argument_list|()
operator|<
name|freeGoal
condition|)
block|{
name|fullCount
operator|++
expr_stmt|;
block|}
block|}
return|return
name|fullCount
return|;
block|}
comment|/**    * This method will find the buckets that are minimally occupied    * and are not reference counted and will free them completely    * without any constraint on the access times of the elements,    * and as a process will completely free at most the number of buckets    * passed, sometimes it might not due to changing refCounts    *    * @param completelyFreeBucketsNeeded number of buckets to free    **/
specifier|private
name|void
name|freeEntireBuckets
parameter_list|(
name|int
name|completelyFreeBucketsNeeded
parameter_list|)
block|{
if|if
condition|(
name|completelyFreeBucketsNeeded
operator|!=
literal|0
condition|)
block|{
comment|// First we will build a set where the offsets are reference counted, usually
comment|// this set is small around O(Handler Count) unless something else is wrong
name|Set
argument_list|<
name|Integer
argument_list|>
name|inUseBuckets
init|=
operator|new
name|HashSet
argument_list|<>
argument_list|()
decl_stmt|;
name|backingMap
operator|.
name|forEach
argument_list|(
parameter_list|(
name|k
parameter_list|,
name|be
parameter_list|)
lambda|->
block|{
if|if
condition|(
name|be
operator|.
name|isRpcRef
argument_list|()
condition|)
block|{
name|inUseBuckets
operator|.
name|add
argument_list|(
name|bucketAllocator
operator|.
name|getBucketIndex
argument_list|(
name|be
operator|.
name|offset
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
argument_list|)
expr_stmt|;
name|Set
argument_list|<
name|Integer
argument_list|>
name|candidateBuckets
init|=
name|bucketAllocator
operator|.
name|getLeastFilledBuckets
argument_list|(
name|inUseBuckets
argument_list|,
name|completelyFreeBucketsNeeded
argument_list|)
decl_stmt|;
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|BlockCacheKey
argument_list|,
name|BucketEntry
argument_list|>
name|entry
range|:
name|backingMap
operator|.
name|entrySet
argument_list|()
control|)
block|{
if|if
condition|(
name|candidateBuckets
operator|.
name|contains
argument_list|(
name|bucketAllocator
operator|.
name|getBucketIndex
argument_list|(
name|entry
operator|.
name|getValue
argument_list|()
operator|.
name|offset
argument_list|()
argument_list|)
argument_list|)
condition|)
block|{
name|entry
operator|.
name|getValue
argument_list|()
operator|.
name|withWriteLock
argument_list|(
name|offsetLock
argument_list|,
name|entry
operator|.
name|getValue
argument_list|()
operator|::
name|markStaleAsEvicted
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
comment|/**    * Free the space if the used size reaches acceptableSize() or one size block    * couldn't be allocated. When freeing the space, we use the LRU algorithm and    * ensure there must be some blocks evicted    * @param why Why we are being called    */
specifier|private
name|void
name|freeSpace
parameter_list|(
specifier|final
name|String
name|why
parameter_list|)
block|{
comment|// Ensure only one freeSpace progress at a time
if|if
condition|(
operator|!
name|freeSpaceLock
operator|.
name|tryLock
argument_list|()
condition|)
block|{
return|return;
block|}
try|try
block|{
name|freeInProgress
operator|=
literal|true
expr_stmt|;
name|long
name|bytesToFreeWithoutExtra
init|=
literal|0
decl_stmt|;
comment|// Calculate free byte for each bucketSizeinfo
name|StringBuilder
name|msgBuffer
init|=
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|?
operator|new
name|StringBuilder
argument_list|()
else|:
literal|null
decl_stmt|;
name|BucketAllocator
operator|.
name|IndexStatistics
index|[]
name|stats
init|=
name|bucketAllocator
operator|.
name|getIndexStatistics
argument_list|()
decl_stmt|;
name|long
index|[]
name|bytesToFreeForBucket
init|=
operator|new
name|long
index|[
name|stats
operator|.
name|length
index|]
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|stats
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|bytesToFreeForBucket
index|[
name|i
index|]
operator|=
literal|0
expr_stmt|;
name|long
name|freeGoal
init|=
operator|(
name|long
operator|)
name|Math
operator|.
name|floor
argument_list|(
name|stats
index|[
name|i
index|]
operator|.
name|totalCount
argument_list|()
operator|*
operator|(
literal|1
operator|-
name|minFactor
operator|)
argument_list|)
decl_stmt|;
name|freeGoal
operator|=
name|Math
operator|.
name|max
argument_list|(
name|freeGoal
argument_list|,
literal|1
argument_list|)
expr_stmt|;
if|if
condition|(
name|stats
index|[
name|i
index|]
operator|.
name|freeCount
argument_list|()
operator|<
name|freeGoal
condition|)
block|{
name|bytesToFreeForBucket
index|[
name|i
index|]
operator|=
name|stats
index|[
name|i
index|]
operator|.
name|itemSize
argument_list|()
operator|*
operator|(
name|freeGoal
operator|-
name|stats
index|[
name|i
index|]
operator|.
name|freeCount
argument_list|()
operator|)
expr_stmt|;
name|bytesToFreeWithoutExtra
operator|+=
name|bytesToFreeForBucket
index|[
name|i
index|]
expr_stmt|;
if|if
condition|(
name|msgBuffer
operator|!=
literal|null
condition|)
block|{
name|msgBuffer
operator|.
name|append
argument_list|(
literal|"Free for bucketSize("
operator|+
name|stats
index|[
name|i
index|]
operator|.
name|itemSize
argument_list|()
operator|+
literal|")="
operator|+
name|StringUtils
operator|.
name|byteDesc
argument_list|(
name|bytesToFreeForBucket
index|[
name|i
index|]
argument_list|)
operator|+
literal|", "
argument_list|)
expr_stmt|;
block|}
block|}
block|}
if|if
condition|(
name|msgBuffer
operator|!=
literal|null
condition|)
block|{
name|msgBuffer
operator|.
name|append
argument_list|(
literal|"Free for total="
operator|+
name|StringUtils
operator|.
name|byteDesc
argument_list|(
name|bytesToFreeWithoutExtra
argument_list|)
operator|+
literal|", "
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|bytesToFreeWithoutExtra
operator|<=
literal|0
condition|)
block|{
return|return;
block|}
name|long
name|currentSize
init|=
name|bucketAllocator
operator|.
name|getUsedSize
argument_list|()
decl_stmt|;
name|long
name|totalSize
init|=
name|bucketAllocator
operator|.
name|getTotalSize
argument_list|()
decl_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
operator|&&
name|msgBuffer
operator|!=
literal|null
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Free started because \""
operator|+
name|why
operator|+
literal|"\"; "
operator|+
name|msgBuffer
operator|.
name|toString
argument_list|()
operator|+
literal|" of current used="
operator|+
name|StringUtils
operator|.
name|byteDesc
argument_list|(
name|currentSize
argument_list|)
operator|+
literal|", actual cacheSize="
operator|+
name|StringUtils
operator|.
name|byteDesc
argument_list|(
name|realCacheSize
operator|.
name|sum
argument_list|()
argument_list|)
operator|+
literal|", total="
operator|+
name|StringUtils
operator|.
name|byteDesc
argument_list|(
name|totalSize
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|long
name|bytesToFreeWithExtra
init|=
operator|(
name|long
operator|)
name|Math
operator|.
name|floor
argument_list|(
name|bytesToFreeWithoutExtra
operator|*
operator|(
literal|1
operator|+
name|extraFreeFactor
operator|)
argument_list|)
decl_stmt|;
comment|// Instantiate priority buckets
name|BucketEntryGroup
name|bucketSingle
init|=
operator|new
name|BucketEntryGroup
argument_list|(
name|bytesToFreeWithExtra
argument_list|,
name|blockSize
argument_list|,
name|getPartitionSize
argument_list|(
name|singleFactor
argument_list|)
argument_list|)
decl_stmt|;
name|BucketEntryGroup
name|bucketMulti
init|=
operator|new
name|BucketEntryGroup
argument_list|(
name|bytesToFreeWithExtra
argument_list|,
name|blockSize
argument_list|,
name|getPartitionSize
argument_list|(
name|multiFactor
argument_list|)
argument_list|)
decl_stmt|;
name|BucketEntryGroup
name|bucketMemory
init|=
operator|new
name|BucketEntryGroup
argument_list|(
name|bytesToFreeWithExtra
argument_list|,
name|blockSize
argument_list|,
name|getPartitionSize
argument_list|(
name|memoryFactor
argument_list|)
argument_list|)
decl_stmt|;
comment|// Scan entire map putting bucket entry into appropriate bucket entry
comment|// group
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|BlockCacheKey
argument_list|,
name|BucketEntry
argument_list|>
name|bucketEntryWithKey
range|:
name|backingMap
operator|.
name|entrySet
argument_list|()
control|)
block|{
switch|switch
condition|(
name|bucketEntryWithKey
operator|.
name|getValue
argument_list|()
operator|.
name|getPriority
argument_list|()
condition|)
block|{
case|case
name|SINGLE
case|:
block|{
name|bucketSingle
operator|.
name|add
argument_list|(
name|bucketEntryWithKey
argument_list|)
expr_stmt|;
break|break;
block|}
case|case
name|MULTI
case|:
block|{
name|bucketMulti
operator|.
name|add
argument_list|(
name|bucketEntryWithKey
argument_list|)
expr_stmt|;
break|break;
block|}
case|case
name|MEMORY
case|:
block|{
name|bucketMemory
operator|.
name|add
argument_list|(
name|bucketEntryWithKey
argument_list|)
expr_stmt|;
break|break;
block|}
block|}
block|}
name|PriorityQueue
argument_list|<
name|BucketEntryGroup
argument_list|>
name|bucketQueue
init|=
operator|new
name|PriorityQueue
argument_list|<>
argument_list|(
literal|3
argument_list|,
name|Comparator
operator|.
name|comparingLong
argument_list|(
name|BucketEntryGroup
operator|::
name|overflow
argument_list|)
argument_list|)
decl_stmt|;
name|bucketQueue
operator|.
name|add
argument_list|(
name|bucketSingle
argument_list|)
expr_stmt|;
name|bucketQueue
operator|.
name|add
argument_list|(
name|bucketMulti
argument_list|)
expr_stmt|;
name|bucketQueue
operator|.
name|add
argument_list|(
name|bucketMemory
argument_list|)
expr_stmt|;
name|int
name|remainingBuckets
init|=
name|bucketQueue
operator|.
name|size
argument_list|()
decl_stmt|;
name|long
name|bytesFreed
init|=
literal|0
decl_stmt|;
name|BucketEntryGroup
name|bucketGroup
decl_stmt|;
while|while
condition|(
operator|(
name|bucketGroup
operator|=
name|bucketQueue
operator|.
name|poll
argument_list|()
operator|)
operator|!=
literal|null
condition|)
block|{
name|long
name|overflow
init|=
name|bucketGroup
operator|.
name|overflow
argument_list|()
decl_stmt|;
if|if
condition|(
name|overflow
operator|>
literal|0
condition|)
block|{
name|long
name|bucketBytesToFree
init|=
name|Math
operator|.
name|min
argument_list|(
name|overflow
argument_list|,
operator|(
name|bytesToFreeWithoutExtra
operator|-
name|bytesFreed
operator|)
operator|/
name|remainingBuckets
argument_list|)
decl_stmt|;
name|bytesFreed
operator|+=
name|bucketGroup
operator|.
name|free
argument_list|(
name|bucketBytesToFree
argument_list|)
expr_stmt|;
block|}
name|remainingBuckets
operator|--
expr_stmt|;
block|}
comment|// Check and free if there are buckets that still need freeing of space
if|if
condition|(
name|bucketSizesAboveThresholdCount
argument_list|(
name|minFactor
argument_list|)
operator|>
literal|0
condition|)
block|{
name|bucketQueue
operator|.
name|clear
argument_list|()
expr_stmt|;
name|remainingBuckets
operator|=
literal|3
expr_stmt|;
name|bucketQueue
operator|.
name|add
argument_list|(
name|bucketSingle
argument_list|)
expr_stmt|;
name|bucketQueue
operator|.
name|add
argument_list|(
name|bucketMulti
argument_list|)
expr_stmt|;
name|bucketQueue
operator|.
name|add
argument_list|(
name|bucketMemory
argument_list|)
expr_stmt|;
while|while
condition|(
operator|(
name|bucketGroup
operator|=
name|bucketQueue
operator|.
name|poll
argument_list|()
operator|)
operator|!=
literal|null
condition|)
block|{
name|long
name|bucketBytesToFree
init|=
operator|(
name|bytesToFreeWithExtra
operator|-
name|bytesFreed
operator|)
operator|/
name|remainingBuckets
decl_stmt|;
name|bytesFreed
operator|+=
name|bucketGroup
operator|.
name|free
argument_list|(
name|bucketBytesToFree
argument_list|)
expr_stmt|;
name|remainingBuckets
operator|--
expr_stmt|;
block|}
block|}
comment|// Even after the above free we might still need freeing because of the
comment|// De-fragmentation of the buckets (also called Slab Calcification problem), i.e
comment|// there might be some buckets where the occupancy is very sparse and thus are not
comment|// yielding the free for the other bucket sizes, the fix for this to evict some
comment|// of the buckets, we do this by evicting the buckets that are least fulled
name|freeEntireBuckets
argument_list|(
name|DEFAULT_FREE_ENTIRE_BLOCK_FACTOR
operator|*
name|bucketSizesAboveThresholdCount
argument_list|(
literal|1.0f
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|long
name|single
init|=
name|bucketSingle
operator|.
name|totalSize
argument_list|()
decl_stmt|;
name|long
name|multi
init|=
name|bucketMulti
operator|.
name|totalSize
argument_list|()
decl_stmt|;
name|long
name|memory
init|=
name|bucketMemory
operator|.
name|totalSize
argument_list|()
decl_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Bucket cache free space completed; "
operator|+
literal|"freed="
operator|+
name|StringUtils
operator|.
name|byteDesc
argument_list|(
name|bytesFreed
argument_list|)
operator|+
literal|", "
operator|+
literal|"total="
operator|+
name|StringUtils
operator|.
name|byteDesc
argument_list|(
name|totalSize
argument_list|)
operator|+
literal|", "
operator|+
literal|"single="
operator|+
name|StringUtils
operator|.
name|byteDesc
argument_list|(
name|single
argument_list|)
operator|+
literal|", "
operator|+
literal|"multi="
operator|+
name|StringUtils
operator|.
name|byteDesc
argument_list|(
name|multi
argument_list|)
operator|+
literal|", "
operator|+
literal|"memory="
operator|+
name|StringUtils
operator|.
name|byteDesc
argument_list|(
name|memory
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
block|}
catch|catch
parameter_list|(
name|Throwable
name|t
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failed freeing space"
argument_list|,
name|t
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|cacheStats
operator|.
name|evict
argument_list|()
expr_stmt|;
name|freeInProgress
operator|=
literal|false
expr_stmt|;
name|freeSpaceLock
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
comment|// This handles flushing the RAM cache to IOEngine.
annotation|@
name|VisibleForTesting
class|class
name|WriterThread
extends|extends
name|HasThread
block|{
specifier|private
specifier|final
name|BlockingQueue
argument_list|<
name|RAMQueueEntry
argument_list|>
name|inputQueue
decl_stmt|;
specifier|private
specifier|volatile
name|boolean
name|writerEnabled
init|=
literal|true
decl_stmt|;
name|WriterThread
parameter_list|(
name|BlockingQueue
argument_list|<
name|RAMQueueEntry
argument_list|>
name|queue
parameter_list|)
block|{
name|super
argument_list|(
literal|"BucketCacheWriterThread"
argument_list|)
expr_stmt|;
name|this
operator|.
name|inputQueue
operator|=
name|queue
expr_stmt|;
block|}
comment|// Used for test
annotation|@
name|VisibleForTesting
name|void
name|disableWriter
parameter_list|()
block|{
name|this
operator|.
name|writerEnabled
operator|=
literal|false
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|run
parameter_list|()
block|{
name|List
argument_list|<
name|RAMQueueEntry
argument_list|>
name|entries
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
try|try
block|{
while|while
condition|(
name|cacheEnabled
operator|&&
name|writerEnabled
condition|)
block|{
try|try
block|{
try|try
block|{
comment|// Blocks
name|entries
operator|=
name|getRAMQueueEntries
argument_list|(
name|inputQueue
argument_list|,
name|entries
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|ie
parameter_list|)
block|{
if|if
condition|(
operator|!
name|cacheEnabled
operator|||
operator|!
name|writerEnabled
condition|)
block|{
break|break;
block|}
block|}
name|doDrain
argument_list|(
name|entries
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|ioe
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"WriterThread encountered error"
argument_list|,
name|ioe
argument_list|)
expr_stmt|;
block|}
block|}
block|}
catch|catch
parameter_list|(
name|Throwable
name|t
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failed doing drain"
argument_list|,
name|t
argument_list|)
expr_stmt|;
block|}
name|LOG
operator|.
name|info
argument_list|(
name|this
operator|.
name|getName
argument_list|()
operator|+
literal|" exiting, cacheEnabled="
operator|+
name|cacheEnabled
argument_list|)
expr_stmt|;
block|}
comment|/**      * Put the new bucket entry into backingMap. Notice that we are allowed to replace the existing      * cache with a new block for the same cache key. there's a corner case: one thread cache a      * block in ramCache, copy to io-engine and add a bucket entry to backingMap. Caching another      * new block with the same cache key do the same thing for the same cache key, so if not evict      * the previous bucket entry, then memory leak happen because the previous bucketEntry is gone      * but the bucketAllocator do not free its memory.      * @see BlockCacheUtil#shouldReplaceExistingCacheBlock(BlockCache blockCache,BlockCacheKey      *      cacheKey, Cacheable newBlock)      * @param key Block cache key      * @param bucketEntry Bucket entry to put into backingMap.      */
specifier|private
name|void
name|putIntoBackingMap
parameter_list|(
name|BlockCacheKey
name|key
parameter_list|,
name|BucketEntry
name|bucketEntry
parameter_list|)
block|{
name|BucketEntry
name|previousEntry
init|=
name|backingMap
operator|.
name|put
argument_list|(
name|key
argument_list|,
name|bucketEntry
argument_list|)
decl_stmt|;
if|if
condition|(
name|previousEntry
operator|!=
literal|null
operator|&&
name|previousEntry
operator|!=
name|bucketEntry
condition|)
block|{
name|previousEntry
operator|.
name|withWriteLock
argument_list|(
name|offsetLock
argument_list|,
parameter_list|()
lambda|->
block|{
name|blockEvicted
argument_list|(
name|key
argument_list|,
name|previousEntry
argument_list|,
literal|false
argument_list|)
expr_stmt|;
return|return
literal|null
return|;
block|}
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**      * Flush the entries in ramCache to IOEngine and add bucket entry to backingMap.      * Process all that are passed in even if failure being sure to remove from ramCache else we'll      * never undo the references and we'll OOME.      * @param entries Presumes list passed in here will be processed by this invocation only. No      *   interference expected.      * @throws InterruptedException      */
annotation|@
name|VisibleForTesting
name|void
name|doDrain
parameter_list|(
specifier|final
name|List
argument_list|<
name|RAMQueueEntry
argument_list|>
name|entries
parameter_list|)
throws|throws
name|InterruptedException
block|{
if|if
condition|(
name|entries
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
return|return;
block|}
comment|// This method is a little hard to follow. We run through the passed in entries and for each
comment|// successful add, we add a non-null BucketEntry to the below bucketEntries.  Later we must
comment|// do cleanup making sure we've cleared ramCache of all entries regardless of whether we
comment|// successfully added the item to the bucketcache; if we don't do the cleanup, we'll OOME by
comment|// filling ramCache.  We do the clean up by again running through the passed in entries
comment|// doing extra work when we find a non-null bucketEntries corresponding entry.
specifier|final
name|int
name|size
init|=
name|entries
operator|.
name|size
argument_list|()
decl_stmt|;
name|BucketEntry
index|[]
name|bucketEntries
init|=
operator|new
name|BucketEntry
index|[
name|size
index|]
decl_stmt|;
comment|// Index updated inside loop if success or if we can't succeed. We retry if cache is full
comment|// when we go to add an entry by going around the loop again without upping the index.
name|int
name|index
init|=
literal|0
decl_stmt|;
while|while
condition|(
name|cacheEnabled
operator|&&
name|index
operator|<
name|size
condition|)
block|{
name|RAMQueueEntry
name|re
init|=
literal|null
decl_stmt|;
try|try
block|{
name|re
operator|=
name|entries
operator|.
name|get
argument_list|(
name|index
argument_list|)
expr_stmt|;
if|if
condition|(
name|re
operator|==
literal|null
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Couldn't get entry or changed on us; who else is messing with it?"
argument_list|)
expr_stmt|;
name|index
operator|++
expr_stmt|;
continue|continue;
block|}
name|BucketEntry
name|bucketEntry
init|=
name|re
operator|.
name|writeToCache
argument_list|(
name|ioEngine
argument_list|,
name|bucketAllocator
argument_list|,
name|realCacheSize
argument_list|)
decl_stmt|;
comment|// Successfully added. Up index and add bucketEntry. Clear io exceptions.
name|bucketEntries
index|[
name|index
index|]
operator|=
name|bucketEntry
expr_stmt|;
if|if
condition|(
name|ioErrorStartTime
operator|>
literal|0
condition|)
block|{
name|ioErrorStartTime
operator|=
operator|-
literal|1
expr_stmt|;
block|}
name|index
operator|++
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|BucketAllocatorException
name|fle
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failed allocation for "
operator|+
operator|(
name|re
operator|==
literal|null
condition|?
literal|""
else|:
name|re
operator|.
name|getKey
argument_list|()
operator|)
operator|+
literal|"; "
operator|+
name|fle
argument_list|)
expr_stmt|;
comment|// Presume can't add. Too big? Move index on. Entry will be cleared from ramCache below.
name|bucketEntries
index|[
name|index
index|]
operator|=
literal|null
expr_stmt|;
name|index
operator|++
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|CacheFullException
name|cfe
parameter_list|)
block|{
comment|// Cache full when we tried to add. Try freeing space and then retrying (don't up index)
if|if
condition|(
operator|!
name|freeInProgress
condition|)
block|{
name|freeSpace
argument_list|(
literal|"Full!"
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|Thread
operator|.
name|sleep
argument_list|(
literal|50
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|ioex
parameter_list|)
block|{
comment|// Hopefully transient. Retry. checkIOErrorIsTolerated disables cache if problem.
name|LOG
operator|.
name|error
argument_list|(
literal|"Failed writing to bucket cache"
argument_list|,
name|ioex
argument_list|)
expr_stmt|;
name|checkIOErrorIsTolerated
argument_list|()
expr_stmt|;
block|}
block|}
comment|// Make sure data pages are written on media before we update maps.
try|try
block|{
name|ioEngine
operator|.
name|sync
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ioex
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Failed syncing IO engine"
argument_list|,
name|ioex
argument_list|)
expr_stmt|;
name|checkIOErrorIsTolerated
argument_list|()
expr_stmt|;
comment|// Since we failed sync, free the blocks in bucket allocator
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|entries
operator|.
name|size
argument_list|()
condition|;
operator|++
name|i
control|)
block|{
if|if
condition|(
name|bucketEntries
index|[
name|i
index|]
operator|!=
literal|null
condition|)
block|{
name|bucketAllocator
operator|.
name|freeBlock
argument_list|(
name|bucketEntries
index|[
name|i
index|]
operator|.
name|offset
argument_list|()
argument_list|)
expr_stmt|;
name|bucketEntries
index|[
name|i
index|]
operator|=
literal|null
expr_stmt|;
block|}
block|}
block|}
comment|// Now add to backingMap if successfully added to bucket cache.  Remove from ramCache if
comment|// success or error.
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|size
condition|;
operator|++
name|i
control|)
block|{
name|BlockCacheKey
name|key
init|=
name|entries
operator|.
name|get
argument_list|(
name|i
argument_list|)
operator|.
name|getKey
argument_list|()
decl_stmt|;
comment|// Only add if non-null entry.
if|if
condition|(
name|bucketEntries
index|[
name|i
index|]
operator|!=
literal|null
condition|)
block|{
name|putIntoBackingMap
argument_list|(
name|key
argument_list|,
name|bucketEntries
index|[
name|i
index|]
argument_list|)
expr_stmt|;
block|}
comment|// Always remove from ramCache even if we failed adding it to the block cache above.
name|boolean
name|existed
init|=
name|ramCache
operator|.
name|remove
argument_list|(
name|key
argument_list|,
name|re
lambda|->
block|{
if|if
condition|(
name|re
operator|!=
literal|null
condition|)
block|{
name|heapSize
operator|.
name|add
argument_list|(
operator|-
literal|1
operator|*
name|re
operator|.
name|getData
argument_list|()
operator|.
name|heapSize
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|existed
operator|&&
name|bucketEntries
index|[
name|i
index|]
operator|!=
literal|null
condition|)
block|{
comment|// Block should have already been evicted. Remove it and free space.
specifier|final
name|BucketEntry
name|bucketEntry
init|=
name|bucketEntries
index|[
name|i
index|]
decl_stmt|;
name|bucketEntry
operator|.
name|withWriteLock
argument_list|(
name|offsetLock
argument_list|,
parameter_list|()
lambda|->
block|{
if|if
condition|(
name|backingMap
operator|.
name|remove
argument_list|(
name|key
argument_list|,
name|bucketEntry
argument_list|)
condition|)
block|{
name|blockEvicted
argument_list|(
name|key
argument_list|,
name|bucketEntry
argument_list|,
literal|false
argument_list|)
expr_stmt|;
block|}
return|return
literal|null
return|;
block|}
argument_list|)
expr_stmt|;
block|}
block|}
name|long
name|used
init|=
name|bucketAllocator
operator|.
name|getUsedSize
argument_list|()
decl_stmt|;
if|if
condition|(
name|used
operator|>
name|acceptableSize
argument_list|()
condition|)
block|{
name|freeSpace
argument_list|(
literal|"Used="
operator|+
name|used
operator|+
literal|"> acceptable="
operator|+
name|acceptableSize
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return;
block|}
block|}
comment|/**    * Blocks until elements available in {@code q} then tries to grab as many as possible before    * returning.    * @param receptacle Where to stash the elements taken from queue. We clear before we use it just    *          in case.    * @param q The queue to take from.    * @return {@code receptacle} laden with elements taken from the queue or empty if none found.    */
annotation|@
name|VisibleForTesting
specifier|static
name|List
argument_list|<
name|RAMQueueEntry
argument_list|>
name|getRAMQueueEntries
parameter_list|(
name|BlockingQueue
argument_list|<
name|RAMQueueEntry
argument_list|>
name|q
parameter_list|,
name|List
argument_list|<
name|RAMQueueEntry
argument_list|>
name|receptacle
parameter_list|)
throws|throws
name|InterruptedException
block|{
comment|// Clear sets all entries to null and sets size to 0. We retain allocations. Presume it
comment|// ok even if list grew to accommodate thousands.
name|receptacle
operator|.
name|clear
argument_list|()
expr_stmt|;
name|receptacle
operator|.
name|add
argument_list|(
name|q
operator|.
name|take
argument_list|()
argument_list|)
expr_stmt|;
name|q
operator|.
name|drainTo
argument_list|(
name|receptacle
argument_list|)
expr_stmt|;
return|return
name|receptacle
return|;
block|}
comment|/**    * @see #retrieveFromFile(int[])    */
annotation|@
name|edu
operator|.
name|umd
operator|.
name|cs
operator|.
name|findbugs
operator|.
name|annotations
operator|.
name|SuppressWarnings
argument_list|(
name|value
operator|=
literal|"OBL_UNSATISFIED_OBLIGATION"
argument_list|,
name|justification
operator|=
literal|"false positive, try-with-resources ensures close is called."
argument_list|)
specifier|private
name|void
name|persistToFile
parameter_list|()
throws|throws
name|IOException
block|{
assert|assert
operator|!
name|cacheEnabled
assert|;
if|if
condition|(
operator|!
name|ioEngine
operator|.
name|isPersistent
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Attempt to persist non-persistent cache mappings!"
argument_list|)
throw|;
block|}
try|try
init|(
name|FileOutputStream
name|fos
init|=
operator|new
name|FileOutputStream
argument_list|(
name|persistencePath
argument_list|,
literal|false
argument_list|)
init|)
block|{
name|fos
operator|.
name|write
argument_list|(
name|ProtobufMagic
operator|.
name|PB_MAGIC
argument_list|)
expr_stmt|;
name|BucketProtoUtils
operator|.
name|toPB
argument_list|(
name|this
argument_list|)
operator|.
name|writeDelimitedTo
argument_list|(
name|fos
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * @see #persistToFile()    */
specifier|private
name|void
name|retrieveFromFile
parameter_list|(
name|int
index|[]
name|bucketSizes
parameter_list|)
throws|throws
name|IOException
block|{
name|File
name|persistenceFile
init|=
operator|new
name|File
argument_list|(
name|persistencePath
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|persistenceFile
operator|.
name|exists
argument_list|()
condition|)
block|{
return|return;
block|}
assert|assert
operator|!
name|cacheEnabled
assert|;
try|try
init|(
name|FileInputStream
name|in
init|=
name|deleteFileOnClose
argument_list|(
name|persistenceFile
argument_list|)
init|)
block|{
name|int
name|pblen
init|=
name|ProtobufMagic
operator|.
name|lengthOfPBMagic
argument_list|()
decl_stmt|;
name|byte
index|[]
name|pbuf
init|=
operator|new
name|byte
index|[
name|pblen
index|]
decl_stmt|;
name|int
name|read
init|=
name|in
operator|.
name|read
argument_list|(
name|pbuf
argument_list|)
decl_stmt|;
if|if
condition|(
name|read
operator|!=
name|pblen
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Incorrect number of bytes read while checking for protobuf magic "
operator|+
literal|"number. Requested="
operator|+
name|pblen
operator|+
literal|", Received= "
operator|+
name|read
operator|+
literal|", File="
operator|+
name|persistencePath
argument_list|)
throw|;
block|}
if|if
condition|(
operator|!
name|ProtobufMagic
operator|.
name|isPBMagicPrefix
argument_list|(
name|pbuf
argument_list|)
condition|)
block|{
comment|// In 3.0 we have enough flexibility to dump the old cache data.
comment|// TODO: In 2.x line, this might need to be filled in to support reading the old format
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Persistence file does not start with protobuf magic number. "
operator|+
name|persistencePath
argument_list|)
throw|;
block|}
name|parsePB
argument_list|(
name|BucketCacheProtos
operator|.
name|BucketCacheEntry
operator|.
name|parseDelimitedFrom
argument_list|(
name|in
argument_list|)
argument_list|)
expr_stmt|;
name|bucketAllocator
operator|=
operator|new
name|BucketAllocator
argument_list|(
name|cacheCapacity
argument_list|,
name|bucketSizes
argument_list|,
name|backingMap
argument_list|,
name|realCacheSize
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Create an input stream that deletes the file after reading it. Use in try-with-resources to    * avoid this pattern where an exception thrown from a finally block may mask earlier exceptions:    *<pre>    *   File f = ...    *   try (FileInputStream fis = new FileInputStream(f)) {    *     // use the input stream    *   } finally {    *     if (!f.delete()) throw new IOException("failed to delete");    *   }    *</pre>    * @param file the file to read and delete    * @return a FileInputStream for the given file    * @throws IOException if there is a problem creating the stream    */
specifier|private
name|FileInputStream
name|deleteFileOnClose
parameter_list|(
specifier|final
name|File
name|file
parameter_list|)
throws|throws
name|IOException
block|{
return|return
operator|new
name|FileInputStream
argument_list|(
name|file
argument_list|)
block|{
annotation|@
name|Override
specifier|public
name|void
name|close
parameter_list|()
throws|throws
name|IOException
block|{
name|super
operator|.
name|close
argument_list|()
expr_stmt|;
if|if
condition|(
operator|!
name|file
operator|.
name|delete
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Failed deleting persistence file "
operator|+
name|file
operator|.
name|getAbsolutePath
argument_list|()
argument_list|)
throw|;
block|}
block|}
block|}
return|;
block|}
specifier|private
name|void
name|verifyCapacityAndClasses
parameter_list|(
name|long
name|capacitySize
parameter_list|,
name|String
name|ioclass
parameter_list|,
name|String
name|mapclass
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|capacitySize
operator|!=
name|cacheCapacity
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Mismatched cache capacity:"
operator|+
name|StringUtils
operator|.
name|byteDesc
argument_list|(
name|capacitySize
argument_list|)
operator|+
literal|", expected: "
operator|+
name|StringUtils
operator|.
name|byteDesc
argument_list|(
name|cacheCapacity
argument_list|)
argument_list|)
throw|;
block|}
if|if
condition|(
operator|!
name|ioEngine
operator|.
name|getClass
argument_list|()
operator|.
name|getName
argument_list|()
operator|.
name|equals
argument_list|(
name|ioclass
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Class name for IO engine mismatch: "
operator|+
name|ioclass
operator|+
literal|", expected:"
operator|+
name|ioEngine
operator|.
name|getClass
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|)
throw|;
block|}
if|if
condition|(
operator|!
name|backingMap
operator|.
name|getClass
argument_list|()
operator|.
name|getName
argument_list|()
operator|.
name|equals
argument_list|(
name|mapclass
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Class name for cache map mismatch: "
operator|+
name|mapclass
operator|+
literal|", expected:"
operator|+
name|backingMap
operator|.
name|getClass
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|)
throw|;
block|}
block|}
specifier|private
name|void
name|parsePB
parameter_list|(
name|BucketCacheProtos
operator|.
name|BucketCacheEntry
name|proto
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|proto
operator|.
name|hasChecksum
argument_list|()
condition|)
block|{
operator|(
operator|(
name|PersistentIOEngine
operator|)
name|ioEngine
operator|)
operator|.
name|verifyFileIntegrity
argument_list|(
name|proto
operator|.
name|getChecksum
argument_list|()
operator|.
name|toByteArray
argument_list|()
argument_list|,
name|algorithm
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// if has not checksum, it means the persistence file is old format
name|LOG
operator|.
name|info
argument_list|(
literal|"Persistent file is old format, it does not support verifying file integrity!"
argument_list|)
expr_stmt|;
block|}
name|verifyCapacityAndClasses
argument_list|(
name|proto
operator|.
name|getCacheCapacity
argument_list|()
argument_list|,
name|proto
operator|.
name|getIoClass
argument_list|()
argument_list|,
name|proto
operator|.
name|getMapClass
argument_list|()
argument_list|)
expr_stmt|;
name|backingMap
operator|=
name|BucketProtoUtils
operator|.
name|fromPB
argument_list|(
name|proto
operator|.
name|getDeserializersMap
argument_list|()
argument_list|,
name|proto
operator|.
name|getBackingMap
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|/**    * Check whether we tolerate IO error this time. If the duration of IOEngine    * throwing errors exceeds ioErrorsDurationTimeTolerated, we will disable the    * cache    */
specifier|private
name|void
name|checkIOErrorIsTolerated
parameter_list|()
block|{
name|long
name|now
init|=
name|EnvironmentEdgeManager
operator|.
name|currentTime
argument_list|()
decl_stmt|;
if|if
condition|(
name|this
operator|.
name|ioErrorStartTime
operator|>
literal|0
condition|)
block|{
if|if
condition|(
name|cacheEnabled
operator|&&
operator|(
name|now
operator|-
name|ioErrorStartTime
operator|)
operator|>
name|this
operator|.
name|ioErrorsTolerationDuration
condition|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"IO errors duration time has exceeded "
operator|+
name|ioErrorsTolerationDuration
operator|+
literal|"ms, disabling cache, please check your IOEngine"
argument_list|)
expr_stmt|;
name|disableCache
argument_list|()
expr_stmt|;
block|}
block|}
else|else
block|{
name|this
operator|.
name|ioErrorStartTime
operator|=
name|now
expr_stmt|;
block|}
block|}
comment|/**    * Used to shut down the cache -or- turn it off in the case of something broken.    */
specifier|private
name|void
name|disableCache
parameter_list|()
block|{
if|if
condition|(
operator|!
name|cacheEnabled
condition|)
return|return;
name|cacheEnabled
operator|=
literal|false
expr_stmt|;
name|ioEngine
operator|.
name|shutdown
argument_list|()
expr_stmt|;
name|this
operator|.
name|scheduleThreadPool
operator|.
name|shutdown
argument_list|()
expr_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|writerThreads
operator|.
name|length
condition|;
operator|++
name|i
control|)
name|writerThreads
index|[
name|i
index|]
operator|.
name|interrupt
argument_list|()
expr_stmt|;
name|this
operator|.
name|ramCache
operator|.
name|clear
argument_list|()
expr_stmt|;
if|if
condition|(
operator|!
name|ioEngine
operator|.
name|isPersistent
argument_list|()
operator|||
name|persistencePath
operator|==
literal|null
condition|)
block|{
comment|// If persistent ioengine and a path, we will serialize out the backingMap.
name|this
operator|.
name|backingMap
operator|.
name|clear
argument_list|()
expr_stmt|;
block|}
block|}
specifier|private
name|void
name|join
parameter_list|()
throws|throws
name|InterruptedException
block|{
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|writerThreads
operator|.
name|length
condition|;
operator|++
name|i
control|)
name|writerThreads
index|[
name|i
index|]
operator|.
name|join
argument_list|()
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|shutdown
parameter_list|()
block|{
name|disableCache
argument_list|()
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Shutdown bucket cache: IO persistent="
operator|+
name|ioEngine
operator|.
name|isPersistent
argument_list|()
operator|+
literal|"; path to write="
operator|+
name|persistencePath
argument_list|)
expr_stmt|;
if|if
condition|(
name|ioEngine
operator|.
name|isPersistent
argument_list|()
operator|&&
name|persistencePath
operator|!=
literal|null
condition|)
block|{
try|try
block|{
name|join
argument_list|()
expr_stmt|;
name|persistToFile
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ex
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Unable to persist data on exit: "
operator|+
name|ex
operator|.
name|toString
argument_list|()
argument_list|,
name|ex
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failed to persist data on exit"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
block|}
block|}
annotation|@
name|Override
specifier|public
name|CacheStats
name|getStats
parameter_list|()
block|{
return|return
name|cacheStats
return|;
block|}
specifier|public
name|BucketAllocator
name|getAllocator
parameter_list|()
block|{
return|return
name|this
operator|.
name|bucketAllocator
return|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|heapSize
parameter_list|()
block|{
return|return
name|this
operator|.
name|heapSize
operator|.
name|sum
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|size
parameter_list|()
block|{
return|return
name|this
operator|.
name|realCacheSize
operator|.
name|sum
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|getCurrentDataSize
parameter_list|()
block|{
return|return
name|size
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|getFreeSize
parameter_list|()
block|{
return|return
name|this
operator|.
name|bucketAllocator
operator|.
name|getFreeSize
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|getBlockCount
parameter_list|()
block|{
return|return
name|this
operator|.
name|blockNumber
operator|.
name|sum
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|getDataBlockCount
parameter_list|()
block|{
return|return
name|getBlockCount
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|getCurrentSize
parameter_list|()
block|{
return|return
name|this
operator|.
name|bucketAllocator
operator|.
name|getUsedSize
argument_list|()
return|;
block|}
specifier|protected
name|String
name|getAlgorithm
parameter_list|()
block|{
return|return
name|algorithm
return|;
block|}
comment|/**    * Evicts all blocks for a specific HFile.    *<p>    * This is used for evict-on-close to remove all blocks of a specific HFile.    *    * @return the number of blocks evicted    */
annotation|@
name|Override
specifier|public
name|int
name|evictBlocksByHfileName
parameter_list|(
name|String
name|hfileName
parameter_list|)
block|{
name|Set
argument_list|<
name|BlockCacheKey
argument_list|>
name|keySet
init|=
name|blocksByHFile
operator|.
name|subSet
argument_list|(
operator|new
name|BlockCacheKey
argument_list|(
name|hfileName
argument_list|,
name|Long
operator|.
name|MIN_VALUE
argument_list|)
argument_list|,
literal|true
argument_list|,
operator|new
name|BlockCacheKey
argument_list|(
name|hfileName
argument_list|,
name|Long
operator|.
name|MAX_VALUE
argument_list|)
argument_list|,
literal|true
argument_list|)
decl_stmt|;
name|int
name|numEvicted
init|=
literal|0
decl_stmt|;
for|for
control|(
name|BlockCacheKey
name|key
range|:
name|keySet
control|)
block|{
if|if
condition|(
name|evictBlock
argument_list|(
name|key
argument_list|)
condition|)
block|{
operator|++
name|numEvicted
expr_stmt|;
block|}
block|}
return|return
name|numEvicted
return|;
block|}
comment|/**    * Used to group bucket entries into priority buckets. There will be a    * BucketEntryGroup for each priority (single, multi, memory). Once bucketed,    * the eviction algorithm takes the appropriate number of elements out of each    * according to configuration parameters and their relative sizes.    */
specifier|private
class|class
name|BucketEntryGroup
block|{
specifier|private
name|CachedEntryQueue
name|queue
decl_stmt|;
specifier|private
name|long
name|totalSize
init|=
literal|0
decl_stmt|;
specifier|private
name|long
name|bucketSize
decl_stmt|;
specifier|public
name|BucketEntryGroup
parameter_list|(
name|long
name|bytesToFree
parameter_list|,
name|long
name|blockSize
parameter_list|,
name|long
name|bucketSize
parameter_list|)
block|{
name|this
operator|.
name|bucketSize
operator|=
name|bucketSize
expr_stmt|;
name|queue
operator|=
operator|new
name|CachedEntryQueue
argument_list|(
name|bytesToFree
argument_list|,
name|blockSize
argument_list|)
expr_stmt|;
name|totalSize
operator|=
literal|0
expr_stmt|;
block|}
specifier|public
name|void
name|add
parameter_list|(
name|Map
operator|.
name|Entry
argument_list|<
name|BlockCacheKey
argument_list|,
name|BucketEntry
argument_list|>
name|block
parameter_list|)
block|{
name|totalSize
operator|+=
name|block
operator|.
name|getValue
argument_list|()
operator|.
name|getLength
argument_list|()
expr_stmt|;
name|queue
operator|.
name|add
argument_list|(
name|block
argument_list|)
expr_stmt|;
block|}
specifier|public
name|long
name|free
parameter_list|(
name|long
name|toFree
parameter_list|)
block|{
name|Map
operator|.
name|Entry
argument_list|<
name|BlockCacheKey
argument_list|,
name|BucketEntry
argument_list|>
name|entry
decl_stmt|;
name|long
name|freedBytes
init|=
literal|0
decl_stmt|;
comment|// TODO avoid a cycling siutation. We find no block which is not in use and so no way to free
comment|// What to do then? Caching attempt fail? Need some changes in cacheBlock API?
while|while
condition|(
operator|(
name|entry
operator|=
name|queue
operator|.
name|pollLast
argument_list|()
operator|)
operator|!=
literal|null
condition|)
block|{
name|BucketEntry
name|be
init|=
name|entry
operator|.
name|getValue
argument_list|()
decl_stmt|;
if|if
condition|(
name|be
operator|.
name|withWriteLock
argument_list|(
name|offsetLock
argument_list|,
name|be
operator|::
name|markStaleAsEvicted
argument_list|)
condition|)
block|{
name|freedBytes
operator|+=
name|be
operator|.
name|getLength
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|freedBytes
operator|>=
name|toFree
condition|)
block|{
return|return
name|freedBytes
return|;
block|}
block|}
return|return
name|freedBytes
return|;
block|}
specifier|public
name|long
name|overflow
parameter_list|()
block|{
return|return
name|totalSize
operator|-
name|bucketSize
return|;
block|}
specifier|public
name|long
name|totalSize
parameter_list|()
block|{
return|return
name|totalSize
return|;
block|}
block|}
comment|/**    * Block Entry stored in the memory with key,data and so on    */
annotation|@
name|VisibleForTesting
specifier|static
class|class
name|RAMQueueEntry
block|{
specifier|private
specifier|final
name|BlockCacheKey
name|key
decl_stmt|;
specifier|private
specifier|final
name|Cacheable
name|data
decl_stmt|;
specifier|private
name|long
name|accessCounter
decl_stmt|;
specifier|private
name|boolean
name|inMemory
decl_stmt|;
specifier|private
specifier|final
name|Recycler
name|recycler
decl_stmt|;
name|RAMQueueEntry
parameter_list|(
name|BlockCacheKey
name|bck
parameter_list|,
name|Cacheable
name|data
parameter_list|,
name|long
name|accessCounter
parameter_list|,
name|boolean
name|inMemory
parameter_list|,
name|Recycler
name|recycler
parameter_list|)
block|{
name|this
operator|.
name|key
operator|=
name|bck
expr_stmt|;
name|this
operator|.
name|data
operator|=
name|data
expr_stmt|;
name|this
operator|.
name|accessCounter
operator|=
name|accessCounter
expr_stmt|;
name|this
operator|.
name|inMemory
operator|=
name|inMemory
expr_stmt|;
name|this
operator|.
name|recycler
operator|=
name|recycler
expr_stmt|;
block|}
specifier|public
name|Cacheable
name|getData
parameter_list|()
block|{
return|return
name|data
return|;
block|}
specifier|public
name|BlockCacheKey
name|getKey
parameter_list|()
block|{
return|return
name|key
return|;
block|}
specifier|public
name|void
name|access
parameter_list|(
name|long
name|accessCounter
parameter_list|)
block|{
name|this
operator|.
name|accessCounter
operator|=
name|accessCounter
expr_stmt|;
block|}
specifier|private
name|ByteBuffAllocator
name|getByteBuffAllocator
parameter_list|()
block|{
if|if
condition|(
name|data
operator|instanceof
name|HFileBlock
condition|)
block|{
return|return
operator|(
operator|(
name|HFileBlock
operator|)
name|data
operator|)
operator|.
name|getByteBuffAllocator
argument_list|()
return|;
block|}
return|return
name|ByteBuffAllocator
operator|.
name|HEAP
return|;
block|}
specifier|public
name|BucketEntry
name|writeToCache
parameter_list|(
specifier|final
name|IOEngine
name|ioEngine
parameter_list|,
specifier|final
name|BucketAllocator
name|alloc
parameter_list|,
specifier|final
name|LongAdder
name|realCacheSize
parameter_list|)
throws|throws
name|IOException
block|{
name|int
name|len
init|=
name|data
operator|.
name|getSerializedLength
argument_list|()
decl_stmt|;
comment|// This cacheable thing can't be serialized
if|if
condition|(
name|len
operator|==
literal|0
condition|)
block|{
return|return
literal|null
return|;
block|}
name|long
name|offset
init|=
name|alloc
operator|.
name|allocateBlock
argument_list|(
name|len
argument_list|)
decl_stmt|;
name|boolean
name|succ
init|=
literal|false
decl_stmt|;
name|BucketEntry
name|bucketEntry
init|=
literal|null
decl_stmt|;
try|try
block|{
name|bucketEntry
operator|=
operator|new
name|BucketEntry
argument_list|(
name|offset
argument_list|,
name|len
argument_list|,
name|accessCounter
argument_list|,
name|inMemory
argument_list|,
name|RefCnt
operator|.
name|create
argument_list|(
name|recycler
argument_list|)
argument_list|,
name|getByteBuffAllocator
argument_list|()
argument_list|)
expr_stmt|;
name|bucketEntry
operator|.
name|setDeserializerReference
argument_list|(
name|data
operator|.
name|getDeserializer
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|data
operator|instanceof
name|HFileBlock
condition|)
block|{
comment|// If an instance of HFileBlock, save on some allocations.
name|HFileBlock
name|block
init|=
operator|(
name|HFileBlock
operator|)
name|data
decl_stmt|;
name|ByteBuff
name|sliceBuf
init|=
name|block
operator|.
name|getBufferReadOnly
argument_list|()
decl_stmt|;
name|ByteBuffer
name|metadata
init|=
name|block
operator|.
name|getMetaData
argument_list|()
decl_stmt|;
name|ioEngine
operator|.
name|write
argument_list|(
name|sliceBuf
argument_list|,
name|offset
argument_list|)
expr_stmt|;
name|ioEngine
operator|.
name|write
argument_list|(
name|metadata
argument_list|,
name|offset
operator|+
name|len
operator|-
name|metadata
operator|.
name|limit
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// Only used for testing.
name|ByteBuffer
name|bb
init|=
name|ByteBuffer
operator|.
name|allocate
argument_list|(
name|len
argument_list|)
decl_stmt|;
name|data
operator|.
name|serialize
argument_list|(
name|bb
argument_list|,
literal|true
argument_list|)
expr_stmt|;
name|ioEngine
operator|.
name|write
argument_list|(
name|bb
argument_list|,
name|offset
argument_list|)
expr_stmt|;
block|}
name|succ
operator|=
literal|true
expr_stmt|;
block|}
finally|finally
block|{
if|if
condition|(
operator|!
name|succ
condition|)
block|{
name|alloc
operator|.
name|freeBlock
argument_list|(
name|offset
argument_list|)
expr_stmt|;
block|}
block|}
name|realCacheSize
operator|.
name|add
argument_list|(
name|len
argument_list|)
expr_stmt|;
return|return
name|bucketEntry
return|;
block|}
block|}
comment|/**    * Only used in test    * @throws InterruptedException    */
name|void
name|stopWriterThreads
parameter_list|()
throws|throws
name|InterruptedException
block|{
for|for
control|(
name|WriterThread
name|writerThread
range|:
name|writerThreads
control|)
block|{
name|writerThread
operator|.
name|disableWriter
argument_list|()
expr_stmt|;
name|writerThread
operator|.
name|interrupt
argument_list|()
expr_stmt|;
name|writerThread
operator|.
name|join
argument_list|()
expr_stmt|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|Iterator
argument_list|<
name|CachedBlock
argument_list|>
name|iterator
parameter_list|()
block|{
comment|// Don't bother with ramcache since stuff is in here only a little while.
specifier|final
name|Iterator
argument_list|<
name|Map
operator|.
name|Entry
argument_list|<
name|BlockCacheKey
argument_list|,
name|BucketEntry
argument_list|>
argument_list|>
name|i
init|=
name|this
operator|.
name|backingMap
operator|.
name|entrySet
argument_list|()
operator|.
name|iterator
argument_list|()
decl_stmt|;
return|return
operator|new
name|Iterator
argument_list|<
name|CachedBlock
argument_list|>
argument_list|()
block|{
specifier|private
specifier|final
name|long
name|now
init|=
name|System
operator|.
name|nanoTime
argument_list|()
decl_stmt|;
annotation|@
name|Override
specifier|public
name|boolean
name|hasNext
parameter_list|()
block|{
return|return
name|i
operator|.
name|hasNext
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|CachedBlock
name|next
parameter_list|()
block|{
specifier|final
name|Map
operator|.
name|Entry
argument_list|<
name|BlockCacheKey
argument_list|,
name|BucketEntry
argument_list|>
name|e
init|=
name|i
operator|.
name|next
argument_list|()
decl_stmt|;
return|return
operator|new
name|CachedBlock
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|String
name|toString
parameter_list|()
block|{
return|return
name|BlockCacheUtil
operator|.
name|toString
argument_list|(
name|this
argument_list|,
name|now
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|BlockPriority
name|getBlockPriority
parameter_list|()
block|{
return|return
name|e
operator|.
name|getValue
argument_list|()
operator|.
name|getPriority
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|BlockType
name|getBlockType
parameter_list|()
block|{
comment|// Not held by BucketEntry.  Could add it if wanted on BucketEntry creation.
return|return
literal|null
return|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|getOffset
parameter_list|()
block|{
return|return
name|e
operator|.
name|getKey
argument_list|()
operator|.
name|getOffset
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|getSize
parameter_list|()
block|{
return|return
name|e
operator|.
name|getValue
argument_list|()
operator|.
name|getLength
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|getCachedTime
parameter_list|()
block|{
return|return
name|e
operator|.
name|getValue
argument_list|()
operator|.
name|getCachedTime
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|String
name|getFilename
parameter_list|()
block|{
return|return
name|e
operator|.
name|getKey
argument_list|()
operator|.
name|getHfileName
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|int
name|compareTo
parameter_list|(
name|CachedBlock
name|other
parameter_list|)
block|{
name|int
name|diff
init|=
name|this
operator|.
name|getFilename
argument_list|()
operator|.
name|compareTo
argument_list|(
name|other
operator|.
name|getFilename
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|diff
operator|!=
literal|0
condition|)
return|return
name|diff
return|;
name|diff
operator|=
name|Long
operator|.
name|compare
argument_list|(
name|this
operator|.
name|getOffset
argument_list|()
argument_list|,
name|other
operator|.
name|getOffset
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|diff
operator|!=
literal|0
condition|)
return|return
name|diff
return|;
if|if
condition|(
name|other
operator|.
name|getCachedTime
argument_list|()
operator|<
literal|0
operator|||
name|this
operator|.
name|getCachedTime
argument_list|()
operator|<
literal|0
condition|)
block|{
throw|throw
operator|new
name|IllegalStateException
argument_list|(
literal|""
operator|+
name|this
operator|.
name|getCachedTime
argument_list|()
operator|+
literal|", "
operator|+
name|other
operator|.
name|getCachedTime
argument_list|()
argument_list|)
throw|;
block|}
return|return
name|Long
operator|.
name|compare
argument_list|(
name|other
operator|.
name|getCachedTime
argument_list|()
argument_list|,
name|this
operator|.
name|getCachedTime
argument_list|()
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|int
name|hashCode
parameter_list|()
block|{
return|return
name|e
operator|.
name|getKey
argument_list|()
operator|.
name|hashCode
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|equals
parameter_list|(
name|Object
name|obj
parameter_list|)
block|{
if|if
condition|(
name|obj
operator|instanceof
name|CachedBlock
condition|)
block|{
name|CachedBlock
name|cb
init|=
operator|(
name|CachedBlock
operator|)
name|obj
decl_stmt|;
return|return
name|compareTo
argument_list|(
name|cb
argument_list|)
operator|==
literal|0
return|;
block|}
else|else
block|{
return|return
literal|false
return|;
block|}
block|}
block|}
return|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|remove
parameter_list|()
block|{
throw|throw
operator|new
name|UnsupportedOperationException
argument_list|()
throw|;
block|}
block|}
return|;
block|}
annotation|@
name|Override
specifier|public
name|BlockCache
index|[]
name|getBlockCaches
parameter_list|()
block|{
return|return
literal|null
return|;
block|}
annotation|@
name|VisibleForTesting
specifier|public
name|int
name|getRpcRefCount
parameter_list|(
name|BlockCacheKey
name|cacheKey
parameter_list|)
block|{
name|BucketEntry
name|bucketEntry
init|=
name|backingMap
operator|.
name|get
argument_list|(
name|cacheKey
argument_list|)
decl_stmt|;
if|if
condition|(
name|bucketEntry
operator|!=
literal|null
condition|)
block|{
return|return
name|bucketEntry
operator|.
name|refCnt
argument_list|()
operator|-
operator|(
name|bucketEntry
operator|.
name|markedAsEvicted
operator|.
name|get
argument_list|()
condition|?
literal|0
else|:
literal|1
operator|)
return|;
block|}
return|return
literal|0
return|;
block|}
name|float
name|getAcceptableFactor
parameter_list|()
block|{
return|return
name|acceptableFactor
return|;
block|}
name|float
name|getMinFactor
parameter_list|()
block|{
return|return
name|minFactor
return|;
block|}
name|float
name|getExtraFreeFactor
parameter_list|()
block|{
return|return
name|extraFreeFactor
return|;
block|}
name|float
name|getSingleFactor
parameter_list|()
block|{
return|return
name|singleFactor
return|;
block|}
name|float
name|getMultiFactor
parameter_list|()
block|{
return|return
name|multiFactor
return|;
block|}
name|float
name|getMemoryFactor
parameter_list|()
block|{
return|return
name|memoryFactor
return|;
block|}
comment|/**    * Wrapped the delegate ConcurrentMap with maintaining its block's reference count.    */
specifier|static
class|class
name|RAMCache
block|{
comment|/**      * Defined the map as {@link ConcurrentHashMap} explicitly here, because in      * {@link RAMCache#get(BlockCacheKey)} and      * {@link RAMCache#putIfAbsent(BlockCacheKey, BucketCache.RAMQueueEntry)} , we need to      * guarantee the atomicity of map#computeIfPresent(key, func) and map#putIfAbsent(key, func).      * Besides, the func method can execute exactly once only when the key is present(or absent)      * and under the lock context. Otherwise, the reference count of block will be messed up.      * Notice that the {@link java.util.concurrent.ConcurrentSkipListMap} can not guarantee that.      */
specifier|final
name|ConcurrentHashMap
argument_list|<
name|BlockCacheKey
argument_list|,
name|RAMQueueEntry
argument_list|>
name|delegate
init|=
operator|new
name|ConcurrentHashMap
argument_list|<>
argument_list|()
decl_stmt|;
specifier|public
name|boolean
name|containsKey
parameter_list|(
name|BlockCacheKey
name|key
parameter_list|)
block|{
return|return
name|delegate
operator|.
name|containsKey
argument_list|(
name|key
argument_list|)
return|;
block|}
specifier|public
name|RAMQueueEntry
name|get
parameter_list|(
name|BlockCacheKey
name|key
parameter_list|)
block|{
return|return
name|delegate
operator|.
name|computeIfPresent
argument_list|(
name|key
argument_list|,
parameter_list|(
name|k
parameter_list|,
name|re
parameter_list|)
lambda|->
block|{
comment|// It'll be referenced by RPC, so retain atomically here. if the get and retain is not
comment|// atomic, another thread may remove and release the block, when retaining in this thread we
comment|// may retain a block with refCnt=0 which is disallowed. (see HBASE-22422)
name|re
operator|.
name|getData
argument_list|()
operator|.
name|retain
argument_list|()
expr_stmt|;
return|return
name|re
return|;
block|}
argument_list|)
return|;
block|}
comment|/**      * Return the previous associated value, or null if absent. It has the same meaning as      * {@link ConcurrentMap#putIfAbsent(Object, Object)}      */
specifier|public
name|RAMQueueEntry
name|putIfAbsent
parameter_list|(
name|BlockCacheKey
name|key
parameter_list|,
name|RAMQueueEntry
name|entry
parameter_list|)
block|{
name|AtomicBoolean
name|absent
init|=
operator|new
name|AtomicBoolean
argument_list|(
literal|false
argument_list|)
decl_stmt|;
name|RAMQueueEntry
name|re
init|=
name|delegate
operator|.
name|computeIfAbsent
argument_list|(
name|key
argument_list|,
name|k
lambda|->
block|{
comment|// The RAMCache reference to this entry, so reference count should be increment.
name|entry
operator|.
name|getData
argument_list|()
operator|.
name|retain
argument_list|()
expr_stmt|;
name|absent
operator|.
name|set
argument_list|(
literal|true
argument_list|)
expr_stmt|;
return|return
name|entry
return|;
block|}
argument_list|)
decl_stmt|;
return|return
name|absent
operator|.
name|get
argument_list|()
condition|?
literal|null
else|:
name|re
return|;
block|}
specifier|public
name|boolean
name|remove
parameter_list|(
name|BlockCacheKey
name|key
parameter_list|)
block|{
return|return
name|remove
argument_list|(
name|key
argument_list|,
name|re
lambda|->
block|{}
argument_list|)
return|;
block|}
comment|/**      * Defined an {@link Consumer} here, because once the removed entry release its reference count,      * then it's ByteBuffers may be recycled and accessing it outside this method will be thrown an      * exception. the consumer will access entry to remove before release its reference count.      * Notice, don't change its reference count in the {@link Consumer}      */
specifier|public
name|boolean
name|remove
parameter_list|(
name|BlockCacheKey
name|key
parameter_list|,
name|Consumer
argument_list|<
name|RAMQueueEntry
argument_list|>
name|action
parameter_list|)
block|{
name|RAMQueueEntry
name|previous
init|=
name|delegate
operator|.
name|remove
argument_list|(
name|key
argument_list|)
decl_stmt|;
name|action
operator|.
name|accept
argument_list|(
name|previous
argument_list|)
expr_stmt|;
if|if
condition|(
name|previous
operator|!=
literal|null
condition|)
block|{
name|previous
operator|.
name|getData
argument_list|()
operator|.
name|release
argument_list|()
expr_stmt|;
block|}
return|return
name|previous
operator|!=
literal|null
return|;
block|}
specifier|public
name|boolean
name|isEmpty
parameter_list|()
block|{
return|return
name|delegate
operator|.
name|isEmpty
argument_list|()
return|;
block|}
specifier|public
name|void
name|clear
parameter_list|()
block|{
name|Iterator
argument_list|<
name|Map
operator|.
name|Entry
argument_list|<
name|BlockCacheKey
argument_list|,
name|RAMQueueEntry
argument_list|>
argument_list|>
name|it
init|=
name|delegate
operator|.
name|entrySet
argument_list|()
operator|.
name|iterator
argument_list|()
decl_stmt|;
while|while
condition|(
name|it
operator|.
name|hasNext
argument_list|()
condition|)
block|{
name|RAMQueueEntry
name|re
init|=
name|it
operator|.
name|next
argument_list|()
operator|.
name|getValue
argument_list|()
decl_stmt|;
name|it
operator|.
name|remove
argument_list|()
expr_stmt|;
name|re
operator|.
name|getData
argument_list|()
operator|.
name|release
argument_list|()
expr_stmt|;
block|}
block|}
block|}
block|}
end_class

end_unit

