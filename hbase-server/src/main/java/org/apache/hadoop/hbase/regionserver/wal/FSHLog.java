begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|wal
package|;
end_package

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|wal
operator|.
name|DefaultWALProvider
operator|.
name|WAL_FILE_NAME_DELIMITER
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|FileNotFoundException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|InterruptedIOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|OutputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|lang
operator|.
name|reflect
operator|.
name|InvocationTargetException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|lang
operator|.
name|reflect
operator|.
name|Method
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|URLEncoder
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Arrays
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Comparator
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|NavigableMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Set
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|TreeMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|UUID
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|BlockingQueue
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ConcurrentHashMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ConcurrentMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ConcurrentSkipListMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|CopyOnWriteArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|CountDownLatch
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ExecutionException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ExecutorService
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|Executors
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|LinkedBlockingQueue
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|TimeUnit
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|atomic
operator|.
name|AtomicBoolean
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|atomic
operator|.
name|AtomicInteger
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|atomic
operator|.
name|AtomicLong
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|locks
operator|.
name|ReentrantLock
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|Log
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|LogFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FSDataOutputStream
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileStatus
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|PathFilter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|Cell
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|CellUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HBaseConfiguration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HConstants
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HRegionInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HTableDescriptor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|TableName
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|classification
operator|.
name|InterfaceAudience
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|Bytes
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|ClassSize
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|DrainBarrier
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|EnvironmentEdgeManager
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|FSUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|HasThread
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|Threads
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|wal
operator|.
name|DefaultWALProvider
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|wal
operator|.
name|WAL
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|wal
operator|.
name|WALFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|wal
operator|.
name|WALKey
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|wal
operator|.
name|WALPrettyPrinter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|wal
operator|.
name|WALProvider
operator|.
name|Writer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|wal
operator|.
name|WALSplitter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|DatanodeInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|StringUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|htrace
operator|.
name|NullScope
import|;
end_import

begin_import
import|import
name|org
operator|.
name|htrace
operator|.
name|Span
import|;
end_import

begin_import
import|import
name|org
operator|.
name|htrace
operator|.
name|Trace
import|;
end_import

begin_import
import|import
name|org
operator|.
name|htrace
operator|.
name|TraceScope
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|annotations
operator|.
name|VisibleForTesting
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|Maps
import|;
end_import

begin_import
import|import
name|com
operator|.
name|lmax
operator|.
name|disruptor
operator|.
name|BlockingWaitStrategy
import|;
end_import

begin_import
import|import
name|com
operator|.
name|lmax
operator|.
name|disruptor
operator|.
name|EventHandler
import|;
end_import

begin_import
import|import
name|com
operator|.
name|lmax
operator|.
name|disruptor
operator|.
name|ExceptionHandler
import|;
end_import

begin_import
import|import
name|com
operator|.
name|lmax
operator|.
name|disruptor
operator|.
name|LifecycleAware
import|;
end_import

begin_import
import|import
name|com
operator|.
name|lmax
operator|.
name|disruptor
operator|.
name|TimeoutException
import|;
end_import

begin_import
import|import
name|com
operator|.
name|lmax
operator|.
name|disruptor
operator|.
name|dsl
operator|.
name|Disruptor
import|;
end_import

begin_import
import|import
name|com
operator|.
name|lmax
operator|.
name|disruptor
operator|.
name|dsl
operator|.
name|ProducerType
import|;
end_import

begin_comment
comment|/**  * Implementation of {@link WAL} to go against {@link FileSystem}; i.e. keep WALs in HDFS.  * Only one WAL is ever being written at a time.  When a WAL hits a configured maximum size,  * it is rolled.  This is done internal to the implementation.  *  *<p>As data is flushed from the MemStore to other on-disk structures (files sorted by  * key, hfiles), a WAL becomes obsolete. We can let go of all the log edits/entries for a given  * HRegion-sequence id.  A bunch of work in the below is done keeping account of these region  * sequence ids -- what is flushed out to hfiles, and what is yet in WAL and in memory only.  *  *<p>It is only practical to delete entire files. Thus, we delete an entire on-disk file  *<code>F</code> when all of the edits in<code>F</code> have a log-sequence-id that's older  * (smaller) than the most-recent flush.  *  *<p>To read an WAL, call {@link WALFactory#createReader(org.apache.hadoop.fs.FileSystem,  * org.apache.hadoop.fs.Path)}.  */
end_comment

begin_class
annotation|@
name|InterfaceAudience
operator|.
name|Private
specifier|public
class|class
name|FSHLog
implements|implements
name|WAL
block|{
comment|// IMPLEMENTATION NOTES:
comment|//
comment|// At the core is a ring buffer.  Our ring buffer is the LMAX Disruptor.  It tries to
comment|// minimize synchronizations and volatile writes when multiple contending threads as is the case
comment|// here appending and syncing on a single WAL.  The Disruptor is configured to handle multiple
comment|// producers but it has one consumer only (the producers in HBase are IPC Handlers calling append
comment|// and then sync).  The single consumer/writer pulls the appends and syncs off the ring buffer.
comment|// When a handler calls sync, it is given back a future. The producer 'blocks' on the future so
comment|// it does not return until the sync completes.  The future is passed over the ring buffer from
comment|// the producer/handler to the consumer thread where it does its best to batch up the producer
comment|// syncs so one WAL sync actually spans multiple producer sync invocations.  How well the
comment|// batching works depends on the write rate; i.e. we tend to batch more in times of
comment|// high writes/syncs.
comment|//
comment|// Calls to append now also wait until the append has been done on the consumer side of the
comment|// disruptor.  We used to not wait but it makes the implemenation easier to grok if we have
comment|// the region edit/sequence id after the append returns.
comment|//
comment|// TODO: Handlers need to coordinate appending AND syncing.  Can we have the threads contend
comment|// once only?  Probably hard given syncs take way longer than an append.
comment|//
comment|// The consumer threads pass the syncs off to multiple syncing threads in a round robin fashion
comment|// to ensure we keep up back-to-back FS sync calls (FS sync calls are the long poll writing the
comment|// WAL).  The consumer thread passes the futures to the sync threads for it to complete
comment|// the futures when done.
comment|//
comment|// The 'sequence' in the below is the sequence of the append/sync on the ringbuffer.  It
comment|// acts as a sort-of transaction id.  It is always incrementing.
comment|//
comment|// The RingBufferEventHandler class hosts the ring buffer consuming code.  The threads that
comment|// do the actual FS sync are implementations of SyncRunner.  SafePointZigZagLatch is a
comment|// synchronization class used to halt the consumer at a safe point --  just after all outstanding
comment|// syncs and appends have completed -- so the log roller can swap the WAL out under it.
specifier|static
specifier|final
name|Log
name|LOG
init|=
name|LogFactory
operator|.
name|getLog
argument_list|(
name|FSHLog
operator|.
name|class
argument_list|)
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|int
name|DEFAULT_SLOW_SYNC_TIME_MS
init|=
literal|100
decl_stmt|;
comment|// in ms
comment|/**    * The nexus at which all incoming handlers meet.  Does appends and sync with an ordering.    * Appends and syncs are each put on the ring which means handlers need to    * smash up against the ring twice (can we make it once only? ... maybe not since time to append    * is so different from time to sync and sometimes we don't want to sync or we want to async    * the sync).  The ring is where we make sure of our ordering and it is also where we do    * batching up of handler sync calls.    */
specifier|private
specifier|final
name|Disruptor
argument_list|<
name|RingBufferTruck
argument_list|>
name|disruptor
decl_stmt|;
comment|/**    * An executorservice that runs the disrutpor AppendEventHandler append executor.    */
specifier|private
specifier|final
name|ExecutorService
name|appendExecutor
decl_stmt|;
comment|/**    * This fellow is run by the above appendExecutor service but it is all about batching up appends    * and syncs; it may shutdown without cleaning out the last few appends or syncs.  To guard    * against this, keep a reference to this handler and do explicit close on way out to make sure    * all flushed out before we exit.    */
specifier|private
specifier|final
name|RingBufferEventHandler
name|ringBufferEventHandler
decl_stmt|;
comment|/**    * Map of {@link SyncFuture}s keyed by Handler objects.  Used so we reuse SyncFutures.    * TODO: Reus FSWALEntry's rather than create them anew each time as we do SyncFutures here.    * TODO: Add a FSWalEntry and SyncFuture as thread locals on handlers rather than have them    * get them from this Map?    */
specifier|private
specifier|final
name|Map
argument_list|<
name|Thread
argument_list|,
name|SyncFuture
argument_list|>
name|syncFuturesByHandler
decl_stmt|;
comment|/**    * The highest known outstanding unsync'd WALEdit sequence number where sequence number is the    * ring buffer sequence.  Maintained by the ring buffer consumer.    */
specifier|private
specifier|volatile
name|long
name|highestUnsyncedSequence
init|=
operator|-
literal|1
decl_stmt|;
comment|/**    * Updated to the ring buffer sequence of the last successful sync call.  This can be less than    * {@link #highestUnsyncedSequence} for case where we have an append where a sync has not yet    * come in for it.  Maintained by the syncing threads.    */
specifier|private
specifier|final
name|AtomicLong
name|highestSyncedSequence
init|=
operator|new
name|AtomicLong
argument_list|(
literal|0
argument_list|)
decl_stmt|;
comment|/**    * file system instance    */
specifier|private
specifier|final
name|FileSystem
name|fs
decl_stmt|;
comment|/**    * WAL directory, where all WAL files would be placed.    */
specifier|private
specifier|final
name|Path
name|fullPathLogDir
decl_stmt|;
comment|/**    * dir path where old logs are kept.    */
specifier|private
specifier|final
name|Path
name|fullPathArchiveDir
decl_stmt|;
comment|/**    * Matches just those wal files that belong to this wal instance.    */
specifier|private
specifier|final
name|PathFilter
name|ourFiles
decl_stmt|;
comment|/**    * Prefix of a WAL file, usually the region server name it is hosted on.    */
specifier|private
specifier|final
name|String
name|logFilePrefix
decl_stmt|;
comment|/**    * Suffix included on generated wal file names     */
specifier|private
specifier|final
name|String
name|logFileSuffix
decl_stmt|;
comment|/**    * Prefix used when checking for wal membership.    */
specifier|private
specifier|final
name|String
name|prefixPathStr
decl_stmt|;
specifier|private
specifier|final
name|WALCoprocessorHost
name|coprocessorHost
decl_stmt|;
comment|/**    * conf object    */
specifier|private
specifier|final
name|Configuration
name|conf
decl_stmt|;
comment|/** Listeners that are called on WAL events. */
specifier|private
specifier|final
name|List
argument_list|<
name|WALActionsListener
argument_list|>
name|listeners
init|=
operator|new
name|CopyOnWriteArrayList
argument_list|<
name|WALActionsListener
argument_list|>
argument_list|()
decl_stmt|;
annotation|@
name|Override
specifier|public
name|void
name|registerWALActionsListener
parameter_list|(
specifier|final
name|WALActionsListener
name|listener
parameter_list|)
block|{
name|this
operator|.
name|listeners
operator|.
name|add
argument_list|(
name|listener
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|unregisterWALActionsListener
parameter_list|(
specifier|final
name|WALActionsListener
name|listener
parameter_list|)
block|{
return|return
name|this
operator|.
name|listeners
operator|.
name|remove
argument_list|(
name|listener
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|WALCoprocessorHost
name|getCoprocessorHost
parameter_list|()
block|{
return|return
name|coprocessorHost
return|;
block|}
comment|/**    * FSDataOutputStream associated with the current SequenceFile.writer    */
specifier|private
name|FSDataOutputStream
name|hdfs_out
decl_stmt|;
comment|// All about log rolling if not enough replicas outstanding.
comment|// Minimum tolerable replicas, if the actual value is lower than it, rollWriter will be triggered
specifier|private
specifier|final
name|int
name|minTolerableReplication
decl_stmt|;
comment|// DFSOutputStream.getNumCurrentReplicas method instance gotten via reflection.
specifier|private
specifier|final
name|Method
name|getNumCurrentReplicas
decl_stmt|;
specifier|private
specifier|final
name|Method
name|getPipeLine
decl_stmt|;
comment|// refers to DFSOutputStream.getPipeLine
specifier|private
specifier|final
name|int
name|slowSyncNs
decl_stmt|;
specifier|private
specifier|final
specifier|static
name|Object
index|[]
name|NO_ARGS
init|=
operator|new
name|Object
index|[]
block|{}
decl_stmt|;
comment|// If live datanode count is lower than the default replicas value,
comment|// RollWriter will be triggered in each sync(So the RollWriter will be
comment|// triggered one by one in a short time). Using it as a workaround to slow
comment|// down the roll frequency triggered by checkLowReplication().
specifier|private
specifier|final
name|AtomicInteger
name|consecutiveLogRolls
init|=
operator|new
name|AtomicInteger
argument_list|(
literal|0
argument_list|)
decl_stmt|;
specifier|private
specifier|final
name|int
name|lowReplicationRollLimit
decl_stmt|;
comment|// If consecutiveLogRolls is larger than lowReplicationRollLimit,
comment|// then disable the rolling in checkLowReplication().
comment|// Enable it if the replications recover.
specifier|private
specifier|volatile
name|boolean
name|lowReplicationRollEnabled
init|=
literal|true
decl_stmt|;
comment|/**    * Current log file.    */
specifier|volatile
name|Writer
name|writer
decl_stmt|;
comment|/** The barrier used to ensure that close() waits for all log rolls and flushes to finish. */
specifier|private
specifier|final
name|DrainBarrier
name|closeBarrier
init|=
operator|new
name|DrainBarrier
argument_list|()
decl_stmt|;
comment|/**    * This lock makes sure only one log roll runs at a time. Should not be taken while any other    * lock is held. We don't just use synchronized because that results in bogus and tedious    * findbugs warning when it thinks synchronized controls writer thread safety.  It is held when    * we are actually rolling the log.  It is checked when we are looking to see if we should roll    * the log or not.    */
specifier|private
specifier|final
name|ReentrantLock
name|rollWriterLock
init|=
operator|new
name|ReentrantLock
argument_list|(
literal|true
argument_list|)
decl_stmt|;
specifier|private
specifier|volatile
name|boolean
name|closed
init|=
literal|false
decl_stmt|;
specifier|private
specifier|final
name|AtomicBoolean
name|shutdown
init|=
operator|new
name|AtomicBoolean
argument_list|(
literal|false
argument_list|)
decl_stmt|;
comment|// The timestamp (in ms) when the log file was created.
specifier|private
specifier|final
name|AtomicLong
name|filenum
init|=
operator|new
name|AtomicLong
argument_list|(
operator|-
literal|1
argument_list|)
decl_stmt|;
comment|// Number of transactions in the current Wal.
specifier|private
specifier|final
name|AtomicInteger
name|numEntries
init|=
operator|new
name|AtomicInteger
argument_list|(
literal|0
argument_list|)
decl_stmt|;
comment|// If> than this size, roll the log.
specifier|private
specifier|final
name|long
name|logrollsize
decl_stmt|;
comment|/**    * The total size of wal    */
specifier|private
name|AtomicLong
name|totalLogSize
init|=
operator|new
name|AtomicLong
argument_list|(
literal|0
argument_list|)
decl_stmt|;
comment|/*    * If more than this many logs, force flush of oldest region to oldest edit    * goes to disk.  If too many and we crash, then will take forever replaying.    * Keep the number of logs tidy.    */
specifier|private
specifier|final
name|int
name|maxLogs
decl_stmt|;
comment|/** Number of log close errors tolerated before we abort */
specifier|private
specifier|final
name|int
name|closeErrorsTolerated
decl_stmt|;
specifier|private
specifier|final
name|AtomicInteger
name|closeErrorCount
init|=
operator|new
name|AtomicInteger
argument_list|()
decl_stmt|;
comment|// Region sequence id accounting across flushes and for knowing when we can GC a WAL.  These
comment|// sequence id numbers are by region and unrelated to the ring buffer sequence number accounting
comment|// done above in failedSequence, highest sequence, etc.
comment|/**    * This lock ties all operations on lowestFlushingStoreSequenceIds and    * oldestUnflushedStoreSequenceIds Maps with the exception of append's putIfAbsent call into    * oldestUnflushedStoreSequenceIds. We use these Maps to find out the low bound regions    * sequence id, or to find regions with old sequence ids to force flush; we are interested in    * old stuff not the new additions (TODO: IS THIS SAFE?  CHECK!).    */
specifier|private
specifier|final
name|Object
name|regionSequenceIdLock
init|=
operator|new
name|Object
argument_list|()
decl_stmt|;
comment|/**    * Map of encoded region names and family names to their OLDEST -- i.e. their first,    * the longest-lived -- sequence id in memstore. Note that this sequence id is the region    * sequence id.  This is not related to the id we use above for {@link #highestSyncedSequence}    * and {@link #highestUnsyncedSequence} which is the sequence from the disruptor    * ring buffer.    */
specifier|private
specifier|final
name|ConcurrentMap
argument_list|<
name|byte
index|[]
argument_list|,
name|ConcurrentMap
argument_list|<
name|byte
index|[]
argument_list|,
name|Long
argument_list|>
argument_list|>
name|oldestUnflushedStoreSequenceIds
init|=
operator|new
name|ConcurrentSkipListMap
argument_list|<
name|byte
index|[]
argument_list|,
name|ConcurrentMap
argument_list|<
name|byte
index|[]
argument_list|,
name|Long
argument_list|>
argument_list|>
argument_list|(
name|Bytes
operator|.
name|BYTES_COMPARATOR
argument_list|)
decl_stmt|;
comment|/**    * Map of encoded region names and family names to their lowest or OLDEST sequence/edit id in    * memstore currently being flushed out to hfiles. Entries are moved here from    * {@link #oldestUnflushedStoreSequenceIds} while the lock {@link #regionSequenceIdLock} is held    * (so movement between the Maps is atomic). This is not related to the id we use above for    * {@link #highestSyncedSequence} and {@link #highestUnsyncedSequence} which is the sequence from    * the disruptor ring buffer, an internal detail.    */
specifier|private
specifier|final
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|Long
argument_list|>
argument_list|>
name|lowestFlushingStoreSequenceIds
init|=
operator|new
name|TreeMap
argument_list|<
name|byte
index|[]
argument_list|,
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|Long
argument_list|>
argument_list|>
argument_list|(
name|Bytes
operator|.
name|BYTES_COMPARATOR
argument_list|)
decl_stmt|;
comment|/**   * Map of region encoded names to the latest region sequence id.  Updated on each append of   * WALEdits to the WAL. We create one map for each WAL file at the time it is rolled.   *<p>When deciding whether to archive a WAL file, we compare the sequence IDs in this map to   * {@link #lowestFlushingRegionSequenceIds} and {@link #oldestUnflushedRegionSequenceIds}.   * See {@link FSHLog#areAllRegionsFlushed(Map, Map, Map)} for more info.   *<p>   * This map uses byte[] as the key, and uses reference equality. It works in our use case as we   * use {@link HRegionInfo#getEncodedNameAsBytes()} as keys. For a given region, it always returns   * the same array.   */
specifier|private
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|Long
argument_list|>
name|highestRegionSequenceIds
init|=
operator|new
name|HashMap
argument_list|<
name|byte
index|[]
argument_list|,
name|Long
argument_list|>
argument_list|()
decl_stmt|;
comment|/**    * WAL Comparator; it compares the timestamp (log filenum), present in the log file name.    * Throws an IllegalArgumentException if used to compare paths from different wals.    */
specifier|public
specifier|final
name|Comparator
argument_list|<
name|Path
argument_list|>
name|LOG_NAME_COMPARATOR
init|=
operator|new
name|Comparator
argument_list|<
name|Path
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|int
name|compare
parameter_list|(
name|Path
name|o1
parameter_list|,
name|Path
name|o2
parameter_list|)
block|{
name|long
name|t1
init|=
name|getFileNumFromFileName
argument_list|(
name|o1
argument_list|)
decl_stmt|;
name|long
name|t2
init|=
name|getFileNumFromFileName
argument_list|(
name|o2
argument_list|)
decl_stmt|;
if|if
condition|(
name|t1
operator|==
name|t2
condition|)
return|return
literal|0
return|;
return|return
operator|(
name|t1
operator|>
name|t2
operator|)
condition|?
literal|1
else|:
operator|-
literal|1
return|;
block|}
block|}
decl_stmt|;
comment|/**    * Map of wal log file to the latest sequence ids of all regions it has entries of.    * The map is sorted by the log file creation timestamp (contained in the log file name).    */
specifier|private
name|NavigableMap
argument_list|<
name|Path
argument_list|,
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|Long
argument_list|>
argument_list|>
name|byWalRegionSequenceIds
init|=
operator|new
name|ConcurrentSkipListMap
argument_list|<
name|Path
argument_list|,
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|Long
argument_list|>
argument_list|>
argument_list|(
name|LOG_NAME_COMPARATOR
argument_list|)
decl_stmt|;
comment|/**    * Exception handler to pass the disruptor ringbuffer.  Same as native implementation only it    * logs using our logger instead of java native logger.    */
specifier|static
class|class
name|RingBufferExceptionHandler
implements|implements
name|ExceptionHandler
block|{
annotation|@
name|Override
specifier|public
name|void
name|handleEventException
parameter_list|(
name|Throwable
name|ex
parameter_list|,
name|long
name|sequence
parameter_list|,
name|Object
name|event
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Sequence="
operator|+
name|sequence
operator|+
literal|", event="
operator|+
name|event
argument_list|,
name|ex
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|RuntimeException
argument_list|(
name|ex
argument_list|)
throw|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|handleOnStartException
parameter_list|(
name|Throwable
name|ex
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|ex
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|RuntimeException
argument_list|(
name|ex
argument_list|)
throw|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|handleOnShutdownException
parameter_list|(
name|Throwable
name|ex
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|ex
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|RuntimeException
argument_list|(
name|ex
argument_list|)
throw|;
block|}
block|}
comment|/**    * Constructor.    *    * @param fs filesystem handle    * @param root path for stored and archived wals    * @param logDir dir where wals are stored    * @param conf configuration to use    * @throws IOException    */
specifier|public
name|FSHLog
parameter_list|(
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Path
name|root
parameter_list|,
specifier|final
name|String
name|logDir
parameter_list|,
specifier|final
name|Configuration
name|conf
parameter_list|)
throws|throws
name|IOException
block|{
name|this
argument_list|(
name|fs
argument_list|,
name|root
argument_list|,
name|logDir
argument_list|,
name|HConstants
operator|.
name|HREGION_OLDLOGDIR_NAME
argument_list|,
name|conf
argument_list|,
literal|null
argument_list|,
literal|true
argument_list|,
literal|null
argument_list|,
literal|null
argument_list|)
expr_stmt|;
block|}
comment|/**    * Create an edit log at the given<code>dir</code> location.    *    * You should never have to load an existing log. If there is a log at    * startup, it should have already been processed and deleted by the time the    * WAL object is started up.    *    * @param fs filesystem handle    * @param rootDir path to where logs and oldlogs    * @param logDir dir where wals are stored    * @param archiveDir dir where wals are archived    * @param conf configuration to use    * @param listeners Listeners on WAL events. Listeners passed here will    * be registered before we do anything else; e.g. the    * Constructor {@link #rollWriter()}.    * @param failIfWALExists If true IOException will be thrown if files related to this wal    *        already exist.    * @param prefix should always be hostname and port in distributed env and    *        it will be URL encoded before being used.    *        If prefix is null, "wal" will be used    * @param suffix will be url encoded. null is treated as empty. non-empty must start with    *        {@link DefaultWALProvider#WAL_FILE_NAME_DELIMITER}    * @throws IOException    */
specifier|public
name|FSHLog
parameter_list|(
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Path
name|rootDir
parameter_list|,
specifier|final
name|String
name|logDir
parameter_list|,
specifier|final
name|String
name|archiveDir
parameter_list|,
specifier|final
name|Configuration
name|conf
parameter_list|,
specifier|final
name|List
argument_list|<
name|WALActionsListener
argument_list|>
name|listeners
parameter_list|,
specifier|final
name|boolean
name|failIfWALExists
parameter_list|,
specifier|final
name|String
name|prefix
parameter_list|,
specifier|final
name|String
name|suffix
parameter_list|)
throws|throws
name|IOException
block|{
name|this
operator|.
name|fs
operator|=
name|fs
expr_stmt|;
name|this
operator|.
name|fullPathLogDir
operator|=
operator|new
name|Path
argument_list|(
name|rootDir
argument_list|,
name|logDir
argument_list|)
expr_stmt|;
name|this
operator|.
name|fullPathArchiveDir
operator|=
operator|new
name|Path
argument_list|(
name|rootDir
argument_list|,
name|archiveDir
argument_list|)
expr_stmt|;
name|this
operator|.
name|conf
operator|=
name|conf
expr_stmt|;
if|if
condition|(
operator|!
name|fs
operator|.
name|exists
argument_list|(
name|fullPathLogDir
argument_list|)
operator|&&
operator|!
name|fs
operator|.
name|mkdirs
argument_list|(
name|fullPathLogDir
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Unable to mkdir "
operator|+
name|fullPathLogDir
argument_list|)
throw|;
block|}
if|if
condition|(
operator|!
name|fs
operator|.
name|exists
argument_list|(
name|this
operator|.
name|fullPathArchiveDir
argument_list|)
condition|)
block|{
if|if
condition|(
operator|!
name|fs
operator|.
name|mkdirs
argument_list|(
name|this
operator|.
name|fullPathArchiveDir
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Unable to mkdir "
operator|+
name|this
operator|.
name|fullPathArchiveDir
argument_list|)
throw|;
block|}
block|}
comment|// If prefix is null||empty then just name it wal
name|this
operator|.
name|logFilePrefix
operator|=
name|prefix
operator|==
literal|null
operator|||
name|prefix
operator|.
name|isEmpty
argument_list|()
condition|?
literal|"wal"
else|:
name|URLEncoder
operator|.
name|encode
argument_list|(
name|prefix
argument_list|,
literal|"UTF8"
argument_list|)
expr_stmt|;
comment|// we only correctly differentiate suffices when numeric ones start with '.'
if|if
condition|(
name|suffix
operator|!=
literal|null
operator|&&
operator|!
operator|(
name|suffix
operator|.
name|isEmpty
argument_list|()
operator|)
operator|&&
operator|!
operator|(
name|suffix
operator|.
name|startsWith
argument_list|(
name|WAL_FILE_NAME_DELIMITER
argument_list|)
operator|)
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"wal suffix must start with '"
operator|+
name|WAL_FILE_NAME_DELIMITER
operator|+
literal|"' but instead was '"
operator|+
name|suffix
operator|+
literal|"'"
argument_list|)
throw|;
block|}
name|this
operator|.
name|logFileSuffix
operator|=
operator|(
name|suffix
operator|==
literal|null
operator|)
condition|?
literal|""
else|:
name|URLEncoder
operator|.
name|encode
argument_list|(
name|suffix
argument_list|,
literal|"UTF8"
argument_list|)
expr_stmt|;
name|this
operator|.
name|prefixPathStr
operator|=
operator|new
name|Path
argument_list|(
name|fullPathLogDir
argument_list|,
name|logFilePrefix
operator|+
name|WAL_FILE_NAME_DELIMITER
argument_list|)
operator|.
name|toString
argument_list|()
expr_stmt|;
name|this
operator|.
name|ourFiles
operator|=
operator|new
name|PathFilter
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|boolean
name|accept
parameter_list|(
specifier|final
name|Path
name|fileName
parameter_list|)
block|{
comment|// The path should start with dir/<prefix> and end with our suffix
specifier|final
name|String
name|fileNameString
init|=
name|fileName
operator|.
name|toString
argument_list|()
decl_stmt|;
if|if
condition|(
operator|!
name|fileNameString
operator|.
name|startsWith
argument_list|(
name|prefixPathStr
argument_list|)
condition|)
block|{
return|return
literal|false
return|;
block|}
if|if
condition|(
name|logFileSuffix
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
comment|// in the case of the null suffix, we need to ensure the filename ends with a timestamp.
return|return
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|lang
operator|.
name|StringUtils
operator|.
name|isNumeric
argument_list|(
name|fileNameString
operator|.
name|substring
argument_list|(
name|prefixPathStr
operator|.
name|length
argument_list|()
argument_list|)
argument_list|)
return|;
block|}
elseif|else
if|if
condition|(
operator|!
name|fileNameString
operator|.
name|endsWith
argument_list|(
name|logFileSuffix
argument_list|)
condition|)
block|{
return|return
literal|false
return|;
block|}
return|return
literal|true
return|;
block|}
block|}
expr_stmt|;
if|if
condition|(
name|failIfWALExists
condition|)
block|{
specifier|final
name|FileStatus
index|[]
name|walFiles
init|=
name|FSUtils
operator|.
name|listStatus
argument_list|(
name|fs
argument_list|,
name|fullPathLogDir
argument_list|,
name|ourFiles
argument_list|)
decl_stmt|;
if|if
condition|(
literal|null
operator|!=
name|walFiles
operator|&&
literal|0
operator|!=
name|walFiles
operator|.
name|length
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Target WAL already exists within directory "
operator|+
name|fullPathLogDir
argument_list|)
throw|;
block|}
block|}
comment|// Register listeners.  TODO: Should this exist anymore?  We have CPs?
if|if
condition|(
name|listeners
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|WALActionsListener
name|i
range|:
name|listeners
control|)
block|{
name|registerWALActionsListener
argument_list|(
name|i
argument_list|)
expr_stmt|;
block|}
block|}
name|this
operator|.
name|coprocessorHost
operator|=
operator|new
name|WALCoprocessorHost
argument_list|(
name|this
argument_list|,
name|conf
argument_list|)
expr_stmt|;
comment|// Get size to roll log at. Roll at 95% of HDFS block size so we avoid crossing HDFS blocks
comment|// (it costs a little x'ing bocks)
specifier|final
name|long
name|blocksize
init|=
name|this
operator|.
name|conf
operator|.
name|getLong
argument_list|(
literal|"hbase.regionserver.hlog.blocksize"
argument_list|,
name|FSUtils
operator|.
name|getDefaultBlockSize
argument_list|(
name|this
operator|.
name|fs
argument_list|,
name|this
operator|.
name|fullPathLogDir
argument_list|)
argument_list|)
decl_stmt|;
name|this
operator|.
name|logrollsize
operator|=
call|(
name|long
call|)
argument_list|(
name|blocksize
operator|*
name|conf
operator|.
name|getFloat
argument_list|(
literal|"hbase.regionserver.logroll.multiplier"
argument_list|,
literal|0.95f
argument_list|)
argument_list|)
expr_stmt|;
name|this
operator|.
name|maxLogs
operator|=
name|conf
operator|.
name|getInt
argument_list|(
literal|"hbase.regionserver.maxlogs"
argument_list|,
literal|32
argument_list|)
expr_stmt|;
name|this
operator|.
name|minTolerableReplication
operator|=
name|conf
operator|.
name|getInt
argument_list|(
literal|"hbase.regionserver.hlog.tolerable.lowreplication"
argument_list|,
name|FSUtils
operator|.
name|getDefaultReplication
argument_list|(
name|fs
argument_list|,
name|this
operator|.
name|fullPathLogDir
argument_list|)
argument_list|)
expr_stmt|;
name|this
operator|.
name|lowReplicationRollLimit
operator|=
name|conf
operator|.
name|getInt
argument_list|(
literal|"hbase.regionserver.hlog.lowreplication.rolllimit"
argument_list|,
literal|5
argument_list|)
expr_stmt|;
name|this
operator|.
name|closeErrorsTolerated
operator|=
name|conf
operator|.
name|getInt
argument_list|(
literal|"hbase.regionserver.logroll.errors.tolerated"
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|int
name|maxHandlersCount
init|=
name|conf
operator|.
name|getInt
argument_list|(
name|HConstants
operator|.
name|REGION_SERVER_HANDLER_COUNT
argument_list|,
literal|200
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"WAL configuration: blocksize="
operator|+
name|StringUtils
operator|.
name|byteDesc
argument_list|(
name|blocksize
argument_list|)
operator|+
literal|", rollsize="
operator|+
name|StringUtils
operator|.
name|byteDesc
argument_list|(
name|this
operator|.
name|logrollsize
argument_list|)
operator|+
literal|", prefix="
operator|+
name|this
operator|.
name|logFilePrefix
operator|+
literal|", suffix="
operator|+
name|logFileSuffix
operator|+
literal|", logDir="
operator|+
name|this
operator|.
name|fullPathLogDir
operator|+
literal|", archiveDir="
operator|+
name|this
operator|.
name|fullPathArchiveDir
argument_list|)
expr_stmt|;
comment|// rollWriter sets this.hdfs_out if it can.
name|rollWriter
argument_list|()
expr_stmt|;
name|this
operator|.
name|slowSyncNs
operator|=
literal|1000000
operator|*
name|conf
operator|.
name|getInt
argument_list|(
literal|"hbase.regionserver.hlog.slowsync.ms"
argument_list|,
name|DEFAULT_SLOW_SYNC_TIME_MS
argument_list|)
expr_stmt|;
comment|// handle the reflection necessary to call getNumCurrentReplicas(). TODO: Replace with
comment|// HdfsDataOutputStream#getCurrentBlockReplication() and go without reflection.
name|this
operator|.
name|getNumCurrentReplicas
operator|=
name|getGetNumCurrentReplicas
argument_list|(
name|this
operator|.
name|hdfs_out
argument_list|)
expr_stmt|;
name|this
operator|.
name|getPipeLine
operator|=
name|getGetPipeline
argument_list|(
name|this
operator|.
name|hdfs_out
argument_list|)
expr_stmt|;
comment|// This is the 'writer' -- a single threaded executor.  This single thread 'consumes' what is
comment|// put on the ring buffer.
name|String
name|hostingThreadName
init|=
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|getName
argument_list|()
decl_stmt|;
name|this
operator|.
name|appendExecutor
operator|=
name|Executors
operator|.
name|newSingleThreadExecutor
argument_list|(
name|Threads
operator|.
name|getNamedThreadFactory
argument_list|(
name|hostingThreadName
operator|+
literal|".append"
argument_list|)
argument_list|)
expr_stmt|;
comment|// Preallocate objects to use on the ring buffer.  The way that appends and syncs work, we will
comment|// be stuck and make no progress if the buffer is filled with appends only and there is no
comment|// sync. If no sync, then the handlers will be outstanding just waiting on sync completion
comment|// before they return.
specifier|final
name|int
name|preallocatedEventCount
init|=
name|this
operator|.
name|conf
operator|.
name|getInt
argument_list|(
literal|"hbase.regionserver.wal.disruptor.event.count"
argument_list|,
literal|1024
operator|*
literal|16
argument_list|)
decl_stmt|;
comment|// Using BlockingWaitStrategy.  Stuff that is going on here takes so long it makes no sense
comment|// spinning as other strategies do.
name|this
operator|.
name|disruptor
operator|=
operator|new
name|Disruptor
argument_list|<
name|RingBufferTruck
argument_list|>
argument_list|(
name|RingBufferTruck
operator|.
name|EVENT_FACTORY
argument_list|,
name|preallocatedEventCount
argument_list|,
name|this
operator|.
name|appendExecutor
argument_list|,
name|ProducerType
operator|.
name|MULTI
argument_list|,
operator|new
name|BlockingWaitStrategy
argument_list|()
argument_list|)
expr_stmt|;
comment|// Advance the ring buffer sequence so that it starts from 1 instead of 0,
comment|// because SyncFuture.NOT_DONE = 0.
name|this
operator|.
name|disruptor
operator|.
name|getRingBuffer
argument_list|()
operator|.
name|next
argument_list|()
expr_stmt|;
name|this
operator|.
name|ringBufferEventHandler
operator|=
operator|new
name|RingBufferEventHandler
argument_list|(
name|conf
operator|.
name|getInt
argument_list|(
literal|"hbase.regionserver.hlog.syncer.count"
argument_list|,
literal|5
argument_list|)
argument_list|,
name|maxHandlersCount
argument_list|)
expr_stmt|;
name|this
operator|.
name|disruptor
operator|.
name|handleExceptionsWith
argument_list|(
operator|new
name|RingBufferExceptionHandler
argument_list|()
argument_list|)
expr_stmt|;
name|this
operator|.
name|disruptor
operator|.
name|handleEventsWith
argument_list|(
operator|new
name|RingBufferEventHandler
index|[]
block|{
name|this
operator|.
name|ringBufferEventHandler
block|}
argument_list|)
expr_stmt|;
comment|// Presize our map of SyncFutures by handler objects.
name|this
operator|.
name|syncFuturesByHandler
operator|=
operator|new
name|ConcurrentHashMap
argument_list|<
name|Thread
argument_list|,
name|SyncFuture
argument_list|>
argument_list|(
name|maxHandlersCount
argument_list|)
expr_stmt|;
comment|// Starting up threads in constructor is a no no; Interface should have an init call.
name|this
operator|.
name|disruptor
operator|.
name|start
argument_list|()
expr_stmt|;
block|}
comment|/**    * Get the backing files associated with this WAL.    * @return may be null if there are no files.    */
specifier|protected
name|FileStatus
index|[]
name|getFiles
parameter_list|()
throws|throws
name|IOException
block|{
return|return
name|FSUtils
operator|.
name|listStatus
argument_list|(
name|fs
argument_list|,
name|fullPathLogDir
argument_list|,
name|ourFiles
argument_list|)
return|;
block|}
comment|/**    * Currently, we need to expose the writer's OutputStream to tests so that they can manipulate    * the default behavior (such as setting the maxRecoveryErrorCount value for example (see    * {@link TestWALReplay#testReplayEditsWrittenIntoWAL()}). This is done using reflection on the    * underlying HDFS OutputStream.    * NOTE: This could be removed once Hadoop1 support is removed.    * @return null if underlying stream is not ready.    */
annotation|@
name|VisibleForTesting
name|OutputStream
name|getOutputStream
parameter_list|()
block|{
return|return
name|this
operator|.
name|hdfs_out
operator|.
name|getWrappedStream
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|byte
index|[]
index|[]
name|rollWriter
parameter_list|()
throws|throws
name|FailedLogCloseException
throws|,
name|IOException
block|{
return|return
name|rollWriter
argument_list|(
literal|false
argument_list|)
return|;
block|}
comment|/**    * retrieve the next path to use for writing.    * Increments the internal filenum.    */
specifier|private
name|Path
name|getNewPath
parameter_list|()
throws|throws
name|IOException
block|{
name|this
operator|.
name|filenum
operator|.
name|set
argument_list|(
name|System
operator|.
name|currentTimeMillis
argument_list|()
argument_list|)
expr_stmt|;
name|Path
name|newPath
init|=
name|getCurrentFileName
argument_list|()
decl_stmt|;
while|while
condition|(
name|fs
operator|.
name|exists
argument_list|(
name|newPath
argument_list|)
condition|)
block|{
name|this
operator|.
name|filenum
operator|.
name|incrementAndGet
argument_list|()
expr_stmt|;
name|newPath
operator|=
name|getCurrentFileName
argument_list|()
expr_stmt|;
block|}
return|return
name|newPath
return|;
block|}
name|Path
name|getOldPath
parameter_list|()
block|{
name|long
name|currentFilenum
init|=
name|this
operator|.
name|filenum
operator|.
name|get
argument_list|()
decl_stmt|;
name|Path
name|oldPath
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|currentFilenum
operator|>
literal|0
condition|)
block|{
comment|// ComputeFilename  will take care of meta wal filename
name|oldPath
operator|=
name|computeFilename
argument_list|(
name|currentFilenum
argument_list|)
expr_stmt|;
block|}
comment|// I presume if currentFilenum is<= 0, this is first file and null for oldPath if fine?
return|return
name|oldPath
return|;
block|}
comment|/**    * Tell listeners about pre log roll.    * @throws IOException     */
specifier|private
name|void
name|tellListenersAboutPreLogRoll
parameter_list|(
specifier|final
name|Path
name|oldPath
parameter_list|,
specifier|final
name|Path
name|newPath
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
operator|!
name|this
operator|.
name|listeners
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
for|for
control|(
name|WALActionsListener
name|i
range|:
name|this
operator|.
name|listeners
control|)
block|{
name|i
operator|.
name|preLogRoll
argument_list|(
name|oldPath
argument_list|,
name|newPath
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|/**    * Tell listeners about post log roll.    * @throws IOException     */
specifier|private
name|void
name|tellListenersAboutPostLogRoll
parameter_list|(
specifier|final
name|Path
name|oldPath
parameter_list|,
specifier|final
name|Path
name|newPath
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
operator|!
name|this
operator|.
name|listeners
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
for|for
control|(
name|WALActionsListener
name|i
range|:
name|this
operator|.
name|listeners
control|)
block|{
name|i
operator|.
name|postLogRoll
argument_list|(
name|oldPath
argument_list|,
name|newPath
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|/**    * Run a sync after opening to set up the pipeline.    * @param nextWriter    * @param startTimeNanos    */
specifier|private
name|void
name|preemptiveSync
parameter_list|(
specifier|final
name|ProtobufLogWriter
name|nextWriter
parameter_list|)
block|{
name|long
name|startTimeNanos
init|=
name|System
operator|.
name|nanoTime
argument_list|()
decl_stmt|;
try|try
block|{
name|nextWriter
operator|.
name|sync
argument_list|()
expr_stmt|;
name|postSync
argument_list|(
name|System
operator|.
name|nanoTime
argument_list|()
operator|-
name|startTimeNanos
argument_list|,
literal|0
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
comment|// optimization failed, no need to abort here.
name|LOG
operator|.
name|warn
argument_list|(
literal|"pre-sync failed but an optimization so keep going"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|byte
index|[]
index|[]
name|rollWriter
parameter_list|(
name|boolean
name|force
parameter_list|)
throws|throws
name|FailedLogCloseException
throws|,
name|IOException
block|{
name|rollWriterLock
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
comment|// Return if nothing to flush.
if|if
condition|(
operator|!
name|force
operator|&&
operator|(
name|this
operator|.
name|writer
operator|!=
literal|null
operator|&&
name|this
operator|.
name|numEntries
operator|.
name|get
argument_list|()
operator|<=
literal|0
operator|)
condition|)
return|return
literal|null
return|;
name|byte
index|[]
index|[]
name|regionsToFlush
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|this
operator|.
name|closed
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"WAL closed. Skipping rolling of writer"
argument_list|)
expr_stmt|;
return|return
name|regionsToFlush
return|;
block|}
if|if
condition|(
operator|!
name|closeBarrier
operator|.
name|beginOp
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"WAL closing. Skipping rolling of writer"
argument_list|)
expr_stmt|;
return|return
name|regionsToFlush
return|;
block|}
name|TraceScope
name|scope
init|=
name|Trace
operator|.
name|startSpan
argument_list|(
literal|"FSHLog.rollWriter"
argument_list|)
decl_stmt|;
try|try
block|{
name|Path
name|oldPath
init|=
name|getOldPath
argument_list|()
decl_stmt|;
name|Path
name|newPath
init|=
name|getNewPath
argument_list|()
decl_stmt|;
comment|// Any exception from here on is catastrophic, non-recoverable so we currently abort.
name|Writer
name|nextWriter
init|=
name|this
operator|.
name|createWriterInstance
argument_list|(
name|newPath
argument_list|)
decl_stmt|;
name|FSDataOutputStream
name|nextHdfsOut
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|nextWriter
operator|instanceof
name|ProtobufLogWriter
condition|)
block|{
name|nextHdfsOut
operator|=
operator|(
operator|(
name|ProtobufLogWriter
operator|)
name|nextWriter
operator|)
operator|.
name|getStream
argument_list|()
expr_stmt|;
comment|// If a ProtobufLogWriter, go ahead and try and sync to force setup of pipeline.
comment|// If this fails, we just keep going.... it is an optimization, not the end of the world.
name|preemptiveSync
argument_list|(
operator|(
name|ProtobufLogWriter
operator|)
name|nextWriter
argument_list|)
expr_stmt|;
block|}
name|tellListenersAboutPreLogRoll
argument_list|(
name|oldPath
argument_list|,
name|newPath
argument_list|)
expr_stmt|;
comment|// NewPath could be equal to oldPath if replaceWriter fails.
name|newPath
operator|=
name|replaceWriter
argument_list|(
name|oldPath
argument_list|,
name|newPath
argument_list|,
name|nextWriter
argument_list|,
name|nextHdfsOut
argument_list|)
expr_stmt|;
name|tellListenersAboutPostLogRoll
argument_list|(
name|oldPath
argument_list|,
name|newPath
argument_list|)
expr_stmt|;
comment|// Can we delete any of the old log files?
if|if
condition|(
name|getNumRolledLogFiles
argument_list|()
operator|>
literal|0
condition|)
block|{
name|cleanOldLogs
argument_list|()
expr_stmt|;
name|regionsToFlush
operator|=
name|findRegionsToForceFlush
argument_list|()
expr_stmt|;
block|}
block|}
finally|finally
block|{
name|closeBarrier
operator|.
name|endOp
argument_list|()
expr_stmt|;
assert|assert
name|scope
operator|==
name|NullScope
operator|.
name|INSTANCE
operator|||
operator|!
name|scope
operator|.
name|isDetached
argument_list|()
assert|;
name|scope
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
return|return
name|regionsToFlush
return|;
block|}
finally|finally
block|{
name|rollWriterLock
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**    * This method allows subclasses to inject different writers without having to    * extend other methods like rollWriter().    *    * @return Writer instance    */
specifier|protected
name|Writer
name|createWriterInstance
parameter_list|(
specifier|final
name|Path
name|path
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|DefaultWALProvider
operator|.
name|createWriter
argument_list|(
name|conf
argument_list|,
name|fs
argument_list|,
name|path
argument_list|,
literal|false
argument_list|)
return|;
block|}
specifier|private
name|long
name|getLowestSeqId
parameter_list|(
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|Long
argument_list|>
name|seqIdMap
parameter_list|)
block|{
name|long
name|result
init|=
name|HConstants
operator|.
name|NO_SEQNUM
decl_stmt|;
for|for
control|(
name|Long
name|seqNum
range|:
name|seqIdMap
operator|.
name|values
argument_list|()
control|)
block|{
if|if
condition|(
name|result
operator|==
name|HConstants
operator|.
name|NO_SEQNUM
operator|||
name|seqNum
operator|.
name|longValue
argument_list|()
operator|<
name|result
condition|)
block|{
name|result
operator|=
name|seqNum
operator|.
name|longValue
argument_list|()
expr_stmt|;
block|}
block|}
return|return
name|result
return|;
block|}
specifier|private
parameter_list|<
name|T
extends|extends
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|Long
argument_list|>
parameter_list|>
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|Long
argument_list|>
name|copyMapWithLowestSeqId
parameter_list|(
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|T
argument_list|>
name|mapToCopy
parameter_list|)
block|{
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|Long
argument_list|>
name|copied
init|=
name|Maps
operator|.
name|newHashMap
argument_list|()
decl_stmt|;
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|byte
index|[]
argument_list|,
name|T
argument_list|>
name|entry
range|:
name|mapToCopy
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|long
name|lowestSeqId
init|=
name|getLowestSeqId
argument_list|(
name|entry
operator|.
name|getValue
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|lowestSeqId
operator|!=
name|HConstants
operator|.
name|NO_SEQNUM
condition|)
block|{
name|copied
operator|.
name|put
argument_list|(
name|entry
operator|.
name|getKey
argument_list|()
argument_list|,
name|lowestSeqId
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|copied
return|;
block|}
comment|/**    * Archive old logs that could be archived: a log is eligible for archiving if all its WALEdits    * have been flushed to hfiles.    *<p>    * For each log file, it compares its region to sequenceId map    * (@link {@link FSHLog#highestRegionSequenceIds} with corresponding region entries in    * {@link FSHLog#lowestFlushingRegionSequenceIds} and    * {@link FSHLog#oldestUnflushedRegionSequenceIds}. If all the regions in the map are flushed    * past of their value, then the wal is eligible for archiving.    * @throws IOException    */
specifier|private
name|void
name|cleanOldLogs
parameter_list|()
throws|throws
name|IOException
block|{
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|Long
argument_list|>
name|lowestFlushingRegionSequenceIdsLocal
init|=
literal|null
decl_stmt|;
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|Long
argument_list|>
name|oldestUnflushedRegionSequenceIdsLocal
init|=
literal|null
decl_stmt|;
name|List
argument_list|<
name|Path
argument_list|>
name|logsToArchive
init|=
operator|new
name|ArrayList
argument_list|<
name|Path
argument_list|>
argument_list|()
decl_stmt|;
comment|// make a local copy so as to avoid locking when we iterate over these maps.
synchronized|synchronized
init|(
name|regionSequenceIdLock
init|)
block|{
name|lowestFlushingRegionSequenceIdsLocal
operator|=
name|copyMapWithLowestSeqId
argument_list|(
name|this
operator|.
name|lowestFlushingStoreSequenceIds
argument_list|)
expr_stmt|;
name|oldestUnflushedRegionSequenceIdsLocal
operator|=
name|copyMapWithLowestSeqId
argument_list|(
name|this
operator|.
name|oldestUnflushedStoreSequenceIds
argument_list|)
expr_stmt|;
block|}
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|Path
argument_list|,
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|Long
argument_list|>
argument_list|>
name|e
range|:
name|byWalRegionSequenceIds
operator|.
name|entrySet
argument_list|()
control|)
block|{
comment|// iterate over the log file.
name|Path
name|log
init|=
name|e
operator|.
name|getKey
argument_list|()
decl_stmt|;
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|Long
argument_list|>
name|sequenceNums
init|=
name|e
operator|.
name|getValue
argument_list|()
decl_stmt|;
comment|// iterate over the map for this log file, and tell whether it should be archive or not.
if|if
condition|(
name|areAllRegionsFlushed
argument_list|(
name|sequenceNums
argument_list|,
name|lowestFlushingRegionSequenceIdsLocal
argument_list|,
name|oldestUnflushedRegionSequenceIdsLocal
argument_list|)
condition|)
block|{
name|logsToArchive
operator|.
name|add
argument_list|(
name|log
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"WAL file ready for archiving "
operator|+
name|log
argument_list|)
expr_stmt|;
block|}
block|}
for|for
control|(
name|Path
name|p
range|:
name|logsToArchive
control|)
block|{
name|this
operator|.
name|totalLogSize
operator|.
name|addAndGet
argument_list|(
operator|-
name|this
operator|.
name|fs
operator|.
name|getFileStatus
argument_list|(
name|p
argument_list|)
operator|.
name|getLen
argument_list|()
argument_list|)
expr_stmt|;
name|archiveLogFile
argument_list|(
name|p
argument_list|)
expr_stmt|;
name|this
operator|.
name|byWalRegionSequenceIds
operator|.
name|remove
argument_list|(
name|p
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Takes a region:sequenceId map for a WAL file, and checks whether the file can be archived.    * It compares the region entries present in the passed sequenceNums map with the local copy of    * {@link #oldestUnflushedRegionSequenceIds} and {@link #lowestFlushingRegionSequenceIds}. If,    * for all regions, the value is lesser than the minimum of values present in the    * oldestFlushing/UnflushedSeqNums, then the wal file is eligible for archiving.    * @param sequenceNums for a WAL, at the time when it was rolled.    * @param oldestFlushingMap    * @param oldestUnflushedMap    * @return true if wal is eligible for archiving, false otherwise.    */
specifier|static
name|boolean
name|areAllRegionsFlushed
parameter_list|(
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|Long
argument_list|>
name|sequenceNums
parameter_list|,
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|Long
argument_list|>
name|oldestFlushingMap
parameter_list|,
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|Long
argument_list|>
name|oldestUnflushedMap
parameter_list|)
block|{
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|byte
index|[]
argument_list|,
name|Long
argument_list|>
name|regionSeqIdEntry
range|:
name|sequenceNums
operator|.
name|entrySet
argument_list|()
control|)
block|{
comment|// find region entries in the flushing/unflushed map. If there is no entry, it meansj
comment|// a region doesn't have any unflushed entry.
name|long
name|oldestFlushing
init|=
name|oldestFlushingMap
operator|.
name|containsKey
argument_list|(
name|regionSeqIdEntry
operator|.
name|getKey
argument_list|()
argument_list|)
condition|?
name|oldestFlushingMap
operator|.
name|get
argument_list|(
name|regionSeqIdEntry
operator|.
name|getKey
argument_list|()
argument_list|)
else|:
name|Long
operator|.
name|MAX_VALUE
decl_stmt|;
name|long
name|oldestUnFlushed
init|=
name|oldestUnflushedMap
operator|.
name|containsKey
argument_list|(
name|regionSeqIdEntry
operator|.
name|getKey
argument_list|()
argument_list|)
condition|?
name|oldestUnflushedMap
operator|.
name|get
argument_list|(
name|regionSeqIdEntry
operator|.
name|getKey
argument_list|()
argument_list|)
else|:
name|Long
operator|.
name|MAX_VALUE
decl_stmt|;
comment|// do a minimum to be sure to contain oldest sequence Id
name|long
name|minSeqNum
init|=
name|Math
operator|.
name|min
argument_list|(
name|oldestFlushing
argument_list|,
name|oldestUnFlushed
argument_list|)
decl_stmt|;
if|if
condition|(
name|minSeqNum
operator|<=
name|regionSeqIdEntry
operator|.
name|getValue
argument_list|()
condition|)
return|return
literal|false
return|;
comment|// can't archive
block|}
return|return
literal|true
return|;
block|}
comment|/**    * Iterates over the given map of regions, and compares their sequence numbers with corresponding    * entries in {@link #oldestUnflushedRegionSequenceIds}. If the sequence number is greater or    * equal, the region is eligible to flush, otherwise, there is no benefit to flush (from the    * perspective of passed regionsSequenceNums map), because the region has already flushed the    * entries present in the WAL file for which this method is called for (typically, the oldest    * wal file).    * @param regionsSequenceNums    * @return regions which should be flushed (whose sequence numbers are larger than their    * corresponding un-flushed entries.    */
specifier|private
name|byte
index|[]
index|[]
name|findEligibleMemstoresToFlush
parameter_list|(
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|Long
argument_list|>
name|regionsSequenceNums
parameter_list|)
block|{
name|List
argument_list|<
name|byte
index|[]
argument_list|>
name|regionsToFlush
init|=
literal|null
decl_stmt|;
comment|// Keeping the old behavior of iterating unflushedSeqNums under oldestSeqNumsLock.
synchronized|synchronized
init|(
name|regionSequenceIdLock
init|)
block|{
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|byte
index|[]
argument_list|,
name|Long
argument_list|>
name|e
range|:
name|regionsSequenceNums
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|long
name|unFlushedVal
init|=
name|getEarliestMemstoreSeqNum
argument_list|(
name|e
operator|.
name|getKey
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|unFlushedVal
operator|!=
name|HConstants
operator|.
name|NO_SEQNUM
operator|&&
name|unFlushedVal
operator|<=
name|e
operator|.
name|getValue
argument_list|()
condition|)
block|{
if|if
condition|(
name|regionsToFlush
operator|==
literal|null
condition|)
name|regionsToFlush
operator|=
operator|new
name|ArrayList
argument_list|<
name|byte
index|[]
argument_list|>
argument_list|()
expr_stmt|;
name|regionsToFlush
operator|.
name|add
argument_list|(
name|e
operator|.
name|getKey
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
block|}
return|return
name|regionsToFlush
operator|==
literal|null
condition|?
literal|null
else|:
name|regionsToFlush
operator|.
name|toArray
argument_list|(
operator|new
name|byte
index|[]
index|[]
block|{
name|HConstants
operator|.
name|EMPTY_BYTE_ARRAY
block|}
argument_list|)
return|;
block|}
comment|/**    * If the number of un-archived WAL files is greater than maximum allowed, it checks    * the first (oldest) WAL file, and returns the regions which should be flushed so that it could    * be archived.    * @return regions to flush in order to archive oldest wal file.    * @throws IOException    */
name|byte
index|[]
index|[]
name|findRegionsToForceFlush
parameter_list|()
throws|throws
name|IOException
block|{
name|byte
index|[]
index|[]
name|regions
init|=
literal|null
decl_stmt|;
name|int
name|logCount
init|=
name|getNumRolledLogFiles
argument_list|()
decl_stmt|;
if|if
condition|(
name|logCount
operator|>
name|this
operator|.
name|maxLogs
operator|&&
name|logCount
operator|>
literal|0
condition|)
block|{
name|Map
operator|.
name|Entry
argument_list|<
name|Path
argument_list|,
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|Long
argument_list|>
argument_list|>
name|firstWALEntry
init|=
name|this
operator|.
name|byWalRegionSequenceIds
operator|.
name|firstEntry
argument_list|()
decl_stmt|;
name|regions
operator|=
name|findEligibleMemstoresToFlush
argument_list|(
name|firstWALEntry
operator|.
name|getValue
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|regions
operator|!=
literal|null
condition|)
block|{
name|StringBuilder
name|sb
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|regions
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|i
operator|>
literal|0
condition|)
name|sb
operator|.
name|append
argument_list|(
literal|", "
argument_list|)
expr_stmt|;
name|sb
operator|.
name|append
argument_list|(
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|regions
index|[
name|i
index|]
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|LOG
operator|.
name|info
argument_list|(
literal|"Too many wals: logs="
operator|+
name|logCount
operator|+
literal|", maxlogs="
operator|+
name|this
operator|.
name|maxLogs
operator|+
literal|"; forcing flush of "
operator|+
name|regions
operator|.
name|length
operator|+
literal|" regions(s): "
operator|+
name|sb
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
name|regions
return|;
block|}
comment|/**    * Cleans up current writer closing it and then puts in place the passed in    *<code>nextWriter</code>.    *    * In the case of creating a new WAL, oldPath will be null.    *    * In the case of rolling over from one file to the next, none of the params will be null.    *    * In the case of closing out this FSHLog with no further use newPath, nextWriter, and    * nextHdfsOut will be null.    *    * @param oldPath may be null    * @param newPath may be null    * @param nextWriter may be null    * @param nextHdfsOut may be null    * @return the passed in<code>newPath</code>    * @throws IOException if there is a problem flushing or closing the underlying FS    */
name|Path
name|replaceWriter
parameter_list|(
specifier|final
name|Path
name|oldPath
parameter_list|,
specifier|final
name|Path
name|newPath
parameter_list|,
name|Writer
name|nextWriter
parameter_list|,
specifier|final
name|FSDataOutputStream
name|nextHdfsOut
parameter_list|)
throws|throws
name|IOException
block|{
comment|// Ask the ring buffer writer to pause at a safe point.  Once we do this, the writer
comment|// thread will eventually pause. An error hereafter needs to release the writer thread
comment|// regardless -- hence the finally block below.  Note, this method is called from the FSHLog
comment|// constructor BEFORE the ring buffer is set running so it is null on first time through
comment|// here; allow for that.
name|SyncFuture
name|syncFuture
init|=
literal|null
decl_stmt|;
name|SafePointZigZagLatch
name|zigzagLatch
init|=
operator|(
name|this
operator|.
name|ringBufferEventHandler
operator|==
literal|null
operator|)
condition|?
literal|null
else|:
name|this
operator|.
name|ringBufferEventHandler
operator|.
name|attainSafePoint
argument_list|()
decl_stmt|;
name|TraceScope
name|scope
init|=
name|Trace
operator|.
name|startSpan
argument_list|(
literal|"FSHFile.replaceWriter"
argument_list|)
decl_stmt|;
try|try
block|{
comment|// Wait on the safe point to be achieved.  Send in a sync in case nothing has hit the
comment|// ring buffer between the above notification of writer that we want it to go to
comment|// 'safe point' and then here where we are waiting on it to attain safe point.  Use
comment|// 'sendSync' instead of 'sync' because we do not want this thread to block waiting on it
comment|// to come back.  Cleanup this syncFuture down below after we are ready to run again.
try|try
block|{
if|if
condition|(
name|zigzagLatch
operator|!=
literal|null
condition|)
block|{
name|Trace
operator|.
name|addTimelineAnnotation
argument_list|(
literal|"awaiting safepoint"
argument_list|)
expr_stmt|;
name|syncFuture
operator|=
name|zigzagLatch
operator|.
name|waitSafePoint
argument_list|(
name|publishSyncOnRingBuffer
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|FailedSyncBeforeLogCloseException
name|e
parameter_list|)
block|{
if|if
condition|(
name|isUnflushedEntries
argument_list|()
condition|)
throw|throw
name|e
throw|;
comment|// Else, let is pass through to the close.
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failed last sync but no outstanding unsync edits so falling through to close; "
operator|+
name|e
operator|.
name|getMessage
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|// It is at the safe point.  Swap out writer from under the blocked writer thread.
comment|// TODO: This is close is inline with critical section.  Should happen in background?
try|try
block|{
if|if
condition|(
name|this
operator|.
name|writer
operator|!=
literal|null
condition|)
block|{
name|Trace
operator|.
name|addTimelineAnnotation
argument_list|(
literal|"closing writer"
argument_list|)
expr_stmt|;
name|this
operator|.
name|writer
operator|.
name|close
argument_list|()
expr_stmt|;
name|Trace
operator|.
name|addTimelineAnnotation
argument_list|(
literal|"writer closed"
argument_list|)
expr_stmt|;
block|}
name|this
operator|.
name|closeErrorCount
operator|.
name|set
argument_list|(
literal|0
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ioe
parameter_list|)
block|{
name|int
name|errors
init|=
name|closeErrorCount
operator|.
name|incrementAndGet
argument_list|()
decl_stmt|;
if|if
condition|(
operator|!
name|isUnflushedEntries
argument_list|()
operator|&&
operator|(
name|errors
operator|<=
name|this
operator|.
name|closeErrorsTolerated
operator|)
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Riding over failed WAL close of "
operator|+
name|oldPath
operator|+
literal|", cause=\""
operator|+
name|ioe
operator|.
name|getMessage
argument_list|()
operator|+
literal|"\", errors="
operator|+
name|errors
operator|+
literal|"; THIS FILE WAS NOT CLOSED BUT ALL EDITS SYNCED SO SHOULD BE OK"
argument_list|)
expr_stmt|;
block|}
else|else
block|{
throw|throw
name|ioe
throw|;
block|}
block|}
name|this
operator|.
name|writer
operator|=
name|nextWriter
expr_stmt|;
name|this
operator|.
name|hdfs_out
operator|=
name|nextHdfsOut
expr_stmt|;
name|int
name|oldNumEntries
init|=
name|this
operator|.
name|numEntries
operator|.
name|get
argument_list|()
decl_stmt|;
name|this
operator|.
name|numEntries
operator|.
name|set
argument_list|(
literal|0
argument_list|)
expr_stmt|;
specifier|final
name|String
name|newPathString
init|=
operator|(
literal|null
operator|==
name|newPath
condition|?
literal|null
else|:
name|FSUtils
operator|.
name|getPath
argument_list|(
name|newPath
argument_list|)
operator|)
decl_stmt|;
if|if
condition|(
name|oldPath
operator|!=
literal|null
condition|)
block|{
name|this
operator|.
name|byWalRegionSequenceIds
operator|.
name|put
argument_list|(
name|oldPath
argument_list|,
name|this
operator|.
name|highestRegionSequenceIds
argument_list|)
expr_stmt|;
name|this
operator|.
name|highestRegionSequenceIds
operator|=
operator|new
name|HashMap
argument_list|<
name|byte
index|[]
argument_list|,
name|Long
argument_list|>
argument_list|()
expr_stmt|;
name|long
name|oldFileLen
init|=
name|this
operator|.
name|fs
operator|.
name|getFileStatus
argument_list|(
name|oldPath
argument_list|)
operator|.
name|getLen
argument_list|()
decl_stmt|;
name|this
operator|.
name|totalLogSize
operator|.
name|addAndGet
argument_list|(
name|oldFileLen
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Rolled WAL "
operator|+
name|FSUtils
operator|.
name|getPath
argument_list|(
name|oldPath
argument_list|)
operator|+
literal|" with entries="
operator|+
name|oldNumEntries
operator|+
literal|", filesize="
operator|+
name|StringUtils
operator|.
name|byteDesc
argument_list|(
name|oldFileLen
argument_list|)
operator|+
literal|"; new WAL "
operator|+
name|newPathString
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"New WAL "
operator|+
name|newPathString
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|ie
parameter_list|)
block|{
comment|// Perpetuate the interrupt
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|interrupt
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|long
name|count
init|=
name|getUnflushedEntriesCount
argument_list|()
decl_stmt|;
name|LOG
operator|.
name|error
argument_list|(
literal|"Failed close of WAL writer "
operator|+
name|oldPath
operator|+
literal|", unflushedEntries="
operator|+
name|count
argument_list|,
name|e
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|FailedLogCloseException
argument_list|(
name|oldPath
operator|+
literal|", unflushedEntries="
operator|+
name|count
argument_list|,
name|e
argument_list|)
throw|;
block|}
finally|finally
block|{
try|try
block|{
comment|// Let the writer thread go regardless, whether error or not.
if|if
condition|(
name|zigzagLatch
operator|!=
literal|null
condition|)
block|{
name|zigzagLatch
operator|.
name|releaseSafePoint
argument_list|()
expr_stmt|;
comment|// It will be null if we failed our wait on safe point above.
if|if
condition|(
name|syncFuture
operator|!=
literal|null
condition|)
name|blockOnSync
argument_list|(
name|syncFuture
argument_list|)
expr_stmt|;
block|}
block|}
finally|finally
block|{
name|scope
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
block|}
return|return
name|newPath
return|;
block|}
name|long
name|getUnflushedEntriesCount
parameter_list|()
block|{
name|long
name|highestSynced
init|=
name|this
operator|.
name|highestSyncedSequence
operator|.
name|get
argument_list|()
decl_stmt|;
return|return
name|highestSynced
operator|>
name|this
operator|.
name|highestUnsyncedSequence
condition|?
literal|0
else|:
name|this
operator|.
name|highestUnsyncedSequence
operator|-
name|highestSynced
return|;
block|}
name|boolean
name|isUnflushedEntries
parameter_list|()
block|{
return|return
name|getUnflushedEntriesCount
argument_list|()
operator|>
literal|0
return|;
block|}
comment|/*    * only public so WALSplitter can use.    * @return archived location of a WAL file with the given path p    */
specifier|public
specifier|static
name|Path
name|getWALArchivePath
parameter_list|(
name|Path
name|archiveDir
parameter_list|,
name|Path
name|p
parameter_list|)
block|{
return|return
operator|new
name|Path
argument_list|(
name|archiveDir
argument_list|,
name|p
operator|.
name|getName
argument_list|()
argument_list|)
return|;
block|}
specifier|private
name|void
name|archiveLogFile
parameter_list|(
specifier|final
name|Path
name|p
parameter_list|)
throws|throws
name|IOException
block|{
name|Path
name|newPath
init|=
name|getWALArchivePath
argument_list|(
name|this
operator|.
name|fullPathArchiveDir
argument_list|,
name|p
argument_list|)
decl_stmt|;
comment|// Tell our listeners that a log is going to be archived.
if|if
condition|(
operator|!
name|this
operator|.
name|listeners
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
for|for
control|(
name|WALActionsListener
name|i
range|:
name|this
operator|.
name|listeners
control|)
block|{
name|i
operator|.
name|preLogArchive
argument_list|(
name|p
argument_list|,
name|newPath
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
operator|!
name|FSUtils
operator|.
name|renameAndSetModifyTime
argument_list|(
name|this
operator|.
name|fs
argument_list|,
name|p
argument_list|,
name|newPath
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Unable to rename "
operator|+
name|p
operator|+
literal|" to "
operator|+
name|newPath
argument_list|)
throw|;
block|}
comment|// Tell our listeners that a log has been archived.
if|if
condition|(
operator|!
name|this
operator|.
name|listeners
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
for|for
control|(
name|WALActionsListener
name|i
range|:
name|this
operator|.
name|listeners
control|)
block|{
name|i
operator|.
name|postLogArchive
argument_list|(
name|p
argument_list|,
name|newPath
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|/**    * This is a convenience method that computes a new filename with a given    * file-number.    * @param filenum to use    * @return Path    */
specifier|protected
name|Path
name|computeFilename
parameter_list|(
specifier|final
name|long
name|filenum
parameter_list|)
block|{
if|if
condition|(
name|filenum
operator|<
literal|0
condition|)
block|{
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"wal file number can't be< 0"
argument_list|)
throw|;
block|}
name|String
name|child
init|=
name|logFilePrefix
operator|+
name|WAL_FILE_NAME_DELIMITER
operator|+
name|filenum
operator|+
name|logFileSuffix
decl_stmt|;
return|return
operator|new
name|Path
argument_list|(
name|fullPathLogDir
argument_list|,
name|child
argument_list|)
return|;
block|}
comment|/**    * This is a convenience method that computes a new filename with a given    * using the current WAL file-number    * @return Path    */
specifier|public
name|Path
name|getCurrentFileName
parameter_list|()
block|{
return|return
name|computeFilename
argument_list|(
name|this
operator|.
name|filenum
operator|.
name|get
argument_list|()
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|String
name|toString
parameter_list|()
block|{
return|return
literal|"FSHLog "
operator|+
name|logFilePrefix
operator|+
literal|":"
operator|+
name|logFileSuffix
operator|+
literal|"(num "
operator|+
name|filenum
operator|+
literal|")"
return|;
block|}
comment|/**  * A log file has a creation timestamp (in ms) in its file name ({@link #filenum}.  * This helper method returns the creation timestamp from a given log file.  * It extracts the timestamp assuming the filename is created with the  * {@link #computeFilename(long filenum)} method.  * @param fileName  * @return timestamp, as in the log file name.  */
specifier|protected
name|long
name|getFileNumFromFileName
parameter_list|(
name|Path
name|fileName
parameter_list|)
block|{
if|if
condition|(
name|fileName
operator|==
literal|null
condition|)
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"file name can't be null"
argument_list|)
throw|;
if|if
condition|(
operator|!
name|ourFiles
operator|.
name|accept
argument_list|(
name|fileName
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"The log file "
operator|+
name|fileName
operator|+
literal|" doesn't belong to this wal. ("
operator|+
name|toString
argument_list|()
operator|+
literal|")"
argument_list|)
throw|;
block|}
specifier|final
name|String
name|fileNameString
init|=
name|fileName
operator|.
name|toString
argument_list|()
decl_stmt|;
name|String
name|chompedPath
init|=
name|fileNameString
operator|.
name|substring
argument_list|(
name|prefixPathStr
operator|.
name|length
argument_list|()
argument_list|,
operator|(
name|fileNameString
operator|.
name|length
argument_list|()
operator|-
name|logFileSuffix
operator|.
name|length
argument_list|()
operator|)
argument_list|)
decl_stmt|;
return|return
name|Long
operator|.
name|parseLong
argument_list|(
name|chompedPath
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|close
parameter_list|()
throws|throws
name|IOException
block|{
name|shutdown
argument_list|()
expr_stmt|;
specifier|final
name|FileStatus
index|[]
name|files
init|=
name|getFiles
argument_list|()
decl_stmt|;
if|if
condition|(
literal|null
operator|!=
name|files
operator|&&
literal|0
operator|!=
name|files
operator|.
name|length
condition|)
block|{
for|for
control|(
name|FileStatus
name|file
range|:
name|files
control|)
block|{
name|Path
name|p
init|=
name|getWALArchivePath
argument_list|(
name|this
operator|.
name|fullPathArchiveDir
argument_list|,
name|file
operator|.
name|getPath
argument_list|()
argument_list|)
decl_stmt|;
comment|// Tell our listeners that a log is going to be archived.
if|if
condition|(
operator|!
name|this
operator|.
name|listeners
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
for|for
control|(
name|WALActionsListener
name|i
range|:
name|this
operator|.
name|listeners
control|)
block|{
name|i
operator|.
name|preLogArchive
argument_list|(
name|file
operator|.
name|getPath
argument_list|()
argument_list|,
name|p
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
operator|!
name|FSUtils
operator|.
name|renameAndSetModifyTime
argument_list|(
name|fs
argument_list|,
name|file
operator|.
name|getPath
argument_list|()
argument_list|,
name|p
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Unable to rename "
operator|+
name|file
operator|.
name|getPath
argument_list|()
operator|+
literal|" to "
operator|+
name|p
argument_list|)
throw|;
block|}
comment|// Tell our listeners that a log was archived.
if|if
condition|(
operator|!
name|this
operator|.
name|listeners
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
for|for
control|(
name|WALActionsListener
name|i
range|:
name|this
operator|.
name|listeners
control|)
block|{
name|i
operator|.
name|postLogArchive
argument_list|(
name|file
operator|.
name|getPath
argument_list|()
argument_list|,
name|p
argument_list|)
expr_stmt|;
block|}
block|}
block|}
name|LOG
operator|.
name|debug
argument_list|(
literal|"Moved "
operator|+
name|files
operator|.
name|length
operator|+
literal|" WAL file(s) to "
operator|+
name|FSUtils
operator|.
name|getPath
argument_list|(
name|this
operator|.
name|fullPathArchiveDir
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|LOG
operator|.
name|info
argument_list|(
literal|"Closed WAL: "
operator|+
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|shutdown
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|shutdown
operator|.
name|compareAndSet
argument_list|(
literal|false
argument_list|,
literal|true
argument_list|)
condition|)
block|{
try|try
block|{
comment|// Prevent all further flushing and rolling.
name|closeBarrier
operator|.
name|stopAndDrainOps
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Exception while waiting for cache flushes and log rolls"
argument_list|,
name|e
argument_list|)
expr_stmt|;
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|interrupt
argument_list|()
expr_stmt|;
block|}
comment|// Shutdown the disruptor.  Will stop after all entries have been processed.  Make sure we
comment|// have stopped incoming appends before calling this else it will not shutdown.  We are
comment|// conservative below waiting a long time and if not elapsed, then halting.
if|if
condition|(
name|this
operator|.
name|disruptor
operator|!=
literal|null
condition|)
block|{
name|long
name|timeoutms
init|=
name|conf
operator|.
name|getLong
argument_list|(
literal|"hbase.wal.disruptor.shutdown.timeout.ms"
argument_list|,
literal|60000
argument_list|)
decl_stmt|;
try|try
block|{
name|this
operator|.
name|disruptor
operator|.
name|shutdown
argument_list|(
name|timeoutms
argument_list|,
name|TimeUnit
operator|.
name|MILLISECONDS
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|TimeoutException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Timed out bringing down disruptor after "
operator|+
name|timeoutms
operator|+
literal|"ms; forcing halt "
operator|+
literal|"(It is a problem if this is NOT an ABORT! -- DATALOSS!!!!)"
argument_list|)
expr_stmt|;
name|this
operator|.
name|disruptor
operator|.
name|halt
argument_list|()
expr_stmt|;
name|this
operator|.
name|disruptor
operator|.
name|shutdown
argument_list|()
expr_stmt|;
block|}
block|}
comment|// With disruptor down, this is safe to let go.
if|if
condition|(
name|this
operator|.
name|appendExecutor
operator|!=
literal|null
condition|)
name|this
operator|.
name|appendExecutor
operator|.
name|shutdown
argument_list|()
expr_stmt|;
comment|// Tell our listeners that the log is closing
if|if
condition|(
operator|!
name|this
operator|.
name|listeners
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
for|for
control|(
name|WALActionsListener
name|i
range|:
name|this
operator|.
name|listeners
control|)
block|{
name|i
operator|.
name|logCloseRequested
argument_list|()
expr_stmt|;
block|}
block|}
name|this
operator|.
name|closed
operator|=
literal|true
expr_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Closing WAL writer in "
operator|+
name|FSUtils
operator|.
name|getPath
argument_list|(
name|fullPathLogDir
argument_list|)
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|this
operator|.
name|writer
operator|!=
literal|null
condition|)
block|{
name|this
operator|.
name|writer
operator|.
name|close
argument_list|()
expr_stmt|;
name|this
operator|.
name|writer
operator|=
literal|null
expr_stmt|;
block|}
block|}
block|}
comment|/**    * @param now    * @param encodedRegionName Encoded name of the region as returned by    *<code>HRegionInfo#getEncodedNameAsBytes()</code>.    * @param tableName    * @param clusterIds that have consumed the change    * @return New log key.    */
specifier|protected
name|WALKey
name|makeKey
parameter_list|(
name|byte
index|[]
name|encodedRegionName
parameter_list|,
name|TableName
name|tableName
parameter_list|,
name|long
name|seqnum
parameter_list|,
name|long
name|now
parameter_list|,
name|List
argument_list|<
name|UUID
argument_list|>
name|clusterIds
parameter_list|,
name|long
name|nonceGroup
parameter_list|,
name|long
name|nonce
parameter_list|)
block|{
comment|// we use HLogKey here instead of WALKey directly to support legacy coprocessors.
return|return
operator|new
name|HLogKey
argument_list|(
name|encodedRegionName
argument_list|,
name|tableName
argument_list|,
name|seqnum
argument_list|,
name|now
argument_list|,
name|clusterIds
argument_list|,
name|nonceGroup
argument_list|,
name|nonce
argument_list|)
return|;
block|}
annotation|@
name|edu
operator|.
name|umd
operator|.
name|cs
operator|.
name|findbugs
operator|.
name|annotations
operator|.
name|SuppressWarnings
argument_list|(
name|value
operator|=
literal|"NP_NULL_ON_SOME_PATH_EXCEPTION"
argument_list|,
name|justification
operator|=
literal|"Will never be null"
argument_list|)
annotation|@
name|Override
specifier|public
name|long
name|append
parameter_list|(
specifier|final
name|HTableDescriptor
name|htd
parameter_list|,
specifier|final
name|HRegionInfo
name|hri
parameter_list|,
specifier|final
name|WALKey
name|key
parameter_list|,
specifier|final
name|WALEdit
name|edits
parameter_list|,
specifier|final
name|AtomicLong
name|sequenceId
parameter_list|,
specifier|final
name|boolean
name|inMemstore
parameter_list|,
specifier|final
name|List
argument_list|<
name|Cell
argument_list|>
name|memstoreCells
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|this
operator|.
name|closed
condition|)
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Cannot append; log is closed"
argument_list|)
throw|;
comment|// Make a trace scope for the append.  It is closed on other side of the ring buffer by the
comment|// single consuming thread.  Don't have to worry about it.
name|TraceScope
name|scope
init|=
name|Trace
operator|.
name|startSpan
argument_list|(
literal|"FSHLog.append"
argument_list|)
decl_stmt|;
comment|// This is crazy how much it takes to make an edit.  Do we need all this stuff!!!!????  We need
comment|// all this to make a key and then below to append the edit, we need to carry htd, info,
comment|// etc. all over the ring buffer.
name|FSWALEntry
name|entry
init|=
literal|null
decl_stmt|;
name|long
name|sequence
init|=
name|this
operator|.
name|disruptor
operator|.
name|getRingBuffer
argument_list|()
operator|.
name|next
argument_list|()
decl_stmt|;
try|try
block|{
name|RingBufferTruck
name|truck
init|=
name|this
operator|.
name|disruptor
operator|.
name|getRingBuffer
argument_list|()
operator|.
name|get
argument_list|(
name|sequence
argument_list|)
decl_stmt|;
comment|// Construction of FSWALEntry sets a latch.  The latch is thrown just after we stamp the
comment|// edit with its edit/sequence id.  The below entry.getRegionSequenceId will wait on the
comment|// latch to be thrown.  TODO: reuse FSWALEntry as we do SyncFuture rather create per append.
name|entry
operator|=
operator|new
name|FSWALEntry
argument_list|(
name|sequence
argument_list|,
name|key
argument_list|,
name|edits
argument_list|,
name|sequenceId
argument_list|,
name|inMemstore
argument_list|,
name|htd
argument_list|,
name|hri
argument_list|,
name|memstoreCells
argument_list|)
expr_stmt|;
name|truck
operator|.
name|loadPayload
argument_list|(
name|entry
argument_list|,
name|scope
operator|.
name|detach
argument_list|()
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|this
operator|.
name|disruptor
operator|.
name|getRingBuffer
argument_list|()
operator|.
name|publish
argument_list|(
name|sequence
argument_list|)
expr_stmt|;
block|}
return|return
name|sequence
return|;
block|}
comment|/**    * Thread to runs the hdfs sync call. This call takes a while to complete.  This is the longest    * pole adding edits to the WAL and this must complete to be sure all edits persisted.  We run    * multiple threads sync'ng rather than one that just syncs in series so we have better    * latencies; otherwise, an edit that arrived just after a sync started, might have to wait    * almost the length of two sync invocations before it is marked done.    *<p>When the sync completes, it marks all the passed in futures done.  On the other end of the    * sync future is a blocked thread, usually a regionserver Handler.  There may be more than one    * future passed in the case where a few threads arrive at about the same time and all invoke    * 'sync'.  In this case we'll batch up the invocations and run one filesystem sync only for a    * batch of Handler sync invocations.  Do not confuse these Handler SyncFutures with the futures    * an ExecutorService returns when you call submit. We have no use for these in this model. These    * SyncFutures are 'artificial', something to hold the Handler until the filesystem sync    * completes.    */
specifier|private
class|class
name|SyncRunner
extends|extends
name|HasThread
block|{
specifier|private
specifier|volatile
name|long
name|sequence
decl_stmt|;
specifier|private
specifier|final
name|BlockingQueue
argument_list|<
name|SyncFuture
argument_list|>
name|syncFutures
decl_stmt|;
comment|/**      * UPDATE!       * @param syncs the batch of calls to sync that arrived as this thread was starting; when done,      * we will put the result of the actual hdfs sync call as the result.      * @param sequence The sequence number on the ring buffer when this thread was set running.      * If this actual writer sync completes then all appends up this point have been      * flushed/synced/pushed to datanodes.  If we fail, then the passed in<code>syncs</code>      * futures will return the exception to their clients; some of the edits may have made it out      * to data nodes but we will report all that were part of this session as failed.      */
name|SyncRunner
parameter_list|(
specifier|final
name|String
name|name
parameter_list|,
specifier|final
name|int
name|maxHandlersCount
parameter_list|)
block|{
name|super
argument_list|(
name|name
argument_list|)
expr_stmt|;
comment|// LinkedBlockingQueue because of
comment|// http://www.javacodegeeks.com/2010/09/java-best-practices-queue-battle-and.html
comment|// Could use other blockingqueues here or concurrent queues.
comment|//
comment|// We could let the capacity be 'open' but bound it so we get alerted in pathological case
comment|// where we cannot sync and we have a bunch of threads all backed up waiting on their syncs
comment|// to come in.  LinkedBlockingQueue actually shrinks when you remove elements so Q should
comment|// stay neat and tidy in usual case.  Let the max size be three times the maximum handlers.
comment|// The passed in maxHandlerCount is the user-level handlers which is what we put up most of
comment|// but HBase has other handlers running too -- opening region handlers which want to write
comment|// the meta table when succesful (i.e. sync), closing handlers -- etc.  These are usually
comment|// much fewer in number than the user-space handlers so Q-size should be user handlers plus
comment|// some space for these other handlers.  Lets multiply by 3 for good-measure.
name|this
operator|.
name|syncFutures
operator|=
operator|new
name|LinkedBlockingQueue
argument_list|<
name|SyncFuture
argument_list|>
argument_list|(
name|maxHandlersCount
operator|*
literal|3
argument_list|)
expr_stmt|;
block|}
name|void
name|offer
parameter_list|(
specifier|final
name|long
name|sequence
parameter_list|,
specifier|final
name|SyncFuture
index|[]
name|syncFutures
parameter_list|,
specifier|final
name|int
name|syncFutureCount
parameter_list|)
block|{
comment|// Set sequence first because the add to the queue will wake the thread if sleeping.
name|this
operator|.
name|sequence
operator|=
name|sequence
expr_stmt|;
name|this
operator|.
name|syncFutures
operator|.
name|addAll
argument_list|(
name|Arrays
operator|.
name|asList
argument_list|(
name|syncFutures
argument_list|)
operator|.
name|subList
argument_list|(
literal|0
argument_list|,
name|syncFutureCount
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|/**      * Release the passed<code>syncFuture</code>      * @param syncFuture      * @param currentSequence      * @param t      * @return Returns 1.      */
specifier|private
name|int
name|releaseSyncFuture
parameter_list|(
specifier|final
name|SyncFuture
name|syncFuture
parameter_list|,
specifier|final
name|long
name|currentSequence
parameter_list|,
specifier|final
name|Throwable
name|t
parameter_list|)
block|{
if|if
condition|(
operator|!
name|syncFuture
operator|.
name|done
argument_list|(
name|currentSequence
argument_list|,
name|t
argument_list|)
condition|)
throw|throw
operator|new
name|IllegalStateException
argument_list|()
throw|;
comment|// This function releases one sync future only.
return|return
literal|1
return|;
block|}
comment|/**      * Release all SyncFutures whose sequence is<=<code>currentSequence</code>.      * @param currentSequence      * @param t May be non-null if we are processing SyncFutures because an exception was thrown.      * @return Count of SyncFutures we let go.      */
specifier|private
name|int
name|releaseSyncFutures
parameter_list|(
specifier|final
name|long
name|currentSequence
parameter_list|,
specifier|final
name|Throwable
name|t
parameter_list|)
block|{
name|int
name|syncCount
init|=
literal|0
decl_stmt|;
for|for
control|(
name|SyncFuture
name|syncFuture
init|;
operator|(
name|syncFuture
operator|=
name|this
operator|.
name|syncFutures
operator|.
name|peek
argument_list|()
operator|)
operator|!=
literal|null
condition|;
control|)
block|{
if|if
condition|(
name|syncFuture
operator|.
name|getRingBufferSequence
argument_list|()
operator|>
name|currentSequence
condition|)
break|break;
name|releaseSyncFuture
argument_list|(
name|syncFuture
argument_list|,
name|currentSequence
argument_list|,
name|t
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|this
operator|.
name|syncFutures
operator|.
name|remove
argument_list|(
name|syncFuture
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IllegalStateException
argument_list|(
name|syncFuture
operator|.
name|toString
argument_list|()
argument_list|)
throw|;
block|}
name|syncCount
operator|++
expr_stmt|;
block|}
return|return
name|syncCount
return|;
block|}
comment|/**      * @param sequence The sequence we ran the filesystem sync against.      * @return Current highest synced sequence.      */
specifier|private
name|long
name|updateHighestSyncedSequence
parameter_list|(
name|long
name|sequence
parameter_list|)
block|{
name|long
name|currentHighestSyncedSequence
decl_stmt|;
comment|// Set the highestSyncedSequence IFF our current sequence id is the 'highest'.
do|do
block|{
name|currentHighestSyncedSequence
operator|=
name|highestSyncedSequence
operator|.
name|get
argument_list|()
expr_stmt|;
if|if
condition|(
name|currentHighestSyncedSequence
operator|>=
name|sequence
condition|)
block|{
comment|// Set the sync number to current highwater mark; might be able to let go more
comment|// queued sync futures
name|sequence
operator|=
name|currentHighestSyncedSequence
expr_stmt|;
break|break;
block|}
block|}
do|while
condition|(
operator|!
name|highestSyncedSequence
operator|.
name|compareAndSet
argument_list|(
name|currentHighestSyncedSequence
argument_list|,
name|sequence
argument_list|)
condition|)
do|;
return|return
name|sequence
return|;
block|}
specifier|public
name|void
name|run
parameter_list|()
block|{
name|long
name|currentSequence
decl_stmt|;
while|while
condition|(
operator|!
name|isInterrupted
argument_list|()
condition|)
block|{
name|int
name|syncCount
init|=
literal|0
decl_stmt|;
name|SyncFuture
name|takeSyncFuture
decl_stmt|;
try|try
block|{
while|while
condition|(
literal|true
condition|)
block|{
comment|// We have to process what we 'take' from the queue
name|takeSyncFuture
operator|=
name|this
operator|.
name|syncFutures
operator|.
name|take
argument_list|()
expr_stmt|;
name|currentSequence
operator|=
name|this
operator|.
name|sequence
expr_stmt|;
name|long
name|syncFutureSequence
init|=
name|takeSyncFuture
operator|.
name|getRingBufferSequence
argument_list|()
decl_stmt|;
if|if
condition|(
name|syncFutureSequence
operator|>
name|currentSequence
condition|)
block|{
throw|throw
operator|new
name|IllegalStateException
argument_list|(
literal|"currentSequence="
operator|+
name|syncFutureSequence
operator|+
literal|", syncFutureSequence="
operator|+
name|syncFutureSequence
argument_list|)
throw|;
block|}
comment|// See if we can process any syncfutures BEFORE we go sync.
name|long
name|currentHighestSyncedSequence
init|=
name|highestSyncedSequence
operator|.
name|get
argument_list|()
decl_stmt|;
if|if
condition|(
name|currentSequence
operator|<
name|currentHighestSyncedSequence
condition|)
block|{
name|syncCount
operator|+=
name|releaseSyncFuture
argument_list|(
name|takeSyncFuture
argument_list|,
name|currentHighestSyncedSequence
argument_list|,
literal|null
argument_list|)
expr_stmt|;
comment|// Done with the 'take'.  Go around again and do a new 'take'.
continue|continue;
block|}
break|break;
block|}
comment|// I got something.  Lets run.  Save off current sequence number in case it changes
comment|// while we run.
name|TraceScope
name|scope
init|=
name|Trace
operator|.
name|continueSpan
argument_list|(
name|takeSyncFuture
operator|.
name|getSpan
argument_list|()
argument_list|)
decl_stmt|;
name|long
name|start
init|=
name|System
operator|.
name|nanoTime
argument_list|()
decl_stmt|;
name|Throwable
name|t
init|=
literal|null
decl_stmt|;
try|try
block|{
name|Trace
operator|.
name|addTimelineAnnotation
argument_list|(
literal|"syncing writer"
argument_list|)
expr_stmt|;
name|writer
operator|.
name|sync
argument_list|()
expr_stmt|;
name|Trace
operator|.
name|addTimelineAnnotation
argument_list|(
literal|"writer synced"
argument_list|)
expr_stmt|;
name|currentSequence
operator|=
name|updateHighestSyncedSequence
argument_list|(
name|currentSequence
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Error syncing, request close of wal "
argument_list|,
name|e
argument_list|)
expr_stmt|;
name|t
operator|=
name|e
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"UNEXPECTED"
argument_list|,
name|e
argument_list|)
expr_stmt|;
name|t
operator|=
name|e
expr_stmt|;
block|}
finally|finally
block|{
comment|// reattach the span to the future before releasing.
name|takeSyncFuture
operator|.
name|setSpan
argument_list|(
name|scope
operator|.
name|detach
argument_list|()
argument_list|)
expr_stmt|;
comment|// First release what we 'took' from the queue.
name|syncCount
operator|+=
name|releaseSyncFuture
argument_list|(
name|takeSyncFuture
argument_list|,
name|currentSequence
argument_list|,
name|t
argument_list|)
expr_stmt|;
comment|// Can we release other syncs?
name|syncCount
operator|+=
name|releaseSyncFutures
argument_list|(
name|currentSequence
argument_list|,
name|t
argument_list|)
expr_stmt|;
if|if
condition|(
name|t
operator|!=
literal|null
condition|)
block|{
name|requestLogRoll
argument_list|()
expr_stmt|;
block|}
else|else
name|checkLogRoll
argument_list|()
expr_stmt|;
block|}
name|postSync
argument_list|(
name|System
operator|.
name|nanoTime
argument_list|()
operator|-
name|start
argument_list|,
name|syncCount
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
comment|// Presume legit interrupt.
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|interrupt
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Throwable
name|t
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"UNEXPECTED, continuing"
argument_list|,
name|t
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
comment|/**    * Schedule a log roll if needed.    */
name|void
name|checkLogRoll
parameter_list|()
block|{
comment|// Will return immediately if we are in the middle of a WAL log roll currently.
if|if
condition|(
operator|!
name|rollWriterLock
operator|.
name|tryLock
argument_list|()
condition|)
return|return;
name|boolean
name|lowReplication
decl_stmt|;
try|try
block|{
name|lowReplication
operator|=
name|checkLowReplication
argument_list|()
expr_stmt|;
block|}
finally|finally
block|{
name|rollWriterLock
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
try|try
block|{
if|if
condition|(
name|lowReplication
operator|||
name|writer
operator|!=
literal|null
operator|&&
name|writer
operator|.
name|getLength
argument_list|()
operator|>
name|logrollsize
condition|)
block|{
name|requestLogRoll
argument_list|(
name|lowReplication
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Writer.getLength() failed; continuing"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
block|}
comment|/*    * @return true if number of replicas for the WAL is lower than threshold    */
specifier|private
name|boolean
name|checkLowReplication
parameter_list|()
block|{
name|boolean
name|logRollNeeded
init|=
literal|false
decl_stmt|;
comment|// if the number of replicas in HDFS has fallen below the configured
comment|// value, then roll logs.
try|try
block|{
name|int
name|numCurrentReplicas
init|=
name|getLogReplication
argument_list|()
decl_stmt|;
if|if
condition|(
name|numCurrentReplicas
operator|!=
literal|0
operator|&&
name|numCurrentReplicas
operator|<
name|this
operator|.
name|minTolerableReplication
condition|)
block|{
if|if
condition|(
name|this
operator|.
name|lowReplicationRollEnabled
condition|)
block|{
if|if
condition|(
name|this
operator|.
name|consecutiveLogRolls
operator|.
name|get
argument_list|()
operator|<
name|this
operator|.
name|lowReplicationRollLimit
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"HDFS pipeline error detected. "
operator|+
literal|"Found "
operator|+
name|numCurrentReplicas
operator|+
literal|" replicas but expecting no less than "
operator|+
name|this
operator|.
name|minTolerableReplication
operator|+
literal|" replicas. "
operator|+
literal|" Requesting close of wal."
argument_list|)
expr_stmt|;
name|logRollNeeded
operator|=
literal|true
expr_stmt|;
comment|// If rollWriter is requested, increase consecutiveLogRolls. Once it
comment|// is larger than lowReplicationRollLimit, disable the
comment|// LowReplication-Roller
name|this
operator|.
name|consecutiveLogRolls
operator|.
name|getAndIncrement
argument_list|()
expr_stmt|;
block|}
else|else
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Too many consecutive RollWriter requests, it's a sign of "
operator|+
literal|"the total number of live datanodes is lower than the tolerable replicas."
argument_list|)
expr_stmt|;
name|this
operator|.
name|consecutiveLogRolls
operator|.
name|set
argument_list|(
literal|0
argument_list|)
expr_stmt|;
name|this
operator|.
name|lowReplicationRollEnabled
operator|=
literal|false
expr_stmt|;
block|}
block|}
block|}
elseif|else
if|if
condition|(
name|numCurrentReplicas
operator|>=
name|this
operator|.
name|minTolerableReplication
condition|)
block|{
if|if
condition|(
operator|!
name|this
operator|.
name|lowReplicationRollEnabled
condition|)
block|{
comment|// The new writer's log replicas is always the default value.
comment|// So we should not enable LowReplication-Roller. If numEntries
comment|// is lower than or equals 1, we consider it as a new writer.
if|if
condition|(
name|this
operator|.
name|numEntries
operator|.
name|get
argument_list|()
operator|<=
literal|1
condition|)
block|{
return|return
name|logRollNeeded
return|;
block|}
comment|// Once the live datanode number and the replicas return to normal,
comment|// enable the LowReplication-Roller.
name|this
operator|.
name|lowReplicationRollEnabled
operator|=
literal|true
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"LowReplication-Roller was enabled."
argument_list|)
expr_stmt|;
block|}
block|}
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Unable to invoke DFSOutputStream.getNumCurrentReplicas"
operator|+
name|e
operator|+
literal|" still proceeding ahead..."
argument_list|)
expr_stmt|;
block|}
return|return
name|logRollNeeded
return|;
block|}
specifier|private
name|SyncFuture
name|publishSyncOnRingBuffer
parameter_list|()
block|{
return|return
name|publishSyncOnRingBuffer
argument_list|(
literal|null
argument_list|)
return|;
block|}
specifier|private
name|SyncFuture
name|publishSyncOnRingBuffer
parameter_list|(
name|Span
name|span
parameter_list|)
block|{
name|long
name|sequence
init|=
name|this
operator|.
name|disruptor
operator|.
name|getRingBuffer
argument_list|()
operator|.
name|next
argument_list|()
decl_stmt|;
name|SyncFuture
name|syncFuture
init|=
name|getSyncFuture
argument_list|(
name|sequence
argument_list|,
name|span
argument_list|)
decl_stmt|;
try|try
block|{
name|RingBufferTruck
name|truck
init|=
name|this
operator|.
name|disruptor
operator|.
name|getRingBuffer
argument_list|()
operator|.
name|get
argument_list|(
name|sequence
argument_list|)
decl_stmt|;
name|truck
operator|.
name|loadPayload
argument_list|(
name|syncFuture
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|this
operator|.
name|disruptor
operator|.
name|getRingBuffer
argument_list|()
operator|.
name|publish
argument_list|(
name|sequence
argument_list|)
expr_stmt|;
block|}
return|return
name|syncFuture
return|;
block|}
comment|// Sync all known transactions
specifier|private
name|Span
name|publishSyncThenBlockOnCompletion
parameter_list|(
name|Span
name|span
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|blockOnSync
argument_list|(
name|publishSyncOnRingBuffer
argument_list|(
name|span
argument_list|)
argument_list|)
return|;
block|}
specifier|private
name|Span
name|blockOnSync
parameter_list|(
specifier|final
name|SyncFuture
name|syncFuture
parameter_list|)
throws|throws
name|IOException
block|{
comment|// Now we have published the ringbuffer, halt the current thread until we get an answer back.
try|try
block|{
name|syncFuture
operator|.
name|get
argument_list|()
expr_stmt|;
return|return
name|syncFuture
operator|.
name|getSpan
argument_list|()
return|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|ie
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Interrupted"
argument_list|,
name|ie
argument_list|)
expr_stmt|;
throw|throw
name|convertInterruptedExceptionToIOException
argument_list|(
name|ie
argument_list|)
throw|;
block|}
catch|catch
parameter_list|(
name|ExecutionException
name|e
parameter_list|)
block|{
throw|throw
name|ensureIOException
argument_list|(
name|e
operator|.
name|getCause
argument_list|()
argument_list|)
throw|;
block|}
block|}
specifier|private
name|IOException
name|convertInterruptedExceptionToIOException
parameter_list|(
specifier|final
name|InterruptedException
name|ie
parameter_list|)
block|{
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|interrupt
argument_list|()
expr_stmt|;
name|IOException
name|ioe
init|=
operator|new
name|InterruptedIOException
argument_list|()
decl_stmt|;
name|ioe
operator|.
name|initCause
argument_list|(
name|ie
argument_list|)
expr_stmt|;
return|return
name|ioe
return|;
block|}
specifier|private
name|SyncFuture
name|getSyncFuture
parameter_list|(
specifier|final
name|long
name|sequence
parameter_list|,
name|Span
name|span
parameter_list|)
block|{
name|SyncFuture
name|syncFuture
init|=
name|this
operator|.
name|syncFuturesByHandler
operator|.
name|get
argument_list|(
name|Thread
operator|.
name|currentThread
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|syncFuture
operator|==
literal|null
condition|)
block|{
name|syncFuture
operator|=
operator|new
name|SyncFuture
argument_list|()
expr_stmt|;
name|this
operator|.
name|syncFuturesByHandler
operator|.
name|put
argument_list|(
name|Thread
operator|.
name|currentThread
argument_list|()
argument_list|,
name|syncFuture
argument_list|)
expr_stmt|;
block|}
return|return
name|syncFuture
operator|.
name|reset
argument_list|(
name|sequence
argument_list|,
name|span
argument_list|)
return|;
block|}
specifier|private
name|void
name|postSync
parameter_list|(
specifier|final
name|long
name|timeInNanos
parameter_list|,
specifier|final
name|int
name|handlerSyncs
parameter_list|)
block|{
if|if
condition|(
name|timeInNanos
operator|>
name|this
operator|.
name|slowSyncNs
condition|)
block|{
name|String
name|msg
init|=
operator|new
name|StringBuilder
argument_list|()
operator|.
name|append
argument_list|(
literal|"Slow sync cost: "
argument_list|)
operator|.
name|append
argument_list|(
name|timeInNanos
operator|/
literal|1000000
argument_list|)
operator|.
name|append
argument_list|(
literal|" ms, current pipeline: "
argument_list|)
operator|.
name|append
argument_list|(
name|Arrays
operator|.
name|toString
argument_list|(
name|getPipeLine
argument_list|()
argument_list|)
argument_list|)
operator|.
name|toString
argument_list|()
decl_stmt|;
name|Trace
operator|.
name|addTimelineAnnotation
argument_list|(
name|msg
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
name|msg
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|!
name|listeners
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
for|for
control|(
name|WALActionsListener
name|listener
range|:
name|listeners
control|)
block|{
name|listener
operator|.
name|postSync
argument_list|(
name|timeInNanos
argument_list|,
name|handlerSyncs
argument_list|)
expr_stmt|;
block|}
block|}
block|}
specifier|private
name|long
name|postAppend
parameter_list|(
specifier|final
name|Entry
name|e
parameter_list|,
specifier|final
name|long
name|elapsedTime
parameter_list|)
block|{
name|long
name|len
init|=
literal|0
decl_stmt|;
if|if
condition|(
operator|!
name|listeners
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
for|for
control|(
name|Cell
name|cell
range|:
name|e
operator|.
name|getEdit
argument_list|()
operator|.
name|getCells
argument_list|()
control|)
block|{
name|len
operator|+=
name|CellUtil
operator|.
name|estimatedSerializedSizeOf
argument_list|(
name|cell
argument_list|)
expr_stmt|;
block|}
for|for
control|(
name|WALActionsListener
name|listener
range|:
name|listeners
control|)
block|{
name|listener
operator|.
name|postAppend
argument_list|(
name|len
argument_list|,
name|elapsedTime
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|len
return|;
block|}
comment|/**    * Find the 'getNumCurrentReplicas' on the passed<code>os</code> stream.    * This is used for getting current replicas of a file being written.    * @return Method or null.    */
specifier|private
name|Method
name|getGetNumCurrentReplicas
parameter_list|(
specifier|final
name|FSDataOutputStream
name|os
parameter_list|)
block|{
comment|// TODO: Remove all this and use the now publically available
comment|// HdfsDataOutputStream#getCurrentBlockReplication()
name|Method
name|m
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|os
operator|!=
literal|null
condition|)
block|{
name|Class
argument_list|<
name|?
extends|extends
name|OutputStream
argument_list|>
name|wrappedStreamClass
init|=
name|os
operator|.
name|getWrappedStream
argument_list|()
operator|.
name|getClass
argument_list|()
decl_stmt|;
try|try
block|{
name|m
operator|=
name|wrappedStreamClass
operator|.
name|getDeclaredMethod
argument_list|(
literal|"getNumCurrentReplicas"
argument_list|,
operator|new
name|Class
argument_list|<
name|?
argument_list|>
index|[]
block|{}
block|)
empty_stmt|;
name|m
operator|.
name|setAccessible
argument_list|(
literal|true
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|NoSuchMethodException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"FileSystem's output stream doesn't support getNumCurrentReplicas; "
operator|+
literal|"HDFS-826 not available; fsOut="
operator|+
name|wrappedStreamClass
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|SecurityException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"No access to getNumCurrentReplicas on FileSystems's output stream; HDFS-826 "
operator|+
literal|"not available; fsOut="
operator|+
name|wrappedStreamClass
operator|.
name|getName
argument_list|()
argument_list|,
name|e
argument_list|)
expr_stmt|;
name|m
operator|=
literal|null
expr_stmt|;
comment|// could happen on setAccessible()
block|}
block|}
if|if
condition|(
name|m
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
name|LOG
operator|.
name|isTraceEnabled
argument_list|()
condition|)
name|LOG
operator|.
name|trace
argument_list|(
literal|"Using getNumCurrentReplicas"
argument_list|)
expr_stmt|;
block|}
return|return
name|m
return|;
block|}
end_class

begin_comment
comment|/**    * This method gets the datanode replication count for the current WAL.    *    * If the pipeline isn't started yet or is empty, you will get the default    * replication factor.  Therefore, if this function returns 0, it means you    * are not properly running with the HDFS-826 patch.    * @throws InvocationTargetException    * @throws IllegalAccessException    * @throws IllegalArgumentException    *    * @throws Exception    */
end_comment

begin_function
annotation|@
name|VisibleForTesting
name|int
name|getLogReplication
parameter_list|()
throws|throws
name|IllegalArgumentException
throws|,
name|IllegalAccessException
throws|,
name|InvocationTargetException
block|{
specifier|final
name|OutputStream
name|stream
init|=
name|getOutputStream
argument_list|()
decl_stmt|;
if|if
condition|(
name|this
operator|.
name|getNumCurrentReplicas
operator|!=
literal|null
operator|&&
name|stream
operator|!=
literal|null
condition|)
block|{
name|Object
name|repl
init|=
name|this
operator|.
name|getNumCurrentReplicas
operator|.
name|invoke
argument_list|(
name|stream
argument_list|,
name|NO_ARGS
argument_list|)
decl_stmt|;
if|if
condition|(
name|repl
operator|instanceof
name|Integer
condition|)
block|{
return|return
operator|(
operator|(
name|Integer
operator|)
name|repl
operator|)
operator|.
name|intValue
argument_list|()
return|;
block|}
block|}
return|return
literal|0
return|;
block|}
end_function

begin_function
annotation|@
name|Override
specifier|public
name|void
name|sync
parameter_list|()
throws|throws
name|IOException
block|{
name|TraceScope
name|scope
init|=
name|Trace
operator|.
name|startSpan
argument_list|(
literal|"FSHLog.sync"
argument_list|)
decl_stmt|;
try|try
block|{
name|scope
operator|=
name|Trace
operator|.
name|continueSpan
argument_list|(
name|publishSyncThenBlockOnCompletion
argument_list|(
name|scope
operator|.
name|detach
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
assert|assert
name|scope
operator|==
name|NullScope
operator|.
name|INSTANCE
operator|||
operator|!
name|scope
operator|.
name|isDetached
argument_list|()
assert|;
name|scope
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
block|}
end_function

begin_function
annotation|@
name|Override
specifier|public
name|void
name|sync
parameter_list|(
name|long
name|txid
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|this
operator|.
name|highestSyncedSequence
operator|.
name|get
argument_list|()
operator|>=
name|txid
condition|)
block|{
comment|// Already sync'd.
return|return;
block|}
name|TraceScope
name|scope
init|=
name|Trace
operator|.
name|startSpan
argument_list|(
literal|"FSHLog.sync"
argument_list|)
decl_stmt|;
try|try
block|{
name|scope
operator|=
name|Trace
operator|.
name|continueSpan
argument_list|(
name|publishSyncThenBlockOnCompletion
argument_list|(
name|scope
operator|.
name|detach
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
assert|assert
name|scope
operator|==
name|NullScope
operator|.
name|INSTANCE
operator|||
operator|!
name|scope
operator|.
name|isDetached
argument_list|()
assert|;
name|scope
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|// public only until class moves to o.a.h.h.wal
end_comment

begin_function
specifier|public
name|void
name|requestLogRoll
parameter_list|()
block|{
name|requestLogRoll
argument_list|(
literal|false
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|private
name|void
name|requestLogRoll
parameter_list|(
name|boolean
name|tooFewReplicas
parameter_list|)
block|{
if|if
condition|(
operator|!
name|this
operator|.
name|listeners
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
for|for
control|(
name|WALActionsListener
name|i
range|:
name|this
operator|.
name|listeners
control|)
block|{
name|i
operator|.
name|logRollRequested
argument_list|(
name|tooFewReplicas
argument_list|)
expr_stmt|;
block|}
block|}
block|}
end_function

begin_comment
comment|// public only until class moves to o.a.h.h.wal
end_comment

begin_comment
comment|/** @return the number of rolled log files */
end_comment

begin_function
specifier|public
name|int
name|getNumRolledLogFiles
parameter_list|()
block|{
return|return
name|byWalRegionSequenceIds
operator|.
name|size
argument_list|()
return|;
block|}
end_function

begin_comment
comment|// public only until class moves to o.a.h.h.wal
end_comment

begin_comment
comment|/** @return the number of log files in use */
end_comment

begin_function
specifier|public
name|int
name|getNumLogFiles
parameter_list|()
block|{
comment|// +1 for current use log
return|return
name|getNumRolledLogFiles
argument_list|()
operator|+
literal|1
return|;
block|}
end_function

begin_comment
comment|// public only until class moves to o.a.h.h.wal
end_comment

begin_comment
comment|/** @return the size of log files in use */
end_comment

begin_function
specifier|public
name|long
name|getLogFileSize
parameter_list|()
block|{
return|return
name|this
operator|.
name|totalLogSize
operator|.
name|get
argument_list|()
return|;
block|}
end_function

begin_function
annotation|@
name|Override
specifier|public
name|boolean
name|startCacheFlush
parameter_list|(
specifier|final
name|byte
index|[]
name|encodedRegionName
parameter_list|,
name|Set
argument_list|<
name|byte
index|[]
argument_list|>
name|flushedFamilyNames
parameter_list|)
block|{
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|Long
argument_list|>
name|oldStoreSeqNum
init|=
name|Maps
operator|.
name|newTreeMap
argument_list|(
name|Bytes
operator|.
name|BYTES_COMPARATOR
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|closeBarrier
operator|.
name|beginOp
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Flush will not be started for "
operator|+
name|Bytes
operator|.
name|toString
argument_list|(
name|encodedRegionName
argument_list|)
operator|+
literal|" - because the server is closing."
argument_list|)
expr_stmt|;
return|return
literal|false
return|;
block|}
synchronized|synchronized
init|(
name|regionSequenceIdLock
init|)
block|{
name|ConcurrentMap
argument_list|<
name|byte
index|[]
argument_list|,
name|Long
argument_list|>
name|oldestUnflushedStoreSequenceIdsOfRegion
init|=
name|oldestUnflushedStoreSequenceIds
operator|.
name|get
argument_list|(
name|encodedRegionName
argument_list|)
decl_stmt|;
if|if
condition|(
name|oldestUnflushedStoreSequenceIdsOfRegion
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|byte
index|[]
name|familyName
range|:
name|flushedFamilyNames
control|)
block|{
name|Long
name|seqId
init|=
name|oldestUnflushedStoreSequenceIdsOfRegion
operator|.
name|remove
argument_list|(
name|familyName
argument_list|)
decl_stmt|;
if|if
condition|(
name|seqId
operator|!=
literal|null
condition|)
block|{
name|oldStoreSeqNum
operator|.
name|put
argument_list|(
name|familyName
argument_list|,
name|seqId
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
operator|!
name|oldStoreSeqNum
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|Long
argument_list|>
name|oldValue
init|=
name|this
operator|.
name|lowestFlushingStoreSequenceIds
operator|.
name|put
argument_list|(
name|encodedRegionName
argument_list|,
name|oldStoreSeqNum
argument_list|)
decl_stmt|;
assert|assert
name|oldValue
operator|==
literal|null
operator|:
literal|"Flushing map not cleaned up for "
operator|+
name|Bytes
operator|.
name|toString
argument_list|(
name|encodedRegionName
argument_list|)
assert|;
block|}
if|if
condition|(
name|oldestUnflushedStoreSequenceIdsOfRegion
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
comment|// Remove it otherwise it will be in oldestUnflushedStoreSequenceIds for ever
comment|// even if the region is already moved to other server.
comment|// Do not worry about data racing, we held write lock of region when calling
comment|// startCacheFlush, so no one can add value to the map we removed.
name|oldestUnflushedStoreSequenceIds
operator|.
name|remove
argument_list|(
name|encodedRegionName
argument_list|)
expr_stmt|;
block|}
block|}
block|}
if|if
condition|(
name|oldStoreSeqNum
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
comment|// TODO: if we have no oldStoreSeqNum, and WAL is not disabled, presumably either
comment|// the region is already flushing (which would make this call invalid), or there
comment|// were no appends after last flush, so why are we starting flush? Maybe we should
comment|// assert not empty. Less rigorous, but safer, alternative is telling the caller to stop.
comment|// For now preserve old logic.
name|LOG
operator|.
name|warn
argument_list|(
literal|"Couldn't find oldest seqNum for the region we are about to flush: ["
operator|+
name|Bytes
operator|.
name|toString
argument_list|(
name|encodedRegionName
argument_list|)
operator|+
literal|"]"
argument_list|)
expr_stmt|;
block|}
return|return
literal|true
return|;
block|}
end_function

begin_function
annotation|@
name|Override
specifier|public
name|void
name|completeCacheFlush
parameter_list|(
specifier|final
name|byte
index|[]
name|encodedRegionName
parameter_list|)
block|{
synchronized|synchronized
init|(
name|regionSequenceIdLock
init|)
block|{
name|this
operator|.
name|lowestFlushingStoreSequenceIds
operator|.
name|remove
argument_list|(
name|encodedRegionName
argument_list|)
expr_stmt|;
block|}
name|closeBarrier
operator|.
name|endOp
argument_list|()
expr_stmt|;
block|}
end_function

begin_function
specifier|private
name|ConcurrentMap
argument_list|<
name|byte
index|[]
argument_list|,
name|Long
argument_list|>
name|getOrCreateOldestUnflushedStoreSequenceIdsOfRegion
parameter_list|(
name|byte
index|[]
name|encodedRegionName
parameter_list|)
block|{
name|ConcurrentMap
argument_list|<
name|byte
index|[]
argument_list|,
name|Long
argument_list|>
name|oldestUnflushedStoreSequenceIdsOfRegion
init|=
name|oldestUnflushedStoreSequenceIds
operator|.
name|get
argument_list|(
name|encodedRegionName
argument_list|)
decl_stmt|;
if|if
condition|(
name|oldestUnflushedStoreSequenceIdsOfRegion
operator|!=
literal|null
condition|)
block|{
return|return
name|oldestUnflushedStoreSequenceIdsOfRegion
return|;
block|}
name|oldestUnflushedStoreSequenceIdsOfRegion
operator|=
operator|new
name|ConcurrentSkipListMap
argument_list|<
name|byte
index|[]
argument_list|,
name|Long
argument_list|>
argument_list|(
name|Bytes
operator|.
name|BYTES_COMPARATOR
argument_list|)
expr_stmt|;
name|ConcurrentMap
argument_list|<
name|byte
index|[]
argument_list|,
name|Long
argument_list|>
name|alreadyPut
init|=
name|oldestUnflushedStoreSequenceIds
operator|.
name|putIfAbsent
argument_list|(
name|encodedRegionName
argument_list|,
name|oldestUnflushedStoreSequenceIdsOfRegion
argument_list|)
decl_stmt|;
return|return
name|alreadyPut
operator|==
literal|null
condition|?
name|oldestUnflushedStoreSequenceIdsOfRegion
else|:
name|alreadyPut
return|;
block|}
end_function

begin_function
annotation|@
name|Override
specifier|public
name|void
name|abortCacheFlush
parameter_list|(
name|byte
index|[]
name|encodedRegionName
parameter_list|)
block|{
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|Long
argument_list|>
name|storeSeqNumsBeforeFlushStarts
decl_stmt|;
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|Long
argument_list|>
name|currentStoreSeqNums
init|=
operator|new
name|TreeMap
argument_list|<
name|byte
index|[]
argument_list|,
name|Long
argument_list|>
argument_list|(
name|Bytes
operator|.
name|BYTES_COMPARATOR
argument_list|)
decl_stmt|;
synchronized|synchronized
init|(
name|regionSequenceIdLock
init|)
block|{
name|storeSeqNumsBeforeFlushStarts
operator|=
name|this
operator|.
name|lowestFlushingStoreSequenceIds
operator|.
name|remove
argument_list|(
name|encodedRegionName
argument_list|)
expr_stmt|;
if|if
condition|(
name|storeSeqNumsBeforeFlushStarts
operator|!=
literal|null
condition|)
block|{
name|ConcurrentMap
argument_list|<
name|byte
index|[]
argument_list|,
name|Long
argument_list|>
name|oldestUnflushedStoreSequenceIdsOfRegion
init|=
name|getOrCreateOldestUnflushedStoreSequenceIdsOfRegion
argument_list|(
name|encodedRegionName
argument_list|)
decl_stmt|;
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|byte
index|[]
argument_list|,
name|Long
argument_list|>
name|familyNameAndSeqId
range|:
name|storeSeqNumsBeforeFlushStarts
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|currentStoreSeqNums
operator|.
name|put
argument_list|(
name|familyNameAndSeqId
operator|.
name|getKey
argument_list|()
argument_list|,
name|oldestUnflushedStoreSequenceIdsOfRegion
operator|.
name|put
argument_list|(
name|familyNameAndSeqId
operator|.
name|getKey
argument_list|()
argument_list|,
name|familyNameAndSeqId
operator|.
name|getValue
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
block|}
name|closeBarrier
operator|.
name|endOp
argument_list|()
expr_stmt|;
if|if
condition|(
name|storeSeqNumsBeforeFlushStarts
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|byte
index|[]
argument_list|,
name|Long
argument_list|>
name|familyNameAndSeqId
range|:
name|storeSeqNumsBeforeFlushStarts
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|Long
name|currentSeqNum
init|=
name|currentStoreSeqNums
operator|.
name|get
argument_list|(
name|familyNameAndSeqId
operator|.
name|getKey
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|currentSeqNum
operator|!=
literal|null
operator|&&
name|currentSeqNum
operator|.
name|longValue
argument_list|()
operator|<=
name|familyNameAndSeqId
operator|.
name|getValue
argument_list|()
operator|.
name|longValue
argument_list|()
condition|)
block|{
name|String
name|errorStr
init|=
literal|"Region "
operator|+
name|Bytes
operator|.
name|toString
argument_list|(
name|encodedRegionName
argument_list|)
operator|+
literal|" family "
operator|+
name|Bytes
operator|.
name|toString
argument_list|(
name|familyNameAndSeqId
operator|.
name|getKey
argument_list|()
argument_list|)
operator|+
literal|" acquired edits out of order current memstore seq="
operator|+
name|currentSeqNum
operator|+
literal|", previous oldest unflushed id="
operator|+
name|familyNameAndSeqId
operator|.
name|getValue
argument_list|()
decl_stmt|;
name|LOG
operator|.
name|error
argument_list|(
name|errorStr
argument_list|)
expr_stmt|;
name|Runtime
operator|.
name|getRuntime
argument_list|()
operator|.
name|halt
argument_list|(
literal|1
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
end_function

begin_function
annotation|@
name|VisibleForTesting
name|boolean
name|isLowReplicationRollEnabled
parameter_list|()
block|{
return|return
name|lowReplicationRollEnabled
return|;
block|}
end_function

begin_decl_stmt
specifier|public
specifier|static
specifier|final
name|long
name|FIXED_OVERHEAD
init|=
name|ClassSize
operator|.
name|align
argument_list|(
name|ClassSize
operator|.
name|OBJECT
operator|+
operator|(
literal|5
operator|*
name|ClassSize
operator|.
name|REFERENCE
operator|)
operator|+
name|ClassSize
operator|.
name|ATOMIC_INTEGER
operator|+
name|Bytes
operator|.
name|SIZEOF_INT
operator|+
operator|(
literal|3
operator|*
name|Bytes
operator|.
name|SIZEOF_LONG
operator|)
argument_list|)
decl_stmt|;
end_decl_stmt

begin_function
specifier|private
specifier|static
name|void
name|split
parameter_list|(
specifier|final
name|Configuration
name|conf
parameter_list|,
specifier|final
name|Path
name|p
parameter_list|)
throws|throws
name|IOException
block|{
name|FileSystem
name|fs
init|=
name|FileSystem
operator|.
name|get
argument_list|(
name|conf
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|fs
operator|.
name|exists
argument_list|(
name|p
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|FileNotFoundException
argument_list|(
name|p
operator|.
name|toString
argument_list|()
argument_list|)
throw|;
block|}
if|if
condition|(
operator|!
name|fs
operator|.
name|getFileStatus
argument_list|(
name|p
argument_list|)
operator|.
name|isDirectory
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|p
operator|+
literal|" is not a directory"
argument_list|)
throw|;
block|}
specifier|final
name|Path
name|baseDir
init|=
name|FSUtils
operator|.
name|getRootDir
argument_list|(
name|conf
argument_list|)
decl_stmt|;
specifier|final
name|Path
name|archiveDir
init|=
operator|new
name|Path
argument_list|(
name|baseDir
argument_list|,
name|HConstants
operator|.
name|HREGION_OLDLOGDIR_NAME
argument_list|)
decl_stmt|;
name|WALSplitter
operator|.
name|split
argument_list|(
name|baseDir
argument_list|,
name|p
argument_list|,
name|archiveDir
argument_list|,
name|fs
argument_list|,
name|conf
argument_list|,
name|WALFactory
operator|.
name|getInstance
argument_list|(
name|conf
argument_list|)
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
annotation|@
name|Override
specifier|public
name|long
name|getEarliestMemstoreSeqNum
parameter_list|(
name|byte
index|[]
name|encodedRegionName
parameter_list|)
block|{
name|ConcurrentMap
argument_list|<
name|byte
index|[]
argument_list|,
name|Long
argument_list|>
name|oldestUnflushedStoreSequenceIdsOfRegion
init|=
name|this
operator|.
name|oldestUnflushedStoreSequenceIds
operator|.
name|get
argument_list|(
name|encodedRegionName
argument_list|)
decl_stmt|;
return|return
name|oldestUnflushedStoreSequenceIdsOfRegion
operator|!=
literal|null
condition|?
name|getLowestSeqId
argument_list|(
name|oldestUnflushedStoreSequenceIdsOfRegion
argument_list|)
else|:
name|HConstants
operator|.
name|NO_SEQNUM
return|;
block|}
end_function

begin_function
annotation|@
name|Override
specifier|public
name|long
name|getEarliestMemstoreSeqNum
parameter_list|(
name|byte
index|[]
name|encodedRegionName
parameter_list|,
name|byte
index|[]
name|familyName
parameter_list|)
block|{
name|ConcurrentMap
argument_list|<
name|byte
index|[]
argument_list|,
name|Long
argument_list|>
name|oldestUnflushedStoreSequenceIdsOfRegion
init|=
name|this
operator|.
name|oldestUnflushedStoreSequenceIds
operator|.
name|get
argument_list|(
name|encodedRegionName
argument_list|)
decl_stmt|;
if|if
condition|(
name|oldestUnflushedStoreSequenceIdsOfRegion
operator|!=
literal|null
condition|)
block|{
name|Long
name|result
init|=
name|oldestUnflushedStoreSequenceIdsOfRegion
operator|.
name|get
argument_list|(
name|familyName
argument_list|)
decl_stmt|;
return|return
name|result
operator|!=
literal|null
condition|?
name|result
operator|.
name|longValue
argument_list|()
else|:
name|HConstants
operator|.
name|NO_SEQNUM
return|;
block|}
else|else
block|{
return|return
name|HConstants
operator|.
name|NO_SEQNUM
return|;
block|}
block|}
end_function

begin_comment
comment|/**    * This class is used coordinating two threads holding one thread at a    * 'safe point' while the orchestrating thread does some work that requires the first thread    * paused: e.g. holding the WAL writer while its WAL is swapped out from under it by another    * thread.    *     *<p>Thread A signals Thread B to hold when it gets to a 'safe point'.  Thread A wait until    * Thread B gets there. When the 'safe point' has been attained, Thread B signals Thread A.    * Thread B then holds at the 'safe point'.  Thread A on notification that Thread B is paused,    * goes ahead and does the work it needs to do while Thread B is holding.  When Thread A is done,    * it flags B and then Thread A and Thread B continue along on their merry way.  Pause and    * signalling 'zigzags' between the two participating threads.  We use two latches -- one the    * inverse of the other -- pausing and signaling when states are achieved.    *     *<p>To start up the drama, Thread A creates an instance of this class each time it would do    * this zigzag dance and passes it to Thread B (these classes use Latches so it is one shot    * only). Thread B notices the new instance (via reading a volatile reference or how ever) and it    * starts to work toward the 'safe point'.  Thread A calls {@link #waitSafePoint()} when it    * cannot proceed until the Thread B 'safe point' is attained. Thread A will be held inside in    * {@link #waitSafePoint()} until Thread B reaches the 'safe point'.  Once there, Thread B    * frees Thread A by calling {@link #safePointAttained()}.  Thread A now knows Thread B    * is at the 'safe point' and that it is holding there (When Thread B calls    * {@link #safePointAttained()} it blocks here until Thread A calls {@link #releaseSafePoint()}).    * Thread A proceeds to do what it needs to do while Thread B is paused.  When finished,    * it lets Thread B lose by calling {@link #releaseSafePoint()} and away go both Threads again.    */
end_comment

begin_class
specifier|static
class|class
name|SafePointZigZagLatch
block|{
comment|/**      * Count down this latch when safe point attained.      */
specifier|private
specifier|volatile
name|CountDownLatch
name|safePointAttainedLatch
init|=
operator|new
name|CountDownLatch
argument_list|(
literal|1
argument_list|)
decl_stmt|;
comment|/**      * Latch to wait on.  Will be released when we can proceed.      */
specifier|private
specifier|volatile
name|CountDownLatch
name|safePointReleasedLatch
init|=
operator|new
name|CountDownLatch
argument_list|(
literal|1
argument_list|)
decl_stmt|;
comment|/**      * For Thread A to call when it is ready to wait on the 'safe point' to be attained.      * Thread A will be held in here until Thread B calls {@link #safePointAttained()}      * @throws InterruptedException      * @throws ExecutionException      * @param syncFuture We need this as barometer on outstanding syncs.  If it comes home with      * an exception, then something is up w/ our syncing.      * @return The passed<code>syncFuture</code>      * @throws FailedSyncBeforeLogCloseException       */
name|SyncFuture
name|waitSafePoint
parameter_list|(
specifier|final
name|SyncFuture
name|syncFuture
parameter_list|)
throws|throws
name|InterruptedException
throws|,
name|FailedSyncBeforeLogCloseException
block|{
while|while
condition|(
literal|true
condition|)
block|{
if|if
condition|(
name|this
operator|.
name|safePointAttainedLatch
operator|.
name|await
argument_list|(
literal|1
argument_list|,
name|TimeUnit
operator|.
name|NANOSECONDS
argument_list|)
condition|)
break|break;
if|if
condition|(
name|syncFuture
operator|.
name|isThrowable
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|FailedSyncBeforeLogCloseException
argument_list|(
name|syncFuture
operator|.
name|getThrowable
argument_list|()
argument_list|)
throw|;
block|}
block|}
return|return
name|syncFuture
return|;
block|}
comment|/**      * Called by Thread B when it attains the 'safe point'.  In this method, Thread B signals      * Thread A it can proceed. Thread B will be held in here until {@link #releaseSafePoint()}      * is called by Thread A.      * @throws InterruptedException      */
name|void
name|safePointAttained
parameter_list|()
throws|throws
name|InterruptedException
block|{
name|this
operator|.
name|safePointAttainedLatch
operator|.
name|countDown
argument_list|()
expr_stmt|;
name|this
operator|.
name|safePointReleasedLatch
operator|.
name|await
argument_list|()
expr_stmt|;
block|}
comment|/**      * Called by Thread A when it is done with the work it needs to do while Thread B is      * halted.  This will release the Thread B held in a call to {@link #safePointAttained()}      */
name|void
name|releaseSafePoint
parameter_list|()
block|{
name|this
operator|.
name|safePointReleasedLatch
operator|.
name|countDown
argument_list|()
expr_stmt|;
block|}
comment|/**      * @return True is this is a 'cocked', fresh instance, and not one that has already fired.      */
name|boolean
name|isCocked
parameter_list|()
block|{
return|return
name|this
operator|.
name|safePointAttainedLatch
operator|.
name|getCount
argument_list|()
operator|>
literal|0
operator|&&
name|this
operator|.
name|safePointReleasedLatch
operator|.
name|getCount
argument_list|()
operator|>
literal|0
return|;
block|}
block|}
end_class

begin_comment
comment|/**    * Handler that is run by the disruptor ringbuffer consumer. Consumer is a SINGLE    * 'writer/appender' thread.  Appends edits and starts up sync runs.  Tries its best to batch up    * syncs.  There is no discernible benefit batching appends so we just append as they come in    * because it simplifies the below implementation.  See metrics for batching effectiveness    * (In measurement, at 100 concurrent handlers writing 1k, we are batching> 10 appends and 10    * handler sync invocations for every actual dfsclient sync call; at 10 concurrent handlers,    * YMMV).    *<p>Herein, we have an array into which we store the sync futures as they come in.  When we    * have a 'batch', we'll then pass what we have collected to a SyncRunner thread to do the    * filesystem sync.  When it completes, it will then call    * {@link SyncFuture#done(long, Throwable)} on each of SyncFutures in the batch to release    * blocked Handler threads.    *<p>I've tried various effects to try and make latencies low while keeping throughput high.    * I've tried keeping a single Queue of SyncFutures in this class appending to its tail as the    * syncs coming and having sync runner threads poll off the head to 'finish' completed    * SyncFutures.  I've tried linkedlist, and various from concurrent utils whether    * LinkedBlockingQueue or ArrayBlockingQueue, etc.  The more points of synchronization, the    * more 'work' (according to 'perf stats') that has to be done; small increases in stall    * percentages seem to have a big impact on throughput/latencies.  The below model where we have    * an array into which we stash the syncs and then hand them off to the sync thread seemed like    * a decent compromise.  See HBASE-8755 for more detail.    */
end_comment

begin_class
class|class
name|RingBufferEventHandler
implements|implements
name|EventHandler
argument_list|<
name|RingBufferTruck
argument_list|>
implements|,
name|LifecycleAware
block|{
specifier|private
specifier|final
name|SyncRunner
index|[]
name|syncRunners
decl_stmt|;
specifier|private
specifier|final
name|SyncFuture
index|[]
name|syncFutures
decl_stmt|;
comment|// Had 'interesting' issues when this was non-volatile.  On occasion, we'd not pass all
comment|// syncFutures to the next sync'ing thread.
specifier|private
specifier|volatile
name|int
name|syncFuturesCount
init|=
literal|0
decl_stmt|;
specifier|private
specifier|volatile
name|SafePointZigZagLatch
name|zigzagLatch
decl_stmt|;
comment|/**      * Object to block on while waiting on safe point.      */
specifier|private
specifier|final
name|Object
name|safePointWaiter
init|=
operator|new
name|Object
argument_list|()
decl_stmt|;
specifier|private
specifier|volatile
name|boolean
name|shutdown
init|=
literal|false
decl_stmt|;
comment|/**      * Which syncrunner to use next.      */
specifier|private
name|int
name|syncRunnerIndex
decl_stmt|;
name|RingBufferEventHandler
parameter_list|(
specifier|final
name|int
name|syncRunnerCount
parameter_list|,
specifier|final
name|int
name|maxHandlersCount
parameter_list|)
block|{
name|this
operator|.
name|syncFutures
operator|=
operator|new
name|SyncFuture
index|[
name|maxHandlersCount
index|]
expr_stmt|;
name|this
operator|.
name|syncRunners
operator|=
operator|new
name|SyncRunner
index|[
name|syncRunnerCount
index|]
expr_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|syncRunnerCount
condition|;
name|i
operator|++
control|)
block|{
name|this
operator|.
name|syncRunners
index|[
name|i
index|]
operator|=
operator|new
name|SyncRunner
argument_list|(
literal|"sync."
operator|+
name|i
argument_list|,
name|maxHandlersCount
argument_list|)
expr_stmt|;
block|}
block|}
specifier|private
name|void
name|cleanupOutstandingSyncsOnException
parameter_list|(
specifier|final
name|long
name|sequence
parameter_list|,
specifier|final
name|Exception
name|e
parameter_list|)
block|{
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|this
operator|.
name|syncFuturesCount
condition|;
name|i
operator|++
control|)
name|this
operator|.
name|syncFutures
index|[
name|i
index|]
operator|.
name|done
argument_list|(
name|sequence
argument_list|,
name|e
argument_list|)
expr_stmt|;
name|this
operator|.
name|syncFuturesCount
operator|=
literal|0
expr_stmt|;
block|}
annotation|@
name|Override
comment|// We can set endOfBatch in the below method if at end of our this.syncFutures array
specifier|public
name|void
name|onEvent
parameter_list|(
specifier|final
name|RingBufferTruck
name|truck
parameter_list|,
specifier|final
name|long
name|sequence
parameter_list|,
name|boolean
name|endOfBatch
parameter_list|)
throws|throws
name|Exception
block|{
comment|// Appends and syncs are coming in order off the ringbuffer.  We depend on this fact.  We'll
comment|// add appends to dfsclient as they come in.  Batching appends doesn't give any significant
comment|// benefit on measurement.  Handler sync calls we will batch up.
try|try
block|{
if|if
condition|(
name|truck
operator|.
name|hasSyncFuturePayload
argument_list|()
condition|)
block|{
name|this
operator|.
name|syncFutures
index|[
name|this
operator|.
name|syncFuturesCount
operator|++
index|]
operator|=
name|truck
operator|.
name|unloadSyncFuturePayload
argument_list|()
expr_stmt|;
comment|// Force flush of syncs if we are carrying a full complement of syncFutures.
if|if
condition|(
name|this
operator|.
name|syncFuturesCount
operator|==
name|this
operator|.
name|syncFutures
operator|.
name|length
condition|)
name|endOfBatch
operator|=
literal|true
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|truck
operator|.
name|hasFSWALEntryPayload
argument_list|()
condition|)
block|{
name|TraceScope
name|scope
init|=
name|Trace
operator|.
name|continueSpan
argument_list|(
name|truck
operator|.
name|unloadSpanPayload
argument_list|()
argument_list|)
decl_stmt|;
try|try
block|{
name|append
argument_list|(
name|truck
operator|.
name|unloadFSWALEntryPayload
argument_list|()
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
comment|// If append fails, presume any pending syncs will fail too; let all waiting handlers
comment|// know of the exception.
name|cleanupOutstandingSyncsOnException
argument_list|(
name|sequence
argument_list|,
name|e
argument_list|)
expr_stmt|;
comment|// Return to keep processing.
return|return;
block|}
finally|finally
block|{
assert|assert
name|scope
operator|==
name|NullScope
operator|.
name|INSTANCE
operator|||
operator|!
name|scope
operator|.
name|isDetached
argument_list|()
assert|;
name|scope
operator|.
name|close
argument_list|()
expr_stmt|;
comment|// append scope is complete
block|}
block|}
else|else
block|{
comment|// They can't both be null.  Fail all up to this!!!
name|cleanupOutstandingSyncsOnException
argument_list|(
name|sequence
argument_list|,
operator|new
name|IllegalStateException
argument_list|(
literal|"Neither append nor sync"
argument_list|)
argument_list|)
expr_stmt|;
comment|// Return to keep processing.
return|return;
block|}
comment|// TODO: Check size and if big go ahead and call a sync if we have enough data.
comment|// If not a batch, return to consume more events from the ring buffer before proceeding;
comment|// we want to get up a batch of syncs and appends before we go do a filesystem sync.
if|if
condition|(
operator|!
name|endOfBatch
operator|||
name|this
operator|.
name|syncFuturesCount
operator|<=
literal|0
condition|)
return|return;
comment|// Now we have a batch.
if|if
condition|(
name|LOG
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|trace
argument_list|(
literal|"Sequence="
operator|+
name|sequence
operator|+
literal|", syncCount="
operator|+
name|this
operator|.
name|syncFuturesCount
argument_list|)
expr_stmt|;
block|}
comment|// Below expects that the offer 'transfers' responsibility for the outstanding syncs to the
comment|// syncRunner. We should never get an exception in here. HBASE-11145 was because queue
comment|// was sized exactly to the count of user handlers but we could have more if we factor in
comment|// meta handlers doing opens and closes.
name|int
name|index
init|=
name|Math
operator|.
name|abs
argument_list|(
name|this
operator|.
name|syncRunnerIndex
operator|++
argument_list|)
operator|%
name|this
operator|.
name|syncRunners
operator|.
name|length
decl_stmt|;
try|try
block|{
name|this
operator|.
name|syncRunners
index|[
name|index
index|]
operator|.
name|offer
argument_list|(
name|sequence
argument_list|,
name|this
operator|.
name|syncFutures
argument_list|,
name|this
operator|.
name|syncFuturesCount
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|cleanupOutstandingSyncsOnException
argument_list|(
name|sequence
argument_list|,
name|e
argument_list|)
expr_stmt|;
throw|throw
name|e
throw|;
block|}
name|attainSafePoint
argument_list|(
name|sequence
argument_list|)
expr_stmt|;
name|this
operator|.
name|syncFuturesCount
operator|=
literal|0
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Throwable
name|t
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"UNEXPECTED!!! syncFutures.length="
operator|+
name|this
operator|.
name|syncFutures
operator|.
name|length
argument_list|,
name|t
argument_list|)
expr_stmt|;
block|}
block|}
name|SafePointZigZagLatch
name|attainSafePoint
parameter_list|()
block|{
name|this
operator|.
name|zigzagLatch
operator|=
operator|new
name|SafePointZigZagLatch
argument_list|()
expr_stmt|;
return|return
name|this
operator|.
name|zigzagLatch
return|;
block|}
comment|/**      * Check if we should attain safe point.  If so, go there and then wait till signalled before      * we proceeding.      */
specifier|private
name|void
name|attainSafePoint
parameter_list|(
specifier|final
name|long
name|currentSequence
parameter_list|)
block|{
if|if
condition|(
name|this
operator|.
name|zigzagLatch
operator|==
literal|null
operator|||
operator|!
name|this
operator|.
name|zigzagLatch
operator|.
name|isCocked
argument_list|()
condition|)
return|return;
comment|// If here, another thread is waiting on us to get to safe point.  Don't leave it hanging.
try|try
block|{
comment|// Wait on outstanding syncers; wait for them to finish syncing (unless we've been
comment|// shutdown or unless our latch has been thrown because we have been aborted).
while|while
condition|(
operator|!
name|this
operator|.
name|shutdown
operator|&&
name|this
operator|.
name|zigzagLatch
operator|.
name|isCocked
argument_list|()
operator|&&
name|highestSyncedSequence
operator|.
name|get
argument_list|()
operator|<
name|currentSequence
condition|)
block|{
synchronized|synchronized
init|(
name|this
operator|.
name|safePointWaiter
init|)
block|{
name|this
operator|.
name|safePointWaiter
operator|.
name|wait
argument_list|(
literal|0
argument_list|,
literal|1
argument_list|)
expr_stmt|;
block|}
block|}
comment|// Tell waiting thread we've attained safe point
name|this
operator|.
name|zigzagLatch
operator|.
name|safePointAttained
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Interrupted "
argument_list|,
name|e
argument_list|)
expr_stmt|;
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|interrupt
argument_list|()
expr_stmt|;
block|}
block|}
specifier|private
name|void
name|updateOldestUnflushedSequenceIds
parameter_list|(
name|byte
index|[]
name|encodedRegionName
parameter_list|,
name|Set
argument_list|<
name|byte
index|[]
argument_list|>
name|familyNameSet
parameter_list|,
name|Long
name|lRegionSequenceId
parameter_list|)
block|{
name|ConcurrentMap
argument_list|<
name|byte
index|[]
argument_list|,
name|Long
argument_list|>
name|oldestUnflushedStoreSequenceIdsOfRegion
init|=
name|getOrCreateOldestUnflushedStoreSequenceIdsOfRegion
argument_list|(
name|encodedRegionName
argument_list|)
decl_stmt|;
for|for
control|(
name|byte
index|[]
name|familyName
range|:
name|familyNameSet
control|)
block|{
name|oldestUnflushedStoreSequenceIdsOfRegion
operator|.
name|putIfAbsent
argument_list|(
name|familyName
argument_list|,
name|lRegionSequenceId
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**      * Append to the WAL.  Does all CP and WAL listener calls.      * @param entry      * @throws Exception      */
name|void
name|append
parameter_list|(
specifier|final
name|FSWALEntry
name|entry
parameter_list|)
throws|throws
name|Exception
block|{
comment|// TODO: WORK ON MAKING THIS APPEND FASTER. DOING WAY TOO MUCH WORK WITH CPs, PBing, etc.
name|atHeadOfRingBufferEventHandlerAppend
argument_list|()
expr_stmt|;
name|long
name|start
init|=
name|EnvironmentEdgeManager
operator|.
name|currentTime
argument_list|()
decl_stmt|;
name|byte
index|[]
name|encodedRegionName
init|=
name|entry
operator|.
name|getKey
argument_list|()
operator|.
name|getEncodedRegionName
argument_list|()
decl_stmt|;
name|long
name|regionSequenceId
init|=
name|WALKey
operator|.
name|NO_SEQUENCE_ID
decl_stmt|;
try|try
block|{
comment|// We are about to append this edit; update the region-scoped sequence number.  Do it
comment|// here inside this single appending/writing thread.  Events are ordered on the ringbuffer
comment|// so region sequenceids will also be in order.
name|regionSequenceId
operator|=
name|entry
operator|.
name|stampRegionSequenceId
argument_list|()
expr_stmt|;
comment|// Edits are empty, there is nothing to append.  Maybe empty when we are looking for a
comment|// region sequence id only, a region edit/sequence id that is not associated with an actual
comment|// edit. It has to go through all the rigmarole to be sure we have the right ordering.
if|if
condition|(
name|entry
operator|.
name|getEdit
argument_list|()
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
return|return;
block|}
comment|// Coprocessor hook.
if|if
condition|(
operator|!
name|coprocessorHost
operator|.
name|preWALWrite
argument_list|(
name|entry
operator|.
name|getHRegionInfo
argument_list|()
argument_list|,
name|entry
operator|.
name|getKey
argument_list|()
argument_list|,
name|entry
operator|.
name|getEdit
argument_list|()
argument_list|)
condition|)
block|{
if|if
condition|(
name|entry
operator|.
name|getEdit
argument_list|()
operator|.
name|isReplay
argument_list|()
condition|)
block|{
comment|// Set replication scope null so that this won't be replicated
name|entry
operator|.
name|getKey
argument_list|()
operator|.
name|setScopes
argument_list|(
literal|null
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
operator|!
name|listeners
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
for|for
control|(
name|WALActionsListener
name|i
range|:
name|listeners
control|)
block|{
comment|// TODO: Why does listener take a table description and CPs take a regioninfo?  Fix.
name|i
operator|.
name|visitLogEntryBeforeWrite
argument_list|(
name|entry
operator|.
name|getHTableDescriptor
argument_list|()
argument_list|,
name|entry
operator|.
name|getKey
argument_list|()
argument_list|,
name|entry
operator|.
name|getEdit
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
name|writer
operator|.
name|append
argument_list|(
name|entry
argument_list|)
expr_stmt|;
assert|assert
name|highestUnsyncedSequence
operator|<
name|entry
operator|.
name|getSequence
argument_list|()
assert|;
name|highestUnsyncedSequence
operator|=
name|entry
operator|.
name|getSequence
argument_list|()
expr_stmt|;
name|Long
name|lRegionSequenceId
init|=
name|Long
operator|.
name|valueOf
argument_list|(
name|regionSequenceId
argument_list|)
decl_stmt|;
name|highestRegionSequenceIds
operator|.
name|put
argument_list|(
name|encodedRegionName
argument_list|,
name|lRegionSequenceId
argument_list|)
expr_stmt|;
if|if
condition|(
name|entry
operator|.
name|isInMemstore
argument_list|()
condition|)
block|{
name|updateOldestUnflushedSequenceIds
argument_list|(
name|encodedRegionName
argument_list|,
name|entry
operator|.
name|getFamilyNames
argument_list|()
argument_list|,
name|lRegionSequenceId
argument_list|)
expr_stmt|;
block|}
name|coprocessorHost
operator|.
name|postWALWrite
argument_list|(
name|entry
operator|.
name|getHRegionInfo
argument_list|()
argument_list|,
name|entry
operator|.
name|getKey
argument_list|()
argument_list|,
name|entry
operator|.
name|getEdit
argument_list|()
argument_list|)
expr_stmt|;
comment|// Update metrics.
name|postAppend
argument_list|(
name|entry
argument_list|,
name|EnvironmentEdgeManager
operator|.
name|currentTime
argument_list|()
operator|-
name|start
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|fatal
argument_list|(
literal|"Could not append. Requesting close of wal"
argument_list|,
name|e
argument_list|)
expr_stmt|;
name|requestLogRoll
argument_list|()
expr_stmt|;
throw|throw
name|e
throw|;
block|}
name|numEntries
operator|.
name|incrementAndGet
argument_list|()
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|onStart
parameter_list|()
block|{
for|for
control|(
name|SyncRunner
name|syncRunner
range|:
name|this
operator|.
name|syncRunners
control|)
name|syncRunner
operator|.
name|start
argument_list|()
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|onShutdown
parameter_list|()
block|{
for|for
control|(
name|SyncRunner
name|syncRunner
range|:
name|this
operator|.
name|syncRunners
control|)
name|syncRunner
operator|.
name|interrupt
argument_list|()
expr_stmt|;
block|}
block|}
end_class

begin_comment
comment|/**    * Exposed for testing only.  Use to tricks like halt the ring buffer appending.    */
end_comment

begin_function
annotation|@
name|VisibleForTesting
name|void
name|atHeadOfRingBufferEventHandlerAppend
parameter_list|()
block|{
comment|// Noop
block|}
end_function

begin_function
specifier|private
specifier|static
name|IOException
name|ensureIOException
parameter_list|(
specifier|final
name|Throwable
name|t
parameter_list|)
block|{
return|return
operator|(
name|t
operator|instanceof
name|IOException
operator|)
condition|?
operator|(
name|IOException
operator|)
name|t
else|:
operator|new
name|IOException
argument_list|(
name|t
argument_list|)
return|;
block|}
end_function

begin_function
specifier|private
specifier|static
name|void
name|usage
parameter_list|()
block|{
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|"Usage: FSHLog<ARGS>"
argument_list|)
expr_stmt|;
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|"Arguments:"
argument_list|)
expr_stmt|;
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|" --dump  Dump textual representation of passed one or more files"
argument_list|)
expr_stmt|;
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|"         For example: "
operator|+
literal|"FSHLog --dump hdfs://example.com:9000/hbase/.logs/MACHINE/LOGFILE"
argument_list|)
expr_stmt|;
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|" --split Split the passed directory of WAL logs"
argument_list|)
expr_stmt|;
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|"         For example: "
operator|+
literal|"FSHLog --split hdfs://example.com:9000/hbase/.logs/DIR"
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/**    * Pass one or more log file names and it will either dump out a text version    * on<code>stdout</code> or split the specified log files.    *    * @param args    * @throws IOException    */
end_comment

begin_function
specifier|public
specifier|static
name|void
name|main
parameter_list|(
name|String
index|[]
name|args
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|args
operator|.
name|length
operator|<
literal|2
condition|)
block|{
name|usage
argument_list|()
expr_stmt|;
name|System
operator|.
name|exit
argument_list|(
operator|-
literal|1
argument_list|)
expr_stmt|;
block|}
comment|// either dump using the WALPrettyPrinter or split, depending on args
if|if
condition|(
name|args
index|[
literal|0
index|]
operator|.
name|compareTo
argument_list|(
literal|"--dump"
argument_list|)
operator|==
literal|0
condition|)
block|{
name|WALPrettyPrinter
operator|.
name|run
argument_list|(
name|Arrays
operator|.
name|copyOfRange
argument_list|(
name|args
argument_list|,
literal|1
argument_list|,
name|args
operator|.
name|length
argument_list|)
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|args
index|[
literal|0
index|]
operator|.
name|compareTo
argument_list|(
literal|"--perf"
argument_list|)
operator|==
literal|0
condition|)
block|{
name|LOG
operator|.
name|fatal
argument_list|(
literal|"Please use the WALPerformanceEvaluation tool instead. i.e.:"
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|fatal
argument_list|(
literal|"\thbase org.apache.hadoop.hbase.wal.WALPerformanceEvaluation --iterations "
operator|+
name|args
index|[
literal|1
index|]
argument_list|)
expr_stmt|;
name|System
operator|.
name|exit
argument_list|(
operator|-
literal|1
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|args
index|[
literal|0
index|]
operator|.
name|compareTo
argument_list|(
literal|"--split"
argument_list|)
operator|==
literal|0
condition|)
block|{
name|Configuration
name|conf
init|=
name|HBaseConfiguration
operator|.
name|create
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|1
init|;
name|i
operator|<
name|args
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
try|try
block|{
name|Path
name|logPath
init|=
operator|new
name|Path
argument_list|(
name|args
index|[
name|i
index|]
argument_list|)
decl_stmt|;
name|FSUtils
operator|.
name|setFsDefault
argument_list|(
name|conf
argument_list|,
name|logPath
argument_list|)
expr_stmt|;
name|split
argument_list|(
name|conf
argument_list|,
name|logPath
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|t
parameter_list|)
block|{
name|t
operator|.
name|printStackTrace
argument_list|(
name|System
operator|.
name|err
argument_list|)
expr_stmt|;
name|System
operator|.
name|exit
argument_list|(
operator|-
literal|1
argument_list|)
expr_stmt|;
block|}
block|}
block|}
else|else
block|{
name|usage
argument_list|()
expr_stmt|;
name|System
operator|.
name|exit
argument_list|(
operator|-
literal|1
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/**    * Find the 'getPipeline' on the passed<code>os</code> stream.    * @return Method or null.    */
end_comment

begin_function
specifier|private
name|Method
name|getGetPipeline
parameter_list|(
specifier|final
name|FSDataOutputStream
name|os
parameter_list|)
block|{
name|Method
name|m
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|os
operator|!=
literal|null
condition|)
block|{
name|Class
argument_list|<
name|?
extends|extends
name|OutputStream
argument_list|>
name|wrappedStreamClass
init|=
name|os
operator|.
name|getWrappedStream
argument_list|()
operator|.
name|getClass
argument_list|()
decl_stmt|;
try|try
block|{
name|m
operator|=
name|wrappedStreamClass
operator|.
name|getDeclaredMethod
argument_list|(
literal|"getPipeline"
argument_list|,
operator|new
name|Class
argument_list|<
name|?
argument_list|>
index|[]
block|{}
block|)
empty_stmt|;
name|m
operator|.
name|setAccessible
argument_list|(
literal|true
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|NoSuchMethodException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"FileSystem's output stream doesn't support"
operator|+
literal|" getPipeline; not available; fsOut="
operator|+
name|wrappedStreamClass
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|SecurityException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Doesn't have access to getPipeline on "
operator|+
literal|"FileSystems's output stream ; fsOut="
operator|+
name|wrappedStreamClass
operator|.
name|getName
argument_list|()
argument_list|,
name|e
argument_list|)
expr_stmt|;
name|m
operator|=
literal|null
expr_stmt|;
comment|// could happen on setAccessible()
block|}
block|}
end_function

begin_return
return|return
name|m
return|;
end_return

begin_comment
unit|}
comment|/**    * This method gets the pipeline for the current WAL.    */
end_comment

begin_function
unit|@
name|VisibleForTesting
name|DatanodeInfo
index|[]
name|getPipeLine
parameter_list|()
block|{
if|if
condition|(
name|this
operator|.
name|getPipeLine
operator|!=
literal|null
operator|&&
name|this
operator|.
name|hdfs_out
operator|!=
literal|null
condition|)
block|{
name|Object
name|repl
decl_stmt|;
try|try
block|{
name|repl
operator|=
name|this
operator|.
name|getPipeLine
operator|.
name|invoke
argument_list|(
name|getOutputStream
argument_list|()
argument_list|,
name|NO_ARGS
argument_list|)
expr_stmt|;
if|if
condition|(
name|repl
operator|instanceof
name|DatanodeInfo
index|[]
condition|)
block|{
return|return
operator|(
operator|(
name|DatanodeInfo
index|[]
operator|)
name|repl
operator|)
return|;
block|}
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Get pipeline failed"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
block|}
return|return
operator|new
name|DatanodeInfo
index|[
literal|0
index|]
return|;
block|}
end_function

unit|}
end_unit

