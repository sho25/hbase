begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  *  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|wal
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|FileNotFoundException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|OutputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|lang
operator|.
name|reflect
operator|.
name|InvocationTargetException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|lang
operator|.
name|reflect
operator|.
name|Method
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|URLEncoder
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Arrays
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collections
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|LinkedList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|SortedMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|TreeMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|TreeSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|UUID
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ConcurrentSkipListMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|CopyOnWriteArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|atomic
operator|.
name|AtomicBoolean
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|atomic
operator|.
name|AtomicInteger
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|atomic
operator|.
name|AtomicLong
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|Log
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|LogFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|classification
operator|.
name|InterfaceAudience
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FSDataOutputStream
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileStatus
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Syncable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HBaseConfiguration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HConstants
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HRegionInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HTableDescriptor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|KeyValue
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|exceptions
operator|.
name|FailedLogCloseException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|Bytes
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|ClassSize
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|DrainBarrier
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|EnvironmentEdgeManager
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|FSUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|HasThread
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|Threads
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|StringUtils
import|;
end_import

begin_comment
comment|/**  * HLog stores all the edits to the HStore.  Its the hbase write-ahead-log  * implementation.  *  * It performs logfile-rolling, so external callers are not aware that the  * underlying file is being rolled.  *  *<p>  * There is one HLog per RegionServer.  All edits for all Regions carried by  * a particular RegionServer are entered first in the HLog.  *  *<p>  * Each HRegion is identified by a unique long<code>int</code>. HRegions do  * not need to declare themselves before using the HLog; they simply include  * their HRegion-id in the<code>append</code> or  *<code>completeCacheFlush</code> calls.  *  *<p>  * An HLog consists of multiple on-disk files, which have a chronological order.  * As data is flushed to other (better) on-disk structures, the log becomes  * obsolete. We can destroy all the log messages for a given HRegion-id up to  * the most-recent CACHEFLUSH message from that HRegion.  *  *<p>  * It's only practical to delete entire files. Thus, we delete an entire on-disk  * file F when all of the messages in F have a log-sequence-id that's older  * (smaller) than the most-recent CACHEFLUSH message for every HRegion that has  * a message in F.  *  *<p>  * Synchronized methods can never execute in parallel. However, between the  * start of a cache flush and the completion point, appends are allowed but log  * rolling is not. To prevent log rolling taking place during this period, a  * separate reentrant lock is used.  *  *<p>To read an HLog, call {@link HLogFactory#createReader(org.apache.hadoop.fs.FileSystem,  * org.apache.hadoop.fs.Path, org.apache.hadoop.conf.Configuration)}.  *  */
end_comment

begin_class
annotation|@
name|InterfaceAudience
operator|.
name|Private
class|class
name|FSHLog
implements|implements
name|HLog
implements|,
name|Syncable
block|{
specifier|static
specifier|final
name|Log
name|LOG
init|=
name|LogFactory
operator|.
name|getLog
argument_list|(
name|FSHLog
operator|.
name|class
argument_list|)
decl_stmt|;
specifier|private
specifier|final
name|FileSystem
name|fs
decl_stmt|;
specifier|private
specifier|final
name|Path
name|rootDir
decl_stmt|;
specifier|private
specifier|final
name|Path
name|dir
decl_stmt|;
specifier|private
specifier|final
name|Configuration
name|conf
decl_stmt|;
comment|// Listeners that are called on WAL events.
specifier|private
name|List
argument_list|<
name|WALActionsListener
argument_list|>
name|listeners
init|=
operator|new
name|CopyOnWriteArrayList
argument_list|<
name|WALActionsListener
argument_list|>
argument_list|()
decl_stmt|;
specifier|private
specifier|final
name|long
name|optionalFlushInterval
decl_stmt|;
specifier|private
specifier|final
name|long
name|blocksize
decl_stmt|;
specifier|private
specifier|final
name|String
name|prefix
decl_stmt|;
specifier|private
specifier|final
name|AtomicLong
name|unflushedEntries
init|=
operator|new
name|AtomicLong
argument_list|(
literal|0
argument_list|)
decl_stmt|;
specifier|private
specifier|volatile
name|long
name|syncedTillHere
init|=
literal|0
decl_stmt|;
specifier|private
name|long
name|lastDeferredTxid
decl_stmt|;
specifier|private
specifier|final
name|Path
name|oldLogDir
decl_stmt|;
specifier|private
specifier|volatile
name|boolean
name|logRollRunning
decl_stmt|;
specifier|private
name|WALCoprocessorHost
name|coprocessorHost
decl_stmt|;
specifier|private
name|FSDataOutputStream
name|hdfs_out
decl_stmt|;
comment|// FSDataOutputStream associated with the current SequenceFile.writer
comment|// Minimum tolerable replicas, if the actual value is lower than it,
comment|// rollWriter will be triggered
specifier|private
name|int
name|minTolerableReplication
decl_stmt|;
specifier|private
name|Method
name|getNumCurrentReplicas
decl_stmt|;
comment|// refers to DFSOutputStream.getNumCurrentReplicas
specifier|final
specifier|static
name|Object
index|[]
name|NO_ARGS
init|=
operator|new
name|Object
index|[]
block|{}
decl_stmt|;
comment|/** The barrier used to ensure that close() waits for all log rolls and flushes to finish. */
specifier|private
name|DrainBarrier
name|closeBarrier
init|=
operator|new
name|DrainBarrier
argument_list|()
decl_stmt|;
comment|/**    * Current log file.    */
name|Writer
name|writer
decl_stmt|;
comment|/**    * Map of all log files but the current one.    */
specifier|final
name|SortedMap
argument_list|<
name|Long
argument_list|,
name|Path
argument_list|>
name|outputfiles
init|=
name|Collections
operator|.
name|synchronizedSortedMap
argument_list|(
operator|new
name|TreeMap
argument_list|<
name|Long
argument_list|,
name|Path
argument_list|>
argument_list|()
argument_list|)
decl_stmt|;
comment|/**    * This lock synchronizes all operations on oldestUnflushedSeqNums and oldestFlushingSeqNums,    * with the exception of append's putIfAbsent into oldestUnflushedSeqNums.    * We only use these to find out the low bound seqNum, or to find regions with old seqNums to    * force flush them, so we don't care about these numbers messing with anything. */
specifier|private
specifier|final
name|Object
name|oldestSeqNumsLock
init|=
operator|new
name|Object
argument_list|()
decl_stmt|;
comment|/**    * This lock makes sure only one log roll runs at the same time. Should not be taken while    * any other lock is held. We don't just use synchronized because that results in bogus and    * tedious findbugs warning when it thinks synchronized controls writer thread safety */
specifier|private
specifier|final
name|Object
name|rollWriterLock
init|=
operator|new
name|Object
argument_list|()
decl_stmt|;
comment|/**    * Map of encoded region names to their most recent sequence/edit id in their memstore.    */
specifier|private
specifier|final
name|ConcurrentSkipListMap
argument_list|<
name|byte
index|[]
argument_list|,
name|Long
argument_list|>
name|oldestUnflushedSeqNums
init|=
operator|new
name|ConcurrentSkipListMap
argument_list|<
name|byte
index|[]
argument_list|,
name|Long
argument_list|>
argument_list|(
name|Bytes
operator|.
name|BYTES_COMPARATOR
argument_list|)
decl_stmt|;
comment|/**    * Map of encoded region names to their most recent sequence/edit id in their memstore;    * contains the regions that are currently flushing. That way we can store two numbers for    * flushing and non-flushing (oldestUnflushedSeqNums) memstore for the same region.    */
specifier|private
specifier|final
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|Long
argument_list|>
name|oldestFlushingSeqNums
init|=
operator|new
name|TreeMap
argument_list|<
name|byte
index|[]
argument_list|,
name|Long
argument_list|>
argument_list|(
name|Bytes
operator|.
name|BYTES_COMPARATOR
argument_list|)
decl_stmt|;
specifier|private
specifier|volatile
name|boolean
name|closed
init|=
literal|false
decl_stmt|;
specifier|private
specifier|final
name|AtomicLong
name|logSeqNum
init|=
operator|new
name|AtomicLong
argument_list|(
literal|0
argument_list|)
decl_stmt|;
specifier|private
name|boolean
name|forMeta
init|=
literal|false
decl_stmt|;
comment|// The timestamp (in ms) when the log file was created.
specifier|private
specifier|volatile
name|long
name|filenum
init|=
operator|-
literal|1
decl_stmt|;
comment|//number of transactions in the current Hlog.
specifier|private
specifier|final
name|AtomicInteger
name|numEntries
init|=
operator|new
name|AtomicInteger
argument_list|(
literal|0
argument_list|)
decl_stmt|;
comment|// If live datanode count is lower than the default replicas value,
comment|// RollWriter will be triggered in each sync(So the RollWriter will be
comment|// triggered one by one in a short time). Using it as a workaround to slow
comment|// down the roll frequency triggered by checkLowReplication().
specifier|private
name|AtomicInteger
name|consecutiveLogRolls
init|=
operator|new
name|AtomicInteger
argument_list|(
literal|0
argument_list|)
decl_stmt|;
specifier|private
specifier|final
name|int
name|lowReplicationRollLimit
decl_stmt|;
comment|// If consecutiveLogRolls is larger than lowReplicationRollLimit,
comment|// then disable the rolling in checkLowReplication().
comment|// Enable it if the replications recover.
specifier|private
specifier|volatile
name|boolean
name|lowReplicationRollEnabled
init|=
literal|true
decl_stmt|;
comment|// If> than this size, roll the log. This is typically 0.95 times the size
comment|// of the default Hdfs block size.
specifier|private
specifier|final
name|long
name|logrollsize
decl_stmt|;
comment|// We synchronize on updateLock to prevent updates and to prevent a log roll
comment|// during an update
comment|// locked during appends
specifier|private
specifier|final
name|Object
name|updateLock
init|=
operator|new
name|Object
argument_list|()
decl_stmt|;
specifier|private
specifier|final
name|Object
name|flushLock
init|=
operator|new
name|Object
argument_list|()
decl_stmt|;
specifier|private
specifier|final
name|boolean
name|enabled
decl_stmt|;
comment|/*    * If more than this many logs, force flush of oldest region to oldest edit    * goes to disk.  If too many and we crash, then will take forever replaying.    * Keep the number of logs tidy.    */
specifier|private
specifier|final
name|int
name|maxLogs
decl_stmt|;
comment|/**    * Thread that handles optional sync'ing    */
specifier|private
specifier|final
name|LogSyncer
name|logSyncer
decl_stmt|;
comment|/** Number of log close errors tolerated before we abort */
specifier|private
specifier|final
name|int
name|closeErrorsTolerated
decl_stmt|;
specifier|private
specifier|final
name|AtomicInteger
name|closeErrorCount
init|=
operator|new
name|AtomicInteger
argument_list|()
decl_stmt|;
specifier|private
specifier|final
name|MetricsWAL
name|metrics
decl_stmt|;
comment|/**    * Constructor.    *    * @param fs filesystem handle    * @param root path for stored and archived hlogs    * @param logDir dir where hlogs are stored    * @param conf configuration to use    * @throws IOException    */
specifier|public
name|FSHLog
parameter_list|(
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Path
name|root
parameter_list|,
specifier|final
name|String
name|logDir
parameter_list|,
specifier|final
name|Configuration
name|conf
parameter_list|)
throws|throws
name|IOException
block|{
name|this
argument_list|(
name|fs
argument_list|,
name|root
argument_list|,
name|logDir
argument_list|,
name|HConstants
operator|.
name|HREGION_OLDLOGDIR_NAME
argument_list|,
name|conf
argument_list|,
literal|null
argument_list|,
literal|true
argument_list|,
literal|null
argument_list|,
literal|false
argument_list|)
expr_stmt|;
block|}
comment|/**    * Constructor.    *    * @param fs filesystem handle    * @param root path for stored and archived hlogs    * @param logDir dir where hlogs are stored    * @param oldLogDir dir where hlogs are archived    * @param conf configuration to use    * @throws IOException    */
specifier|public
name|FSHLog
parameter_list|(
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Path
name|root
parameter_list|,
specifier|final
name|String
name|logDir
parameter_list|,
specifier|final
name|String
name|oldLogDir
parameter_list|,
specifier|final
name|Configuration
name|conf
parameter_list|)
throws|throws
name|IOException
block|{
name|this
argument_list|(
name|fs
argument_list|,
name|root
argument_list|,
name|logDir
argument_list|,
name|oldLogDir
argument_list|,
name|conf
argument_list|,
literal|null
argument_list|,
literal|true
argument_list|,
literal|null
argument_list|,
literal|false
argument_list|)
expr_stmt|;
block|}
comment|/**    * Create an edit log at the given<code>dir</code> location.    *    * You should never have to load an existing log. If there is a log at    * startup, it should have already been processed and deleted by the time the    * HLog object is started up.    *    * @param fs filesystem handle    * @param root path for stored and archived hlogs    * @param logDir dir where hlogs are stored    * @param conf configuration to use    * @param listeners Listeners on WAL events. Listeners passed here will    * be registered before we do anything else; e.g. the    * Constructor {@link #rollWriter()}.    * @param prefix should always be hostname and port in distributed env and    *        it will be URL encoded before being used.    *        If prefix is null, "hlog" will be used    * @throws IOException    */
specifier|public
name|FSHLog
parameter_list|(
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Path
name|root
parameter_list|,
specifier|final
name|String
name|logDir
parameter_list|,
specifier|final
name|Configuration
name|conf
parameter_list|,
specifier|final
name|List
argument_list|<
name|WALActionsListener
argument_list|>
name|listeners
parameter_list|,
specifier|final
name|String
name|prefix
parameter_list|)
throws|throws
name|IOException
block|{
name|this
argument_list|(
name|fs
argument_list|,
name|root
argument_list|,
name|logDir
argument_list|,
name|HConstants
operator|.
name|HREGION_OLDLOGDIR_NAME
argument_list|,
name|conf
argument_list|,
name|listeners
argument_list|,
literal|true
argument_list|,
name|prefix
argument_list|,
literal|false
argument_list|)
expr_stmt|;
block|}
comment|/**    * Create an edit log at the given<code>dir</code> location.    *    * You should never have to load an existing log. If there is a log at    * startup, it should have already been processed and deleted by the time the    * HLog object is started up.    *    * @param fs filesystem handle    * @param root path to where logs and oldlogs    * @param logDir dir where hlogs are stored    * @param oldLogDir dir where hlogs are archived    * @param conf configuration to use    * @param listeners Listeners on WAL events. Listeners passed here will    * be registered before we do anything else; e.g. the    * Constructor {@link #rollWriter()}.    * @param failIfLogDirExists If true IOException will be thrown if dir already exists.    * @param prefix should always be hostname and port in distributed env and    *        it will be URL encoded before being used.    *        If prefix is null, "hlog" will be used    * @param forMeta if this hlog is meant for meta updates    * @throws IOException    */
specifier|public
name|FSHLog
parameter_list|(
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Path
name|root
parameter_list|,
specifier|final
name|String
name|logDir
parameter_list|,
specifier|final
name|String
name|oldLogDir
parameter_list|,
specifier|final
name|Configuration
name|conf
parameter_list|,
specifier|final
name|List
argument_list|<
name|WALActionsListener
argument_list|>
name|listeners
parameter_list|,
specifier|final
name|boolean
name|failIfLogDirExists
parameter_list|,
specifier|final
name|String
name|prefix
parameter_list|,
name|boolean
name|forMeta
parameter_list|)
throws|throws
name|IOException
block|{
name|super
argument_list|()
expr_stmt|;
name|this
operator|.
name|fs
operator|=
name|fs
expr_stmt|;
name|this
operator|.
name|rootDir
operator|=
name|root
expr_stmt|;
name|this
operator|.
name|dir
operator|=
operator|new
name|Path
argument_list|(
name|this
operator|.
name|rootDir
argument_list|,
name|logDir
argument_list|)
expr_stmt|;
name|this
operator|.
name|oldLogDir
operator|=
operator|new
name|Path
argument_list|(
name|this
operator|.
name|rootDir
argument_list|,
name|oldLogDir
argument_list|)
expr_stmt|;
name|this
operator|.
name|forMeta
operator|=
name|forMeta
expr_stmt|;
name|this
operator|.
name|conf
operator|=
name|conf
expr_stmt|;
if|if
condition|(
name|listeners
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|WALActionsListener
name|i
range|:
name|listeners
control|)
block|{
name|registerWALActionsListener
argument_list|(
name|i
argument_list|)
expr_stmt|;
block|}
block|}
name|this
operator|.
name|blocksize
operator|=
name|this
operator|.
name|conf
operator|.
name|getLong
argument_list|(
literal|"hbase.regionserver.hlog.blocksize"
argument_list|,
name|FSUtils
operator|.
name|getDefaultBlockSize
argument_list|(
name|this
operator|.
name|fs
argument_list|,
name|this
operator|.
name|dir
argument_list|)
argument_list|)
expr_stmt|;
comment|// Roll at 95% of block size.
name|float
name|multi
init|=
name|conf
operator|.
name|getFloat
argument_list|(
literal|"hbase.regionserver.logroll.multiplier"
argument_list|,
literal|0.95f
argument_list|)
decl_stmt|;
name|this
operator|.
name|logrollsize
operator|=
call|(
name|long
call|)
argument_list|(
name|this
operator|.
name|blocksize
operator|*
name|multi
argument_list|)
expr_stmt|;
name|this
operator|.
name|optionalFlushInterval
operator|=
name|conf
operator|.
name|getLong
argument_list|(
literal|"hbase.regionserver.optionallogflushinterval"
argument_list|,
literal|1
operator|*
literal|1000
argument_list|)
expr_stmt|;
name|this
operator|.
name|maxLogs
operator|=
name|conf
operator|.
name|getInt
argument_list|(
literal|"hbase.regionserver.maxlogs"
argument_list|,
literal|32
argument_list|)
expr_stmt|;
name|this
operator|.
name|minTolerableReplication
operator|=
name|conf
operator|.
name|getInt
argument_list|(
literal|"hbase.regionserver.hlog.tolerable.lowreplication"
argument_list|,
name|FSUtils
operator|.
name|getDefaultReplication
argument_list|(
name|fs
argument_list|,
name|this
operator|.
name|dir
argument_list|)
argument_list|)
expr_stmt|;
name|this
operator|.
name|lowReplicationRollLimit
operator|=
name|conf
operator|.
name|getInt
argument_list|(
literal|"hbase.regionserver.hlog.lowreplication.rolllimit"
argument_list|,
literal|5
argument_list|)
expr_stmt|;
name|this
operator|.
name|enabled
operator|=
name|conf
operator|.
name|getBoolean
argument_list|(
literal|"hbase.regionserver.hlog.enabled"
argument_list|,
literal|true
argument_list|)
expr_stmt|;
name|this
operator|.
name|closeErrorsTolerated
operator|=
name|conf
operator|.
name|getInt
argument_list|(
literal|"hbase.regionserver.logroll.errors.tolerated"
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|this
operator|.
name|logSyncer
operator|=
operator|new
name|LogSyncer
argument_list|(
name|this
operator|.
name|optionalFlushInterval
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"HLog configuration: blocksize="
operator|+
name|StringUtils
operator|.
name|byteDesc
argument_list|(
name|this
operator|.
name|blocksize
argument_list|)
operator|+
literal|", rollsize="
operator|+
name|StringUtils
operator|.
name|byteDesc
argument_list|(
name|this
operator|.
name|logrollsize
argument_list|)
operator|+
literal|", enabled="
operator|+
name|this
operator|.
name|enabled
operator|+
literal|", optionallogflushinternal="
operator|+
name|this
operator|.
name|optionalFlushInterval
operator|+
literal|"ms"
argument_list|)
expr_stmt|;
comment|// If prefix is null||empty then just name it hlog
name|this
operator|.
name|prefix
operator|=
name|prefix
operator|==
literal|null
operator|||
name|prefix
operator|.
name|isEmpty
argument_list|()
condition|?
literal|"hlog"
else|:
name|URLEncoder
operator|.
name|encode
argument_list|(
name|prefix
argument_list|,
literal|"UTF8"
argument_list|)
expr_stmt|;
name|boolean
name|dirExists
init|=
literal|false
decl_stmt|;
if|if
condition|(
name|failIfLogDirExists
operator|&&
operator|(
name|dirExists
operator|=
name|this
operator|.
name|fs
operator|.
name|exists
argument_list|(
name|dir
argument_list|)
operator|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Target HLog directory already exists: "
operator|+
name|dir
argument_list|)
throw|;
block|}
if|if
condition|(
operator|!
name|dirExists
operator|&&
operator|!
name|fs
operator|.
name|mkdirs
argument_list|(
name|dir
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Unable to mkdir "
operator|+
name|dir
argument_list|)
throw|;
block|}
if|if
condition|(
operator|!
name|fs
operator|.
name|exists
argument_list|(
name|this
operator|.
name|oldLogDir
argument_list|)
condition|)
block|{
if|if
condition|(
operator|!
name|fs
operator|.
name|mkdirs
argument_list|(
name|this
operator|.
name|oldLogDir
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Unable to mkdir "
operator|+
name|this
operator|.
name|oldLogDir
argument_list|)
throw|;
block|}
block|}
comment|// rollWriter sets this.hdfs_out if it can.
name|rollWriter
argument_list|()
expr_stmt|;
comment|// handle the reflection necessary to call getNumCurrentReplicas()
name|this
operator|.
name|getNumCurrentReplicas
operator|=
name|getGetNumCurrentReplicas
argument_list|(
name|this
operator|.
name|hdfs_out
argument_list|)
expr_stmt|;
comment|// When optionalFlushInterval is set as 0, don't start a thread for deferred log sync.
if|if
condition|(
name|this
operator|.
name|optionalFlushInterval
operator|>
literal|0
condition|)
block|{
name|Threads
operator|.
name|setDaemonThreadRunning
argument_list|(
name|logSyncer
operator|.
name|getThread
argument_list|()
argument_list|,
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|".logSyncer"
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"hbase.regionserver.optionallogflushinterval is set as "
operator|+
name|this
operator|.
name|optionalFlushInterval
operator|+
literal|". Deferred log syncing won't work. "
operator|+
literal|"Any Mutation, marked to be deferred synced, will be flushed immediately."
argument_list|)
expr_stmt|;
block|}
name|coprocessorHost
operator|=
operator|new
name|WALCoprocessorHost
argument_list|(
name|this
argument_list|,
name|conf
argument_list|)
expr_stmt|;
name|this
operator|.
name|metrics
operator|=
operator|new
name|MetricsWAL
argument_list|()
expr_stmt|;
block|}
comment|/**    * Find the 'getNumCurrentReplicas' on the passed<code>os</code> stream.    * @return Method or null.    */
specifier|private
name|Method
name|getGetNumCurrentReplicas
parameter_list|(
specifier|final
name|FSDataOutputStream
name|os
parameter_list|)
block|{
name|Method
name|m
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|os
operator|!=
literal|null
condition|)
block|{
name|Class
argument_list|<
name|?
extends|extends
name|OutputStream
argument_list|>
name|wrappedStreamClass
init|=
name|os
operator|.
name|getWrappedStream
argument_list|()
operator|.
name|getClass
argument_list|()
decl_stmt|;
try|try
block|{
name|m
operator|=
name|wrappedStreamClass
operator|.
name|getDeclaredMethod
argument_list|(
literal|"getNumCurrentReplicas"
argument_list|,
operator|new
name|Class
argument_list|<
name|?
argument_list|>
index|[]
block|{}
block|)
empty_stmt|;
name|m
operator|.
name|setAccessible
argument_list|(
literal|true
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|NoSuchMethodException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"FileSystem's output stream doesn't support"
operator|+
literal|" getNumCurrentReplicas; --HDFS-826 not available; fsOut="
operator|+
name|wrappedStreamClass
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|SecurityException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Doesn't have access to getNumCurrentReplicas on "
operator|+
literal|"FileSystems's output stream --HDFS-826 not available; fsOut="
operator|+
name|wrappedStreamClass
operator|.
name|getName
argument_list|()
argument_list|,
name|e
argument_list|)
expr_stmt|;
name|m
operator|=
literal|null
expr_stmt|;
comment|// could happen on setAccessible()
block|}
block|}
if|if
condition|(
name|m
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
name|LOG
operator|.
name|isTraceEnabled
argument_list|()
condition|)
name|LOG
operator|.
name|trace
argument_list|(
literal|"Using getNumCurrentReplicas--HDFS-826"
argument_list|)
expr_stmt|;
block|}
return|return
name|m
return|;
block|}
end_class

begin_function
annotation|@
name|Override
specifier|public
name|void
name|registerWALActionsListener
parameter_list|(
specifier|final
name|WALActionsListener
name|listener
parameter_list|)
block|{
name|this
operator|.
name|listeners
operator|.
name|add
argument_list|(
name|listener
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
annotation|@
name|Override
specifier|public
name|boolean
name|unregisterWALActionsListener
parameter_list|(
specifier|final
name|WALActionsListener
name|listener
parameter_list|)
block|{
return|return
name|this
operator|.
name|listeners
operator|.
name|remove
argument_list|(
name|listener
argument_list|)
return|;
block|}
end_function

begin_function
annotation|@
name|Override
specifier|public
name|long
name|getFilenum
parameter_list|()
block|{
return|return
name|this
operator|.
name|filenum
return|;
block|}
end_function

begin_function
annotation|@
name|Override
specifier|public
name|void
name|setSequenceNumber
parameter_list|(
specifier|final
name|long
name|newvalue
parameter_list|)
block|{
for|for
control|(
name|long
name|id
init|=
name|this
operator|.
name|logSeqNum
operator|.
name|get
argument_list|()
init|;
name|id
operator|<
name|newvalue
operator|&&
operator|!
name|this
operator|.
name|logSeqNum
operator|.
name|compareAndSet
argument_list|(
name|id
argument_list|,
name|newvalue
argument_list|)
condition|;
name|id
operator|=
name|this
operator|.
name|logSeqNum
operator|.
name|get
argument_list|()
control|)
block|{
comment|// This could spin on occasion but better the occasional spin than locking
comment|// every increment of sequence number.
name|LOG
operator|.
name|debug
argument_list|(
literal|"Changed sequenceid from "
operator|+
name|id
operator|+
literal|" to "
operator|+
name|newvalue
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_function
annotation|@
name|Override
specifier|public
name|long
name|getSequenceNumber
parameter_list|()
block|{
return|return
name|logSeqNum
operator|.
name|get
argument_list|()
return|;
block|}
end_function

begin_comment
comment|/**    * Method used internal to this class and for tests only.    * @return The wrapped stream our writer is using; its not the    * writer's 'out' FSDatoOutputStream but the stream that this 'out' wraps    * (In hdfs its an instance of DFSDataOutputStream).    *    * usage: see TestLogRolling.java    */
end_comment

begin_function
name|OutputStream
name|getOutputStream
parameter_list|()
block|{
return|return
name|this
operator|.
name|hdfs_out
operator|.
name|getWrappedStream
argument_list|()
return|;
block|}
end_function

begin_function
annotation|@
name|Override
specifier|public
name|byte
index|[]
index|[]
name|rollWriter
parameter_list|()
throws|throws
name|FailedLogCloseException
throws|,
name|IOException
block|{
return|return
name|rollWriter
argument_list|(
literal|false
argument_list|)
return|;
block|}
end_function

begin_function
annotation|@
name|Override
specifier|public
name|byte
index|[]
index|[]
name|rollWriter
parameter_list|(
name|boolean
name|force
parameter_list|)
throws|throws
name|FailedLogCloseException
throws|,
name|IOException
block|{
synchronized|synchronized
init|(
name|rollWriterLock
init|)
block|{
comment|// Return if nothing to flush.
if|if
condition|(
operator|!
name|force
operator|&&
name|this
operator|.
name|writer
operator|!=
literal|null
operator|&&
name|this
operator|.
name|numEntries
operator|.
name|get
argument_list|()
operator|<=
literal|0
condition|)
block|{
return|return
literal|null
return|;
block|}
name|byte
index|[]
index|[]
name|regionsToFlush
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|closed
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"HLog closed. Skipping rolling of writer"
argument_list|)
expr_stmt|;
return|return
literal|null
return|;
block|}
try|try
block|{
name|this
operator|.
name|logRollRunning
operator|=
literal|true
expr_stmt|;
if|if
condition|(
operator|!
name|closeBarrier
operator|.
name|beginOp
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"HLog closing. Skipping rolling of writer"
argument_list|)
expr_stmt|;
return|return
name|regionsToFlush
return|;
block|}
comment|// Do all the preparation outside of the updateLock to block
comment|// as less as possible the incoming writes
name|long
name|currentFilenum
init|=
name|this
operator|.
name|filenum
decl_stmt|;
name|Path
name|oldPath
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|currentFilenum
operator|>
literal|0
condition|)
block|{
comment|//computeFilename  will take care of meta hlog filename
name|oldPath
operator|=
name|computeFilename
argument_list|(
name|currentFilenum
argument_list|)
expr_stmt|;
block|}
name|this
operator|.
name|filenum
operator|=
name|System
operator|.
name|currentTimeMillis
argument_list|()
expr_stmt|;
name|Path
name|newPath
init|=
name|computeFilename
argument_list|()
decl_stmt|;
comment|// Tell our listeners that a new log is about to be created
if|if
condition|(
operator|!
name|this
operator|.
name|listeners
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
for|for
control|(
name|WALActionsListener
name|i
range|:
name|this
operator|.
name|listeners
control|)
block|{
name|i
operator|.
name|preLogRoll
argument_list|(
name|oldPath
argument_list|,
name|newPath
argument_list|)
expr_stmt|;
block|}
block|}
name|FSHLog
operator|.
name|Writer
name|nextWriter
init|=
name|this
operator|.
name|createWriterInstance
argument_list|(
name|fs
argument_list|,
name|newPath
argument_list|,
name|conf
argument_list|)
decl_stmt|;
comment|// Can we get at the dfsclient outputstream?
name|FSDataOutputStream
name|nextHdfsOut
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|nextWriter
operator|instanceof
name|ProtobufLogWriter
condition|)
block|{
name|nextHdfsOut
operator|=
operator|(
operator|(
name|ProtobufLogWriter
operator|)
name|nextWriter
operator|)
operator|.
name|getStream
argument_list|()
expr_stmt|;
block|}
name|Path
name|oldFile
init|=
literal|null
decl_stmt|;
name|int
name|oldNumEntries
init|=
literal|0
decl_stmt|;
synchronized|synchronized
init|(
name|updateLock
init|)
block|{
comment|// Clean up current writer.
name|oldNumEntries
operator|=
name|this
operator|.
name|numEntries
operator|.
name|get
argument_list|()
expr_stmt|;
name|oldFile
operator|=
name|cleanupCurrentWriter
argument_list|(
name|currentFilenum
argument_list|)
expr_stmt|;
name|this
operator|.
name|writer
operator|=
name|nextWriter
expr_stmt|;
name|this
operator|.
name|hdfs_out
operator|=
name|nextHdfsOut
expr_stmt|;
name|this
operator|.
name|numEntries
operator|.
name|set
argument_list|(
literal|0
argument_list|)
expr_stmt|;
block|}
name|LOG
operator|.
name|info
argument_list|(
literal|"Rolled log"
operator|+
operator|(
name|oldFile
operator|!=
literal|null
condition|?
literal|" for file="
operator|+
name|FSUtils
operator|.
name|getPath
argument_list|(
name|oldFile
argument_list|)
operator|+
literal|", entries="
operator|+
name|oldNumEntries
operator|+
literal|", filesize="
operator|+
name|this
operator|.
name|fs
operator|.
name|getFileStatus
argument_list|(
name|oldFile
argument_list|)
operator|.
name|getLen
argument_list|()
else|:
literal|""
operator|)
operator|+
literal|"; new path="
operator|+
name|FSUtils
operator|.
name|getPath
argument_list|(
name|newPath
argument_list|)
argument_list|)
expr_stmt|;
comment|// Tell our listeners that a new log was created
if|if
condition|(
operator|!
name|this
operator|.
name|listeners
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
for|for
control|(
name|WALActionsListener
name|i
range|:
name|this
operator|.
name|listeners
control|)
block|{
name|i
operator|.
name|postLogRoll
argument_list|(
name|oldPath
argument_list|,
name|newPath
argument_list|)
expr_stmt|;
block|}
block|}
comment|// Can we delete any of the old log files?
if|if
condition|(
name|getNumLogFiles
argument_list|()
operator|>
literal|0
condition|)
block|{
name|cleanOldLogs
argument_list|()
expr_stmt|;
name|regionsToFlush
operator|=
name|getRegionsToForceFlush
argument_list|()
expr_stmt|;
block|}
block|}
finally|finally
block|{
name|this
operator|.
name|logRollRunning
operator|=
literal|false
expr_stmt|;
name|closeBarrier
operator|.
name|endOp
argument_list|()
expr_stmt|;
block|}
return|return
name|regionsToFlush
return|;
block|}
block|}
end_function

begin_comment
comment|/**    * This method allows subclasses to inject different writers without having to    * extend other methods like rollWriter().    *    * @param fs    * @param path    * @param conf    * @return Writer instance    * @throws IOException    */
end_comment

begin_function
specifier|protected
name|Writer
name|createWriterInstance
parameter_list|(
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Path
name|path
parameter_list|,
specifier|final
name|Configuration
name|conf
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|forMeta
condition|)
block|{
comment|//TODO: set a higher replication for the hlog files (HBASE-6773)
block|}
return|return
name|HLogFactory
operator|.
name|createWriter
argument_list|(
name|fs
argument_list|,
name|path
argument_list|,
name|conf
argument_list|)
return|;
block|}
end_function

begin_comment
comment|/*    * Clean up old commit logs.    * @return If lots of logs, flush the returned region so next time through    * we can clean logs. Returns null if nothing to flush.  Returns array of    * encoded region names to flush.    * @throws IOException    */
end_comment

begin_function
specifier|private
name|void
name|cleanOldLogs
parameter_list|()
throws|throws
name|IOException
block|{
name|long
name|oldestOutstandingSeqNum
init|=
name|Long
operator|.
name|MAX_VALUE
decl_stmt|;
synchronized|synchronized
init|(
name|oldestSeqNumsLock
init|)
block|{
name|Long
name|oldestFlushing
init|=
operator|(
name|oldestFlushingSeqNums
operator|.
name|size
argument_list|()
operator|>
literal|0
operator|)
condition|?
name|Collections
operator|.
name|min
argument_list|(
name|oldestFlushingSeqNums
operator|.
name|values
argument_list|()
argument_list|)
else|:
name|Long
operator|.
name|MAX_VALUE
decl_stmt|;
name|Long
name|oldestUnflushed
init|=
operator|(
name|oldestUnflushedSeqNums
operator|.
name|size
argument_list|()
operator|>
literal|0
operator|)
condition|?
name|Collections
operator|.
name|min
argument_list|(
name|oldestUnflushedSeqNums
operator|.
name|values
argument_list|()
argument_list|)
else|:
name|Long
operator|.
name|MAX_VALUE
decl_stmt|;
name|oldestOutstandingSeqNum
operator|=
name|Math
operator|.
name|min
argument_list|(
name|oldestFlushing
argument_list|,
name|oldestUnflushed
argument_list|)
expr_stmt|;
block|}
comment|// Get the set of all log files whose last sequence number is smaller than
comment|// the oldest edit's sequence number.
name|TreeSet
argument_list|<
name|Long
argument_list|>
name|sequenceNumbers
init|=
operator|new
name|TreeSet
argument_list|<
name|Long
argument_list|>
argument_list|(
name|this
operator|.
name|outputfiles
operator|.
name|headMap
argument_list|(
name|oldestOutstandingSeqNum
argument_list|)
operator|.
name|keySet
argument_list|()
argument_list|)
decl_stmt|;
comment|// Now remove old log files (if any)
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
if|if
condition|(
name|sequenceNumbers
operator|.
name|size
argument_list|()
operator|>
literal|0
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Found "
operator|+
name|sequenceNumbers
operator|.
name|size
argument_list|()
operator|+
literal|" hlogs to remove"
operator|+
literal|" out of total "
operator|+
name|this
operator|.
name|outputfiles
operator|.
name|size
argument_list|()
operator|+
literal|";"
operator|+
literal|" oldest outstanding sequenceid is "
operator|+
name|oldestOutstandingSeqNum
argument_list|)
expr_stmt|;
block|}
block|}
for|for
control|(
name|Long
name|seq
range|:
name|sequenceNumbers
control|)
block|{
name|archiveLogFile
argument_list|(
name|this
operator|.
name|outputfiles
operator|.
name|remove
argument_list|(
name|seq
argument_list|)
argument_list|,
name|seq
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/**    * Return regions that have edits that are equal or less than a certain sequence number.    * Static due to some old unit test.    * @param walSeqNum The sequence number to compare with.    * @param regionsToSeqNums Encoded region names to sequence ids    * @return All regions whose seqNum<= walSeqNum. Null if no regions found.    */
end_comment

begin_function
specifier|static
name|byte
index|[]
index|[]
name|findMemstoresWithEditsEqualOrOlderThan
parameter_list|(
specifier|final
name|long
name|walSeqNum
parameter_list|,
specifier|final
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|Long
argument_list|>
name|regionsToSeqNums
parameter_list|)
block|{
name|List
argument_list|<
name|byte
index|[]
argument_list|>
name|regions
init|=
literal|null
decl_stmt|;
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|byte
index|[]
argument_list|,
name|Long
argument_list|>
name|e
range|:
name|regionsToSeqNums
operator|.
name|entrySet
argument_list|()
control|)
block|{
if|if
condition|(
name|e
operator|.
name|getValue
argument_list|()
operator|.
name|longValue
argument_list|()
operator|<=
name|walSeqNum
condition|)
block|{
if|if
condition|(
name|regions
operator|==
literal|null
condition|)
name|regions
operator|=
operator|new
name|ArrayList
argument_list|<
name|byte
index|[]
argument_list|>
argument_list|()
expr_stmt|;
name|regions
operator|.
name|add
argument_list|(
name|e
operator|.
name|getKey
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|regions
operator|==
literal|null
condition|?
literal|null
else|:
name|regions
operator|.
name|toArray
argument_list|(
operator|new
name|byte
index|[]
index|[]
block|{
name|HConstants
operator|.
name|EMPTY_BYTE_ARRAY
block|}
argument_list|)
return|;
block|}
end_function

begin_function
specifier|private
name|byte
index|[]
index|[]
name|getRegionsToForceFlush
parameter_list|()
throws|throws
name|IOException
block|{
comment|// If too many log files, figure which regions we need to flush.
comment|// Array is an array of encoded region names.
name|byte
index|[]
index|[]
name|regions
init|=
literal|null
decl_stmt|;
name|int
name|logCount
init|=
name|getNumLogFiles
argument_list|()
decl_stmt|;
if|if
condition|(
name|logCount
operator|>
name|this
operator|.
name|maxLogs
operator|&&
name|logCount
operator|>
literal|0
condition|)
block|{
comment|// This is an array of encoded region names.
synchronized|synchronized
init|(
name|oldestSeqNumsLock
init|)
block|{
name|regions
operator|=
name|findMemstoresWithEditsEqualOrOlderThan
argument_list|(
name|this
operator|.
name|outputfiles
operator|.
name|firstKey
argument_list|()
argument_list|,
name|this
operator|.
name|oldestUnflushedSeqNums
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|regions
operator|!=
literal|null
condition|)
block|{
name|StringBuilder
name|sb
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|regions
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|i
operator|>
literal|0
condition|)
name|sb
operator|.
name|append
argument_list|(
literal|", "
argument_list|)
expr_stmt|;
name|sb
operator|.
name|append
argument_list|(
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|regions
index|[
name|i
index|]
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|LOG
operator|.
name|info
argument_list|(
literal|"Too many hlogs: logs="
operator|+
name|logCount
operator|+
literal|", maxlogs="
operator|+
name|this
operator|.
name|maxLogs
operator|+
literal|"; forcing flush of "
operator|+
name|regions
operator|.
name|length
operator|+
literal|" regions(s): "
operator|+
name|sb
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|regions
return|;
block|}
end_function

begin_comment
comment|/*    * Cleans up current writer closing and adding to outputfiles.    * Presumes we're operating inside an updateLock scope.    * @return Path to current writer or null if none.    * @throws IOException    */
end_comment

begin_function
name|Path
name|cleanupCurrentWriter
parameter_list|(
specifier|final
name|long
name|currentfilenum
parameter_list|)
throws|throws
name|IOException
block|{
name|Path
name|oldFile
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|this
operator|.
name|writer
operator|!=
literal|null
condition|)
block|{
comment|// Close the current writer, get a new one.
try|try
block|{
comment|// Wait till all current transactions are written to the hlog.
comment|// No new transactions can occur because we have the updatelock.
if|if
condition|(
name|this
operator|.
name|unflushedEntries
operator|.
name|get
argument_list|()
operator|!=
name|this
operator|.
name|syncedTillHere
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"cleanupCurrentWriter "
operator|+
literal|" waiting for transactions to get synced "
operator|+
literal|" total "
operator|+
name|this
operator|.
name|unflushedEntries
operator|.
name|get
argument_list|()
operator|+
literal|" synced till here "
operator|+
name|syncedTillHere
argument_list|)
expr_stmt|;
name|sync
argument_list|()
expr_stmt|;
block|}
name|this
operator|.
name|writer
operator|.
name|close
argument_list|()
expr_stmt|;
name|this
operator|.
name|writer
operator|=
literal|null
expr_stmt|;
name|closeErrorCount
operator|.
name|set
argument_list|(
literal|0
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Failed close of HLog writer"
argument_list|,
name|e
argument_list|)
expr_stmt|;
name|int
name|errors
init|=
name|closeErrorCount
operator|.
name|incrementAndGet
argument_list|()
decl_stmt|;
if|if
condition|(
name|errors
operator|<=
name|closeErrorsTolerated
operator|&&
operator|!
name|hasDeferredEntries
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Riding over HLog close failure! error count="
operator|+
name|errors
argument_list|)
expr_stmt|;
block|}
else|else
block|{
if|if
condition|(
name|hasDeferredEntries
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Aborting due to unflushed edits in HLog"
argument_list|)
expr_stmt|;
block|}
comment|// Failed close of log file.  Means we're losing edits.  For now,
comment|// shut ourselves down to minimize loss.  Alternative is to try and
comment|// keep going.  See HBASE-930.
name|FailedLogCloseException
name|flce
init|=
operator|new
name|FailedLogCloseException
argument_list|(
literal|"#"
operator|+
name|currentfilenum
argument_list|)
decl_stmt|;
name|flce
operator|.
name|initCause
argument_list|(
name|e
argument_list|)
expr_stmt|;
throw|throw
name|flce
throw|;
block|}
block|}
if|if
condition|(
name|currentfilenum
operator|>=
literal|0
condition|)
block|{
name|oldFile
operator|=
name|computeFilename
argument_list|(
name|currentfilenum
argument_list|)
expr_stmt|;
name|this
operator|.
name|outputfiles
operator|.
name|put
argument_list|(
name|Long
operator|.
name|valueOf
argument_list|(
name|this
operator|.
name|logSeqNum
operator|.
name|get
argument_list|()
argument_list|)
argument_list|,
name|oldFile
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|oldFile
return|;
block|}
end_function

begin_function
specifier|private
name|void
name|archiveLogFile
parameter_list|(
specifier|final
name|Path
name|p
parameter_list|,
specifier|final
name|Long
name|seqno
parameter_list|)
throws|throws
name|IOException
block|{
name|Path
name|newPath
init|=
name|getHLogArchivePath
argument_list|(
name|this
operator|.
name|oldLogDir
argument_list|,
name|p
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"moving old hlog file "
operator|+
name|FSUtils
operator|.
name|getPath
argument_list|(
name|p
argument_list|)
operator|+
literal|" whose highest sequenceid is "
operator|+
name|seqno
operator|+
literal|" to "
operator|+
name|FSUtils
operator|.
name|getPath
argument_list|(
name|newPath
argument_list|)
argument_list|)
expr_stmt|;
comment|// Tell our listeners that a log is going to be archived.
if|if
condition|(
operator|!
name|this
operator|.
name|listeners
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
for|for
control|(
name|WALActionsListener
name|i
range|:
name|this
operator|.
name|listeners
control|)
block|{
name|i
operator|.
name|preLogArchive
argument_list|(
name|p
argument_list|,
name|newPath
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
operator|!
name|this
operator|.
name|fs
operator|.
name|rename
argument_list|(
name|p
argument_list|,
name|newPath
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Unable to rename "
operator|+
name|p
operator|+
literal|" to "
operator|+
name|newPath
argument_list|)
throw|;
block|}
comment|// Tell our listeners that a log has been archived.
if|if
condition|(
operator|!
name|this
operator|.
name|listeners
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
for|for
control|(
name|WALActionsListener
name|i
range|:
name|this
operator|.
name|listeners
control|)
block|{
name|i
operator|.
name|postLogArchive
argument_list|(
name|p
argument_list|,
name|newPath
argument_list|)
expr_stmt|;
block|}
block|}
block|}
end_function

begin_comment
comment|/**    * This is a convenience method that computes a new filename with a given    * using the current HLog file-number    * @return Path    */
end_comment

begin_function
specifier|protected
name|Path
name|computeFilename
parameter_list|()
block|{
return|return
name|computeFilename
argument_list|(
name|this
operator|.
name|filenum
argument_list|)
return|;
block|}
end_function

begin_comment
comment|/**    * This is a convenience method that computes a new filename with a given    * file-number.    * @param filenum to use    * @return Path    */
end_comment

begin_function
specifier|protected
name|Path
name|computeFilename
parameter_list|(
name|long
name|filenum
parameter_list|)
block|{
if|if
condition|(
name|filenum
operator|<
literal|0
condition|)
block|{
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"hlog file number can't be< 0"
argument_list|)
throw|;
block|}
name|String
name|child
init|=
name|prefix
operator|+
literal|"."
operator|+
name|filenum
decl_stmt|;
if|if
condition|(
name|forMeta
condition|)
block|{
name|child
operator|+=
name|HLog
operator|.
name|META_HLOG_FILE_EXTN
expr_stmt|;
block|}
return|return
operator|new
name|Path
argument_list|(
name|dir
argument_list|,
name|child
argument_list|)
return|;
block|}
end_function

begin_function
annotation|@
name|Override
specifier|public
name|void
name|closeAndDelete
parameter_list|()
throws|throws
name|IOException
block|{
name|close
argument_list|()
expr_stmt|;
if|if
condition|(
operator|!
name|fs
operator|.
name|exists
argument_list|(
name|this
operator|.
name|dir
argument_list|)
condition|)
return|return;
name|FileStatus
index|[]
name|files
init|=
name|fs
operator|.
name|listStatus
argument_list|(
name|this
operator|.
name|dir
argument_list|)
decl_stmt|;
if|if
condition|(
name|files
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|FileStatus
name|file
range|:
name|files
control|)
block|{
name|Path
name|p
init|=
name|getHLogArchivePath
argument_list|(
name|this
operator|.
name|oldLogDir
argument_list|,
name|file
operator|.
name|getPath
argument_list|()
argument_list|)
decl_stmt|;
comment|// Tell our listeners that a log is going to be archived.
if|if
condition|(
operator|!
name|this
operator|.
name|listeners
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
for|for
control|(
name|WALActionsListener
name|i
range|:
name|this
operator|.
name|listeners
control|)
block|{
name|i
operator|.
name|preLogArchive
argument_list|(
name|file
operator|.
name|getPath
argument_list|()
argument_list|,
name|p
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
operator|!
name|fs
operator|.
name|rename
argument_list|(
name|file
operator|.
name|getPath
argument_list|()
argument_list|,
name|p
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Unable to rename "
operator|+
name|file
operator|.
name|getPath
argument_list|()
operator|+
literal|" to "
operator|+
name|p
argument_list|)
throw|;
block|}
comment|// Tell our listeners that a log was archived.
if|if
condition|(
operator|!
name|this
operator|.
name|listeners
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
for|for
control|(
name|WALActionsListener
name|i
range|:
name|this
operator|.
name|listeners
control|)
block|{
name|i
operator|.
name|postLogArchive
argument_list|(
name|file
operator|.
name|getPath
argument_list|()
argument_list|,
name|p
argument_list|)
expr_stmt|;
block|}
block|}
block|}
name|LOG
operator|.
name|debug
argument_list|(
literal|"Moved "
operator|+
name|files
operator|.
name|length
operator|+
literal|" log files to "
operator|+
name|FSUtils
operator|.
name|getPath
argument_list|(
name|this
operator|.
name|oldLogDir
argument_list|)
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|!
name|fs
operator|.
name|delete
argument_list|(
name|dir
argument_list|,
literal|true
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Unable to delete "
operator|+
name|dir
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_function
annotation|@
name|Override
specifier|public
name|void
name|close
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|this
operator|.
name|closed
condition|)
block|{
return|return;
block|}
comment|// When optionalFlushInterval is 0, the logSyncer is not started as a Thread.
if|if
condition|(
name|this
operator|.
name|optionalFlushInterval
operator|>
literal|0
condition|)
block|{
try|try
block|{
name|logSyncer
operator|.
name|close
argument_list|()
expr_stmt|;
comment|// Make sure we synced everything
name|logSyncer
operator|.
name|join
argument_list|(
name|this
operator|.
name|optionalFlushInterval
operator|*
literal|2
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Exception while waiting for syncer thread to die"
argument_list|,
name|e
argument_list|)
expr_stmt|;
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|interrupt
argument_list|()
expr_stmt|;
block|}
block|}
try|try
block|{
comment|// Prevent all further flushing and rolling.
name|closeBarrier
operator|.
name|stopAndDrainOps
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Exception while waiting for cache flushes and log rolls"
argument_list|,
name|e
argument_list|)
expr_stmt|;
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|interrupt
argument_list|()
expr_stmt|;
block|}
comment|// Tell our listeners that the log is closing
if|if
condition|(
operator|!
name|this
operator|.
name|listeners
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
for|for
control|(
name|WALActionsListener
name|i
range|:
name|this
operator|.
name|listeners
control|)
block|{
name|i
operator|.
name|logCloseRequested
argument_list|()
expr_stmt|;
block|}
block|}
synchronized|synchronized
init|(
name|updateLock
init|)
block|{
name|this
operator|.
name|closed
operator|=
literal|true
expr_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"closing hlog writer in "
operator|+
name|this
operator|.
name|dir
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|this
operator|.
name|writer
operator|!=
literal|null
condition|)
block|{
name|this
operator|.
name|writer
operator|.
name|close
argument_list|()
expr_stmt|;
name|this
operator|.
name|writer
operator|=
literal|null
expr_stmt|;
block|}
block|}
block|}
end_function

begin_comment
comment|/**    * @param now    * @param encodedRegionName Encoded name of the region as returned by    *<code>HRegionInfo#getEncodedNameAsBytes()</code>.    * @param tableName    * @param clusterId    * @return New log key.    */
end_comment

begin_function
specifier|protected
name|HLogKey
name|makeKey
parameter_list|(
name|byte
index|[]
name|encodedRegionName
parameter_list|,
name|byte
index|[]
name|tableName
parameter_list|,
name|long
name|seqnum
parameter_list|,
name|long
name|now
parameter_list|,
name|UUID
name|clusterId
parameter_list|)
block|{
return|return
operator|new
name|HLogKey
argument_list|(
name|encodedRegionName
argument_list|,
name|tableName
argument_list|,
name|seqnum
argument_list|,
name|now
argument_list|,
name|clusterId
argument_list|)
return|;
block|}
end_function

begin_function
annotation|@
name|Override
specifier|public
name|void
name|append
parameter_list|(
name|HRegionInfo
name|info
parameter_list|,
name|byte
index|[]
name|tableName
parameter_list|,
name|WALEdit
name|edits
parameter_list|,
specifier|final
name|long
name|now
parameter_list|,
name|HTableDescriptor
name|htd
parameter_list|)
throws|throws
name|IOException
block|{
name|append
argument_list|(
name|info
argument_list|,
name|tableName
argument_list|,
name|edits
argument_list|,
name|HConstants
operator|.
name|DEFAULT_CLUSTER_ID
argument_list|,
name|now
argument_list|,
name|htd
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/**    * Append a set of edits to the log. Log edits are keyed by (encoded)    * regionName, rowname, and log-sequence-id.    *    * Later, if we sort by these keys, we obtain all the relevant edits for a    * given key-range of the HRegion (TODO). Any edits that do not have a    * matching COMPLETE_CACHEFLUSH message can be discarded.    *    *<p>    * Logs cannot be restarted once closed, or once the HLog process dies. Each    * time the HLog starts, it must create a new log. This means that other    * systems should process the log appropriately upon each startup (and prior    * to initializing HLog).    *    * synchronized prevents appends during the completion of a cache flush or for    * the duration of a log roll.    *    * @param info    * @param tableName    * @param edits    * @param clusterId The originating clusterId for this edit (for replication)    * @param now    * @param doSync shall we sync?    * @return txid of this transaction    * @throws IOException    */
end_comment

begin_function
specifier|private
name|long
name|append
parameter_list|(
name|HRegionInfo
name|info
parameter_list|,
name|byte
index|[]
name|tableName
parameter_list|,
name|WALEdit
name|edits
parameter_list|,
name|UUID
name|clusterId
parameter_list|,
specifier|final
name|long
name|now
parameter_list|,
name|HTableDescriptor
name|htd
parameter_list|,
name|boolean
name|doSync
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|edits
operator|.
name|isEmpty
argument_list|()
condition|)
return|return
name|this
operator|.
name|unflushedEntries
operator|.
name|get
argument_list|()
return|;
empty_stmt|;
if|if
condition|(
name|this
operator|.
name|closed
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Cannot append; log is closed"
argument_list|)
throw|;
block|}
name|long
name|txid
init|=
literal|0
decl_stmt|;
synchronized|synchronized
init|(
name|this
operator|.
name|updateLock
init|)
block|{
name|long
name|seqNum
init|=
name|obtainSeqNum
argument_list|()
decl_stmt|;
comment|// The 'lastSeqWritten' map holds the sequence number of the oldest
comment|// write for each region (i.e. the first edit added to the particular
comment|// memstore). . When the cache is flushed, the entry for the
comment|// region being flushed is removed if the sequence number of the flush
comment|// is greater than or equal to the value in lastSeqWritten.
comment|// Use encoded name.  Its shorter, guaranteed unique and a subset of
comment|// actual  name.
name|byte
index|[]
name|encodedRegionName
init|=
name|info
operator|.
name|getEncodedNameAsBytes
argument_list|()
decl_stmt|;
name|this
operator|.
name|oldestUnflushedSeqNums
operator|.
name|putIfAbsent
argument_list|(
name|encodedRegionName
argument_list|,
name|seqNum
argument_list|)
expr_stmt|;
name|HLogKey
name|logKey
init|=
name|makeKey
argument_list|(
name|encodedRegionName
argument_list|,
name|tableName
argument_list|,
name|seqNum
argument_list|,
name|now
argument_list|,
name|clusterId
argument_list|)
decl_stmt|;
name|doWrite
argument_list|(
name|info
argument_list|,
name|logKey
argument_list|,
name|edits
argument_list|,
name|htd
argument_list|)
expr_stmt|;
name|this
operator|.
name|numEntries
operator|.
name|incrementAndGet
argument_list|()
expr_stmt|;
name|txid
operator|=
name|this
operator|.
name|unflushedEntries
operator|.
name|incrementAndGet
argument_list|()
expr_stmt|;
if|if
condition|(
name|htd
operator|.
name|isDeferredLogFlush
argument_list|()
condition|)
block|{
name|lastDeferredTxid
operator|=
name|txid
expr_stmt|;
block|}
block|}
comment|// Sync if catalog region, and if not then check if that table supports
comment|// deferred log flushing
if|if
condition|(
name|doSync
operator|&&
operator|(
name|info
operator|.
name|isMetaRegion
argument_list|()
operator|||
operator|!
name|htd
operator|.
name|isDeferredLogFlush
argument_list|()
operator|)
condition|)
block|{
comment|// sync txn to file system
name|this
operator|.
name|sync
argument_list|(
name|txid
argument_list|)
expr_stmt|;
block|}
return|return
name|txid
return|;
block|}
end_function

begin_function
annotation|@
name|Override
specifier|public
name|long
name|appendNoSync
parameter_list|(
name|HRegionInfo
name|info
parameter_list|,
name|byte
index|[]
name|tableName
parameter_list|,
name|WALEdit
name|edits
parameter_list|,
name|UUID
name|clusterId
parameter_list|,
specifier|final
name|long
name|now
parameter_list|,
name|HTableDescriptor
name|htd
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|append
argument_list|(
name|info
argument_list|,
name|tableName
argument_list|,
name|edits
argument_list|,
name|clusterId
argument_list|,
name|now
argument_list|,
name|htd
argument_list|,
literal|false
argument_list|)
return|;
block|}
end_function

begin_function
annotation|@
name|Override
specifier|public
name|long
name|append
parameter_list|(
name|HRegionInfo
name|info
parameter_list|,
name|byte
index|[]
name|tableName
parameter_list|,
name|WALEdit
name|edits
parameter_list|,
name|UUID
name|clusterId
parameter_list|,
specifier|final
name|long
name|now
parameter_list|,
name|HTableDescriptor
name|htd
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|append
argument_list|(
name|info
argument_list|,
name|tableName
argument_list|,
name|edits
argument_list|,
name|clusterId
argument_list|,
name|now
argument_list|,
name|htd
argument_list|,
literal|true
argument_list|)
return|;
block|}
end_function

begin_comment
comment|/**    * This class is responsible to hold the HLog's appended Entry list    * and to sync them according to a configurable interval.    *    * Deferred log flushing works first by piggy backing on this process by    * simply not sync'ing the appended Entry. It can also be sync'd by other    * non-deferred log flushed entries outside of this thread.    */
end_comment

begin_class
class|class
name|LogSyncer
extends|extends
name|HasThread
block|{
specifier|private
specifier|final
name|long
name|optionalFlushInterval
decl_stmt|;
specifier|private
specifier|final
name|AtomicBoolean
name|closeLogSyncer
init|=
operator|new
name|AtomicBoolean
argument_list|(
literal|false
argument_list|)
decl_stmt|;
comment|// List of pending writes to the HLog. There corresponds to transactions
comment|// that have not yet returned to the client. We keep them cached here
comment|// instead of writing them to HDFS piecemeal, because the HDFS write
comment|// method is pretty heavyweight as far as locking is concerned. The
comment|// goal is to increase the batchsize for writing-to-hdfs as well as
comment|// sync-to-hdfs, so that we can get better system throughput.
specifier|private
name|List
argument_list|<
name|Entry
argument_list|>
name|pendingWrites
init|=
operator|new
name|LinkedList
argument_list|<
name|Entry
argument_list|>
argument_list|()
decl_stmt|;
name|LogSyncer
parameter_list|(
name|long
name|optionalFlushInterval
parameter_list|)
block|{
name|this
operator|.
name|optionalFlushInterval
operator|=
name|optionalFlushInterval
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|run
parameter_list|()
block|{
try|try
block|{
comment|// awaiting with a timeout doesn't always
comment|// throw exceptions on interrupt
while|while
condition|(
operator|!
name|this
operator|.
name|isInterrupted
argument_list|()
operator|&&
operator|!
name|closeLogSyncer
operator|.
name|get
argument_list|()
condition|)
block|{
try|try
block|{
if|if
condition|(
name|unflushedEntries
operator|.
name|get
argument_list|()
operator|<=
name|syncedTillHere
condition|)
block|{
synchronized|synchronized
init|(
name|closeLogSyncer
init|)
block|{
name|closeLogSyncer
operator|.
name|wait
argument_list|(
name|this
operator|.
name|optionalFlushInterval
argument_list|)
expr_stmt|;
block|}
block|}
comment|// Calling sync since we waited or had unflushed entries.
comment|// Entries appended but not sync'd are taken care of here AKA
comment|// deferred log flush
name|sync
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Error while syncing, requesting close of hlog "
argument_list|,
name|e
argument_list|)
expr_stmt|;
name|requestLogRoll
argument_list|()
expr_stmt|;
name|Threads
operator|.
name|sleep
argument_list|(
name|this
operator|.
name|optionalFlushInterval
argument_list|)
expr_stmt|;
block|}
block|}
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
name|getName
argument_list|()
operator|+
literal|" interrupted while waiting for sync requests"
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|LOG
operator|.
name|info
argument_list|(
name|getName
argument_list|()
operator|+
literal|" exiting"
argument_list|)
expr_stmt|;
block|}
block|}
comment|// appends new writes to the pendingWrites. It is better to keep it in
comment|// our own queue rather than writing it to the HDFS output stream because
comment|// HDFSOutputStream.writeChunk is not lightweight at all.
specifier|synchronized
name|void
name|append
parameter_list|(
name|Entry
name|e
parameter_list|)
throws|throws
name|IOException
block|{
name|pendingWrites
operator|.
name|add
argument_list|(
name|e
argument_list|)
expr_stmt|;
block|}
comment|// Returns all currently pending writes. New writes
comment|// will accumulate in a new list.
specifier|synchronized
name|List
argument_list|<
name|Entry
argument_list|>
name|getPendingWrites
parameter_list|()
block|{
name|List
argument_list|<
name|Entry
argument_list|>
name|save
init|=
name|this
operator|.
name|pendingWrites
decl_stmt|;
name|this
operator|.
name|pendingWrites
operator|=
operator|new
name|LinkedList
argument_list|<
name|Entry
argument_list|>
argument_list|()
expr_stmt|;
return|return
name|save
return|;
block|}
comment|// writes out pending entries to the HLog
name|void
name|hlogFlush
parameter_list|(
name|Writer
name|writer
parameter_list|,
name|List
argument_list|<
name|Entry
argument_list|>
name|pending
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|pending
operator|==
literal|null
condition|)
return|return;
comment|// write out all accumulated Entries to hdfs.
for|for
control|(
name|Entry
name|e
range|:
name|pending
control|)
block|{
name|writer
operator|.
name|append
argument_list|(
name|e
argument_list|)
expr_stmt|;
block|}
block|}
name|void
name|close
parameter_list|()
block|{
synchronized|synchronized
init|(
name|closeLogSyncer
init|)
block|{
name|closeLogSyncer
operator|.
name|set
argument_list|(
literal|true
argument_list|)
expr_stmt|;
name|closeLogSyncer
operator|.
name|notifyAll
argument_list|()
expr_stmt|;
block|}
block|}
block|}
end_class

begin_comment
comment|// sync all known transactions
end_comment

begin_function
specifier|private
name|void
name|syncer
parameter_list|()
throws|throws
name|IOException
block|{
name|syncer
argument_list|(
name|this
operator|.
name|unflushedEntries
operator|.
name|get
argument_list|()
argument_list|)
expr_stmt|;
comment|// sync all pending items
block|}
end_function

begin_comment
comment|// sync all transactions upto the specified txid
end_comment

begin_function
specifier|private
name|void
name|syncer
parameter_list|(
name|long
name|txid
parameter_list|)
throws|throws
name|IOException
block|{
comment|// if the transaction that we are interested in is already
comment|// synced, then return immediately.
if|if
condition|(
name|txid
operator|<=
name|this
operator|.
name|syncedTillHere
condition|)
block|{
return|return;
block|}
name|Writer
name|tempWriter
decl_stmt|;
synchronized|synchronized
init|(
name|this
operator|.
name|updateLock
init|)
block|{
if|if
condition|(
name|this
operator|.
name|closed
condition|)
return|return;
comment|// Guaranteed non-null.
comment|// Note that parallel sync can close tempWriter.
comment|// The current method of dealing with this is to catch exceptions.
comment|// See HBASE-4387, HBASE-5623, HBASE-7329.
name|tempWriter
operator|=
name|this
operator|.
name|writer
expr_stmt|;
block|}
try|try
block|{
name|long
name|doneUpto
decl_stmt|;
name|long
name|now
init|=
name|EnvironmentEdgeManager
operator|.
name|currentTimeMillis
argument_list|()
decl_stmt|;
comment|// First flush all the pending writes to HDFS. Then
comment|// issue the sync to HDFS. If sync is successful, then update
comment|// syncedTillHere to indicate that transactions till this
comment|// number has been successfully synced.
name|IOException
name|ioe
init|=
literal|null
decl_stmt|;
name|List
argument_list|<
name|Entry
argument_list|>
name|pending
init|=
literal|null
decl_stmt|;
synchronized|synchronized
init|(
name|flushLock
init|)
block|{
if|if
condition|(
name|txid
operator|<=
name|this
operator|.
name|syncedTillHere
condition|)
block|{
return|return;
block|}
name|doneUpto
operator|=
name|this
operator|.
name|unflushedEntries
operator|.
name|get
argument_list|()
expr_stmt|;
name|pending
operator|=
name|logSyncer
operator|.
name|getPendingWrites
argument_list|()
expr_stmt|;
try|try
block|{
name|logSyncer
operator|.
name|hlogFlush
argument_list|(
name|tempWriter
argument_list|,
name|pending
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|io
parameter_list|)
block|{
name|ioe
operator|=
name|io
expr_stmt|;
name|LOG
operator|.
name|error
argument_list|(
literal|"syncer encountered error, will retry. txid="
operator|+
name|txid
argument_list|,
name|ioe
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|ioe
operator|!=
literal|null
operator|&&
name|pending
operator|!=
literal|null
condition|)
block|{
synchronized|synchronized
init|(
name|this
operator|.
name|updateLock
init|)
block|{
synchronized|synchronized
init|(
name|flushLock
init|)
block|{
comment|// HBASE-4387, HBASE-5623, retry with updateLock held
name|tempWriter
operator|=
name|this
operator|.
name|writer
expr_stmt|;
name|logSyncer
operator|.
name|hlogFlush
argument_list|(
name|tempWriter
argument_list|,
name|pending
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|// another thread might have sync'ed avoid double-sync'ing
if|if
condition|(
name|txid
operator|<=
name|this
operator|.
name|syncedTillHere
condition|)
block|{
return|return;
block|}
try|try
block|{
if|if
condition|(
name|tempWriter
operator|!=
literal|null
condition|)
name|tempWriter
operator|.
name|sync
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ex
parameter_list|)
block|{
synchronized|synchronized
init|(
name|this
operator|.
name|updateLock
init|)
block|{
comment|// HBASE-4387, HBASE-5623, retry with updateLock held
comment|// TODO: we don't actually need to do it for concurrent close - what is the point
comment|//       of syncing new unrelated writer? Keep behavior for now.
name|tempWriter
operator|=
name|this
operator|.
name|writer
expr_stmt|;
if|if
condition|(
name|tempWriter
operator|!=
literal|null
condition|)
name|tempWriter
operator|.
name|sync
argument_list|()
expr_stmt|;
block|}
block|}
name|this
operator|.
name|syncedTillHere
operator|=
name|Math
operator|.
name|max
argument_list|(
name|this
operator|.
name|syncedTillHere
argument_list|,
name|doneUpto
argument_list|)
expr_stmt|;
name|this
operator|.
name|metrics
operator|.
name|finishSync
argument_list|(
name|EnvironmentEdgeManager
operator|.
name|currentTimeMillis
argument_list|()
operator|-
name|now
argument_list|)
expr_stmt|;
comment|// TODO: preserving the old behavior for now, but this check is strange. It's not
comment|//       protected by any locks here, so for all we know rolling locks might start
comment|//       as soon as we enter the "if". Is this best-effort optimization check?
if|if
condition|(
operator|!
name|this
operator|.
name|logRollRunning
condition|)
block|{
name|checkLowReplication
argument_list|()
expr_stmt|;
try|try
block|{
if|if
condition|(
name|tempWriter
operator|.
name|getLength
argument_list|()
operator|>
name|this
operator|.
name|logrollsize
condition|)
block|{
name|requestLogRoll
argument_list|()
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|x
parameter_list|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Log roll failed and will be retried. (This is not an error)"
argument_list|)
expr_stmt|;
block|}
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|fatal
argument_list|(
literal|"Could not sync. Requesting roll of hlog"
argument_list|,
name|e
argument_list|)
expr_stmt|;
name|requestLogRoll
argument_list|()
expr_stmt|;
throw|throw
name|e
throw|;
block|}
block|}
end_function

begin_function
specifier|private
name|void
name|checkLowReplication
parameter_list|()
block|{
comment|// if the number of replicas in HDFS has fallen below the configured
comment|// value, then roll logs.
try|try
block|{
name|int
name|numCurrentReplicas
init|=
name|getLogReplication
argument_list|()
decl_stmt|;
if|if
condition|(
name|numCurrentReplicas
operator|!=
literal|0
operator|&&
name|numCurrentReplicas
operator|<
name|this
operator|.
name|minTolerableReplication
condition|)
block|{
if|if
condition|(
name|this
operator|.
name|lowReplicationRollEnabled
condition|)
block|{
if|if
condition|(
name|this
operator|.
name|consecutiveLogRolls
operator|.
name|get
argument_list|()
operator|<
name|this
operator|.
name|lowReplicationRollLimit
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"HDFS pipeline error detected. "
operator|+
literal|"Found "
operator|+
name|numCurrentReplicas
operator|+
literal|" replicas but expecting no less than "
operator|+
name|this
operator|.
name|minTolerableReplication
operator|+
literal|" replicas. "
operator|+
literal|" Requesting close of hlog."
argument_list|)
expr_stmt|;
name|requestLogRoll
argument_list|()
expr_stmt|;
comment|// If rollWriter is requested, increase consecutiveLogRolls. Once it
comment|// is larger than lowReplicationRollLimit, disable the
comment|// LowReplication-Roller
name|this
operator|.
name|consecutiveLogRolls
operator|.
name|getAndIncrement
argument_list|()
expr_stmt|;
block|}
else|else
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Too many consecutive RollWriter requests, it's a sign of "
operator|+
literal|"the total number of live datanodes is lower than the tolerable replicas."
argument_list|)
expr_stmt|;
name|this
operator|.
name|consecutiveLogRolls
operator|.
name|set
argument_list|(
literal|0
argument_list|)
expr_stmt|;
name|this
operator|.
name|lowReplicationRollEnabled
operator|=
literal|false
expr_stmt|;
block|}
block|}
block|}
elseif|else
if|if
condition|(
name|numCurrentReplicas
operator|>=
name|this
operator|.
name|minTolerableReplication
condition|)
block|{
if|if
condition|(
operator|!
name|this
operator|.
name|lowReplicationRollEnabled
condition|)
block|{
comment|// The new writer's log replicas is always the default value.
comment|// So we should not enable LowReplication-Roller. If numEntries
comment|// is lower than or equals 1, we consider it as a new writer.
if|if
condition|(
name|this
operator|.
name|numEntries
operator|.
name|get
argument_list|()
operator|<=
literal|1
condition|)
block|{
return|return;
block|}
comment|// Once the live datanode number and the replicas return to normal,
comment|// enable the LowReplication-Roller.
name|this
operator|.
name|lowReplicationRollEnabled
operator|=
literal|true
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"LowReplication-Roller was enabled."
argument_list|)
expr_stmt|;
block|}
block|}
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Unable to invoke DFSOutputStream.getNumCurrentReplicas"
operator|+
name|e
operator|+
literal|" still proceeding ahead..."
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/**    * This method gets the datanode replication count for the current HLog.    *    * If the pipeline isn't started yet or is empty, you will get the default    * replication factor.  Therefore, if this function returns 0, it means you    * are not properly running with the HDFS-826 patch.    * @throws InvocationTargetException    * @throws IllegalAccessException    * @throws IllegalArgumentException    *    * @throws Exception    */
end_comment

begin_function
name|int
name|getLogReplication
parameter_list|()
throws|throws
name|IllegalArgumentException
throws|,
name|IllegalAccessException
throws|,
name|InvocationTargetException
block|{
if|if
condition|(
name|this
operator|.
name|getNumCurrentReplicas
operator|!=
literal|null
operator|&&
name|this
operator|.
name|hdfs_out
operator|!=
literal|null
condition|)
block|{
name|Object
name|repl
init|=
name|this
operator|.
name|getNumCurrentReplicas
operator|.
name|invoke
argument_list|(
name|getOutputStream
argument_list|()
argument_list|,
name|NO_ARGS
argument_list|)
decl_stmt|;
if|if
condition|(
name|repl
operator|instanceof
name|Integer
condition|)
block|{
return|return
operator|(
operator|(
name|Integer
operator|)
name|repl
operator|)
operator|.
name|intValue
argument_list|()
return|;
block|}
block|}
return|return
literal|0
return|;
block|}
end_function

begin_function
name|boolean
name|canGetCurReplicas
parameter_list|()
block|{
return|return
name|this
operator|.
name|getNumCurrentReplicas
operator|!=
literal|null
return|;
block|}
end_function

begin_function
annotation|@
name|Override
specifier|public
name|void
name|hsync
parameter_list|()
throws|throws
name|IOException
block|{
name|syncer
argument_list|()
expr_stmt|;
block|}
end_function

begin_function
annotation|@
name|Override
specifier|public
name|void
name|hflush
parameter_list|()
throws|throws
name|IOException
block|{
name|syncer
argument_list|()
expr_stmt|;
block|}
end_function

begin_function
annotation|@
name|Override
specifier|public
name|void
name|sync
parameter_list|()
throws|throws
name|IOException
block|{
name|syncer
argument_list|()
expr_stmt|;
block|}
end_function

begin_function
annotation|@
name|Override
specifier|public
name|void
name|sync
parameter_list|(
name|long
name|txid
parameter_list|)
throws|throws
name|IOException
block|{
name|syncer
argument_list|(
name|txid
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|private
name|void
name|requestLogRoll
parameter_list|()
block|{
if|if
condition|(
operator|!
name|this
operator|.
name|listeners
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
for|for
control|(
name|WALActionsListener
name|i
range|:
name|this
operator|.
name|listeners
control|)
block|{
name|i
operator|.
name|logRollRequested
argument_list|()
expr_stmt|;
block|}
block|}
block|}
end_function

begin_comment
comment|// TODO: Remove info.  Unused.
end_comment

begin_function
specifier|protected
name|void
name|doWrite
parameter_list|(
name|HRegionInfo
name|info
parameter_list|,
name|HLogKey
name|logKey
parameter_list|,
name|WALEdit
name|logEdit
parameter_list|,
name|HTableDescriptor
name|htd
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
operator|!
name|this
operator|.
name|enabled
condition|)
block|{
return|return;
block|}
if|if
condition|(
operator|!
name|this
operator|.
name|listeners
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
for|for
control|(
name|WALActionsListener
name|i
range|:
name|this
operator|.
name|listeners
control|)
block|{
name|i
operator|.
name|visitLogEntryBeforeWrite
argument_list|(
name|htd
argument_list|,
name|logKey
argument_list|,
name|logEdit
argument_list|)
expr_stmt|;
block|}
block|}
try|try
block|{
name|long
name|now
init|=
name|EnvironmentEdgeManager
operator|.
name|currentTimeMillis
argument_list|()
decl_stmt|;
comment|// coprocessor hook:
if|if
condition|(
operator|!
name|coprocessorHost
operator|.
name|preWALWrite
argument_list|(
name|info
argument_list|,
name|logKey
argument_list|,
name|logEdit
argument_list|)
condition|)
block|{
if|if
condition|(
name|logEdit
operator|.
name|isReplay
argument_list|()
condition|)
block|{
comment|// set replication scope null so that this won't be replicated
name|logKey
operator|.
name|setScopes
argument_list|(
literal|null
argument_list|)
expr_stmt|;
block|}
comment|// write to our buffer for the Hlog file.
name|logSyncer
operator|.
name|append
argument_list|(
operator|new
name|FSHLog
operator|.
name|Entry
argument_list|(
name|logKey
argument_list|,
name|logEdit
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|long
name|took
init|=
name|EnvironmentEdgeManager
operator|.
name|currentTimeMillis
argument_list|()
operator|-
name|now
decl_stmt|;
name|coprocessorHost
operator|.
name|postWALWrite
argument_list|(
name|info
argument_list|,
name|logKey
argument_list|,
name|logEdit
argument_list|)
expr_stmt|;
name|long
name|len
init|=
literal|0
decl_stmt|;
for|for
control|(
name|KeyValue
name|kv
range|:
name|logEdit
operator|.
name|getKeyValues
argument_list|()
control|)
block|{
name|len
operator|+=
name|kv
operator|.
name|getLength
argument_list|()
expr_stmt|;
block|}
name|this
operator|.
name|metrics
operator|.
name|finishAppend
argument_list|(
name|took
argument_list|,
name|len
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|fatal
argument_list|(
literal|"Could not append. Requesting close of hlog"
argument_list|,
name|e
argument_list|)
expr_stmt|;
name|requestLogRoll
argument_list|()
expr_stmt|;
throw|throw
name|e
throw|;
block|}
block|}
end_function

begin_comment
comment|/** @return How many items have been added to the log */
end_comment

begin_function
name|int
name|getNumEntries
parameter_list|()
block|{
return|return
name|numEntries
operator|.
name|get
argument_list|()
return|;
block|}
end_function

begin_function
annotation|@
name|Override
specifier|public
name|long
name|obtainSeqNum
parameter_list|()
block|{
return|return
name|this
operator|.
name|logSeqNum
operator|.
name|incrementAndGet
argument_list|()
return|;
block|}
end_function

begin_comment
comment|/** @return the number of log files in use */
end_comment

begin_function
name|int
name|getNumLogFiles
parameter_list|()
block|{
return|return
name|outputfiles
operator|.
name|size
argument_list|()
return|;
block|}
end_function

begin_function
annotation|@
name|Override
specifier|public
name|Long
name|startCacheFlush
parameter_list|(
specifier|final
name|byte
index|[]
name|encodedRegionName
parameter_list|)
block|{
name|Long
name|oldRegionSeqNum
init|=
literal|null
decl_stmt|;
if|if
condition|(
operator|!
name|closeBarrier
operator|.
name|beginOp
argument_list|()
condition|)
block|{
return|return
literal|null
return|;
block|}
synchronized|synchronized
init|(
name|oldestSeqNumsLock
init|)
block|{
name|oldRegionSeqNum
operator|=
name|this
operator|.
name|oldestUnflushedSeqNums
operator|.
name|remove
argument_list|(
name|encodedRegionName
argument_list|)
expr_stmt|;
if|if
condition|(
name|oldRegionSeqNum
operator|!=
literal|null
condition|)
block|{
name|Long
name|oldValue
init|=
name|this
operator|.
name|oldestFlushingSeqNums
operator|.
name|put
argument_list|(
name|encodedRegionName
argument_list|,
name|oldRegionSeqNum
argument_list|)
decl_stmt|;
assert|assert
name|oldValue
operator|==
literal|null
operator|:
literal|"Flushing map not cleaned up for "
operator|+
name|Bytes
operator|.
name|toString
argument_list|(
name|encodedRegionName
argument_list|)
assert|;
block|}
block|}
if|if
condition|(
name|oldRegionSeqNum
operator|==
literal|null
condition|)
block|{
comment|// TODO: if we have no oldRegionSeqNum, and WAL is not disabled, presumably either
comment|//       the region is already flushing (which would make this call invalid), or there
comment|//       were no appends after last flush, so why are we starting flush? Maybe we should
comment|//       assert not null, and switch to "long" everywhere. Less rigorous, but safer,
comment|//       alternative is telling the caller to stop. For now preserve old logic.
name|LOG
operator|.
name|warn
argument_list|(
literal|"Couldn't find oldest seqNum for the region we are about to flush: ["
operator|+
name|Bytes
operator|.
name|toString
argument_list|(
name|encodedRegionName
argument_list|)
operator|+
literal|"]"
argument_list|)
expr_stmt|;
block|}
return|return
name|obtainSeqNum
argument_list|()
return|;
block|}
end_function

begin_function
annotation|@
name|Override
specifier|public
name|void
name|completeCacheFlush
parameter_list|(
specifier|final
name|byte
index|[]
name|encodedRegionName
parameter_list|)
block|{
synchronized|synchronized
init|(
name|oldestSeqNumsLock
init|)
block|{
name|this
operator|.
name|oldestFlushingSeqNums
operator|.
name|remove
argument_list|(
name|encodedRegionName
argument_list|)
expr_stmt|;
block|}
name|closeBarrier
operator|.
name|endOp
argument_list|()
expr_stmt|;
block|}
end_function

begin_function
annotation|@
name|Override
specifier|public
name|void
name|abortCacheFlush
parameter_list|(
name|byte
index|[]
name|encodedRegionName
parameter_list|)
block|{
name|Long
name|currentSeqNum
init|=
literal|null
decl_stmt|,
name|seqNumBeforeFlushStarts
init|=
literal|null
decl_stmt|;
synchronized|synchronized
init|(
name|oldestSeqNumsLock
init|)
block|{
name|seqNumBeforeFlushStarts
operator|=
name|this
operator|.
name|oldestFlushingSeqNums
operator|.
name|remove
argument_list|(
name|encodedRegionName
argument_list|)
expr_stmt|;
if|if
condition|(
name|seqNumBeforeFlushStarts
operator|!=
literal|null
condition|)
block|{
name|currentSeqNum
operator|=
name|this
operator|.
name|oldestUnflushedSeqNums
operator|.
name|put
argument_list|(
name|encodedRegionName
argument_list|,
name|seqNumBeforeFlushStarts
argument_list|)
expr_stmt|;
block|}
block|}
name|closeBarrier
operator|.
name|endOp
argument_list|()
expr_stmt|;
if|if
condition|(
operator|(
name|currentSeqNum
operator|!=
literal|null
operator|)
operator|&&
operator|(
name|currentSeqNum
operator|.
name|longValue
argument_list|()
operator|<=
name|seqNumBeforeFlushStarts
operator|.
name|longValue
argument_list|()
operator|)
condition|)
block|{
name|String
name|errorStr
init|=
literal|"Region "
operator|+
name|Bytes
operator|.
name|toString
argument_list|(
name|encodedRegionName
argument_list|)
operator|+
literal|"acquired edits out of order current memstore seq="
operator|+
name|currentSeqNum
operator|+
literal|", previous oldest unflushed id="
operator|+
name|seqNumBeforeFlushStarts
decl_stmt|;
name|LOG
operator|.
name|error
argument_list|(
name|errorStr
argument_list|)
expr_stmt|;
assert|assert
literal|false
operator|:
name|errorStr
assert|;
name|Runtime
operator|.
name|getRuntime
argument_list|()
operator|.
name|halt
argument_list|(
literal|1
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_function
annotation|@
name|Override
specifier|public
name|boolean
name|isLowReplicationRollEnabled
parameter_list|()
block|{
return|return
name|lowReplicationRollEnabled
return|;
block|}
end_function

begin_comment
comment|/**    * Get the directory we are making logs in.    *    * @return dir    */
end_comment

begin_function
specifier|protected
name|Path
name|getDir
parameter_list|()
block|{
return|return
name|dir
return|;
block|}
end_function

begin_function
specifier|static
name|Path
name|getHLogArchivePath
parameter_list|(
name|Path
name|oldLogDir
parameter_list|,
name|Path
name|p
parameter_list|)
block|{
return|return
operator|new
name|Path
argument_list|(
name|oldLogDir
argument_list|,
name|p
operator|.
name|getName
argument_list|()
argument_list|)
return|;
block|}
end_function

begin_function
specifier|static
name|String
name|formatRecoveredEditsFileName
parameter_list|(
specifier|final
name|long
name|seqid
parameter_list|)
block|{
return|return
name|String
operator|.
name|format
argument_list|(
literal|"%019d"
argument_list|,
name|seqid
argument_list|)
return|;
block|}
end_function

begin_decl_stmt
specifier|public
specifier|static
specifier|final
name|long
name|FIXED_OVERHEAD
init|=
name|ClassSize
operator|.
name|align
argument_list|(
name|ClassSize
operator|.
name|OBJECT
operator|+
operator|(
literal|5
operator|*
name|ClassSize
operator|.
name|REFERENCE
operator|)
operator|+
name|ClassSize
operator|.
name|ATOMIC_INTEGER
operator|+
name|Bytes
operator|.
name|SIZEOF_INT
operator|+
operator|(
literal|3
operator|*
name|Bytes
operator|.
name|SIZEOF_LONG
operator|)
argument_list|)
decl_stmt|;
end_decl_stmt

begin_function
specifier|private
specifier|static
name|void
name|usage
parameter_list|()
block|{
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|"Usage: HLog<ARGS>"
argument_list|)
expr_stmt|;
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|"Arguments:"
argument_list|)
expr_stmt|;
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|" --dump  Dump textual representation of passed one or more files"
argument_list|)
expr_stmt|;
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|"         For example: HLog --dump hdfs://example.com:9000/hbase/.logs/MACHINE/LOGFILE"
argument_list|)
expr_stmt|;
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|" --split Split the passed directory of WAL logs"
argument_list|)
expr_stmt|;
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
literal|"         For example: HLog --split hdfs://example.com:9000/hbase/.logs/DIR"
argument_list|)
expr_stmt|;
block|}
end_function

begin_function
specifier|private
specifier|static
name|void
name|split
parameter_list|(
specifier|final
name|Configuration
name|conf
parameter_list|,
specifier|final
name|Path
name|p
parameter_list|)
throws|throws
name|IOException
block|{
name|FileSystem
name|fs
init|=
name|FileSystem
operator|.
name|get
argument_list|(
name|conf
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|fs
operator|.
name|exists
argument_list|(
name|p
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|FileNotFoundException
argument_list|(
name|p
operator|.
name|toString
argument_list|()
argument_list|)
throw|;
block|}
specifier|final
name|Path
name|baseDir
init|=
name|FSUtils
operator|.
name|getRootDir
argument_list|(
name|conf
argument_list|)
decl_stmt|;
specifier|final
name|Path
name|oldLogDir
init|=
operator|new
name|Path
argument_list|(
name|baseDir
argument_list|,
name|HConstants
operator|.
name|HREGION_OLDLOGDIR_NAME
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|fs
operator|.
name|getFileStatus
argument_list|(
name|p
argument_list|)
operator|.
name|isDir
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|p
operator|+
literal|" is not a directory"
argument_list|)
throw|;
block|}
name|HLogSplitter
name|logSplitter
init|=
name|HLogSplitter
operator|.
name|createLogSplitter
argument_list|(
name|conf
argument_list|,
name|baseDir
argument_list|,
name|p
argument_list|,
name|oldLogDir
argument_list|,
name|fs
argument_list|)
decl_stmt|;
name|logSplitter
operator|.
name|splitLog
argument_list|()
expr_stmt|;
block|}
end_function

begin_function
annotation|@
name|Override
specifier|public
name|WALCoprocessorHost
name|getCoprocessorHost
parameter_list|()
block|{
return|return
name|coprocessorHost
return|;
block|}
end_function

begin_comment
comment|/** Provide access to currently deferred sequence num for tests */
end_comment

begin_function
name|boolean
name|hasDeferredEntries
parameter_list|()
block|{
return|return
name|lastDeferredTxid
operator|>
name|syncedTillHere
return|;
block|}
end_function

begin_function
annotation|@
name|Override
specifier|public
name|long
name|getEarliestMemstoreSeqNum
parameter_list|(
name|byte
index|[]
name|encodedRegionName
parameter_list|)
block|{
name|Long
name|result
init|=
name|oldestUnflushedSeqNums
operator|.
name|get
argument_list|(
name|encodedRegionName
argument_list|)
decl_stmt|;
return|return
name|result
operator|==
literal|null
condition|?
name|HConstants
operator|.
name|NO_SEQNUM
else|:
name|result
operator|.
name|longValue
argument_list|()
return|;
block|}
end_function

begin_comment
comment|/**    * Pass one or more log file names and it will either dump out a text version    * on<code>stdout</code> or split the specified log files.    *    * @param args    * @throws IOException    */
end_comment

begin_function
specifier|public
specifier|static
name|void
name|main
parameter_list|(
name|String
index|[]
name|args
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|args
operator|.
name|length
operator|<
literal|2
condition|)
block|{
name|usage
argument_list|()
expr_stmt|;
name|System
operator|.
name|exit
argument_list|(
operator|-
literal|1
argument_list|)
expr_stmt|;
block|}
comment|// either dump using the HLogPrettyPrinter or split, depending on args
if|if
condition|(
name|args
index|[
literal|0
index|]
operator|.
name|compareTo
argument_list|(
literal|"--dump"
argument_list|)
operator|==
literal|0
condition|)
block|{
name|HLogPrettyPrinter
operator|.
name|run
argument_list|(
name|Arrays
operator|.
name|copyOfRange
argument_list|(
name|args
argument_list|,
literal|1
argument_list|,
name|args
operator|.
name|length
argument_list|)
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|args
index|[
literal|0
index|]
operator|.
name|compareTo
argument_list|(
literal|"--split"
argument_list|)
operator|==
literal|0
condition|)
block|{
name|Configuration
name|conf
init|=
name|HBaseConfiguration
operator|.
name|create
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|1
init|;
name|i
operator|<
name|args
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
try|try
block|{
name|Path
name|logPath
init|=
operator|new
name|Path
argument_list|(
name|args
index|[
name|i
index|]
argument_list|)
decl_stmt|;
name|FSUtils
operator|.
name|setFsDefault
argument_list|(
name|conf
argument_list|,
name|logPath
argument_list|)
expr_stmt|;
name|split
argument_list|(
name|conf
argument_list|,
name|logPath
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Throwable
name|t
parameter_list|)
block|{
name|t
operator|.
name|printStackTrace
argument_list|(
name|System
operator|.
name|err
argument_list|)
expr_stmt|;
name|System
operator|.
name|exit
argument_list|(
operator|-
literal|1
argument_list|)
expr_stmt|;
block|}
block|}
block|}
else|else
block|{
name|usage
argument_list|()
expr_stmt|;
name|System
operator|.
name|exit
argument_list|(
operator|-
literal|1
argument_list|)
expr_stmt|;
block|}
block|}
end_function

unit|}
end_unit

