begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/*  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|Closeable
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|FileNotFoundException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|InterruptedIOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|PrintWriter
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|StringWriter
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|InetAddress
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|URI
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Arrays
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collection
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collections
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Comparator
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|EnumSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Iterator
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Locale
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
operator|.
name|Entry
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Objects
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Optional
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Set
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|SortedMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|SortedSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|TreeMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|TreeSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Vector
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|Callable
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ConcurrentSkipListMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ExecutionException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ExecutorService
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|Executors
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|Future
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|FutureTask
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ScheduledThreadPoolExecutor
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|TimeUnit
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|TimeoutException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|atomic
operator|.
name|AtomicBoolean
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|atomic
operator|.
name|AtomicInteger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|io
operator|.
name|IOUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|lang3
operator|.
name|RandomStringUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|lang3
operator|.
name|StringUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configured
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FSDataOutputStream
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileStatus
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|permission
operator|.
name|FsAction
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|permission
operator|.
name|FsPermission
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|Abortable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|Cell
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|CellUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|ClusterMetrics
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|ClusterMetrics
operator|.
name|Option
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HBaseConfiguration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HBaseInterfaceAudience
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HConstants
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HRegionInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HRegionLocation
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|KeyValue
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|MasterNotRunningException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|MetaTableAccessor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|RegionLocations
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|ServerName
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|TableName
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|ZooKeeperConnectionException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|Admin
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|ClusterConnection
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|ColumnFamilyDescriptor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|ColumnFamilyDescriptorBuilder
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|Connection
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|ConnectionFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|Delete
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|Get
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|Put
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|RegionInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|RegionInfoBuilder
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|RegionReplicaUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|Result
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|RowMutations
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|Table
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|TableDescriptor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|TableDescriptorBuilder
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|TableState
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|FileLink
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|HFileLink
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|hfile
operator|.
name|CacheConfig
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|hfile
operator|.
name|HFile
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|log
operator|.
name|HBaseMarkers
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|master
operator|.
name|MasterFileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|master
operator|.
name|RegionState
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|HRegion
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|HRegionFileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|StoreFileInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|replication
operator|.
name|ReplicationException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|security
operator|.
name|AccessDeniedException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|security
operator|.
name|UserProvider
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|Bytes
operator|.
name|ByteArrayComparator
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|HBaseFsck
operator|.
name|ErrorReporter
operator|.
name|ERROR_CODE
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|hbck
operator|.
name|HFileCorruptionChecker
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|hbck
operator|.
name|ReplicationChecker
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|hbck
operator|.
name|TableIntegrityErrorHandler
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|hbck
operator|.
name|TableIntegrityErrorHandlerImpl
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|wal
operator|.
name|WAL
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|wal
operator|.
name|WALFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|wal
operator|.
name|WALSplitter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|zookeeper
operator|.
name|MetaTableLocator
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|zookeeper
operator|.
name|ZKUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|zookeeper
operator|.
name|ZKWatcher
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|zookeeper
operator|.
name|ZNodePaths
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hdfs
operator|.
name|protocol
operator|.
name|AlreadyBeingCreatedException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|ipc
operator|.
name|RemoteException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|security
operator|.
name|UserGroupInformation
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|ReflectionUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|Tool
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|ToolRunner
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hbase
operator|.
name|thirdparty
operator|.
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|Sets
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|yetus
operator|.
name|audience
operator|.
name|InterfaceAudience
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|yetus
operator|.
name|audience
operator|.
name|InterfaceStability
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|zookeeper
operator|.
name|KeeperException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|Logger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|LoggerFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hbase
operator|.
name|thirdparty
operator|.
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Joiner
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hbase
operator|.
name|thirdparty
operator|.
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Preconditions
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hbase
operator|.
name|thirdparty
operator|.
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|ImmutableList
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hbase
operator|.
name|thirdparty
operator|.
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|Lists
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hbase
operator|.
name|thirdparty
operator|.
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|Multimap
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hbase
operator|.
name|thirdparty
operator|.
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|Ordering
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hbase
operator|.
name|thirdparty
operator|.
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|TreeMultimap
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|shaded
operator|.
name|protobuf
operator|.
name|ProtobufUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|shaded
operator|.
name|protobuf
operator|.
name|generated
operator|.
name|AdminProtos
operator|.
name|AdminService
operator|.
name|BlockingInterface
import|;
end_import

begin_comment
comment|/**  * HBaseFsck (hbck) is a tool for checking and repairing region consistency and  * table integrity problems in a corrupted HBase.  *<p>  * Region consistency checks verify that hbase:meta, region deployment on region  * servers and the state of data in HDFS (.regioninfo files) all are in  * accordance.  *<p>  * Table integrity checks verify that all possible row keys resolve to exactly  * one region of a table.  This means there are no individual degenerate  * or backwards regions; no holes between regions; and that there are no  * overlapping regions.  *<p>  * The general repair strategy works in two phases:  *<ol>  *<li> Repair Table Integrity on HDFS. (merge or fabricate regions)  *<li> Repair Region Consistency with hbase:meta and assignments  *</ol>  *<p>  * For table integrity repairs, the tables' region directories are scanned  * for .regioninfo files.  Each table's integrity is then verified.  If there  * are any orphan regions (regions with no .regioninfo files) or holes, new  * regions are fabricated.  Backwards regions are sidelined as well as empty  * degenerate (endkey==startkey) regions.  If there are any overlapping regions,  * a new region is created and all data is merged into the new region.  *<p>  * Table integrity repairs deal solely with HDFS and could potentially be done  * offline -- the hbase region servers or master do not need to be running.  * This phase can eventually be used to completely reconstruct the hbase:meta table in  * an offline fashion.  *<p>  * Region consistency requires three conditions -- 1) valid .regioninfo file  * present in an HDFS region dir,  2) valid row with .regioninfo data in META,  * and 3) a region is deployed only at the regionserver that was assigned to  * with proper state in the master.  *<p>  * Region consistency repairs require hbase to be online so that hbck can  * contact the HBase master and region servers.  The hbck#connect() method must  * first be called successfully.  Much of the region consistency information  * is transient and less risky to repair.  *<p>  * If hbck is run from the command line, there are a handful of arguments that  * can be used to limit the kinds of repairs hbck will do.  See the code in  * {@link #printUsageAndExit()} for more details.  */
end_comment

begin_class
annotation|@
name|InterfaceAudience
operator|.
name|LimitedPrivate
argument_list|(
name|HBaseInterfaceAudience
operator|.
name|TOOLS
argument_list|)
annotation|@
name|InterfaceStability
operator|.
name|Evolving
specifier|public
class|class
name|HBaseFsck
extends|extends
name|Configured
implements|implements
name|Closeable
block|{
specifier|public
specifier|static
specifier|final
name|long
name|DEFAULT_TIME_LAG
init|=
literal|60000
decl_stmt|;
comment|// default value of 1 minute
specifier|public
specifier|static
specifier|final
name|long
name|DEFAULT_SLEEP_BEFORE_RERUN
init|=
literal|10000
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|int
name|MAX_NUM_THREADS
init|=
literal|50
decl_stmt|;
comment|// #threads to contact regions
specifier|private
specifier|static
name|boolean
name|rsSupportsOffline
init|=
literal|true
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|int
name|DEFAULT_OVERLAPS_TO_SIDELINE
init|=
literal|2
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|int
name|DEFAULT_MAX_MERGE
init|=
literal|5
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|String
name|TO_BE_LOADED
init|=
literal|"to_be_loaded"
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|String
name|HBCK_LOCK_FILE
init|=
literal|"hbase-hbck.lock"
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|int
name|DEFAULT_MAX_LOCK_FILE_ATTEMPTS
init|=
literal|5
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|int
name|DEFAULT_LOCK_FILE_ATTEMPT_SLEEP_INTERVAL
init|=
literal|200
decl_stmt|;
comment|// milliseconds
specifier|private
specifier|static
specifier|final
name|int
name|DEFAULT_LOCK_FILE_ATTEMPT_MAX_SLEEP_TIME
init|=
literal|5000
decl_stmt|;
comment|// milliseconds
comment|// We have to set the timeout value> HdfsConstants.LEASE_SOFTLIMIT_PERIOD.
comment|// In HADOOP-2.6 and later, the Namenode proxy now created with custom RetryPolicy for
comment|// AlreadyBeingCreatedException which is implies timeout on this operations up to
comment|// HdfsConstants.LEASE_SOFTLIMIT_PERIOD (60 seconds).
specifier|private
specifier|static
specifier|final
name|int
name|DEFAULT_WAIT_FOR_LOCK_TIMEOUT
init|=
literal|80
decl_stmt|;
comment|// seconds
specifier|private
specifier|static
specifier|final
name|int
name|DEFAULT_MAX_CREATE_ZNODE_ATTEMPTS
init|=
literal|5
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|int
name|DEFAULT_CREATE_ZNODE_ATTEMPT_SLEEP_INTERVAL
init|=
literal|200
decl_stmt|;
comment|// milliseconds
specifier|private
specifier|static
specifier|final
name|int
name|DEFAULT_CREATE_ZNODE_ATTEMPT_MAX_SLEEP_TIME
init|=
literal|5000
decl_stmt|;
comment|// milliseconds
comment|/**********************    * Internal resources    **********************/
specifier|private
specifier|static
specifier|final
name|Logger
name|LOG
init|=
name|LoggerFactory
operator|.
name|getLogger
argument_list|(
name|HBaseFsck
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
specifier|private
name|ClusterMetrics
name|status
decl_stmt|;
specifier|private
name|ClusterConnection
name|connection
decl_stmt|;
specifier|private
name|Admin
name|admin
decl_stmt|;
specifier|private
name|Table
name|meta
decl_stmt|;
comment|// threads to do ||izable tasks: retrieve data from regionservers, handle overlapping regions
specifier|protected
name|ExecutorService
name|executor
decl_stmt|;
specifier|private
name|long
name|startMillis
init|=
name|EnvironmentEdgeManager
operator|.
name|currentTime
argument_list|()
decl_stmt|;
specifier|private
name|HFileCorruptionChecker
name|hfcc
decl_stmt|;
specifier|private
name|int
name|retcode
init|=
literal|0
decl_stmt|;
specifier|private
name|Path
name|HBCK_LOCK_PATH
decl_stmt|;
specifier|private
name|FSDataOutputStream
name|hbckOutFd
decl_stmt|;
comment|// This lock is to prevent cleanup of balancer resources twice between
comment|// ShutdownHook and the main code. We cleanup only if the connect() is
comment|// successful
specifier|private
specifier|final
name|AtomicBoolean
name|hbckLockCleanup
init|=
operator|new
name|AtomicBoolean
argument_list|(
literal|false
argument_list|)
decl_stmt|;
comment|// Unsupported options in HBase 2.0+
specifier|private
specifier|static
specifier|final
name|Set
argument_list|<
name|String
argument_list|>
name|unsupportedOptionsInV2
init|=
name|Sets
operator|.
name|newHashSet
argument_list|(
literal|"-fix"
argument_list|,
literal|"-fixAssignments"
argument_list|,
literal|"-fixMeta"
argument_list|,
literal|"-fixHdfsHoles"
argument_list|,
literal|"-fixHdfsOrphans"
argument_list|,
literal|"-fixTableOrphans"
argument_list|,
literal|"-fixHdfsOverlaps"
argument_list|,
literal|"-sidelineBigOverlaps"
argument_list|,
literal|"-fixSplitParents"
argument_list|,
literal|"-removeParents"
argument_list|,
literal|"-fixEmptyMetaCells"
argument_list|,
literal|"-repair"
argument_list|,
literal|"-repairHoles"
argument_list|,
literal|"-maxOverlapsToSideline"
argument_list|,
literal|"-maxMerge"
argument_list|)
decl_stmt|;
comment|/***********    * Options    ***********/
specifier|private
specifier|static
name|boolean
name|details
init|=
literal|false
decl_stmt|;
comment|// do we display the full report
specifier|private
name|long
name|timelag
init|=
name|DEFAULT_TIME_LAG
decl_stmt|;
comment|// tables whose modtime is older
specifier|private
specifier|static
name|boolean
name|forceExclusive
init|=
literal|false
decl_stmt|;
comment|// only this hbck can modify HBase
specifier|private
name|boolean
name|fixAssignments
init|=
literal|false
decl_stmt|;
comment|// fix assignment errors?
specifier|private
name|boolean
name|fixMeta
init|=
literal|false
decl_stmt|;
comment|// fix meta errors?
specifier|private
name|boolean
name|checkHdfs
init|=
literal|true
decl_stmt|;
comment|// load and check fs consistency?
specifier|private
name|boolean
name|fixHdfsHoles
init|=
literal|false
decl_stmt|;
comment|// fix fs holes?
specifier|private
name|boolean
name|fixHdfsOverlaps
init|=
literal|false
decl_stmt|;
comment|// fix fs overlaps (risky)
specifier|private
name|boolean
name|fixHdfsOrphans
init|=
literal|false
decl_stmt|;
comment|// fix fs holes (missing .regioninfo)
specifier|private
name|boolean
name|fixTableOrphans
init|=
literal|false
decl_stmt|;
comment|// fix fs holes (missing .tableinfo)
specifier|private
name|boolean
name|fixVersionFile
init|=
literal|false
decl_stmt|;
comment|// fix missing hbase.version file in hdfs
specifier|private
name|boolean
name|fixSplitParents
init|=
literal|false
decl_stmt|;
comment|// fix lingering split parents
specifier|private
name|boolean
name|removeParents
init|=
literal|false
decl_stmt|;
comment|// remove split parents
specifier|private
name|boolean
name|fixReferenceFiles
init|=
literal|false
decl_stmt|;
comment|// fix lingering reference store file
specifier|private
name|boolean
name|fixHFileLinks
init|=
literal|false
decl_stmt|;
comment|// fix lingering HFileLinks
specifier|private
name|boolean
name|fixEmptyMetaCells
init|=
literal|false
decl_stmt|;
comment|// fix (remove) empty REGIONINFO_QUALIFIER rows
specifier|private
name|boolean
name|fixReplication
init|=
literal|false
decl_stmt|;
comment|// fix undeleted replication queues for removed peer
specifier|private
name|boolean
name|fixAny
init|=
literal|false
decl_stmt|;
comment|// Set to true if any of the fix is required.
comment|// limit checking/fixes to listed tables, if empty attempt to check/fix all
comment|// hbase:meta are always checked
specifier|private
name|Set
argument_list|<
name|TableName
argument_list|>
name|tablesIncluded
init|=
operator|new
name|HashSet
argument_list|<>
argument_list|()
decl_stmt|;
specifier|private
name|int
name|maxMerge
init|=
name|DEFAULT_MAX_MERGE
decl_stmt|;
comment|// maximum number of overlapping regions to merge
comment|// maximum number of overlapping regions to sideline
specifier|private
name|int
name|maxOverlapsToSideline
init|=
name|DEFAULT_OVERLAPS_TO_SIDELINE
decl_stmt|;
specifier|private
name|boolean
name|sidelineBigOverlaps
init|=
literal|false
decl_stmt|;
comment|// sideline overlaps with>maxMerge regions
specifier|private
name|Path
name|sidelineDir
init|=
literal|null
decl_stmt|;
specifier|private
name|boolean
name|rerun
init|=
literal|false
decl_stmt|;
comment|// if we tried to fix something, rerun hbck
specifier|private
specifier|static
name|boolean
name|summary
init|=
literal|false
decl_stmt|;
comment|// if we want to print less output
specifier|private
name|boolean
name|checkMetaOnly
init|=
literal|false
decl_stmt|;
specifier|private
name|boolean
name|checkRegionBoundaries
init|=
literal|false
decl_stmt|;
specifier|private
name|boolean
name|ignorePreCheckPermission
init|=
literal|false
decl_stmt|;
comment|// if pre-check permission
comment|/*********    * State    *********/
specifier|final
specifier|private
name|ErrorReporter
name|errors
decl_stmt|;
name|int
name|fixes
init|=
literal|0
decl_stmt|;
comment|/**    * This map contains the state of all hbck items.  It maps from encoded region    * name to HbckInfo structure.  The information contained in HbckInfo is used    * to detect and correct consistency (hdfs/meta/deployment) problems.    */
specifier|private
name|TreeMap
argument_list|<
name|String
argument_list|,
name|HbckInfo
argument_list|>
name|regionInfoMap
init|=
operator|new
name|TreeMap
argument_list|<>
argument_list|()
decl_stmt|;
comment|// Empty regioninfo qualifiers in hbase:meta
specifier|private
name|Set
argument_list|<
name|Result
argument_list|>
name|emptyRegionInfoQualifiers
init|=
operator|new
name|HashSet
argument_list|<>
argument_list|()
decl_stmt|;
comment|/**    * This map from Tablename -> TableInfo contains the structures necessary to    * detect table consistency problems (holes, dupes, overlaps).  It is sorted    * to prevent dupes.    *    * If tablesIncluded is empty, this map contains all tables.    * Otherwise, it contains only meta tables and tables in tablesIncluded,    * unless checkMetaOnly is specified, in which case, it contains only    * the meta table    */
specifier|private
name|SortedMap
argument_list|<
name|TableName
argument_list|,
name|TableInfo
argument_list|>
name|tablesInfo
init|=
operator|new
name|ConcurrentSkipListMap
argument_list|<>
argument_list|()
decl_stmt|;
comment|/**    * When initially looking at HDFS, we attempt to find any orphaned data.    */
specifier|private
name|List
argument_list|<
name|HbckInfo
argument_list|>
name|orphanHdfsDirs
init|=
name|Collections
operator|.
name|synchronizedList
argument_list|(
operator|new
name|ArrayList
argument_list|<
name|HbckInfo
argument_list|>
argument_list|()
argument_list|)
decl_stmt|;
specifier|private
name|Map
argument_list|<
name|TableName
argument_list|,
name|Set
argument_list|<
name|String
argument_list|>
argument_list|>
name|orphanTableDirs
init|=
operator|new
name|HashMap
argument_list|<>
argument_list|()
decl_stmt|;
specifier|private
name|Map
argument_list|<
name|TableName
argument_list|,
name|TableState
argument_list|>
name|tableStates
init|=
operator|new
name|HashMap
argument_list|<>
argument_list|()
decl_stmt|;
specifier|private
specifier|final
name|RetryCounterFactory
name|lockFileRetryCounterFactory
decl_stmt|;
specifier|private
specifier|final
name|RetryCounterFactory
name|createZNodeRetryCounterFactory
decl_stmt|;
specifier|private
name|Map
argument_list|<
name|TableName
argument_list|,
name|Set
argument_list|<
name|String
argument_list|>
argument_list|>
name|skippedRegions
init|=
operator|new
name|HashMap
argument_list|<>
argument_list|()
decl_stmt|;
specifier|private
name|ZKWatcher
name|zkw
init|=
literal|null
decl_stmt|;
specifier|private
name|String
name|hbckEphemeralNodePath
init|=
literal|null
decl_stmt|;
specifier|private
name|boolean
name|hbckZodeCreated
init|=
literal|false
decl_stmt|;
comment|/**    * Constructor    *    * @param conf Configuration object    * @throws MasterNotRunningException if the master is not running    * @throws ZooKeeperConnectionException if unable to connect to ZooKeeper    */
specifier|public
name|HBaseFsck
parameter_list|(
name|Configuration
name|conf
parameter_list|)
throws|throws
name|IOException
throws|,
name|ClassNotFoundException
block|{
name|this
argument_list|(
name|conf
argument_list|,
name|createThreadPool
argument_list|(
name|conf
argument_list|)
argument_list|)
expr_stmt|;
block|}
specifier|private
specifier|static
name|ExecutorService
name|createThreadPool
parameter_list|(
name|Configuration
name|conf
parameter_list|)
block|{
name|int
name|numThreads
init|=
name|conf
operator|.
name|getInt
argument_list|(
literal|"hbasefsck.numthreads"
argument_list|,
name|MAX_NUM_THREADS
argument_list|)
decl_stmt|;
return|return
operator|new
name|ScheduledThreadPoolExecutor
argument_list|(
name|numThreads
argument_list|,
name|Threads
operator|.
name|newDaemonThreadFactory
argument_list|(
literal|"hbasefsck"
argument_list|)
argument_list|)
return|;
block|}
comment|/**    * Constructor    *    * @param conf    *          Configuration object    * @throws MasterNotRunningException    *           if the master is not running    * @throws ZooKeeperConnectionException    *           if unable to connect to ZooKeeper    */
specifier|public
name|HBaseFsck
parameter_list|(
name|Configuration
name|conf
parameter_list|,
name|ExecutorService
name|exec
parameter_list|)
throws|throws
name|MasterNotRunningException
throws|,
name|ZooKeeperConnectionException
throws|,
name|IOException
throws|,
name|ClassNotFoundException
block|{
name|super
argument_list|(
name|conf
argument_list|)
expr_stmt|;
name|errors
operator|=
name|getErrorReporter
argument_list|(
name|getConf
argument_list|()
argument_list|)
expr_stmt|;
name|this
operator|.
name|executor
operator|=
name|exec
expr_stmt|;
name|lockFileRetryCounterFactory
operator|=
operator|new
name|RetryCounterFactory
argument_list|(
name|getConf
argument_list|()
operator|.
name|getInt
argument_list|(
literal|"hbase.hbck.lockfile.attempts"
argument_list|,
name|DEFAULT_MAX_LOCK_FILE_ATTEMPTS
argument_list|)
argument_list|,
name|getConf
argument_list|()
operator|.
name|getInt
argument_list|(
literal|"hbase.hbck.lockfile.attempt.sleep.interval"
argument_list|,
name|DEFAULT_LOCK_FILE_ATTEMPT_SLEEP_INTERVAL
argument_list|)
argument_list|,
name|getConf
argument_list|()
operator|.
name|getInt
argument_list|(
literal|"hbase.hbck.lockfile.attempt.maxsleeptime"
argument_list|,
name|DEFAULT_LOCK_FILE_ATTEMPT_MAX_SLEEP_TIME
argument_list|)
argument_list|)
expr_stmt|;
name|createZNodeRetryCounterFactory
operator|=
operator|new
name|RetryCounterFactory
argument_list|(
name|getConf
argument_list|()
operator|.
name|getInt
argument_list|(
literal|"hbase.hbck.createznode.attempts"
argument_list|,
name|DEFAULT_MAX_CREATE_ZNODE_ATTEMPTS
argument_list|)
argument_list|,
name|getConf
argument_list|()
operator|.
name|getInt
argument_list|(
literal|"hbase.hbck.createznode.attempt.sleep.interval"
argument_list|,
name|DEFAULT_CREATE_ZNODE_ATTEMPT_SLEEP_INTERVAL
argument_list|)
argument_list|,
name|getConf
argument_list|()
operator|.
name|getInt
argument_list|(
literal|"hbase.hbck.createznode.attempt.maxsleeptime"
argument_list|,
name|DEFAULT_CREATE_ZNODE_ATTEMPT_MAX_SLEEP_TIME
argument_list|)
argument_list|)
expr_stmt|;
name|zkw
operator|=
name|createZooKeeperWatcher
argument_list|()
expr_stmt|;
block|}
specifier|private
class|class
name|FileLockCallable
implements|implements
name|Callable
argument_list|<
name|FSDataOutputStream
argument_list|>
block|{
name|RetryCounter
name|retryCounter
decl_stmt|;
specifier|public
name|FileLockCallable
parameter_list|(
name|RetryCounter
name|retryCounter
parameter_list|)
block|{
name|this
operator|.
name|retryCounter
operator|=
name|retryCounter
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|FSDataOutputStream
name|call
parameter_list|()
throws|throws
name|IOException
block|{
try|try
block|{
name|FileSystem
name|fs
init|=
name|FSUtils
operator|.
name|getCurrentFileSystem
argument_list|(
name|getConf
argument_list|()
argument_list|)
decl_stmt|;
name|FsPermission
name|defaultPerms
init|=
name|FSUtils
operator|.
name|getFilePermissions
argument_list|(
name|fs
argument_list|,
name|getConf
argument_list|()
argument_list|,
name|HConstants
operator|.
name|DATA_FILE_UMASK_KEY
argument_list|)
decl_stmt|;
name|Path
name|tmpDir
init|=
operator|new
name|Path
argument_list|(
name|FSUtils
operator|.
name|getRootDir
argument_list|(
name|getConf
argument_list|()
argument_list|)
argument_list|,
name|HConstants
operator|.
name|HBASE_TEMP_DIRECTORY
argument_list|)
decl_stmt|;
name|fs
operator|.
name|mkdirs
argument_list|(
name|tmpDir
argument_list|)
expr_stmt|;
name|HBCK_LOCK_PATH
operator|=
operator|new
name|Path
argument_list|(
name|tmpDir
argument_list|,
name|HBCK_LOCK_FILE
argument_list|)
expr_stmt|;
specifier|final
name|FSDataOutputStream
name|out
init|=
name|createFileWithRetries
argument_list|(
name|fs
argument_list|,
name|HBCK_LOCK_PATH
argument_list|,
name|defaultPerms
argument_list|)
decl_stmt|;
name|out
operator|.
name|writeBytes
argument_list|(
name|InetAddress
operator|.
name|getLocalHost
argument_list|()
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
name|out
operator|.
name|flush
argument_list|()
expr_stmt|;
return|return
name|out
return|;
block|}
catch|catch
parameter_list|(
name|RemoteException
name|e
parameter_list|)
block|{
if|if
condition|(
name|AlreadyBeingCreatedException
operator|.
name|class
operator|.
name|getName
argument_list|()
operator|.
name|equals
argument_list|(
name|e
operator|.
name|getClassName
argument_list|()
argument_list|)
condition|)
block|{
return|return
literal|null
return|;
block|}
else|else
block|{
throw|throw
name|e
throw|;
block|}
block|}
block|}
specifier|private
name|FSDataOutputStream
name|createFileWithRetries
parameter_list|(
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Path
name|hbckLockFilePath
parameter_list|,
specifier|final
name|FsPermission
name|defaultPerms
parameter_list|)
throws|throws
name|IOException
block|{
name|IOException
name|exception
init|=
literal|null
decl_stmt|;
do|do
block|{
try|try
block|{
return|return
name|FSUtils
operator|.
name|create
argument_list|(
name|fs
argument_list|,
name|hbckLockFilePath
argument_list|,
name|defaultPerms
argument_list|,
literal|false
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ioe
parameter_list|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Failed to create lock file "
operator|+
name|hbckLockFilePath
operator|.
name|getName
argument_list|()
operator|+
literal|", try="
operator|+
operator|(
name|retryCounter
operator|.
name|getAttemptTimes
argument_list|()
operator|+
literal|1
operator|)
operator|+
literal|" of "
operator|+
name|retryCounter
operator|.
name|getMaxAttempts
argument_list|()
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Failed to create lock file "
operator|+
name|hbckLockFilePath
operator|.
name|getName
argument_list|()
argument_list|,
name|ioe
argument_list|)
expr_stmt|;
try|try
block|{
name|exception
operator|=
name|ioe
expr_stmt|;
name|retryCounter
operator|.
name|sleepUntilNextRetry
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|ie
parameter_list|)
block|{
throw|throw
operator|(
name|InterruptedIOException
operator|)
operator|new
name|InterruptedIOException
argument_list|(
literal|"Can't create lock file "
operator|+
name|hbckLockFilePath
operator|.
name|getName
argument_list|()
argument_list|)
operator|.
name|initCause
argument_list|(
name|ie
argument_list|)
throw|;
block|}
block|}
block|}
do|while
condition|(
name|retryCounter
operator|.
name|shouldRetry
argument_list|()
condition|)
do|;
throw|throw
name|exception
throw|;
block|}
block|}
comment|/**    * This method maintains a lock using a file. If the creation fails we return null    *    * @return FSDataOutputStream object corresponding to the newly opened lock file    * @throws IOException if IO failure occurs    */
specifier|private
name|FSDataOutputStream
name|checkAndMarkRunningHbck
parameter_list|()
throws|throws
name|IOException
block|{
name|RetryCounter
name|retryCounter
init|=
name|lockFileRetryCounterFactory
operator|.
name|create
argument_list|()
decl_stmt|;
name|FileLockCallable
name|callable
init|=
operator|new
name|FileLockCallable
argument_list|(
name|retryCounter
argument_list|)
decl_stmt|;
name|ExecutorService
name|executor
init|=
name|Executors
operator|.
name|newFixedThreadPool
argument_list|(
literal|1
argument_list|)
decl_stmt|;
name|FutureTask
argument_list|<
name|FSDataOutputStream
argument_list|>
name|futureTask
init|=
operator|new
name|FutureTask
argument_list|<>
argument_list|(
name|callable
argument_list|)
decl_stmt|;
name|executor
operator|.
name|execute
argument_list|(
name|futureTask
argument_list|)
expr_stmt|;
specifier|final
name|int
name|timeoutInSeconds
init|=
name|getConf
argument_list|()
operator|.
name|getInt
argument_list|(
literal|"hbase.hbck.lockfile.maxwaittime"
argument_list|,
name|DEFAULT_WAIT_FOR_LOCK_TIMEOUT
argument_list|)
decl_stmt|;
name|FSDataOutputStream
name|stream
init|=
literal|null
decl_stmt|;
try|try
block|{
name|stream
operator|=
name|futureTask
operator|.
name|get
argument_list|(
name|timeoutInSeconds
argument_list|,
name|TimeUnit
operator|.
name|SECONDS
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|ExecutionException
name|ee
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Encountered exception when opening lock file"
argument_list|,
name|ee
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|ie
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Interrupted when opening lock file"
argument_list|,
name|ie
argument_list|)
expr_stmt|;
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|interrupt
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|TimeoutException
name|exception
parameter_list|)
block|{
comment|// took too long to obtain lock
name|LOG
operator|.
name|warn
argument_list|(
literal|"Took more than "
operator|+
name|timeoutInSeconds
operator|+
literal|" seconds in obtaining lock"
argument_list|)
expr_stmt|;
name|futureTask
operator|.
name|cancel
argument_list|(
literal|true
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|executor
operator|.
name|shutdownNow
argument_list|()
expr_stmt|;
block|}
return|return
name|stream
return|;
block|}
specifier|private
name|void
name|unlockHbck
parameter_list|()
block|{
if|if
condition|(
name|isExclusive
argument_list|()
operator|&&
name|hbckLockCleanup
operator|.
name|compareAndSet
argument_list|(
literal|true
argument_list|,
literal|false
argument_list|)
condition|)
block|{
name|RetryCounter
name|retryCounter
init|=
name|lockFileRetryCounterFactory
operator|.
name|create
argument_list|()
decl_stmt|;
do|do
block|{
try|try
block|{
name|IOUtils
operator|.
name|closeQuietly
argument_list|(
name|hbckOutFd
argument_list|)
expr_stmt|;
name|FSUtils
operator|.
name|delete
argument_list|(
name|FSUtils
operator|.
name|getCurrentFileSystem
argument_list|(
name|getConf
argument_list|()
argument_list|)
argument_list|,
name|HBCK_LOCK_PATH
argument_list|,
literal|true
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Finishing hbck"
argument_list|)
expr_stmt|;
return|return;
block|}
catch|catch
parameter_list|(
name|IOException
name|ioe
parameter_list|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Failed to delete "
operator|+
name|HBCK_LOCK_PATH
operator|+
literal|", try="
operator|+
operator|(
name|retryCounter
operator|.
name|getAttemptTimes
argument_list|()
operator|+
literal|1
operator|)
operator|+
literal|" of "
operator|+
name|retryCounter
operator|.
name|getMaxAttempts
argument_list|()
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Failed to delete "
operator|+
name|HBCK_LOCK_PATH
argument_list|,
name|ioe
argument_list|)
expr_stmt|;
try|try
block|{
name|retryCounter
operator|.
name|sleepUntilNextRetry
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|ie
parameter_list|)
block|{
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|interrupt
argument_list|()
expr_stmt|;
name|LOG
operator|.
name|warn
argument_list|(
literal|"Interrupted while deleting lock file"
operator|+
name|HBCK_LOCK_PATH
argument_list|)
expr_stmt|;
return|return;
block|}
block|}
block|}
do|while
condition|(
name|retryCounter
operator|.
name|shouldRetry
argument_list|()
condition|)
do|;
block|}
block|}
comment|/**    * To repair region consistency, one must call connect() in order to repair    * online state.    */
specifier|public
name|void
name|connect
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|isExclusive
argument_list|()
condition|)
block|{
comment|// Grab the lock
name|hbckOutFd
operator|=
name|checkAndMarkRunningHbck
argument_list|()
expr_stmt|;
if|if
condition|(
name|hbckOutFd
operator|==
literal|null
condition|)
block|{
name|setRetCode
argument_list|(
operator|-
literal|1
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|error
argument_list|(
literal|"Another instance of hbck is fixing HBase, exiting this instance. "
operator|+
literal|"[If you are sure no other instance is running, delete the lock file "
operator|+
name|HBCK_LOCK_PATH
operator|+
literal|" and rerun the tool]"
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Duplicate hbck - Abort"
argument_list|)
throw|;
block|}
comment|// Make sure to cleanup the lock
name|hbckLockCleanup
operator|.
name|set
argument_list|(
literal|true
argument_list|)
expr_stmt|;
block|}
comment|// Add a shutdown hook to this thread, in case user tries to
comment|// kill the hbck with a ctrl-c, we want to cleanup the lock so that
comment|// it is available for further calls
name|Runtime
operator|.
name|getRuntime
argument_list|()
operator|.
name|addShutdownHook
argument_list|(
operator|new
name|Thread
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|void
name|run
parameter_list|()
block|{
name|IOUtils
operator|.
name|closeQuietly
argument_list|(
name|HBaseFsck
operator|.
name|this
argument_list|)
expr_stmt|;
name|cleanupHbckZnode
argument_list|()
expr_stmt|;
name|unlockHbck
argument_list|()
expr_stmt|;
block|}
block|}
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Launching hbck"
argument_list|)
expr_stmt|;
name|connection
operator|=
operator|(
name|ClusterConnection
operator|)
name|ConnectionFactory
operator|.
name|createConnection
argument_list|(
name|getConf
argument_list|()
argument_list|)
expr_stmt|;
name|admin
operator|=
name|connection
operator|.
name|getAdmin
argument_list|()
expr_stmt|;
name|meta
operator|=
name|connection
operator|.
name|getTable
argument_list|(
name|TableName
operator|.
name|META_TABLE_NAME
argument_list|)
expr_stmt|;
name|status
operator|=
name|admin
operator|.
name|getClusterMetrics
argument_list|(
name|EnumSet
operator|.
name|of
argument_list|(
name|Option
operator|.
name|LIVE_SERVERS
argument_list|,
name|Option
operator|.
name|DEAD_SERVERS
argument_list|,
name|Option
operator|.
name|MASTER
argument_list|,
name|Option
operator|.
name|BACKUP_MASTERS
argument_list|,
name|Option
operator|.
name|REGIONS_IN_TRANSITION
argument_list|,
name|Option
operator|.
name|HBASE_VERSION
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|/**    * Get deployed regions according to the region servers.    */
specifier|private
name|void
name|loadDeployedRegions
parameter_list|()
throws|throws
name|IOException
throws|,
name|InterruptedException
block|{
comment|// From the master, get a list of all known live region servers
name|Collection
argument_list|<
name|ServerName
argument_list|>
name|regionServers
init|=
name|status
operator|.
name|getLiveServerMetrics
argument_list|()
operator|.
name|keySet
argument_list|()
decl_stmt|;
name|errors
operator|.
name|print
argument_list|(
literal|"Number of live region servers: "
operator|+
name|regionServers
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|details
condition|)
block|{
for|for
control|(
name|ServerName
name|rsinfo
range|:
name|regionServers
control|)
block|{
name|errors
operator|.
name|print
argument_list|(
literal|"  "
operator|+
name|rsinfo
operator|.
name|getServerName
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
comment|// From the master, get a list of all dead region servers
name|Collection
argument_list|<
name|ServerName
argument_list|>
name|deadRegionServers
init|=
name|status
operator|.
name|getDeadServerNames
argument_list|()
decl_stmt|;
name|errors
operator|.
name|print
argument_list|(
literal|"Number of dead region servers: "
operator|+
name|deadRegionServers
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|details
condition|)
block|{
for|for
control|(
name|ServerName
name|name
range|:
name|deadRegionServers
control|)
block|{
name|errors
operator|.
name|print
argument_list|(
literal|"  "
operator|+
name|name
argument_list|)
expr_stmt|;
block|}
block|}
comment|// Print the current master name and state
name|errors
operator|.
name|print
argument_list|(
literal|"Master: "
operator|+
name|status
operator|.
name|getMasterName
argument_list|()
argument_list|)
expr_stmt|;
comment|// Print the list of all backup masters
name|Collection
argument_list|<
name|ServerName
argument_list|>
name|backupMasters
init|=
name|status
operator|.
name|getBackupMasterNames
argument_list|()
decl_stmt|;
name|errors
operator|.
name|print
argument_list|(
literal|"Number of backup masters: "
operator|+
name|backupMasters
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|details
condition|)
block|{
for|for
control|(
name|ServerName
name|name
range|:
name|backupMasters
control|)
block|{
name|errors
operator|.
name|print
argument_list|(
literal|"  "
operator|+
name|name
argument_list|)
expr_stmt|;
block|}
block|}
name|errors
operator|.
name|print
argument_list|(
literal|"Average load: "
operator|+
name|status
operator|.
name|getAverageLoad
argument_list|()
argument_list|)
expr_stmt|;
name|errors
operator|.
name|print
argument_list|(
literal|"Number of requests: "
operator|+
name|status
operator|.
name|getRequestCount
argument_list|()
argument_list|)
expr_stmt|;
name|errors
operator|.
name|print
argument_list|(
literal|"Number of regions: "
operator|+
name|status
operator|.
name|getRegionCount
argument_list|()
argument_list|)
expr_stmt|;
name|List
argument_list|<
name|RegionState
argument_list|>
name|rits
init|=
name|status
operator|.
name|getRegionStatesInTransition
argument_list|()
decl_stmt|;
name|errors
operator|.
name|print
argument_list|(
literal|"Number of regions in transition: "
operator|+
name|rits
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|details
condition|)
block|{
for|for
control|(
name|RegionState
name|state
range|:
name|rits
control|)
block|{
name|errors
operator|.
name|print
argument_list|(
literal|"  "
operator|+
name|state
operator|.
name|toDescriptiveString
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
comment|// Determine what's deployed
name|processRegionServers
argument_list|(
name|regionServers
argument_list|)
expr_stmt|;
block|}
comment|/**    * Clear the current state of hbck.    */
specifier|private
name|void
name|clearState
parameter_list|()
block|{
comment|// Make sure regionInfo is empty before starting
name|fixes
operator|=
literal|0
expr_stmt|;
name|regionInfoMap
operator|.
name|clear
argument_list|()
expr_stmt|;
name|emptyRegionInfoQualifiers
operator|.
name|clear
argument_list|()
expr_stmt|;
name|tableStates
operator|.
name|clear
argument_list|()
expr_stmt|;
name|errors
operator|.
name|clear
argument_list|()
expr_stmt|;
name|tablesInfo
operator|.
name|clear
argument_list|()
expr_stmt|;
name|orphanHdfsDirs
operator|.
name|clear
argument_list|()
expr_stmt|;
name|skippedRegions
operator|.
name|clear
argument_list|()
expr_stmt|;
block|}
comment|/**    * This repair method analyzes hbase data in hdfs and repairs it to satisfy    * the table integrity rules.  HBase doesn't need to be online for this    * operation to work.    */
specifier|public
name|void
name|offlineHdfsIntegrityRepair
parameter_list|()
throws|throws
name|IOException
throws|,
name|InterruptedException
block|{
comment|// Initial pass to fix orphans.
if|if
condition|(
name|shouldCheckHdfs
argument_list|()
operator|&&
operator|(
name|shouldFixHdfsOrphans
argument_list|()
operator|||
name|shouldFixHdfsHoles
argument_list|()
operator|||
name|shouldFixHdfsOverlaps
argument_list|()
operator|||
name|shouldFixTableOrphans
argument_list|()
operator|)
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Loading regioninfos HDFS"
argument_list|)
expr_stmt|;
comment|// if nothing is happening this should always complete in two iterations.
name|int
name|maxIterations
init|=
name|getConf
argument_list|()
operator|.
name|getInt
argument_list|(
literal|"hbase.hbck.integrityrepair.iterations.max"
argument_list|,
literal|3
argument_list|)
decl_stmt|;
name|int
name|curIter
init|=
literal|0
decl_stmt|;
do|do
block|{
name|clearState
argument_list|()
expr_stmt|;
comment|// clears hbck state and reset fixes to 0 and.
comment|// repair what's on HDFS
name|restoreHdfsIntegrity
argument_list|()
expr_stmt|;
name|curIter
operator|++
expr_stmt|;
comment|// limit the number of iterations.
block|}
do|while
condition|(
name|fixes
operator|>
literal|0
operator|&&
name|curIter
operator|<=
name|maxIterations
condition|)
do|;
comment|// Repairs should be done in the first iteration and verification in the second.
comment|// If there are more than 2 passes, something funny has happened.
if|if
condition|(
name|curIter
operator|>
literal|2
condition|)
block|{
if|if
condition|(
name|curIter
operator|==
name|maxIterations
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Exiting integrity repairs after max "
operator|+
name|curIter
operator|+
literal|" iterations. "
operator|+
literal|"Tables integrity may not be fully repaired!"
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Successfully exiting integrity repairs after "
operator|+
name|curIter
operator|+
literal|" iterations"
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
comment|/**    * This repair method requires the cluster to be online since it contacts    * region servers and the masters.  It makes each region's state in HDFS, in    * hbase:meta, and deployments consistent.    *    * @return If&gt; 0 , number of errors detected, if&lt; 0 there was an unrecoverable    *     error.  If 0, we have a clean hbase.    */
specifier|public
name|int
name|onlineConsistencyRepair
parameter_list|()
throws|throws
name|IOException
throws|,
name|KeeperException
throws|,
name|InterruptedException
block|{
comment|// get regions according to what is online on each RegionServer
name|loadDeployedRegions
argument_list|()
expr_stmt|;
comment|// check whether hbase:meta is deployed and online
name|recordMetaRegion
argument_list|()
expr_stmt|;
comment|// Check if hbase:meta is found only once and in the right place
if|if
condition|(
operator|!
name|checkMetaRegion
argument_list|()
condition|)
block|{
name|String
name|errorMsg
init|=
literal|"hbase:meta table is not consistent. "
decl_stmt|;
if|if
condition|(
name|shouldFixAssignments
argument_list|()
condition|)
block|{
name|errorMsg
operator|+=
literal|"HBCK will try fixing it. Rerun once hbase:meta is back to consistent state."
expr_stmt|;
block|}
else|else
block|{
name|errorMsg
operator|+=
literal|"Run HBCK with proper fix options to fix hbase:meta inconsistency."
expr_stmt|;
block|}
name|errors
operator|.
name|reportError
argument_list|(
name|errorMsg
operator|+
literal|" Exiting..."
argument_list|)
expr_stmt|;
return|return
operator|-
literal|2
return|;
block|}
comment|// Not going with further consistency check for tables when hbase:meta itself is not consistent.
name|LOG
operator|.
name|info
argument_list|(
literal|"Loading regionsinfo from the hbase:meta table"
argument_list|)
expr_stmt|;
name|boolean
name|success
init|=
name|loadMetaEntries
argument_list|()
decl_stmt|;
if|if
condition|(
operator|!
name|success
condition|)
return|return
operator|-
literal|1
return|;
comment|// Empty cells in hbase:meta?
name|reportEmptyMetaCells
argument_list|()
expr_stmt|;
comment|// Check if we have to cleanup empty REGIONINFO_QUALIFIER rows from hbase:meta
if|if
condition|(
name|shouldFixEmptyMetaCells
argument_list|()
condition|)
block|{
name|fixEmptyMetaCells
argument_list|()
expr_stmt|;
block|}
comment|// get a list of all tables that have not changed recently.
if|if
condition|(
operator|!
name|checkMetaOnly
condition|)
block|{
name|reportTablesInFlux
argument_list|()
expr_stmt|;
block|}
comment|// Get disabled tables states
name|loadTableStates
argument_list|()
expr_stmt|;
comment|// load regiondirs and regioninfos from HDFS
if|if
condition|(
name|shouldCheckHdfs
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Loading region directories from HDFS"
argument_list|)
expr_stmt|;
name|loadHdfsRegionDirs
argument_list|()
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Loading region information from HDFS"
argument_list|)
expr_stmt|;
name|loadHdfsRegionInfos
argument_list|()
expr_stmt|;
block|}
comment|// fix the orphan tables
name|fixOrphanTables
argument_list|()
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Checking and fixing region consistency"
argument_list|)
expr_stmt|;
comment|// Check and fix consistency
name|checkAndFixConsistency
argument_list|()
expr_stmt|;
comment|// Check integrity (does not fix)
name|checkIntegrity
argument_list|()
expr_stmt|;
return|return
name|errors
operator|.
name|getErrorList
argument_list|()
operator|.
name|size
argument_list|()
return|;
block|}
comment|/**    * This method maintains an ephemeral znode. If the creation fails we return false or throw    * exception    *    * @return true if creating znode succeeds; false otherwise    * @throws IOException if IO failure occurs    */
specifier|private
name|boolean
name|setMasterInMaintenanceMode
parameter_list|()
throws|throws
name|IOException
block|{
name|RetryCounter
name|retryCounter
init|=
name|createZNodeRetryCounterFactory
operator|.
name|create
argument_list|()
decl_stmt|;
name|hbckEphemeralNodePath
operator|=
name|ZNodePaths
operator|.
name|joinZNode
argument_list|(
name|zkw
operator|.
name|znodePaths
operator|.
name|masterMaintZNode
argument_list|,
literal|"hbck-"
operator|+
name|Long
operator|.
name|toString
argument_list|(
name|EnvironmentEdgeManager
operator|.
name|currentTime
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
do|do
block|{
try|try
block|{
name|hbckZodeCreated
operator|=
name|ZKUtil
operator|.
name|createEphemeralNodeAndWatch
argument_list|(
name|zkw
argument_list|,
name|hbckEphemeralNodePath
argument_list|,
literal|null
argument_list|)
expr_stmt|;
if|if
condition|(
name|hbckZodeCreated
condition|)
block|{
break|break;
block|}
block|}
catch|catch
parameter_list|(
name|KeeperException
name|e
parameter_list|)
block|{
if|if
condition|(
name|retryCounter
operator|.
name|getAttemptTimes
argument_list|()
operator|>=
name|retryCounter
operator|.
name|getMaxAttempts
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Can't create znode "
operator|+
name|hbckEphemeralNodePath
argument_list|,
name|e
argument_list|)
throw|;
block|}
comment|// fall through and retry
block|}
name|LOG
operator|.
name|warn
argument_list|(
literal|"Fail to create znode "
operator|+
name|hbckEphemeralNodePath
operator|+
literal|", try="
operator|+
operator|(
name|retryCounter
operator|.
name|getAttemptTimes
argument_list|()
operator|+
literal|1
operator|)
operator|+
literal|" of "
operator|+
name|retryCounter
operator|.
name|getMaxAttempts
argument_list|()
argument_list|)
expr_stmt|;
try|try
block|{
name|retryCounter
operator|.
name|sleepUntilNextRetry
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|ie
parameter_list|)
block|{
throw|throw
operator|(
name|InterruptedIOException
operator|)
operator|new
name|InterruptedIOException
argument_list|(
literal|"Can't create znode "
operator|+
name|hbckEphemeralNodePath
argument_list|)
operator|.
name|initCause
argument_list|(
name|ie
argument_list|)
throw|;
block|}
block|}
do|while
condition|(
name|retryCounter
operator|.
name|shouldRetry
argument_list|()
condition|)
do|;
return|return
name|hbckZodeCreated
return|;
block|}
specifier|private
name|void
name|cleanupHbckZnode
parameter_list|()
block|{
try|try
block|{
if|if
condition|(
name|zkw
operator|!=
literal|null
operator|&&
name|hbckZodeCreated
condition|)
block|{
name|ZKUtil
operator|.
name|deleteNode
argument_list|(
name|zkw
argument_list|,
name|hbckEphemeralNodePath
argument_list|)
expr_stmt|;
name|hbckZodeCreated
operator|=
literal|false
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|KeeperException
name|e
parameter_list|)
block|{
comment|// Ignore
if|if
condition|(
operator|!
name|e
operator|.
name|code
argument_list|()
operator|.
name|equals
argument_list|(
name|KeeperException
operator|.
name|Code
operator|.
name|NONODE
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Delete HBCK znode "
operator|+
name|hbckEphemeralNodePath
operator|+
literal|" failed "
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|/**    * Contacts the master and prints out cluster-wide information    * @return 0 on success, non-zero on failure    */
specifier|public
name|int
name|onlineHbck
parameter_list|()
throws|throws
name|IOException
throws|,
name|KeeperException
throws|,
name|InterruptedException
throws|,
name|ReplicationException
block|{
comment|// print hbase server version
name|errors
operator|.
name|print
argument_list|(
literal|"Version: "
operator|+
name|status
operator|.
name|getHBaseVersion
argument_list|()
argument_list|)
expr_stmt|;
comment|// Clean start
name|clearState
argument_list|()
expr_stmt|;
comment|// Do offline check and repair first
name|offlineHdfsIntegrityRepair
argument_list|()
expr_stmt|;
name|offlineReferenceFileRepair
argument_list|()
expr_stmt|;
name|offlineHLinkFileRepair
argument_list|()
expr_stmt|;
comment|// If Master runs maintenance tasks (such as balancer, catalog janitor, etc) during online
comment|// hbck, it is likely that hbck would be misled and report transient errors.  Therefore, it
comment|// is better to set Master into maintenance mode during online hbck.
comment|//
if|if
condition|(
operator|!
name|setMasterInMaintenanceMode
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"HBCK is running while master is not in maintenance mode, you might see transient "
operator|+
literal|"error.  Please run HBCK multiple times to reduce the chance of transient error."
argument_list|)
expr_stmt|;
block|}
name|onlineConsistencyRepair
argument_list|()
expr_stmt|;
if|if
condition|(
name|checkRegionBoundaries
condition|)
block|{
name|checkRegionBoundaries
argument_list|()
expr_stmt|;
block|}
name|checkAndFixReplication
argument_list|()
expr_stmt|;
comment|// Remove the hbck znode
name|cleanupHbckZnode
argument_list|()
expr_stmt|;
comment|// Remove the hbck lock
name|unlockHbck
argument_list|()
expr_stmt|;
comment|// Print table summary
name|printTableSummary
argument_list|(
name|tablesInfo
argument_list|)
expr_stmt|;
return|return
name|errors
operator|.
name|summarize
argument_list|()
return|;
block|}
specifier|public
specifier|static
name|byte
index|[]
name|keyOnly
parameter_list|(
name|byte
index|[]
name|b
parameter_list|)
block|{
if|if
condition|(
name|b
operator|==
literal|null
condition|)
return|return
name|b
return|;
name|int
name|rowlength
init|=
name|Bytes
operator|.
name|toShort
argument_list|(
name|b
argument_list|,
literal|0
argument_list|)
decl_stmt|;
name|byte
index|[]
name|result
init|=
operator|new
name|byte
index|[
name|rowlength
index|]
decl_stmt|;
name|System
operator|.
name|arraycopy
argument_list|(
name|b
argument_list|,
name|Bytes
operator|.
name|SIZEOF_SHORT
argument_list|,
name|result
argument_list|,
literal|0
argument_list|,
name|rowlength
argument_list|)
expr_stmt|;
return|return
name|result
return|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|close
parameter_list|()
throws|throws
name|IOException
block|{
try|try
block|{
name|cleanupHbckZnode
argument_list|()
expr_stmt|;
name|unlockHbck
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|io
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
name|io
operator|.
name|toString
argument_list|()
argument_list|,
name|io
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
if|if
condition|(
name|zkw
operator|!=
literal|null
condition|)
block|{
name|zkw
operator|.
name|close
argument_list|()
expr_stmt|;
name|zkw
operator|=
literal|null
expr_stmt|;
block|}
name|IOUtils
operator|.
name|closeQuietly
argument_list|(
name|admin
argument_list|)
expr_stmt|;
name|IOUtils
operator|.
name|closeQuietly
argument_list|(
name|meta
argument_list|)
expr_stmt|;
name|IOUtils
operator|.
name|closeQuietly
argument_list|(
name|connection
argument_list|)
expr_stmt|;
block|}
block|}
specifier|private
specifier|static
class|class
name|RegionBoundariesInformation
block|{
specifier|public
name|byte
index|[]
name|regionName
decl_stmt|;
specifier|public
name|byte
index|[]
name|metaFirstKey
decl_stmt|;
specifier|public
name|byte
index|[]
name|metaLastKey
decl_stmt|;
specifier|public
name|byte
index|[]
name|storesFirstKey
decl_stmt|;
specifier|public
name|byte
index|[]
name|storesLastKey
decl_stmt|;
annotation|@
name|Override
specifier|public
name|String
name|toString
parameter_list|()
block|{
return|return
literal|"regionName="
operator|+
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|regionName
argument_list|)
operator|+
literal|"\nmetaFirstKey="
operator|+
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|metaFirstKey
argument_list|)
operator|+
literal|"\nmetaLastKey="
operator|+
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|metaLastKey
argument_list|)
operator|+
literal|"\nstoresFirstKey="
operator|+
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|storesFirstKey
argument_list|)
operator|+
literal|"\nstoresLastKey="
operator|+
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|storesLastKey
argument_list|)
return|;
block|}
block|}
specifier|public
name|void
name|checkRegionBoundaries
parameter_list|()
block|{
try|try
block|{
name|ByteArrayComparator
name|comparator
init|=
operator|new
name|ByteArrayComparator
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|RegionInfo
argument_list|>
name|regions
init|=
name|MetaTableAccessor
operator|.
name|getAllRegions
argument_list|(
name|connection
argument_list|,
literal|true
argument_list|)
decl_stmt|;
specifier|final
name|RegionBoundariesInformation
name|currentRegionBoundariesInformation
init|=
operator|new
name|RegionBoundariesInformation
argument_list|()
decl_stmt|;
name|Path
name|hbaseRoot
init|=
name|FSUtils
operator|.
name|getRootDir
argument_list|(
name|getConf
argument_list|()
argument_list|)
decl_stmt|;
for|for
control|(
name|RegionInfo
name|regionInfo
range|:
name|regions
control|)
block|{
name|Path
name|tableDir
init|=
name|FSUtils
operator|.
name|getTableDir
argument_list|(
name|hbaseRoot
argument_list|,
name|regionInfo
operator|.
name|getTable
argument_list|()
argument_list|)
decl_stmt|;
name|currentRegionBoundariesInformation
operator|.
name|regionName
operator|=
name|regionInfo
operator|.
name|getRegionName
argument_list|()
expr_stmt|;
comment|// For each region, get the start and stop key from the META and compare them to the
comment|// same information from the Stores.
name|Path
name|path
init|=
operator|new
name|Path
argument_list|(
name|tableDir
argument_list|,
name|regionInfo
operator|.
name|getEncodedName
argument_list|()
argument_list|)
decl_stmt|;
name|FileSystem
name|fs
init|=
name|path
operator|.
name|getFileSystem
argument_list|(
name|getConf
argument_list|()
argument_list|)
decl_stmt|;
name|FileStatus
index|[]
name|files
init|=
name|fs
operator|.
name|listStatus
argument_list|(
name|path
argument_list|)
decl_stmt|;
comment|// For all the column families in this region...
name|byte
index|[]
name|storeFirstKey
init|=
literal|null
decl_stmt|;
name|byte
index|[]
name|storeLastKey
init|=
literal|null
decl_stmt|;
for|for
control|(
name|FileStatus
name|file
range|:
name|files
control|)
block|{
name|String
name|fileName
init|=
name|file
operator|.
name|getPath
argument_list|()
operator|.
name|toString
argument_list|()
decl_stmt|;
name|fileName
operator|=
name|fileName
operator|.
name|substring
argument_list|(
name|fileName
operator|.
name|lastIndexOf
argument_list|(
literal|"/"
argument_list|)
operator|+
literal|1
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|fileName
operator|.
name|startsWith
argument_list|(
literal|"."
argument_list|)
operator|&&
operator|!
name|fileName
operator|.
name|endsWith
argument_list|(
literal|"recovered.edits"
argument_list|)
condition|)
block|{
name|FileStatus
index|[]
name|storeFiles
init|=
name|fs
operator|.
name|listStatus
argument_list|(
name|file
operator|.
name|getPath
argument_list|()
argument_list|)
decl_stmt|;
comment|// For all the stores in this column family.
for|for
control|(
name|FileStatus
name|storeFile
range|:
name|storeFiles
control|)
block|{
name|HFile
operator|.
name|Reader
name|reader
init|=
name|HFile
operator|.
name|createReader
argument_list|(
name|fs
argument_list|,
name|storeFile
operator|.
name|getPath
argument_list|()
argument_list|,
operator|new
name|CacheConfig
argument_list|(
name|getConf
argument_list|()
argument_list|)
argument_list|,
literal|true
argument_list|,
name|getConf
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
operator|(
name|reader
operator|.
name|getFirstKey
argument_list|()
operator|!=
literal|null
operator|)
operator|&&
operator|(
operator|(
name|storeFirstKey
operator|==
literal|null
operator|)
operator|||
operator|(
name|comparator
operator|.
name|compare
argument_list|(
name|storeFirstKey
argument_list|,
operator|(
operator|(
name|KeyValue
operator|.
name|KeyOnlyKeyValue
operator|)
name|reader
operator|.
name|getFirstKey
argument_list|()
operator|.
name|get
argument_list|()
operator|)
operator|.
name|getKey
argument_list|()
argument_list|)
operator|>
literal|0
operator|)
operator|)
condition|)
block|{
name|storeFirstKey
operator|=
operator|(
operator|(
name|KeyValue
operator|.
name|KeyOnlyKeyValue
operator|)
name|reader
operator|.
name|getFirstKey
argument_list|()
operator|.
name|get
argument_list|()
operator|)
operator|.
name|getKey
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
operator|(
name|reader
operator|.
name|getLastKey
argument_list|()
operator|!=
literal|null
operator|)
operator|&&
operator|(
operator|(
name|storeLastKey
operator|==
literal|null
operator|)
operator|||
operator|(
name|comparator
operator|.
name|compare
argument_list|(
name|storeLastKey
argument_list|,
operator|(
operator|(
name|KeyValue
operator|.
name|KeyOnlyKeyValue
operator|)
name|reader
operator|.
name|getLastKey
argument_list|()
operator|.
name|get
argument_list|()
operator|)
operator|.
name|getKey
argument_list|()
argument_list|)
operator|)
operator|<
literal|0
operator|)
condition|)
block|{
name|storeLastKey
operator|=
operator|(
operator|(
name|KeyValue
operator|.
name|KeyOnlyKeyValue
operator|)
name|reader
operator|.
name|getLastKey
argument_list|()
operator|.
name|get
argument_list|()
operator|)
operator|.
name|getKey
argument_list|()
expr_stmt|;
block|}
name|reader
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
block|}
block|}
name|currentRegionBoundariesInformation
operator|.
name|metaFirstKey
operator|=
name|regionInfo
operator|.
name|getStartKey
argument_list|()
expr_stmt|;
name|currentRegionBoundariesInformation
operator|.
name|metaLastKey
operator|=
name|regionInfo
operator|.
name|getEndKey
argument_list|()
expr_stmt|;
name|currentRegionBoundariesInformation
operator|.
name|storesFirstKey
operator|=
name|keyOnly
argument_list|(
name|storeFirstKey
argument_list|)
expr_stmt|;
name|currentRegionBoundariesInformation
operator|.
name|storesLastKey
operator|=
name|keyOnly
argument_list|(
name|storeLastKey
argument_list|)
expr_stmt|;
if|if
condition|(
name|currentRegionBoundariesInformation
operator|.
name|metaFirstKey
operator|.
name|length
operator|==
literal|0
condition|)
name|currentRegionBoundariesInformation
operator|.
name|metaFirstKey
operator|=
literal|null
expr_stmt|;
if|if
condition|(
name|currentRegionBoundariesInformation
operator|.
name|metaLastKey
operator|.
name|length
operator|==
literal|0
condition|)
name|currentRegionBoundariesInformation
operator|.
name|metaLastKey
operator|=
literal|null
expr_stmt|;
comment|// For a region to be correct, we need the META start key to be smaller or equal to the
comment|// smallest start key from all the stores, and the start key from the next META entry to
comment|// be bigger than the last key from all the current stores. First region start key is null;
comment|// Last region end key is null; some regions can be empty and not have any store.
name|boolean
name|valid
init|=
literal|true
decl_stmt|;
comment|// Checking start key.
if|if
condition|(
operator|(
name|currentRegionBoundariesInformation
operator|.
name|storesFirstKey
operator|!=
literal|null
operator|)
operator|&&
operator|(
name|currentRegionBoundariesInformation
operator|.
name|metaFirstKey
operator|!=
literal|null
operator|)
condition|)
block|{
name|valid
operator|=
name|valid
operator|&&
name|comparator
operator|.
name|compare
argument_list|(
name|currentRegionBoundariesInformation
operator|.
name|storesFirstKey
argument_list|,
name|currentRegionBoundariesInformation
operator|.
name|metaFirstKey
argument_list|)
operator|>=
literal|0
expr_stmt|;
block|}
comment|// Checking stop key.
if|if
condition|(
operator|(
name|currentRegionBoundariesInformation
operator|.
name|storesLastKey
operator|!=
literal|null
operator|)
operator|&&
operator|(
name|currentRegionBoundariesInformation
operator|.
name|metaLastKey
operator|!=
literal|null
operator|)
condition|)
block|{
name|valid
operator|=
name|valid
operator|&&
name|comparator
operator|.
name|compare
argument_list|(
name|currentRegionBoundariesInformation
operator|.
name|storesLastKey
argument_list|,
name|currentRegionBoundariesInformation
operator|.
name|metaLastKey
argument_list|)
operator|<
literal|0
expr_stmt|;
block|}
if|if
condition|(
operator|!
name|valid
condition|)
block|{
name|errors
operator|.
name|reportError
argument_list|(
name|ERROR_CODE
operator|.
name|BOUNDARIES_ERROR
argument_list|,
literal|"Found issues with regions boundaries"
argument_list|,
name|tablesInfo
operator|.
name|get
argument_list|(
name|regionInfo
operator|.
name|getTable
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|warn
argument_list|(
literal|"Region's boundaries not aligned between stores and META for:"
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|warn
argument_list|(
name|Objects
operator|.
name|toString
argument_list|(
name|currentRegionBoundariesInformation
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|e
operator|.
name|toString
argument_list|()
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Iterates through the list of all orphan/invalid regiondirs.    */
specifier|private
name|void
name|adoptHdfsOrphans
parameter_list|(
name|Collection
argument_list|<
name|HbckInfo
argument_list|>
name|orphanHdfsDirs
parameter_list|)
throws|throws
name|IOException
block|{
for|for
control|(
name|HbckInfo
name|hi
range|:
name|orphanHdfsDirs
control|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Attempting to handle orphan hdfs dir: "
operator|+
name|hi
operator|.
name|getHdfsRegionDir
argument_list|()
argument_list|)
expr_stmt|;
name|adoptHdfsOrphan
argument_list|(
name|hi
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Orphaned regions are regions without a .regioninfo file in them.  We "adopt"    * these orphans by creating a new region, and moving the column families,    * recovered edits, WALs, into the new region dir.  We determine the region    * startkey and endkeys by looking at all of the hfiles inside the column    * families to identify the min and max keys. The resulting region will    * likely violate table integrity but will be dealt with by merging    * overlapping regions.    */
annotation|@
name|SuppressWarnings
argument_list|(
literal|"deprecation"
argument_list|)
specifier|private
name|void
name|adoptHdfsOrphan
parameter_list|(
name|HbckInfo
name|hi
parameter_list|)
throws|throws
name|IOException
block|{
name|Path
name|p
init|=
name|hi
operator|.
name|getHdfsRegionDir
argument_list|()
decl_stmt|;
name|FileSystem
name|fs
init|=
name|p
operator|.
name|getFileSystem
argument_list|(
name|getConf
argument_list|()
argument_list|)
decl_stmt|;
name|FileStatus
index|[]
name|dirs
init|=
name|fs
operator|.
name|listStatus
argument_list|(
name|p
argument_list|)
decl_stmt|;
if|if
condition|(
name|dirs
operator|==
literal|null
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Attempt to adopt orphan hdfs region skipped because no files present in "
operator|+
name|p
operator|+
literal|". This dir could probably be deleted."
argument_list|)
expr_stmt|;
return|return ;
block|}
name|TableName
name|tableName
init|=
name|hi
operator|.
name|getTableName
argument_list|()
decl_stmt|;
name|TableInfo
name|tableInfo
init|=
name|tablesInfo
operator|.
name|get
argument_list|(
name|tableName
argument_list|)
decl_stmt|;
name|Preconditions
operator|.
name|checkNotNull
argument_list|(
name|tableInfo
argument_list|,
literal|"Table '"
operator|+
name|tableName
operator|+
literal|"' not present!"
argument_list|)
expr_stmt|;
name|TableDescriptor
name|template
init|=
name|tableInfo
operator|.
name|getHTD
argument_list|()
decl_stmt|;
comment|// find min and max key values
name|Pair
argument_list|<
name|byte
index|[]
argument_list|,
name|byte
index|[]
argument_list|>
name|orphanRegionRange
init|=
literal|null
decl_stmt|;
for|for
control|(
name|FileStatus
name|cf
range|:
name|dirs
control|)
block|{
name|String
name|cfName
init|=
name|cf
operator|.
name|getPath
argument_list|()
operator|.
name|getName
argument_list|()
decl_stmt|;
comment|// TODO Figure out what the special dirs are
if|if
condition|(
name|cfName
operator|.
name|startsWith
argument_list|(
literal|"."
argument_list|)
operator|||
name|cfName
operator|.
name|equals
argument_list|(
name|HConstants
operator|.
name|SPLIT_LOGDIR_NAME
argument_list|)
condition|)
continue|continue;
name|FileStatus
index|[]
name|hfiles
init|=
name|fs
operator|.
name|listStatus
argument_list|(
name|cf
operator|.
name|getPath
argument_list|()
argument_list|)
decl_stmt|;
for|for
control|(
name|FileStatus
name|hfile
range|:
name|hfiles
control|)
block|{
name|byte
index|[]
name|start
decl_stmt|,
name|end
decl_stmt|;
name|HFile
operator|.
name|Reader
name|hf
init|=
literal|null
decl_stmt|;
try|try
block|{
name|CacheConfig
name|cacheConf
init|=
operator|new
name|CacheConfig
argument_list|(
name|getConf
argument_list|()
argument_list|)
decl_stmt|;
name|hf
operator|=
name|HFile
operator|.
name|createReader
argument_list|(
name|fs
argument_list|,
name|hfile
operator|.
name|getPath
argument_list|()
argument_list|,
name|cacheConf
argument_list|,
literal|true
argument_list|,
name|getConf
argument_list|()
argument_list|)
expr_stmt|;
name|hf
operator|.
name|loadFileInfo
argument_list|()
expr_stmt|;
name|Optional
argument_list|<
name|Cell
argument_list|>
name|startKv
init|=
name|hf
operator|.
name|getFirstKey
argument_list|()
decl_stmt|;
name|start
operator|=
name|CellUtil
operator|.
name|cloneRow
argument_list|(
name|startKv
operator|.
name|get
argument_list|()
argument_list|)
expr_stmt|;
name|Optional
argument_list|<
name|Cell
argument_list|>
name|endKv
init|=
name|hf
operator|.
name|getLastKey
argument_list|()
decl_stmt|;
name|end
operator|=
name|CellUtil
operator|.
name|cloneRow
argument_list|(
name|endKv
operator|.
name|get
argument_list|()
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ioe
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Problem reading orphan file "
operator|+
name|hfile
operator|+
literal|", skipping"
argument_list|)
expr_stmt|;
continue|continue;
block|}
catch|catch
parameter_list|(
name|NullPointerException
name|ioe
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Orphan file "
operator|+
name|hfile
operator|+
literal|" is possibly corrupted HFile, skipping"
argument_list|)
expr_stmt|;
continue|continue;
block|}
finally|finally
block|{
if|if
condition|(
name|hf
operator|!=
literal|null
condition|)
block|{
name|hf
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
block|}
comment|// expand the range to include the range of all hfiles
if|if
condition|(
name|orphanRegionRange
operator|==
literal|null
condition|)
block|{
comment|// first range
name|orphanRegionRange
operator|=
operator|new
name|Pair
argument_list|<>
argument_list|(
name|start
argument_list|,
name|end
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// TODO add test
comment|// expand range only if the hfile is wider.
if|if
condition|(
name|Bytes
operator|.
name|compareTo
argument_list|(
name|orphanRegionRange
operator|.
name|getFirst
argument_list|()
argument_list|,
name|start
argument_list|)
operator|>
literal|0
condition|)
block|{
name|orphanRegionRange
operator|.
name|setFirst
argument_list|(
name|start
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|Bytes
operator|.
name|compareTo
argument_list|(
name|orphanRegionRange
operator|.
name|getSecond
argument_list|()
argument_list|,
name|end
argument_list|)
operator|<
literal|0
condition|)
block|{
name|orphanRegionRange
operator|.
name|setSecond
argument_list|(
name|end
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
if|if
condition|(
name|orphanRegionRange
operator|==
literal|null
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"No data in dir "
operator|+
name|p
operator|+
literal|", sidelining data"
argument_list|)
expr_stmt|;
name|fixes
operator|++
expr_stmt|;
name|sidelineRegionDir
argument_list|(
name|fs
argument_list|,
name|hi
argument_list|)
expr_stmt|;
return|return;
block|}
name|LOG
operator|.
name|info
argument_list|(
literal|"Min max keys are : ["
operator|+
name|Bytes
operator|.
name|toString
argument_list|(
name|orphanRegionRange
operator|.
name|getFirst
argument_list|()
argument_list|)
operator|+
literal|", "
operator|+
name|Bytes
operator|.
name|toString
argument_list|(
name|orphanRegionRange
operator|.
name|getSecond
argument_list|()
argument_list|)
operator|+
literal|")"
argument_list|)
expr_stmt|;
comment|// create new region on hdfs. move data into place.
name|RegionInfo
name|regionInfo
init|=
name|RegionInfoBuilder
operator|.
name|newBuilder
argument_list|(
name|template
operator|.
name|getTableName
argument_list|()
argument_list|)
operator|.
name|setStartKey
argument_list|(
name|orphanRegionRange
operator|.
name|getFirst
argument_list|()
argument_list|)
operator|.
name|setEndKey
argument_list|(
name|Bytes
operator|.
name|add
argument_list|(
name|orphanRegionRange
operator|.
name|getSecond
argument_list|()
argument_list|,
operator|new
name|byte
index|[
literal|1
index|]
argument_list|)
argument_list|)
operator|.
name|build
argument_list|()
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Creating new region : "
operator|+
name|regionInfo
argument_list|)
expr_stmt|;
name|HRegion
name|region
init|=
name|HBaseFsckRepair
operator|.
name|createHDFSRegionDir
argument_list|(
name|getConf
argument_list|()
argument_list|,
name|regionInfo
argument_list|,
name|template
argument_list|)
decl_stmt|;
name|Path
name|target
init|=
name|region
operator|.
name|getRegionFileSystem
argument_list|()
operator|.
name|getRegionDir
argument_list|()
decl_stmt|;
comment|// rename all the data to new region
name|mergeRegionDirs
argument_list|(
name|target
argument_list|,
name|hi
argument_list|)
expr_stmt|;
name|fixes
operator|++
expr_stmt|;
block|}
comment|/**    * This method determines if there are table integrity errors in HDFS.  If    * there are errors and the appropriate "fix" options are enabled, the method    * will first correct orphan regions making them into legit regiondirs, and    * then reload to merge potentially overlapping regions.    *    * @return number of table integrity errors found    */
specifier|private
name|int
name|restoreHdfsIntegrity
parameter_list|()
throws|throws
name|IOException
throws|,
name|InterruptedException
block|{
comment|// Determine what's on HDFS
name|LOG
operator|.
name|info
argument_list|(
literal|"Loading HBase regioninfo from HDFS..."
argument_list|)
expr_stmt|;
name|loadHdfsRegionDirs
argument_list|()
expr_stmt|;
comment|// populating regioninfo table.
name|int
name|errs
init|=
name|errors
operator|.
name|getErrorList
argument_list|()
operator|.
name|size
argument_list|()
decl_stmt|;
comment|// First time just get suggestions.
name|tablesInfo
operator|=
name|loadHdfsRegionInfos
argument_list|()
expr_stmt|;
comment|// update tableInfos based on region info in fs.
name|checkHdfsIntegrity
argument_list|(
literal|false
argument_list|,
literal|false
argument_list|)
expr_stmt|;
if|if
condition|(
name|errors
operator|.
name|getErrorList
argument_list|()
operator|.
name|size
argument_list|()
operator|==
name|errs
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"No integrity errors.  We are done with this phase. Glorious."
argument_list|)
expr_stmt|;
return|return
literal|0
return|;
block|}
if|if
condition|(
name|shouldFixHdfsOrphans
argument_list|()
operator|&&
name|orphanHdfsDirs
operator|.
name|size
argument_list|()
operator|>
literal|0
condition|)
block|{
name|adoptHdfsOrphans
argument_list|(
name|orphanHdfsDirs
argument_list|)
expr_stmt|;
comment|// TODO optimize by incrementally adding instead of reloading.
block|}
comment|// Make sure there are no holes now.
if|if
condition|(
name|shouldFixHdfsHoles
argument_list|()
condition|)
block|{
name|clearState
argument_list|()
expr_stmt|;
comment|// this also resets # fixes.
name|loadHdfsRegionDirs
argument_list|()
expr_stmt|;
name|tablesInfo
operator|=
name|loadHdfsRegionInfos
argument_list|()
expr_stmt|;
comment|// update tableInfos based on region info in fs.
name|tablesInfo
operator|=
name|checkHdfsIntegrity
argument_list|(
name|shouldFixHdfsHoles
argument_list|()
argument_list|,
literal|false
argument_list|)
expr_stmt|;
block|}
comment|// Now we fix overlaps
if|if
condition|(
name|shouldFixHdfsOverlaps
argument_list|()
condition|)
block|{
comment|// second pass we fix overlaps.
name|clearState
argument_list|()
expr_stmt|;
comment|// this also resets # fixes.
name|loadHdfsRegionDirs
argument_list|()
expr_stmt|;
name|tablesInfo
operator|=
name|loadHdfsRegionInfos
argument_list|()
expr_stmt|;
comment|// update tableInfos based on region info in fs.
name|tablesInfo
operator|=
name|checkHdfsIntegrity
argument_list|(
literal|false
argument_list|,
name|shouldFixHdfsOverlaps
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
name|errors
operator|.
name|getErrorList
argument_list|()
operator|.
name|size
argument_list|()
return|;
block|}
comment|/**    * Scan all the store file names to find any lingering reference files,    * which refer to some none-exiting files. If "fix" option is enabled,    * any lingering reference file will be sidelined if found.    *<p>    * Lingering reference file prevents a region from opening. It has to    * be fixed before a cluster can start properly.    */
specifier|private
name|void
name|offlineReferenceFileRepair
parameter_list|()
throws|throws
name|IOException
throws|,
name|InterruptedException
block|{
name|clearState
argument_list|()
expr_stmt|;
name|Configuration
name|conf
init|=
name|getConf
argument_list|()
decl_stmt|;
name|Path
name|hbaseRoot
init|=
name|FSUtils
operator|.
name|getRootDir
argument_list|(
name|conf
argument_list|)
decl_stmt|;
name|FileSystem
name|fs
init|=
name|hbaseRoot
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Computing mapping of all store files"
argument_list|)
expr_stmt|;
name|Map
argument_list|<
name|String
argument_list|,
name|Path
argument_list|>
name|allFiles
init|=
name|FSUtils
operator|.
name|getTableStoreFilePathMap
argument_list|(
name|fs
argument_list|,
name|hbaseRoot
argument_list|,
operator|new
name|FSUtils
operator|.
name|ReferenceFileFilter
argument_list|(
name|fs
argument_list|)
argument_list|,
name|executor
argument_list|,
name|errors
argument_list|)
decl_stmt|;
name|errors
operator|.
name|print
argument_list|(
literal|""
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Validating mapping using HDFS state"
argument_list|)
expr_stmt|;
for|for
control|(
name|Path
name|path
range|:
name|allFiles
operator|.
name|values
argument_list|()
control|)
block|{
name|Path
name|referredToFile
init|=
name|StoreFileInfo
operator|.
name|getReferredToFile
argument_list|(
name|path
argument_list|)
decl_stmt|;
if|if
condition|(
name|fs
operator|.
name|exists
argument_list|(
name|referredToFile
argument_list|)
condition|)
continue|continue;
comment|// good, expected
comment|// Found a lingering reference file
name|errors
operator|.
name|reportError
argument_list|(
name|ERROR_CODE
operator|.
name|LINGERING_REFERENCE_HFILE
argument_list|,
literal|"Found lingering reference file "
operator|+
name|path
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|shouldFixReferenceFiles
argument_list|()
condition|)
continue|continue;
comment|// Now, trying to fix it since requested
name|boolean
name|success
init|=
literal|false
decl_stmt|;
name|String
name|pathStr
init|=
name|path
operator|.
name|toString
argument_list|()
decl_stmt|;
comment|// A reference file path should be like
comment|// ${hbase.rootdir}/data/namespace/table_name/region_id/family_name/referred_file.region_name
comment|// Up 5 directories to get the root folder.
comment|// So the file will be sidelined to a similar folder structure.
name|int
name|index
init|=
name|pathStr
operator|.
name|lastIndexOf
argument_list|(
name|Path
operator|.
name|SEPARATOR_CHAR
argument_list|)
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|index
operator|>
literal|0
operator|&&
name|i
operator|<
literal|5
condition|;
name|i
operator|++
control|)
block|{
name|index
operator|=
name|pathStr
operator|.
name|lastIndexOf
argument_list|(
name|Path
operator|.
name|SEPARATOR_CHAR
argument_list|,
name|index
operator|-
literal|1
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|index
operator|>
literal|0
condition|)
block|{
name|Path
name|rootDir
init|=
name|getSidelineDir
argument_list|()
decl_stmt|;
name|Path
name|dst
init|=
operator|new
name|Path
argument_list|(
name|rootDir
argument_list|,
name|pathStr
operator|.
name|substring
argument_list|(
name|index
operator|+
literal|1
argument_list|)
argument_list|)
decl_stmt|;
name|fs
operator|.
name|mkdirs
argument_list|(
name|dst
operator|.
name|getParent
argument_list|()
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Trying to sideline reference file "
operator|+
name|path
operator|+
literal|" to "
operator|+
name|dst
argument_list|)
expr_stmt|;
name|setShouldRerun
argument_list|()
expr_stmt|;
name|success
operator|=
name|fs
operator|.
name|rename
argument_list|(
name|path
argument_list|,
name|dst
argument_list|)
expr_stmt|;
name|debugLsr
argument_list|(
name|dst
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|!
name|success
condition|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Failed to sideline reference file "
operator|+
name|path
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|/**    * Scan all the store file names to find any lingering HFileLink files,    * which refer to some none-exiting files. If "fix" option is enabled,    * any lingering HFileLink file will be sidelined if found.    */
specifier|private
name|void
name|offlineHLinkFileRepair
parameter_list|()
throws|throws
name|IOException
throws|,
name|InterruptedException
block|{
name|Configuration
name|conf
init|=
name|getConf
argument_list|()
decl_stmt|;
name|Path
name|hbaseRoot
init|=
name|FSUtils
operator|.
name|getRootDir
argument_list|(
name|conf
argument_list|)
decl_stmt|;
name|FileSystem
name|fs
init|=
name|hbaseRoot
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Computing mapping of all link files"
argument_list|)
expr_stmt|;
name|Map
argument_list|<
name|String
argument_list|,
name|Path
argument_list|>
name|allFiles
init|=
name|FSUtils
operator|.
name|getTableStoreFilePathMap
argument_list|(
name|fs
argument_list|,
name|hbaseRoot
argument_list|,
operator|new
name|FSUtils
operator|.
name|HFileLinkFilter
argument_list|()
argument_list|,
name|executor
argument_list|,
name|errors
argument_list|)
decl_stmt|;
name|errors
operator|.
name|print
argument_list|(
literal|""
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Validating mapping using HDFS state"
argument_list|)
expr_stmt|;
for|for
control|(
name|Path
name|path
range|:
name|allFiles
operator|.
name|values
argument_list|()
control|)
block|{
comment|// building HFileLink object to gather locations
name|HFileLink
name|actualLink
init|=
name|HFileLink
operator|.
name|buildFromHFileLinkPattern
argument_list|(
name|conf
argument_list|,
name|path
argument_list|)
decl_stmt|;
if|if
condition|(
name|actualLink
operator|.
name|exists
argument_list|(
name|fs
argument_list|)
condition|)
continue|continue;
comment|// good, expected
comment|// Found a lingering HFileLink
name|errors
operator|.
name|reportError
argument_list|(
name|ERROR_CODE
operator|.
name|LINGERING_HFILELINK
argument_list|,
literal|"Found lingering HFileLink "
operator|+
name|path
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|shouldFixHFileLinks
argument_list|()
condition|)
continue|continue;
comment|// Now, trying to fix it since requested
name|setShouldRerun
argument_list|()
expr_stmt|;
comment|// An HFileLink path should be like
comment|// ${hbase.rootdir}/data/namespace/table_name/region_id/family_name/linkedtable=linkedregionname-linkedhfilename
comment|// sidelineing will happen in the ${hbase.rootdir}/${sidelinedir} directory with the same folder structure.
name|boolean
name|success
init|=
name|sidelineFile
argument_list|(
name|fs
argument_list|,
name|hbaseRoot
argument_list|,
name|path
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|success
condition|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Failed to sideline HFileLink file "
operator|+
name|path
argument_list|)
expr_stmt|;
block|}
comment|// An HFileLink backreference path should be like
comment|// ${hbase.rootdir}/archive/data/namespace/table_name/region_id/family_name/.links-linkedhfilename
comment|// sidelineing will happen in the ${hbase.rootdir}/${sidelinedir} directory with the same folder structure.
name|Path
name|backRefPath
init|=
name|FileLink
operator|.
name|getBackReferencesDir
argument_list|(
name|HFileArchiveUtil
operator|.
name|getStoreArchivePath
argument_list|(
name|conf
argument_list|,
name|HFileLink
operator|.
name|getReferencedTableName
argument_list|(
name|path
operator|.
name|getName
argument_list|()
operator|.
name|toString
argument_list|()
argument_list|)
argument_list|,
name|HFileLink
operator|.
name|getReferencedRegionName
argument_list|(
name|path
operator|.
name|getName
argument_list|()
operator|.
name|toString
argument_list|()
argument_list|)
argument_list|,
name|path
operator|.
name|getParent
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|)
argument_list|,
name|HFileLink
operator|.
name|getReferencedHFileName
argument_list|(
name|path
operator|.
name|getName
argument_list|()
operator|.
name|toString
argument_list|()
argument_list|)
argument_list|)
decl_stmt|;
name|success
operator|=
name|sidelineFile
argument_list|(
name|fs
argument_list|,
name|hbaseRoot
argument_list|,
name|backRefPath
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|success
condition|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Failed to sideline HFileLink backreference file "
operator|+
name|path
argument_list|)
expr_stmt|;
block|}
block|}
block|}
specifier|private
name|boolean
name|sidelineFile
parameter_list|(
name|FileSystem
name|fs
parameter_list|,
name|Path
name|hbaseRoot
parameter_list|,
name|Path
name|path
parameter_list|)
throws|throws
name|IOException
block|{
name|URI
name|uri
init|=
name|hbaseRoot
operator|.
name|toUri
argument_list|()
operator|.
name|relativize
argument_list|(
name|path
operator|.
name|toUri
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|uri
operator|.
name|isAbsolute
argument_list|()
condition|)
return|return
literal|false
return|;
name|String
name|relativePath
init|=
name|uri
operator|.
name|getPath
argument_list|()
decl_stmt|;
name|Path
name|rootDir
init|=
name|getSidelineDir
argument_list|()
decl_stmt|;
name|Path
name|dst
init|=
operator|new
name|Path
argument_list|(
name|rootDir
argument_list|,
name|relativePath
argument_list|)
decl_stmt|;
name|boolean
name|pathCreated
init|=
name|fs
operator|.
name|mkdirs
argument_list|(
name|dst
operator|.
name|getParent
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|pathCreated
condition|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Failed to create path: "
operator|+
name|dst
operator|.
name|getParent
argument_list|()
argument_list|)
expr_stmt|;
return|return
literal|false
return|;
block|}
name|LOG
operator|.
name|info
argument_list|(
literal|"Trying to sideline file "
operator|+
name|path
operator|+
literal|" to "
operator|+
name|dst
argument_list|)
expr_stmt|;
return|return
name|fs
operator|.
name|rename
argument_list|(
name|path
argument_list|,
name|dst
argument_list|)
return|;
block|}
comment|/**    * TODO -- need to add tests for this.    */
specifier|private
name|void
name|reportEmptyMetaCells
parameter_list|()
block|{
name|errors
operator|.
name|print
argument_list|(
literal|"Number of empty REGIONINFO_QUALIFIER rows in hbase:meta: "
operator|+
name|emptyRegionInfoQualifiers
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|details
condition|)
block|{
for|for
control|(
name|Result
name|r
range|:
name|emptyRegionInfoQualifiers
control|)
block|{
name|errors
operator|.
name|print
argument_list|(
literal|"  "
operator|+
name|r
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|/**    * TODO -- need to add tests for this.    */
specifier|private
name|void
name|reportTablesInFlux
parameter_list|()
block|{
name|AtomicInteger
name|numSkipped
init|=
operator|new
name|AtomicInteger
argument_list|(
literal|0
argument_list|)
decl_stmt|;
name|TableDescriptor
index|[]
name|allTables
init|=
name|getTables
argument_list|(
name|numSkipped
argument_list|)
decl_stmt|;
name|errors
operator|.
name|print
argument_list|(
literal|"Number of Tables: "
operator|+
name|allTables
operator|.
name|length
argument_list|)
expr_stmt|;
if|if
condition|(
name|details
condition|)
block|{
if|if
condition|(
name|numSkipped
operator|.
name|get
argument_list|()
operator|>
literal|0
condition|)
block|{
name|errors
operator|.
name|detail
argument_list|(
literal|"Number of Tables in flux: "
operator|+
name|numSkipped
operator|.
name|get
argument_list|()
argument_list|)
expr_stmt|;
block|}
for|for
control|(
name|TableDescriptor
name|td
range|:
name|allTables
control|)
block|{
name|errors
operator|.
name|detail
argument_list|(
literal|"  Table: "
operator|+
name|td
operator|.
name|getTableName
argument_list|()
operator|+
literal|"\t"
operator|+
operator|(
name|td
operator|.
name|isReadOnly
argument_list|()
condition|?
literal|"ro"
else|:
literal|"rw"
operator|)
operator|+
literal|"\t"
operator|+
operator|(
name|td
operator|.
name|isMetaRegion
argument_list|()
condition|?
literal|"META"
else|:
literal|"    "
operator|)
operator|+
literal|"\t"
operator|+
literal|" families: "
operator|+
name|td
operator|.
name|getColumnFamilyCount
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
block|}
specifier|public
name|ErrorReporter
name|getErrors
parameter_list|()
block|{
return|return
name|errors
return|;
block|}
comment|/**    * Read the .regioninfo file from the file system.  If there is no    * .regioninfo, add it to the orphan hdfs region list.    */
specifier|private
name|void
name|loadHdfsRegioninfo
parameter_list|(
name|HbckInfo
name|hbi
parameter_list|)
throws|throws
name|IOException
block|{
name|Path
name|regionDir
init|=
name|hbi
operator|.
name|getHdfsRegionDir
argument_list|()
decl_stmt|;
if|if
condition|(
name|regionDir
operator|==
literal|null
condition|)
block|{
if|if
condition|(
name|hbi
operator|.
name|getReplicaId
argument_list|()
operator|==
name|RegionInfo
operator|.
name|DEFAULT_REPLICA_ID
condition|)
block|{
comment|// Log warning only for default/ primary replica with no region dir
name|LOG
operator|.
name|warn
argument_list|(
literal|"No HDFS region dir found: "
operator|+
name|hbi
operator|+
literal|" meta="
operator|+
name|hbi
operator|.
name|metaEntry
argument_list|)
expr_stmt|;
block|}
return|return;
block|}
if|if
condition|(
name|hbi
operator|.
name|hdfsEntry
operator|.
name|hri
operator|!=
literal|null
condition|)
block|{
comment|// already loaded data
return|return;
block|}
name|FileSystem
name|fs
init|=
name|FileSystem
operator|.
name|get
argument_list|(
name|getConf
argument_list|()
argument_list|)
decl_stmt|;
name|RegionInfo
name|hri
init|=
name|HRegionFileSystem
operator|.
name|loadRegionInfoFileContent
argument_list|(
name|fs
argument_list|,
name|regionDir
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"RegionInfo read: "
operator|+
name|hri
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
name|hbi
operator|.
name|hdfsEntry
operator|.
name|hri
operator|=
name|hri
expr_stmt|;
block|}
comment|/**    * Exception thrown when a integrity repair operation fails in an    * unresolvable way.    */
specifier|public
specifier|static
class|class
name|RegionRepairException
extends|extends
name|IOException
block|{
specifier|private
specifier|static
specifier|final
name|long
name|serialVersionUID
init|=
literal|1L
decl_stmt|;
specifier|final
name|IOException
name|ioe
decl_stmt|;
specifier|public
name|RegionRepairException
parameter_list|(
name|String
name|s
parameter_list|,
name|IOException
name|ioe
parameter_list|)
block|{
name|super
argument_list|(
name|s
argument_list|)
expr_stmt|;
name|this
operator|.
name|ioe
operator|=
name|ioe
expr_stmt|;
block|}
block|}
comment|/**    * Populate hbi's from regionInfos loaded from file system.    */
specifier|private
name|SortedMap
argument_list|<
name|TableName
argument_list|,
name|TableInfo
argument_list|>
name|loadHdfsRegionInfos
parameter_list|()
throws|throws
name|IOException
throws|,
name|InterruptedException
block|{
name|tablesInfo
operator|.
name|clear
argument_list|()
expr_stmt|;
comment|// regenerating the data
comment|// generate region split structure
name|Collection
argument_list|<
name|HbckInfo
argument_list|>
name|hbckInfos
init|=
name|regionInfoMap
operator|.
name|values
argument_list|()
decl_stmt|;
comment|// Parallelized read of .regioninfo files.
name|List
argument_list|<
name|WorkItemHdfsRegionInfo
argument_list|>
name|hbis
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
name|hbckInfos
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|Future
argument_list|<
name|Void
argument_list|>
argument_list|>
name|hbiFutures
decl_stmt|;
for|for
control|(
name|HbckInfo
name|hbi
range|:
name|hbckInfos
control|)
block|{
name|WorkItemHdfsRegionInfo
name|work
init|=
operator|new
name|WorkItemHdfsRegionInfo
argument_list|(
name|hbi
argument_list|,
name|this
argument_list|,
name|errors
argument_list|)
decl_stmt|;
name|hbis
operator|.
name|add
argument_list|(
name|work
argument_list|)
expr_stmt|;
block|}
comment|// Submit and wait for completion
name|hbiFutures
operator|=
name|executor
operator|.
name|invokeAll
argument_list|(
name|hbis
argument_list|)
expr_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|hbiFutures
operator|.
name|size
argument_list|()
condition|;
name|i
operator|++
control|)
block|{
name|WorkItemHdfsRegionInfo
name|work
init|=
name|hbis
operator|.
name|get
argument_list|(
name|i
argument_list|)
decl_stmt|;
name|Future
argument_list|<
name|Void
argument_list|>
name|f
init|=
name|hbiFutures
operator|.
name|get
argument_list|(
name|i
argument_list|)
decl_stmt|;
try|try
block|{
name|f
operator|.
name|get
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|ExecutionException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failed to read .regioninfo file for region "
operator|+
name|work
operator|.
name|hbi
operator|.
name|getRegionNameAsString
argument_list|()
argument_list|,
name|e
operator|.
name|getCause
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
name|Path
name|hbaseRoot
init|=
name|FSUtils
operator|.
name|getRootDir
argument_list|(
name|getConf
argument_list|()
argument_list|)
decl_stmt|;
name|FileSystem
name|fs
init|=
name|hbaseRoot
operator|.
name|getFileSystem
argument_list|(
name|getConf
argument_list|()
argument_list|)
decl_stmt|;
comment|// serialized table info gathering.
for|for
control|(
name|HbckInfo
name|hbi
range|:
name|hbckInfos
control|)
block|{
if|if
condition|(
name|hbi
operator|.
name|getHdfsHRI
argument_list|()
operator|==
literal|null
condition|)
block|{
comment|// was an orphan
continue|continue;
block|}
comment|// get table name from hdfs, populate various HBaseFsck tables.
name|TableName
name|tableName
init|=
name|hbi
operator|.
name|getTableName
argument_list|()
decl_stmt|;
if|if
condition|(
name|tableName
operator|==
literal|null
condition|)
block|{
comment|// There was an entry in hbase:meta not in the HDFS?
name|LOG
operator|.
name|warn
argument_list|(
literal|"tableName was null for: "
operator|+
name|hbi
argument_list|)
expr_stmt|;
continue|continue;
block|}
name|TableInfo
name|modTInfo
init|=
name|tablesInfo
operator|.
name|get
argument_list|(
name|tableName
argument_list|)
decl_stmt|;
if|if
condition|(
name|modTInfo
operator|==
literal|null
condition|)
block|{
comment|// only executed once per table.
name|modTInfo
operator|=
operator|new
name|TableInfo
argument_list|(
name|tableName
argument_list|)
expr_stmt|;
name|tablesInfo
operator|.
name|put
argument_list|(
name|tableName
argument_list|,
name|modTInfo
argument_list|)
expr_stmt|;
try|try
block|{
name|TableDescriptor
name|htd
init|=
name|FSTableDescriptors
operator|.
name|getTableDescriptorFromFs
argument_list|(
name|fs
argument_list|,
name|hbaseRoot
argument_list|,
name|tableName
argument_list|)
decl_stmt|;
name|modTInfo
operator|.
name|htds
operator|.
name|add
argument_list|(
name|htd
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ioe
parameter_list|)
block|{
if|if
condition|(
operator|!
name|orphanTableDirs
operator|.
name|containsKey
argument_list|(
name|tableName
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Unable to read .tableinfo from "
operator|+
name|hbaseRoot
argument_list|,
name|ioe
argument_list|)
expr_stmt|;
comment|//should only report once for each table
name|errors
operator|.
name|reportError
argument_list|(
name|ERROR_CODE
operator|.
name|NO_TABLEINFO_FILE
argument_list|,
literal|"Unable to read .tableinfo from "
operator|+
name|hbaseRoot
operator|+
literal|"/"
operator|+
name|tableName
argument_list|)
expr_stmt|;
name|Set
argument_list|<
name|String
argument_list|>
name|columns
init|=
operator|new
name|HashSet
argument_list|<>
argument_list|()
decl_stmt|;
name|orphanTableDirs
operator|.
name|put
argument_list|(
name|tableName
argument_list|,
name|getColumnFamilyList
argument_list|(
name|columns
argument_list|,
name|hbi
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
block|}
if|if
condition|(
operator|!
name|hbi
operator|.
name|isSkipChecks
argument_list|()
condition|)
block|{
name|modTInfo
operator|.
name|addRegionInfo
argument_list|(
name|hbi
argument_list|)
expr_stmt|;
block|}
block|}
name|loadTableInfosForTablesWithNoRegion
argument_list|()
expr_stmt|;
name|errors
operator|.
name|print
argument_list|(
literal|""
argument_list|)
expr_stmt|;
return|return
name|tablesInfo
return|;
block|}
comment|/**    * To get the column family list according to the column family dirs    * @param columns    * @param hbi    * @return a set of column families    * @throws IOException    */
specifier|private
name|Set
argument_list|<
name|String
argument_list|>
name|getColumnFamilyList
parameter_list|(
name|Set
argument_list|<
name|String
argument_list|>
name|columns
parameter_list|,
name|HbckInfo
name|hbi
parameter_list|)
throws|throws
name|IOException
block|{
name|Path
name|regionDir
init|=
name|hbi
operator|.
name|getHdfsRegionDir
argument_list|()
decl_stmt|;
name|FileSystem
name|fs
init|=
name|regionDir
operator|.
name|getFileSystem
argument_list|(
name|getConf
argument_list|()
argument_list|)
decl_stmt|;
name|FileStatus
index|[]
name|subDirs
init|=
name|fs
operator|.
name|listStatus
argument_list|(
name|regionDir
argument_list|,
operator|new
name|FSUtils
operator|.
name|FamilyDirFilter
argument_list|(
name|fs
argument_list|)
argument_list|)
decl_stmt|;
for|for
control|(
name|FileStatus
name|subdir
range|:
name|subDirs
control|)
block|{
name|String
name|columnfamily
init|=
name|subdir
operator|.
name|getPath
argument_list|()
operator|.
name|getName
argument_list|()
decl_stmt|;
name|columns
operator|.
name|add
argument_list|(
name|columnfamily
argument_list|)
expr_stmt|;
block|}
return|return
name|columns
return|;
block|}
comment|/**    * To fabricate a .tableinfo file with following contents<br>    * 1. the correct tablename<br>    * 2. the correct colfamily list<br>    * 3. the default properties for both {@link TableDescriptor} and {@link ColumnFamilyDescriptor}<br>    * @throws IOException    */
specifier|private
name|boolean
name|fabricateTableInfo
parameter_list|(
name|FSTableDescriptors
name|fstd
parameter_list|,
name|TableName
name|tableName
parameter_list|,
name|Set
argument_list|<
name|String
argument_list|>
name|columns
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|columns
operator|==
literal|null
operator|||
name|columns
operator|.
name|isEmpty
argument_list|()
condition|)
return|return
literal|false
return|;
name|TableDescriptorBuilder
name|builder
init|=
name|TableDescriptorBuilder
operator|.
name|newBuilder
argument_list|(
name|tableName
argument_list|)
decl_stmt|;
for|for
control|(
name|String
name|columnfamimly
range|:
name|columns
control|)
block|{
name|builder
operator|.
name|setColumnFamily
argument_list|(
name|ColumnFamilyDescriptorBuilder
operator|.
name|of
argument_list|(
name|columnfamimly
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|fstd
operator|.
name|createTableDescriptor
argument_list|(
name|builder
operator|.
name|build
argument_list|()
argument_list|,
literal|true
argument_list|)
expr_stmt|;
return|return
literal|true
return|;
block|}
comment|/**    * To fix the empty REGIONINFO_QUALIFIER rows from hbase:meta<br>    * @throws IOException    */
specifier|public
name|void
name|fixEmptyMetaCells
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|shouldFixEmptyMetaCells
argument_list|()
operator|&&
operator|!
name|emptyRegionInfoQualifiers
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Trying to fix empty REGIONINFO_QUALIFIER hbase:meta rows."
argument_list|)
expr_stmt|;
for|for
control|(
name|Result
name|region
range|:
name|emptyRegionInfoQualifiers
control|)
block|{
name|deleteMetaRegion
argument_list|(
name|region
operator|.
name|getRow
argument_list|()
argument_list|)
expr_stmt|;
name|errors
operator|.
name|getErrorList
argument_list|()
operator|.
name|remove
argument_list|(
name|ERROR_CODE
operator|.
name|EMPTY_META_CELL
argument_list|)
expr_stmt|;
block|}
name|emptyRegionInfoQualifiers
operator|.
name|clear
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**    * To fix orphan table by creating a .tableinfo file under tableDir<br>    * 1. if TableInfo is cached, to recover the .tableinfo accordingly<br>    * 2. else create a default .tableinfo file with following items<br>    *&nbsp;2.1 the correct tablename<br>    *&nbsp;2.2 the correct colfamily list<br>    *&nbsp;2.3 the default properties for both {@link TableDescriptor} and {@link ColumnFamilyDescriptor}<br>    * @throws IOException    */
specifier|public
name|void
name|fixOrphanTables
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|shouldFixTableOrphans
argument_list|()
operator|&&
operator|!
name|orphanTableDirs
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|List
argument_list|<
name|TableName
argument_list|>
name|tmpList
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
name|orphanTableDirs
operator|.
name|keySet
argument_list|()
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
name|tmpList
operator|.
name|addAll
argument_list|(
name|orphanTableDirs
operator|.
name|keySet
argument_list|()
argument_list|)
expr_stmt|;
name|TableDescriptor
index|[]
name|htds
init|=
name|getTableDescriptors
argument_list|(
name|tmpList
argument_list|)
decl_stmt|;
name|Iterator
argument_list|<
name|Entry
argument_list|<
name|TableName
argument_list|,
name|Set
argument_list|<
name|String
argument_list|>
argument_list|>
argument_list|>
name|iter
init|=
name|orphanTableDirs
operator|.
name|entrySet
argument_list|()
operator|.
name|iterator
argument_list|()
decl_stmt|;
name|int
name|j
init|=
literal|0
decl_stmt|;
name|int
name|numFailedCase
init|=
literal|0
decl_stmt|;
name|FSTableDescriptors
name|fstd
init|=
operator|new
name|FSTableDescriptors
argument_list|(
name|getConf
argument_list|()
argument_list|)
decl_stmt|;
while|while
condition|(
name|iter
operator|.
name|hasNext
argument_list|()
condition|)
block|{
name|Entry
argument_list|<
name|TableName
argument_list|,
name|Set
argument_list|<
name|String
argument_list|>
argument_list|>
name|entry
init|=
name|iter
operator|.
name|next
argument_list|()
decl_stmt|;
name|TableName
name|tableName
init|=
name|entry
operator|.
name|getKey
argument_list|()
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Trying to fix orphan table error: "
operator|+
name|tableName
argument_list|)
expr_stmt|;
if|if
condition|(
name|j
operator|<
name|htds
operator|.
name|length
condition|)
block|{
if|if
condition|(
name|tableName
operator|.
name|equals
argument_list|(
name|htds
index|[
name|j
index|]
operator|.
name|getTableName
argument_list|()
argument_list|)
condition|)
block|{
name|TableDescriptor
name|htd
init|=
name|htds
index|[
name|j
index|]
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"fixing orphan table: "
operator|+
name|tableName
operator|+
literal|" from cache"
argument_list|)
expr_stmt|;
name|fstd
operator|.
name|createTableDescriptor
argument_list|(
name|htd
argument_list|,
literal|true
argument_list|)
expr_stmt|;
name|j
operator|++
expr_stmt|;
name|iter
operator|.
name|remove
argument_list|()
expr_stmt|;
block|}
block|}
else|else
block|{
if|if
condition|(
name|fabricateTableInfo
argument_list|(
name|fstd
argument_list|,
name|tableName
argument_list|,
name|entry
operator|.
name|getValue
argument_list|()
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"fixing orphan table: "
operator|+
name|tableName
operator|+
literal|" with a default .tableinfo file"
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|warn
argument_list|(
literal|"Strongly recommend to modify the TableDescriptor if necessary for: "
operator|+
name|tableName
argument_list|)
expr_stmt|;
name|iter
operator|.
name|remove
argument_list|()
expr_stmt|;
block|}
else|else
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Unable to create default .tableinfo for "
operator|+
name|tableName
operator|+
literal|" while missing column family information"
argument_list|)
expr_stmt|;
name|numFailedCase
operator|++
expr_stmt|;
block|}
block|}
name|fixes
operator|++
expr_stmt|;
block|}
if|if
condition|(
name|orphanTableDirs
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
comment|// all orphanTableDirs are luckily recovered
comment|// re-run doFsck after recovering the .tableinfo file
name|setShouldRerun
argument_list|()
expr_stmt|;
name|LOG
operator|.
name|warn
argument_list|(
literal|"Strongly recommend to re-run manually hfsck after all orphanTableDirs being fixed"
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|numFailedCase
operator|>
literal|0
condition|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Failed to fix "
operator|+
name|numFailedCase
operator|+
literal|" OrphanTables with default .tableinfo files"
argument_list|)
expr_stmt|;
block|}
block|}
comment|//cleanup the list
name|orphanTableDirs
operator|.
name|clear
argument_list|()
expr_stmt|;
block|}
comment|/**    * This borrows code from MasterFileSystem.bootstrap(). Explicitly creates it's own WAL, so be    * sure to close it as well as the region when you're finished.    * @param walFactoryID A unique identifier for WAL factory. Filesystem implementations will use    *          this ID to make a directory inside WAL directory path.    * @return an open hbase:meta HRegion    */
specifier|private
name|HRegion
name|createNewMeta
parameter_list|(
name|String
name|walFactoryID
parameter_list|)
throws|throws
name|IOException
block|{
name|Path
name|rootdir
init|=
name|FSUtils
operator|.
name|getRootDir
argument_list|(
name|getConf
argument_list|()
argument_list|)
decl_stmt|;
name|Configuration
name|c
init|=
name|getConf
argument_list|()
decl_stmt|;
name|RegionInfo
name|metaHRI
init|=
name|RegionInfoBuilder
operator|.
name|FIRST_META_REGIONINFO
decl_stmt|;
name|TableDescriptor
name|metaDescriptor
init|=
operator|new
name|FSTableDescriptors
argument_list|(
name|c
argument_list|)
operator|.
name|get
argument_list|(
name|TableName
operator|.
name|META_TABLE_NAME
argument_list|)
decl_stmt|;
name|MasterFileSystem
operator|.
name|setInfoFamilyCachingForMeta
argument_list|(
name|metaDescriptor
argument_list|,
literal|false
argument_list|)
expr_stmt|;
comment|// The WAL subsystem will use the default rootDir rather than the passed in rootDir
comment|// unless I pass along via the conf.
name|Configuration
name|confForWAL
init|=
operator|new
name|Configuration
argument_list|(
name|c
argument_list|)
decl_stmt|;
name|confForWAL
operator|.
name|set
argument_list|(
name|HConstants
operator|.
name|HBASE_DIR
argument_list|,
name|rootdir
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
name|WAL
name|wal
init|=
operator|new
name|WALFactory
argument_list|(
name|confForWAL
argument_list|,
name|walFactoryID
argument_list|)
operator|.
name|getWAL
argument_list|(
name|metaHRI
argument_list|)
decl_stmt|;
name|HRegion
name|meta
init|=
name|HRegion
operator|.
name|createHRegion
argument_list|(
name|metaHRI
argument_list|,
name|rootdir
argument_list|,
name|c
argument_list|,
name|metaDescriptor
argument_list|,
name|wal
argument_list|)
decl_stmt|;
name|MasterFileSystem
operator|.
name|setInfoFamilyCachingForMeta
argument_list|(
name|metaDescriptor
argument_list|,
literal|true
argument_list|)
expr_stmt|;
return|return
name|meta
return|;
block|}
comment|/**    * Generate set of puts to add to new meta.  This expects the tables to be    * clean with no overlaps or holes.  If there are any problems it returns null.    *    * @return An array list of puts to do in bulk, null if tables have problems    */
specifier|private
name|ArrayList
argument_list|<
name|Put
argument_list|>
name|generatePuts
parameter_list|(
name|SortedMap
argument_list|<
name|TableName
argument_list|,
name|TableInfo
argument_list|>
name|tablesInfo
parameter_list|)
throws|throws
name|IOException
block|{
name|ArrayList
argument_list|<
name|Put
argument_list|>
name|puts
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
name|boolean
name|hasProblems
init|=
literal|false
decl_stmt|;
for|for
control|(
name|Entry
argument_list|<
name|TableName
argument_list|,
name|TableInfo
argument_list|>
name|e
range|:
name|tablesInfo
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|TableName
name|name
init|=
name|e
operator|.
name|getKey
argument_list|()
decl_stmt|;
comment|// skip "hbase:meta"
if|if
condition|(
name|name
operator|.
name|compareTo
argument_list|(
name|TableName
operator|.
name|META_TABLE_NAME
argument_list|)
operator|==
literal|0
condition|)
block|{
continue|continue;
block|}
name|TableInfo
name|ti
init|=
name|e
operator|.
name|getValue
argument_list|()
decl_stmt|;
name|puts
operator|.
name|add
argument_list|(
name|MetaTableAccessor
operator|.
name|makePutFromTableState
argument_list|(
operator|new
name|TableState
argument_list|(
name|ti
operator|.
name|tableName
argument_list|,
name|TableState
operator|.
name|State
operator|.
name|ENABLED
argument_list|)
argument_list|,
name|EnvironmentEdgeManager
operator|.
name|currentTime
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
for|for
control|(
name|Entry
argument_list|<
name|byte
index|[]
argument_list|,
name|Collection
argument_list|<
name|HbckInfo
argument_list|>
argument_list|>
name|spl
range|:
name|ti
operator|.
name|sc
operator|.
name|getStarts
argument_list|()
operator|.
name|asMap
argument_list|()
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|Collection
argument_list|<
name|HbckInfo
argument_list|>
name|his
init|=
name|spl
operator|.
name|getValue
argument_list|()
decl_stmt|;
name|int
name|sz
init|=
name|his
operator|.
name|size
argument_list|()
decl_stmt|;
if|if
condition|(
name|sz
operator|!=
literal|1
condition|)
block|{
comment|// problem
name|LOG
operator|.
name|error
argument_list|(
literal|"Split starting at "
operator|+
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|spl
operator|.
name|getKey
argument_list|()
argument_list|)
operator|+
literal|" had "
operator|+
name|sz
operator|+
literal|" regions instead of exactly 1."
argument_list|)
expr_stmt|;
name|hasProblems
operator|=
literal|true
expr_stmt|;
continue|continue;
block|}
comment|// add the row directly to meta.
name|HbckInfo
name|hi
init|=
name|his
operator|.
name|iterator
argument_list|()
operator|.
name|next
argument_list|()
decl_stmt|;
name|RegionInfo
name|hri
init|=
name|hi
operator|.
name|getHdfsHRI
argument_list|()
decl_stmt|;
comment|// hi.metaEntry;
name|Put
name|p
init|=
name|MetaTableAccessor
operator|.
name|makePutFromRegionInfo
argument_list|(
name|hri
argument_list|,
name|EnvironmentEdgeManager
operator|.
name|currentTime
argument_list|()
argument_list|)
decl_stmt|;
name|puts
operator|.
name|add
argument_list|(
name|p
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|hasProblems
condition|?
literal|null
else|:
name|puts
return|;
block|}
comment|/**    * Suggest fixes for each table    */
specifier|private
name|void
name|suggestFixes
parameter_list|(
name|SortedMap
argument_list|<
name|TableName
argument_list|,
name|TableInfo
argument_list|>
name|tablesInfo
parameter_list|)
throws|throws
name|IOException
block|{
name|logParallelMerge
argument_list|()
expr_stmt|;
for|for
control|(
name|TableInfo
name|tInfo
range|:
name|tablesInfo
operator|.
name|values
argument_list|()
control|)
block|{
name|TableIntegrityErrorHandler
name|handler
init|=
name|tInfo
operator|.
expr|new
name|IntegrityFixSuggester
argument_list|(
name|tInfo
argument_list|,
name|errors
argument_list|)
decl_stmt|;
name|tInfo
operator|.
name|checkRegionChain
argument_list|(
name|handler
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Rebuilds meta from information in hdfs/fs.  Depends on configuration settings passed into    * hbck constructor to point to a particular fs/dir. Assumes HBase is OFFLINE.    *    * @param fix flag that determines if method should attempt to fix holes    * @return true if successful, false if attempt failed.    */
specifier|public
name|boolean
name|rebuildMeta
parameter_list|(
name|boolean
name|fix
parameter_list|)
throws|throws
name|IOException
throws|,
name|InterruptedException
block|{
comment|// TODO check to make sure hbase is offline. (or at least the table
comment|// currently being worked on is off line)
comment|// Determine what's on HDFS
name|LOG
operator|.
name|info
argument_list|(
literal|"Loading HBase regioninfo from HDFS..."
argument_list|)
expr_stmt|;
name|loadHdfsRegionDirs
argument_list|()
expr_stmt|;
comment|// populating regioninfo table.
name|int
name|errs
init|=
name|errors
operator|.
name|getErrorList
argument_list|()
operator|.
name|size
argument_list|()
decl_stmt|;
name|tablesInfo
operator|=
name|loadHdfsRegionInfos
argument_list|()
expr_stmt|;
comment|// update tableInfos based on region info in fs.
name|checkHdfsIntegrity
argument_list|(
literal|false
argument_list|,
literal|false
argument_list|)
expr_stmt|;
comment|// make sure ok.
if|if
condition|(
name|errors
operator|.
name|getErrorList
argument_list|()
operator|.
name|size
argument_list|()
operator|!=
name|errs
condition|)
block|{
comment|// While in error state, iterate until no more fixes possible
while|while
condition|(
literal|true
condition|)
block|{
name|fixes
operator|=
literal|0
expr_stmt|;
name|suggestFixes
argument_list|(
name|tablesInfo
argument_list|)
expr_stmt|;
name|errors
operator|.
name|clear
argument_list|()
expr_stmt|;
name|loadHdfsRegionInfos
argument_list|()
expr_stmt|;
comment|// update tableInfos based on region info in fs.
name|checkHdfsIntegrity
argument_list|(
name|shouldFixHdfsHoles
argument_list|()
argument_list|,
name|shouldFixHdfsOverlaps
argument_list|()
argument_list|)
expr_stmt|;
name|int
name|errCount
init|=
name|errors
operator|.
name|getErrorList
argument_list|()
operator|.
name|size
argument_list|()
decl_stmt|;
if|if
condition|(
name|fixes
operator|==
literal|0
condition|)
block|{
if|if
condition|(
name|errCount
operator|>
literal|0
condition|)
block|{
return|return
literal|false
return|;
comment|// failed to fix problems.
block|}
else|else
block|{
break|break;
comment|// no fixes and no problems? drop out and fix stuff!
block|}
block|}
block|}
block|}
comment|// we can rebuild, move old meta out of the way and start
name|LOG
operator|.
name|info
argument_list|(
literal|"HDFS regioninfo's seems good.  Sidelining old hbase:meta"
argument_list|)
expr_stmt|;
name|Path
name|backupDir
init|=
name|sidelineOldMeta
argument_list|()
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Creating new hbase:meta"
argument_list|)
expr_stmt|;
name|String
name|walFactoryId
init|=
literal|"hbck-meta-recovery-"
operator|+
name|RandomStringUtils
operator|.
name|randomNumeric
argument_list|(
literal|8
argument_list|)
decl_stmt|;
name|HRegion
name|meta
init|=
name|createNewMeta
argument_list|(
name|walFactoryId
argument_list|)
decl_stmt|;
comment|// populate meta
name|List
argument_list|<
name|Put
argument_list|>
name|puts
init|=
name|generatePuts
argument_list|(
name|tablesInfo
argument_list|)
decl_stmt|;
if|if
condition|(
name|puts
operator|==
literal|null
condition|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|HBaseMarkers
operator|.
name|FATAL
argument_list|,
literal|"Problem encountered when creating new hbase:meta "
operator|+
literal|"entries. You may need to restore the previously sidelined hbase:meta"
argument_list|)
expr_stmt|;
return|return
literal|false
return|;
block|}
name|meta
operator|.
name|batchMutate
argument_list|(
name|puts
operator|.
name|toArray
argument_list|(
operator|new
name|Put
index|[
name|puts
operator|.
name|size
argument_list|()
index|]
argument_list|)
argument_list|,
name|HConstants
operator|.
name|NO_NONCE
argument_list|,
name|HConstants
operator|.
name|NO_NONCE
argument_list|)
expr_stmt|;
name|meta
operator|.
name|close
argument_list|()
expr_stmt|;
if|if
condition|(
name|meta
operator|.
name|getWAL
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|meta
operator|.
name|getWAL
argument_list|()
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
comment|// clean up the temporary hbck meta recovery WAL directory
name|removeHBCKMetaRecoveryWALDir
argument_list|(
name|walFactoryId
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Success! hbase:meta table rebuilt."
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Old hbase:meta is moved into "
operator|+
name|backupDir
argument_list|)
expr_stmt|;
return|return
literal|true
return|;
block|}
comment|/**    * Removes the empty Meta recovery WAL directory.    * @param walFactoryId A unique identifier for WAL factory which was used by Filesystem to make a    *          Meta recovery WAL directory inside WAL directory path.    */
specifier|private
name|void
name|removeHBCKMetaRecoveryWALDir
parameter_list|(
name|String
name|walFactoryId
parameter_list|)
throws|throws
name|IOException
block|{
name|Path
name|rootdir
init|=
name|FSUtils
operator|.
name|getRootDir
argument_list|(
name|getConf
argument_list|()
argument_list|)
decl_stmt|;
name|Path
name|walLogDir
init|=
operator|new
name|Path
argument_list|(
operator|new
name|Path
argument_list|(
name|rootdir
argument_list|,
name|HConstants
operator|.
name|HREGION_LOGDIR_NAME
argument_list|)
argument_list|,
name|walFactoryId
argument_list|)
decl_stmt|;
name|FileSystem
name|fs
init|=
name|FSUtils
operator|.
name|getCurrentFileSystem
argument_list|(
name|getConf
argument_list|()
argument_list|)
decl_stmt|;
name|FileStatus
index|[]
name|walFiles
init|=
name|FSUtils
operator|.
name|listStatus
argument_list|(
name|fs
argument_list|,
name|walLogDir
argument_list|,
literal|null
argument_list|)
decl_stmt|;
if|if
condition|(
name|walFiles
operator|==
literal|null
operator|||
name|walFiles
operator|.
name|length
operator|==
literal|0
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"HBCK meta recovery WAL directory is empty, removing it now."
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|FSUtils
operator|.
name|deleteDirectory
argument_list|(
name|fs
argument_list|,
name|walLogDir
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Couldn't clear the HBCK Meta recovery WAL directory "
operator|+
name|walLogDir
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|/**    * Log an appropriate message about whether or not overlapping merges are computed in parallel.    */
specifier|private
name|void
name|logParallelMerge
parameter_list|()
block|{
if|if
condition|(
name|getConf
argument_list|()
operator|.
name|getBoolean
argument_list|(
literal|"hbasefsck.overlap.merge.parallel"
argument_list|,
literal|true
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Handling overlap merges in parallel. set hbasefsck.overlap.merge.parallel to"
operator|+
literal|" false to run serially."
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Handling overlap merges serially.  set hbasefsck.overlap.merge.parallel to"
operator|+
literal|" true to run in parallel."
argument_list|)
expr_stmt|;
block|}
block|}
specifier|private
name|SortedMap
argument_list|<
name|TableName
argument_list|,
name|TableInfo
argument_list|>
name|checkHdfsIntegrity
parameter_list|(
name|boolean
name|fixHoles
parameter_list|,
name|boolean
name|fixOverlaps
parameter_list|)
throws|throws
name|IOException
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Checking HBase region split map from HDFS data..."
argument_list|)
expr_stmt|;
name|logParallelMerge
argument_list|()
expr_stmt|;
for|for
control|(
name|TableInfo
name|tInfo
range|:
name|tablesInfo
operator|.
name|values
argument_list|()
control|)
block|{
name|TableIntegrityErrorHandler
name|handler
decl_stmt|;
if|if
condition|(
name|fixHoles
operator|||
name|fixOverlaps
condition|)
block|{
name|handler
operator|=
name|tInfo
operator|.
expr|new
name|HDFSIntegrityFixer
argument_list|(
name|tInfo
argument_list|,
name|errors
argument_list|,
name|getConf
argument_list|()
argument_list|,
name|fixHoles
argument_list|,
name|fixOverlaps
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|handler
operator|=
name|tInfo
operator|.
expr|new
name|IntegrityFixSuggester
argument_list|(
name|tInfo
argument_list|,
name|errors
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|!
name|tInfo
operator|.
name|checkRegionChain
argument_list|(
name|handler
argument_list|)
condition|)
block|{
comment|// should dump info as well.
name|errors
operator|.
name|report
argument_list|(
literal|"Found inconsistency in table "
operator|+
name|tInfo
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|tablesInfo
return|;
block|}
specifier|private
name|Path
name|getSidelineDir
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|sidelineDir
operator|==
literal|null
condition|)
block|{
name|Path
name|hbaseDir
init|=
name|FSUtils
operator|.
name|getRootDir
argument_list|(
name|getConf
argument_list|()
argument_list|)
decl_stmt|;
name|Path
name|hbckDir
init|=
operator|new
name|Path
argument_list|(
name|hbaseDir
argument_list|,
name|HConstants
operator|.
name|HBCK_SIDELINEDIR_NAME
argument_list|)
decl_stmt|;
name|sidelineDir
operator|=
operator|new
name|Path
argument_list|(
name|hbckDir
argument_list|,
name|hbaseDir
operator|.
name|getName
argument_list|()
operator|+
literal|"-"
operator|+
name|startMillis
argument_list|)
expr_stmt|;
block|}
return|return
name|sidelineDir
return|;
block|}
comment|/**    * Sideline a region dir (instead of deleting it)    */
name|Path
name|sidelineRegionDir
parameter_list|(
name|FileSystem
name|fs
parameter_list|,
name|HbckInfo
name|hi
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|sidelineRegionDir
argument_list|(
name|fs
argument_list|,
literal|null
argument_list|,
name|hi
argument_list|)
return|;
block|}
comment|/**    * Sideline a region dir (instead of deleting it)    *    * @param parentDir if specified, the region will be sidelined to folder like    *     {@literal .../parentDir/<table name>/<region name>}. The purpose is to group together    *     similar regions sidelined, for example, those regions should be bulk loaded back later    *     on. If NULL, it is ignored.    */
name|Path
name|sidelineRegionDir
parameter_list|(
name|FileSystem
name|fs
parameter_list|,
name|String
name|parentDir
parameter_list|,
name|HbckInfo
name|hi
parameter_list|)
throws|throws
name|IOException
block|{
name|TableName
name|tableName
init|=
name|hi
operator|.
name|getTableName
argument_list|()
decl_stmt|;
name|Path
name|regionDir
init|=
name|hi
operator|.
name|getHdfsRegionDir
argument_list|()
decl_stmt|;
if|if
condition|(
operator|!
name|fs
operator|.
name|exists
argument_list|(
name|regionDir
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"No previous "
operator|+
name|regionDir
operator|+
literal|" exists.  Continuing."
argument_list|)
expr_stmt|;
return|return
literal|null
return|;
block|}
name|Path
name|rootDir
init|=
name|getSidelineDir
argument_list|()
decl_stmt|;
if|if
condition|(
name|parentDir
operator|!=
literal|null
condition|)
block|{
name|rootDir
operator|=
operator|new
name|Path
argument_list|(
name|rootDir
argument_list|,
name|parentDir
argument_list|)
expr_stmt|;
block|}
name|Path
name|sidelineTableDir
init|=
name|FSUtils
operator|.
name|getTableDir
argument_list|(
name|rootDir
argument_list|,
name|tableName
argument_list|)
decl_stmt|;
name|Path
name|sidelineRegionDir
init|=
operator|new
name|Path
argument_list|(
name|sidelineTableDir
argument_list|,
name|regionDir
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
name|fs
operator|.
name|mkdirs
argument_list|(
name|sidelineRegionDir
argument_list|)
expr_stmt|;
name|boolean
name|success
init|=
literal|false
decl_stmt|;
name|FileStatus
index|[]
name|cfs
init|=
name|fs
operator|.
name|listStatus
argument_list|(
name|regionDir
argument_list|)
decl_stmt|;
if|if
condition|(
name|cfs
operator|==
literal|null
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Region dir is empty: "
operator|+
name|regionDir
argument_list|)
expr_stmt|;
block|}
else|else
block|{
for|for
control|(
name|FileStatus
name|cf
range|:
name|cfs
control|)
block|{
name|Path
name|src
init|=
name|cf
operator|.
name|getPath
argument_list|()
decl_stmt|;
name|Path
name|dst
init|=
operator|new
name|Path
argument_list|(
name|sidelineRegionDir
argument_list|,
name|src
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|fs
operator|.
name|isFile
argument_list|(
name|src
argument_list|)
condition|)
block|{
comment|// simple file
name|success
operator|=
name|fs
operator|.
name|rename
argument_list|(
name|src
argument_list|,
name|dst
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|success
condition|)
block|{
name|String
name|msg
init|=
literal|"Unable to rename file "
operator|+
name|src
operator|+
literal|" to "
operator|+
name|dst
decl_stmt|;
name|LOG
operator|.
name|error
argument_list|(
name|msg
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|IOException
argument_list|(
name|msg
argument_list|)
throw|;
block|}
continue|continue;
block|}
comment|// is a directory.
name|fs
operator|.
name|mkdirs
argument_list|(
name|dst
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Sidelining files from "
operator|+
name|src
operator|+
literal|" into containing region "
operator|+
name|dst
argument_list|)
expr_stmt|;
comment|// FileSystem.rename is inconsistent with directories -- if the
comment|// dst (foo/a) exists and is a dir, and the src (foo/b) is a dir,
comment|// it moves the src into the dst dir resulting in (foo/a/b).  If
comment|// the dst does not exist, and the src a dir, src becomes dst. (foo/b)
name|FileStatus
index|[]
name|hfiles
init|=
name|fs
operator|.
name|listStatus
argument_list|(
name|src
argument_list|)
decl_stmt|;
if|if
condition|(
name|hfiles
operator|!=
literal|null
operator|&&
name|hfiles
operator|.
name|length
operator|>
literal|0
condition|)
block|{
for|for
control|(
name|FileStatus
name|hfile
range|:
name|hfiles
control|)
block|{
name|success
operator|=
name|fs
operator|.
name|rename
argument_list|(
name|hfile
operator|.
name|getPath
argument_list|()
argument_list|,
name|dst
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|success
condition|)
block|{
name|String
name|msg
init|=
literal|"Unable to rename file "
operator|+
name|src
operator|+
literal|" to "
operator|+
name|dst
decl_stmt|;
name|LOG
operator|.
name|error
argument_list|(
name|msg
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|IOException
argument_list|(
name|msg
argument_list|)
throw|;
block|}
block|}
block|}
name|LOG
operator|.
name|debug
argument_list|(
literal|"Sideline directory contents:"
argument_list|)
expr_stmt|;
name|debugLsr
argument_list|(
name|sidelineRegionDir
argument_list|)
expr_stmt|;
block|}
block|}
name|LOG
operator|.
name|info
argument_list|(
literal|"Removing old region dir: "
operator|+
name|regionDir
argument_list|)
expr_stmt|;
name|success
operator|=
name|fs
operator|.
name|delete
argument_list|(
name|regionDir
argument_list|,
literal|true
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|success
condition|)
block|{
name|String
name|msg
init|=
literal|"Unable to delete dir "
operator|+
name|regionDir
decl_stmt|;
name|LOG
operator|.
name|error
argument_list|(
name|msg
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|IOException
argument_list|(
name|msg
argument_list|)
throw|;
block|}
return|return
name|sidelineRegionDir
return|;
block|}
comment|/**    * Side line an entire table.    */
name|void
name|sidelineTable
parameter_list|(
name|FileSystem
name|fs
parameter_list|,
name|TableName
name|tableName
parameter_list|,
name|Path
name|hbaseDir
parameter_list|,
name|Path
name|backupHbaseDir
parameter_list|)
throws|throws
name|IOException
block|{
name|Path
name|tableDir
init|=
name|FSUtils
operator|.
name|getTableDir
argument_list|(
name|hbaseDir
argument_list|,
name|tableName
argument_list|)
decl_stmt|;
if|if
condition|(
name|fs
operator|.
name|exists
argument_list|(
name|tableDir
argument_list|)
condition|)
block|{
name|Path
name|backupTableDir
init|=
name|FSUtils
operator|.
name|getTableDir
argument_list|(
name|backupHbaseDir
argument_list|,
name|tableName
argument_list|)
decl_stmt|;
name|fs
operator|.
name|mkdirs
argument_list|(
name|backupTableDir
operator|.
name|getParent
argument_list|()
argument_list|)
expr_stmt|;
name|boolean
name|success
init|=
name|fs
operator|.
name|rename
argument_list|(
name|tableDir
argument_list|,
name|backupTableDir
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|success
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Failed to move  "
operator|+
name|tableName
operator|+
literal|" from "
operator|+
name|tableDir
operator|+
literal|" to "
operator|+
name|backupTableDir
argument_list|)
throw|;
block|}
block|}
else|else
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"No previous "
operator|+
name|tableName
operator|+
literal|" exists.  Continuing."
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * @return Path to backup of original directory    */
name|Path
name|sidelineOldMeta
parameter_list|()
throws|throws
name|IOException
block|{
comment|// put current hbase:meta aside.
name|Path
name|hbaseDir
init|=
name|FSUtils
operator|.
name|getRootDir
argument_list|(
name|getConf
argument_list|()
argument_list|)
decl_stmt|;
name|FileSystem
name|fs
init|=
name|hbaseDir
operator|.
name|getFileSystem
argument_list|(
name|getConf
argument_list|()
argument_list|)
decl_stmt|;
name|Path
name|backupDir
init|=
name|getSidelineDir
argument_list|()
decl_stmt|;
name|fs
operator|.
name|mkdirs
argument_list|(
name|backupDir
argument_list|)
expr_stmt|;
try|try
block|{
name|sidelineTable
argument_list|(
name|fs
argument_list|,
name|TableName
operator|.
name|META_TABLE_NAME
argument_list|,
name|hbaseDir
argument_list|,
name|backupDir
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|HBaseMarkers
operator|.
name|FATAL
argument_list|,
literal|"... failed to sideline meta. Currently in "
operator|+
literal|"inconsistent state.  To restore try to rename hbase:meta in "
operator|+
name|backupDir
operator|.
name|getName
argument_list|()
operator|+
literal|" to "
operator|+
name|hbaseDir
operator|.
name|getName
argument_list|()
operator|+
literal|"."
argument_list|,
name|e
argument_list|)
expr_stmt|;
throw|throw
name|e
throw|;
comment|// throw original exception
block|}
return|return
name|backupDir
return|;
block|}
comment|/**    * Load the list of disabled tables in ZK into local set.    * @throws ZooKeeperConnectionException    * @throws IOException    */
specifier|private
name|void
name|loadTableStates
parameter_list|()
throws|throws
name|IOException
block|{
name|tableStates
operator|=
name|MetaTableAccessor
operator|.
name|getTableStates
argument_list|(
name|connection
argument_list|)
expr_stmt|;
comment|// Add hbase:meta so this tool keeps working. In hbase2, meta is always enabled though it
comment|// has no entry in the table states. HBCK doesn't work right w/ hbase2 but just do this in
comment|// meantime.
name|this
operator|.
name|tableStates
operator|.
name|put
argument_list|(
name|TableName
operator|.
name|META_TABLE_NAME
argument_list|,
operator|new
name|TableState
argument_list|(
name|TableName
operator|.
name|META_TABLE_NAME
argument_list|,
name|TableState
operator|.
name|State
operator|.
name|ENABLED
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|/**    * Check if the specified region's table is disabled.    * @param tableName table to check status of    */
specifier|private
name|boolean
name|isTableDisabled
parameter_list|(
name|TableName
name|tableName
parameter_list|)
block|{
return|return
name|tableStates
operator|.
name|containsKey
argument_list|(
name|tableName
argument_list|)
operator|&&
name|tableStates
operator|.
name|get
argument_list|(
name|tableName
argument_list|)
operator|.
name|inStates
argument_list|(
name|TableState
operator|.
name|State
operator|.
name|DISABLED
argument_list|,
name|TableState
operator|.
name|State
operator|.
name|DISABLING
argument_list|)
return|;
block|}
comment|/**    * Scan HDFS for all regions, recording their information into    * regionInfoMap    */
specifier|public
name|void
name|loadHdfsRegionDirs
parameter_list|()
throws|throws
name|IOException
throws|,
name|InterruptedException
block|{
name|Path
name|rootDir
init|=
name|FSUtils
operator|.
name|getRootDir
argument_list|(
name|getConf
argument_list|()
argument_list|)
decl_stmt|;
name|FileSystem
name|fs
init|=
name|rootDir
operator|.
name|getFileSystem
argument_list|(
name|getConf
argument_list|()
argument_list|)
decl_stmt|;
comment|// list all tables from HDFS
name|List
argument_list|<
name|FileStatus
argument_list|>
name|tableDirs
init|=
name|Lists
operator|.
name|newArrayList
argument_list|()
decl_stmt|;
name|boolean
name|foundVersionFile
init|=
name|fs
operator|.
name|exists
argument_list|(
operator|new
name|Path
argument_list|(
name|rootDir
argument_list|,
name|HConstants
operator|.
name|VERSION_FILE_NAME
argument_list|)
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|Path
argument_list|>
name|paths
init|=
name|FSUtils
operator|.
name|getTableDirs
argument_list|(
name|fs
argument_list|,
name|rootDir
argument_list|)
decl_stmt|;
for|for
control|(
name|Path
name|path
range|:
name|paths
control|)
block|{
name|TableName
name|tableName
init|=
name|FSUtils
operator|.
name|getTableName
argument_list|(
name|path
argument_list|)
decl_stmt|;
if|if
condition|(
operator|(
operator|!
name|checkMetaOnly
operator|&&
name|isTableIncluded
argument_list|(
name|tableName
argument_list|)
operator|)
operator|||
name|tableName
operator|.
name|equals
argument_list|(
name|TableName
operator|.
name|META_TABLE_NAME
argument_list|)
condition|)
block|{
name|tableDirs
operator|.
name|add
argument_list|(
name|fs
operator|.
name|getFileStatus
argument_list|(
name|path
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
comment|// verify that version file exists
if|if
condition|(
operator|!
name|foundVersionFile
condition|)
block|{
name|errors
operator|.
name|reportError
argument_list|(
name|ERROR_CODE
operator|.
name|NO_VERSION_FILE
argument_list|,
literal|"Version file does not exist in root dir "
operator|+
name|rootDir
argument_list|)
expr_stmt|;
if|if
condition|(
name|shouldFixVersionFile
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Trying to create a new "
operator|+
name|HConstants
operator|.
name|VERSION_FILE_NAME
operator|+
literal|" file."
argument_list|)
expr_stmt|;
name|setShouldRerun
argument_list|()
expr_stmt|;
name|FSUtils
operator|.
name|setVersion
argument_list|(
name|fs
argument_list|,
name|rootDir
argument_list|,
name|getConf
argument_list|()
operator|.
name|getInt
argument_list|(
name|HConstants
operator|.
name|THREAD_WAKE_FREQUENCY
argument_list|,
literal|10
operator|*
literal|1000
argument_list|)
argument_list|,
name|getConf
argument_list|()
operator|.
name|getInt
argument_list|(
name|HConstants
operator|.
name|VERSION_FILE_WRITE_ATTEMPTS
argument_list|,
name|HConstants
operator|.
name|DEFAULT_VERSION_FILE_WRITE_ATTEMPTS
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
comment|// Avoid multithreading at table-level because already multithreaded internally at
comment|// region-level.  Additionally multithreading at table-level can lead to deadlock
comment|// if there are many tables in the cluster.  Since there are a limited # of threads
comment|// in the executor's thread pool and if we multithread at the table-level by putting
comment|// WorkItemHdfsDir callables into the executor, then we will have some threads in the
comment|// executor tied up solely in waiting for the tables' region-level calls to complete.
comment|// If there are enough tables then there will be no actual threads in the pool left
comment|// for the region-level callables to be serviced.
for|for
control|(
name|FileStatus
name|tableDir
range|:
name|tableDirs
control|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Loading region dirs from "
operator|+
name|tableDir
operator|.
name|getPath
argument_list|()
argument_list|)
expr_stmt|;
name|WorkItemHdfsDir
name|item
init|=
operator|new
name|WorkItemHdfsDir
argument_list|(
name|fs
argument_list|,
name|errors
argument_list|,
name|tableDir
argument_list|)
decl_stmt|;
try|try
block|{
name|item
operator|.
name|call
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|ExecutionException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Could not completely load table dir "
operator|+
name|tableDir
operator|.
name|getPath
argument_list|()
argument_list|,
name|e
operator|.
name|getCause
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
name|errors
operator|.
name|print
argument_list|(
literal|""
argument_list|)
expr_stmt|;
block|}
comment|/**    * Record the location of the hbase:meta region as found in ZooKeeper.    */
specifier|private
name|boolean
name|recordMetaRegion
parameter_list|()
throws|throws
name|IOException
block|{
name|RegionLocations
name|rl
init|=
name|connection
operator|.
name|locateRegion
argument_list|(
name|TableName
operator|.
name|META_TABLE_NAME
argument_list|,
name|HConstants
operator|.
name|EMPTY_START_ROW
argument_list|,
literal|false
argument_list|,
literal|false
argument_list|)
decl_stmt|;
if|if
condition|(
name|rl
operator|==
literal|null
condition|)
block|{
name|errors
operator|.
name|reportError
argument_list|(
name|ERROR_CODE
operator|.
name|NULL_META_REGION
argument_list|,
literal|"META region was not found in ZooKeeper"
argument_list|)
expr_stmt|;
return|return
literal|false
return|;
block|}
for|for
control|(
name|HRegionLocation
name|metaLocation
range|:
name|rl
operator|.
name|getRegionLocations
argument_list|()
control|)
block|{
comment|// Check if Meta region is valid and existing
if|if
condition|(
name|metaLocation
operator|==
literal|null
condition|)
block|{
name|errors
operator|.
name|reportError
argument_list|(
name|ERROR_CODE
operator|.
name|NULL_META_REGION
argument_list|,
literal|"META region location is null"
argument_list|)
expr_stmt|;
return|return
literal|false
return|;
block|}
if|if
condition|(
name|metaLocation
operator|.
name|getRegionInfo
argument_list|()
operator|==
literal|null
condition|)
block|{
name|errors
operator|.
name|reportError
argument_list|(
name|ERROR_CODE
operator|.
name|NULL_META_REGION
argument_list|,
literal|"META location regionInfo is null"
argument_list|)
expr_stmt|;
return|return
literal|false
return|;
block|}
if|if
condition|(
name|metaLocation
operator|.
name|getHostname
argument_list|()
operator|==
literal|null
condition|)
block|{
name|errors
operator|.
name|reportError
argument_list|(
name|ERROR_CODE
operator|.
name|NULL_META_REGION
argument_list|,
literal|"META location hostName is null"
argument_list|)
expr_stmt|;
return|return
literal|false
return|;
block|}
name|ServerName
name|sn
init|=
name|metaLocation
operator|.
name|getServerName
argument_list|()
decl_stmt|;
name|MetaEntry
name|m
init|=
operator|new
name|MetaEntry
argument_list|(
name|metaLocation
operator|.
name|getRegionInfo
argument_list|()
argument_list|,
name|sn
argument_list|,
name|EnvironmentEdgeManager
operator|.
name|currentTime
argument_list|()
argument_list|)
decl_stmt|;
name|HbckInfo
name|hbckInfo
init|=
name|regionInfoMap
operator|.
name|get
argument_list|(
name|metaLocation
operator|.
name|getRegionInfo
argument_list|()
operator|.
name|getEncodedName
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|hbckInfo
operator|==
literal|null
condition|)
block|{
name|regionInfoMap
operator|.
name|put
argument_list|(
name|metaLocation
operator|.
name|getRegionInfo
argument_list|()
operator|.
name|getEncodedName
argument_list|()
argument_list|,
operator|new
name|HbckInfo
argument_list|(
name|m
argument_list|)
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|hbckInfo
operator|.
name|metaEntry
operator|=
name|m
expr_stmt|;
block|}
block|}
return|return
literal|true
return|;
block|}
specifier|private
name|ZKWatcher
name|createZooKeeperWatcher
parameter_list|()
throws|throws
name|IOException
block|{
return|return
operator|new
name|ZKWatcher
argument_list|(
name|getConf
argument_list|()
argument_list|,
literal|"hbase Fsck"
argument_list|,
operator|new
name|Abortable
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|void
name|abort
parameter_list|(
name|String
name|why
parameter_list|,
name|Throwable
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|why
argument_list|,
name|e
argument_list|)
expr_stmt|;
name|System
operator|.
name|exit
argument_list|(
literal|1
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|isAborted
parameter_list|()
block|{
return|return
literal|false
return|;
block|}
block|}
argument_list|)
return|;
block|}
specifier|private
name|ServerName
name|getMetaRegionServerName
parameter_list|(
name|int
name|replicaId
parameter_list|)
throws|throws
name|IOException
throws|,
name|KeeperException
block|{
return|return
operator|new
name|MetaTableLocator
argument_list|()
operator|.
name|getMetaRegionLocation
argument_list|(
name|zkw
argument_list|,
name|replicaId
argument_list|)
return|;
block|}
comment|/**    * Contacts each regionserver and fetches metadata about regions.    * @param regionServerList - the list of region servers to connect to    * @throws IOException if a remote or network exception occurs    */
name|void
name|processRegionServers
parameter_list|(
name|Collection
argument_list|<
name|ServerName
argument_list|>
name|regionServerList
parameter_list|)
throws|throws
name|IOException
throws|,
name|InterruptedException
block|{
name|List
argument_list|<
name|WorkItemRegion
argument_list|>
name|workItems
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
name|regionServerList
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|Future
argument_list|<
name|Void
argument_list|>
argument_list|>
name|workFutures
decl_stmt|;
comment|// loop to contact each region server in parallel
for|for
control|(
name|ServerName
name|rsinfo
range|:
name|regionServerList
control|)
block|{
name|workItems
operator|.
name|add
argument_list|(
operator|new
name|WorkItemRegion
argument_list|(
name|this
argument_list|,
name|rsinfo
argument_list|,
name|errors
argument_list|,
name|connection
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|workFutures
operator|=
name|executor
operator|.
name|invokeAll
argument_list|(
name|workItems
argument_list|)
expr_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|workFutures
operator|.
name|size
argument_list|()
condition|;
name|i
operator|++
control|)
block|{
name|WorkItemRegion
name|item
init|=
name|workItems
operator|.
name|get
argument_list|(
name|i
argument_list|)
decl_stmt|;
name|Future
argument_list|<
name|Void
argument_list|>
name|f
init|=
name|workFutures
operator|.
name|get
argument_list|(
name|i
argument_list|)
decl_stmt|;
try|try
block|{
name|f
operator|.
name|get
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|ExecutionException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Could not process regionserver "
operator|+
name|item
operator|.
name|rsinfo
operator|.
name|getHostAndPort
argument_list|()
argument_list|,
name|e
operator|.
name|getCause
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|/**    * Check consistency of all regions that have been found in previous phases.    */
specifier|private
name|void
name|checkAndFixConsistency
parameter_list|()
throws|throws
name|IOException
throws|,
name|KeeperException
throws|,
name|InterruptedException
block|{
comment|// Divide the checks in two phases. One for default/primary replicas and another
comment|// for the non-primary ones. Keeps code cleaner this way.
name|List
argument_list|<
name|CheckRegionConsistencyWorkItem
argument_list|>
name|workItems
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
name|regionInfoMap
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
for|for
control|(
name|java
operator|.
name|util
operator|.
name|Map
operator|.
name|Entry
argument_list|<
name|String
argument_list|,
name|HbckInfo
argument_list|>
name|e
range|:
name|regionInfoMap
operator|.
name|entrySet
argument_list|()
control|)
block|{
if|if
condition|(
name|e
operator|.
name|getValue
argument_list|()
operator|.
name|getReplicaId
argument_list|()
operator|==
name|RegionInfo
operator|.
name|DEFAULT_REPLICA_ID
condition|)
block|{
name|workItems
operator|.
name|add
argument_list|(
operator|new
name|CheckRegionConsistencyWorkItem
argument_list|(
name|e
operator|.
name|getKey
argument_list|()
argument_list|,
name|e
operator|.
name|getValue
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
name|checkRegionConsistencyConcurrently
argument_list|(
name|workItems
argument_list|)
expr_stmt|;
name|boolean
name|prevHdfsCheck
init|=
name|shouldCheckHdfs
argument_list|()
decl_stmt|;
name|setCheckHdfs
argument_list|(
literal|false
argument_list|)
expr_stmt|;
comment|//replicas don't have any hdfs data
comment|// Run a pass over the replicas and fix any assignment issues that exist on the currently
comment|// deployed/undeployed replicas.
name|List
argument_list|<
name|CheckRegionConsistencyWorkItem
argument_list|>
name|replicaWorkItems
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
name|regionInfoMap
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
for|for
control|(
name|java
operator|.
name|util
operator|.
name|Map
operator|.
name|Entry
argument_list|<
name|String
argument_list|,
name|HbckInfo
argument_list|>
name|e
range|:
name|regionInfoMap
operator|.
name|entrySet
argument_list|()
control|)
block|{
if|if
condition|(
name|e
operator|.
name|getValue
argument_list|()
operator|.
name|getReplicaId
argument_list|()
operator|!=
name|RegionInfo
operator|.
name|DEFAULT_REPLICA_ID
condition|)
block|{
name|replicaWorkItems
operator|.
name|add
argument_list|(
operator|new
name|CheckRegionConsistencyWorkItem
argument_list|(
name|e
operator|.
name|getKey
argument_list|()
argument_list|,
name|e
operator|.
name|getValue
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
name|checkRegionConsistencyConcurrently
argument_list|(
name|replicaWorkItems
argument_list|)
expr_stmt|;
name|setCheckHdfs
argument_list|(
name|prevHdfsCheck
argument_list|)
expr_stmt|;
comment|// If some regions is skipped during checkRegionConsistencyConcurrently() phase, we might
comment|// not get accurate state of the hbase if continuing. The config here allows users to tune
comment|// the tolerance of number of skipped region.
comment|// TODO: evaluate the consequence to continue the hbck operation without config.
name|int
name|terminateThreshold
init|=
name|getConf
argument_list|()
operator|.
name|getInt
argument_list|(
literal|"hbase.hbck.skipped.regions.limit"
argument_list|,
literal|0
argument_list|)
decl_stmt|;
name|int
name|numOfSkippedRegions
init|=
name|skippedRegions
operator|.
name|size
argument_list|()
decl_stmt|;
if|if
condition|(
name|numOfSkippedRegions
operator|>
literal|0
operator|&&
name|numOfSkippedRegions
operator|>
name|terminateThreshold
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|numOfSkippedRegions
operator|+
literal|" region(s) could not be checked or repaired.  See logs for detail."
argument_list|)
throw|;
block|}
if|if
condition|(
name|shouldCheckHdfs
argument_list|()
condition|)
block|{
name|checkAndFixTableStates
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**    * Check consistency of all regions using mulitple threads concurrently.    */
specifier|private
name|void
name|checkRegionConsistencyConcurrently
parameter_list|(
specifier|final
name|List
argument_list|<
name|CheckRegionConsistencyWorkItem
argument_list|>
name|workItems
parameter_list|)
throws|throws
name|IOException
throws|,
name|KeeperException
throws|,
name|InterruptedException
block|{
if|if
condition|(
name|workItems
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
return|return;
comment|// nothing to check
block|}
name|List
argument_list|<
name|Future
argument_list|<
name|Void
argument_list|>
argument_list|>
name|workFutures
init|=
name|executor
operator|.
name|invokeAll
argument_list|(
name|workItems
argument_list|)
decl_stmt|;
for|for
control|(
name|Future
argument_list|<
name|Void
argument_list|>
name|f
range|:
name|workFutures
control|)
block|{
try|try
block|{
name|f
operator|.
name|get
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|ExecutionException
name|e1
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Could not check region consistency "
argument_list|,
name|e1
operator|.
name|getCause
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|e1
operator|.
name|getCause
argument_list|()
operator|instanceof
name|IOException
condition|)
block|{
throw|throw
operator|(
name|IOException
operator|)
name|e1
operator|.
name|getCause
argument_list|()
throw|;
block|}
elseif|else
if|if
condition|(
name|e1
operator|.
name|getCause
argument_list|()
operator|instanceof
name|KeeperException
condition|)
block|{
throw|throw
operator|(
name|KeeperException
operator|)
name|e1
operator|.
name|getCause
argument_list|()
throw|;
block|}
elseif|else
if|if
condition|(
name|e1
operator|.
name|getCause
argument_list|()
operator|instanceof
name|InterruptedException
condition|)
block|{
throw|throw
operator|(
name|InterruptedException
operator|)
name|e1
operator|.
name|getCause
argument_list|()
throw|;
block|}
else|else
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|e1
operator|.
name|getCause
argument_list|()
argument_list|)
throw|;
block|}
block|}
block|}
block|}
class|class
name|CheckRegionConsistencyWorkItem
implements|implements
name|Callable
argument_list|<
name|Void
argument_list|>
block|{
specifier|private
specifier|final
name|String
name|key
decl_stmt|;
specifier|private
specifier|final
name|HbckInfo
name|hbi
decl_stmt|;
name|CheckRegionConsistencyWorkItem
parameter_list|(
name|String
name|key
parameter_list|,
name|HbckInfo
name|hbi
parameter_list|)
block|{
name|this
operator|.
name|key
operator|=
name|key
expr_stmt|;
name|this
operator|.
name|hbi
operator|=
name|hbi
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
specifier|synchronized
name|Void
name|call
parameter_list|()
throws|throws
name|Exception
block|{
try|try
block|{
name|checkRegionConsistency
argument_list|(
name|key
argument_list|,
name|hbi
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
comment|// If the region is non-META region, skip this region and send warning/error message; if
comment|// the region is META region, we should not continue.
name|LOG
operator|.
name|warn
argument_list|(
literal|"Unable to complete check or repair the region '"
operator|+
name|hbi
operator|.
name|getRegionNameAsString
argument_list|()
operator|+
literal|"'."
argument_list|,
name|e
argument_list|)
expr_stmt|;
if|if
condition|(
name|hbi
operator|.
name|getHdfsHRI
argument_list|()
operator|.
name|isMetaRegion
argument_list|()
condition|)
block|{
throw|throw
name|e
throw|;
block|}
name|LOG
operator|.
name|warn
argument_list|(
literal|"Skip region '"
operator|+
name|hbi
operator|.
name|getRegionNameAsString
argument_list|()
operator|+
literal|"'"
argument_list|)
expr_stmt|;
name|addSkippedRegion
argument_list|(
name|hbi
argument_list|)
expr_stmt|;
block|}
return|return
literal|null
return|;
block|}
block|}
specifier|private
name|void
name|addSkippedRegion
parameter_list|(
specifier|final
name|HbckInfo
name|hbi
parameter_list|)
block|{
name|Set
argument_list|<
name|String
argument_list|>
name|skippedRegionNames
init|=
name|skippedRegions
operator|.
name|get
argument_list|(
name|hbi
operator|.
name|getTableName
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|skippedRegionNames
operator|==
literal|null
condition|)
block|{
name|skippedRegionNames
operator|=
operator|new
name|HashSet
argument_list|<>
argument_list|()
expr_stmt|;
block|}
name|skippedRegionNames
operator|.
name|add
argument_list|(
name|hbi
operator|.
name|getRegionNameAsString
argument_list|()
argument_list|)
expr_stmt|;
name|skippedRegions
operator|.
name|put
argument_list|(
name|hbi
operator|.
name|getTableName
argument_list|()
argument_list|,
name|skippedRegionNames
argument_list|)
expr_stmt|;
block|}
comment|/**    * Check and fix table states, assumes full info available:    * - tableInfos    * - empty tables loaded    */
specifier|private
name|void
name|checkAndFixTableStates
parameter_list|()
throws|throws
name|IOException
block|{
comment|// first check dangling states
for|for
control|(
name|Entry
argument_list|<
name|TableName
argument_list|,
name|TableState
argument_list|>
name|entry
range|:
name|tableStates
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|TableName
name|tableName
init|=
name|entry
operator|.
name|getKey
argument_list|()
decl_stmt|;
name|TableState
name|tableState
init|=
name|entry
operator|.
name|getValue
argument_list|()
decl_stmt|;
name|TableInfo
name|tableInfo
init|=
name|tablesInfo
operator|.
name|get
argument_list|(
name|tableName
argument_list|)
decl_stmt|;
if|if
condition|(
name|isTableIncluded
argument_list|(
name|tableName
argument_list|)
operator|&&
operator|!
name|tableName
operator|.
name|isSystemTable
argument_list|()
operator|&&
name|tableInfo
operator|==
literal|null
condition|)
block|{
if|if
condition|(
name|fixMeta
condition|)
block|{
name|MetaTableAccessor
operator|.
name|deleteTableState
argument_list|(
name|connection
argument_list|,
name|tableName
argument_list|)
expr_stmt|;
name|TableState
name|state
init|=
name|MetaTableAccessor
operator|.
name|getTableState
argument_list|(
name|connection
argument_list|,
name|tableName
argument_list|)
decl_stmt|;
if|if
condition|(
name|state
operator|!=
literal|null
condition|)
block|{
name|errors
operator|.
name|reportError
argument_list|(
name|ERROR_CODE
operator|.
name|ORPHAN_TABLE_STATE
argument_list|,
name|tableName
operator|+
literal|" unable to delete dangling table state "
operator|+
name|tableState
argument_list|)
expr_stmt|;
block|}
block|}
elseif|else
if|if
condition|(
operator|!
name|checkMetaOnly
condition|)
block|{
comment|// dangling table state in meta if checkMetaOnly is false. If checkMetaOnly is
comment|// true, tableInfo will be null as tablesInfo are not polulated for all tables from hdfs
name|errors
operator|.
name|reportError
argument_list|(
name|ERROR_CODE
operator|.
name|ORPHAN_TABLE_STATE
argument_list|,
name|tableName
operator|+
literal|" has dangling table state "
operator|+
name|tableState
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|// check that all tables have states
for|for
control|(
name|TableName
name|tableName
range|:
name|tablesInfo
operator|.
name|keySet
argument_list|()
control|)
block|{
if|if
condition|(
name|isTableIncluded
argument_list|(
name|tableName
argument_list|)
operator|&&
operator|!
name|tableStates
operator|.
name|containsKey
argument_list|(
name|tableName
argument_list|)
condition|)
block|{
if|if
condition|(
name|fixMeta
condition|)
block|{
name|MetaTableAccessor
operator|.
name|updateTableState
argument_list|(
name|connection
argument_list|,
name|tableName
argument_list|,
name|TableState
operator|.
name|State
operator|.
name|ENABLED
argument_list|)
expr_stmt|;
name|TableState
name|newState
init|=
name|MetaTableAccessor
operator|.
name|getTableState
argument_list|(
name|connection
argument_list|,
name|tableName
argument_list|)
decl_stmt|;
if|if
condition|(
name|newState
operator|==
literal|null
condition|)
block|{
name|errors
operator|.
name|reportError
argument_list|(
name|ERROR_CODE
operator|.
name|NO_TABLE_STATE
argument_list|,
literal|"Unable to change state for table "
operator|+
name|tableName
operator|+
literal|" in meta "
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
name|errors
operator|.
name|reportError
argument_list|(
name|ERROR_CODE
operator|.
name|NO_TABLE_STATE
argument_list|,
name|tableName
operator|+
literal|" has no state in meta "
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
specifier|private
name|void
name|preCheckPermission
parameter_list|()
throws|throws
name|IOException
throws|,
name|AccessDeniedException
block|{
if|if
condition|(
name|shouldIgnorePreCheckPermission
argument_list|()
condition|)
block|{
return|return;
block|}
name|Path
name|hbaseDir
init|=
name|FSUtils
operator|.
name|getRootDir
argument_list|(
name|getConf
argument_list|()
argument_list|)
decl_stmt|;
name|FileSystem
name|fs
init|=
name|hbaseDir
operator|.
name|getFileSystem
argument_list|(
name|getConf
argument_list|()
argument_list|)
decl_stmt|;
name|UserProvider
name|userProvider
init|=
name|UserProvider
operator|.
name|instantiate
argument_list|(
name|getConf
argument_list|()
argument_list|)
decl_stmt|;
name|UserGroupInformation
name|ugi
init|=
name|userProvider
operator|.
name|getCurrent
argument_list|()
operator|.
name|getUGI
argument_list|()
decl_stmt|;
name|FileStatus
index|[]
name|files
init|=
name|fs
operator|.
name|listStatus
argument_list|(
name|hbaseDir
argument_list|)
decl_stmt|;
for|for
control|(
name|FileStatus
name|file
range|:
name|files
control|)
block|{
try|try
block|{
name|FSUtils
operator|.
name|checkAccess
argument_list|(
name|ugi
argument_list|,
name|file
argument_list|,
name|FsAction
operator|.
name|WRITE
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|AccessDeniedException
name|ace
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Got AccessDeniedException when preCheckPermission "
argument_list|,
name|ace
argument_list|)
expr_stmt|;
name|errors
operator|.
name|reportError
argument_list|(
name|ERROR_CODE
operator|.
name|WRONG_USAGE
argument_list|,
literal|"Current user "
operator|+
name|ugi
operator|.
name|getUserName
argument_list|()
operator|+
literal|" does not have write perms to "
operator|+
name|file
operator|.
name|getPath
argument_list|()
operator|+
literal|". Please rerun hbck as hdfs user "
operator|+
name|file
operator|.
name|getOwner
argument_list|()
argument_list|)
expr_stmt|;
throw|throw
name|ace
throw|;
block|}
block|}
block|}
comment|/**    * Deletes region from meta table    */
specifier|private
name|void
name|deleteMetaRegion
parameter_list|(
name|HbckInfo
name|hi
parameter_list|)
throws|throws
name|IOException
block|{
name|deleteMetaRegion
argument_list|(
name|hi
operator|.
name|metaEntry
operator|.
name|getRegionName
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|/**    * Deletes region from meta table    */
specifier|private
name|void
name|deleteMetaRegion
parameter_list|(
name|byte
index|[]
name|metaKey
parameter_list|)
throws|throws
name|IOException
block|{
name|Delete
name|d
init|=
operator|new
name|Delete
argument_list|(
name|metaKey
argument_list|)
decl_stmt|;
name|meta
operator|.
name|delete
argument_list|(
name|d
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Deleted "
operator|+
name|Bytes
operator|.
name|toString
argument_list|(
name|metaKey
argument_list|)
operator|+
literal|" from META"
argument_list|)
expr_stmt|;
block|}
comment|/**    * Reset the split parent region info in meta table    */
specifier|private
name|void
name|resetSplitParent
parameter_list|(
name|HbckInfo
name|hi
parameter_list|)
throws|throws
name|IOException
block|{
name|RowMutations
name|mutations
init|=
operator|new
name|RowMutations
argument_list|(
name|hi
operator|.
name|metaEntry
operator|.
name|getRegionName
argument_list|()
argument_list|)
decl_stmt|;
name|Delete
name|d
init|=
operator|new
name|Delete
argument_list|(
name|hi
operator|.
name|metaEntry
operator|.
name|getRegionName
argument_list|()
argument_list|)
decl_stmt|;
name|d
operator|.
name|addColumn
argument_list|(
name|HConstants
operator|.
name|CATALOG_FAMILY
argument_list|,
name|HConstants
operator|.
name|SPLITA_QUALIFIER
argument_list|)
expr_stmt|;
name|d
operator|.
name|addColumn
argument_list|(
name|HConstants
operator|.
name|CATALOG_FAMILY
argument_list|,
name|HConstants
operator|.
name|SPLITB_QUALIFIER
argument_list|)
expr_stmt|;
name|mutations
operator|.
name|add
argument_list|(
name|d
argument_list|)
expr_stmt|;
name|RegionInfo
name|hri
init|=
name|RegionInfoBuilder
operator|.
name|newBuilder
argument_list|(
name|hi
operator|.
name|metaEntry
argument_list|)
operator|.
name|setOffline
argument_list|(
literal|false
argument_list|)
operator|.
name|setSplit
argument_list|(
literal|false
argument_list|)
operator|.
name|build
argument_list|()
decl_stmt|;
name|Put
name|p
init|=
name|MetaTableAccessor
operator|.
name|makePutFromRegionInfo
argument_list|(
name|hri
argument_list|,
name|EnvironmentEdgeManager
operator|.
name|currentTime
argument_list|()
argument_list|)
decl_stmt|;
name|mutations
operator|.
name|add
argument_list|(
name|p
argument_list|)
expr_stmt|;
name|meta
operator|.
name|mutateRow
argument_list|(
name|mutations
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Reset split parent "
operator|+
name|hi
operator|.
name|metaEntry
operator|.
name|getRegionNameAsString
argument_list|()
operator|+
literal|" in META"
argument_list|)
expr_stmt|;
block|}
comment|/**    * This backwards-compatibility wrapper for permanently offlining a region    * that should not be alive.  If the region server does not support the    * "offline" method, it will use the closest unassign method instead.  This    * will basically work until one attempts to disable or delete the affected    * table.  The problem has to do with in-memory only master state, so    * restarting the HMaster or failing over to another should fix this.    */
specifier|private
name|void
name|offline
parameter_list|(
name|byte
index|[]
name|regionName
parameter_list|)
throws|throws
name|IOException
block|{
name|String
name|regionString
init|=
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|regionName
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|rsSupportsOffline
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Using unassign region "
operator|+
name|regionString
operator|+
literal|" instead of using offline method, you should"
operator|+
literal|" restart HMaster after these repairs"
argument_list|)
expr_stmt|;
name|admin
operator|.
name|unassign
argument_list|(
name|regionName
argument_list|,
literal|true
argument_list|)
expr_stmt|;
return|return;
block|}
comment|// first time we assume the rs's supports #offline.
try|try
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Offlining region "
operator|+
name|regionString
argument_list|)
expr_stmt|;
name|admin
operator|.
name|offline
argument_list|(
name|regionName
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ioe
parameter_list|)
block|{
name|String
name|notFoundMsg
init|=
literal|"java.lang.NoSuchMethodException: "
operator|+
literal|"org.apache.hadoop.hbase.master.HMaster.offline([B)"
decl_stmt|;
if|if
condition|(
name|ioe
operator|.
name|getMessage
argument_list|()
operator|.
name|contains
argument_list|(
name|notFoundMsg
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Using unassign region "
operator|+
name|regionString
operator|+
literal|" instead of using offline method, you should"
operator|+
literal|" restart HMaster after these repairs"
argument_list|)
expr_stmt|;
name|rsSupportsOffline
operator|=
literal|false
expr_stmt|;
comment|// in the future just use unassign
name|admin
operator|.
name|unassign
argument_list|(
name|regionName
argument_list|,
literal|true
argument_list|)
expr_stmt|;
return|return;
block|}
throw|throw
name|ioe
throw|;
block|}
block|}
specifier|private
name|void
name|undeployRegions
parameter_list|(
name|HbckInfo
name|hi
parameter_list|)
throws|throws
name|IOException
throws|,
name|InterruptedException
block|{
name|undeployRegionsForHbi
argument_list|(
name|hi
argument_list|)
expr_stmt|;
comment|// undeploy replicas of the region (but only if the method is invoked for the primary)
if|if
condition|(
name|hi
operator|.
name|getReplicaId
argument_list|()
operator|!=
name|RegionInfo
operator|.
name|DEFAULT_REPLICA_ID
condition|)
block|{
return|return;
block|}
name|int
name|numReplicas
init|=
name|admin
operator|.
name|getTableDescriptor
argument_list|(
name|hi
operator|.
name|getTableName
argument_list|()
argument_list|)
operator|.
name|getRegionReplication
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|1
init|;
name|i
operator|<
name|numReplicas
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|hi
operator|.
name|getPrimaryHRIForDeployedReplica
argument_list|()
operator|==
literal|null
condition|)
continue|continue;
name|RegionInfo
name|hri
init|=
name|RegionReplicaUtil
operator|.
name|getRegionInfoForReplica
argument_list|(
name|hi
operator|.
name|getPrimaryHRIForDeployedReplica
argument_list|()
argument_list|,
name|i
argument_list|)
decl_stmt|;
name|HbckInfo
name|h
init|=
name|regionInfoMap
operator|.
name|get
argument_list|(
name|hri
operator|.
name|getEncodedName
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|h
operator|!=
literal|null
condition|)
block|{
name|undeployRegionsForHbi
argument_list|(
name|h
argument_list|)
expr_stmt|;
comment|//set skip checks; we undeployed it, and we don't want to evaluate this anymore
comment|//in consistency checks
name|h
operator|.
name|setSkipChecks
argument_list|(
literal|true
argument_list|)
expr_stmt|;
block|}
block|}
block|}
specifier|private
name|void
name|undeployRegionsForHbi
parameter_list|(
name|HbckInfo
name|hi
parameter_list|)
throws|throws
name|IOException
throws|,
name|InterruptedException
block|{
for|for
control|(
name|OnlineEntry
name|rse
range|:
name|hi
operator|.
name|deployedEntries
control|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Undeploy region "
operator|+
name|rse
operator|.
name|hri
operator|+
literal|" from "
operator|+
name|rse
operator|.
name|hsa
argument_list|)
expr_stmt|;
try|try
block|{
name|HBaseFsckRepair
operator|.
name|closeRegionSilentlyAndWait
argument_list|(
name|connection
argument_list|,
name|rse
operator|.
name|hsa
argument_list|,
name|rse
operator|.
name|hri
argument_list|)
expr_stmt|;
name|offline
argument_list|(
name|rse
operator|.
name|hri
operator|.
name|getRegionName
argument_list|()
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ioe
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Got exception when attempting to offline region "
operator|+
name|Bytes
operator|.
name|toString
argument_list|(
name|rse
operator|.
name|hri
operator|.
name|getRegionName
argument_list|()
argument_list|)
argument_list|,
name|ioe
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|/**    * Attempts to undeploy a region from a region server based in information in    * META.  Any operations that modify the file system should make sure that    * its corresponding region is not deployed to prevent data races.    *    * A separate call is required to update the master in-memory region state    * kept in the AssignementManager.  Because disable uses this state instead of    * that found in META, we can't seem to cleanly disable/delete tables that    * have been hbck fixed.  When used on a version of HBase that does not have    * the offline ipc call exposed on the master (&lt;0.90.5,&lt;0.92.0) a master    * restart or failover may be required.    */
specifier|private
name|void
name|closeRegion
parameter_list|(
name|HbckInfo
name|hi
parameter_list|)
throws|throws
name|IOException
throws|,
name|InterruptedException
block|{
if|if
condition|(
name|hi
operator|.
name|metaEntry
operator|==
literal|null
operator|&&
name|hi
operator|.
name|hdfsEntry
operator|==
literal|null
condition|)
block|{
name|undeployRegions
argument_list|(
name|hi
argument_list|)
expr_stmt|;
return|return;
block|}
comment|// get assignment info and hregioninfo from meta.
name|Get
name|get
init|=
operator|new
name|Get
argument_list|(
name|hi
operator|.
name|getRegionName
argument_list|()
argument_list|)
decl_stmt|;
name|get
operator|.
name|addColumn
argument_list|(
name|HConstants
operator|.
name|CATALOG_FAMILY
argument_list|,
name|HConstants
operator|.
name|REGIONINFO_QUALIFIER
argument_list|)
expr_stmt|;
name|get
operator|.
name|addColumn
argument_list|(
name|HConstants
operator|.
name|CATALOG_FAMILY
argument_list|,
name|HConstants
operator|.
name|SERVER_QUALIFIER
argument_list|)
expr_stmt|;
name|get
operator|.
name|addColumn
argument_list|(
name|HConstants
operator|.
name|CATALOG_FAMILY
argument_list|,
name|HConstants
operator|.
name|STARTCODE_QUALIFIER
argument_list|)
expr_stmt|;
comment|// also get the locations of the replicas to close if the primary region is being closed
if|if
condition|(
name|hi
operator|.
name|getReplicaId
argument_list|()
operator|==
name|RegionInfo
operator|.
name|DEFAULT_REPLICA_ID
condition|)
block|{
name|int
name|numReplicas
init|=
name|admin
operator|.
name|getTableDescriptor
argument_list|(
name|hi
operator|.
name|getTableName
argument_list|()
argument_list|)
operator|.
name|getRegionReplication
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|numReplicas
condition|;
name|i
operator|++
control|)
block|{
name|get
operator|.
name|addColumn
argument_list|(
name|HConstants
operator|.
name|CATALOG_FAMILY
argument_list|,
name|MetaTableAccessor
operator|.
name|getServerColumn
argument_list|(
name|i
argument_list|)
argument_list|)
expr_stmt|;
name|get
operator|.
name|addColumn
argument_list|(
name|HConstants
operator|.
name|CATALOG_FAMILY
argument_list|,
name|MetaTableAccessor
operator|.
name|getStartCodeColumn
argument_list|(
name|i
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
name|Result
name|r
init|=
name|meta
operator|.
name|get
argument_list|(
name|get
argument_list|)
decl_stmt|;
name|RegionLocations
name|rl
init|=
name|MetaTableAccessor
operator|.
name|getRegionLocations
argument_list|(
name|r
argument_list|)
decl_stmt|;
if|if
condition|(
name|rl
operator|==
literal|null
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Unable to close region "
operator|+
name|hi
operator|.
name|getRegionNameAsString
argument_list|()
operator|+
literal|" since meta does not have handle to reach it"
argument_list|)
expr_stmt|;
return|return;
block|}
for|for
control|(
name|HRegionLocation
name|h
range|:
name|rl
operator|.
name|getRegionLocations
argument_list|()
control|)
block|{
name|ServerName
name|serverName
init|=
name|h
operator|.
name|getServerName
argument_list|()
decl_stmt|;
if|if
condition|(
name|serverName
operator|==
literal|null
condition|)
block|{
name|errors
operator|.
name|reportError
argument_list|(
literal|"Unable to close region "
operator|+
name|hi
operator|.
name|getRegionNameAsString
argument_list|()
operator|+
literal|" because meta does not "
operator|+
literal|"have handle to reach it."
argument_list|)
expr_stmt|;
continue|continue;
block|}
name|RegionInfo
name|hri
init|=
name|h
operator|.
name|getRegionInfo
argument_list|()
decl_stmt|;
if|if
condition|(
name|hri
operator|==
literal|null
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Unable to close region "
operator|+
name|hi
operator|.
name|getRegionNameAsString
argument_list|()
operator|+
literal|" because hbase:meta had invalid or missing "
operator|+
name|HConstants
operator|.
name|CATALOG_FAMILY_STR
operator|+
literal|":"
operator|+
name|Bytes
operator|.
name|toString
argument_list|(
name|HConstants
operator|.
name|REGIONINFO_QUALIFIER
argument_list|)
operator|+
literal|" qualifier value."
argument_list|)
expr_stmt|;
continue|continue;
block|}
comment|// close the region -- close files and remove assignment
name|HBaseFsckRepair
operator|.
name|closeRegionSilentlyAndWait
argument_list|(
name|connection
argument_list|,
name|serverName
argument_list|,
name|hri
argument_list|)
expr_stmt|;
block|}
block|}
specifier|private
name|void
name|tryAssignmentRepair
parameter_list|(
name|HbckInfo
name|hbi
parameter_list|,
name|String
name|msg
parameter_list|)
throws|throws
name|IOException
throws|,
name|KeeperException
throws|,
name|InterruptedException
block|{
comment|// If we are trying to fix the errors
if|if
condition|(
name|shouldFixAssignments
argument_list|()
condition|)
block|{
name|errors
operator|.
name|print
argument_list|(
name|msg
argument_list|)
expr_stmt|;
name|undeployRegions
argument_list|(
name|hbi
argument_list|)
expr_stmt|;
name|setShouldRerun
argument_list|()
expr_stmt|;
name|RegionInfo
name|hri
init|=
name|hbi
operator|.
name|getHdfsHRI
argument_list|()
decl_stmt|;
if|if
condition|(
name|hri
operator|==
literal|null
condition|)
block|{
name|hri
operator|=
name|hbi
operator|.
name|metaEntry
expr_stmt|;
block|}
name|HBaseFsckRepair
operator|.
name|fixUnassigned
argument_list|(
name|admin
argument_list|,
name|hri
argument_list|)
expr_stmt|;
name|HBaseFsckRepair
operator|.
name|waitUntilAssigned
argument_list|(
name|admin
argument_list|,
name|hri
argument_list|)
expr_stmt|;
comment|// also assign replicas if needed (do it only when this call operates on a primary replica)
if|if
condition|(
name|hbi
operator|.
name|getReplicaId
argument_list|()
operator|!=
name|RegionInfo
operator|.
name|DEFAULT_REPLICA_ID
condition|)
return|return;
name|int
name|replicationCount
init|=
name|admin
operator|.
name|getTableDescriptor
argument_list|(
name|hri
operator|.
name|getTable
argument_list|()
argument_list|)
operator|.
name|getRegionReplication
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|1
init|;
name|i
operator|<
name|replicationCount
condition|;
name|i
operator|++
control|)
block|{
name|hri
operator|=
name|RegionReplicaUtil
operator|.
name|getRegionInfoForReplica
argument_list|(
name|hri
argument_list|,
name|i
argument_list|)
expr_stmt|;
name|HbckInfo
name|h
init|=
name|regionInfoMap
operator|.
name|get
argument_list|(
name|hri
operator|.
name|getEncodedName
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|h
operator|!=
literal|null
condition|)
block|{
name|undeployRegions
argument_list|(
name|h
argument_list|)
expr_stmt|;
comment|//set skip checks; we undeploy& deploy it; we don't want to evaluate this hbi anymore
comment|//in consistency checks
name|h
operator|.
name|setSkipChecks
argument_list|(
literal|true
argument_list|)
expr_stmt|;
block|}
name|HBaseFsckRepair
operator|.
name|fixUnassigned
argument_list|(
name|admin
argument_list|,
name|hri
argument_list|)
expr_stmt|;
name|HBaseFsckRepair
operator|.
name|waitUntilAssigned
argument_list|(
name|admin
argument_list|,
name|hri
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|/**    * Check a single region for consistency and correct deployment.    */
specifier|private
name|void
name|checkRegionConsistency
parameter_list|(
specifier|final
name|String
name|key
parameter_list|,
specifier|final
name|HbckInfo
name|hbi
parameter_list|)
throws|throws
name|IOException
throws|,
name|KeeperException
throws|,
name|InterruptedException
block|{
if|if
condition|(
name|hbi
operator|.
name|isSkipChecks
argument_list|()
condition|)
return|return;
name|String
name|descriptiveName
init|=
name|hbi
operator|.
name|toString
argument_list|()
decl_stmt|;
name|boolean
name|inMeta
init|=
name|hbi
operator|.
name|metaEntry
operator|!=
literal|null
decl_stmt|;
comment|// In case not checking HDFS, assume the region is on HDFS
name|boolean
name|inHdfs
init|=
operator|!
name|shouldCheckHdfs
argument_list|()
operator|||
name|hbi
operator|.
name|getHdfsRegionDir
argument_list|()
operator|!=
literal|null
decl_stmt|;
name|boolean
name|hasMetaAssignment
init|=
name|inMeta
operator|&&
name|hbi
operator|.
name|metaEntry
operator|.
name|regionServer
operator|!=
literal|null
decl_stmt|;
name|boolean
name|isDeployed
init|=
operator|!
name|hbi
operator|.
name|deployedOn
operator|.
name|isEmpty
argument_list|()
decl_stmt|;
name|boolean
name|isMultiplyDeployed
init|=
name|hbi
operator|.
name|deployedOn
operator|.
name|size
argument_list|()
operator|>
literal|1
decl_stmt|;
name|boolean
name|deploymentMatchesMeta
init|=
name|hasMetaAssignment
operator|&&
name|isDeployed
operator|&&
operator|!
name|isMultiplyDeployed
operator|&&
name|hbi
operator|.
name|metaEntry
operator|.
name|regionServer
operator|.
name|equals
argument_list|(
name|hbi
operator|.
name|deployedOn
operator|.
name|get
argument_list|(
literal|0
argument_list|)
argument_list|)
decl_stmt|;
name|boolean
name|splitParent
init|=
name|inMeta
operator|&&
name|hbi
operator|.
name|metaEntry
operator|.
name|isSplit
argument_list|()
operator|&&
name|hbi
operator|.
name|metaEntry
operator|.
name|isOffline
argument_list|()
decl_stmt|;
name|boolean
name|shouldBeDeployed
init|=
name|inMeta
operator|&&
operator|!
name|isTableDisabled
argument_list|(
name|hbi
operator|.
name|metaEntry
operator|.
name|getTable
argument_list|()
argument_list|)
decl_stmt|;
name|boolean
name|recentlyModified
init|=
name|inHdfs
operator|&&
name|hbi
operator|.
name|getModTime
argument_list|()
operator|+
name|timelag
operator|>
name|EnvironmentEdgeManager
operator|.
name|currentTime
argument_list|()
decl_stmt|;
comment|// ========== First the healthy cases =============
if|if
condition|(
name|hbi
operator|.
name|containsOnlyHdfsEdits
argument_list|()
condition|)
block|{
return|return;
block|}
if|if
condition|(
name|inMeta
operator|&&
name|inHdfs
operator|&&
name|isDeployed
operator|&&
name|deploymentMatchesMeta
operator|&&
name|shouldBeDeployed
condition|)
block|{
return|return;
block|}
elseif|else
if|if
condition|(
name|inMeta
operator|&&
name|inHdfs
operator|&&
operator|!
name|shouldBeDeployed
operator|&&
operator|!
name|isDeployed
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Region "
operator|+
name|descriptiveName
operator|+
literal|" is in META, and in a disabled "
operator|+
literal|"tabled that is not deployed"
argument_list|)
expr_stmt|;
return|return;
block|}
elseif|else
if|if
condition|(
name|recentlyModified
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Region "
operator|+
name|descriptiveName
operator|+
literal|" was recently modified -- skipping"
argument_list|)
expr_stmt|;
return|return;
block|}
comment|// ========== Cases where the region is not in hbase:meta =============
elseif|else
if|if
condition|(
operator|!
name|inMeta
operator|&&
operator|!
name|inHdfs
operator|&&
operator|!
name|isDeployed
condition|)
block|{
comment|// We shouldn't have record of this region at all then!
assert|assert
literal|false
operator|:
literal|"Entry for region with no data"
assert|;
block|}
elseif|else
if|if
condition|(
operator|!
name|inMeta
operator|&&
operator|!
name|inHdfs
operator|&&
name|isDeployed
condition|)
block|{
name|errors
operator|.
name|reportError
argument_list|(
name|ERROR_CODE
operator|.
name|NOT_IN_META_HDFS
argument_list|,
literal|"Region "
operator|+
name|descriptiveName
operator|+
literal|", key="
operator|+
name|key
operator|+
literal|", not on HDFS or in hbase:meta but "
operator|+
literal|"deployed on "
operator|+
name|Joiner
operator|.
name|on
argument_list|(
literal|", "
argument_list|)
operator|.
name|join
argument_list|(
name|hbi
operator|.
name|deployedOn
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|shouldFixAssignments
argument_list|()
condition|)
block|{
name|undeployRegions
argument_list|(
name|hbi
argument_list|)
expr_stmt|;
block|}
block|}
elseif|else
if|if
condition|(
operator|!
name|inMeta
operator|&&
name|inHdfs
operator|&&
operator|!
name|isDeployed
condition|)
block|{
if|if
condition|(
name|hbi
operator|.
name|isMerged
argument_list|()
condition|)
block|{
comment|// This region has already been merged, the remaining hdfs file will be
comment|// cleaned by CatalogJanitor later
name|hbi
operator|.
name|setSkipChecks
argument_list|(
literal|true
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Region "
operator|+
name|descriptiveName
operator|+
literal|" got merge recently, its file(s) will be cleaned by CatalogJanitor later"
argument_list|)
expr_stmt|;
return|return;
block|}
name|errors
operator|.
name|reportError
argument_list|(
name|ERROR_CODE
operator|.
name|NOT_IN_META_OR_DEPLOYED
argument_list|,
literal|"Region "
operator|+
name|descriptiveName
operator|+
literal|" on HDFS, but not listed in hbase:meta "
operator|+
literal|"or deployed on any region server"
argument_list|)
expr_stmt|;
comment|// restore region consistency of an adopted orphan
if|if
condition|(
name|shouldFixMeta
argument_list|()
condition|)
block|{
if|if
condition|(
operator|!
name|hbi
operator|.
name|isHdfsRegioninfoPresent
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Region "
operator|+
name|hbi
operator|.
name|getHdfsHRI
argument_list|()
operator|+
literal|" could have been repaired"
operator|+
literal|" in table integrity repair phase if -fixHdfsOrphans was"
operator|+
literal|" used."
argument_list|)
expr_stmt|;
return|return;
block|}
name|RegionInfo
name|hri
init|=
name|hbi
operator|.
name|getHdfsHRI
argument_list|()
decl_stmt|;
name|TableInfo
name|tableInfo
init|=
name|tablesInfo
operator|.
name|get
argument_list|(
name|hri
operator|.
name|getTable
argument_list|()
argument_list|)
decl_stmt|;
for|for
control|(
name|RegionInfo
name|region
range|:
name|tableInfo
operator|.
name|getRegionsFromMeta
argument_list|()
control|)
block|{
if|if
condition|(
name|Bytes
operator|.
name|compareTo
argument_list|(
name|region
operator|.
name|getStartKey
argument_list|()
argument_list|,
name|hri
operator|.
name|getStartKey
argument_list|()
argument_list|)
operator|<=
literal|0
operator|&&
operator|(
name|region
operator|.
name|getEndKey
argument_list|()
operator|.
name|length
operator|==
literal|0
operator|||
name|Bytes
operator|.
name|compareTo
argument_list|(
name|region
operator|.
name|getEndKey
argument_list|()
argument_list|,
name|hri
operator|.
name|getEndKey
argument_list|()
argument_list|)
operator|>=
literal|0
operator|)
operator|&&
name|Bytes
operator|.
name|compareTo
argument_list|(
name|region
operator|.
name|getStartKey
argument_list|()
argument_list|,
name|hri
operator|.
name|getEndKey
argument_list|()
argument_list|)
operator|<=
literal|0
condition|)
block|{
if|if
condition|(
name|region
operator|.
name|isSplit
argument_list|()
operator|||
name|region
operator|.
name|isOffline
argument_list|()
condition|)
continue|continue;
name|Path
name|regionDir
init|=
name|hbi
operator|.
name|getHdfsRegionDir
argument_list|()
decl_stmt|;
name|FileSystem
name|fs
init|=
name|regionDir
operator|.
name|getFileSystem
argument_list|(
name|getConf
argument_list|()
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|Path
argument_list|>
name|familyDirs
init|=
name|FSUtils
operator|.
name|getFamilyDirs
argument_list|(
name|fs
argument_list|,
name|regionDir
argument_list|)
decl_stmt|;
for|for
control|(
name|Path
name|familyDir
range|:
name|familyDirs
control|)
block|{
name|List
argument_list|<
name|Path
argument_list|>
name|referenceFilePaths
init|=
name|FSUtils
operator|.
name|getReferenceFilePaths
argument_list|(
name|fs
argument_list|,
name|familyDir
argument_list|)
decl_stmt|;
for|for
control|(
name|Path
name|referenceFilePath
range|:
name|referenceFilePaths
control|)
block|{
name|Path
name|parentRegionDir
init|=
name|StoreFileInfo
operator|.
name|getReferredToFile
argument_list|(
name|referenceFilePath
argument_list|)
operator|.
name|getParent
argument_list|()
operator|.
name|getParent
argument_list|()
decl_stmt|;
if|if
condition|(
name|parentRegionDir
operator|.
name|toString
argument_list|()
operator|.
name|endsWith
argument_list|(
name|region
operator|.
name|getEncodedName
argument_list|()
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
name|hri
operator|+
literal|" start and stop keys are in the range of "
operator|+
name|region
operator|+
literal|". The region might not be cleaned up from hdfs when region "
operator|+
name|region
operator|+
literal|" split failed. Hence deleting from hdfs."
argument_list|)
expr_stmt|;
name|HRegionFileSystem
operator|.
name|deleteRegionFromFileSystem
argument_list|(
name|getConf
argument_list|()
argument_list|,
name|fs
argument_list|,
name|regionDir
operator|.
name|getParent
argument_list|()
argument_list|,
name|hri
argument_list|)
expr_stmt|;
return|return;
block|}
block|}
block|}
block|}
block|}
name|LOG
operator|.
name|info
argument_list|(
literal|"Patching hbase:meta with .regioninfo: "
operator|+
name|hbi
operator|.
name|getHdfsHRI
argument_list|()
argument_list|)
expr_stmt|;
name|int
name|numReplicas
init|=
name|admin
operator|.
name|getTableDescriptor
argument_list|(
name|hbi
operator|.
name|getTableName
argument_list|()
argument_list|)
operator|.
name|getRegionReplication
argument_list|()
decl_stmt|;
name|HBaseFsckRepair
operator|.
name|fixMetaHoleOnlineAndAddReplicas
argument_list|(
name|getConf
argument_list|()
argument_list|,
name|hbi
operator|.
name|getHdfsHRI
argument_list|()
argument_list|,
name|admin
operator|.
name|getClusterMetrics
argument_list|(
name|EnumSet
operator|.
name|of
argument_list|(
name|Option
operator|.
name|LIVE_SERVERS
argument_list|)
argument_list|)
operator|.
name|getLiveServerMetrics
argument_list|()
operator|.
name|keySet
argument_list|()
argument_list|,
name|numReplicas
argument_list|)
expr_stmt|;
name|tryAssignmentRepair
argument_list|(
name|hbi
argument_list|,
literal|"Trying to reassign region..."
argument_list|)
expr_stmt|;
block|}
block|}
elseif|else
if|if
condition|(
operator|!
name|inMeta
operator|&&
name|inHdfs
operator|&&
name|isDeployed
condition|)
block|{
name|errors
operator|.
name|reportError
argument_list|(
name|ERROR_CODE
operator|.
name|NOT_IN_META
argument_list|,
literal|"Region "
operator|+
name|descriptiveName
operator|+
literal|" not in META, but deployed on "
operator|+
name|Joiner
operator|.
name|on
argument_list|(
literal|", "
argument_list|)
operator|.
name|join
argument_list|(
name|hbi
operator|.
name|deployedOn
argument_list|)
argument_list|)
expr_stmt|;
name|debugLsr
argument_list|(
name|hbi
operator|.
name|getHdfsRegionDir
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|hbi
operator|.
name|getReplicaId
argument_list|()
operator|!=
name|RegionInfo
operator|.
name|DEFAULT_REPLICA_ID
condition|)
block|{
comment|// for replicas, this means that we should undeploy the region (we would have
comment|// gone over the primaries and fixed meta holes in first phase under
comment|// checkAndFixConsistency; we shouldn't get the condition !inMeta at
comment|// this stage unless unwanted replica)
if|if
condition|(
name|shouldFixAssignments
argument_list|()
condition|)
block|{
name|undeployRegionsForHbi
argument_list|(
name|hbi
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|shouldFixMeta
argument_list|()
operator|&&
name|hbi
operator|.
name|getReplicaId
argument_list|()
operator|==
name|RegionInfo
operator|.
name|DEFAULT_REPLICA_ID
condition|)
block|{
if|if
condition|(
operator|!
name|hbi
operator|.
name|isHdfsRegioninfoPresent
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"This should have been repaired in table integrity repair phase"
argument_list|)
expr_stmt|;
return|return;
block|}
name|LOG
operator|.
name|info
argument_list|(
literal|"Patching hbase:meta with with .regioninfo: "
operator|+
name|hbi
operator|.
name|getHdfsHRI
argument_list|()
argument_list|)
expr_stmt|;
name|int
name|numReplicas
init|=
name|admin
operator|.
name|getTableDescriptor
argument_list|(
name|hbi
operator|.
name|getTableName
argument_list|()
argument_list|)
operator|.
name|getRegionReplication
argument_list|()
decl_stmt|;
name|HBaseFsckRepair
operator|.
name|fixMetaHoleOnlineAndAddReplicas
argument_list|(
name|getConf
argument_list|()
argument_list|,
name|hbi
operator|.
name|getHdfsHRI
argument_list|()
argument_list|,
name|admin
operator|.
name|getClusterMetrics
argument_list|(
name|EnumSet
operator|.
name|of
argument_list|(
name|Option
operator|.
name|LIVE_SERVERS
argument_list|)
argument_list|)
operator|.
name|getLiveServerMetrics
argument_list|()
operator|.
name|keySet
argument_list|()
argument_list|,
name|numReplicas
argument_list|)
expr_stmt|;
name|tryAssignmentRepair
argument_list|(
name|hbi
argument_list|,
literal|"Trying to fix unassigned region..."
argument_list|)
expr_stmt|;
block|}
comment|// ========== Cases where the region is in hbase:meta =============
block|}
elseif|else
if|if
condition|(
name|inMeta
operator|&&
name|inHdfs
operator|&&
operator|!
name|isDeployed
operator|&&
name|splitParent
condition|)
block|{
comment|// check whether this is an actual error, or just transient state where parent
comment|// is not cleaned
if|if
condition|(
name|hbi
operator|.
name|metaEntry
operator|.
name|splitA
operator|!=
literal|null
operator|&&
name|hbi
operator|.
name|metaEntry
operator|.
name|splitB
operator|!=
literal|null
condition|)
block|{
comment|// check that split daughters are there
name|HbckInfo
name|infoA
init|=
name|this
operator|.
name|regionInfoMap
operator|.
name|get
argument_list|(
name|hbi
operator|.
name|metaEntry
operator|.
name|splitA
operator|.
name|getEncodedName
argument_list|()
argument_list|)
decl_stmt|;
name|HbckInfo
name|infoB
init|=
name|this
operator|.
name|regionInfoMap
operator|.
name|get
argument_list|(
name|hbi
operator|.
name|metaEntry
operator|.
name|splitB
operator|.
name|getEncodedName
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|infoA
operator|!=
literal|null
operator|&&
name|infoB
operator|!=
literal|null
condition|)
block|{
comment|// we already processed or will process daughters. Move on, nothing to see here.
name|hbi
operator|.
name|setSkipChecks
argument_list|(
literal|true
argument_list|)
expr_stmt|;
return|return;
block|}
block|}
comment|// For Replica region, we need to do a similar check. If replica is not split successfully,
comment|// error is going to be reported against primary daughter region.
if|if
condition|(
name|hbi
operator|.
name|getReplicaId
argument_list|()
operator|!=
name|RegionInfo
operator|.
name|DEFAULT_REPLICA_ID
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Region "
operator|+
name|descriptiveName
operator|+
literal|" is a split parent in META, in HDFS, "
operator|+
literal|"and not deployed on any region server. This may be transient."
argument_list|)
expr_stmt|;
name|hbi
operator|.
name|setSkipChecks
argument_list|(
literal|true
argument_list|)
expr_stmt|;
return|return;
block|}
name|errors
operator|.
name|reportError
argument_list|(
name|ERROR_CODE
operator|.
name|LINGERING_SPLIT_PARENT
argument_list|,
literal|"Region "
operator|+
name|descriptiveName
operator|+
literal|" is a split parent in META, in HDFS, "
operator|+
literal|"and not deployed on any region server. This could be transient, "
operator|+
literal|"consider to run the catalog janitor first!"
argument_list|)
expr_stmt|;
if|if
condition|(
name|shouldFixSplitParents
argument_list|()
condition|)
block|{
name|setShouldRerun
argument_list|()
expr_stmt|;
name|resetSplitParent
argument_list|(
name|hbi
argument_list|)
expr_stmt|;
block|}
block|}
elseif|else
if|if
condition|(
name|inMeta
operator|&&
operator|!
name|inHdfs
operator|&&
operator|!
name|isDeployed
condition|)
block|{
name|errors
operator|.
name|reportError
argument_list|(
name|ERROR_CODE
operator|.
name|NOT_IN_HDFS_OR_DEPLOYED
argument_list|,
literal|"Region "
operator|+
name|descriptiveName
operator|+
literal|" found in META, but not in HDFS "
operator|+
literal|"or deployed on any region server."
argument_list|)
expr_stmt|;
if|if
condition|(
name|shouldFixMeta
argument_list|()
condition|)
block|{
name|deleteMetaRegion
argument_list|(
name|hbi
argument_list|)
expr_stmt|;
block|}
block|}
elseif|else
if|if
condition|(
name|inMeta
operator|&&
operator|!
name|inHdfs
operator|&&
name|isDeployed
condition|)
block|{
name|errors
operator|.
name|reportError
argument_list|(
name|ERROR_CODE
operator|.
name|NOT_IN_HDFS
argument_list|,
literal|"Region "
operator|+
name|descriptiveName
operator|+
literal|" found in META, but not in HDFS, "
operator|+
literal|"and deployed on "
operator|+
name|Joiner
operator|.
name|on
argument_list|(
literal|", "
argument_list|)
operator|.
name|join
argument_list|(
name|hbi
operator|.
name|deployedOn
argument_list|)
argument_list|)
expr_stmt|;
comment|// We treat HDFS as ground truth.  Any information in meta is transient
comment|// and equivalent data can be regenerated.  So, lets unassign and remove
comment|// these problems from META.
if|if
condition|(
name|shouldFixAssignments
argument_list|()
condition|)
block|{
name|errors
operator|.
name|print
argument_list|(
literal|"Trying to fix unassigned region..."
argument_list|)
expr_stmt|;
name|undeployRegions
argument_list|(
name|hbi
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|shouldFixMeta
argument_list|()
condition|)
block|{
comment|// wait for it to complete
name|deleteMetaRegion
argument_list|(
name|hbi
argument_list|)
expr_stmt|;
block|}
block|}
elseif|else
if|if
condition|(
name|inMeta
operator|&&
name|inHdfs
operator|&&
operator|!
name|isDeployed
operator|&&
name|shouldBeDeployed
condition|)
block|{
name|errors
operator|.
name|reportError
argument_list|(
name|ERROR_CODE
operator|.
name|NOT_DEPLOYED
argument_list|,
literal|"Region "
operator|+
name|descriptiveName
operator|+
literal|" not deployed on any region server."
argument_list|)
expr_stmt|;
name|tryAssignmentRepair
argument_list|(
name|hbi
argument_list|,
literal|"Trying to fix unassigned region..."
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|inMeta
operator|&&
name|inHdfs
operator|&&
name|isDeployed
operator|&&
operator|!
name|shouldBeDeployed
condition|)
block|{
name|errors
operator|.
name|reportError
argument_list|(
name|ERROR_CODE
operator|.
name|SHOULD_NOT_BE_DEPLOYED
argument_list|,
literal|"Region "
operator|+
name|descriptiveName
operator|+
literal|" should not be deployed according "
operator|+
literal|"to META, but is deployed on "
operator|+
name|Joiner
operator|.
name|on
argument_list|(
literal|", "
argument_list|)
operator|.
name|join
argument_list|(
name|hbi
operator|.
name|deployedOn
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|shouldFixAssignments
argument_list|()
condition|)
block|{
name|errors
operator|.
name|print
argument_list|(
literal|"Trying to close the region "
operator|+
name|descriptiveName
argument_list|)
expr_stmt|;
name|setShouldRerun
argument_list|()
expr_stmt|;
name|HBaseFsckRepair
operator|.
name|fixMultiAssignment
argument_list|(
name|connection
argument_list|,
name|hbi
operator|.
name|metaEntry
argument_list|,
name|hbi
operator|.
name|deployedOn
argument_list|)
expr_stmt|;
block|}
block|}
elseif|else
if|if
condition|(
name|inMeta
operator|&&
name|inHdfs
operator|&&
name|isMultiplyDeployed
condition|)
block|{
name|errors
operator|.
name|reportError
argument_list|(
name|ERROR_CODE
operator|.
name|MULTI_DEPLOYED
argument_list|,
literal|"Region "
operator|+
name|descriptiveName
operator|+
literal|" is listed in hbase:meta on region server "
operator|+
name|hbi
operator|.
name|metaEntry
operator|.
name|regionServer
operator|+
literal|" but is multiply assigned to region servers "
operator|+
name|Joiner
operator|.
name|on
argument_list|(
literal|", "
argument_list|)
operator|.
name|join
argument_list|(
name|hbi
operator|.
name|deployedOn
argument_list|)
argument_list|)
expr_stmt|;
comment|// If we are trying to fix the errors
if|if
condition|(
name|shouldFixAssignments
argument_list|()
condition|)
block|{
name|errors
operator|.
name|print
argument_list|(
literal|"Trying to fix assignment error..."
argument_list|)
expr_stmt|;
name|setShouldRerun
argument_list|()
expr_stmt|;
name|HBaseFsckRepair
operator|.
name|fixMultiAssignment
argument_list|(
name|connection
argument_list|,
name|hbi
operator|.
name|metaEntry
argument_list|,
name|hbi
operator|.
name|deployedOn
argument_list|)
expr_stmt|;
block|}
block|}
elseif|else
if|if
condition|(
name|inMeta
operator|&&
name|inHdfs
operator|&&
name|isDeployed
operator|&&
operator|!
name|deploymentMatchesMeta
condition|)
block|{
name|errors
operator|.
name|reportError
argument_list|(
name|ERROR_CODE
operator|.
name|SERVER_DOES_NOT_MATCH_META
argument_list|,
literal|"Region "
operator|+
name|descriptiveName
operator|+
literal|" listed in hbase:meta on region server "
operator|+
name|hbi
operator|.
name|metaEntry
operator|.
name|regionServer
operator|+
literal|" but found on region server "
operator|+
name|hbi
operator|.
name|deployedOn
operator|.
name|get
argument_list|(
literal|0
argument_list|)
argument_list|)
expr_stmt|;
comment|// If we are trying to fix the errors
if|if
condition|(
name|shouldFixAssignments
argument_list|()
condition|)
block|{
name|errors
operator|.
name|print
argument_list|(
literal|"Trying to fix assignment error..."
argument_list|)
expr_stmt|;
name|setShouldRerun
argument_list|()
expr_stmt|;
name|HBaseFsckRepair
operator|.
name|fixMultiAssignment
argument_list|(
name|connection
argument_list|,
name|hbi
operator|.
name|metaEntry
argument_list|,
name|hbi
operator|.
name|deployedOn
argument_list|)
expr_stmt|;
name|HBaseFsckRepair
operator|.
name|waitUntilAssigned
argument_list|(
name|admin
argument_list|,
name|hbi
operator|.
name|getHdfsHRI
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
name|errors
operator|.
name|reportError
argument_list|(
name|ERROR_CODE
operator|.
name|UNKNOWN
argument_list|,
literal|"Region "
operator|+
name|descriptiveName
operator|+
literal|" is in an unforeseen state:"
operator|+
literal|" inMeta="
operator|+
name|inMeta
operator|+
literal|" inHdfs="
operator|+
name|inHdfs
operator|+
literal|" isDeployed="
operator|+
name|isDeployed
operator|+
literal|" isMultiplyDeployed="
operator|+
name|isMultiplyDeployed
operator|+
literal|" deploymentMatchesMeta="
operator|+
name|deploymentMatchesMeta
operator|+
literal|" shouldBeDeployed="
operator|+
name|shouldBeDeployed
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Checks tables integrity. Goes over all regions and scans the tables.    * Collects all the pieces for each table and checks if there are missing,    * repeated or overlapping ones.    * @throws IOException    */
name|SortedMap
argument_list|<
name|TableName
argument_list|,
name|TableInfo
argument_list|>
name|checkIntegrity
parameter_list|()
throws|throws
name|IOException
block|{
name|tablesInfo
operator|=
operator|new
name|TreeMap
argument_list|<>
argument_list|()
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"There are "
operator|+
name|regionInfoMap
operator|.
name|size
argument_list|()
operator|+
literal|" region info entries"
argument_list|)
expr_stmt|;
for|for
control|(
name|HbckInfo
name|hbi
range|:
name|regionInfoMap
operator|.
name|values
argument_list|()
control|)
block|{
comment|// Check only valid, working regions
if|if
condition|(
name|hbi
operator|.
name|metaEntry
operator|==
literal|null
condition|)
block|{
comment|// this assumes that consistency check has run loadMetaEntry
name|Path
name|p
init|=
name|hbi
operator|.
name|getHdfsRegionDir
argument_list|()
decl_stmt|;
if|if
condition|(
name|p
operator|==
literal|null
condition|)
block|{
name|errors
operator|.
name|report
argument_list|(
literal|"No regioninfo in Meta or HDFS. "
operator|+
name|hbi
argument_list|)
expr_stmt|;
block|}
comment|// TODO test.
continue|continue;
block|}
if|if
condition|(
name|hbi
operator|.
name|metaEntry
operator|.
name|regionServer
operator|==
literal|null
condition|)
block|{
name|errors
operator|.
name|detail
argument_list|(
literal|"Skipping region because no region server: "
operator|+
name|hbi
argument_list|)
expr_stmt|;
continue|continue;
block|}
if|if
condition|(
name|hbi
operator|.
name|metaEntry
operator|.
name|isOffline
argument_list|()
condition|)
block|{
name|errors
operator|.
name|detail
argument_list|(
literal|"Skipping region because it is offline: "
operator|+
name|hbi
argument_list|)
expr_stmt|;
continue|continue;
block|}
if|if
condition|(
name|hbi
operator|.
name|containsOnlyHdfsEdits
argument_list|()
condition|)
block|{
name|errors
operator|.
name|detail
argument_list|(
literal|"Skipping region because it only contains edits"
operator|+
name|hbi
argument_list|)
expr_stmt|;
continue|continue;
block|}
comment|// Missing regionDir or over-deployment is checked elsewhere. Include
comment|// these cases in modTInfo, so we can evaluate those regions as part of
comment|// the region chain in META
comment|//if (hbi.foundRegionDir == null) continue;
comment|//if (hbi.deployedOn.size() != 1) continue;
if|if
condition|(
name|hbi
operator|.
name|deployedOn
operator|.
name|isEmpty
argument_list|()
condition|)
continue|continue;
comment|// We should be safe here
name|TableName
name|tableName
init|=
name|hbi
operator|.
name|metaEntry
operator|.
name|getTable
argument_list|()
decl_stmt|;
name|TableInfo
name|modTInfo
init|=
name|tablesInfo
operator|.
name|get
argument_list|(
name|tableName
argument_list|)
decl_stmt|;
if|if
condition|(
name|modTInfo
operator|==
literal|null
condition|)
block|{
name|modTInfo
operator|=
operator|new
name|TableInfo
argument_list|(
name|tableName
argument_list|)
expr_stmt|;
block|}
for|for
control|(
name|ServerName
name|server
range|:
name|hbi
operator|.
name|deployedOn
control|)
block|{
name|modTInfo
operator|.
name|addServer
argument_list|(
name|server
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|!
name|hbi
operator|.
name|isSkipChecks
argument_list|()
condition|)
block|{
name|modTInfo
operator|.
name|addRegionInfo
argument_list|(
name|hbi
argument_list|)
expr_stmt|;
block|}
name|tablesInfo
operator|.
name|put
argument_list|(
name|tableName
argument_list|,
name|modTInfo
argument_list|)
expr_stmt|;
block|}
name|loadTableInfosForTablesWithNoRegion
argument_list|()
expr_stmt|;
name|logParallelMerge
argument_list|()
expr_stmt|;
for|for
control|(
name|TableInfo
name|tInfo
range|:
name|tablesInfo
operator|.
name|values
argument_list|()
control|)
block|{
name|TableIntegrityErrorHandler
name|handler
init|=
name|tInfo
operator|.
expr|new
name|IntegrityFixSuggester
argument_list|(
name|tInfo
argument_list|,
name|errors
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|tInfo
operator|.
name|checkRegionChain
argument_list|(
name|handler
argument_list|)
condition|)
block|{
name|errors
operator|.
name|report
argument_list|(
literal|"Found inconsistency in table "
operator|+
name|tInfo
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|tablesInfo
return|;
block|}
comment|/** Loads table info's for tables that may not have been included, since there are no    * regions reported for the table, but table dir is there in hdfs    */
specifier|private
name|void
name|loadTableInfosForTablesWithNoRegion
parameter_list|()
throws|throws
name|IOException
block|{
name|Map
argument_list|<
name|String
argument_list|,
name|TableDescriptor
argument_list|>
name|allTables
init|=
operator|new
name|FSTableDescriptors
argument_list|(
name|getConf
argument_list|()
argument_list|)
operator|.
name|getAll
argument_list|()
decl_stmt|;
for|for
control|(
name|TableDescriptor
name|htd
range|:
name|allTables
operator|.
name|values
argument_list|()
control|)
block|{
if|if
condition|(
name|checkMetaOnly
operator|&&
operator|!
name|htd
operator|.
name|isMetaTable
argument_list|()
condition|)
block|{
continue|continue;
block|}
name|TableName
name|tableName
init|=
name|htd
operator|.
name|getTableName
argument_list|()
decl_stmt|;
if|if
condition|(
name|isTableIncluded
argument_list|(
name|tableName
argument_list|)
operator|&&
operator|!
name|tablesInfo
operator|.
name|containsKey
argument_list|(
name|tableName
argument_list|)
condition|)
block|{
name|TableInfo
name|tableInfo
init|=
operator|new
name|TableInfo
argument_list|(
name|tableName
argument_list|)
decl_stmt|;
name|tableInfo
operator|.
name|htds
operator|.
name|add
argument_list|(
name|htd
argument_list|)
expr_stmt|;
name|tablesInfo
operator|.
name|put
argument_list|(
name|htd
operator|.
name|getTableName
argument_list|()
argument_list|,
name|tableInfo
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|/**    * Merge hdfs data by moving from contained HbckInfo into targetRegionDir.    * @return number of file move fixes done to merge regions.    */
specifier|public
name|int
name|mergeRegionDirs
parameter_list|(
name|Path
name|targetRegionDir
parameter_list|,
name|HbckInfo
name|contained
parameter_list|)
throws|throws
name|IOException
block|{
name|int
name|fileMoves
init|=
literal|0
decl_stmt|;
name|String
name|thread
init|=
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|getName
argument_list|()
decl_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"["
operator|+
name|thread
operator|+
literal|"] Contained region dir after close and pause"
argument_list|)
expr_stmt|;
name|debugLsr
argument_list|(
name|contained
operator|.
name|getHdfsRegionDir
argument_list|()
argument_list|)
expr_stmt|;
comment|// rename the contained into the container.
name|FileSystem
name|fs
init|=
name|targetRegionDir
operator|.
name|getFileSystem
argument_list|(
name|getConf
argument_list|()
argument_list|)
decl_stmt|;
name|FileStatus
index|[]
name|dirs
init|=
literal|null
decl_stmt|;
try|try
block|{
name|dirs
operator|=
name|fs
operator|.
name|listStatus
argument_list|(
name|contained
operator|.
name|getHdfsRegionDir
argument_list|()
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|FileNotFoundException
name|fnfe
parameter_list|)
block|{
comment|// region we are attempting to merge in is not present!  Since this is a merge, there is
comment|// no harm skipping this region if it does not exist.
if|if
condition|(
operator|!
name|fs
operator|.
name|exists
argument_list|(
name|contained
operator|.
name|getHdfsRegionDir
argument_list|()
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"["
operator|+
name|thread
operator|+
literal|"] HDFS region dir "
operator|+
name|contained
operator|.
name|getHdfsRegionDir
argument_list|()
operator|+
literal|" is missing. Assuming already sidelined or moved."
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|sidelineRegionDir
argument_list|(
name|fs
argument_list|,
name|contained
argument_list|)
expr_stmt|;
block|}
return|return
name|fileMoves
return|;
block|}
if|if
condition|(
name|dirs
operator|==
literal|null
condition|)
block|{
if|if
condition|(
operator|!
name|fs
operator|.
name|exists
argument_list|(
name|contained
operator|.
name|getHdfsRegionDir
argument_list|()
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"["
operator|+
name|thread
operator|+
literal|"] HDFS region dir "
operator|+
name|contained
operator|.
name|getHdfsRegionDir
argument_list|()
operator|+
literal|" already sidelined."
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|sidelineRegionDir
argument_list|(
name|fs
argument_list|,
name|contained
argument_list|)
expr_stmt|;
block|}
return|return
name|fileMoves
return|;
block|}
for|for
control|(
name|FileStatus
name|cf
range|:
name|dirs
control|)
block|{
name|Path
name|src
init|=
name|cf
operator|.
name|getPath
argument_list|()
decl_stmt|;
name|Path
name|dst
init|=
operator|new
name|Path
argument_list|(
name|targetRegionDir
argument_list|,
name|src
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|src
operator|.
name|getName
argument_list|()
operator|.
name|equals
argument_list|(
name|HRegionFileSystem
operator|.
name|REGION_INFO_FILE
argument_list|)
condition|)
block|{
comment|// do not copy the old .regioninfo file.
continue|continue;
block|}
if|if
condition|(
name|src
operator|.
name|getName
argument_list|()
operator|.
name|equals
argument_list|(
name|HConstants
operator|.
name|HREGION_OLDLOGDIR_NAME
argument_list|)
condition|)
block|{
comment|// do not copy the .oldlogs files
continue|continue;
block|}
name|LOG
operator|.
name|info
argument_list|(
literal|"["
operator|+
name|thread
operator|+
literal|"] Moving files from "
operator|+
name|src
operator|+
literal|" into containing region "
operator|+
name|dst
argument_list|)
expr_stmt|;
comment|// FileSystem.rename is inconsistent with directories -- if the
comment|// dst (foo/a) exists and is a dir, and the src (foo/b) is a dir,
comment|// it moves the src into the dst dir resulting in (foo/a/b).  If
comment|// the dst does not exist, and the src a dir, src becomes dst. (foo/b)
for|for
control|(
name|FileStatus
name|hfile
range|:
name|fs
operator|.
name|listStatus
argument_list|(
name|src
argument_list|)
control|)
block|{
name|boolean
name|success
init|=
name|fs
operator|.
name|rename
argument_list|(
name|hfile
operator|.
name|getPath
argument_list|()
argument_list|,
name|dst
argument_list|)
decl_stmt|;
if|if
condition|(
name|success
condition|)
block|{
name|fileMoves
operator|++
expr_stmt|;
block|}
block|}
name|LOG
operator|.
name|debug
argument_list|(
literal|"["
operator|+
name|thread
operator|+
literal|"] Sideline directory contents:"
argument_list|)
expr_stmt|;
name|debugLsr
argument_list|(
name|targetRegionDir
argument_list|)
expr_stmt|;
block|}
comment|// if all success.
name|sidelineRegionDir
argument_list|(
name|fs
argument_list|,
name|contained
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"["
operator|+
name|thread
operator|+
literal|"] Sidelined region dir "
operator|+
name|contained
operator|.
name|getHdfsRegionDir
argument_list|()
operator|+
literal|" into "
operator|+
name|getSidelineDir
argument_list|()
argument_list|)
expr_stmt|;
name|debugLsr
argument_list|(
name|contained
operator|.
name|getHdfsRegionDir
argument_list|()
argument_list|)
expr_stmt|;
return|return
name|fileMoves
return|;
block|}
specifier|static
class|class
name|WorkItemOverlapMerge
implements|implements
name|Callable
argument_list|<
name|Void
argument_list|>
block|{
specifier|private
name|TableIntegrityErrorHandler
name|handler
decl_stmt|;
name|Collection
argument_list|<
name|HbckInfo
argument_list|>
name|overlapgroup
decl_stmt|;
name|WorkItemOverlapMerge
parameter_list|(
name|Collection
argument_list|<
name|HbckInfo
argument_list|>
name|overlapgroup
parameter_list|,
name|TableIntegrityErrorHandler
name|handler
parameter_list|)
block|{
name|this
operator|.
name|handler
operator|=
name|handler
expr_stmt|;
name|this
operator|.
name|overlapgroup
operator|=
name|overlapgroup
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|Void
name|call
parameter_list|()
throws|throws
name|Exception
block|{
name|handler
operator|.
name|handleOverlapGroup
argument_list|(
name|overlapgroup
argument_list|)
expr_stmt|;
return|return
literal|null
return|;
block|}
block|}
comment|/**    * Maintain information about a particular table.    */
specifier|public
class|class
name|TableInfo
block|{
name|TableName
name|tableName
decl_stmt|;
name|TreeSet
argument_list|<
name|ServerName
argument_list|>
name|deployedOn
decl_stmt|;
comment|// backwards regions
specifier|final
name|List
argument_list|<
name|HbckInfo
argument_list|>
name|backwards
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
comment|// sidelined big overlapped regions
specifier|final
name|Map
argument_list|<
name|Path
argument_list|,
name|HbckInfo
argument_list|>
name|sidelinedRegions
init|=
operator|new
name|HashMap
argument_list|<>
argument_list|()
decl_stmt|;
comment|// region split calculator
specifier|final
name|RegionSplitCalculator
argument_list|<
name|HbckInfo
argument_list|>
name|sc
init|=
operator|new
name|RegionSplitCalculator
argument_list|<>
argument_list|(
name|cmp
argument_list|)
decl_stmt|;
comment|// Histogram of different TableDescriptors found.  Ideally there is only one!
specifier|final
name|Set
argument_list|<
name|TableDescriptor
argument_list|>
name|htds
init|=
operator|new
name|HashSet
argument_list|<>
argument_list|()
decl_stmt|;
comment|// key = start split, values = set of splits in problem group
specifier|final
name|Multimap
argument_list|<
name|byte
index|[]
argument_list|,
name|HbckInfo
argument_list|>
name|overlapGroups
init|=
name|TreeMultimap
operator|.
name|create
argument_list|(
name|RegionSplitCalculator
operator|.
name|BYTES_COMPARATOR
argument_list|,
name|cmp
argument_list|)
decl_stmt|;
comment|// list of regions derived from meta entries.
specifier|private
name|ImmutableList
argument_list|<
name|RegionInfo
argument_list|>
name|regionsFromMeta
init|=
literal|null
decl_stmt|;
name|TableInfo
parameter_list|(
name|TableName
name|name
parameter_list|)
block|{
name|this
operator|.
name|tableName
operator|=
name|name
expr_stmt|;
name|deployedOn
operator|=
operator|new
name|TreeSet
argument_list|<>
argument_list|()
expr_stmt|;
block|}
comment|/**      * @return descriptor common to all regions.  null if are none or multiple!      */
specifier|private
name|TableDescriptor
name|getHTD
parameter_list|()
block|{
if|if
condition|(
name|htds
operator|.
name|size
argument_list|()
operator|==
literal|1
condition|)
block|{
return|return
operator|(
name|TableDescriptor
operator|)
name|htds
operator|.
name|toArray
argument_list|()
index|[
literal|0
index|]
return|;
block|}
else|else
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"None/Multiple table descriptors found for table '"
operator|+
name|tableName
operator|+
literal|"' regions: "
operator|+
name|htds
argument_list|)
expr_stmt|;
block|}
return|return
literal|null
return|;
block|}
specifier|public
name|void
name|addRegionInfo
parameter_list|(
name|HbckInfo
name|hir
parameter_list|)
block|{
if|if
condition|(
name|Bytes
operator|.
name|equals
argument_list|(
name|hir
operator|.
name|getEndKey
argument_list|()
argument_list|,
name|HConstants
operator|.
name|EMPTY_END_ROW
argument_list|)
condition|)
block|{
comment|// end key is absolute end key, just add it.
comment|// ignore replicas other than primary for these checks
if|if
condition|(
name|hir
operator|.
name|getReplicaId
argument_list|()
operator|==
name|RegionInfo
operator|.
name|DEFAULT_REPLICA_ID
condition|)
name|sc
operator|.
name|add
argument_list|(
name|hir
argument_list|)
expr_stmt|;
return|return;
block|}
comment|// if not the absolute end key, check for cycle
if|if
condition|(
name|Bytes
operator|.
name|compareTo
argument_list|(
name|hir
operator|.
name|getStartKey
argument_list|()
argument_list|,
name|hir
operator|.
name|getEndKey
argument_list|()
argument_list|)
operator|>
literal|0
condition|)
block|{
name|errors
operator|.
name|reportError
argument_list|(
name|ERROR_CODE
operator|.
name|REGION_CYCLE
argument_list|,
name|String
operator|.
name|format
argument_list|(
literal|"The endkey for this region comes before the "
operator|+
literal|"startkey, startkey=%s, endkey=%s"
argument_list|,
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|hir
operator|.
name|getStartKey
argument_list|()
argument_list|)
argument_list|,
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|hir
operator|.
name|getEndKey
argument_list|()
argument_list|)
argument_list|)
argument_list|,
name|this
argument_list|,
name|hir
argument_list|)
expr_stmt|;
name|backwards
operator|.
name|add
argument_list|(
name|hir
argument_list|)
expr_stmt|;
return|return;
block|}
comment|// main case, add to split calculator
comment|// ignore replicas other than primary for these checks
if|if
condition|(
name|hir
operator|.
name|getReplicaId
argument_list|()
operator|==
name|RegionInfo
operator|.
name|DEFAULT_REPLICA_ID
condition|)
name|sc
operator|.
name|add
argument_list|(
name|hir
argument_list|)
expr_stmt|;
block|}
specifier|public
name|void
name|addServer
parameter_list|(
name|ServerName
name|server
parameter_list|)
block|{
name|this
operator|.
name|deployedOn
operator|.
name|add
argument_list|(
name|server
argument_list|)
expr_stmt|;
block|}
specifier|public
name|TableName
name|getName
parameter_list|()
block|{
return|return
name|tableName
return|;
block|}
specifier|public
name|int
name|getNumRegions
parameter_list|()
block|{
return|return
name|sc
operator|.
name|getStarts
argument_list|()
operator|.
name|size
argument_list|()
operator|+
name|backwards
operator|.
name|size
argument_list|()
return|;
block|}
specifier|public
specifier|synchronized
name|ImmutableList
argument_list|<
name|RegionInfo
argument_list|>
name|getRegionsFromMeta
parameter_list|()
block|{
comment|// lazy loaded, synchronized to ensure a single load
if|if
condition|(
name|regionsFromMeta
operator|==
literal|null
condition|)
block|{
name|List
argument_list|<
name|RegionInfo
argument_list|>
name|regions
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
for|for
control|(
name|HbckInfo
name|h
range|:
name|HBaseFsck
operator|.
name|this
operator|.
name|regionInfoMap
operator|.
name|values
argument_list|()
control|)
block|{
if|if
condition|(
name|tableName
operator|.
name|equals
argument_list|(
name|h
operator|.
name|getTableName
argument_list|()
argument_list|)
condition|)
block|{
if|if
condition|(
name|h
operator|.
name|metaEntry
operator|!=
literal|null
condition|)
block|{
name|regions
operator|.
name|add
argument_list|(
name|h
operator|.
name|metaEntry
argument_list|)
expr_stmt|;
block|}
block|}
block|}
name|regionsFromMeta
operator|=
name|Ordering
operator|.
name|from
argument_list|(
name|RegionInfo
operator|.
name|COMPARATOR
argument_list|)
operator|.
name|immutableSortedCopy
argument_list|(
name|regions
argument_list|)
expr_stmt|;
block|}
return|return
name|regionsFromMeta
return|;
block|}
specifier|private
class|class
name|IntegrityFixSuggester
extends|extends
name|TableIntegrityErrorHandlerImpl
block|{
name|ErrorReporter
name|errors
decl_stmt|;
name|IntegrityFixSuggester
parameter_list|(
name|TableInfo
name|ti
parameter_list|,
name|ErrorReporter
name|errors
parameter_list|)
block|{
name|this
operator|.
name|errors
operator|=
name|errors
expr_stmt|;
name|setTableInfo
argument_list|(
name|ti
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|handleRegionStartKeyNotEmpty
parameter_list|(
name|HbckInfo
name|hi
parameter_list|)
throws|throws
name|IOException
block|{
name|errors
operator|.
name|reportError
argument_list|(
name|ERROR_CODE
operator|.
name|FIRST_REGION_STARTKEY_NOT_EMPTY
argument_list|,
literal|"First region should start with an empty key.  You need to "
operator|+
literal|" create a new region and regioninfo in HDFS to plug the hole."
argument_list|,
name|getTableInfo
argument_list|()
argument_list|,
name|hi
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|handleRegionEndKeyNotEmpty
parameter_list|(
name|byte
index|[]
name|curEndKey
parameter_list|)
throws|throws
name|IOException
block|{
name|errors
operator|.
name|reportError
argument_list|(
name|ERROR_CODE
operator|.
name|LAST_REGION_ENDKEY_NOT_EMPTY
argument_list|,
literal|"Last region should end with an empty key. You need to "
operator|+
literal|"create a new region and regioninfo in HDFS to plug the hole."
argument_list|,
name|getTableInfo
argument_list|()
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|handleDegenerateRegion
parameter_list|(
name|HbckInfo
name|hi
parameter_list|)
throws|throws
name|IOException
block|{
name|errors
operator|.
name|reportError
argument_list|(
name|ERROR_CODE
operator|.
name|DEGENERATE_REGION
argument_list|,
literal|"Region has the same start and end key."
argument_list|,
name|getTableInfo
argument_list|()
argument_list|,
name|hi
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|handleDuplicateStartKeys
parameter_list|(
name|HbckInfo
name|r1
parameter_list|,
name|HbckInfo
name|r2
parameter_list|)
throws|throws
name|IOException
block|{
name|byte
index|[]
name|key
init|=
name|r1
operator|.
name|getStartKey
argument_list|()
decl_stmt|;
comment|// dup start key
name|errors
operator|.
name|reportError
argument_list|(
name|ERROR_CODE
operator|.
name|DUPE_STARTKEYS
argument_list|,
literal|"Multiple regions have the same startkey: "
operator|+
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|key
argument_list|)
argument_list|,
name|getTableInfo
argument_list|()
argument_list|,
name|r1
argument_list|)
expr_stmt|;
name|errors
operator|.
name|reportError
argument_list|(
name|ERROR_CODE
operator|.
name|DUPE_STARTKEYS
argument_list|,
literal|"Multiple regions have the same startkey: "
operator|+
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|key
argument_list|)
argument_list|,
name|getTableInfo
argument_list|()
argument_list|,
name|r2
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|handleSplit
parameter_list|(
name|HbckInfo
name|r1
parameter_list|,
name|HbckInfo
name|r2
parameter_list|)
throws|throws
name|IOException
block|{
name|byte
index|[]
name|key
init|=
name|r1
operator|.
name|getStartKey
argument_list|()
decl_stmt|;
comment|// dup start key
name|errors
operator|.
name|reportError
argument_list|(
name|ERROR_CODE
operator|.
name|DUPE_ENDKEYS
argument_list|,
literal|"Multiple regions have the same regionID: "
operator|+
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|key
argument_list|)
argument_list|,
name|getTableInfo
argument_list|()
argument_list|,
name|r1
argument_list|)
expr_stmt|;
name|errors
operator|.
name|reportError
argument_list|(
name|ERROR_CODE
operator|.
name|DUPE_ENDKEYS
argument_list|,
literal|"Multiple regions have the same regionID: "
operator|+
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|key
argument_list|)
argument_list|,
name|getTableInfo
argument_list|()
argument_list|,
name|r2
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|handleOverlapInRegionChain
parameter_list|(
name|HbckInfo
name|hi1
parameter_list|,
name|HbckInfo
name|hi2
parameter_list|)
throws|throws
name|IOException
block|{
name|errors
operator|.
name|reportError
argument_list|(
name|ERROR_CODE
operator|.
name|OVERLAP_IN_REGION_CHAIN
argument_list|,
literal|"There is an overlap in the region chain."
argument_list|,
name|getTableInfo
argument_list|()
argument_list|,
name|hi1
argument_list|,
name|hi2
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|handleHoleInRegionChain
parameter_list|(
name|byte
index|[]
name|holeStart
parameter_list|,
name|byte
index|[]
name|holeStop
parameter_list|)
throws|throws
name|IOException
block|{
name|errors
operator|.
name|reportError
argument_list|(
name|ERROR_CODE
operator|.
name|HOLE_IN_REGION_CHAIN
argument_list|,
literal|"There is a hole in the region chain between "
operator|+
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|holeStart
argument_list|)
operator|+
literal|" and "
operator|+
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|holeStop
argument_list|)
operator|+
literal|".  You need to create a new .regioninfo and region "
operator|+
literal|"dir in hdfs to plug the hole."
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**      * This handler fixes integrity errors from hdfs information.  There are      * basically three classes of integrity problems 1) holes, 2) overlaps, and      * 3) invalid regions.      *      * This class overrides methods that fix holes and the overlap group case.      * Individual cases of particular overlaps are handled by the general      * overlap group merge repair case.      *      * If hbase is online, this forces regions offline before doing merge      * operations.      */
specifier|private
class|class
name|HDFSIntegrityFixer
extends|extends
name|IntegrityFixSuggester
block|{
name|Configuration
name|conf
decl_stmt|;
name|boolean
name|fixOverlaps
init|=
literal|true
decl_stmt|;
name|HDFSIntegrityFixer
parameter_list|(
name|TableInfo
name|ti
parameter_list|,
name|ErrorReporter
name|errors
parameter_list|,
name|Configuration
name|conf
parameter_list|,
name|boolean
name|fixHoles
parameter_list|,
name|boolean
name|fixOverlaps
parameter_list|)
block|{
name|super
argument_list|(
name|ti
argument_list|,
name|errors
argument_list|)
expr_stmt|;
name|this
operator|.
name|conf
operator|=
name|conf
expr_stmt|;
name|this
operator|.
name|fixOverlaps
operator|=
name|fixOverlaps
expr_stmt|;
comment|// TODO properly use fixHoles
block|}
comment|/**        * This is a special case hole -- when the first region of a table is        * missing from META, HBase doesn't acknowledge the existance of the        * table.        */
annotation|@
name|Override
specifier|public
name|void
name|handleRegionStartKeyNotEmpty
parameter_list|(
name|HbckInfo
name|next
parameter_list|)
throws|throws
name|IOException
block|{
name|errors
operator|.
name|reportError
argument_list|(
name|ERROR_CODE
operator|.
name|FIRST_REGION_STARTKEY_NOT_EMPTY
argument_list|,
literal|"First region should start with an empty key.  Creating a new "
operator|+
literal|"region and regioninfo in HDFS to plug the hole."
argument_list|,
name|getTableInfo
argument_list|()
argument_list|,
name|next
argument_list|)
expr_stmt|;
name|TableDescriptor
name|htd
init|=
name|getTableInfo
argument_list|()
operator|.
name|getHTD
argument_list|()
decl_stmt|;
comment|// from special EMPTY_START_ROW to next region's startKey
name|RegionInfo
name|newRegion
init|=
name|RegionInfoBuilder
operator|.
name|newBuilder
argument_list|(
name|htd
operator|.
name|getTableName
argument_list|()
argument_list|)
operator|.
name|setStartKey
argument_list|(
name|HConstants
operator|.
name|EMPTY_START_ROW
argument_list|)
operator|.
name|setEndKey
argument_list|(
name|next
operator|.
name|getStartKey
argument_list|()
argument_list|)
operator|.
name|build
argument_list|()
decl_stmt|;
comment|// TODO test
name|HRegion
name|region
init|=
name|HBaseFsckRepair
operator|.
name|createHDFSRegionDir
argument_list|(
name|conf
argument_list|,
name|newRegion
argument_list|,
name|htd
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Table region start key was not empty.  Created new empty region: "
operator|+
name|newRegion
operator|+
literal|" "
operator|+
name|region
argument_list|)
expr_stmt|;
name|fixes
operator|++
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|handleRegionEndKeyNotEmpty
parameter_list|(
name|byte
index|[]
name|curEndKey
parameter_list|)
throws|throws
name|IOException
block|{
name|errors
operator|.
name|reportError
argument_list|(
name|ERROR_CODE
operator|.
name|LAST_REGION_ENDKEY_NOT_EMPTY
argument_list|,
literal|"Last region should end with an empty key.  Creating a new "
operator|+
literal|"region and regioninfo in HDFS to plug the hole."
argument_list|,
name|getTableInfo
argument_list|()
argument_list|)
expr_stmt|;
name|TableDescriptor
name|htd
init|=
name|getTableInfo
argument_list|()
operator|.
name|getHTD
argument_list|()
decl_stmt|;
comment|// from curEndKey to EMPTY_START_ROW
name|RegionInfo
name|newRegion
init|=
name|RegionInfoBuilder
operator|.
name|newBuilder
argument_list|(
name|htd
operator|.
name|getTableName
argument_list|()
argument_list|)
operator|.
name|setStartKey
argument_list|(
name|curEndKey
argument_list|)
operator|.
name|setEndKey
argument_list|(
name|HConstants
operator|.
name|EMPTY_START_ROW
argument_list|)
operator|.
name|build
argument_list|()
decl_stmt|;
name|HRegion
name|region
init|=
name|HBaseFsckRepair
operator|.
name|createHDFSRegionDir
argument_list|(
name|conf
argument_list|,
name|newRegion
argument_list|,
name|htd
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Table region end key was not empty.  Created new empty region: "
operator|+
name|newRegion
operator|+
literal|" "
operator|+
name|region
argument_list|)
expr_stmt|;
name|fixes
operator|++
expr_stmt|;
block|}
comment|/**        * There is a hole in the hdfs regions that violates the table integrity        * rules.  Create a new empty region that patches the hole.        */
annotation|@
name|Override
specifier|public
name|void
name|handleHoleInRegionChain
parameter_list|(
name|byte
index|[]
name|holeStartKey
parameter_list|,
name|byte
index|[]
name|holeStopKey
parameter_list|)
throws|throws
name|IOException
block|{
name|errors
operator|.
name|reportError
argument_list|(
name|ERROR_CODE
operator|.
name|HOLE_IN_REGION_CHAIN
argument_list|,
literal|"There is a hole in the region chain between "
operator|+
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|holeStartKey
argument_list|)
operator|+
literal|" and "
operator|+
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|holeStopKey
argument_list|)
operator|+
literal|".  Creating a new regioninfo and region "
operator|+
literal|"dir in hdfs to plug the hole."
argument_list|)
expr_stmt|;
name|TableDescriptor
name|htd
init|=
name|getTableInfo
argument_list|()
operator|.
name|getHTD
argument_list|()
decl_stmt|;
name|RegionInfo
name|newRegion
init|=
name|RegionInfoBuilder
operator|.
name|newBuilder
argument_list|(
name|htd
operator|.
name|getTableName
argument_list|()
argument_list|)
operator|.
name|setStartKey
argument_list|(
name|holeStartKey
argument_list|)
operator|.
name|setEndKey
argument_list|(
name|holeStopKey
argument_list|)
operator|.
name|build
argument_list|()
decl_stmt|;
name|HRegion
name|region
init|=
name|HBaseFsckRepair
operator|.
name|createHDFSRegionDir
argument_list|(
name|conf
argument_list|,
name|newRegion
argument_list|,
name|htd
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Plugged hole by creating new empty region: "
operator|+
name|newRegion
operator|+
literal|" "
operator|+
name|region
argument_list|)
expr_stmt|;
name|fixes
operator|++
expr_stmt|;
block|}
comment|/**        * This takes set of overlapping regions and merges them into a single        * region.  This covers cases like degenerate regions, shared start key,        * general overlaps, duplicate ranges, and partial overlapping regions.        *        * Cases:        * - Clean regions that overlap        * - Only .oldlogs regions (can't find start/stop range, or figure out)        *        * This is basically threadsafe, except for the fixer increment in mergeOverlaps.        */
annotation|@
name|Override
specifier|public
name|void
name|handleOverlapGroup
parameter_list|(
name|Collection
argument_list|<
name|HbckInfo
argument_list|>
name|overlap
parameter_list|)
throws|throws
name|IOException
block|{
name|Preconditions
operator|.
name|checkNotNull
argument_list|(
name|overlap
argument_list|)
expr_stmt|;
name|Preconditions
operator|.
name|checkArgument
argument_list|(
name|overlap
operator|.
name|size
argument_list|()
operator|>
literal|0
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|this
operator|.
name|fixOverlaps
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Not attempting to repair overlaps."
argument_list|)
expr_stmt|;
return|return;
block|}
if|if
condition|(
name|overlap
operator|.
name|size
argument_list|()
operator|>
name|maxMerge
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Overlap group has "
operator|+
name|overlap
operator|.
name|size
argument_list|()
operator|+
literal|" overlapping "
operator|+
literal|"regions which is greater than "
operator|+
name|maxMerge
operator|+
literal|", the max number of regions to merge"
argument_list|)
expr_stmt|;
if|if
condition|(
name|sidelineBigOverlaps
condition|)
block|{
comment|// we only sideline big overlapped groups that exceeds the max number of regions to merge
name|sidelineBigOverlaps
argument_list|(
name|overlap
argument_list|)
expr_stmt|;
block|}
return|return;
block|}
if|if
condition|(
name|shouldRemoveParents
argument_list|()
condition|)
block|{
name|removeParentsAndFixSplits
argument_list|(
name|overlap
argument_list|)
expr_stmt|;
block|}
name|mergeOverlaps
argument_list|(
name|overlap
argument_list|)
expr_stmt|;
block|}
name|void
name|removeParentsAndFixSplits
parameter_list|(
name|Collection
argument_list|<
name|HbckInfo
argument_list|>
name|overlap
parameter_list|)
throws|throws
name|IOException
block|{
name|Pair
argument_list|<
name|byte
index|[]
argument_list|,
name|byte
index|[]
argument_list|>
name|range
init|=
literal|null
decl_stmt|;
name|HbckInfo
name|parent
init|=
literal|null
decl_stmt|;
name|HbckInfo
name|daughterA
init|=
literal|null
decl_stmt|;
name|HbckInfo
name|daughterB
init|=
literal|null
decl_stmt|;
name|Collection
argument_list|<
name|HbckInfo
argument_list|>
name|daughters
init|=
operator|new
name|ArrayList
argument_list|<
name|HbckInfo
argument_list|>
argument_list|(
name|overlap
argument_list|)
decl_stmt|;
name|String
name|thread
init|=
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|getName
argument_list|()
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"== ["
operator|+
name|thread
operator|+
literal|"] Attempting fix splits in overlap state."
argument_list|)
expr_stmt|;
comment|// we only can handle a single split per group at the time
if|if
condition|(
name|overlap
operator|.
name|size
argument_list|()
operator|>
literal|3
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Too many overlaps were found on this group, falling back to regular merge."
argument_list|)
expr_stmt|;
return|return;
block|}
for|for
control|(
name|HbckInfo
name|hi
range|:
name|overlap
control|)
block|{
if|if
condition|(
name|range
operator|==
literal|null
condition|)
block|{
name|range
operator|=
operator|new
name|Pair
argument_list|<
name|byte
index|[]
argument_list|,
name|byte
index|[]
argument_list|>
argument_list|(
name|hi
operator|.
name|getStartKey
argument_list|()
argument_list|,
name|hi
operator|.
name|getEndKey
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
if|if
condition|(
name|RegionSplitCalculator
operator|.
name|BYTES_COMPARATOR
operator|.
name|compare
argument_list|(
name|hi
operator|.
name|getStartKey
argument_list|()
argument_list|,
name|range
operator|.
name|getFirst
argument_list|()
argument_list|)
operator|<
literal|0
condition|)
block|{
name|range
operator|.
name|setFirst
argument_list|(
name|hi
operator|.
name|getStartKey
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|RegionSplitCalculator
operator|.
name|BYTES_COMPARATOR
operator|.
name|compare
argument_list|(
name|hi
operator|.
name|getEndKey
argument_list|()
argument_list|,
name|range
operator|.
name|getSecond
argument_list|()
argument_list|)
operator|>
literal|0
condition|)
block|{
name|range
operator|.
name|setSecond
argument_list|(
name|hi
operator|.
name|getEndKey
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
block|}
name|LOG
operator|.
name|info
argument_list|(
literal|"This group range is ["
operator|+
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|range
operator|.
name|getFirst
argument_list|()
argument_list|)
operator|+
literal|", "
operator|+
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|range
operator|.
name|getSecond
argument_list|()
argument_list|)
operator|+
literal|"]"
argument_list|)
expr_stmt|;
comment|// attempt to find a possible parent for the edge case of a split
for|for
control|(
name|HbckInfo
name|hi
range|:
name|overlap
control|)
block|{
if|if
condition|(
name|Bytes
operator|.
name|compareTo
argument_list|(
name|hi
operator|.
name|getHdfsHRI
argument_list|()
operator|.
name|getStartKey
argument_list|()
argument_list|,
name|range
operator|.
name|getFirst
argument_list|()
argument_list|)
operator|==
literal|0
operator|&&
name|Bytes
operator|.
name|compareTo
argument_list|(
name|hi
operator|.
name|getHdfsHRI
argument_list|()
operator|.
name|getEndKey
argument_list|()
argument_list|,
name|range
operator|.
name|getSecond
argument_list|()
argument_list|)
operator|==
literal|0
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"This is a parent for this group: "
operator|+
name|hi
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
name|parent
operator|=
name|hi
expr_stmt|;
block|}
block|}
comment|// Remove parent regions from daughters collection
if|if
condition|(
name|parent
operator|!=
literal|null
condition|)
block|{
name|daughters
operator|.
name|remove
argument_list|(
name|parent
argument_list|)
expr_stmt|;
block|}
comment|// Lets verify that daughters share the regionID at split time and they
comment|// were created after the parent
for|for
control|(
name|HbckInfo
name|hi
range|:
name|daughters
control|)
block|{
if|if
condition|(
name|Bytes
operator|.
name|compareTo
argument_list|(
name|hi
operator|.
name|getHdfsHRI
argument_list|()
operator|.
name|getStartKey
argument_list|()
argument_list|,
name|range
operator|.
name|getFirst
argument_list|()
argument_list|)
operator|==
literal|0
condition|)
block|{
if|if
condition|(
name|parent
operator|.
name|getHdfsHRI
argument_list|()
operator|.
name|getRegionId
argument_list|()
operator|<
name|hi
operator|.
name|getHdfsHRI
argument_list|()
operator|.
name|getRegionId
argument_list|()
condition|)
block|{
name|daughterA
operator|=
name|hi
expr_stmt|;
block|}
block|}
if|if
condition|(
name|Bytes
operator|.
name|compareTo
argument_list|(
name|hi
operator|.
name|getHdfsHRI
argument_list|()
operator|.
name|getEndKey
argument_list|()
argument_list|,
name|range
operator|.
name|getSecond
argument_list|()
argument_list|)
operator|==
literal|0
condition|)
block|{
if|if
condition|(
name|parent
operator|.
name|getHdfsHRI
argument_list|()
operator|.
name|getRegionId
argument_list|()
operator|<
name|hi
operator|.
name|getHdfsHRI
argument_list|()
operator|.
name|getRegionId
argument_list|()
condition|)
block|{
name|daughterB
operator|=
name|hi
expr_stmt|;
block|}
block|}
block|}
comment|// daughters must share the same regionID and we should have a parent too
if|if
condition|(
name|daughterA
operator|.
name|getHdfsHRI
argument_list|()
operator|.
name|getRegionId
argument_list|()
operator|!=
name|daughterB
operator|.
name|getHdfsHRI
argument_list|()
operator|.
name|getRegionId
argument_list|()
operator|||
name|parent
operator|==
literal|null
condition|)
return|return;
name|FileSystem
name|fs
init|=
name|FileSystem
operator|.
name|get
argument_list|(
name|conf
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Found parent: "
operator|+
name|parent
operator|.
name|getRegionNameAsString
argument_list|()
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Found potential daughter a: "
operator|+
name|daughterA
operator|.
name|getRegionNameAsString
argument_list|()
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Found potential daughter b: "
operator|+
name|daughterB
operator|.
name|getRegionNameAsString
argument_list|()
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Trying to fix parent in overlap by removing the parent."
argument_list|)
expr_stmt|;
try|try
block|{
name|closeRegion
argument_list|(
name|parent
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ioe
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Parent region could not be closed, continuing with regular merge..."
argument_list|,
name|ioe
argument_list|)
expr_stmt|;
return|return;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|ie
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Parent region could not be closed, continuing with regular merge..."
argument_list|,
name|ie
argument_list|)
expr_stmt|;
return|return;
block|}
try|try
block|{
name|offline
argument_list|(
name|parent
operator|.
name|getRegionName
argument_list|()
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ioe
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Unable to offline parent region: "
operator|+
name|parent
operator|.
name|getRegionNameAsString
argument_list|()
operator|+
literal|".  Just continuing with regular merge... "
argument_list|,
name|ioe
argument_list|)
expr_stmt|;
return|return;
block|}
try|try
block|{
name|HBaseFsckRepair
operator|.
name|removeParentInMeta
argument_list|(
name|conf
argument_list|,
name|parent
operator|.
name|getHdfsHRI
argument_list|()
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ioe
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Unable to remove parent region in META: "
operator|+
name|parent
operator|.
name|getRegionNameAsString
argument_list|()
operator|+
literal|".  Just continuing with regular merge... "
argument_list|,
name|ioe
argument_list|)
expr_stmt|;
return|return;
block|}
name|sidelineRegionDir
argument_list|(
name|fs
argument_list|,
name|parent
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"["
operator|+
name|thread
operator|+
literal|"] Sidelined parent region dir "
operator|+
name|parent
operator|.
name|getHdfsRegionDir
argument_list|()
operator|+
literal|" into "
operator|+
name|getSidelineDir
argument_list|()
argument_list|)
expr_stmt|;
name|debugLsr
argument_list|(
name|parent
operator|.
name|getHdfsRegionDir
argument_list|()
argument_list|)
expr_stmt|;
comment|// Make sure we don't have the parents and daughters around
name|overlap
operator|.
name|remove
argument_list|(
name|parent
argument_list|)
expr_stmt|;
name|overlap
operator|.
name|remove
argument_list|(
name|daughterA
argument_list|)
expr_stmt|;
name|overlap
operator|.
name|remove
argument_list|(
name|daughterB
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Done fixing split."
argument_list|)
expr_stmt|;
block|}
name|void
name|mergeOverlaps
parameter_list|(
name|Collection
argument_list|<
name|HbckInfo
argument_list|>
name|overlap
parameter_list|)
throws|throws
name|IOException
block|{
name|String
name|thread
init|=
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|getName
argument_list|()
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"== ["
operator|+
name|thread
operator|+
literal|"] Merging regions into one region: "
operator|+
name|Joiner
operator|.
name|on
argument_list|(
literal|","
argument_list|)
operator|.
name|join
argument_list|(
name|overlap
argument_list|)
argument_list|)
expr_stmt|;
comment|// get the min / max range and close all concerned regions
name|Pair
argument_list|<
name|byte
index|[]
argument_list|,
name|byte
index|[]
argument_list|>
name|range
init|=
literal|null
decl_stmt|;
for|for
control|(
name|HbckInfo
name|hi
range|:
name|overlap
control|)
block|{
if|if
condition|(
name|range
operator|==
literal|null
condition|)
block|{
name|range
operator|=
operator|new
name|Pair
argument_list|<>
argument_list|(
name|hi
operator|.
name|getStartKey
argument_list|()
argument_list|,
name|hi
operator|.
name|getEndKey
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
if|if
condition|(
name|RegionSplitCalculator
operator|.
name|BYTES_COMPARATOR
operator|.
name|compare
argument_list|(
name|hi
operator|.
name|getStartKey
argument_list|()
argument_list|,
name|range
operator|.
name|getFirst
argument_list|()
argument_list|)
operator|<
literal|0
condition|)
block|{
name|range
operator|.
name|setFirst
argument_list|(
name|hi
operator|.
name|getStartKey
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|RegionSplitCalculator
operator|.
name|BYTES_COMPARATOR
operator|.
name|compare
argument_list|(
name|hi
operator|.
name|getEndKey
argument_list|()
argument_list|,
name|range
operator|.
name|getSecond
argument_list|()
argument_list|)
operator|>
literal|0
condition|)
block|{
name|range
operator|.
name|setSecond
argument_list|(
name|hi
operator|.
name|getEndKey
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
comment|// need to close files so delete can happen.
name|LOG
operator|.
name|debug
argument_list|(
literal|"["
operator|+
name|thread
operator|+
literal|"] Closing region before moving data around: "
operator|+
name|hi
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"["
operator|+
name|thread
operator|+
literal|"] Contained region dir before close"
argument_list|)
expr_stmt|;
name|debugLsr
argument_list|(
name|hi
operator|.
name|getHdfsRegionDir
argument_list|()
argument_list|)
expr_stmt|;
try|try
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"["
operator|+
name|thread
operator|+
literal|"] Closing region: "
operator|+
name|hi
argument_list|)
expr_stmt|;
name|closeRegion
argument_list|(
name|hi
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ioe
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"["
operator|+
name|thread
operator|+
literal|"] Was unable to close region "
operator|+
name|hi
operator|+
literal|".  Just continuing... "
argument_list|,
name|ioe
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"["
operator|+
name|thread
operator|+
literal|"] Was unable to close region "
operator|+
name|hi
operator|+
literal|".  Just continuing... "
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
try|try
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"["
operator|+
name|thread
operator|+
literal|"] Offlining region: "
operator|+
name|hi
argument_list|)
expr_stmt|;
name|offline
argument_list|(
name|hi
operator|.
name|getRegionName
argument_list|()
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ioe
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"["
operator|+
name|thread
operator|+
literal|"] Unable to offline region from master: "
operator|+
name|hi
operator|+
literal|".  Just continuing... "
argument_list|,
name|ioe
argument_list|)
expr_stmt|;
block|}
block|}
comment|// create new empty container region.
name|TableDescriptor
name|htd
init|=
name|getTableInfo
argument_list|()
operator|.
name|getHTD
argument_list|()
decl_stmt|;
comment|// from start key to end Key
name|RegionInfo
name|newRegion
init|=
name|RegionInfoBuilder
operator|.
name|newBuilder
argument_list|(
name|htd
operator|.
name|getTableName
argument_list|()
argument_list|)
operator|.
name|setStartKey
argument_list|(
name|range
operator|.
name|getFirst
argument_list|()
argument_list|)
operator|.
name|setEndKey
argument_list|(
name|range
operator|.
name|getSecond
argument_list|()
argument_list|)
operator|.
name|build
argument_list|()
decl_stmt|;
name|HRegion
name|region
init|=
name|HBaseFsckRepair
operator|.
name|createHDFSRegionDir
argument_list|(
name|conf
argument_list|,
name|newRegion
argument_list|,
name|htd
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"["
operator|+
name|thread
operator|+
literal|"] Created new empty container region: "
operator|+
name|newRegion
operator|+
literal|" to contain regions: "
operator|+
name|Joiner
operator|.
name|on
argument_list|(
literal|","
argument_list|)
operator|.
name|join
argument_list|(
name|overlap
argument_list|)
argument_list|)
expr_stmt|;
name|debugLsr
argument_list|(
name|region
operator|.
name|getRegionFileSystem
argument_list|()
operator|.
name|getRegionDir
argument_list|()
argument_list|)
expr_stmt|;
comment|// all target regions are closed, should be able to safely cleanup.
name|boolean
name|didFix
init|=
literal|false
decl_stmt|;
name|Path
name|target
init|=
name|region
operator|.
name|getRegionFileSystem
argument_list|()
operator|.
name|getRegionDir
argument_list|()
decl_stmt|;
for|for
control|(
name|HbckInfo
name|contained
range|:
name|overlap
control|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"["
operator|+
name|thread
operator|+
literal|"] Merging "
operator|+
name|contained
operator|+
literal|" into "
operator|+
name|target
argument_list|)
expr_stmt|;
name|int
name|merges
init|=
name|mergeRegionDirs
argument_list|(
name|target
argument_list|,
name|contained
argument_list|)
decl_stmt|;
if|if
condition|(
name|merges
operator|>
literal|0
condition|)
block|{
name|didFix
operator|=
literal|true
expr_stmt|;
block|}
block|}
if|if
condition|(
name|didFix
condition|)
block|{
name|fixes
operator|++
expr_stmt|;
block|}
block|}
comment|/**        * Sideline some regions in a big overlap group so that it        * will have fewer regions, and it is easier to merge them later on.        *        * @param bigOverlap the overlapped group with regions more than maxMerge        * @throws IOException        */
name|void
name|sidelineBigOverlaps
parameter_list|(
name|Collection
argument_list|<
name|HbckInfo
argument_list|>
name|bigOverlap
parameter_list|)
throws|throws
name|IOException
block|{
name|int
name|overlapsToSideline
init|=
name|bigOverlap
operator|.
name|size
argument_list|()
operator|-
name|maxMerge
decl_stmt|;
if|if
condition|(
name|overlapsToSideline
operator|>
name|maxOverlapsToSideline
condition|)
block|{
name|overlapsToSideline
operator|=
name|maxOverlapsToSideline
expr_stmt|;
block|}
name|List
argument_list|<
name|HbckInfo
argument_list|>
name|regionsToSideline
init|=
name|RegionSplitCalculator
operator|.
name|findBigRanges
argument_list|(
name|bigOverlap
argument_list|,
name|overlapsToSideline
argument_list|)
decl_stmt|;
name|FileSystem
name|fs
init|=
name|FileSystem
operator|.
name|get
argument_list|(
name|conf
argument_list|)
decl_stmt|;
for|for
control|(
name|HbckInfo
name|regionToSideline
range|:
name|regionsToSideline
control|)
block|{
try|try
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Closing region: "
operator|+
name|regionToSideline
argument_list|)
expr_stmt|;
name|closeRegion
argument_list|(
name|regionToSideline
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ioe
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Was unable to close region "
operator|+
name|regionToSideline
operator|+
literal|".  Just continuing... "
argument_list|,
name|ioe
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Was unable to close region "
operator|+
name|regionToSideline
operator|+
literal|".  Just continuing... "
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
try|try
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Offlining region: "
operator|+
name|regionToSideline
argument_list|)
expr_stmt|;
name|offline
argument_list|(
name|regionToSideline
operator|.
name|getRegionName
argument_list|()
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ioe
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Unable to offline region from master: "
operator|+
name|regionToSideline
operator|+
literal|".  Just continuing... "
argument_list|,
name|ioe
argument_list|)
expr_stmt|;
block|}
name|LOG
operator|.
name|info
argument_list|(
literal|"Before sideline big overlapped region: "
operator|+
name|regionToSideline
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
name|Path
name|sidelineRegionDir
init|=
name|sidelineRegionDir
argument_list|(
name|fs
argument_list|,
name|TO_BE_LOADED
argument_list|,
name|regionToSideline
argument_list|)
decl_stmt|;
if|if
condition|(
name|sidelineRegionDir
operator|!=
literal|null
condition|)
block|{
name|sidelinedRegions
operator|.
name|put
argument_list|(
name|sidelineRegionDir
argument_list|,
name|regionToSideline
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"After sidelined big overlapped region: "
operator|+
name|regionToSideline
operator|.
name|getRegionNameAsString
argument_list|()
operator|+
literal|" to "
operator|+
name|sidelineRegionDir
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
name|fixes
operator|++
expr_stmt|;
block|}
block|}
block|}
block|}
comment|/**      * Check the region chain (from META) of this table.  We are looking for      * holes, overlaps, and cycles.      * @return false if there are errors      * @throws IOException      */
specifier|public
name|boolean
name|checkRegionChain
parameter_list|(
name|TableIntegrityErrorHandler
name|handler
parameter_list|)
throws|throws
name|IOException
block|{
comment|// When table is disabled no need to check for the region chain. Some of the regions
comment|// accidently if deployed, this below code might report some issues like missing start
comment|// or end regions or region hole in chain and may try to fix which is unwanted.
if|if
condition|(
name|isTableDisabled
argument_list|(
name|this
operator|.
name|tableName
argument_list|)
condition|)
block|{
return|return
literal|true
return|;
block|}
name|int
name|originalErrorsCount
init|=
name|errors
operator|.
name|getErrorList
argument_list|()
operator|.
name|size
argument_list|()
decl_stmt|;
name|Multimap
argument_list|<
name|byte
index|[]
argument_list|,
name|HbckInfo
argument_list|>
name|regions
init|=
name|sc
operator|.
name|calcCoverage
argument_list|()
decl_stmt|;
name|SortedSet
argument_list|<
name|byte
index|[]
argument_list|>
name|splits
init|=
name|sc
operator|.
name|getSplits
argument_list|()
decl_stmt|;
name|byte
index|[]
name|prevKey
init|=
literal|null
decl_stmt|;
name|byte
index|[]
name|problemKey
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|splits
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
comment|// no region for this table
name|handler
operator|.
name|handleHoleInRegionChain
argument_list|(
name|HConstants
operator|.
name|EMPTY_START_ROW
argument_list|,
name|HConstants
operator|.
name|EMPTY_END_ROW
argument_list|)
expr_stmt|;
block|}
for|for
control|(
name|byte
index|[]
name|key
range|:
name|splits
control|)
block|{
name|Collection
argument_list|<
name|HbckInfo
argument_list|>
name|ranges
init|=
name|regions
operator|.
name|get
argument_list|(
name|key
argument_list|)
decl_stmt|;
if|if
condition|(
name|prevKey
operator|==
literal|null
operator|&&
operator|!
name|Bytes
operator|.
name|equals
argument_list|(
name|key
argument_list|,
name|HConstants
operator|.
name|EMPTY_BYTE_ARRAY
argument_list|)
condition|)
block|{
for|for
control|(
name|HbckInfo
name|rng
range|:
name|ranges
control|)
block|{
name|handler
operator|.
name|handleRegionStartKeyNotEmpty
argument_list|(
name|rng
argument_list|)
expr_stmt|;
block|}
block|}
comment|// check for degenerate ranges
for|for
control|(
name|HbckInfo
name|rng
range|:
name|ranges
control|)
block|{
comment|// special endkey case converts '' to null
name|byte
index|[]
name|endKey
init|=
name|rng
operator|.
name|getEndKey
argument_list|()
decl_stmt|;
name|endKey
operator|=
operator|(
name|endKey
operator|.
name|length
operator|==
literal|0
operator|)
condition|?
literal|null
else|:
name|endKey
expr_stmt|;
if|if
condition|(
name|Bytes
operator|.
name|equals
argument_list|(
name|rng
operator|.
name|getStartKey
argument_list|()
argument_list|,
name|endKey
argument_list|)
condition|)
block|{
name|handler
operator|.
name|handleDegenerateRegion
argument_list|(
name|rng
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|ranges
operator|.
name|size
argument_list|()
operator|==
literal|1
condition|)
block|{
comment|// this split key is ok -- no overlap, not a hole.
if|if
condition|(
name|problemKey
operator|!=
literal|null
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"reached end of problem group: "
operator|+
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|key
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|problemKey
operator|=
literal|null
expr_stmt|;
comment|// fell through, no more problem.
block|}
elseif|else
if|if
condition|(
name|ranges
operator|.
name|size
argument_list|()
operator|>
literal|1
condition|)
block|{
comment|// set the new problem key group name, if already have problem key, just
comment|// keep using it.
if|if
condition|(
name|problemKey
operator|==
literal|null
condition|)
block|{
comment|// only for overlap regions.
name|LOG
operator|.
name|warn
argument_list|(
literal|"Naming new problem group: "
operator|+
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|key
argument_list|)
argument_list|)
expr_stmt|;
name|problemKey
operator|=
name|key
expr_stmt|;
block|}
name|overlapGroups
operator|.
name|putAll
argument_list|(
name|problemKey
argument_list|,
name|ranges
argument_list|)
expr_stmt|;
comment|// record errors
name|ArrayList
argument_list|<
name|HbckInfo
argument_list|>
name|subRange
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
name|ranges
argument_list|)
decl_stmt|;
comment|//  this dumb and n^2 but this shouldn't happen often
for|for
control|(
name|HbckInfo
name|r1
range|:
name|ranges
control|)
block|{
if|if
condition|(
name|r1
operator|.
name|getReplicaId
argument_list|()
operator|!=
name|RegionInfo
operator|.
name|DEFAULT_REPLICA_ID
condition|)
continue|continue;
name|subRange
operator|.
name|remove
argument_list|(
name|r1
argument_list|)
expr_stmt|;
for|for
control|(
name|HbckInfo
name|r2
range|:
name|subRange
control|)
block|{
if|if
condition|(
name|r2
operator|.
name|getReplicaId
argument_list|()
operator|!=
name|RegionInfo
operator|.
name|DEFAULT_REPLICA_ID
condition|)
continue|continue;
comment|// general case of same start key
if|if
condition|(
name|Bytes
operator|.
name|compareTo
argument_list|(
name|r1
operator|.
name|getStartKey
argument_list|()
argument_list|,
name|r2
operator|.
name|getStartKey
argument_list|()
argument_list|)
operator|==
literal|0
condition|)
block|{
name|handler
operator|.
name|handleDuplicateStartKeys
argument_list|(
name|r1
argument_list|,
name|r2
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|Bytes
operator|.
name|compareTo
argument_list|(
name|r1
operator|.
name|getEndKey
argument_list|()
argument_list|,
name|r2
operator|.
name|getStartKey
argument_list|()
argument_list|)
operator|==
literal|0
operator|&&
name|r1
operator|.
name|getHdfsHRI
argument_list|()
operator|.
name|getRegionId
argument_list|()
operator|==
name|r2
operator|.
name|getHdfsHRI
argument_list|()
operator|.
name|getRegionId
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"this is a split, log to splits"
argument_list|)
expr_stmt|;
name|handler
operator|.
name|handleSplit
argument_list|(
name|r1
argument_list|,
name|r2
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// overlap
name|handler
operator|.
name|handleOverlapInRegionChain
argument_list|(
name|r1
argument_list|,
name|r2
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
elseif|else
if|if
condition|(
name|ranges
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
if|if
condition|(
name|problemKey
operator|!=
literal|null
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"reached end of problem group: "
operator|+
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|key
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|problemKey
operator|=
literal|null
expr_stmt|;
name|byte
index|[]
name|holeStopKey
init|=
name|sc
operator|.
name|getSplits
argument_list|()
operator|.
name|higher
argument_list|(
name|key
argument_list|)
decl_stmt|;
comment|// if higher key is null we reached the top.
if|if
condition|(
name|holeStopKey
operator|!=
literal|null
condition|)
block|{
comment|// hole
name|handler
operator|.
name|handleHoleInRegionChain
argument_list|(
name|key
argument_list|,
name|holeStopKey
argument_list|)
expr_stmt|;
block|}
block|}
name|prevKey
operator|=
name|key
expr_stmt|;
block|}
comment|// When the last region of a table is proper and having an empty end key, 'prevKey'
comment|// will be null.
if|if
condition|(
name|prevKey
operator|!=
literal|null
condition|)
block|{
name|handler
operator|.
name|handleRegionEndKeyNotEmpty
argument_list|(
name|prevKey
argument_list|)
expr_stmt|;
block|}
comment|// TODO fold this into the TableIntegrityHandler
if|if
condition|(
name|getConf
argument_list|()
operator|.
name|getBoolean
argument_list|(
literal|"hbasefsck.overlap.merge.parallel"
argument_list|,
literal|true
argument_list|)
condition|)
block|{
name|boolean
name|ok
init|=
name|handleOverlapsParallel
argument_list|(
name|handler
argument_list|,
name|prevKey
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|ok
condition|)
block|{
return|return
literal|false
return|;
block|}
block|}
else|else
block|{
for|for
control|(
name|Collection
argument_list|<
name|HbckInfo
argument_list|>
name|overlap
range|:
name|overlapGroups
operator|.
name|asMap
argument_list|()
operator|.
name|values
argument_list|()
control|)
block|{
name|handler
operator|.
name|handleOverlapGroup
argument_list|(
name|overlap
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|details
condition|)
block|{
comment|// do full region split map dump
name|errors
operator|.
name|print
argument_list|(
literal|"---- Table '"
operator|+
name|this
operator|.
name|tableName
operator|+
literal|"': region split map"
argument_list|)
expr_stmt|;
name|dump
argument_list|(
name|splits
argument_list|,
name|regions
argument_list|)
expr_stmt|;
name|errors
operator|.
name|print
argument_list|(
literal|"---- Table '"
operator|+
name|this
operator|.
name|tableName
operator|+
literal|"': overlap groups"
argument_list|)
expr_stmt|;
name|dumpOverlapProblems
argument_list|(
name|overlapGroups
argument_list|)
expr_stmt|;
name|errors
operator|.
name|print
argument_list|(
literal|"There are "
operator|+
name|overlapGroups
operator|.
name|keySet
argument_list|()
operator|.
name|size
argument_list|()
operator|+
literal|" overlap groups with "
operator|+
name|overlapGroups
operator|.
name|size
argument_list|()
operator|+
literal|" overlapping regions"
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|!
name|sidelinedRegions
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Sidelined big overlapped regions, please bulk load them!"
argument_list|)
expr_stmt|;
name|errors
operator|.
name|print
argument_list|(
literal|"---- Table '"
operator|+
name|this
operator|.
name|tableName
operator|+
literal|"': sidelined big overlapped regions"
argument_list|)
expr_stmt|;
name|dumpSidelinedRegions
argument_list|(
name|sidelinedRegions
argument_list|)
expr_stmt|;
block|}
return|return
name|errors
operator|.
name|getErrorList
argument_list|()
operator|.
name|size
argument_list|()
operator|==
name|originalErrorsCount
return|;
block|}
specifier|private
name|boolean
name|handleOverlapsParallel
parameter_list|(
name|TableIntegrityErrorHandler
name|handler
parameter_list|,
name|byte
index|[]
name|prevKey
parameter_list|)
throws|throws
name|IOException
block|{
comment|// we parallelize overlap handler for the case we have lots of groups to fix.  We can
comment|// safely assume each group is independent.
name|List
argument_list|<
name|WorkItemOverlapMerge
argument_list|>
name|merges
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
name|overlapGroups
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|Future
argument_list|<
name|Void
argument_list|>
argument_list|>
name|rets
decl_stmt|;
for|for
control|(
name|Collection
argument_list|<
name|HbckInfo
argument_list|>
name|overlap
range|:
name|overlapGroups
operator|.
name|asMap
argument_list|()
operator|.
name|values
argument_list|()
control|)
block|{
comment|//
name|merges
operator|.
name|add
argument_list|(
operator|new
name|WorkItemOverlapMerge
argument_list|(
name|overlap
argument_list|,
name|handler
argument_list|)
argument_list|)
expr_stmt|;
block|}
try|try
block|{
name|rets
operator|=
name|executor
operator|.
name|invokeAll
argument_list|(
name|merges
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Overlap merges were interrupted"
argument_list|,
name|e
argument_list|)
expr_stmt|;
return|return
literal|false
return|;
block|}
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|merges
operator|.
name|size
argument_list|()
condition|;
name|i
operator|++
control|)
block|{
name|WorkItemOverlapMerge
name|work
init|=
name|merges
operator|.
name|get
argument_list|(
name|i
argument_list|)
decl_stmt|;
name|Future
argument_list|<
name|Void
argument_list|>
name|f
init|=
name|rets
operator|.
name|get
argument_list|(
name|i
argument_list|)
decl_stmt|;
try|try
block|{
name|f
operator|.
name|get
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|ExecutionException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failed to merge overlap group"
operator|+
name|work
argument_list|,
name|e
operator|.
name|getCause
argument_list|()
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Waiting for overlap merges was interrupted"
argument_list|,
name|e
argument_list|)
expr_stmt|;
return|return
literal|false
return|;
block|}
block|}
return|return
literal|true
return|;
block|}
comment|/**      * This dumps data in a visually reasonable way for visual debugging      *      * @param splits      * @param regions      */
name|void
name|dump
parameter_list|(
name|SortedSet
argument_list|<
name|byte
index|[]
argument_list|>
name|splits
parameter_list|,
name|Multimap
argument_list|<
name|byte
index|[]
argument_list|,
name|HbckInfo
argument_list|>
name|regions
parameter_list|)
block|{
comment|// we display this way because the last end key should be displayed as well.
name|StringBuilder
name|sb
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
for|for
control|(
name|byte
index|[]
name|k
range|:
name|splits
control|)
block|{
name|sb
operator|.
name|setLength
argument_list|(
literal|0
argument_list|)
expr_stmt|;
comment|// clear out existing buffer, if any.
name|sb
operator|.
name|append
argument_list|(
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|k
argument_list|)
operator|+
literal|":\t"
argument_list|)
expr_stmt|;
for|for
control|(
name|HbckInfo
name|r
range|:
name|regions
operator|.
name|get
argument_list|(
name|k
argument_list|)
control|)
block|{
name|sb
operator|.
name|append
argument_list|(
literal|"[ "
operator|+
name|r
operator|.
name|toString
argument_list|()
operator|+
literal|", "
operator|+
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|r
operator|.
name|getEndKey
argument_list|()
argument_list|)
operator|+
literal|"]\t"
argument_list|)
expr_stmt|;
block|}
name|errors
operator|.
name|print
argument_list|(
name|sb
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
block|}
specifier|public
name|void
name|dumpOverlapProblems
parameter_list|(
name|Multimap
argument_list|<
name|byte
index|[]
argument_list|,
name|HbckInfo
argument_list|>
name|regions
parameter_list|)
block|{
comment|// we display this way because the last end key should be displayed as
comment|// well.
for|for
control|(
name|byte
index|[]
name|k
range|:
name|regions
operator|.
name|keySet
argument_list|()
control|)
block|{
name|errors
operator|.
name|print
argument_list|(
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|k
argument_list|)
operator|+
literal|":"
argument_list|)
expr_stmt|;
for|for
control|(
name|HbckInfo
name|r
range|:
name|regions
operator|.
name|get
argument_list|(
name|k
argument_list|)
control|)
block|{
name|errors
operator|.
name|print
argument_list|(
literal|"[ "
operator|+
name|r
operator|.
name|toString
argument_list|()
operator|+
literal|", "
operator|+
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|r
operator|.
name|getEndKey
argument_list|()
argument_list|)
operator|+
literal|"]"
argument_list|)
expr_stmt|;
block|}
name|errors
operator|.
name|print
argument_list|(
literal|"----"
argument_list|)
expr_stmt|;
block|}
block|}
specifier|public
name|void
name|dumpSidelinedRegions
parameter_list|(
name|Map
argument_list|<
name|Path
argument_list|,
name|HbckInfo
argument_list|>
name|regions
parameter_list|)
block|{
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|Path
argument_list|,
name|HbckInfo
argument_list|>
name|entry
range|:
name|regions
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|TableName
name|tableName
init|=
name|entry
operator|.
name|getValue
argument_list|()
operator|.
name|getTableName
argument_list|()
decl_stmt|;
name|Path
name|path
init|=
name|entry
operator|.
name|getKey
argument_list|()
decl_stmt|;
name|errors
operator|.
name|print
argument_list|(
literal|"This sidelined region dir should be bulk loaded: "
operator|+
name|path
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
name|errors
operator|.
name|print
argument_list|(
literal|"Bulk load command looks like: "
operator|+
literal|"hbase org.apache.hadoop.hbase.tool.LoadIncrementalHFiles "
operator|+
name|path
operator|.
name|toUri
argument_list|()
operator|.
name|getPath
argument_list|()
operator|+
literal|" "
operator|+
name|tableName
argument_list|)
expr_stmt|;
block|}
block|}
specifier|public
name|Multimap
argument_list|<
name|byte
index|[]
argument_list|,
name|HbckInfo
argument_list|>
name|getOverlapGroups
parameter_list|(
name|TableName
name|table
parameter_list|)
block|{
name|TableInfo
name|ti
init|=
name|tablesInfo
operator|.
name|get
argument_list|(
name|table
argument_list|)
decl_stmt|;
return|return
name|ti
operator|.
name|overlapGroups
return|;
block|}
comment|/**    * Return a list of user-space table names whose metadata have not been    * modified in the last few milliseconds specified by timelag    * if any of the REGIONINFO_QUALIFIER, SERVER_QUALIFIER, STARTCODE_QUALIFIER,    * SPLITA_QUALIFIER, SPLITB_QUALIFIER have not changed in the last    * milliseconds specified by timelag, then the table is a candidate to be returned.    * @return tables that have not been modified recently    * @throws IOException if an error is encountered    */
name|TableDescriptor
index|[]
name|getTables
parameter_list|(
name|AtomicInteger
name|numSkipped
parameter_list|)
block|{
name|List
argument_list|<
name|TableName
argument_list|>
name|tableNames
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
name|long
name|now
init|=
name|EnvironmentEdgeManager
operator|.
name|currentTime
argument_list|()
decl_stmt|;
for|for
control|(
name|HbckInfo
name|hbi
range|:
name|regionInfoMap
operator|.
name|values
argument_list|()
control|)
block|{
name|MetaEntry
name|info
init|=
name|hbi
operator|.
name|metaEntry
decl_stmt|;
comment|// if the start key is zero, then we have found the first region of a table.
comment|// pick only those tables that were not modified in the last few milliseconds.
if|if
condition|(
name|info
operator|!=
literal|null
operator|&&
name|info
operator|.
name|getStartKey
argument_list|()
operator|.
name|length
operator|==
literal|0
operator|&&
operator|!
name|info
operator|.
name|isMetaRegion
argument_list|()
condition|)
block|{
if|if
condition|(
name|info
operator|.
name|modTime
operator|+
name|timelag
operator|<
name|now
condition|)
block|{
name|tableNames
operator|.
name|add
argument_list|(
name|info
operator|.
name|getTable
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|numSkipped
operator|.
name|incrementAndGet
argument_list|()
expr_stmt|;
comment|// one more in-flux table
block|}
block|}
block|}
return|return
name|getTableDescriptors
argument_list|(
name|tableNames
argument_list|)
return|;
block|}
name|TableDescriptor
index|[]
name|getTableDescriptors
parameter_list|(
name|List
argument_list|<
name|TableName
argument_list|>
name|tableNames
parameter_list|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"getTableDescriptors == tableNames => "
operator|+
name|tableNames
argument_list|)
expr_stmt|;
try|try
init|(
name|Connection
name|conn
init|=
name|ConnectionFactory
operator|.
name|createConnection
argument_list|(
name|getConf
argument_list|()
argument_list|)
init|;
name|Admin
name|admin
operator|=
name|conn
operator|.
name|getAdmin
argument_list|()
init|)
block|{
name|List
argument_list|<
name|TableDescriptor
argument_list|>
name|tds
init|=
name|admin
operator|.
name|listTableDescriptors
argument_list|(
name|tableNames
argument_list|)
decl_stmt|;
return|return
name|tds
operator|.
name|toArray
argument_list|(
operator|new
name|TableDescriptor
index|[
name|tds
operator|.
name|size
argument_list|()
index|]
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Exception getting table descriptors"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
return|return
operator|new
name|TableDescriptor
index|[
literal|0
index|]
return|;
block|}
comment|/**    * Gets the entry in regionInfo corresponding to the the given encoded    * region name. If the region has not been seen yet, a new entry is added    * and returned.    */
specifier|private
specifier|synchronized
name|HbckInfo
name|getOrCreateInfo
parameter_list|(
name|String
name|name
parameter_list|)
block|{
name|HbckInfo
name|hbi
init|=
name|regionInfoMap
operator|.
name|get
argument_list|(
name|name
argument_list|)
decl_stmt|;
if|if
condition|(
name|hbi
operator|==
literal|null
condition|)
block|{
name|hbi
operator|=
operator|new
name|HbckInfo
argument_list|(
literal|null
argument_list|)
expr_stmt|;
name|regionInfoMap
operator|.
name|put
argument_list|(
name|name
argument_list|,
name|hbi
argument_list|)
expr_stmt|;
block|}
return|return
name|hbi
return|;
block|}
specifier|private
name|void
name|checkAndFixReplication
parameter_list|()
throws|throws
name|ReplicationException
block|{
name|ReplicationChecker
name|checker
init|=
operator|new
name|ReplicationChecker
argument_list|(
name|getConf
argument_list|()
argument_list|,
name|zkw
argument_list|,
name|errors
argument_list|)
decl_stmt|;
name|checker
operator|.
name|checkUnDeletedQueues
argument_list|()
expr_stmt|;
if|if
condition|(
name|checker
operator|.
name|hasUnDeletedQueues
argument_list|()
operator|&&
name|this
operator|.
name|fixReplication
condition|)
block|{
name|checker
operator|.
name|fixUnDeletedQueues
argument_list|()
expr_stmt|;
name|setShouldRerun
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**     * Check values in regionInfo for hbase:meta     * Check if zero or more than one regions with hbase:meta are found.     * If there are inconsistencies (i.e. zero or more than one regions     * pretend to be holding the hbase:meta) try to fix that and report an error.     * @throws IOException from HBaseFsckRepair functions     * @throws KeeperException     * @throws InterruptedException     */
name|boolean
name|checkMetaRegion
parameter_list|()
throws|throws
name|IOException
throws|,
name|KeeperException
throws|,
name|InterruptedException
block|{
name|Map
argument_list|<
name|Integer
argument_list|,
name|HbckInfo
argument_list|>
name|metaRegions
init|=
operator|new
name|HashMap
argument_list|<>
argument_list|()
decl_stmt|;
for|for
control|(
name|HbckInfo
name|value
range|:
name|regionInfoMap
operator|.
name|values
argument_list|()
control|)
block|{
if|if
condition|(
name|value
operator|.
name|metaEntry
operator|!=
literal|null
operator|&&
name|value
operator|.
name|metaEntry
operator|.
name|isMetaRegion
argument_list|()
condition|)
block|{
name|metaRegions
operator|.
name|put
argument_list|(
name|value
operator|.
name|getReplicaId
argument_list|()
argument_list|,
name|value
argument_list|)
expr_stmt|;
block|}
block|}
name|int
name|metaReplication
init|=
name|admin
operator|.
name|getTableDescriptor
argument_list|(
name|TableName
operator|.
name|META_TABLE_NAME
argument_list|)
operator|.
name|getRegionReplication
argument_list|()
decl_stmt|;
name|boolean
name|noProblem
init|=
literal|true
decl_stmt|;
comment|// There will be always entries in regionInfoMap corresponding to hbase:meta& its replicas
comment|// Check the deployed servers. It should be exactly one server for each replica.
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|metaReplication
condition|;
name|i
operator|++
control|)
block|{
name|HbckInfo
name|metaHbckInfo
init|=
name|metaRegions
operator|.
name|remove
argument_list|(
name|i
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|ServerName
argument_list|>
name|servers
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
if|if
condition|(
name|metaHbckInfo
operator|!=
literal|null
condition|)
block|{
name|servers
operator|=
name|metaHbckInfo
operator|.
name|deployedOn
expr_stmt|;
block|}
if|if
condition|(
name|servers
operator|.
name|size
argument_list|()
operator|!=
literal|1
condition|)
block|{
name|noProblem
operator|=
literal|false
expr_stmt|;
if|if
condition|(
name|servers
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|assignMetaReplica
argument_list|(
name|i
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|servers
operator|.
name|size
argument_list|()
operator|>
literal|1
condition|)
block|{
name|errors
operator|.
name|reportError
argument_list|(
name|ERROR_CODE
operator|.
name|MULTI_META_REGION
argument_list|,
literal|"hbase:meta, replicaId "
operator|+
name|metaHbckInfo
operator|.
name|getReplicaId
argument_list|()
operator|+
literal|" is found on more than one region."
argument_list|)
expr_stmt|;
if|if
condition|(
name|shouldFixAssignments
argument_list|()
condition|)
block|{
name|errors
operator|.
name|print
argument_list|(
literal|"Trying to fix a problem with hbase:meta, replicaId "
operator|+
name|metaHbckInfo
operator|.
name|getReplicaId
argument_list|()
operator|+
literal|".."
argument_list|)
expr_stmt|;
name|setShouldRerun
argument_list|()
expr_stmt|;
comment|// try fix it (treat is a dupe assignment)
name|HBaseFsckRepair
operator|.
name|fixMultiAssignment
argument_list|(
name|connection
argument_list|,
name|metaHbckInfo
operator|.
name|metaEntry
argument_list|,
name|servers
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
comment|// unassign whatever is remaining in metaRegions. They are excess replicas.
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|Integer
argument_list|,
name|HbckInfo
argument_list|>
name|entry
range|:
name|metaRegions
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|noProblem
operator|=
literal|false
expr_stmt|;
name|errors
operator|.
name|reportError
argument_list|(
name|ERROR_CODE
operator|.
name|SHOULD_NOT_BE_DEPLOYED
argument_list|,
literal|"hbase:meta replicas are deployed in excess. Configured "
operator|+
name|metaReplication
operator|+
literal|", deployed "
operator|+
name|metaRegions
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|shouldFixAssignments
argument_list|()
condition|)
block|{
name|errors
operator|.
name|print
argument_list|(
literal|"Trying to undeploy excess replica, replicaId: "
operator|+
name|entry
operator|.
name|getKey
argument_list|()
operator|+
literal|" of hbase:meta.."
argument_list|)
expr_stmt|;
name|setShouldRerun
argument_list|()
expr_stmt|;
name|unassignMetaReplica
argument_list|(
name|entry
operator|.
name|getValue
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
comment|// if noProblem is false, rerun hbck with hopefully fixed META
comment|// if noProblem is true, no errors, so continue normally
return|return
name|noProblem
return|;
block|}
specifier|private
name|void
name|unassignMetaReplica
parameter_list|(
name|HbckInfo
name|hi
parameter_list|)
throws|throws
name|IOException
throws|,
name|InterruptedException
throws|,
name|KeeperException
block|{
name|undeployRegions
argument_list|(
name|hi
argument_list|)
expr_stmt|;
name|ZKUtil
operator|.
name|deleteNode
argument_list|(
name|zkw
argument_list|,
name|zkw
operator|.
name|znodePaths
operator|.
name|getZNodeForReplica
argument_list|(
name|hi
operator|.
name|metaEntry
operator|.
name|getReplicaId
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
specifier|private
name|void
name|assignMetaReplica
parameter_list|(
name|int
name|replicaId
parameter_list|)
throws|throws
name|IOException
throws|,
name|KeeperException
throws|,
name|InterruptedException
block|{
name|errors
operator|.
name|reportError
argument_list|(
name|ERROR_CODE
operator|.
name|NO_META_REGION
argument_list|,
literal|"hbase:meta, replicaId "
operator|+
name|replicaId
operator|+
literal|" is not found on any region."
argument_list|)
expr_stmt|;
if|if
condition|(
name|shouldFixAssignments
argument_list|()
condition|)
block|{
name|errors
operator|.
name|print
argument_list|(
literal|"Trying to fix a problem with hbase:meta.."
argument_list|)
expr_stmt|;
name|setShouldRerun
argument_list|()
expr_stmt|;
comment|// try to fix it (treat it as unassigned region)
name|RegionInfo
name|h
init|=
name|RegionReplicaUtil
operator|.
name|getRegionInfoForReplica
argument_list|(
name|RegionInfoBuilder
operator|.
name|FIRST_META_REGIONINFO
argument_list|,
name|replicaId
argument_list|)
decl_stmt|;
name|HBaseFsckRepair
operator|.
name|fixUnassigned
argument_list|(
name|admin
argument_list|,
name|h
argument_list|)
expr_stmt|;
name|HBaseFsckRepair
operator|.
name|waitUntilAssigned
argument_list|(
name|admin
argument_list|,
name|h
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Scan hbase:meta, adding all regions found to the regionInfo map.    * @throws IOException if an error is encountered    */
name|boolean
name|loadMetaEntries
parameter_list|()
throws|throws
name|IOException
block|{
name|MetaTableAccessor
operator|.
name|Visitor
name|visitor
init|=
operator|new
name|MetaTableAccessor
operator|.
name|Visitor
argument_list|()
block|{
name|int
name|countRecord
init|=
literal|1
decl_stmt|;
comment|// comparator to sort KeyValues with latest modtime
specifier|final
name|Comparator
argument_list|<
name|Cell
argument_list|>
name|comp
init|=
operator|new
name|Comparator
argument_list|<
name|Cell
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|int
name|compare
parameter_list|(
name|Cell
name|k1
parameter_list|,
name|Cell
name|k2
parameter_list|)
block|{
return|return
name|Long
operator|.
name|compare
argument_list|(
name|k1
operator|.
name|getTimestamp
argument_list|()
argument_list|,
name|k2
operator|.
name|getTimestamp
argument_list|()
argument_list|)
return|;
block|}
block|}
decl_stmt|;
annotation|@
name|Override
specifier|public
name|boolean
name|visit
parameter_list|(
name|Result
name|result
parameter_list|)
throws|throws
name|IOException
block|{
try|try
block|{
comment|// record the latest modification of this META record
name|long
name|ts
init|=
name|Collections
operator|.
name|max
argument_list|(
name|result
operator|.
name|listCells
argument_list|()
argument_list|,
name|comp
argument_list|)
operator|.
name|getTimestamp
argument_list|()
decl_stmt|;
name|RegionLocations
name|rl
init|=
name|MetaTableAccessor
operator|.
name|getRegionLocations
argument_list|(
name|result
argument_list|)
decl_stmt|;
if|if
condition|(
name|rl
operator|==
literal|null
condition|)
block|{
name|emptyRegionInfoQualifiers
operator|.
name|add
argument_list|(
name|result
argument_list|)
expr_stmt|;
name|errors
operator|.
name|reportError
argument_list|(
name|ERROR_CODE
operator|.
name|EMPTY_META_CELL
argument_list|,
literal|"Empty REGIONINFO_QUALIFIER found in hbase:meta"
argument_list|)
expr_stmt|;
return|return
literal|true
return|;
block|}
name|ServerName
name|sn
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|rl
operator|.
name|getRegionLocation
argument_list|(
name|RegionInfo
operator|.
name|DEFAULT_REPLICA_ID
argument_list|)
operator|==
literal|null
operator|||
name|rl
operator|.
name|getRegionLocation
argument_list|(
name|RegionInfo
operator|.
name|DEFAULT_REPLICA_ID
argument_list|)
operator|.
name|getRegionInfo
argument_list|()
operator|==
literal|null
condition|)
block|{
name|emptyRegionInfoQualifiers
operator|.
name|add
argument_list|(
name|result
argument_list|)
expr_stmt|;
name|errors
operator|.
name|reportError
argument_list|(
name|ERROR_CODE
operator|.
name|EMPTY_META_CELL
argument_list|,
literal|"Empty REGIONINFO_QUALIFIER found in hbase:meta"
argument_list|)
expr_stmt|;
return|return
literal|true
return|;
block|}
name|RegionInfo
name|hri
init|=
name|rl
operator|.
name|getRegionLocation
argument_list|(
name|RegionInfo
operator|.
name|DEFAULT_REPLICA_ID
argument_list|)
operator|.
name|getRegionInfo
argument_list|()
decl_stmt|;
if|if
condition|(
operator|!
operator|(
name|isTableIncluded
argument_list|(
name|hri
operator|.
name|getTable
argument_list|()
argument_list|)
operator|||
name|hri
operator|.
name|isMetaRegion
argument_list|()
operator|)
condition|)
block|{
return|return
literal|true
return|;
block|}
name|PairOfSameType
argument_list|<
name|RegionInfo
argument_list|>
name|daughters
init|=
name|MetaTableAccessor
operator|.
name|getDaughterRegions
argument_list|(
name|result
argument_list|)
decl_stmt|;
for|for
control|(
name|HRegionLocation
name|h
range|:
name|rl
operator|.
name|getRegionLocations
argument_list|()
control|)
block|{
if|if
condition|(
name|h
operator|==
literal|null
operator|||
name|h
operator|.
name|getRegionInfo
argument_list|()
operator|==
literal|null
condition|)
block|{
continue|continue;
block|}
name|sn
operator|=
name|h
operator|.
name|getServerName
argument_list|()
expr_stmt|;
name|hri
operator|=
name|h
operator|.
name|getRegionInfo
argument_list|()
expr_stmt|;
name|MetaEntry
name|m
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|hri
operator|.
name|getReplicaId
argument_list|()
operator|==
name|RegionInfo
operator|.
name|DEFAULT_REPLICA_ID
condition|)
block|{
name|m
operator|=
operator|new
name|MetaEntry
argument_list|(
name|hri
argument_list|,
name|sn
argument_list|,
name|ts
argument_list|,
name|daughters
operator|.
name|getFirst
argument_list|()
argument_list|,
name|daughters
operator|.
name|getSecond
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|m
operator|=
operator|new
name|MetaEntry
argument_list|(
name|hri
argument_list|,
name|sn
argument_list|,
name|ts
argument_list|,
literal|null
argument_list|,
literal|null
argument_list|)
expr_stmt|;
block|}
name|HbckInfo
name|previous
init|=
name|regionInfoMap
operator|.
name|get
argument_list|(
name|hri
operator|.
name|getEncodedName
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|previous
operator|==
literal|null
condition|)
block|{
name|regionInfoMap
operator|.
name|put
argument_list|(
name|hri
operator|.
name|getEncodedName
argument_list|()
argument_list|,
operator|new
name|HbckInfo
argument_list|(
name|m
argument_list|)
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|previous
operator|.
name|metaEntry
operator|==
literal|null
condition|)
block|{
name|previous
operator|.
name|metaEntry
operator|=
name|m
expr_stmt|;
block|}
else|else
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Two entries in hbase:meta are same "
operator|+
name|previous
argument_list|)
throw|;
block|}
block|}
name|PairOfSameType
argument_list|<
name|RegionInfo
argument_list|>
name|mergeRegions
init|=
name|MetaTableAccessor
operator|.
name|getMergeRegions
argument_list|(
name|result
argument_list|)
decl_stmt|;
for|for
control|(
name|RegionInfo
name|mergeRegion
range|:
operator|new
name|RegionInfo
index|[]
block|{
name|mergeRegions
operator|.
name|getFirst
argument_list|()
block|,
name|mergeRegions
operator|.
name|getSecond
argument_list|()
block|}
control|)
block|{
if|if
condition|(
name|mergeRegion
operator|!=
literal|null
condition|)
block|{
comment|// This region is already been merged
name|HbckInfo
name|hbInfo
init|=
name|getOrCreateInfo
argument_list|(
name|mergeRegion
operator|.
name|getEncodedName
argument_list|()
argument_list|)
decl_stmt|;
name|hbInfo
operator|.
name|setMerged
argument_list|(
literal|true
argument_list|)
expr_stmt|;
block|}
block|}
comment|// show proof of progress to the user, once for every 100 records.
if|if
condition|(
name|countRecord
operator|%
literal|100
operator|==
literal|0
condition|)
block|{
name|errors
operator|.
name|progress
argument_list|()
expr_stmt|;
block|}
name|countRecord
operator|++
expr_stmt|;
return|return
literal|true
return|;
block|}
catch|catch
parameter_list|(
name|RuntimeException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Result="
operator|+
name|result
argument_list|)
expr_stmt|;
throw|throw
name|e
throw|;
block|}
block|}
block|}
decl_stmt|;
if|if
condition|(
operator|!
name|checkMetaOnly
condition|)
block|{
comment|// Scan hbase:meta to pick up user regions
name|MetaTableAccessor
operator|.
name|fullScanRegions
argument_list|(
name|connection
argument_list|,
name|visitor
argument_list|)
expr_stmt|;
block|}
name|errors
operator|.
name|print
argument_list|(
literal|""
argument_list|)
expr_stmt|;
return|return
literal|true
return|;
block|}
comment|/**    * Stores the regioninfo entries scanned from META    */
specifier|static
class|class
name|MetaEntry
extends|extends
name|HRegionInfo
block|{
name|ServerName
name|regionServer
decl_stmt|;
comment|// server hosting this region
name|long
name|modTime
decl_stmt|;
comment|// timestamp of most recent modification metadata
name|RegionInfo
name|splitA
decl_stmt|,
name|splitB
decl_stmt|;
comment|//split daughters
specifier|public
name|MetaEntry
parameter_list|(
name|RegionInfo
name|rinfo
parameter_list|,
name|ServerName
name|regionServer
parameter_list|,
name|long
name|modTime
parameter_list|)
block|{
name|this
argument_list|(
name|rinfo
argument_list|,
name|regionServer
argument_list|,
name|modTime
argument_list|,
literal|null
argument_list|,
literal|null
argument_list|)
expr_stmt|;
block|}
specifier|public
name|MetaEntry
parameter_list|(
name|RegionInfo
name|rinfo
parameter_list|,
name|ServerName
name|regionServer
parameter_list|,
name|long
name|modTime
parameter_list|,
name|RegionInfo
name|splitA
parameter_list|,
name|RegionInfo
name|splitB
parameter_list|)
block|{
name|super
argument_list|(
name|rinfo
argument_list|)
expr_stmt|;
name|this
operator|.
name|regionServer
operator|=
name|regionServer
expr_stmt|;
name|this
operator|.
name|modTime
operator|=
name|modTime
expr_stmt|;
name|this
operator|.
name|splitA
operator|=
name|splitA
expr_stmt|;
name|this
operator|.
name|splitB
operator|=
name|splitB
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|equals
parameter_list|(
name|Object
name|o
parameter_list|)
block|{
name|boolean
name|superEq
init|=
name|super
operator|.
name|equals
argument_list|(
name|o
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|superEq
condition|)
block|{
return|return
name|superEq
return|;
block|}
name|MetaEntry
name|me
init|=
operator|(
name|MetaEntry
operator|)
name|o
decl_stmt|;
if|if
condition|(
operator|!
name|regionServer
operator|.
name|equals
argument_list|(
name|me
operator|.
name|regionServer
argument_list|)
condition|)
block|{
return|return
literal|false
return|;
block|}
return|return
operator|(
name|modTime
operator|==
name|me
operator|.
name|modTime
operator|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|int
name|hashCode
parameter_list|()
block|{
name|int
name|hash
init|=
name|Arrays
operator|.
name|hashCode
argument_list|(
name|getRegionName
argument_list|()
argument_list|)
decl_stmt|;
name|hash
operator|=
call|(
name|int
call|)
argument_list|(
name|hash
operator|^
name|getRegionId
argument_list|()
argument_list|)
expr_stmt|;
name|hash
operator|^=
name|Arrays
operator|.
name|hashCode
argument_list|(
name|getStartKey
argument_list|()
argument_list|)
expr_stmt|;
name|hash
operator|^=
name|Arrays
operator|.
name|hashCode
argument_list|(
name|getEndKey
argument_list|()
argument_list|)
expr_stmt|;
name|hash
operator|^=
name|Boolean
operator|.
name|valueOf
argument_list|(
name|isOffline
argument_list|()
argument_list|)
operator|.
name|hashCode
argument_list|()
expr_stmt|;
name|hash
operator|^=
name|getTable
argument_list|()
operator|.
name|hashCode
argument_list|()
expr_stmt|;
if|if
condition|(
name|regionServer
operator|!=
literal|null
condition|)
block|{
name|hash
operator|^=
name|regionServer
operator|.
name|hashCode
argument_list|()
expr_stmt|;
block|}
name|hash
operator|=
call|(
name|int
call|)
argument_list|(
name|hash
operator|^
name|modTime
argument_list|)
expr_stmt|;
return|return
name|hash
return|;
block|}
block|}
comment|/**    * Stores the regioninfo entries from HDFS    */
specifier|static
class|class
name|HdfsEntry
block|{
name|RegionInfo
name|hri
decl_stmt|;
name|Path
name|hdfsRegionDir
init|=
literal|null
decl_stmt|;
name|long
name|hdfsRegionDirModTime
init|=
literal|0
decl_stmt|;
name|boolean
name|hdfsRegioninfoFilePresent
init|=
literal|false
decl_stmt|;
name|boolean
name|hdfsOnlyEdits
init|=
literal|false
decl_stmt|;
block|}
comment|/**    * Stores the regioninfo retrieved from Online region servers.    */
specifier|static
class|class
name|OnlineEntry
block|{
name|RegionInfo
name|hri
decl_stmt|;
name|ServerName
name|hsa
decl_stmt|;
annotation|@
name|Override
specifier|public
name|String
name|toString
parameter_list|()
block|{
return|return
name|hsa
operator|.
name|toString
argument_list|()
operator|+
literal|";"
operator|+
name|hri
operator|.
name|getRegionNameAsString
argument_list|()
return|;
block|}
block|}
comment|/**    * Maintain information about a particular region.  It gathers information    * from three places -- HDFS, META, and region servers.    */
specifier|public
specifier|static
class|class
name|HbckInfo
implements|implements
name|KeyRange
block|{
specifier|private
name|MetaEntry
name|metaEntry
init|=
literal|null
decl_stmt|;
comment|// info in META
specifier|private
name|HdfsEntry
name|hdfsEntry
init|=
literal|null
decl_stmt|;
comment|// info in HDFS
specifier|private
name|List
argument_list|<
name|OnlineEntry
argument_list|>
name|deployedEntries
init|=
name|Lists
operator|.
name|newArrayList
argument_list|()
decl_stmt|;
comment|// on Region Server
specifier|private
name|List
argument_list|<
name|ServerName
argument_list|>
name|deployedOn
init|=
name|Lists
operator|.
name|newArrayList
argument_list|()
decl_stmt|;
comment|// info on RS's
specifier|private
name|boolean
name|skipChecks
init|=
literal|false
decl_stmt|;
comment|// whether to skip further checks to this region info.
specifier|private
name|boolean
name|isMerged
init|=
literal|false
decl_stmt|;
comment|// whether this region has already been merged into another one
specifier|private
name|int
name|deployedReplicaId
init|=
name|RegionInfo
operator|.
name|DEFAULT_REPLICA_ID
decl_stmt|;
specifier|private
name|RegionInfo
name|primaryHRIForDeployedReplica
init|=
literal|null
decl_stmt|;
name|HbckInfo
parameter_list|(
name|MetaEntry
name|metaEntry
parameter_list|)
block|{
name|this
operator|.
name|metaEntry
operator|=
name|metaEntry
expr_stmt|;
block|}
specifier|public
specifier|synchronized
name|int
name|getReplicaId
parameter_list|()
block|{
return|return
name|metaEntry
operator|!=
literal|null
condition|?
name|metaEntry
operator|.
name|getReplicaId
argument_list|()
else|:
name|deployedReplicaId
return|;
block|}
specifier|public
specifier|synchronized
name|void
name|addServer
parameter_list|(
name|RegionInfo
name|hri
parameter_list|,
name|ServerName
name|server
parameter_list|)
block|{
name|OnlineEntry
name|rse
init|=
operator|new
name|OnlineEntry
argument_list|()
decl_stmt|;
name|rse
operator|.
name|hri
operator|=
name|hri
expr_stmt|;
name|rse
operator|.
name|hsa
operator|=
name|server
expr_stmt|;
name|this
operator|.
name|deployedEntries
operator|.
name|add
argument_list|(
name|rse
argument_list|)
expr_stmt|;
name|this
operator|.
name|deployedOn
operator|.
name|add
argument_list|(
name|server
argument_list|)
expr_stmt|;
comment|// save the replicaId that we see deployed in the cluster
name|this
operator|.
name|deployedReplicaId
operator|=
name|hri
operator|.
name|getReplicaId
argument_list|()
expr_stmt|;
name|this
operator|.
name|primaryHRIForDeployedReplica
operator|=
name|RegionReplicaUtil
operator|.
name|getRegionInfoForDefaultReplica
argument_list|(
name|hri
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
specifier|synchronized
name|String
name|toString
parameter_list|()
block|{
name|StringBuilder
name|sb
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
name|sb
operator|.
name|append
argument_list|(
literal|"{ meta => "
argument_list|)
expr_stmt|;
name|sb
operator|.
name|append
argument_list|(
operator|(
name|metaEntry
operator|!=
literal|null
operator|)
condition|?
name|metaEntry
operator|.
name|getRegionNameAsString
argument_list|()
else|:
literal|"null"
argument_list|)
expr_stmt|;
name|sb
operator|.
name|append
argument_list|(
literal|", hdfs => "
operator|+
name|getHdfsRegionDir
argument_list|()
argument_list|)
expr_stmt|;
name|sb
operator|.
name|append
argument_list|(
literal|", deployed => "
operator|+
name|Joiner
operator|.
name|on
argument_list|(
literal|", "
argument_list|)
operator|.
name|join
argument_list|(
name|deployedEntries
argument_list|)
argument_list|)
expr_stmt|;
name|sb
operator|.
name|append
argument_list|(
literal|", replicaId => "
operator|+
name|getReplicaId
argument_list|()
argument_list|)
expr_stmt|;
name|sb
operator|.
name|append
argument_list|(
literal|" }"
argument_list|)
expr_stmt|;
return|return
name|sb
operator|.
name|toString
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|byte
index|[]
name|getStartKey
parameter_list|()
block|{
if|if
condition|(
name|this
operator|.
name|metaEntry
operator|!=
literal|null
condition|)
block|{
return|return
name|this
operator|.
name|metaEntry
operator|.
name|getStartKey
argument_list|()
return|;
block|}
elseif|else
if|if
condition|(
name|this
operator|.
name|hdfsEntry
operator|!=
literal|null
condition|)
block|{
return|return
name|this
operator|.
name|hdfsEntry
operator|.
name|hri
operator|.
name|getStartKey
argument_list|()
return|;
block|}
else|else
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Entry "
operator|+
name|this
operator|+
literal|" has no meta or hdfs region start key."
argument_list|)
expr_stmt|;
return|return
literal|null
return|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|byte
index|[]
name|getEndKey
parameter_list|()
block|{
if|if
condition|(
name|this
operator|.
name|metaEntry
operator|!=
literal|null
condition|)
block|{
return|return
name|this
operator|.
name|metaEntry
operator|.
name|getEndKey
argument_list|()
return|;
block|}
elseif|else
if|if
condition|(
name|this
operator|.
name|hdfsEntry
operator|!=
literal|null
condition|)
block|{
return|return
name|this
operator|.
name|hdfsEntry
operator|.
name|hri
operator|.
name|getEndKey
argument_list|()
return|;
block|}
else|else
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Entry "
operator|+
name|this
operator|+
literal|" has no meta or hdfs region start key."
argument_list|)
expr_stmt|;
return|return
literal|null
return|;
block|}
block|}
specifier|public
name|TableName
name|getTableName
parameter_list|()
block|{
if|if
condition|(
name|this
operator|.
name|metaEntry
operator|!=
literal|null
condition|)
block|{
return|return
name|this
operator|.
name|metaEntry
operator|.
name|getTable
argument_list|()
return|;
block|}
elseif|else
if|if
condition|(
name|this
operator|.
name|hdfsEntry
operator|!=
literal|null
condition|)
block|{
comment|// we are only guaranteed to have a path and not an HRI for hdfsEntry,
comment|// so we get the name from the Path
name|Path
name|tableDir
init|=
name|this
operator|.
name|hdfsEntry
operator|.
name|hdfsRegionDir
operator|.
name|getParent
argument_list|()
decl_stmt|;
return|return
name|FSUtils
operator|.
name|getTableName
argument_list|(
name|tableDir
argument_list|)
return|;
block|}
else|else
block|{
comment|// return the info from the first online/deployed hri
for|for
control|(
name|OnlineEntry
name|e
range|:
name|deployedEntries
control|)
block|{
return|return
name|e
operator|.
name|hri
operator|.
name|getTable
argument_list|()
return|;
block|}
return|return
literal|null
return|;
block|}
block|}
specifier|public
name|String
name|getRegionNameAsString
parameter_list|()
block|{
if|if
condition|(
name|metaEntry
operator|!=
literal|null
condition|)
block|{
return|return
name|metaEntry
operator|.
name|getRegionNameAsString
argument_list|()
return|;
block|}
elseif|else
if|if
condition|(
name|hdfsEntry
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
name|hdfsEntry
operator|.
name|hri
operator|!=
literal|null
condition|)
block|{
return|return
name|hdfsEntry
operator|.
name|hri
operator|.
name|getRegionNameAsString
argument_list|()
return|;
block|}
block|}
else|else
block|{
comment|// return the info from the first online/deployed hri
for|for
control|(
name|OnlineEntry
name|e
range|:
name|deployedEntries
control|)
block|{
return|return
name|e
operator|.
name|hri
operator|.
name|getRegionNameAsString
argument_list|()
return|;
block|}
block|}
return|return
literal|null
return|;
block|}
specifier|public
name|byte
index|[]
name|getRegionName
parameter_list|()
block|{
if|if
condition|(
name|metaEntry
operator|!=
literal|null
condition|)
block|{
return|return
name|metaEntry
operator|.
name|getRegionName
argument_list|()
return|;
block|}
elseif|else
if|if
condition|(
name|hdfsEntry
operator|!=
literal|null
condition|)
block|{
return|return
name|hdfsEntry
operator|.
name|hri
operator|.
name|getRegionName
argument_list|()
return|;
block|}
else|else
block|{
comment|// return the info from the first online/deployed hri
for|for
control|(
name|OnlineEntry
name|e
range|:
name|deployedEntries
control|)
block|{
return|return
name|e
operator|.
name|hri
operator|.
name|getRegionName
argument_list|()
return|;
block|}
return|return
literal|null
return|;
block|}
block|}
specifier|public
name|RegionInfo
name|getPrimaryHRIForDeployedReplica
parameter_list|()
block|{
return|return
name|primaryHRIForDeployedReplica
return|;
block|}
name|Path
name|getHdfsRegionDir
parameter_list|()
block|{
if|if
condition|(
name|hdfsEntry
operator|==
literal|null
condition|)
block|{
return|return
literal|null
return|;
block|}
return|return
name|hdfsEntry
operator|.
name|hdfsRegionDir
return|;
block|}
name|boolean
name|containsOnlyHdfsEdits
parameter_list|()
block|{
if|if
condition|(
name|hdfsEntry
operator|==
literal|null
condition|)
block|{
return|return
literal|false
return|;
block|}
return|return
name|hdfsEntry
operator|.
name|hdfsOnlyEdits
return|;
block|}
name|boolean
name|isHdfsRegioninfoPresent
parameter_list|()
block|{
if|if
condition|(
name|hdfsEntry
operator|==
literal|null
condition|)
block|{
return|return
literal|false
return|;
block|}
return|return
name|hdfsEntry
operator|.
name|hdfsRegioninfoFilePresent
return|;
block|}
name|long
name|getModTime
parameter_list|()
block|{
if|if
condition|(
name|hdfsEntry
operator|==
literal|null
condition|)
block|{
return|return
literal|0
return|;
block|}
return|return
name|hdfsEntry
operator|.
name|hdfsRegionDirModTime
return|;
block|}
name|RegionInfo
name|getHdfsHRI
parameter_list|()
block|{
if|if
condition|(
name|hdfsEntry
operator|==
literal|null
condition|)
block|{
return|return
literal|null
return|;
block|}
return|return
name|hdfsEntry
operator|.
name|hri
return|;
block|}
specifier|public
name|void
name|setSkipChecks
parameter_list|(
name|boolean
name|skipChecks
parameter_list|)
block|{
name|this
operator|.
name|skipChecks
operator|=
name|skipChecks
expr_stmt|;
block|}
specifier|public
name|boolean
name|isSkipChecks
parameter_list|()
block|{
return|return
name|skipChecks
return|;
block|}
specifier|public
name|void
name|setMerged
parameter_list|(
name|boolean
name|isMerged
parameter_list|)
block|{
name|this
operator|.
name|isMerged
operator|=
name|isMerged
expr_stmt|;
block|}
specifier|public
name|boolean
name|isMerged
parameter_list|()
block|{
return|return
name|this
operator|.
name|isMerged
return|;
block|}
block|}
specifier|final
specifier|static
name|Comparator
argument_list|<
name|HbckInfo
argument_list|>
name|cmp
init|=
operator|new
name|Comparator
argument_list|<
name|HbckInfo
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|int
name|compare
parameter_list|(
name|HbckInfo
name|l
parameter_list|,
name|HbckInfo
name|r
parameter_list|)
block|{
if|if
condition|(
name|l
operator|==
name|r
condition|)
block|{
comment|// same instance
return|return
literal|0
return|;
block|}
name|int
name|tableCompare
init|=
name|l
operator|.
name|getTableName
argument_list|()
operator|.
name|compareTo
argument_list|(
name|r
operator|.
name|getTableName
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|tableCompare
operator|!=
literal|0
condition|)
block|{
return|return
name|tableCompare
return|;
block|}
name|int
name|startComparison
init|=
name|RegionSplitCalculator
operator|.
name|BYTES_COMPARATOR
operator|.
name|compare
argument_list|(
name|l
operator|.
name|getStartKey
argument_list|()
argument_list|,
name|r
operator|.
name|getStartKey
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|startComparison
operator|!=
literal|0
condition|)
block|{
return|return
name|startComparison
return|;
block|}
comment|// Special case for absolute endkey
name|byte
index|[]
name|endKey
init|=
name|r
operator|.
name|getEndKey
argument_list|()
decl_stmt|;
name|endKey
operator|=
operator|(
name|endKey
operator|.
name|length
operator|==
literal|0
operator|)
condition|?
literal|null
else|:
name|endKey
expr_stmt|;
name|byte
index|[]
name|endKey2
init|=
name|l
operator|.
name|getEndKey
argument_list|()
decl_stmt|;
name|endKey2
operator|=
operator|(
name|endKey2
operator|.
name|length
operator|==
literal|0
operator|)
condition|?
literal|null
else|:
name|endKey2
expr_stmt|;
name|int
name|endComparison
init|=
name|RegionSplitCalculator
operator|.
name|BYTES_COMPARATOR
operator|.
name|compare
argument_list|(
name|endKey2
argument_list|,
name|endKey
argument_list|)
decl_stmt|;
if|if
condition|(
name|endComparison
operator|!=
literal|0
condition|)
block|{
return|return
name|endComparison
return|;
block|}
comment|// use regionId as tiebreaker.
comment|// Null is considered after all possible values so make it bigger.
if|if
condition|(
name|l
operator|.
name|hdfsEntry
operator|==
literal|null
operator|&&
name|r
operator|.
name|hdfsEntry
operator|==
literal|null
condition|)
block|{
return|return
literal|0
return|;
block|}
if|if
condition|(
name|l
operator|.
name|hdfsEntry
operator|==
literal|null
operator|&&
name|r
operator|.
name|hdfsEntry
operator|!=
literal|null
condition|)
block|{
return|return
literal|1
return|;
block|}
comment|// l.hdfsEntry must not be null
if|if
condition|(
name|r
operator|.
name|hdfsEntry
operator|==
literal|null
condition|)
block|{
return|return
operator|-
literal|1
return|;
block|}
comment|// both l.hdfsEntry and r.hdfsEntry must not be null.
return|return
name|Long
operator|.
name|compare
argument_list|(
name|l
operator|.
name|hdfsEntry
operator|.
name|hri
operator|.
name|getRegionId
argument_list|()
argument_list|,
name|r
operator|.
name|hdfsEntry
operator|.
name|hri
operator|.
name|getRegionId
argument_list|()
argument_list|)
return|;
block|}
block|}
decl_stmt|;
comment|/**    * Prints summary of all tables found on the system.    */
specifier|private
name|void
name|printTableSummary
parameter_list|(
name|SortedMap
argument_list|<
name|TableName
argument_list|,
name|TableInfo
argument_list|>
name|tablesInfo
parameter_list|)
block|{
name|StringBuilder
name|sb
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
name|int
name|numOfSkippedRegions
decl_stmt|;
name|errors
operator|.
name|print
argument_list|(
literal|"Summary:"
argument_list|)
expr_stmt|;
for|for
control|(
name|TableInfo
name|tInfo
range|:
name|tablesInfo
operator|.
name|values
argument_list|()
control|)
block|{
name|numOfSkippedRegions
operator|=
operator|(
name|skippedRegions
operator|.
name|containsKey
argument_list|(
name|tInfo
operator|.
name|getName
argument_list|()
argument_list|)
operator|)
condition|?
name|skippedRegions
operator|.
name|get
argument_list|(
name|tInfo
operator|.
name|getName
argument_list|()
argument_list|)
operator|.
name|size
argument_list|()
else|:
literal|0
expr_stmt|;
if|if
condition|(
name|errors
operator|.
name|tableHasErrors
argument_list|(
name|tInfo
argument_list|)
condition|)
block|{
name|errors
operator|.
name|print
argument_list|(
literal|"Table "
operator|+
name|tInfo
operator|.
name|getName
argument_list|()
operator|+
literal|" is inconsistent."
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|numOfSkippedRegions
operator|>
literal|0
condition|)
block|{
name|errors
operator|.
name|print
argument_list|(
literal|"Table "
operator|+
name|tInfo
operator|.
name|getName
argument_list|()
operator|+
literal|" is okay (with "
operator|+
name|numOfSkippedRegions
operator|+
literal|" skipped regions)."
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|errors
operator|.
name|print
argument_list|(
literal|"Table "
operator|+
name|tInfo
operator|.
name|getName
argument_list|()
operator|+
literal|" is okay."
argument_list|)
expr_stmt|;
block|}
name|errors
operator|.
name|print
argument_list|(
literal|"    Number of regions: "
operator|+
name|tInfo
operator|.
name|getNumRegions
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|numOfSkippedRegions
operator|>
literal|0
condition|)
block|{
name|Set
argument_list|<
name|String
argument_list|>
name|skippedRegionStrings
init|=
name|skippedRegions
operator|.
name|get
argument_list|(
name|tInfo
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"    Number of skipped regions: "
operator|+
name|numOfSkippedRegions
argument_list|)
expr_stmt|;
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"      List of skipped regions:"
argument_list|)
expr_stmt|;
for|for
control|(
name|String
name|sr
range|:
name|skippedRegionStrings
control|)
block|{
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"        "
operator|+
name|sr
argument_list|)
expr_stmt|;
block|}
block|}
name|sb
operator|.
name|setLength
argument_list|(
literal|0
argument_list|)
expr_stmt|;
comment|// clear out existing buffer, if any.
name|sb
operator|.
name|append
argument_list|(
literal|"    Deployed on: "
argument_list|)
expr_stmt|;
for|for
control|(
name|ServerName
name|server
range|:
name|tInfo
operator|.
name|deployedOn
control|)
block|{
name|sb
operator|.
name|append
argument_list|(
literal|" "
operator|+
name|server
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|errors
operator|.
name|print
argument_list|(
name|sb
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
specifier|static
name|ErrorReporter
name|getErrorReporter
parameter_list|(
specifier|final
name|Configuration
name|conf
parameter_list|)
throws|throws
name|ClassNotFoundException
block|{
name|Class
argument_list|<
name|?
extends|extends
name|ErrorReporter
argument_list|>
name|reporter
init|=
name|conf
operator|.
name|getClass
argument_list|(
literal|"hbasefsck.errorreporter"
argument_list|,
name|PrintingErrorReporter
operator|.
name|class
argument_list|,
name|ErrorReporter
operator|.
name|class
argument_list|)
decl_stmt|;
return|return
name|ReflectionUtils
operator|.
name|newInstance
argument_list|(
name|reporter
argument_list|,
name|conf
argument_list|)
return|;
block|}
specifier|public
interface|interface
name|ErrorReporter
block|{
enum|enum
name|ERROR_CODE
block|{
name|UNKNOWN
block|,
name|NO_META_REGION
block|,
name|NULL_META_REGION
block|,
name|NO_VERSION_FILE
block|,
name|NOT_IN_META_HDFS
block|,
name|NOT_IN_META
block|,
name|NOT_IN_META_OR_DEPLOYED
block|,
name|NOT_IN_HDFS_OR_DEPLOYED
block|,
name|NOT_IN_HDFS
block|,
name|SERVER_DOES_NOT_MATCH_META
block|,
name|NOT_DEPLOYED
block|,
name|MULTI_DEPLOYED
block|,
name|SHOULD_NOT_BE_DEPLOYED
block|,
name|MULTI_META_REGION
block|,
name|RS_CONNECT_FAILURE
block|,
name|FIRST_REGION_STARTKEY_NOT_EMPTY
block|,
name|LAST_REGION_ENDKEY_NOT_EMPTY
block|,
name|DUPE_STARTKEYS
block|,
name|HOLE_IN_REGION_CHAIN
block|,
name|OVERLAP_IN_REGION_CHAIN
block|,
name|REGION_CYCLE
block|,
name|DEGENERATE_REGION
block|,
name|ORPHAN_HDFS_REGION
block|,
name|LINGERING_SPLIT_PARENT
block|,
name|NO_TABLEINFO_FILE
block|,
name|LINGERING_REFERENCE_HFILE
block|,
name|LINGERING_HFILELINK
block|,
name|WRONG_USAGE
block|,
name|EMPTY_META_CELL
block|,
name|EXPIRED_TABLE_LOCK
block|,
name|BOUNDARIES_ERROR
block|,
name|ORPHAN_TABLE_STATE
block|,
name|NO_TABLE_STATE
block|,
name|UNDELETED_REPLICATION_QUEUE
block|,
name|DUPE_ENDKEYS
block|,
name|UNSUPPORTED_OPTION
block|}
name|void
name|clear
parameter_list|()
function_decl|;
name|void
name|report
parameter_list|(
name|String
name|message
parameter_list|)
function_decl|;
name|void
name|reportError
parameter_list|(
name|String
name|message
parameter_list|)
function_decl|;
name|void
name|reportError
parameter_list|(
name|ERROR_CODE
name|errorCode
parameter_list|,
name|String
name|message
parameter_list|)
function_decl|;
name|void
name|reportError
parameter_list|(
name|ERROR_CODE
name|errorCode
parameter_list|,
name|String
name|message
parameter_list|,
name|TableInfo
name|table
parameter_list|)
function_decl|;
name|void
name|reportError
parameter_list|(
name|ERROR_CODE
name|errorCode
parameter_list|,
name|String
name|message
parameter_list|,
name|TableInfo
name|table
parameter_list|,
name|HbckInfo
name|info
parameter_list|)
function_decl|;
name|void
name|reportError
parameter_list|(
name|ERROR_CODE
name|errorCode
parameter_list|,
name|String
name|message
parameter_list|,
name|TableInfo
name|table
parameter_list|,
name|HbckInfo
name|info1
parameter_list|,
name|HbckInfo
name|info2
parameter_list|)
function_decl|;
name|int
name|summarize
parameter_list|()
function_decl|;
name|void
name|detail
parameter_list|(
name|String
name|details
parameter_list|)
function_decl|;
name|ArrayList
argument_list|<
name|ERROR_CODE
argument_list|>
name|getErrorList
parameter_list|()
function_decl|;
name|void
name|progress
parameter_list|()
function_decl|;
name|void
name|print
parameter_list|(
name|String
name|message
parameter_list|)
function_decl|;
name|void
name|resetErrors
parameter_list|()
function_decl|;
name|boolean
name|tableHasErrors
parameter_list|(
name|TableInfo
name|table
parameter_list|)
function_decl|;
block|}
specifier|static
class|class
name|PrintingErrorReporter
implements|implements
name|ErrorReporter
block|{
specifier|public
name|int
name|errorCount
init|=
literal|0
decl_stmt|;
specifier|private
name|int
name|showProgress
decl_stmt|;
comment|// How frequently calls to progress() will create output
specifier|private
specifier|static
specifier|final
name|int
name|progressThreshold
init|=
literal|100
decl_stmt|;
name|Set
argument_list|<
name|TableInfo
argument_list|>
name|errorTables
init|=
operator|new
name|HashSet
argument_list|<>
argument_list|()
decl_stmt|;
comment|// for use by unit tests to verify which errors were discovered
specifier|private
name|ArrayList
argument_list|<
name|ERROR_CODE
argument_list|>
name|errorList
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
annotation|@
name|Override
specifier|public
name|void
name|clear
parameter_list|()
block|{
name|errorTables
operator|.
name|clear
argument_list|()
expr_stmt|;
name|errorList
operator|.
name|clear
argument_list|()
expr_stmt|;
name|errorCount
operator|=
literal|0
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
specifier|synchronized
name|void
name|reportError
parameter_list|(
name|ERROR_CODE
name|errorCode
parameter_list|,
name|String
name|message
parameter_list|)
block|{
if|if
condition|(
name|errorCode
operator|==
name|ERROR_CODE
operator|.
name|WRONG_USAGE
condition|)
block|{
name|System
operator|.
name|err
operator|.
name|println
argument_list|(
name|message
argument_list|)
expr_stmt|;
return|return;
block|}
name|errorList
operator|.
name|add
argument_list|(
name|errorCode
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|summary
condition|)
block|{
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"ERROR: "
operator|+
name|message
argument_list|)
expr_stmt|;
block|}
name|errorCount
operator|++
expr_stmt|;
name|showProgress
operator|=
literal|0
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
specifier|synchronized
name|void
name|reportError
parameter_list|(
name|ERROR_CODE
name|errorCode
parameter_list|,
name|String
name|message
parameter_list|,
name|TableInfo
name|table
parameter_list|)
block|{
name|errorTables
operator|.
name|add
argument_list|(
name|table
argument_list|)
expr_stmt|;
name|reportError
argument_list|(
name|errorCode
argument_list|,
name|message
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
specifier|synchronized
name|void
name|reportError
parameter_list|(
name|ERROR_CODE
name|errorCode
parameter_list|,
name|String
name|message
parameter_list|,
name|TableInfo
name|table
parameter_list|,
name|HbckInfo
name|info
parameter_list|)
block|{
name|errorTables
operator|.
name|add
argument_list|(
name|table
argument_list|)
expr_stmt|;
name|String
name|reference
init|=
literal|"(region "
operator|+
name|info
operator|.
name|getRegionNameAsString
argument_list|()
operator|+
literal|")"
decl_stmt|;
name|reportError
argument_list|(
name|errorCode
argument_list|,
name|reference
operator|+
literal|" "
operator|+
name|message
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
specifier|synchronized
name|void
name|reportError
parameter_list|(
name|ERROR_CODE
name|errorCode
parameter_list|,
name|String
name|message
parameter_list|,
name|TableInfo
name|table
parameter_list|,
name|HbckInfo
name|info1
parameter_list|,
name|HbckInfo
name|info2
parameter_list|)
block|{
name|errorTables
operator|.
name|add
argument_list|(
name|table
argument_list|)
expr_stmt|;
name|String
name|reference
init|=
literal|"(regions "
operator|+
name|info1
operator|.
name|getRegionNameAsString
argument_list|()
operator|+
literal|" and "
operator|+
name|info2
operator|.
name|getRegionNameAsString
argument_list|()
operator|+
literal|")"
decl_stmt|;
name|reportError
argument_list|(
name|errorCode
argument_list|,
name|reference
operator|+
literal|" "
operator|+
name|message
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
specifier|synchronized
name|void
name|reportError
parameter_list|(
name|String
name|message
parameter_list|)
block|{
name|reportError
argument_list|(
name|ERROR_CODE
operator|.
name|UNKNOWN
argument_list|,
name|message
argument_list|)
expr_stmt|;
block|}
comment|/**      * Report error information, but do not increment the error count.  Intended for cases      * where the actual error would have been reported previously.      * @param message      */
annotation|@
name|Override
specifier|public
specifier|synchronized
name|void
name|report
parameter_list|(
name|String
name|message
parameter_list|)
block|{
if|if
condition|(
operator|!
name|summary
condition|)
block|{
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"ERROR: "
operator|+
name|message
argument_list|)
expr_stmt|;
block|}
name|showProgress
operator|=
literal|0
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
specifier|synchronized
name|int
name|summarize
parameter_list|()
block|{
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
name|Integer
operator|.
name|toString
argument_list|(
name|errorCount
argument_list|)
operator|+
literal|" inconsistencies detected."
argument_list|)
expr_stmt|;
if|if
condition|(
name|errorCount
operator|==
literal|0
condition|)
block|{
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"Status: OK"
argument_list|)
expr_stmt|;
return|return
literal|0
return|;
block|}
else|else
block|{
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
literal|"Status: INCONSISTENT"
argument_list|)
expr_stmt|;
return|return
operator|-
literal|1
return|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|ArrayList
argument_list|<
name|ERROR_CODE
argument_list|>
name|getErrorList
parameter_list|()
block|{
return|return
name|errorList
return|;
block|}
annotation|@
name|Override
specifier|public
specifier|synchronized
name|void
name|print
parameter_list|(
name|String
name|message
parameter_list|)
block|{
if|if
condition|(
operator|!
name|summary
condition|)
block|{
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
name|message
argument_list|)
expr_stmt|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|tableHasErrors
parameter_list|(
name|TableInfo
name|table
parameter_list|)
block|{
return|return
name|errorTables
operator|.
name|contains
argument_list|(
name|table
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|resetErrors
parameter_list|()
block|{
name|errorCount
operator|=
literal|0
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
specifier|synchronized
name|void
name|detail
parameter_list|(
name|String
name|message
parameter_list|)
block|{
if|if
condition|(
name|details
condition|)
block|{
name|System
operator|.
name|out
operator|.
name|println
argument_list|(
name|message
argument_list|)
expr_stmt|;
block|}
name|showProgress
operator|=
literal|0
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
specifier|synchronized
name|void
name|progress
parameter_list|()
block|{
if|if
condition|(
name|showProgress
operator|++
operator|==
name|progressThreshold
condition|)
block|{
if|if
condition|(
operator|!
name|summary
condition|)
block|{
name|System
operator|.
name|out
operator|.
name|print
argument_list|(
literal|"."
argument_list|)
expr_stmt|;
block|}
name|showProgress
operator|=
literal|0
expr_stmt|;
block|}
block|}
block|}
comment|/**    * Contact a region server and get all information from it    */
specifier|static
class|class
name|WorkItemRegion
implements|implements
name|Callable
argument_list|<
name|Void
argument_list|>
block|{
specifier|private
specifier|final
name|HBaseFsck
name|hbck
decl_stmt|;
specifier|private
specifier|final
name|ServerName
name|rsinfo
decl_stmt|;
specifier|private
specifier|final
name|ErrorReporter
name|errors
decl_stmt|;
specifier|private
specifier|final
name|ClusterConnection
name|connection
decl_stmt|;
name|WorkItemRegion
parameter_list|(
name|HBaseFsck
name|hbck
parameter_list|,
name|ServerName
name|info
parameter_list|,
name|ErrorReporter
name|errors
parameter_list|,
name|ClusterConnection
name|connection
parameter_list|)
block|{
name|this
operator|.
name|hbck
operator|=
name|hbck
expr_stmt|;
name|this
operator|.
name|rsinfo
operator|=
name|info
expr_stmt|;
name|this
operator|.
name|errors
operator|=
name|errors
expr_stmt|;
name|this
operator|.
name|connection
operator|=
name|connection
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
specifier|synchronized
name|Void
name|call
parameter_list|()
throws|throws
name|IOException
block|{
name|errors
operator|.
name|progress
argument_list|()
expr_stmt|;
try|try
block|{
name|BlockingInterface
name|server
init|=
name|connection
operator|.
name|getAdmin
argument_list|(
name|rsinfo
argument_list|)
decl_stmt|;
comment|// list all online regions from this region server
name|List
argument_list|<
name|RegionInfo
argument_list|>
name|regions
init|=
name|ProtobufUtil
operator|.
name|getOnlineRegions
argument_list|(
name|server
argument_list|)
decl_stmt|;
name|regions
operator|=
name|filterRegions
argument_list|(
name|regions
argument_list|)
expr_stmt|;
if|if
condition|(
name|details
condition|)
block|{
name|errors
operator|.
name|detail
argument_list|(
literal|"RegionServer: "
operator|+
name|rsinfo
operator|.
name|getServerName
argument_list|()
operator|+
literal|" number of regions: "
operator|+
name|regions
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
for|for
control|(
name|RegionInfo
name|rinfo
range|:
name|regions
control|)
block|{
name|errors
operator|.
name|detail
argument_list|(
literal|"  "
operator|+
name|rinfo
operator|.
name|getRegionNameAsString
argument_list|()
operator|+
literal|" id: "
operator|+
name|rinfo
operator|.
name|getRegionId
argument_list|()
operator|+
literal|" encoded_name: "
operator|+
name|rinfo
operator|.
name|getEncodedName
argument_list|()
operator|+
literal|" start: "
operator|+
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|rinfo
operator|.
name|getStartKey
argument_list|()
argument_list|)
operator|+
literal|" end: "
operator|+
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|rinfo
operator|.
name|getEndKey
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
comment|// check to see if the existence of this region matches the region in META
for|for
control|(
name|RegionInfo
name|r
range|:
name|regions
control|)
block|{
name|HbckInfo
name|hbi
init|=
name|hbck
operator|.
name|getOrCreateInfo
argument_list|(
name|r
operator|.
name|getEncodedName
argument_list|()
argument_list|)
decl_stmt|;
name|hbi
operator|.
name|addServer
argument_list|(
name|r
argument_list|,
name|rsinfo
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
comment|// unable to connect to the region server.
name|errors
operator|.
name|reportError
argument_list|(
name|ERROR_CODE
operator|.
name|RS_CONNECT_FAILURE
argument_list|,
literal|"RegionServer: "
operator|+
name|rsinfo
operator|.
name|getServerName
argument_list|()
operator|+
literal|" Unable to fetch region information. "
operator|+
name|e
argument_list|)
expr_stmt|;
throw|throw
name|e
throw|;
block|}
return|return
literal|null
return|;
block|}
specifier|private
name|List
argument_list|<
name|RegionInfo
argument_list|>
name|filterRegions
parameter_list|(
name|List
argument_list|<
name|RegionInfo
argument_list|>
name|regions
parameter_list|)
block|{
name|List
argument_list|<
name|RegionInfo
argument_list|>
name|ret
init|=
name|Lists
operator|.
name|newArrayList
argument_list|()
decl_stmt|;
for|for
control|(
name|RegionInfo
name|hri
range|:
name|regions
control|)
block|{
if|if
condition|(
name|hri
operator|.
name|isMetaRegion
argument_list|()
operator|||
operator|(
operator|!
name|hbck
operator|.
name|checkMetaOnly
operator|&&
name|hbck
operator|.
name|isTableIncluded
argument_list|(
name|hri
operator|.
name|getTable
argument_list|()
argument_list|)
operator|)
condition|)
block|{
name|ret
operator|.
name|add
argument_list|(
name|hri
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|ret
return|;
block|}
block|}
comment|/**    * Contact hdfs and get all information about specified table directory into    * regioninfo list.    */
class|class
name|WorkItemHdfsDir
implements|implements
name|Callable
argument_list|<
name|Void
argument_list|>
block|{
specifier|private
name|FileStatus
name|tableDir
decl_stmt|;
specifier|private
name|ErrorReporter
name|errors
decl_stmt|;
specifier|private
name|FileSystem
name|fs
decl_stmt|;
name|WorkItemHdfsDir
parameter_list|(
name|FileSystem
name|fs
parameter_list|,
name|ErrorReporter
name|errors
parameter_list|,
name|FileStatus
name|status
parameter_list|)
block|{
name|this
operator|.
name|fs
operator|=
name|fs
expr_stmt|;
name|this
operator|.
name|tableDir
operator|=
name|status
expr_stmt|;
name|this
operator|.
name|errors
operator|=
name|errors
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
specifier|synchronized
name|Void
name|call
parameter_list|()
throws|throws
name|InterruptedException
throws|,
name|ExecutionException
block|{
specifier|final
name|Vector
argument_list|<
name|Exception
argument_list|>
name|exceptions
init|=
operator|new
name|Vector
argument_list|<>
argument_list|()
decl_stmt|;
try|try
block|{
specifier|final
name|FileStatus
index|[]
name|regionDirs
init|=
name|fs
operator|.
name|listStatus
argument_list|(
name|tableDir
operator|.
name|getPath
argument_list|()
argument_list|)
decl_stmt|;
specifier|final
name|List
argument_list|<
name|Future
argument_list|<
name|?
argument_list|>
argument_list|>
name|futures
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
name|regionDirs
operator|.
name|length
argument_list|)
decl_stmt|;
for|for
control|(
specifier|final
name|FileStatus
name|regionDir
range|:
name|regionDirs
control|)
block|{
name|errors
operator|.
name|progress
argument_list|()
expr_stmt|;
specifier|final
name|String
name|encodedName
init|=
name|regionDir
operator|.
name|getPath
argument_list|()
operator|.
name|getName
argument_list|()
decl_stmt|;
comment|// ignore directories that aren't hexadecimal
if|if
condition|(
operator|!
name|encodedName
operator|.
name|toLowerCase
argument_list|(
name|Locale
operator|.
name|ROOT
argument_list|)
operator|.
name|matches
argument_list|(
literal|"[0-9a-f]+"
argument_list|)
condition|)
block|{
continue|continue;
block|}
if|if
condition|(
operator|!
name|exceptions
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
break|break;
block|}
name|futures
operator|.
name|add
argument_list|(
name|executor
operator|.
name|submit
argument_list|(
operator|new
name|Runnable
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|void
name|run
parameter_list|()
block|{
try|try
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Loading region info from hdfs:"
operator|+
name|regionDir
operator|.
name|getPath
argument_list|()
argument_list|)
expr_stmt|;
name|Path
name|regioninfoFile
init|=
operator|new
name|Path
argument_list|(
name|regionDir
operator|.
name|getPath
argument_list|()
argument_list|,
name|HRegionFileSystem
operator|.
name|REGION_INFO_FILE
argument_list|)
decl_stmt|;
name|boolean
name|regioninfoFileExists
init|=
name|fs
operator|.
name|exists
argument_list|(
name|regioninfoFile
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|regioninfoFileExists
condition|)
block|{
comment|// As tables become larger it is more and more likely that by the time you
comment|// reach a given region that it will be gone due to region splits/merges.
if|if
condition|(
operator|!
name|fs
operator|.
name|exists
argument_list|(
name|regionDir
operator|.
name|getPath
argument_list|()
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"By the time we tried to process this region dir it was already gone: "
operator|+
name|regionDir
operator|.
name|getPath
argument_list|()
argument_list|)
expr_stmt|;
return|return;
block|}
block|}
name|HbckInfo
name|hbi
init|=
name|HBaseFsck
operator|.
name|this
operator|.
name|getOrCreateInfo
argument_list|(
name|encodedName
argument_list|)
decl_stmt|;
name|HdfsEntry
name|he
init|=
operator|new
name|HdfsEntry
argument_list|()
decl_stmt|;
synchronized|synchronized
init|(
name|hbi
init|)
block|{
if|if
condition|(
name|hbi
operator|.
name|getHdfsRegionDir
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|errors
operator|.
name|print
argument_list|(
literal|"Directory "
operator|+
name|encodedName
operator|+
literal|" duplicate??"
operator|+
name|hbi
operator|.
name|getHdfsRegionDir
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|he
operator|.
name|hdfsRegionDir
operator|=
name|regionDir
operator|.
name|getPath
argument_list|()
expr_stmt|;
name|he
operator|.
name|hdfsRegionDirModTime
operator|=
name|regionDir
operator|.
name|getModificationTime
argument_list|()
expr_stmt|;
name|he
operator|.
name|hdfsRegioninfoFilePresent
operator|=
name|regioninfoFileExists
expr_stmt|;
comment|// we add to orphan list when we attempt to read .regioninfo
comment|// Set a flag if this region contains only edits
comment|// This is special case if a region is left after split
name|he
operator|.
name|hdfsOnlyEdits
operator|=
literal|true
expr_stmt|;
name|FileStatus
index|[]
name|subDirs
init|=
name|fs
operator|.
name|listStatus
argument_list|(
name|regionDir
operator|.
name|getPath
argument_list|()
argument_list|)
decl_stmt|;
name|Path
name|ePath
init|=
name|WALSplitter
operator|.
name|getRegionDirRecoveredEditsDir
argument_list|(
name|regionDir
operator|.
name|getPath
argument_list|()
argument_list|)
decl_stmt|;
for|for
control|(
name|FileStatus
name|subDir
range|:
name|subDirs
control|)
block|{
name|errors
operator|.
name|progress
argument_list|()
expr_stmt|;
name|String
name|sdName
init|=
name|subDir
operator|.
name|getPath
argument_list|()
operator|.
name|getName
argument_list|()
decl_stmt|;
if|if
condition|(
operator|!
name|sdName
operator|.
name|startsWith
argument_list|(
literal|"."
argument_list|)
operator|&&
operator|!
name|sdName
operator|.
name|equals
argument_list|(
name|ePath
operator|.
name|getName
argument_list|()
argument_list|)
condition|)
block|{
name|he
operator|.
name|hdfsOnlyEdits
operator|=
literal|false
expr_stmt|;
break|break;
block|}
block|}
name|hbi
operator|.
name|hdfsEntry
operator|=
name|he
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Could not load region dir"
argument_list|,
name|e
argument_list|)
expr_stmt|;
name|exceptions
operator|.
name|add
argument_list|(
name|e
argument_list|)
expr_stmt|;
block|}
block|}
block|}
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|// Ensure all pending tasks are complete (or that we run into an exception)
for|for
control|(
name|Future
argument_list|<
name|?
argument_list|>
name|f
range|:
name|futures
control|)
block|{
if|if
condition|(
operator|!
name|exceptions
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
break|break;
block|}
try|try
block|{
name|f
operator|.
name|get
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|ExecutionException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Unexpected exec exception!  Should've been caught already.  (Bug?)"
argument_list|,
name|e
argument_list|)
expr_stmt|;
comment|// Shouldn't happen, we already logged/caught any exceptions in the Runnable
block|}
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Cannot execute WorkItemHdfsDir for "
operator|+
name|tableDir
argument_list|,
name|e
argument_list|)
expr_stmt|;
name|exceptions
operator|.
name|add
argument_list|(
name|e
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
if|if
condition|(
operator|!
name|exceptions
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|errors
operator|.
name|reportError
argument_list|(
name|ERROR_CODE
operator|.
name|RS_CONNECT_FAILURE
argument_list|,
literal|"Table Directory: "
operator|+
name|tableDir
operator|.
name|getPath
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|" Unable to fetch all HDFS region information. "
argument_list|)
expr_stmt|;
comment|// Just throw the first exception as an indication something bad happened
comment|// Don't need to propagate all the exceptions, we already logged them all anyway
throw|throw
operator|new
name|ExecutionException
argument_list|(
literal|"First exception in WorkItemHdfsDir"
argument_list|,
name|exceptions
operator|.
name|firstElement
argument_list|()
argument_list|)
throw|;
block|}
block|}
return|return
literal|null
return|;
block|}
block|}
comment|/**    * Contact hdfs and get all information about specified table directory into    * regioninfo list.    */
specifier|static
class|class
name|WorkItemHdfsRegionInfo
implements|implements
name|Callable
argument_list|<
name|Void
argument_list|>
block|{
specifier|private
name|HbckInfo
name|hbi
decl_stmt|;
specifier|private
name|HBaseFsck
name|hbck
decl_stmt|;
specifier|private
name|ErrorReporter
name|errors
decl_stmt|;
name|WorkItemHdfsRegionInfo
parameter_list|(
name|HbckInfo
name|hbi
parameter_list|,
name|HBaseFsck
name|hbck
parameter_list|,
name|ErrorReporter
name|errors
parameter_list|)
block|{
name|this
operator|.
name|hbi
operator|=
name|hbi
expr_stmt|;
name|this
operator|.
name|hbck
operator|=
name|hbck
expr_stmt|;
name|this
operator|.
name|errors
operator|=
name|errors
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
specifier|synchronized
name|Void
name|call
parameter_list|()
throws|throws
name|IOException
block|{
comment|// only load entries that haven't been loaded yet.
if|if
condition|(
name|hbi
operator|.
name|getHdfsHRI
argument_list|()
operator|==
literal|null
condition|)
block|{
try|try
block|{
name|errors
operator|.
name|progress
argument_list|()
expr_stmt|;
name|hbck
operator|.
name|loadHdfsRegioninfo
argument_list|(
name|hbi
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ioe
parameter_list|)
block|{
name|String
name|msg
init|=
literal|"Orphan region in HDFS: Unable to load .regioninfo from table "
operator|+
name|hbi
operator|.
name|getTableName
argument_list|()
operator|+
literal|" in hdfs dir "
operator|+
name|hbi
operator|.
name|getHdfsRegionDir
argument_list|()
operator|+
literal|"!  It may be an invalid format or version file.  Treating as "
operator|+
literal|"an orphaned regiondir."
decl_stmt|;
name|errors
operator|.
name|reportError
argument_list|(
name|ERROR_CODE
operator|.
name|ORPHAN_HDFS_REGION
argument_list|,
name|msg
argument_list|)
expr_stmt|;
try|try
block|{
name|hbck
operator|.
name|debugLsr
argument_list|(
name|hbi
operator|.
name|getHdfsRegionDir
argument_list|()
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ioe2
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Unable to read directory "
operator|+
name|hbi
operator|.
name|getHdfsRegionDir
argument_list|()
argument_list|,
name|ioe2
argument_list|)
expr_stmt|;
throw|throw
name|ioe2
throw|;
block|}
name|hbck
operator|.
name|orphanHdfsDirs
operator|.
name|add
argument_list|(
name|hbi
argument_list|)
expr_stmt|;
throw|throw
name|ioe
throw|;
block|}
block|}
return|return
literal|null
return|;
block|}
block|}
comment|/**    * Display the full report from fsck. This displays all live and dead region    * servers, and all known regions.    */
specifier|public
specifier|static
name|void
name|setDisplayFullReport
parameter_list|()
block|{
name|details
operator|=
literal|true
expr_stmt|;
block|}
comment|/**    * Set exclusive mode.    */
specifier|public
specifier|static
name|void
name|setForceExclusive
parameter_list|()
block|{
name|forceExclusive
operator|=
literal|true
expr_stmt|;
block|}
comment|/**    * Only one instance of hbck can modify HBase at a time.    */
specifier|public
name|boolean
name|isExclusive
parameter_list|()
block|{
return|return
name|fixAny
operator|||
name|forceExclusive
return|;
block|}
comment|/**    * Set summary mode.    * Print only summary of the tables and status (OK or INCONSISTENT)    */
specifier|static
name|void
name|setSummary
parameter_list|()
block|{
name|summary
operator|=
literal|true
expr_stmt|;
block|}
comment|/**    * Set hbase:meta check mode.    * Print only info about hbase:meta table deployment/state    */
name|void
name|setCheckMetaOnly
parameter_list|()
block|{
name|checkMetaOnly
operator|=
literal|true
expr_stmt|;
block|}
comment|/**    * Set region boundaries check mode.    */
name|void
name|setRegionBoundariesCheck
parameter_list|()
block|{
name|checkRegionBoundaries
operator|=
literal|true
expr_stmt|;
block|}
comment|/**    * Set replication fix mode.    */
specifier|public
name|void
name|setFixReplication
parameter_list|(
name|boolean
name|shouldFix
parameter_list|)
block|{
name|fixReplication
operator|=
name|shouldFix
expr_stmt|;
name|fixAny
operator||=
name|shouldFix
expr_stmt|;
block|}
comment|/**    * Check if we should rerun fsck again. This checks if we've tried to    * fix something and we should rerun fsck tool again.    * Display the full report from fsck. This displays all live and dead    * region servers, and all known regions.    */
name|void
name|setShouldRerun
parameter_list|()
block|{
name|rerun
operator|=
literal|true
expr_stmt|;
block|}
name|boolean
name|shouldRerun
parameter_list|()
block|{
return|return
name|rerun
return|;
block|}
comment|/**    * Fix inconsistencies found by fsck. This should try to fix errors (if any)    * found by fsck utility.    */
specifier|public
name|void
name|setFixAssignments
parameter_list|(
name|boolean
name|shouldFix
parameter_list|)
block|{
name|fixAssignments
operator|=
name|shouldFix
expr_stmt|;
name|fixAny
operator||=
name|shouldFix
expr_stmt|;
block|}
name|boolean
name|shouldFixAssignments
parameter_list|()
block|{
return|return
name|fixAssignments
return|;
block|}
specifier|public
name|void
name|setFixMeta
parameter_list|(
name|boolean
name|shouldFix
parameter_list|)
block|{
name|fixMeta
operator|=
name|shouldFix
expr_stmt|;
name|fixAny
operator||=
name|shouldFix
expr_stmt|;
block|}
name|boolean
name|shouldFixMeta
parameter_list|()
block|{
return|return
name|fixMeta
return|;
block|}
specifier|public
name|void
name|setFixEmptyMetaCells
parameter_list|(
name|boolean
name|shouldFix
parameter_list|)
block|{
name|fixEmptyMetaCells
operator|=
name|shouldFix
expr_stmt|;
name|fixAny
operator||=
name|shouldFix
expr_stmt|;
block|}
name|boolean
name|shouldFixEmptyMetaCells
parameter_list|()
block|{
return|return
name|fixEmptyMetaCells
return|;
block|}
specifier|public
name|void
name|setCheckHdfs
parameter_list|(
name|boolean
name|checking
parameter_list|)
block|{
name|checkHdfs
operator|=
name|checking
expr_stmt|;
block|}
name|boolean
name|shouldCheckHdfs
parameter_list|()
block|{
return|return
name|checkHdfs
return|;
block|}
specifier|public
name|void
name|setFixHdfsHoles
parameter_list|(
name|boolean
name|shouldFix
parameter_list|)
block|{
name|fixHdfsHoles
operator|=
name|shouldFix
expr_stmt|;
name|fixAny
operator||=
name|shouldFix
expr_stmt|;
block|}
name|boolean
name|shouldFixHdfsHoles
parameter_list|()
block|{
return|return
name|fixHdfsHoles
return|;
block|}
specifier|public
name|void
name|setFixTableOrphans
parameter_list|(
name|boolean
name|shouldFix
parameter_list|)
block|{
name|fixTableOrphans
operator|=
name|shouldFix
expr_stmt|;
name|fixAny
operator||=
name|shouldFix
expr_stmt|;
block|}
name|boolean
name|shouldFixTableOrphans
parameter_list|()
block|{
return|return
name|fixTableOrphans
return|;
block|}
specifier|public
name|void
name|setFixHdfsOverlaps
parameter_list|(
name|boolean
name|shouldFix
parameter_list|)
block|{
name|fixHdfsOverlaps
operator|=
name|shouldFix
expr_stmt|;
name|fixAny
operator||=
name|shouldFix
expr_stmt|;
block|}
name|boolean
name|shouldFixHdfsOverlaps
parameter_list|()
block|{
return|return
name|fixHdfsOverlaps
return|;
block|}
specifier|public
name|void
name|setFixHdfsOrphans
parameter_list|(
name|boolean
name|shouldFix
parameter_list|)
block|{
name|fixHdfsOrphans
operator|=
name|shouldFix
expr_stmt|;
name|fixAny
operator||=
name|shouldFix
expr_stmt|;
block|}
name|boolean
name|shouldFixHdfsOrphans
parameter_list|()
block|{
return|return
name|fixHdfsOrphans
return|;
block|}
specifier|public
name|void
name|setFixVersionFile
parameter_list|(
name|boolean
name|shouldFix
parameter_list|)
block|{
name|fixVersionFile
operator|=
name|shouldFix
expr_stmt|;
name|fixAny
operator||=
name|shouldFix
expr_stmt|;
block|}
specifier|public
name|boolean
name|shouldFixVersionFile
parameter_list|()
block|{
return|return
name|fixVersionFile
return|;
block|}
specifier|public
name|void
name|setSidelineBigOverlaps
parameter_list|(
name|boolean
name|sbo
parameter_list|)
block|{
name|this
operator|.
name|sidelineBigOverlaps
operator|=
name|sbo
expr_stmt|;
block|}
specifier|public
name|boolean
name|shouldSidelineBigOverlaps
parameter_list|()
block|{
return|return
name|sidelineBigOverlaps
return|;
block|}
specifier|public
name|void
name|setFixSplitParents
parameter_list|(
name|boolean
name|shouldFix
parameter_list|)
block|{
name|fixSplitParents
operator|=
name|shouldFix
expr_stmt|;
name|fixAny
operator||=
name|shouldFix
expr_stmt|;
block|}
specifier|public
name|void
name|setRemoveParents
parameter_list|(
name|boolean
name|shouldFix
parameter_list|)
block|{
name|removeParents
operator|=
name|shouldFix
expr_stmt|;
name|fixAny
operator||=
name|shouldFix
expr_stmt|;
block|}
name|boolean
name|shouldFixSplitParents
parameter_list|()
block|{
return|return
name|fixSplitParents
return|;
block|}
name|boolean
name|shouldRemoveParents
parameter_list|()
block|{
return|return
name|removeParents
return|;
block|}
specifier|public
name|void
name|setFixReferenceFiles
parameter_list|(
name|boolean
name|shouldFix
parameter_list|)
block|{
name|fixReferenceFiles
operator|=
name|shouldFix
expr_stmt|;
name|fixAny
operator||=
name|shouldFix
expr_stmt|;
block|}
name|boolean
name|shouldFixReferenceFiles
parameter_list|()
block|{
return|return
name|fixReferenceFiles
return|;
block|}
specifier|public
name|void
name|setFixHFileLinks
parameter_list|(
name|boolean
name|shouldFix
parameter_list|)
block|{
name|fixHFileLinks
operator|=
name|shouldFix
expr_stmt|;
name|fixAny
operator||=
name|shouldFix
expr_stmt|;
block|}
name|boolean
name|shouldFixHFileLinks
parameter_list|()
block|{
return|return
name|fixHFileLinks
return|;
block|}
specifier|public
name|boolean
name|shouldIgnorePreCheckPermission
parameter_list|()
block|{
return|return
operator|!
name|fixAny
operator|||
name|ignorePreCheckPermission
return|;
block|}
specifier|public
name|void
name|setIgnorePreCheckPermission
parameter_list|(
name|boolean
name|ignorePreCheckPermission
parameter_list|)
block|{
name|this
operator|.
name|ignorePreCheckPermission
operator|=
name|ignorePreCheckPermission
expr_stmt|;
block|}
comment|/**    * @param mm maximum number of regions to merge into a single region.    */
specifier|public
name|void
name|setMaxMerge
parameter_list|(
name|int
name|mm
parameter_list|)
block|{
name|this
operator|.
name|maxMerge
operator|=
name|mm
expr_stmt|;
block|}
specifier|public
name|int
name|getMaxMerge
parameter_list|()
block|{
return|return
name|maxMerge
return|;
block|}
specifier|public
name|void
name|setMaxOverlapsToSideline
parameter_list|(
name|int
name|mo
parameter_list|)
block|{
name|this
operator|.
name|maxOverlapsToSideline
operator|=
name|mo
expr_stmt|;
block|}
specifier|public
name|int
name|getMaxOverlapsToSideline
parameter_list|()
block|{
return|return
name|maxOverlapsToSideline
return|;
block|}
comment|/**    * Only check/fix tables specified by the list,    * Empty list means all tables are included.    */
name|boolean
name|isTableIncluded
parameter_list|(
name|TableName
name|table
parameter_list|)
block|{
return|return
operator|(
name|tablesIncluded
operator|.
name|isEmpty
argument_list|()
operator|)
operator|||
name|tablesIncluded
operator|.
name|contains
argument_list|(
name|table
argument_list|)
return|;
block|}
specifier|public
name|void
name|includeTable
parameter_list|(
name|TableName
name|table
parameter_list|)
block|{
name|tablesIncluded
operator|.
name|add
argument_list|(
name|table
argument_list|)
expr_stmt|;
block|}
name|Set
argument_list|<
name|TableName
argument_list|>
name|getIncludedTables
parameter_list|()
block|{
return|return
operator|new
name|HashSet
argument_list|<>
argument_list|(
name|tablesIncluded
argument_list|)
return|;
block|}
comment|/**    * We are interested in only those tables that have not changed their state in    * hbase:meta during the last few seconds specified by hbase.admin.fsck.timelag    * @param seconds - the time in seconds    */
specifier|public
name|void
name|setTimeLag
parameter_list|(
name|long
name|seconds
parameter_list|)
block|{
name|timelag
operator|=
name|seconds
operator|*
literal|1000
expr_stmt|;
comment|// convert to milliseconds
block|}
comment|/**    *    * @param sidelineDir - HDFS path to sideline data    */
specifier|public
name|void
name|setSidelineDir
parameter_list|(
name|String
name|sidelineDir
parameter_list|)
block|{
name|this
operator|.
name|sidelineDir
operator|=
operator|new
name|Path
argument_list|(
name|sidelineDir
argument_list|)
expr_stmt|;
block|}
specifier|protected
name|HFileCorruptionChecker
name|createHFileCorruptionChecker
parameter_list|(
name|boolean
name|sidelineCorruptHFiles
parameter_list|)
throws|throws
name|IOException
block|{
return|return
operator|new
name|HFileCorruptionChecker
argument_list|(
name|getConf
argument_list|()
argument_list|,
name|executor
argument_list|,
name|sidelineCorruptHFiles
argument_list|)
return|;
block|}
specifier|public
name|HFileCorruptionChecker
name|getHFilecorruptionChecker
parameter_list|()
block|{
return|return
name|hfcc
return|;
block|}
specifier|public
name|void
name|setHFileCorruptionChecker
parameter_list|(
name|HFileCorruptionChecker
name|hfcc
parameter_list|)
block|{
name|this
operator|.
name|hfcc
operator|=
name|hfcc
expr_stmt|;
block|}
specifier|public
name|void
name|setRetCode
parameter_list|(
name|int
name|code
parameter_list|)
block|{
name|this
operator|.
name|retcode
operator|=
name|code
expr_stmt|;
block|}
specifier|public
name|int
name|getRetCode
parameter_list|()
block|{
return|return
name|retcode
return|;
block|}
specifier|protected
name|HBaseFsck
name|printUsageAndExit
parameter_list|()
block|{
name|StringWriter
name|sw
init|=
operator|new
name|StringWriter
argument_list|(
literal|2048
argument_list|)
decl_stmt|;
name|PrintWriter
name|out
init|=
operator|new
name|PrintWriter
argument_list|(
name|sw
argument_list|)
decl_stmt|;
name|out
operator|.
name|println
argument_list|(
literal|""
argument_list|)
expr_stmt|;
name|out
operator|.
name|println
argument_list|(
literal|"-----------------------------------------------------------------------"
argument_list|)
expr_stmt|;
name|out
operator|.
name|println
argument_list|(
literal|"NOTE: As of HBase version 2.0, the hbck tool is significantly changed."
argument_list|)
expr_stmt|;
name|out
operator|.
name|println
argument_list|(
literal|"In general, all Read-Only options are supported and can be be used"
argument_list|)
expr_stmt|;
name|out
operator|.
name|println
argument_list|(
literal|"safely. Most -fix/ -repair options are NOT supported. Please see usage"
argument_list|)
expr_stmt|;
name|out
operator|.
name|println
argument_list|(
literal|"below for details on which options are not supported."
argument_list|)
expr_stmt|;
name|out
operator|.
name|println
argument_list|(
literal|"-----------------------------------------------------------------------"
argument_list|)
expr_stmt|;
name|out
operator|.
name|println
argument_list|(
literal|""
argument_list|)
expr_stmt|;
name|out
operator|.
name|println
argument_list|(
literal|"Usage: fsck [opts] {only tables}"
argument_list|)
expr_stmt|;
name|out
operator|.
name|println
argument_list|(
literal|" where [opts] are:"
argument_list|)
expr_stmt|;
name|out
operator|.
name|println
argument_list|(
literal|"   -help Display help options (this)"
argument_list|)
expr_stmt|;
name|out
operator|.
name|println
argument_list|(
literal|"   -details Display full report of all regions."
argument_list|)
expr_stmt|;
name|out
operator|.
name|println
argument_list|(
literal|"   -timelag<timeInSeconds>  Process only regions that "
operator|+
literal|" have not experienced any metadata updates in the last "
operator|+
literal|"<timeInSeconds> seconds."
argument_list|)
expr_stmt|;
name|out
operator|.
name|println
argument_list|(
literal|"   -sleepBeforeRerun<timeInSeconds> Sleep this many seconds"
operator|+
literal|" before checking if the fix worked if run with -fix"
argument_list|)
expr_stmt|;
name|out
operator|.
name|println
argument_list|(
literal|"   -summary Print only summary of the tables and status."
argument_list|)
expr_stmt|;
name|out
operator|.
name|println
argument_list|(
literal|"   -metaonly Only check the state of the hbase:meta table."
argument_list|)
expr_stmt|;
name|out
operator|.
name|println
argument_list|(
literal|"   -sidelineDir<hdfs://> HDFS path to backup existing meta."
argument_list|)
expr_stmt|;
name|out
operator|.
name|println
argument_list|(
literal|"   -boundaries Verify that regions boundaries are the same between META and store files."
argument_list|)
expr_stmt|;
name|out
operator|.
name|println
argument_list|(
literal|"   -exclusive Abort if another hbck is exclusive or fixing."
argument_list|)
expr_stmt|;
name|out
operator|.
name|println
argument_list|(
literal|""
argument_list|)
expr_stmt|;
name|out
operator|.
name|println
argument_list|(
literal|"  Datafile Repair options: (expert features, use with caution!)"
argument_list|)
expr_stmt|;
name|out
operator|.
name|println
argument_list|(
literal|"   -checkCorruptHFiles     Check all Hfiles by opening them to make sure they are valid"
argument_list|)
expr_stmt|;
name|out
operator|.
name|println
argument_list|(
literal|"   -sidelineCorruptHFiles  Quarantine corrupted HFiles.  implies -checkCorruptHFiles"
argument_list|)
expr_stmt|;
name|out
operator|.
name|println
argument_list|(
literal|""
argument_list|)
expr_stmt|;
name|out
operator|.
name|println
argument_list|(
literal|" Replication options"
argument_list|)
expr_stmt|;
name|out
operator|.
name|println
argument_list|(
literal|"   -fixReplication   Deletes replication queues for removed peers"
argument_list|)
expr_stmt|;
name|out
operator|.
name|println
argument_list|(
literal|""
argument_list|)
expr_stmt|;
name|out
operator|.
name|println
argument_list|(
literal|"  Metadata Repair options supported as of version 2.0: (expert features, use with caution!)"
argument_list|)
expr_stmt|;
name|out
operator|.
name|println
argument_list|(
literal|"   -fixVersionFile   Try to fix missing hbase.version file in hdfs."
argument_list|)
expr_stmt|;
name|out
operator|.
name|println
argument_list|(
literal|"   -fixReferenceFiles  Try to offline lingering reference store files"
argument_list|)
expr_stmt|;
name|out
operator|.
name|println
argument_list|(
literal|"   -fixHFileLinks  Try to offline lingering HFileLinks"
argument_list|)
expr_stmt|;
name|out
operator|.
name|println
argument_list|(
literal|"   -noHdfsChecking   Don't load/check region info from HDFS."
operator|+
literal|" Assumes hbase:meta region info is good. Won't check/fix any HDFS issue, e.g. hole, orphan, or overlap"
argument_list|)
expr_stmt|;
name|out
operator|.
name|println
argument_list|(
literal|"   -ignorePreCheckPermission  ignore filesystem permission pre-check"
argument_list|)
expr_stmt|;
name|out
operator|.
name|println
argument_list|(
literal|""
argument_list|)
expr_stmt|;
name|out
operator|.
name|println
argument_list|(
literal|"NOTE: Following options are NOT supported as of HBase version 2.0+."
argument_list|)
expr_stmt|;
name|out
operator|.
name|println
argument_list|(
literal|""
argument_list|)
expr_stmt|;
name|out
operator|.
name|println
argument_list|(
literal|"  UNSUPPORTED Metadata Repair options: (expert features, use with caution!)"
argument_list|)
expr_stmt|;
name|out
operator|.
name|println
argument_list|(
literal|"   -fix              Try to fix region assignments.  This is for backwards compatiblity"
argument_list|)
expr_stmt|;
name|out
operator|.
name|println
argument_list|(
literal|"   -fixAssignments   Try to fix region assignments.  Replaces the old -fix"
argument_list|)
expr_stmt|;
name|out
operator|.
name|println
argument_list|(
literal|"   -fixMeta          Try to fix meta problems.  This assumes HDFS region info is good."
argument_list|)
expr_stmt|;
name|out
operator|.
name|println
argument_list|(
literal|"   -fixHdfsHoles     Try to fix region holes in hdfs."
argument_list|)
expr_stmt|;
name|out
operator|.
name|println
argument_list|(
literal|"   -fixHdfsOrphans   Try to fix region dirs with no .regioninfo file in hdfs"
argument_list|)
expr_stmt|;
name|out
operator|.
name|println
argument_list|(
literal|"   -fixTableOrphans  Try to fix table dirs with no .tableinfo file in hdfs (online mode only)"
argument_list|)
expr_stmt|;
name|out
operator|.
name|println
argument_list|(
literal|"   -fixHdfsOverlaps  Try to fix region overlaps in hdfs."
argument_list|)
expr_stmt|;
name|out
operator|.
name|println
argument_list|(
literal|"   -maxMerge<n>     When fixing region overlaps, allow at most<n> regions to merge. (n="
operator|+
name|DEFAULT_MAX_MERGE
operator|+
literal|" by default)"
argument_list|)
expr_stmt|;
name|out
operator|.
name|println
argument_list|(
literal|"   -sidelineBigOverlaps  When fixing region overlaps, allow to sideline big overlaps"
argument_list|)
expr_stmt|;
name|out
operator|.
name|println
argument_list|(
literal|"   -maxOverlapsToSideline<n>  When fixing region overlaps, allow at most<n> regions to sideline per group. (n="
operator|+
name|DEFAULT_OVERLAPS_TO_SIDELINE
operator|+
literal|" by default)"
argument_list|)
expr_stmt|;
name|out
operator|.
name|println
argument_list|(
literal|"   -fixSplitParents  Try to force offline split parents to be online."
argument_list|)
expr_stmt|;
name|out
operator|.
name|println
argument_list|(
literal|"   -removeParents    Try to offline and sideline lingering parents and keep daughter regions."
argument_list|)
expr_stmt|;
name|out
operator|.
name|println
argument_list|(
literal|"   -fixEmptyMetaCells  Try to fix hbase:meta entries not referencing any region"
operator|+
literal|" (empty REGIONINFO_QUALIFIER rows)"
argument_list|)
expr_stmt|;
name|out
operator|.
name|println
argument_list|(
literal|""
argument_list|)
expr_stmt|;
name|out
operator|.
name|println
argument_list|(
literal|"  UNSUPPORTED Metadata Repair shortcuts"
argument_list|)
expr_stmt|;
name|out
operator|.
name|println
argument_list|(
literal|"   -repair           Shortcut for -fixAssignments -fixMeta -fixHdfsHoles "
operator|+
literal|"-fixHdfsOrphans -fixHdfsOverlaps -fixVersionFile -sidelineBigOverlaps -fixReferenceFiles"
operator|+
literal|"-fixHFileLinks"
argument_list|)
expr_stmt|;
name|out
operator|.
name|println
argument_list|(
literal|"   -repairHoles      Shortcut for -fixAssignments -fixMeta -fixHdfsHoles"
argument_list|)
expr_stmt|;
name|out
operator|.
name|flush
argument_list|()
expr_stmt|;
name|errors
operator|.
name|reportError
argument_list|(
name|ERROR_CODE
operator|.
name|WRONG_USAGE
argument_list|,
name|sw
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
name|setRetCode
argument_list|(
operator|-
literal|2
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**    * Main program    *    * @param args    * @throws Exception    */
specifier|public
specifier|static
name|void
name|main
parameter_list|(
name|String
index|[]
name|args
parameter_list|)
throws|throws
name|Exception
block|{
comment|// create a fsck object
name|Configuration
name|conf
init|=
name|HBaseConfiguration
operator|.
name|create
argument_list|()
decl_stmt|;
name|Path
name|hbasedir
init|=
name|FSUtils
operator|.
name|getRootDir
argument_list|(
name|conf
argument_list|)
decl_stmt|;
name|URI
name|defaultFs
init|=
name|hbasedir
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
operator|.
name|getUri
argument_list|()
decl_stmt|;
name|FSUtils
operator|.
name|setFsDefault
argument_list|(
name|conf
argument_list|,
operator|new
name|Path
argument_list|(
name|defaultFs
argument_list|)
argument_list|)
expr_stmt|;
name|int
name|ret
init|=
name|ToolRunner
operator|.
name|run
argument_list|(
operator|new
name|HBaseFsckTool
argument_list|(
name|conf
argument_list|)
argument_list|,
name|args
argument_list|)
decl_stmt|;
name|System
operator|.
name|exit
argument_list|(
name|ret
argument_list|)
expr_stmt|;
block|}
comment|/**    * This is a Tool wrapper that gathers -Dxxx=yyy configuration settings from the command line.    */
specifier|static
class|class
name|HBaseFsckTool
extends|extends
name|Configured
implements|implements
name|Tool
block|{
name|HBaseFsckTool
parameter_list|(
name|Configuration
name|conf
parameter_list|)
block|{
name|super
argument_list|(
name|conf
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|int
name|run
parameter_list|(
name|String
index|[]
name|args
parameter_list|)
throws|throws
name|Exception
block|{
name|HBaseFsck
name|hbck
init|=
operator|new
name|HBaseFsck
argument_list|(
name|getConf
argument_list|()
argument_list|)
decl_stmt|;
name|hbck
operator|.
name|exec
argument_list|(
name|hbck
operator|.
name|executor
argument_list|,
name|args
argument_list|)
expr_stmt|;
name|hbck
operator|.
name|close
argument_list|()
expr_stmt|;
return|return
name|hbck
operator|.
name|getRetCode
argument_list|()
return|;
block|}
block|}
specifier|public
name|HBaseFsck
name|exec
parameter_list|(
name|ExecutorService
name|exec
parameter_list|,
name|String
index|[]
name|args
parameter_list|)
throws|throws
name|KeeperException
throws|,
name|IOException
throws|,
name|InterruptedException
throws|,
name|ReplicationException
block|{
name|long
name|sleepBeforeRerun
init|=
name|DEFAULT_SLEEP_BEFORE_RERUN
decl_stmt|;
name|boolean
name|checkCorruptHFiles
init|=
literal|false
decl_stmt|;
name|boolean
name|sidelineCorruptHFiles
init|=
literal|false
decl_stmt|;
comment|// Process command-line args.
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|args
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|String
name|cmd
init|=
name|args
index|[
name|i
index|]
decl_stmt|;
if|if
condition|(
name|cmd
operator|.
name|equals
argument_list|(
literal|"-help"
argument_list|)
operator|||
name|cmd
operator|.
name|equals
argument_list|(
literal|"-h"
argument_list|)
condition|)
block|{
return|return
name|printUsageAndExit
argument_list|()
return|;
block|}
elseif|else
if|if
condition|(
name|cmd
operator|.
name|equals
argument_list|(
literal|"-details"
argument_list|)
condition|)
block|{
name|setDisplayFullReport
argument_list|()
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|cmd
operator|.
name|equals
argument_list|(
literal|"-exclusive"
argument_list|)
condition|)
block|{
name|setForceExclusive
argument_list|()
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|cmd
operator|.
name|equals
argument_list|(
literal|"-timelag"
argument_list|)
condition|)
block|{
if|if
condition|(
name|i
operator|==
name|args
operator|.
name|length
operator|-
literal|1
condition|)
block|{
name|errors
operator|.
name|reportError
argument_list|(
name|ERROR_CODE
operator|.
name|WRONG_USAGE
argument_list|,
literal|"HBaseFsck: -timelag needs a value."
argument_list|)
expr_stmt|;
return|return
name|printUsageAndExit
argument_list|()
return|;
block|}
try|try
block|{
name|long
name|timelag
init|=
name|Long
operator|.
name|parseLong
argument_list|(
name|args
index|[
name|i
operator|+
literal|1
index|]
argument_list|)
decl_stmt|;
name|setTimeLag
argument_list|(
name|timelag
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|NumberFormatException
name|e
parameter_list|)
block|{
name|errors
operator|.
name|reportError
argument_list|(
name|ERROR_CODE
operator|.
name|WRONG_USAGE
argument_list|,
literal|"-timelag needs a numeric value."
argument_list|)
expr_stmt|;
return|return
name|printUsageAndExit
argument_list|()
return|;
block|}
name|i
operator|++
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|cmd
operator|.
name|equals
argument_list|(
literal|"-sleepBeforeRerun"
argument_list|)
condition|)
block|{
if|if
condition|(
name|i
operator|==
name|args
operator|.
name|length
operator|-
literal|1
condition|)
block|{
name|errors
operator|.
name|reportError
argument_list|(
name|ERROR_CODE
operator|.
name|WRONG_USAGE
argument_list|,
literal|"HBaseFsck: -sleepBeforeRerun needs a value."
argument_list|)
expr_stmt|;
return|return
name|printUsageAndExit
argument_list|()
return|;
block|}
try|try
block|{
name|sleepBeforeRerun
operator|=
name|Long
operator|.
name|parseLong
argument_list|(
name|args
index|[
name|i
operator|+
literal|1
index|]
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|NumberFormatException
name|e
parameter_list|)
block|{
name|errors
operator|.
name|reportError
argument_list|(
name|ERROR_CODE
operator|.
name|WRONG_USAGE
argument_list|,
literal|"-sleepBeforeRerun needs a numeric value."
argument_list|)
expr_stmt|;
return|return
name|printUsageAndExit
argument_list|()
return|;
block|}
name|i
operator|++
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|cmd
operator|.
name|equals
argument_list|(
literal|"-sidelineDir"
argument_list|)
condition|)
block|{
if|if
condition|(
name|i
operator|==
name|args
operator|.
name|length
operator|-
literal|1
condition|)
block|{
name|errors
operator|.
name|reportError
argument_list|(
name|ERROR_CODE
operator|.
name|WRONG_USAGE
argument_list|,
literal|"HBaseFsck: -sidelineDir needs a value."
argument_list|)
expr_stmt|;
return|return
name|printUsageAndExit
argument_list|()
return|;
block|}
name|i
operator|++
expr_stmt|;
name|setSidelineDir
argument_list|(
name|args
index|[
name|i
index|]
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|cmd
operator|.
name|equals
argument_list|(
literal|"-fix"
argument_list|)
condition|)
block|{
name|errors
operator|.
name|reportError
argument_list|(
name|ERROR_CODE
operator|.
name|WRONG_USAGE
argument_list|,
literal|"This option is deprecated, please use  -fixAssignments instead."
argument_list|)
expr_stmt|;
name|setFixAssignments
argument_list|(
literal|true
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|cmd
operator|.
name|equals
argument_list|(
literal|"-fixAssignments"
argument_list|)
condition|)
block|{
name|setFixAssignments
argument_list|(
literal|true
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|cmd
operator|.
name|equals
argument_list|(
literal|"-fixMeta"
argument_list|)
condition|)
block|{
name|setFixMeta
argument_list|(
literal|true
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|cmd
operator|.
name|equals
argument_list|(
literal|"-noHdfsChecking"
argument_list|)
condition|)
block|{
name|setCheckHdfs
argument_list|(
literal|false
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|cmd
operator|.
name|equals
argument_list|(
literal|"-fixHdfsHoles"
argument_list|)
condition|)
block|{
name|setFixHdfsHoles
argument_list|(
literal|true
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|cmd
operator|.
name|equals
argument_list|(
literal|"-fixHdfsOrphans"
argument_list|)
condition|)
block|{
name|setFixHdfsOrphans
argument_list|(
literal|true
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|cmd
operator|.
name|equals
argument_list|(
literal|"-fixTableOrphans"
argument_list|)
condition|)
block|{
name|setFixTableOrphans
argument_list|(
literal|true
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|cmd
operator|.
name|equals
argument_list|(
literal|"-fixHdfsOverlaps"
argument_list|)
condition|)
block|{
name|setFixHdfsOverlaps
argument_list|(
literal|true
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|cmd
operator|.
name|equals
argument_list|(
literal|"-fixVersionFile"
argument_list|)
condition|)
block|{
name|setFixVersionFile
argument_list|(
literal|true
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|cmd
operator|.
name|equals
argument_list|(
literal|"-sidelineBigOverlaps"
argument_list|)
condition|)
block|{
name|setSidelineBigOverlaps
argument_list|(
literal|true
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|cmd
operator|.
name|equals
argument_list|(
literal|"-fixSplitParents"
argument_list|)
condition|)
block|{
name|setFixSplitParents
argument_list|(
literal|true
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|cmd
operator|.
name|equals
argument_list|(
literal|"-removeParents"
argument_list|)
condition|)
block|{
name|setRemoveParents
argument_list|(
literal|true
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|cmd
operator|.
name|equals
argument_list|(
literal|"-ignorePreCheckPermission"
argument_list|)
condition|)
block|{
name|setIgnorePreCheckPermission
argument_list|(
literal|true
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|cmd
operator|.
name|equals
argument_list|(
literal|"-checkCorruptHFiles"
argument_list|)
condition|)
block|{
name|checkCorruptHFiles
operator|=
literal|true
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|cmd
operator|.
name|equals
argument_list|(
literal|"-sidelineCorruptHFiles"
argument_list|)
condition|)
block|{
name|sidelineCorruptHFiles
operator|=
literal|true
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|cmd
operator|.
name|equals
argument_list|(
literal|"-fixReferenceFiles"
argument_list|)
condition|)
block|{
name|setFixReferenceFiles
argument_list|(
literal|true
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|cmd
operator|.
name|equals
argument_list|(
literal|"-fixHFileLinks"
argument_list|)
condition|)
block|{
name|setFixHFileLinks
argument_list|(
literal|true
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|cmd
operator|.
name|equals
argument_list|(
literal|"-fixEmptyMetaCells"
argument_list|)
condition|)
block|{
name|setFixEmptyMetaCells
argument_list|(
literal|true
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|cmd
operator|.
name|equals
argument_list|(
literal|"-repair"
argument_list|)
condition|)
block|{
comment|// this attempts to merge overlapping hdfs regions, needs testing
comment|// under load
name|setFixHdfsHoles
argument_list|(
literal|true
argument_list|)
expr_stmt|;
name|setFixHdfsOrphans
argument_list|(
literal|true
argument_list|)
expr_stmt|;
name|setFixMeta
argument_list|(
literal|true
argument_list|)
expr_stmt|;
name|setFixAssignments
argument_list|(
literal|true
argument_list|)
expr_stmt|;
name|setFixHdfsOverlaps
argument_list|(
literal|true
argument_list|)
expr_stmt|;
name|setFixVersionFile
argument_list|(
literal|true
argument_list|)
expr_stmt|;
name|setSidelineBigOverlaps
argument_list|(
literal|true
argument_list|)
expr_stmt|;
name|setFixSplitParents
argument_list|(
literal|false
argument_list|)
expr_stmt|;
name|setCheckHdfs
argument_list|(
literal|true
argument_list|)
expr_stmt|;
name|setFixReferenceFiles
argument_list|(
literal|true
argument_list|)
expr_stmt|;
name|setFixHFileLinks
argument_list|(
literal|true
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|cmd
operator|.
name|equals
argument_list|(
literal|"-repairHoles"
argument_list|)
condition|)
block|{
comment|// this will make all missing hdfs regions available but may lose data
name|setFixHdfsHoles
argument_list|(
literal|true
argument_list|)
expr_stmt|;
name|setFixHdfsOrphans
argument_list|(
literal|false
argument_list|)
expr_stmt|;
name|setFixMeta
argument_list|(
literal|true
argument_list|)
expr_stmt|;
name|setFixAssignments
argument_list|(
literal|true
argument_list|)
expr_stmt|;
name|setFixHdfsOverlaps
argument_list|(
literal|false
argument_list|)
expr_stmt|;
name|setSidelineBigOverlaps
argument_list|(
literal|false
argument_list|)
expr_stmt|;
name|setFixSplitParents
argument_list|(
literal|false
argument_list|)
expr_stmt|;
name|setCheckHdfs
argument_list|(
literal|true
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|cmd
operator|.
name|equals
argument_list|(
literal|"-maxOverlapsToSideline"
argument_list|)
condition|)
block|{
if|if
condition|(
name|i
operator|==
name|args
operator|.
name|length
operator|-
literal|1
condition|)
block|{
name|errors
operator|.
name|reportError
argument_list|(
name|ERROR_CODE
operator|.
name|WRONG_USAGE
argument_list|,
literal|"-maxOverlapsToSideline needs a numeric value argument."
argument_list|)
expr_stmt|;
return|return
name|printUsageAndExit
argument_list|()
return|;
block|}
try|try
block|{
name|int
name|maxOverlapsToSideline
init|=
name|Integer
operator|.
name|parseInt
argument_list|(
name|args
index|[
name|i
operator|+
literal|1
index|]
argument_list|)
decl_stmt|;
name|setMaxOverlapsToSideline
argument_list|(
name|maxOverlapsToSideline
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|NumberFormatException
name|e
parameter_list|)
block|{
name|errors
operator|.
name|reportError
argument_list|(
name|ERROR_CODE
operator|.
name|WRONG_USAGE
argument_list|,
literal|"-maxOverlapsToSideline needs a numeric value argument."
argument_list|)
expr_stmt|;
return|return
name|printUsageAndExit
argument_list|()
return|;
block|}
name|i
operator|++
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|cmd
operator|.
name|equals
argument_list|(
literal|"-maxMerge"
argument_list|)
condition|)
block|{
if|if
condition|(
name|i
operator|==
name|args
operator|.
name|length
operator|-
literal|1
condition|)
block|{
name|errors
operator|.
name|reportError
argument_list|(
name|ERROR_CODE
operator|.
name|WRONG_USAGE
argument_list|,
literal|"-maxMerge needs a numeric value argument."
argument_list|)
expr_stmt|;
return|return
name|printUsageAndExit
argument_list|()
return|;
block|}
try|try
block|{
name|int
name|maxMerge
init|=
name|Integer
operator|.
name|parseInt
argument_list|(
name|args
index|[
name|i
operator|+
literal|1
index|]
argument_list|)
decl_stmt|;
name|setMaxMerge
argument_list|(
name|maxMerge
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|NumberFormatException
name|e
parameter_list|)
block|{
name|errors
operator|.
name|reportError
argument_list|(
name|ERROR_CODE
operator|.
name|WRONG_USAGE
argument_list|,
literal|"-maxMerge needs a numeric value argument."
argument_list|)
expr_stmt|;
return|return
name|printUsageAndExit
argument_list|()
return|;
block|}
name|i
operator|++
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|cmd
operator|.
name|equals
argument_list|(
literal|"-summary"
argument_list|)
condition|)
block|{
name|setSummary
argument_list|()
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|cmd
operator|.
name|equals
argument_list|(
literal|"-metaonly"
argument_list|)
condition|)
block|{
name|setCheckMetaOnly
argument_list|()
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|cmd
operator|.
name|equals
argument_list|(
literal|"-boundaries"
argument_list|)
condition|)
block|{
name|setRegionBoundariesCheck
argument_list|()
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|cmd
operator|.
name|equals
argument_list|(
literal|"-fixReplication"
argument_list|)
condition|)
block|{
name|setFixReplication
argument_list|(
literal|true
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|cmd
operator|.
name|startsWith
argument_list|(
literal|"-"
argument_list|)
condition|)
block|{
name|errors
operator|.
name|reportError
argument_list|(
name|ERROR_CODE
operator|.
name|WRONG_USAGE
argument_list|,
literal|"Unrecognized option:"
operator|+
name|cmd
argument_list|)
expr_stmt|;
return|return
name|printUsageAndExit
argument_list|()
return|;
block|}
else|else
block|{
name|includeTable
argument_list|(
name|TableName
operator|.
name|valueOf
argument_list|(
name|cmd
argument_list|)
argument_list|)
expr_stmt|;
name|errors
operator|.
name|print
argument_list|(
literal|"Allow checking/fixes for table: "
operator|+
name|cmd
argument_list|)
expr_stmt|;
block|}
block|}
name|errors
operator|.
name|print
argument_list|(
literal|"HBaseFsck command line options: "
operator|+
name|StringUtils
operator|.
name|join
argument_list|(
name|args
argument_list|,
literal|" "
argument_list|)
argument_list|)
expr_stmt|;
comment|// pre-check current user has FS write permission or not
try|try
block|{
name|preCheckPermission
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|AccessDeniedException
name|ace
parameter_list|)
block|{
name|Runtime
operator|.
name|getRuntime
argument_list|()
operator|.
name|exit
argument_list|(
operator|-
literal|1
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ioe
parameter_list|)
block|{
name|Runtime
operator|.
name|getRuntime
argument_list|()
operator|.
name|exit
argument_list|(
operator|-
literal|1
argument_list|)
expr_stmt|;
block|}
comment|// do the real work of hbck
name|connect
argument_list|()
expr_stmt|;
comment|// after connecting to server above, we have server version
comment|// check if unsupported option is specified based on server version
if|if
condition|(
operator|!
name|isOptionsSupported
argument_list|(
name|args
argument_list|)
condition|)
block|{
return|return
name|printUsageAndExit
argument_list|()
return|;
block|}
try|try
block|{
comment|// if corrupt file mode is on, first fix them since they may be opened later
if|if
condition|(
name|checkCorruptHFiles
operator|||
name|sidelineCorruptHFiles
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Checking all hfiles for corruption"
argument_list|)
expr_stmt|;
name|HFileCorruptionChecker
name|hfcc
init|=
name|createHFileCorruptionChecker
argument_list|(
name|sidelineCorruptHFiles
argument_list|)
decl_stmt|;
name|setHFileCorruptionChecker
argument_list|(
name|hfcc
argument_list|)
expr_stmt|;
comment|// so we can get result
name|Collection
argument_list|<
name|TableName
argument_list|>
name|tables
init|=
name|getIncludedTables
argument_list|()
decl_stmt|;
name|Collection
argument_list|<
name|Path
argument_list|>
name|tableDirs
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
name|Path
name|rootdir
init|=
name|FSUtils
operator|.
name|getRootDir
argument_list|(
name|getConf
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|tables
operator|.
name|size
argument_list|()
operator|>
literal|0
condition|)
block|{
for|for
control|(
name|TableName
name|t
range|:
name|tables
control|)
block|{
name|tableDirs
operator|.
name|add
argument_list|(
name|FSUtils
operator|.
name|getTableDir
argument_list|(
name|rootdir
argument_list|,
name|t
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
name|tableDirs
operator|=
name|FSUtils
operator|.
name|getTableDirs
argument_list|(
name|FSUtils
operator|.
name|getCurrentFileSystem
argument_list|(
name|getConf
argument_list|()
argument_list|)
argument_list|,
name|rootdir
argument_list|)
expr_stmt|;
block|}
name|hfcc
operator|.
name|checkTables
argument_list|(
name|tableDirs
argument_list|)
expr_stmt|;
name|hfcc
operator|.
name|report
argument_list|(
name|errors
argument_list|)
expr_stmt|;
block|}
comment|// check and fix table integrity, region consistency.
name|int
name|code
init|=
name|onlineHbck
argument_list|()
decl_stmt|;
name|setRetCode
argument_list|(
name|code
argument_list|)
expr_stmt|;
comment|// If we have changed the HBase state it is better to run hbck again
comment|// to see if we haven't broken something else in the process.
comment|// We run it only once more because otherwise we can easily fall into
comment|// an infinite loop.
if|if
condition|(
name|shouldRerun
argument_list|()
condition|)
block|{
try|try
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Sleeping "
operator|+
name|sleepBeforeRerun
operator|+
literal|"ms before re-checking after fix..."
argument_list|)
expr_stmt|;
name|Thread
operator|.
name|sleep
argument_list|(
name|sleepBeforeRerun
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|ie
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Interrupted while sleeping"
argument_list|)
expr_stmt|;
return|return
name|this
return|;
block|}
comment|// Just report
name|setFixAssignments
argument_list|(
literal|false
argument_list|)
expr_stmt|;
name|setFixMeta
argument_list|(
literal|false
argument_list|)
expr_stmt|;
name|setFixHdfsHoles
argument_list|(
literal|false
argument_list|)
expr_stmt|;
name|setFixHdfsOverlaps
argument_list|(
literal|false
argument_list|)
expr_stmt|;
name|setFixVersionFile
argument_list|(
literal|false
argument_list|)
expr_stmt|;
name|setFixTableOrphans
argument_list|(
literal|false
argument_list|)
expr_stmt|;
name|errors
operator|.
name|resetErrors
argument_list|()
expr_stmt|;
name|code
operator|=
name|onlineHbck
argument_list|()
expr_stmt|;
name|setRetCode
argument_list|(
name|code
argument_list|)
expr_stmt|;
block|}
block|}
finally|finally
block|{
name|IOUtils
operator|.
name|closeQuietly
argument_list|(
name|this
argument_list|)
expr_stmt|;
block|}
return|return
name|this
return|;
block|}
specifier|private
name|boolean
name|isOptionsSupported
parameter_list|(
name|String
index|[]
name|args
parameter_list|)
block|{
name|boolean
name|result
init|=
literal|true
decl_stmt|;
name|String
name|hbaseServerVersion
init|=
name|status
operator|.
name|getHBaseVersion
argument_list|()
decl_stmt|;
name|Object
index|[]
name|versionComponents
init|=
name|VersionInfo
operator|.
name|getVersionComponents
argument_list|(
name|hbaseServerVersion
argument_list|)
decl_stmt|;
if|if
condition|(
name|versionComponents
index|[
literal|0
index|]
operator|instanceof
name|Integer
operator|&&
operator|(
operator|(
name|Integer
operator|)
name|versionComponents
index|[
literal|0
index|]
operator|)
operator|>=
literal|2
condition|)
block|{
comment|// Process command-line args.
for|for
control|(
name|String
name|arg
range|:
name|args
control|)
block|{
if|if
condition|(
name|unsupportedOptionsInV2
operator|.
name|contains
argument_list|(
name|arg
argument_list|)
condition|)
block|{
name|errors
operator|.
name|reportError
argument_list|(
name|ERROR_CODE
operator|.
name|UNSUPPORTED_OPTION
argument_list|,
literal|"option '"
operator|+
name|arg
operator|+
literal|"' is not "
operator|+
literal|"supportted!"
argument_list|)
expr_stmt|;
name|result
operator|=
literal|false
expr_stmt|;
break|break;
block|}
block|}
block|}
return|return
name|result
return|;
block|}
comment|/**    * ls -r for debugging purposes    */
name|void
name|debugLsr
parameter_list|(
name|Path
name|p
parameter_list|)
throws|throws
name|IOException
block|{
name|debugLsr
argument_list|(
name|getConf
argument_list|()
argument_list|,
name|p
argument_list|,
name|errors
argument_list|)
expr_stmt|;
block|}
comment|/**    * ls -r for debugging purposes    */
specifier|public
specifier|static
name|void
name|debugLsr
parameter_list|(
name|Configuration
name|conf
parameter_list|,
name|Path
name|p
parameter_list|)
throws|throws
name|IOException
block|{
name|debugLsr
argument_list|(
name|conf
argument_list|,
name|p
argument_list|,
operator|new
name|PrintingErrorReporter
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|/**    * ls -r for debugging purposes    */
specifier|public
specifier|static
name|void
name|debugLsr
parameter_list|(
name|Configuration
name|conf
parameter_list|,
name|Path
name|p
parameter_list|,
name|ErrorReporter
name|errors
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
operator|!
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
operator|||
name|p
operator|==
literal|null
condition|)
block|{
return|return;
block|}
name|FileSystem
name|fs
init|=
name|p
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|fs
operator|.
name|exists
argument_list|(
name|p
argument_list|)
condition|)
block|{
comment|// nothing
return|return;
block|}
name|errors
operator|.
name|print
argument_list|(
name|p
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|fs
operator|.
name|isFile
argument_list|(
name|p
argument_list|)
condition|)
block|{
return|return;
block|}
if|if
condition|(
name|fs
operator|.
name|getFileStatus
argument_list|(
name|p
argument_list|)
operator|.
name|isDirectory
argument_list|()
condition|)
block|{
name|FileStatus
index|[]
name|fss
init|=
name|fs
operator|.
name|listStatus
argument_list|(
name|p
argument_list|)
decl_stmt|;
for|for
control|(
name|FileStatus
name|status
range|:
name|fss
control|)
block|{
name|debugLsr
argument_list|(
name|conf
argument_list|,
name|status
operator|.
name|getPath
argument_list|()
argument_list|,
name|errors
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
end_class

end_unit

