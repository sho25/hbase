begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/*  *  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|replication
operator|.
name|regionserver
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Arrays
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collections
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Iterator
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Set
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|SortedSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|TreeSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|UUID
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ConcurrentHashMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|CopyOnWriteArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|Future
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|LinkedBlockingQueue
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|RejectedExecutionException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ThreadLocalRandom
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ThreadPoolExecutor
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|TimeUnit
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|atomic
operator|.
name|AtomicLong
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|stream
operator|.
name|Collectors
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HConstants
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|MetaTableAccessor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|Server
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|ServerName
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|TableDescriptors
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|TableName
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|Connection
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|ConnectionFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|HRegionServer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|RegionServerCoprocessorHost
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|replication
operator|.
name|ReplicationEndpoint
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|replication
operator|.
name|ReplicationException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|replication
operator|.
name|ReplicationListener
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|replication
operator|.
name|ReplicationPeer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|replication
operator|.
name|ReplicationPeerConfig
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|replication
operator|.
name|ReplicationPeers
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|replication
operator|.
name|ReplicationQueueInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|replication
operator|.
name|ReplicationQueueStorage
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|replication
operator|.
name|ReplicationTracker
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|Bytes
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|Pair
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|wal
operator|.
name|AbstractFSWALProvider
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|yetus
operator|.
name|audience
operator|.
name|InterfaceAudience
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|Logger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|LoggerFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hbase
operator|.
name|thirdparty
operator|.
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|annotations
operator|.
name|VisibleForTesting
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hbase
operator|.
name|thirdparty
operator|.
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ThreadFactoryBuilder
import|;
end_import

begin_comment
comment|/**  * This class is responsible to manage all the replication  * sources. There are two classes of sources:  *<ul>  *<li> Normal sources are persistent and one per peer cluster</li>  *<li> Old sources are recovered from a failed region server and our  * only goal is to finish replicating the WAL queue it had up in ZK</li>  *</ul>  *  * When a region server dies, this class uses a watcher to get notified and it  * tries to grab a lock in order to transfer all the queues in a local  * old source.  *  * This class implements the ReplicationListener interface so that it can track changes in  * replication state.  */
end_comment

begin_class
annotation|@
name|InterfaceAudience
operator|.
name|Private
specifier|public
class|class
name|ReplicationSourceManager
implements|implements
name|ReplicationListener
block|{
specifier|private
specifier|static
specifier|final
name|Logger
name|LOG
init|=
name|LoggerFactory
operator|.
name|getLogger
argument_list|(
name|ReplicationSourceManager
operator|.
name|class
argument_list|)
decl_stmt|;
comment|// List of all the sources that read this RS's logs
specifier|private
specifier|final
name|List
argument_list|<
name|ReplicationSourceInterface
argument_list|>
name|sources
decl_stmt|;
comment|// List of all the sources we got from died RSs
specifier|private
specifier|final
name|List
argument_list|<
name|ReplicationSourceInterface
argument_list|>
name|oldsources
decl_stmt|;
specifier|private
specifier|final
name|ReplicationQueueStorage
name|queueStorage
decl_stmt|;
specifier|private
specifier|final
name|ReplicationTracker
name|replicationTracker
decl_stmt|;
specifier|private
specifier|final
name|ReplicationPeers
name|replicationPeers
decl_stmt|;
comment|// UUID for this cluster
specifier|private
specifier|final
name|UUID
name|clusterId
decl_stmt|;
comment|// All about stopping
specifier|private
specifier|final
name|Server
name|server
decl_stmt|;
comment|// All logs we are currently tracking
comment|// Index structure of the map is: peer_id->logPrefix/logGroup->logs
specifier|private
specifier|final
name|Map
argument_list|<
name|String
argument_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|SortedSet
argument_list|<
name|String
argument_list|>
argument_list|>
argument_list|>
name|walsById
decl_stmt|;
comment|// Logs for recovered sources we are currently tracking
specifier|private
specifier|final
name|Map
argument_list|<
name|String
argument_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|SortedSet
argument_list|<
name|String
argument_list|>
argument_list|>
argument_list|>
name|walsByIdRecoveredQueues
decl_stmt|;
specifier|private
specifier|final
name|Configuration
name|conf
decl_stmt|;
specifier|private
specifier|final
name|FileSystem
name|fs
decl_stmt|;
comment|// The paths to the latest log of each wal group, for new coming peers
specifier|private
name|Set
argument_list|<
name|Path
argument_list|>
name|latestPaths
decl_stmt|;
comment|// Path to the wals directories
specifier|private
specifier|final
name|Path
name|logDir
decl_stmt|;
comment|// Path to the wal archive
specifier|private
specifier|final
name|Path
name|oldLogDir
decl_stmt|;
specifier|private
specifier|final
name|WALFileLengthProvider
name|walFileLengthProvider
decl_stmt|;
comment|// The number of ms that we wait before moving znodes, HBASE-3596
specifier|private
specifier|final
name|long
name|sleepBeforeFailover
decl_stmt|;
comment|// Homemade executer service for replication
specifier|private
specifier|final
name|ThreadPoolExecutor
name|executor
decl_stmt|;
specifier|private
specifier|final
name|boolean
name|replicationForBulkLoadDataEnabled
decl_stmt|;
specifier|private
name|Connection
name|connection
decl_stmt|;
specifier|private
name|long
name|replicationWaitTime
decl_stmt|;
specifier|private
name|AtomicLong
name|totalBufferUsed
init|=
operator|new
name|AtomicLong
argument_list|()
decl_stmt|;
comment|/**    * Creates a replication manager and sets the watch on all the other registered region servers    * @param queueStorage the interface for manipulating replication queues    * @param replicationPeers    * @param replicationTracker    * @param conf the configuration to use    * @param server the server for this region server    * @param fs the file system to use    * @param logDir the directory that contains all wal directories of live RSs    * @param oldLogDir the directory where old logs are archived    * @param clusterId    */
specifier|public
name|ReplicationSourceManager
parameter_list|(
name|ReplicationQueueStorage
name|queueStorage
parameter_list|,
name|ReplicationPeers
name|replicationPeers
parameter_list|,
name|ReplicationTracker
name|replicationTracker
parameter_list|,
name|Configuration
name|conf
parameter_list|,
name|Server
name|server
parameter_list|,
name|FileSystem
name|fs
parameter_list|,
name|Path
name|logDir
parameter_list|,
name|Path
name|oldLogDir
parameter_list|,
name|UUID
name|clusterId
parameter_list|,
name|WALFileLengthProvider
name|walFileLengthProvider
parameter_list|)
throws|throws
name|IOException
block|{
comment|//CopyOnWriteArrayList is thread-safe.
comment|//Generally, reading is more than modifying.
name|this
operator|.
name|sources
operator|=
operator|new
name|CopyOnWriteArrayList
argument_list|<>
argument_list|()
expr_stmt|;
name|this
operator|.
name|queueStorage
operator|=
name|queueStorage
expr_stmt|;
name|this
operator|.
name|replicationPeers
operator|=
name|replicationPeers
expr_stmt|;
name|this
operator|.
name|replicationTracker
operator|=
name|replicationTracker
expr_stmt|;
name|this
operator|.
name|server
operator|=
name|server
expr_stmt|;
name|this
operator|.
name|walsById
operator|=
operator|new
name|HashMap
argument_list|<>
argument_list|()
expr_stmt|;
name|this
operator|.
name|walsByIdRecoveredQueues
operator|=
operator|new
name|ConcurrentHashMap
argument_list|<>
argument_list|()
expr_stmt|;
name|this
operator|.
name|oldsources
operator|=
operator|new
name|CopyOnWriteArrayList
argument_list|<>
argument_list|()
expr_stmt|;
name|this
operator|.
name|conf
operator|=
name|conf
expr_stmt|;
name|this
operator|.
name|fs
operator|=
name|fs
expr_stmt|;
name|this
operator|.
name|logDir
operator|=
name|logDir
expr_stmt|;
name|this
operator|.
name|oldLogDir
operator|=
name|oldLogDir
expr_stmt|;
name|this
operator|.
name|sleepBeforeFailover
operator|=
name|conf
operator|.
name|getLong
argument_list|(
literal|"replication.sleep.before.failover"
argument_list|,
literal|30000
argument_list|)
expr_stmt|;
comment|// 30 seconds
name|this
operator|.
name|clusterId
operator|=
name|clusterId
expr_stmt|;
name|this
operator|.
name|walFileLengthProvider
operator|=
name|walFileLengthProvider
expr_stmt|;
name|this
operator|.
name|replicationTracker
operator|.
name|registerListener
argument_list|(
name|this
argument_list|)
expr_stmt|;
comment|// It's preferable to failover 1 RS at a time, but with good zk servers
comment|// more could be processed at the same time.
name|int
name|nbWorkers
init|=
name|conf
operator|.
name|getInt
argument_list|(
literal|"replication.executor.workers"
argument_list|,
literal|1
argument_list|)
decl_stmt|;
comment|// use a short 100ms sleep since this could be done inline with a RS startup
comment|// even if we fail, other region servers can take care of it
name|this
operator|.
name|executor
operator|=
operator|new
name|ThreadPoolExecutor
argument_list|(
name|nbWorkers
argument_list|,
name|nbWorkers
argument_list|,
literal|100
argument_list|,
name|TimeUnit
operator|.
name|MILLISECONDS
argument_list|,
operator|new
name|LinkedBlockingQueue
argument_list|<>
argument_list|()
argument_list|)
expr_stmt|;
name|ThreadFactoryBuilder
name|tfb
init|=
operator|new
name|ThreadFactoryBuilder
argument_list|()
decl_stmt|;
name|tfb
operator|.
name|setNameFormat
argument_list|(
literal|"ReplicationExecutor-%d"
argument_list|)
expr_stmt|;
name|tfb
operator|.
name|setDaemon
argument_list|(
literal|true
argument_list|)
expr_stmt|;
name|this
operator|.
name|executor
operator|.
name|setThreadFactory
argument_list|(
name|tfb
operator|.
name|build
argument_list|()
argument_list|)
expr_stmt|;
name|this
operator|.
name|latestPaths
operator|=
operator|new
name|HashSet
argument_list|<
name|Path
argument_list|>
argument_list|()
expr_stmt|;
name|replicationForBulkLoadDataEnabled
operator|=
name|conf
operator|.
name|getBoolean
argument_list|(
name|HConstants
operator|.
name|REPLICATION_BULKLOAD_ENABLE_KEY
argument_list|,
name|HConstants
operator|.
name|REPLICATION_BULKLOAD_ENABLE_DEFAULT
argument_list|)
expr_stmt|;
name|this
operator|.
name|replicationWaitTime
operator|=
name|conf
operator|.
name|getLong
argument_list|(
name|HConstants
operator|.
name|REPLICATION_SERIALLY_WAITING_KEY
argument_list|,
name|HConstants
operator|.
name|REPLICATION_SERIALLY_WAITING_DEFAULT
argument_list|)
expr_stmt|;
name|connection
operator|=
name|ConnectionFactory
operator|.
name|createConnection
argument_list|(
name|conf
argument_list|)
expr_stmt|;
block|}
annotation|@
name|FunctionalInterface
specifier|private
interface|interface
name|ReplicationQueueOperation
block|{
name|void
name|exec
parameter_list|()
throws|throws
name|ReplicationException
function_decl|;
block|}
specifier|private
name|void
name|abortWhenFail
parameter_list|(
name|ReplicationQueueOperation
name|op
parameter_list|)
block|{
try|try
block|{
name|op
operator|.
name|exec
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|ReplicationException
name|e
parameter_list|)
block|{
name|server
operator|.
name|abort
argument_list|(
literal|"Failed to operate on replication queue"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Provide the id of the peer and a log key and this method will figure which    * wal it belongs to and will log, for this region server, the current    * position. It will also clean old logs from the queue.    * @param log Path to the log currently being replicated from    * replication status in zookeeper. It will also delete older entries.    * @param id id of the peer cluster    * @param position current location in the log    * @param queueRecovered indicates if this queue comes from another region server    * @param holdLogInZK if true then the log is retained in ZK    */
specifier|public
name|void
name|logPositionAndCleanOldLogs
parameter_list|(
name|Path
name|log
parameter_list|,
name|String
name|id
parameter_list|,
name|long
name|position
parameter_list|,
name|boolean
name|queueRecovered
parameter_list|,
name|boolean
name|holdLogInZK
parameter_list|)
block|{
name|String
name|fileName
init|=
name|log
operator|.
name|getName
argument_list|()
decl_stmt|;
name|abortWhenFail
argument_list|(
parameter_list|()
lambda|->
name|this
operator|.
name|queueStorage
operator|.
name|setWALPosition
argument_list|(
name|server
operator|.
name|getServerName
argument_list|()
argument_list|,
name|id
argument_list|,
name|fileName
argument_list|,
name|position
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|holdLogInZK
condition|)
block|{
return|return;
block|}
name|cleanOldLogs
argument_list|(
name|fileName
argument_list|,
name|id
argument_list|,
name|queueRecovered
argument_list|)
expr_stmt|;
block|}
comment|/**    * Cleans a log file and all older files from ZK. Called when we are sure that a    * log file is closed and has no more entries.    * @param key Path to the log    * @param id id of the peer cluster    * @param queueRecovered Whether this is a recovered queue    */
specifier|public
name|void
name|cleanOldLogs
parameter_list|(
name|String
name|key
parameter_list|,
name|String
name|id
parameter_list|,
name|boolean
name|queueRecovered
parameter_list|)
block|{
name|String
name|logPrefix
init|=
name|AbstractFSWALProvider
operator|.
name|getWALPrefixFromWALName
argument_list|(
name|key
argument_list|)
decl_stmt|;
if|if
condition|(
name|queueRecovered
condition|)
block|{
name|SortedSet
argument_list|<
name|String
argument_list|>
name|wals
init|=
name|walsByIdRecoveredQueues
operator|.
name|get
argument_list|(
name|id
argument_list|)
operator|.
name|get
argument_list|(
name|logPrefix
argument_list|)
decl_stmt|;
if|if
condition|(
name|wals
operator|!=
literal|null
operator|&&
operator|!
name|wals
operator|.
name|first
argument_list|()
operator|.
name|equals
argument_list|(
name|key
argument_list|)
condition|)
block|{
name|cleanOldLogs
argument_list|(
name|wals
argument_list|,
name|key
argument_list|,
name|id
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
synchronized|synchronized
init|(
name|this
operator|.
name|walsById
init|)
block|{
name|SortedSet
argument_list|<
name|String
argument_list|>
name|wals
init|=
name|walsById
operator|.
name|get
argument_list|(
name|id
argument_list|)
operator|.
name|get
argument_list|(
name|logPrefix
argument_list|)
decl_stmt|;
if|if
condition|(
name|wals
operator|!=
literal|null
operator|&&
operator|!
name|wals
operator|.
name|first
argument_list|()
operator|.
name|equals
argument_list|(
name|key
argument_list|)
condition|)
block|{
name|cleanOldLogs
argument_list|(
name|wals
argument_list|,
name|key
argument_list|,
name|id
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
specifier|private
name|void
name|cleanOldLogs
parameter_list|(
name|SortedSet
argument_list|<
name|String
argument_list|>
name|wals
parameter_list|,
name|String
name|key
parameter_list|,
name|String
name|id
parameter_list|)
block|{
name|SortedSet
argument_list|<
name|String
argument_list|>
name|walSet
init|=
name|wals
operator|.
name|headSet
argument_list|(
name|key
argument_list|)
decl_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Removing "
operator|+
name|walSet
operator|.
name|size
argument_list|()
operator|+
literal|" logs in the list: "
operator|+
name|walSet
argument_list|)
expr_stmt|;
block|}
for|for
control|(
name|String
name|wal
range|:
name|walSet
control|)
block|{
name|abortWhenFail
argument_list|(
parameter_list|()
lambda|->
name|this
operator|.
name|queueStorage
operator|.
name|removeWAL
argument_list|(
name|server
operator|.
name|getServerName
argument_list|()
argument_list|,
name|id
argument_list|,
name|wal
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|walSet
operator|.
name|clear
argument_list|()
expr_stmt|;
block|}
specifier|private
name|void
name|adoptAbandonedQueues
parameter_list|()
block|{
name|List
argument_list|<
name|ServerName
argument_list|>
name|currentReplicators
init|=
literal|null
decl_stmt|;
try|try
block|{
name|currentReplicators
operator|=
name|queueStorage
operator|.
name|getListOfReplicators
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|ReplicationException
name|e
parameter_list|)
block|{
name|server
operator|.
name|abort
argument_list|(
literal|"Failed to get all replicators"
argument_list|,
name|e
argument_list|)
expr_stmt|;
return|return;
block|}
if|if
condition|(
name|currentReplicators
operator|==
literal|null
operator|||
name|currentReplicators
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
return|return;
block|}
name|List
argument_list|<
name|ServerName
argument_list|>
name|otherRegionServers
init|=
name|replicationTracker
operator|.
name|getListOfRegionServers
argument_list|()
operator|.
name|stream
argument_list|()
operator|.
name|map
argument_list|(
name|ServerName
operator|::
name|valueOf
argument_list|)
operator|.
name|collect
argument_list|(
name|Collectors
operator|.
name|toList
argument_list|()
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Current list of replicators: "
operator|+
name|currentReplicators
operator|+
literal|" other RSs: "
operator|+
name|otherRegionServers
argument_list|)
expr_stmt|;
comment|// Look if there's anything to process after a restart
for|for
control|(
name|ServerName
name|rs
range|:
name|currentReplicators
control|)
block|{
if|if
condition|(
operator|!
name|otherRegionServers
operator|.
name|contains
argument_list|(
name|rs
argument_list|)
condition|)
block|{
name|transferQueues
argument_list|(
name|rs
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|/**    * Adds a normal source per registered peer cluster and tries to process all old region server wal    * queues    *<p>    * The returned future is for adoptAbandonedQueues task.    */
name|Future
argument_list|<
name|?
argument_list|>
name|init
parameter_list|()
throws|throws
name|IOException
throws|,
name|ReplicationException
block|{
for|for
control|(
name|String
name|id
range|:
name|this
operator|.
name|replicationPeers
operator|.
name|getAllPeerIds
argument_list|()
control|)
block|{
name|addSource
argument_list|(
name|id
argument_list|)
expr_stmt|;
if|if
condition|(
name|replicationForBulkLoadDataEnabled
condition|)
block|{
comment|// Check if peer exists in hfile-refs queue, if not add it. This can happen in the case
comment|// when a peer was added before replication for bulk loaded data was enabled.
name|this
operator|.
name|queueStorage
operator|.
name|addPeerToHFileRefs
argument_list|(
name|id
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|this
operator|.
name|executor
operator|.
name|submit
argument_list|(
name|this
operator|::
name|adoptAbandonedQueues
argument_list|)
return|;
block|}
comment|/**    * Add sources for the given peer cluster on this region server. For the newly added peer, we only    * need to enqueue the latest log of each wal group and do replication    * @param id the id of the peer cluster    * @return the source that was created    */
annotation|@
name|VisibleForTesting
name|ReplicationSourceInterface
name|addSource
parameter_list|(
name|String
name|id
parameter_list|)
throws|throws
name|IOException
throws|,
name|ReplicationException
block|{
name|ReplicationPeerConfig
name|peerConfig
init|=
name|replicationPeers
operator|.
name|getPeerConfig
argument_list|(
name|id
argument_list|)
decl_stmt|;
name|ReplicationPeer
name|peer
init|=
name|replicationPeers
operator|.
name|getPeer
argument_list|(
name|id
argument_list|)
decl_stmt|;
name|ReplicationSourceInterface
name|src
init|=
name|getReplicationSource
argument_list|(
name|id
argument_list|,
name|peerConfig
argument_list|,
name|peer
argument_list|)
decl_stmt|;
synchronized|synchronized
init|(
name|this
operator|.
name|walsById
init|)
block|{
name|this
operator|.
name|sources
operator|.
name|add
argument_list|(
name|src
argument_list|)
expr_stmt|;
name|Map
argument_list|<
name|String
argument_list|,
name|SortedSet
argument_list|<
name|String
argument_list|>
argument_list|>
name|walsByGroup
init|=
operator|new
name|HashMap
argument_list|<>
argument_list|()
decl_stmt|;
name|this
operator|.
name|walsById
operator|.
name|put
argument_list|(
name|id
argument_list|,
name|walsByGroup
argument_list|)
expr_stmt|;
comment|// Add the latest wal to that source's queue
synchronized|synchronized
init|(
name|latestPaths
init|)
block|{
if|if
condition|(
name|this
operator|.
name|latestPaths
operator|.
name|size
argument_list|()
operator|>
literal|0
condition|)
block|{
for|for
control|(
name|Path
name|logPath
range|:
name|latestPaths
control|)
block|{
name|String
name|name
init|=
name|logPath
operator|.
name|getName
argument_list|()
decl_stmt|;
name|String
name|walPrefix
init|=
name|AbstractFSWALProvider
operator|.
name|getWALPrefixFromWALName
argument_list|(
name|name
argument_list|)
decl_stmt|;
name|SortedSet
argument_list|<
name|String
argument_list|>
name|logs
init|=
operator|new
name|TreeSet
argument_list|<>
argument_list|()
decl_stmt|;
name|logs
operator|.
name|add
argument_list|(
name|name
argument_list|)
expr_stmt|;
name|walsByGroup
operator|.
name|put
argument_list|(
name|walPrefix
argument_list|,
name|logs
argument_list|)
expr_stmt|;
try|try
block|{
name|this
operator|.
name|queueStorage
operator|.
name|addWAL
argument_list|(
name|server
operator|.
name|getServerName
argument_list|()
argument_list|,
name|id
argument_list|,
name|name
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|ReplicationException
name|e
parameter_list|)
block|{
name|String
name|message
init|=
literal|"Cannot add log to queue when creating a new source, queueId="
operator|+
name|id
operator|+
literal|", filename="
operator|+
name|name
decl_stmt|;
name|server
operator|.
name|stop
argument_list|(
name|message
argument_list|)
expr_stmt|;
throw|throw
name|e
throw|;
block|}
name|src
operator|.
name|enqueueLog
argument_list|(
name|logPath
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
name|src
operator|.
name|startup
argument_list|()
expr_stmt|;
return|return
name|src
return|;
block|}
annotation|@
name|VisibleForTesting
name|int
name|getSizeOfLatestPath
parameter_list|()
block|{
synchronized|synchronized
init|(
name|latestPaths
init|)
block|{
return|return
name|latestPaths
operator|.
name|size
argument_list|()
return|;
block|}
block|}
comment|/**    * Delete a complete queue of wals associated with a peer cluster    * @param peerId Id of the peer cluster queue of wals to delete    */
specifier|public
name|void
name|deleteSource
parameter_list|(
name|String
name|peerId
parameter_list|,
name|boolean
name|closeConnection
parameter_list|)
block|{
name|abortWhenFail
argument_list|(
parameter_list|()
lambda|->
name|this
operator|.
name|queueStorage
operator|.
name|removeQueue
argument_list|(
name|server
operator|.
name|getServerName
argument_list|()
argument_list|,
name|peerId
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|closeConnection
condition|)
block|{
name|this
operator|.
name|replicationPeers
operator|.
name|removePeer
argument_list|(
name|peerId
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Terminate the replication on this region server    */
specifier|public
name|void
name|join
parameter_list|()
block|{
name|this
operator|.
name|executor
operator|.
name|shutdown
argument_list|()
expr_stmt|;
for|for
control|(
name|ReplicationSourceInterface
name|source
range|:
name|this
operator|.
name|sources
control|)
block|{
name|source
operator|.
name|terminate
argument_list|(
literal|"Region server is closing"
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Get a copy of the wals of the first source on this rs    * @return a sorted set of wal names    */
annotation|@
name|VisibleForTesting
name|Map
argument_list|<
name|String
argument_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|SortedSet
argument_list|<
name|String
argument_list|>
argument_list|>
argument_list|>
name|getWALs
parameter_list|()
block|{
return|return
name|Collections
operator|.
name|unmodifiableMap
argument_list|(
name|walsById
argument_list|)
return|;
block|}
comment|/**    * Get a copy of the wals of the recovered sources on this rs    * @return a sorted set of wal names    */
annotation|@
name|VisibleForTesting
name|Map
argument_list|<
name|String
argument_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|SortedSet
argument_list|<
name|String
argument_list|>
argument_list|>
argument_list|>
name|getWalsByIdRecoveredQueues
parameter_list|()
block|{
return|return
name|Collections
operator|.
name|unmodifiableMap
argument_list|(
name|walsByIdRecoveredQueues
argument_list|)
return|;
block|}
comment|/**    * Get a list of all the normal sources of this rs    * @return lis of all sources    */
specifier|public
name|List
argument_list|<
name|ReplicationSourceInterface
argument_list|>
name|getSources
parameter_list|()
block|{
return|return
name|this
operator|.
name|sources
return|;
block|}
comment|/**    * Get a list of all the old sources of this rs    * @return list of all old sources    */
specifier|public
name|List
argument_list|<
name|ReplicationSourceInterface
argument_list|>
name|getOldSources
parameter_list|()
block|{
return|return
name|this
operator|.
name|oldsources
return|;
block|}
comment|/**    * Get the normal source for a given peer    * @param peerId    * @return the normal source for the give peer if it exists, otherwise null.    */
specifier|public
name|ReplicationSourceInterface
name|getSource
parameter_list|(
name|String
name|peerId
parameter_list|)
block|{
return|return
name|getSources
argument_list|()
operator|.
name|stream
argument_list|()
operator|.
name|filter
argument_list|(
name|s
lambda|->
name|s
operator|.
name|getPeerId
argument_list|()
operator|.
name|equals
argument_list|(
name|peerId
argument_list|)
argument_list|)
operator|.
name|findFirst
argument_list|()
operator|.
name|orElse
argument_list|(
literal|null
argument_list|)
return|;
block|}
annotation|@
name|VisibleForTesting
name|List
argument_list|<
name|String
argument_list|>
name|getAllQueues
parameter_list|()
throws|throws
name|ReplicationException
block|{
return|return
name|queueStorage
operator|.
name|getAllQueues
argument_list|(
name|server
operator|.
name|getServerName
argument_list|()
argument_list|)
return|;
block|}
name|void
name|preLogRoll
parameter_list|(
name|Path
name|newLog
parameter_list|)
throws|throws
name|IOException
block|{
name|recordLog
argument_list|(
name|newLog
argument_list|)
expr_stmt|;
name|String
name|logName
init|=
name|newLog
operator|.
name|getName
argument_list|()
decl_stmt|;
name|String
name|logPrefix
init|=
name|AbstractFSWALProvider
operator|.
name|getWALPrefixFromWALName
argument_list|(
name|logName
argument_list|)
decl_stmt|;
synchronized|synchronized
init|(
name|latestPaths
init|)
block|{
name|Iterator
argument_list|<
name|Path
argument_list|>
name|iterator
init|=
name|latestPaths
operator|.
name|iterator
argument_list|()
decl_stmt|;
while|while
condition|(
name|iterator
operator|.
name|hasNext
argument_list|()
condition|)
block|{
name|Path
name|path
init|=
name|iterator
operator|.
name|next
argument_list|()
decl_stmt|;
if|if
condition|(
name|path
operator|.
name|getName
argument_list|()
operator|.
name|contains
argument_list|(
name|logPrefix
argument_list|)
condition|)
block|{
name|iterator
operator|.
name|remove
argument_list|()
expr_stmt|;
break|break;
block|}
block|}
name|this
operator|.
name|latestPaths
operator|.
name|add
argument_list|(
name|newLog
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Check and enqueue the given log to the correct source. If there's still no source for the    * group to which the given log belongs, create one    * @param logPath the log path to check and enqueue    * @throws IOException    */
specifier|private
name|void
name|recordLog
parameter_list|(
name|Path
name|logPath
parameter_list|)
throws|throws
name|IOException
block|{
name|String
name|logName
init|=
name|logPath
operator|.
name|getName
argument_list|()
decl_stmt|;
name|String
name|logPrefix
init|=
name|AbstractFSWALProvider
operator|.
name|getWALPrefixFromWALName
argument_list|(
name|logName
argument_list|)
decl_stmt|;
comment|// update replication queues on ZK
comment|// synchronize on replicationPeers to avoid adding source for the to-be-removed peer
synchronized|synchronized
init|(
name|replicationPeers
init|)
block|{
for|for
control|(
name|String
name|id
range|:
name|replicationPeers
operator|.
name|getAllPeerIds
argument_list|()
control|)
block|{
try|try
block|{
name|this
operator|.
name|queueStorage
operator|.
name|addWAL
argument_list|(
name|server
operator|.
name|getServerName
argument_list|()
argument_list|,
name|id
argument_list|,
name|logName
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|ReplicationException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Cannot add log to replication queue"
operator|+
literal|" when creating a new source, queueId="
operator|+
name|id
operator|+
literal|", filename="
operator|+
name|logName
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
block|}
comment|// update walsById map
synchronized|synchronized
init|(
name|walsById
init|)
block|{
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|String
argument_list|,
name|Map
argument_list|<
name|String
argument_list|,
name|SortedSet
argument_list|<
name|String
argument_list|>
argument_list|>
argument_list|>
name|entry
range|:
name|this
operator|.
name|walsById
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|String
name|peerId
init|=
name|entry
operator|.
name|getKey
argument_list|()
decl_stmt|;
name|Map
argument_list|<
name|String
argument_list|,
name|SortedSet
argument_list|<
name|String
argument_list|>
argument_list|>
name|walsByPrefix
init|=
name|entry
operator|.
name|getValue
argument_list|()
decl_stmt|;
name|boolean
name|existingPrefix
init|=
literal|false
decl_stmt|;
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|String
argument_list|,
name|SortedSet
argument_list|<
name|String
argument_list|>
argument_list|>
name|walsEntry
range|:
name|walsByPrefix
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|SortedSet
argument_list|<
name|String
argument_list|>
name|wals
init|=
name|walsEntry
operator|.
name|getValue
argument_list|()
decl_stmt|;
if|if
condition|(
name|this
operator|.
name|sources
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
comment|// If there's no slaves, don't need to keep the old wals since
comment|// we only consider the last one when a new slave comes in
name|wals
operator|.
name|clear
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|logPrefix
operator|.
name|equals
argument_list|(
name|walsEntry
operator|.
name|getKey
argument_list|()
argument_list|)
condition|)
block|{
name|wals
operator|.
name|add
argument_list|(
name|logName
argument_list|)
expr_stmt|;
name|existingPrefix
operator|=
literal|true
expr_stmt|;
block|}
block|}
if|if
condition|(
operator|!
name|existingPrefix
condition|)
block|{
comment|// The new log belongs to a new group, add it into this peer
name|LOG
operator|.
name|debug
argument_list|(
literal|"Start tracking logs for wal group "
operator|+
name|logPrefix
operator|+
literal|" for peer "
operator|+
name|peerId
argument_list|)
expr_stmt|;
name|SortedSet
argument_list|<
name|String
argument_list|>
name|wals
init|=
operator|new
name|TreeSet
argument_list|<>
argument_list|()
decl_stmt|;
name|wals
operator|.
name|add
argument_list|(
name|logName
argument_list|)
expr_stmt|;
name|walsByPrefix
operator|.
name|put
argument_list|(
name|logPrefix
argument_list|,
name|wals
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
name|void
name|postLogRoll
parameter_list|(
name|Path
name|newLog
parameter_list|)
throws|throws
name|IOException
block|{
comment|// This only updates the sources we own, not the recovered ones
for|for
control|(
name|ReplicationSourceInterface
name|source
range|:
name|this
operator|.
name|sources
control|)
block|{
name|source
operator|.
name|enqueueLog
argument_list|(
name|newLog
argument_list|)
expr_stmt|;
block|}
block|}
annotation|@
name|VisibleForTesting
specifier|public
name|AtomicLong
name|getTotalBufferUsed
parameter_list|()
block|{
return|return
name|totalBufferUsed
return|;
block|}
comment|/**    * Factory method to create a replication source    * @param peerId the id of the peer cluster    * @return the created source    */
specifier|private
name|ReplicationSourceInterface
name|getReplicationSource
parameter_list|(
name|String
name|peerId
parameter_list|,
name|ReplicationPeerConfig
name|peerConfig
parameter_list|,
name|ReplicationPeer
name|replicationPeer
parameter_list|)
throws|throws
name|IOException
block|{
name|RegionServerCoprocessorHost
name|rsServerHost
init|=
literal|null
decl_stmt|;
name|TableDescriptors
name|tableDescriptors
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|server
operator|instanceof
name|HRegionServer
condition|)
block|{
name|rsServerHost
operator|=
operator|(
operator|(
name|HRegionServer
operator|)
name|server
operator|)
operator|.
name|getRegionServerCoprocessorHost
argument_list|()
expr_stmt|;
name|tableDescriptors
operator|=
operator|(
operator|(
name|HRegionServer
operator|)
name|server
operator|)
operator|.
name|getTableDescriptors
argument_list|()
expr_stmt|;
block|}
name|ReplicationSourceInterface
name|src
init|=
name|ReplicationSourceFactory
operator|.
name|create
argument_list|(
name|conf
argument_list|,
name|peerId
argument_list|)
decl_stmt|;
name|ReplicationEndpoint
name|replicationEndpoint
init|=
literal|null
decl_stmt|;
try|try
block|{
name|String
name|replicationEndpointImpl
init|=
name|peerConfig
operator|.
name|getReplicationEndpointImpl
argument_list|()
decl_stmt|;
if|if
condition|(
name|replicationEndpointImpl
operator|==
literal|null
condition|)
block|{
comment|// Default to HBase inter-cluster replication endpoint
name|replicationEndpointImpl
operator|=
name|HBaseInterClusterReplicationEndpoint
operator|.
name|class
operator|.
name|getName
argument_list|()
expr_stmt|;
block|}
name|replicationEndpoint
operator|=
name|Class
operator|.
name|forName
argument_list|(
name|replicationEndpointImpl
argument_list|)
operator|.
name|asSubclass
argument_list|(
name|ReplicationEndpoint
operator|.
name|class
argument_list|)
operator|.
name|newInstance
argument_list|()
expr_stmt|;
if|if
condition|(
name|rsServerHost
operator|!=
literal|null
condition|)
block|{
name|ReplicationEndpoint
name|newReplicationEndPoint
init|=
name|rsServerHost
operator|.
name|postCreateReplicationEndPoint
argument_list|(
name|replicationEndpoint
argument_list|)
decl_stmt|;
if|if
condition|(
name|newReplicationEndPoint
operator|!=
literal|null
condition|)
block|{
comment|// Override the newly created endpoint from the hook with configured end point
name|replicationEndpoint
operator|=
name|newReplicationEndPoint
expr_stmt|;
block|}
block|}
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Passed replication endpoint implementation throws errors"
operator|+
literal|" while initializing ReplicationSource for peer: "
operator|+
name|peerId
argument_list|,
name|e
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|IOException
argument_list|(
name|e
argument_list|)
throw|;
block|}
name|MetricsSource
name|metrics
init|=
operator|new
name|MetricsSource
argument_list|(
name|peerId
argument_list|)
decl_stmt|;
comment|// init replication source
name|src
operator|.
name|init
argument_list|(
name|conf
argument_list|,
name|fs
argument_list|,
name|this
argument_list|,
name|queueStorage
argument_list|,
name|replicationPeers
argument_list|,
name|server
argument_list|,
name|peerId
argument_list|,
name|clusterId
argument_list|,
name|replicationEndpoint
argument_list|,
name|walFileLengthProvider
argument_list|,
name|metrics
argument_list|)
expr_stmt|;
comment|// init replication endpoint
name|replicationEndpoint
operator|.
name|init
argument_list|(
operator|new
name|ReplicationEndpoint
operator|.
name|Context
argument_list|(
name|conf
argument_list|,
name|replicationPeer
operator|.
name|getConfiguration
argument_list|()
argument_list|,
name|fs
argument_list|,
name|peerId
argument_list|,
name|clusterId
argument_list|,
name|replicationPeer
argument_list|,
name|metrics
argument_list|,
name|tableDescriptors
argument_list|,
name|server
argument_list|)
argument_list|)
expr_stmt|;
return|return
name|src
return|;
block|}
comment|/**    * Transfer all the queues of the specified to this region server. First it tries to grab a lock    * and if it works it will move the znodes and finally will delete the old znodes.    *<p>    * It creates one old source for any type of source of the old rs.    */
specifier|private
name|void
name|transferQueues
parameter_list|(
name|ServerName
name|deadRS
parameter_list|)
block|{
if|if
condition|(
name|server
operator|.
name|getServerName
argument_list|()
operator|.
name|equals
argument_list|(
name|deadRS
argument_list|)
condition|)
block|{
comment|// it's just us, give up
return|return;
block|}
name|NodeFailoverWorker
name|transfer
init|=
operator|new
name|NodeFailoverWorker
argument_list|(
name|deadRS
argument_list|)
decl_stmt|;
try|try
block|{
name|this
operator|.
name|executor
operator|.
name|execute
argument_list|(
name|transfer
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|RejectedExecutionException
name|ex
parameter_list|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Cancelling the transfer of "
operator|+
name|deadRS
operator|+
literal|" because of "
operator|+
name|ex
operator|.
name|getMessage
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Clear the references to the specified old source    * @param src source to clear    */
specifier|public
name|void
name|closeRecoveredQueue
parameter_list|(
name|ReplicationSourceInterface
name|src
parameter_list|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Done with the recovered queue "
operator|+
name|src
operator|.
name|getPeerClusterZnode
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|src
operator|instanceof
name|ReplicationSource
condition|)
block|{
operator|(
operator|(
name|ReplicationSource
operator|)
name|src
operator|)
operator|.
name|getSourceMetrics
argument_list|()
operator|.
name|clear
argument_list|()
expr_stmt|;
block|}
name|this
operator|.
name|oldsources
operator|.
name|remove
argument_list|(
name|src
argument_list|)
expr_stmt|;
name|deleteSource
argument_list|(
name|src
operator|.
name|getPeerClusterZnode
argument_list|()
argument_list|,
literal|false
argument_list|)
expr_stmt|;
name|this
operator|.
name|walsByIdRecoveredQueues
operator|.
name|remove
argument_list|(
name|src
operator|.
name|getPeerClusterZnode
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|/**    * Clear the references to the specified old source    * @param src source to clear    */
specifier|public
name|void
name|closeQueue
parameter_list|(
name|ReplicationSourceInterface
name|src
parameter_list|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Done with the queue "
operator|+
name|src
operator|.
name|getPeerClusterZnode
argument_list|()
argument_list|)
expr_stmt|;
name|src
operator|.
name|getSourceMetrics
argument_list|()
operator|.
name|clear
argument_list|()
expr_stmt|;
name|this
operator|.
name|sources
operator|.
name|remove
argument_list|(
name|src
argument_list|)
expr_stmt|;
name|deleteSource
argument_list|(
name|src
operator|.
name|getPeerClusterZnode
argument_list|()
argument_list|,
literal|true
argument_list|)
expr_stmt|;
name|this
operator|.
name|walsById
operator|.
name|remove
argument_list|(
name|src
operator|.
name|getPeerClusterZnode
argument_list|()
argument_list|)
expr_stmt|;
block|}
specifier|public
name|void
name|addPeer
parameter_list|(
name|String
name|id
parameter_list|)
throws|throws
name|ReplicationException
throws|,
name|IOException
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Trying to add peer, peerId: "
operator|+
name|id
argument_list|)
expr_stmt|;
name|boolean
name|added
init|=
name|this
operator|.
name|replicationPeers
operator|.
name|addPeer
argument_list|(
name|id
argument_list|)
decl_stmt|;
if|if
condition|(
name|added
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Peer "
operator|+
name|id
operator|+
literal|" connected success, trying to start the replication source thread."
argument_list|)
expr_stmt|;
name|addSource
argument_list|(
name|id
argument_list|)
expr_stmt|;
if|if
condition|(
name|replicationForBulkLoadDataEnabled
condition|)
block|{
name|this
operator|.
name|queueStorage
operator|.
name|addPeerToHFileRefs
argument_list|(
name|id
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|/**    * Thie method first deletes all the recovered sources for the specified    * id, then deletes the normal source (deleting all related data in ZK).    * @param id The id of the peer cluster    */
specifier|public
name|void
name|removePeer
parameter_list|(
name|String
name|id
parameter_list|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Closing the following queue "
operator|+
name|id
operator|+
literal|", currently have "
operator|+
name|sources
operator|.
name|size
argument_list|()
operator|+
literal|" and another "
operator|+
name|oldsources
operator|.
name|size
argument_list|()
operator|+
literal|" that were recovered"
argument_list|)
expr_stmt|;
name|String
name|terminateMessage
init|=
literal|"Replication stream was removed by a user"
decl_stmt|;
name|List
argument_list|<
name|ReplicationSourceInterface
argument_list|>
name|oldSourcesToDelete
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
comment|// synchronized on oldsources to avoid adding recovered source for the to-be-removed peer
comment|// see NodeFailoverWorker.run
synchronized|synchronized
init|(
name|oldsources
init|)
block|{
comment|// First close all the recovered sources for this peer
for|for
control|(
name|ReplicationSourceInterface
name|src
range|:
name|oldsources
control|)
block|{
if|if
condition|(
name|id
operator|.
name|equals
argument_list|(
name|src
operator|.
name|getPeerId
argument_list|()
argument_list|)
condition|)
block|{
name|oldSourcesToDelete
operator|.
name|add
argument_list|(
name|src
argument_list|)
expr_stmt|;
block|}
block|}
for|for
control|(
name|ReplicationSourceInterface
name|src
range|:
name|oldSourcesToDelete
control|)
block|{
name|src
operator|.
name|terminate
argument_list|(
name|terminateMessage
argument_list|)
expr_stmt|;
name|closeRecoveredQueue
argument_list|(
name|src
argument_list|)
expr_stmt|;
block|}
block|}
name|LOG
operator|.
name|info
argument_list|(
literal|"Number of deleted recovered sources for "
operator|+
name|id
operator|+
literal|": "
operator|+
name|oldSourcesToDelete
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
comment|// Now look for the one on this cluster
name|List
argument_list|<
name|ReplicationSourceInterface
argument_list|>
name|srcToRemove
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
comment|// synchronize on replicationPeers to avoid adding source for the to-be-removed peer
synchronized|synchronized
init|(
name|this
operator|.
name|replicationPeers
init|)
block|{
for|for
control|(
name|ReplicationSourceInterface
name|src
range|:
name|this
operator|.
name|sources
control|)
block|{
if|if
condition|(
name|id
operator|.
name|equals
argument_list|(
name|src
operator|.
name|getPeerId
argument_list|()
argument_list|)
condition|)
block|{
name|srcToRemove
operator|.
name|add
argument_list|(
name|src
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|srcToRemove
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"The peer we wanted to remove is missing a ReplicationSourceInterface. "
operator|+
literal|"This could mean that ReplicationSourceInterface initialization failed for this peer "
operator|+
literal|"and that replication on this peer may not be caught up. peerId="
operator|+
name|id
argument_list|)
expr_stmt|;
block|}
for|for
control|(
name|ReplicationSourceInterface
name|toRemove
range|:
name|srcToRemove
control|)
block|{
name|toRemove
operator|.
name|terminate
argument_list|(
name|terminateMessage
argument_list|)
expr_stmt|;
name|closeQueue
argument_list|(
name|toRemove
argument_list|)
expr_stmt|;
block|}
name|deleteSource
argument_list|(
name|id
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
comment|// Remove HFile Refs znode from zookeeper
name|abortWhenFail
argument_list|(
parameter_list|()
lambda|->
name|this
operator|.
name|queueStorage
operator|.
name|removePeerFromHFileRefs
argument_list|(
name|id
argument_list|)
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|regionServerRemoved
parameter_list|(
name|String
name|regionserver
parameter_list|)
block|{
name|transferQueues
argument_list|(
name|ServerName
operator|.
name|valueOf
argument_list|(
name|regionserver
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|/**    * Class responsible to setup new ReplicationSources to take care of the    * queues from dead region servers.    */
class|class
name|NodeFailoverWorker
extends|extends
name|Thread
block|{
specifier|private
specifier|final
name|ServerName
name|deadRS
decl_stmt|;
annotation|@
name|VisibleForTesting
specifier|public
name|NodeFailoverWorker
parameter_list|(
name|ServerName
name|deadRS
parameter_list|)
block|{
name|super
argument_list|(
literal|"Failover-for-"
operator|+
name|deadRS
argument_list|)
expr_stmt|;
name|this
operator|.
name|deadRS
operator|=
name|deadRS
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|run
parameter_list|()
block|{
comment|// Wait a bit before transferring the queues, we may be shutting down.
comment|// This sleep may not be enough in some cases.
try|try
block|{
name|Thread
operator|.
name|sleep
argument_list|(
name|sleepBeforeFailover
operator|+
call|(
name|long
call|)
argument_list|(
name|ThreadLocalRandom
operator|.
name|current
argument_list|()
operator|.
name|nextFloat
argument_list|()
operator|*
name|sleepBeforeFailover
argument_list|)
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Interrupted while waiting before transferring a queue."
argument_list|)
expr_stmt|;
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|interrupt
argument_list|()
expr_stmt|;
block|}
comment|// We try to lock that rs' queue directory
if|if
condition|(
name|server
operator|.
name|isStopped
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Not transferring queue since we are shutting down"
argument_list|)
expr_stmt|;
return|return;
block|}
name|Map
argument_list|<
name|String
argument_list|,
name|Set
argument_list|<
name|String
argument_list|>
argument_list|>
name|newQueues
init|=
operator|new
name|HashMap
argument_list|<>
argument_list|()
decl_stmt|;
try|try
block|{
name|List
argument_list|<
name|String
argument_list|>
name|peers
init|=
name|queueStorage
operator|.
name|getAllQueues
argument_list|(
name|deadRS
argument_list|)
decl_stmt|;
while|while
condition|(
operator|!
name|peers
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|Pair
argument_list|<
name|String
argument_list|,
name|SortedSet
argument_list|<
name|String
argument_list|>
argument_list|>
name|peer
init|=
name|queueStorage
operator|.
name|claimQueue
argument_list|(
name|deadRS
argument_list|,
name|peers
operator|.
name|get
argument_list|(
name|ThreadLocalRandom
operator|.
name|current
argument_list|()
operator|.
name|nextInt
argument_list|(
name|peers
operator|.
name|size
argument_list|()
argument_list|)
argument_list|)
argument_list|,
name|server
operator|.
name|getServerName
argument_list|()
argument_list|)
decl_stmt|;
name|long
name|sleep
init|=
name|sleepBeforeFailover
operator|/
literal|2
decl_stmt|;
if|if
condition|(
operator|!
name|peer
operator|.
name|getSecond
argument_list|()
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|newQueues
operator|.
name|put
argument_list|(
name|peer
operator|.
name|getFirst
argument_list|()
argument_list|,
name|peer
operator|.
name|getSecond
argument_list|()
argument_list|)
expr_stmt|;
name|sleep
operator|=
name|sleepBeforeFailover
expr_stmt|;
block|}
try|try
block|{
name|Thread
operator|.
name|sleep
argument_list|(
name|sleep
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Interrupted while waiting before transferring a queue."
argument_list|)
expr_stmt|;
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|interrupt
argument_list|()
expr_stmt|;
block|}
name|peers
operator|=
name|queueStorage
operator|.
name|getAllQueues
argument_list|(
name|deadRS
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|!
name|peers
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|queueStorage
operator|.
name|removeReplicatorIfQueueIsEmpty
argument_list|(
name|deadRS
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|ReplicationException
name|e
parameter_list|)
block|{
name|server
operator|.
name|abort
argument_list|(
literal|"Failed to claim queue from dead regionserver"
argument_list|,
name|e
argument_list|)
expr_stmt|;
return|return;
block|}
comment|// Copying over the failed queue is completed.
if|if
condition|(
name|newQueues
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
comment|// We either didn't get the lock or the failed region server didn't have any outstanding
comment|// WALs to replicate, so we are done.
return|return;
block|}
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|String
argument_list|,
name|Set
argument_list|<
name|String
argument_list|>
argument_list|>
name|entry
range|:
name|newQueues
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|String
name|peerId
init|=
name|entry
operator|.
name|getKey
argument_list|()
decl_stmt|;
name|Set
argument_list|<
name|String
argument_list|>
name|walsSet
init|=
name|entry
operator|.
name|getValue
argument_list|()
decl_stmt|;
try|try
block|{
comment|// there is not an actual peer defined corresponding to peerId for the failover.
name|ReplicationQueueInfo
name|replicationQueueInfo
init|=
operator|new
name|ReplicationQueueInfo
argument_list|(
name|peerId
argument_list|)
decl_stmt|;
name|String
name|actualPeerId
init|=
name|replicationQueueInfo
operator|.
name|getPeerId
argument_list|()
decl_stmt|;
name|ReplicationPeer
name|peer
init|=
name|replicationPeers
operator|.
name|getPeer
argument_list|(
name|actualPeerId
argument_list|)
decl_stmt|;
if|if
condition|(
name|peer
operator|==
literal|null
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Skipping failover for peer:"
operator|+
name|actualPeerId
operator|+
literal|" of node "
operator|+
name|deadRS
operator|+
literal|", peer is null"
argument_list|)
expr_stmt|;
name|abortWhenFail
argument_list|(
parameter_list|()
lambda|->
name|queueStorage
operator|.
name|removeQueue
argument_list|(
name|server
operator|.
name|getServerName
argument_list|()
argument_list|,
name|peerId
argument_list|)
argument_list|)
expr_stmt|;
continue|continue;
block|}
name|ReplicationPeerConfig
name|peerConfig
init|=
literal|null
decl_stmt|;
try|try
block|{
name|peerConfig
operator|=
name|replicationPeers
operator|.
name|getPeerConfig
argument_list|(
name|actualPeerId
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Skipping failover for peer:"
operator|+
name|actualPeerId
operator|+
literal|" of node "
operator|+
name|deadRS
operator|+
literal|", failed to read peer config"
argument_list|,
name|e
argument_list|)
expr_stmt|;
name|abortWhenFail
argument_list|(
parameter_list|()
lambda|->
name|queueStorage
operator|.
name|removeQueue
argument_list|(
name|server
operator|.
name|getServerName
argument_list|()
argument_list|,
name|peerId
argument_list|)
argument_list|)
expr_stmt|;
continue|continue;
block|}
comment|// track sources in walsByIdRecoveredQueues
name|Map
argument_list|<
name|String
argument_list|,
name|SortedSet
argument_list|<
name|String
argument_list|>
argument_list|>
name|walsByGroup
init|=
operator|new
name|HashMap
argument_list|<>
argument_list|()
decl_stmt|;
name|walsByIdRecoveredQueues
operator|.
name|put
argument_list|(
name|peerId
argument_list|,
name|walsByGroup
argument_list|)
expr_stmt|;
for|for
control|(
name|String
name|wal
range|:
name|walsSet
control|)
block|{
name|String
name|walPrefix
init|=
name|AbstractFSWALProvider
operator|.
name|getWALPrefixFromWALName
argument_list|(
name|wal
argument_list|)
decl_stmt|;
name|SortedSet
argument_list|<
name|String
argument_list|>
name|wals
init|=
name|walsByGroup
operator|.
name|get
argument_list|(
name|walPrefix
argument_list|)
decl_stmt|;
if|if
condition|(
name|wals
operator|==
literal|null
condition|)
block|{
name|wals
operator|=
operator|new
name|TreeSet
argument_list|<>
argument_list|()
expr_stmt|;
name|walsByGroup
operator|.
name|put
argument_list|(
name|walPrefix
argument_list|,
name|wals
argument_list|)
expr_stmt|;
block|}
name|wals
operator|.
name|add
argument_list|(
name|wal
argument_list|)
expr_stmt|;
block|}
comment|// enqueue sources
name|ReplicationSourceInterface
name|src
init|=
name|getReplicationSource
argument_list|(
name|peerId
argument_list|,
name|peerConfig
argument_list|,
name|peer
argument_list|)
decl_stmt|;
comment|// synchronized on oldsources to avoid adding recovered source for the to-be-removed peer
comment|// see removePeer
synchronized|synchronized
init|(
name|oldsources
init|)
block|{
if|if
condition|(
operator|!
name|replicationPeers
operator|.
name|getAllPeerIds
argument_list|()
operator|.
name|contains
argument_list|(
name|src
operator|.
name|getPeerId
argument_list|()
argument_list|)
condition|)
block|{
name|src
operator|.
name|terminate
argument_list|(
literal|"Recovered queue doesn't belong to any current peer"
argument_list|)
expr_stmt|;
name|closeRecoveredQueue
argument_list|(
name|src
argument_list|)
expr_stmt|;
continue|continue;
block|}
name|oldsources
operator|.
name|add
argument_list|(
name|src
argument_list|)
expr_stmt|;
for|for
control|(
name|String
name|wal
range|:
name|walsSet
control|)
block|{
name|src
operator|.
name|enqueueLog
argument_list|(
operator|new
name|Path
argument_list|(
name|oldLogDir
argument_list|,
name|wal
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|src
operator|.
name|startup
argument_list|()
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
comment|// TODO manage it
name|LOG
operator|.
name|error
argument_list|(
literal|"Failed creating a source"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
comment|/**    * Get the directory where wals are archived    * @return the directory where wals are archived    */
specifier|public
name|Path
name|getOldLogDir
parameter_list|()
block|{
return|return
name|this
operator|.
name|oldLogDir
return|;
block|}
comment|/**    * Get the directory where wals are stored by their RSs    * @return the directory where wals are stored by their RSs    */
specifier|public
name|Path
name|getLogDir
parameter_list|()
block|{
return|return
name|this
operator|.
name|logDir
return|;
block|}
comment|/**    * Get the handle on the local file system    * @return Handle on the local file system    */
specifier|public
name|FileSystem
name|getFs
parameter_list|()
block|{
return|return
name|this
operator|.
name|fs
return|;
block|}
specifier|public
name|Connection
name|getConnection
parameter_list|()
block|{
return|return
name|this
operator|.
name|connection
return|;
block|}
comment|/**    * Get the ReplicationPeers used by this ReplicationSourceManager    * @return the ReplicationPeers used by this ReplicationSourceManager    */
specifier|public
name|ReplicationPeers
name|getReplicationPeers
parameter_list|()
block|{
return|return
name|this
operator|.
name|replicationPeers
return|;
block|}
comment|/**    * Get a string representation of all the sources' metrics    */
specifier|public
name|String
name|getStats
parameter_list|()
block|{
name|StringBuilder
name|stats
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
for|for
control|(
name|ReplicationSourceInterface
name|source
range|:
name|sources
control|)
block|{
name|stats
operator|.
name|append
argument_list|(
literal|"Normal source for cluster "
operator|+
name|source
operator|.
name|getPeerId
argument_list|()
operator|+
literal|": "
argument_list|)
expr_stmt|;
name|stats
operator|.
name|append
argument_list|(
name|source
operator|.
name|getStats
argument_list|()
operator|+
literal|"\n"
argument_list|)
expr_stmt|;
block|}
for|for
control|(
name|ReplicationSourceInterface
name|oldSource
range|:
name|oldsources
control|)
block|{
name|stats
operator|.
name|append
argument_list|(
literal|"Recovered source for cluster/machine(s) "
operator|+
name|oldSource
operator|.
name|getPeerId
argument_list|()
operator|+
literal|": "
argument_list|)
expr_stmt|;
name|stats
operator|.
name|append
argument_list|(
name|oldSource
operator|.
name|getStats
argument_list|()
operator|+
literal|"\n"
argument_list|)
expr_stmt|;
block|}
return|return
name|stats
operator|.
name|toString
argument_list|()
return|;
block|}
specifier|public
name|void
name|addHFileRefs
parameter_list|(
name|TableName
name|tableName
parameter_list|,
name|byte
index|[]
name|family
parameter_list|,
name|List
argument_list|<
name|Pair
argument_list|<
name|Path
argument_list|,
name|Path
argument_list|>
argument_list|>
name|pairs
parameter_list|)
throws|throws
name|ReplicationException
block|{
for|for
control|(
name|ReplicationSourceInterface
name|source
range|:
name|this
operator|.
name|sources
control|)
block|{
name|source
operator|.
name|addHFileRefs
argument_list|(
name|tableName
argument_list|,
name|family
argument_list|,
name|pairs
argument_list|)
expr_stmt|;
block|}
block|}
specifier|public
name|void
name|cleanUpHFileRefs
parameter_list|(
name|String
name|peerId
parameter_list|,
name|List
argument_list|<
name|String
argument_list|>
name|files
parameter_list|)
block|{
name|abortWhenFail
argument_list|(
parameter_list|()
lambda|->
name|this
operator|.
name|queueStorage
operator|.
name|removeHFileRefs
argument_list|(
name|peerId
argument_list|,
name|files
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|int
name|activeFailoverTaskCount
parameter_list|()
block|{
return|return
name|executor
operator|.
name|getActiveCount
argument_list|()
return|;
block|}
comment|/**    * Whether an entry can be pushed to the peer or not right now.    * If we enable serial replication, we can not push the entry until all entries in its region    * whose sequence numbers are smaller than this entry have been pushed.    * For each ReplicationSource, we need only check the first entry in each region, as long as it    * can be pushed, we can push all in this ReplicationSource.    * This method will be blocked until we can push.    * @return the first barrier of entry's region, or -1 if there is no barrier. It is used to    *         prevent saving positions in the region of no barrier.    */
name|void
name|waitUntilCanBePushed
parameter_list|(
name|byte
index|[]
name|encodedName
parameter_list|,
name|long
name|seq
parameter_list|,
name|String
name|peerId
parameter_list|)
throws|throws
name|IOException
throws|,
name|InterruptedException
block|{
comment|/**      * There are barriers for this region and position for this peer. N barriers form N intervals,      * (b1,b2) (b2,b3) ... (bn,max). Generally, there is no logs whose seq id is not greater than      * the first barrier and the last interval is start from the last barrier.      *      * There are several conditions that we can push now, otherwise we should block:      * 1) "Serial replication" is not enabled, we can push all logs just like before. This case      *    should not call this method.      * 2) There is no barriers for this region, or the seq id is smaller than the first barrier.      *    It is mainly because we alter REPLICATION_SCOPE = 2. We can not guarantee the      *    order of logs that is written before altering.      * 3) This entry is in the first interval of barriers. We can push them because it is the      *    start of a region. But if the region is created by region split, we should check      *    if the parent regions are fully pushed.      * 4) If the entry's seq id and the position are in same section, or the pos is the last      *    number of previous section. Because when open a region we put a barrier the number      *    is the last log's id + 1.      * 5) Log's seq is smaller than pos in meta, we are retrying. It may happen when a RS crashes      *    after save replication meta and before save zk offset.      */
name|List
argument_list|<
name|Long
argument_list|>
name|barriers
init|=
name|MetaTableAccessor
operator|.
name|getReplicationBarriers
argument_list|(
name|connection
argument_list|,
name|encodedName
argument_list|)
decl_stmt|;
if|if
condition|(
name|barriers
operator|.
name|isEmpty
argument_list|()
operator|||
name|seq
operator|<=
name|barriers
operator|.
name|get
argument_list|(
literal|0
argument_list|)
condition|)
block|{
comment|// Case 2
return|return;
block|}
name|int
name|interval
init|=
name|Collections
operator|.
name|binarySearch
argument_list|(
name|barriers
argument_list|,
name|seq
argument_list|)
decl_stmt|;
if|if
condition|(
name|interval
operator|<
literal|0
condition|)
block|{
name|interval
operator|=
operator|-
name|interval
operator|-
literal|1
expr_stmt|;
comment|// get the insert position if negative
block|}
if|if
condition|(
name|interval
operator|==
literal|1
condition|)
block|{
comment|// Case 3
comment|// Check if there are parent regions
name|String
name|parentValue
init|=
name|MetaTableAccessor
operator|.
name|getSerialReplicationParentRegion
argument_list|(
name|connection
argument_list|,
name|encodedName
argument_list|)
decl_stmt|;
if|if
condition|(
name|parentValue
operator|==
literal|null
condition|)
block|{
comment|// This region has no parent or the parent's log entries are fully pushed.
return|return;
block|}
while|while
condition|(
literal|true
condition|)
block|{
name|boolean
name|allParentDone
init|=
literal|true
decl_stmt|;
name|String
index|[]
name|parentRegions
init|=
name|parentValue
operator|.
name|split
argument_list|(
literal|","
argument_list|)
decl_stmt|;
for|for
control|(
name|String
name|parent
range|:
name|parentRegions
control|)
block|{
name|byte
index|[]
name|region
init|=
name|Bytes
operator|.
name|toBytes
argument_list|(
name|parent
argument_list|)
decl_stmt|;
name|long
name|pos
init|=
name|MetaTableAccessor
operator|.
name|getReplicationPositionForOnePeer
argument_list|(
name|connection
argument_list|,
name|region
argument_list|,
name|peerId
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|Long
argument_list|>
name|parentBarriers
init|=
name|MetaTableAccessor
operator|.
name|getReplicationBarriers
argument_list|(
name|connection
argument_list|,
name|region
argument_list|)
decl_stmt|;
if|if
condition|(
name|parentBarriers
operator|.
name|size
argument_list|()
operator|>
literal|0
operator|&&
name|parentBarriers
operator|.
name|get
argument_list|(
name|parentBarriers
operator|.
name|size
argument_list|()
operator|-
literal|1
argument_list|)
operator|-
literal|1
operator|>
name|pos
condition|)
block|{
name|allParentDone
operator|=
literal|false
expr_stmt|;
comment|// For a closed region, we will write a close event marker to WAL whose sequence id is
comment|// larger than final barrier but still smaller than next region's openSeqNum.
comment|// So if the pos is larger than last barrier, we can say we have read the event marker
comment|// which means the parent region has been fully pushed.
name|LOG
operator|.
name|info
argument_list|(
name|Bytes
operator|.
name|toString
argument_list|(
name|encodedName
argument_list|)
operator|+
literal|" can not start pushing because parent region's"
operator|+
literal|" log has not been fully pushed: parent="
operator|+
name|Bytes
operator|.
name|toString
argument_list|(
name|region
argument_list|)
operator|+
literal|" pos="
operator|+
name|pos
operator|+
literal|" barriers="
operator|+
name|Arrays
operator|.
name|toString
argument_list|(
name|barriers
operator|.
name|toArray
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
break|break;
block|}
block|}
if|if
condition|(
name|allParentDone
condition|)
block|{
return|return;
block|}
else|else
block|{
name|Thread
operator|.
name|sleep
argument_list|(
name|replicationWaitTime
argument_list|)
expr_stmt|;
block|}
block|}
block|}
while|while
condition|(
literal|true
condition|)
block|{
name|long
name|pos
init|=
name|MetaTableAccessor
operator|.
name|getReplicationPositionForOnePeer
argument_list|(
name|connection
argument_list|,
name|encodedName
argument_list|,
name|peerId
argument_list|)
decl_stmt|;
if|if
condition|(
name|seq
operator|<=
name|pos
condition|)
block|{
comment|// Case 5
block|}
if|if
condition|(
name|pos
operator|>=
literal|0
condition|)
block|{
comment|// Case 4
name|int
name|posInterval
init|=
name|Collections
operator|.
name|binarySearch
argument_list|(
name|barriers
argument_list|,
name|pos
argument_list|)
decl_stmt|;
if|if
condition|(
name|posInterval
operator|<
literal|0
condition|)
block|{
name|posInterval
operator|=
operator|-
name|posInterval
operator|-
literal|1
expr_stmt|;
comment|// get the insert position if negative
block|}
if|if
condition|(
name|posInterval
operator|==
name|interval
operator|||
name|pos
operator|==
name|barriers
operator|.
name|get
argument_list|(
name|interval
operator|-
literal|1
argument_list|)
operator|-
literal|1
condition|)
block|{
return|return;
block|}
block|}
name|LOG
operator|.
name|info
argument_list|(
name|Bytes
operator|.
name|toString
argument_list|(
name|encodedName
argument_list|)
operator|+
literal|" can not start pushing to peer "
operator|+
name|peerId
operator|+
literal|" because previous log has not been pushed: sequence="
operator|+
name|seq
operator|+
literal|" pos="
operator|+
name|pos
operator|+
literal|" barriers="
operator|+
name|Arrays
operator|.
name|toString
argument_list|(
name|barriers
operator|.
name|toArray
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
name|Thread
operator|.
name|sleep
argument_list|(
name|replicationWaitTime
argument_list|)
expr_stmt|;
block|}
block|}
block|}
end_class

end_unit

