begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**   * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|master
package|;
end_package

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|master
operator|.
name|SplitLogManager
operator|.
name|ResubmitDirective
operator|.
name|CHECK
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|master
operator|.
name|SplitLogManager
operator|.
name|ResubmitDirective
operator|.
name|FORCE
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|master
operator|.
name|SplitLogManager
operator|.
name|TerminationStatus
operator|.
name|DELETED
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|master
operator|.
name|SplitLogManager
operator|.
name|TerminationStatus
operator|.
name|FAILURE
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|master
operator|.
name|SplitLogManager
operator|.
name|TerminationStatus
operator|.
name|IN_PROGRESS
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|master
operator|.
name|SplitLogManager
operator|.
name|TerminationStatus
operator|.
name|SUCCESS
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collections
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Set
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ConcurrentHashMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ConcurrentMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|locks
operator|.
name|ReentrantLock
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|Log
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|LogFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|classification
operator|.
name|InterfaceAudience
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileStatus
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|PathFilter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|Chore
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HConstants
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HRegionInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|ServerName
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|SplitLogCounters
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|SplitLogTask
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|Stoppable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|exceptions
operator|.
name|DeserializationException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|master
operator|.
name|SplitLogManager
operator|.
name|TaskFinisher
operator|.
name|Status
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|monitoring
operator|.
name|MonitoredTask
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|monitoring
operator|.
name|TaskMonitor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|protobuf
operator|.
name|generated
operator|.
name|ZooKeeperProtos
operator|.
name|RegionStoreSequenceIds
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|SplitLogWorker
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|wal
operator|.
name|HLogSplitter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|wal
operator|.
name|HLogUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|EnvironmentEdgeManager
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|FSUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|Pair
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|Threads
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|zookeeper
operator|.
name|ZKSplitLog
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|zookeeper
operator|.
name|ZKUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|zookeeper
operator|.
name|ZooKeeperListener
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|zookeeper
operator|.
name|ZooKeeperWatcher
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|StringUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|zookeeper
operator|.
name|AsyncCallback
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|zookeeper
operator|.
name|CreateMode
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|zookeeper
operator|.
name|KeeperException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|zookeeper
operator|.
name|KeeperException
operator|.
name|NoNodeException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|zookeeper
operator|.
name|ZooDefs
operator|.
name|Ids
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|zookeeper
operator|.
name|data
operator|.
name|Stat
import|;
end_import

begin_comment
comment|/**  * Distributes the task of log splitting to the available region servers.  * Coordination happens via zookeeper. For every log file that has to be split a  * znode is created under<code>/hbase/splitlog</code>. SplitLogWorkers race to grab a task.  *  *<p>SplitLogManager monitors the task znodes that it creates using the  * timeoutMonitor thread. If a task's progress is slow then  * {@link #resubmit(String, Task, ResubmitDirective)} will take away the task from the owner  * {@link SplitLogWorker} and the task will be up for grabs again. When the task is done then the  * task's znode is deleted by SplitLogManager.  *  *<p>Clients call {@link #splitLogDistributed(Path)} to split a region server's  * log files. The caller thread waits in this method until all the log files  * have been split.  *  *<p>All the zookeeper calls made by this class are asynchronous. This is mainly  * to help reduce response time seen by the callers.  *  *<p>There is race in this design between the SplitLogManager and the  * SplitLogWorker. SplitLogManager might re-queue a task that has in reality  * already been completed by a SplitLogWorker. We rely on the idempotency of  * the log splitting task for correctness.  *  *<p>It is also assumed that every log splitting task is unique and once  * completed (either with success or with error) it will be not be submitted  * again. If a task is resubmitted then there is a risk that old "delete task"  * can delete the re-submission.  */
end_comment

begin_class
annotation|@
name|InterfaceAudience
operator|.
name|Private
specifier|public
class|class
name|SplitLogManager
extends|extends
name|ZooKeeperListener
block|{
specifier|private
specifier|static
specifier|final
name|Log
name|LOG
init|=
name|LogFactory
operator|.
name|getLog
argument_list|(
name|SplitLogManager
operator|.
name|class
argument_list|)
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|int
name|DEFAULT_TIMEOUT
init|=
literal|120000
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|int
name|DEFAULT_ZK_RETRIES
init|=
literal|3
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|int
name|DEFAULT_MAX_RESUBMIT
init|=
literal|3
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|int
name|DEFAULT_UNASSIGNED_TIMEOUT
init|=
operator|(
literal|3
operator|*
literal|60
operator|*
literal|1000
operator|)
decl_stmt|;
comment|//3 min
specifier|private
specifier|final
name|Stoppable
name|stopper
decl_stmt|;
specifier|private
specifier|final
name|MasterServices
name|master
decl_stmt|;
specifier|private
specifier|final
name|ServerName
name|serverName
decl_stmt|;
specifier|private
specifier|final
name|TaskFinisher
name|taskFinisher
decl_stmt|;
specifier|private
name|FileSystem
name|fs
decl_stmt|;
specifier|private
name|Configuration
name|conf
decl_stmt|;
specifier|private
name|long
name|zkretries
decl_stmt|;
specifier|private
name|long
name|resubmit_threshold
decl_stmt|;
specifier|private
name|long
name|timeout
decl_stmt|;
specifier|private
name|long
name|unassignedTimeout
decl_stmt|;
specifier|private
name|long
name|lastNodeCreateTime
init|=
name|Long
operator|.
name|MAX_VALUE
decl_stmt|;
specifier|public
name|boolean
name|ignoreZKDeleteForTesting
init|=
literal|false
decl_stmt|;
specifier|private
specifier|volatile
name|long
name|lastRecoveringNodeCreationTime
init|=
literal|0
decl_stmt|;
comment|// When lastRecoveringNodeCreationTime is older than the following threshold, we'll check
comment|// whether to GC stale recovering znodes
specifier|private
name|long
name|checkRecoveringTimeThreshold
init|=
literal|15000
decl_stmt|;
comment|// 15 seconds
specifier|private
specifier|final
name|List
argument_list|<
name|Pair
argument_list|<
name|Set
argument_list|<
name|ServerName
argument_list|>
argument_list|,
name|Boolean
argument_list|>
argument_list|>
name|failedRecoveringRegionDeletions
init|=
name|Collections
operator|.
name|synchronizedList
argument_list|(
operator|new
name|ArrayList
argument_list|<
name|Pair
argument_list|<
name|Set
argument_list|<
name|ServerName
argument_list|>
argument_list|,
name|Boolean
argument_list|>
argument_list|>
argument_list|()
argument_list|)
decl_stmt|;
comment|/**    * In distributedLogReplay mode, we need touch both splitlog and recovering-regions znodes in one    * operation. So the lock is used to guard such cases.    */
specifier|protected
specifier|final
name|ReentrantLock
name|recoveringRegionLock
init|=
operator|new
name|ReentrantLock
argument_list|()
decl_stmt|;
specifier|final
name|boolean
name|distributedLogReplay
decl_stmt|;
specifier|private
specifier|final
name|ConcurrentMap
argument_list|<
name|String
argument_list|,
name|Task
argument_list|>
name|tasks
init|=
operator|new
name|ConcurrentHashMap
argument_list|<
name|String
argument_list|,
name|Task
argument_list|>
argument_list|()
decl_stmt|;
specifier|private
name|TimeoutMonitor
name|timeoutMonitor
decl_stmt|;
specifier|private
specifier|volatile
name|Set
argument_list|<
name|ServerName
argument_list|>
name|deadWorkers
init|=
literal|null
decl_stmt|;
specifier|private
specifier|final
name|Object
name|deadWorkersLock
init|=
operator|new
name|Object
argument_list|()
decl_stmt|;
specifier|private
name|Set
argument_list|<
name|String
argument_list|>
name|failedDeletions
init|=
literal|null
decl_stmt|;
comment|/**    * Wrapper around {@link #SplitLogManager(ZooKeeperWatcher zkw, Configuration conf,    *   Stoppable stopper, MasterServices master, ServerName serverName,    *   boolean masterRecovery, TaskFinisher tf)}    * with masterRecovery = false, and tf = null.  Used in unit tests.    *    * @param zkw the ZK watcher    * @param conf the HBase configuration    * @param stopper the stoppable in case anything is wrong    * @param master the master services    * @param serverName the master server name    */
specifier|public
name|SplitLogManager
parameter_list|(
name|ZooKeeperWatcher
name|zkw
parameter_list|,
specifier|final
name|Configuration
name|conf
parameter_list|,
name|Stoppable
name|stopper
parameter_list|,
name|MasterServices
name|master
parameter_list|,
name|ServerName
name|serverName
parameter_list|)
block|{
name|this
argument_list|(
name|zkw
argument_list|,
name|conf
argument_list|,
name|stopper
argument_list|,
name|master
argument_list|,
name|serverName
argument_list|,
literal|false
argument_list|,
literal|null
argument_list|)
expr_stmt|;
block|}
comment|/**    * Wrapper around {@link #SplitLogManager(ZooKeeperWatcher zkw, Configuration conf,    *   Stoppable stopper, MasterServices master, ServerName serverName,    *   boolean masterRecovery, TaskFinisher tf)}    * that provides a task finisher for copying recovered edits to their final destination.    * The task finisher has to be robust because it can be arbitrarily restarted or called    * multiple times.    *    * @param zkw the ZK watcher    * @param conf the HBase configuration    * @param stopper the stoppable in case anything is wrong    * @param master the master services    * @param serverName the master server name    * @param masterRecovery an indication if the master is in recovery    */
specifier|public
name|SplitLogManager
parameter_list|(
name|ZooKeeperWatcher
name|zkw
parameter_list|,
specifier|final
name|Configuration
name|conf
parameter_list|,
name|Stoppable
name|stopper
parameter_list|,
name|MasterServices
name|master
parameter_list|,
name|ServerName
name|serverName
parameter_list|,
name|boolean
name|masterRecovery
parameter_list|)
block|{
name|this
argument_list|(
name|zkw
argument_list|,
name|conf
argument_list|,
name|stopper
argument_list|,
name|master
argument_list|,
name|serverName
argument_list|,
name|masterRecovery
argument_list|,
operator|new
name|TaskFinisher
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|Status
name|finish
parameter_list|(
name|ServerName
name|workerName
parameter_list|,
name|String
name|logfile
parameter_list|)
block|{
try|try
block|{
name|HLogSplitter
operator|.
name|finishSplitLogFile
argument_list|(
name|logfile
argument_list|,
name|conf
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Could not finish splitting of log file "
operator|+
name|logfile
argument_list|,
name|e
argument_list|)
expr_stmt|;
return|return
name|Status
operator|.
name|ERR
return|;
block|}
return|return
name|Status
operator|.
name|DONE
return|;
block|}
block|}
argument_list|)
expr_stmt|;
block|}
comment|/**    * Its OK to construct this object even when region-servers are not online. It    * does lookup the orphan tasks in zk but it doesn't block waiting for them    * to be done.    *    * @param zkw the ZK watcher    * @param conf the HBase configuration    * @param stopper the stoppable in case anything is wrong    * @param master the master services    * @param serverName the master server name    * @param masterRecovery an indication if the master is in recovery    * @param tf task finisher    */
specifier|public
name|SplitLogManager
parameter_list|(
name|ZooKeeperWatcher
name|zkw
parameter_list|,
name|Configuration
name|conf
parameter_list|,
name|Stoppable
name|stopper
parameter_list|,
name|MasterServices
name|master
parameter_list|,
name|ServerName
name|serverName
parameter_list|,
name|boolean
name|masterRecovery
parameter_list|,
name|TaskFinisher
name|tf
parameter_list|)
block|{
name|super
argument_list|(
name|zkw
argument_list|)
expr_stmt|;
name|this
operator|.
name|taskFinisher
operator|=
name|tf
expr_stmt|;
name|this
operator|.
name|conf
operator|=
name|conf
expr_stmt|;
name|this
operator|.
name|stopper
operator|=
name|stopper
expr_stmt|;
name|this
operator|.
name|master
operator|=
name|master
expr_stmt|;
name|this
operator|.
name|zkretries
operator|=
name|conf
operator|.
name|getLong
argument_list|(
literal|"hbase.splitlog.zk.retries"
argument_list|,
name|DEFAULT_ZK_RETRIES
argument_list|)
expr_stmt|;
name|this
operator|.
name|resubmit_threshold
operator|=
name|conf
operator|.
name|getLong
argument_list|(
literal|"hbase.splitlog.max.resubmit"
argument_list|,
name|DEFAULT_MAX_RESUBMIT
argument_list|)
expr_stmt|;
name|this
operator|.
name|timeout
operator|=
name|conf
operator|.
name|getInt
argument_list|(
literal|"hbase.splitlog.manager.timeout"
argument_list|,
name|DEFAULT_TIMEOUT
argument_list|)
expr_stmt|;
name|this
operator|.
name|unassignedTimeout
operator|=
name|conf
operator|.
name|getInt
argument_list|(
literal|"hbase.splitlog.manager.unassigned.timeout"
argument_list|,
name|DEFAULT_UNASSIGNED_TIMEOUT
argument_list|)
expr_stmt|;
name|this
operator|.
name|distributedLogReplay
operator|=
name|this
operator|.
name|conf
operator|.
name|getBoolean
argument_list|(
name|HConstants
operator|.
name|DISTRIBUTED_LOG_REPLAY_KEY
argument_list|,
name|HConstants
operator|.
name|DEFAULT_DISTRIBUTED_LOG_REPLAY_CONFIG
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Timeout="
operator|+
name|timeout
operator|+
literal|", unassigned timeout="
operator|+
name|unassignedTimeout
operator|+
literal|", distributedLogReplay="
operator|+
name|this
operator|.
name|distributedLogReplay
argument_list|)
expr_stmt|;
name|this
operator|.
name|serverName
operator|=
name|serverName
expr_stmt|;
name|this
operator|.
name|timeoutMonitor
operator|=
operator|new
name|TimeoutMonitor
argument_list|(
name|conf
operator|.
name|getInt
argument_list|(
literal|"hbase.splitlog.manager.timeoutmonitor.period"
argument_list|,
literal|1000
argument_list|)
argument_list|,
name|stopper
argument_list|)
expr_stmt|;
name|this
operator|.
name|failedDeletions
operator|=
name|Collections
operator|.
name|synchronizedSet
argument_list|(
operator|new
name|HashSet
argument_list|<
name|String
argument_list|>
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|masterRecovery
condition|)
block|{
name|Threads
operator|.
name|setDaemonThreadRunning
argument_list|(
name|timeoutMonitor
operator|.
name|getThread
argument_list|()
argument_list|,
name|serverName
operator|+
literal|".splitLogManagerTimeoutMonitor"
argument_list|)
expr_stmt|;
block|}
comment|// Watcher can be null during tests with Mock'd servers.
if|if
condition|(
name|this
operator|.
name|watcher
operator|!=
literal|null
condition|)
block|{
name|this
operator|.
name|watcher
operator|.
name|registerListener
argument_list|(
name|this
argument_list|)
expr_stmt|;
name|lookForOrphans
argument_list|()
expr_stmt|;
block|}
block|}
specifier|private
name|FileStatus
index|[]
name|getFileList
parameter_list|(
name|List
argument_list|<
name|Path
argument_list|>
name|logDirs
parameter_list|,
name|PathFilter
name|filter
parameter_list|)
throws|throws
name|IOException
block|{
name|List
argument_list|<
name|FileStatus
argument_list|>
name|fileStatus
init|=
operator|new
name|ArrayList
argument_list|<
name|FileStatus
argument_list|>
argument_list|()
decl_stmt|;
for|for
control|(
name|Path
name|hLogDir
range|:
name|logDirs
control|)
block|{
name|this
operator|.
name|fs
operator|=
name|hLogDir
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|fs
operator|.
name|exists
argument_list|(
name|hLogDir
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
name|hLogDir
operator|+
literal|" doesn't exist. Nothing to do!"
argument_list|)
expr_stmt|;
continue|continue;
block|}
name|FileStatus
index|[]
name|logfiles
init|=
name|FSUtils
operator|.
name|listStatus
argument_list|(
name|fs
argument_list|,
name|hLogDir
argument_list|,
name|filter
argument_list|)
decl_stmt|;
if|if
condition|(
name|logfiles
operator|==
literal|null
operator|||
name|logfiles
operator|.
name|length
operator|==
literal|0
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
name|hLogDir
operator|+
literal|" is empty dir, no logs to split"
argument_list|)
expr_stmt|;
block|}
else|else
block|{
for|for
control|(
name|FileStatus
name|status
range|:
name|logfiles
control|)
name|fileStatus
operator|.
name|add
argument_list|(
name|status
argument_list|)
expr_stmt|;
block|}
block|}
name|FileStatus
index|[]
name|a
init|=
operator|new
name|FileStatus
index|[
name|fileStatus
operator|.
name|size
argument_list|()
index|]
decl_stmt|;
return|return
name|fileStatus
operator|.
name|toArray
argument_list|(
name|a
argument_list|)
return|;
block|}
comment|/**    * @param logDir    *            one region sever hlog dir path in .logs    * @throws IOException    *             if there was an error while splitting any log file    * @return cumulative size of the logfiles split    * @throws IOException     */
specifier|public
name|long
name|splitLogDistributed
parameter_list|(
specifier|final
name|Path
name|logDir
parameter_list|)
throws|throws
name|IOException
block|{
name|List
argument_list|<
name|Path
argument_list|>
name|logDirs
init|=
operator|new
name|ArrayList
argument_list|<
name|Path
argument_list|>
argument_list|()
decl_stmt|;
name|logDirs
operator|.
name|add
argument_list|(
name|logDir
argument_list|)
expr_stmt|;
return|return
name|splitLogDistributed
argument_list|(
name|logDirs
argument_list|)
return|;
block|}
comment|/**    * The caller will block until all the log files of the given region server    * have been processed - successfully split or an error is encountered - by an    * available worker region server. This method must only be called after the    * region servers have been brought online.    *    * @param logDirs List of log dirs to split    * @throws IOException If there was an error while splitting any log file    * @return cumulative size of the logfiles split    */
specifier|public
name|long
name|splitLogDistributed
parameter_list|(
specifier|final
name|List
argument_list|<
name|Path
argument_list|>
name|logDirs
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|logDirs
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
return|return
literal|0
return|;
block|}
name|Set
argument_list|<
name|ServerName
argument_list|>
name|serverNames
init|=
operator|new
name|HashSet
argument_list|<
name|ServerName
argument_list|>
argument_list|()
decl_stmt|;
for|for
control|(
name|Path
name|logDir
range|:
name|logDirs
control|)
block|{
try|try
block|{
name|ServerName
name|serverName
init|=
name|HLogUtil
operator|.
name|getServerNameFromHLogDirectoryName
argument_list|(
name|logDir
argument_list|)
decl_stmt|;
if|if
condition|(
name|serverName
operator|!=
literal|null
condition|)
block|{
name|serverNames
operator|.
name|add
argument_list|(
name|serverName
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|IllegalArgumentException
name|e
parameter_list|)
block|{
comment|// ignore invalid format error.
name|LOG
operator|.
name|warn
argument_list|(
literal|"Cannot parse server name from "
operator|+
name|logDir
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|splitLogDistributed
argument_list|(
name|serverNames
argument_list|,
name|logDirs
argument_list|,
literal|null
argument_list|)
return|;
block|}
comment|/**    * The caller will block until all the hbase:meta log files of the given region server    * have been processed - successfully split or an error is encountered - by an    * available worker region server. This method must only be called after the    * region servers have been brought online.    *    * @param logDirs List of log dirs to split    * @param filter the Path filter to select specific files for considering    * @throws IOException If there was an error while splitting any log file    * @return cumulative size of the logfiles split    */
specifier|public
name|long
name|splitLogDistributed
parameter_list|(
specifier|final
name|Set
argument_list|<
name|ServerName
argument_list|>
name|serverNames
parameter_list|,
specifier|final
name|List
argument_list|<
name|Path
argument_list|>
name|logDirs
parameter_list|,
name|PathFilter
name|filter
parameter_list|)
throws|throws
name|IOException
block|{
name|MonitoredTask
name|status
init|=
name|TaskMonitor
operator|.
name|get
argument_list|()
operator|.
name|createStatus
argument_list|(
literal|"Doing distributed log split in "
operator|+
name|logDirs
argument_list|)
decl_stmt|;
name|FileStatus
index|[]
name|logfiles
init|=
name|getFileList
argument_list|(
name|logDirs
argument_list|,
name|filter
argument_list|)
decl_stmt|;
name|status
operator|.
name|setStatus
argument_list|(
literal|"Checking directory contents..."
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Scheduling batch of logs to split"
argument_list|)
expr_stmt|;
name|SplitLogCounters
operator|.
name|tot_mgr_log_split_batch_start
operator|.
name|incrementAndGet
argument_list|()
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"started splitting "
operator|+
name|logfiles
operator|.
name|length
operator|+
literal|" logs in "
operator|+
name|logDirs
argument_list|)
expr_stmt|;
name|long
name|t
init|=
name|EnvironmentEdgeManager
operator|.
name|currentTimeMillis
argument_list|()
decl_stmt|;
name|long
name|totalSize
init|=
literal|0
decl_stmt|;
name|TaskBatch
name|batch
init|=
operator|new
name|TaskBatch
argument_list|()
decl_stmt|;
name|Boolean
name|isMetaRecovery
init|=
operator|(
name|filter
operator|==
literal|null
operator|)
condition|?
literal|null
else|:
literal|false
decl_stmt|;
for|for
control|(
name|FileStatus
name|lf
range|:
name|logfiles
control|)
block|{
comment|// TODO If the log file is still being written to - which is most likely
comment|// the case for the last log file - then its length will show up here
comment|// as zero. The size of such a file can only be retrieved after
comment|// recover-lease is done. totalSize will be under in most cases and the
comment|// metrics that it drives will also be under-reported.
name|totalSize
operator|+=
name|lf
operator|.
name|getLen
argument_list|()
expr_stmt|;
name|String
name|pathToLog
init|=
name|FSUtils
operator|.
name|removeRootPath
argument_list|(
name|lf
operator|.
name|getPath
argument_list|()
argument_list|,
name|conf
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|enqueueSplitTask
argument_list|(
name|pathToLog
argument_list|,
name|batch
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"duplicate log split scheduled for "
operator|+
name|lf
operator|.
name|getPath
argument_list|()
argument_list|)
throw|;
block|}
block|}
name|waitForSplittingCompletion
argument_list|(
name|batch
argument_list|,
name|status
argument_list|)
expr_stmt|;
comment|// remove recovering regions from ZK
if|if
condition|(
name|filter
operator|==
name|MasterFileSystem
operator|.
name|META_FILTER
comment|/* reference comparison */
condition|)
block|{
comment|// we split meta regions and user regions separately therefore logfiles are either all for
comment|// meta or user regions but won't for both( we could have mixed situations in tests)
name|isMetaRecovery
operator|=
literal|true
expr_stmt|;
block|}
name|this
operator|.
name|removeRecoveringRegionsFromZK
argument_list|(
name|serverNames
argument_list|,
name|isMetaRecovery
argument_list|)
expr_stmt|;
if|if
condition|(
name|batch
operator|.
name|done
operator|!=
name|batch
operator|.
name|installed
condition|)
block|{
name|batch
operator|.
name|isDead
operator|=
literal|true
expr_stmt|;
name|SplitLogCounters
operator|.
name|tot_mgr_log_split_batch_err
operator|.
name|incrementAndGet
argument_list|()
expr_stmt|;
name|LOG
operator|.
name|warn
argument_list|(
literal|"error while splitting logs in "
operator|+
name|logDirs
operator|+
literal|" installed = "
operator|+
name|batch
operator|.
name|installed
operator|+
literal|" but only "
operator|+
name|batch
operator|.
name|done
operator|+
literal|" done"
argument_list|)
expr_stmt|;
name|String
name|msg
init|=
literal|"error or interrupted while splitting logs in "
operator|+
name|logDirs
operator|+
literal|" Task = "
operator|+
name|batch
decl_stmt|;
name|status
operator|.
name|abort
argument_list|(
name|msg
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|IOException
argument_list|(
name|msg
argument_list|)
throw|;
block|}
for|for
control|(
name|Path
name|logDir
range|:
name|logDirs
control|)
block|{
name|status
operator|.
name|setStatus
argument_list|(
literal|"Cleaning up log directory..."
argument_list|)
expr_stmt|;
try|try
block|{
if|if
condition|(
name|fs
operator|.
name|exists
argument_list|(
name|logDir
argument_list|)
operator|&&
operator|!
name|fs
operator|.
name|delete
argument_list|(
name|logDir
argument_list|,
literal|false
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Unable to delete log src dir. Ignoring. "
operator|+
name|logDir
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|ioe
parameter_list|)
block|{
name|FileStatus
index|[]
name|files
init|=
name|fs
operator|.
name|listStatus
argument_list|(
name|logDir
argument_list|)
decl_stmt|;
if|if
condition|(
name|files
operator|!=
literal|null
operator|&&
name|files
operator|.
name|length
operator|>
literal|0
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"returning success without actually splitting and "
operator|+
literal|"deleting all the log files in path "
operator|+
name|logDir
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Unable to delete log src dir. Ignoring. "
operator|+
name|logDir
argument_list|,
name|ioe
argument_list|)
expr_stmt|;
block|}
block|}
name|SplitLogCounters
operator|.
name|tot_mgr_log_split_batch_success
operator|.
name|incrementAndGet
argument_list|()
expr_stmt|;
block|}
name|String
name|msg
init|=
literal|"finished splitting (more than or equal to) "
operator|+
name|totalSize
operator|+
literal|" bytes in "
operator|+
name|batch
operator|.
name|installed
operator|+
literal|" log files in "
operator|+
name|logDirs
operator|+
literal|" in "
operator|+
operator|(
name|EnvironmentEdgeManager
operator|.
name|currentTimeMillis
argument_list|()
operator|-
name|t
operator|)
operator|+
literal|"ms"
decl_stmt|;
name|status
operator|.
name|markComplete
argument_list|(
name|msg
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
name|msg
argument_list|)
expr_stmt|;
return|return
name|totalSize
return|;
block|}
comment|/**    * Add a task entry to splitlog znode if it is not already there.    *     * @param taskname the path of the log to be split    * @param batch the batch this task belongs to    * @return true if a new entry is created, false if it is already there.    */
name|boolean
name|enqueueSplitTask
parameter_list|(
name|String
name|taskname
parameter_list|,
name|TaskBatch
name|batch
parameter_list|)
block|{
name|SplitLogCounters
operator|.
name|tot_mgr_log_split_start
operator|.
name|incrementAndGet
argument_list|()
expr_stmt|;
comment|// This is a znode path under the splitlog dir with the rest of the path made up of an
comment|// url encoding of the passed in log to split.
name|String
name|path
init|=
name|ZKSplitLog
operator|.
name|getEncodedNodeName
argument_list|(
name|watcher
argument_list|,
name|taskname
argument_list|)
decl_stmt|;
name|Task
name|oldtask
init|=
name|createTaskIfAbsent
argument_list|(
name|path
argument_list|,
name|batch
argument_list|)
decl_stmt|;
if|if
condition|(
name|oldtask
operator|==
literal|null
condition|)
block|{
comment|// publish the task in zk
name|createNode
argument_list|(
name|path
argument_list|,
name|zkretries
argument_list|)
expr_stmt|;
return|return
literal|true
return|;
block|}
return|return
literal|false
return|;
block|}
specifier|private
name|void
name|waitForSplittingCompletion
parameter_list|(
name|TaskBatch
name|batch
parameter_list|,
name|MonitoredTask
name|status
parameter_list|)
block|{
synchronized|synchronized
init|(
name|batch
init|)
block|{
while|while
condition|(
operator|(
name|batch
operator|.
name|done
operator|+
name|batch
operator|.
name|error
operator|)
operator|!=
name|batch
operator|.
name|installed
condition|)
block|{
try|try
block|{
name|status
operator|.
name|setStatus
argument_list|(
literal|"Waiting for distributed tasks to finish. "
operator|+
literal|" scheduled="
operator|+
name|batch
operator|.
name|installed
operator|+
literal|" done="
operator|+
name|batch
operator|.
name|done
operator|+
literal|" error="
operator|+
name|batch
operator|.
name|error
argument_list|)
expr_stmt|;
name|int
name|remaining
init|=
name|batch
operator|.
name|installed
operator|-
operator|(
name|batch
operator|.
name|done
operator|+
name|batch
operator|.
name|error
operator|)
decl_stmt|;
name|int
name|actual
init|=
name|activeTasks
argument_list|(
name|batch
argument_list|)
decl_stmt|;
if|if
condition|(
name|remaining
operator|!=
name|actual
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Expected "
operator|+
name|remaining
operator|+
literal|" active tasks, but actually there are "
operator|+
name|actual
argument_list|)
expr_stmt|;
block|}
name|int
name|remainingInZK
init|=
name|remainingTasksInZK
argument_list|()
decl_stmt|;
if|if
condition|(
name|remainingInZK
operator|>=
literal|0
operator|&&
name|actual
operator|>
name|remainingInZK
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Expected at least"
operator|+
name|actual
operator|+
literal|" tasks in ZK, but actually there are "
operator|+
name|remainingInZK
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|remainingInZK
operator|==
literal|0
operator|||
name|actual
operator|==
literal|0
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"No more task remaining (ZK or task map), splitting "
operator|+
literal|"should have completed. Remaining tasks in ZK "
operator|+
name|remainingInZK
operator|+
literal|", active tasks in map "
operator|+
name|actual
argument_list|)
expr_stmt|;
if|if
condition|(
name|remainingInZK
operator|==
literal|0
operator|&&
name|actual
operator|==
literal|0
condition|)
block|{
return|return;
block|}
block|}
name|batch
operator|.
name|wait
argument_list|(
literal|100
argument_list|)
expr_stmt|;
if|if
condition|(
name|stopper
operator|.
name|isStopped
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Stopped while waiting for log splits to be completed"
argument_list|)
expr_stmt|;
return|return;
block|}
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Interrupted while waiting for log splits to be completed"
argument_list|)
expr_stmt|;
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|interrupt
argument_list|()
expr_stmt|;
return|return;
block|}
block|}
block|}
block|}
specifier|private
name|int
name|activeTasks
parameter_list|(
specifier|final
name|TaskBatch
name|batch
parameter_list|)
block|{
name|int
name|count
init|=
literal|0
decl_stmt|;
for|for
control|(
name|Task
name|t
range|:
name|tasks
operator|.
name|values
argument_list|()
control|)
block|{
if|if
condition|(
name|t
operator|.
name|batch
operator|==
name|batch
operator|&&
name|t
operator|.
name|status
operator|==
name|TerminationStatus
operator|.
name|IN_PROGRESS
condition|)
block|{
name|count
operator|++
expr_stmt|;
block|}
block|}
return|return
name|count
return|;
block|}
specifier|private
name|int
name|remainingTasksInZK
parameter_list|()
block|{
name|int
name|count
init|=
literal|0
decl_stmt|;
try|try
block|{
name|List
argument_list|<
name|String
argument_list|>
name|tasks
init|=
name|ZKUtil
operator|.
name|listChildrenNoWatch
argument_list|(
name|watcher
argument_list|,
name|watcher
operator|.
name|splitLogZNode
argument_list|)
decl_stmt|;
if|if
condition|(
name|tasks
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|String
name|t
range|:
name|tasks
control|)
block|{
if|if
condition|(
operator|!
name|ZKSplitLog
operator|.
name|isRescanNode
argument_list|(
name|watcher
argument_list|,
name|t
argument_list|)
condition|)
block|{
name|count
operator|++
expr_stmt|;
block|}
block|}
block|}
block|}
catch|catch
parameter_list|(
name|KeeperException
name|ke
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failed to check remaining tasks"
argument_list|,
name|ke
argument_list|)
expr_stmt|;
name|count
operator|=
operator|-
literal|1
expr_stmt|;
block|}
return|return
name|count
return|;
block|}
comment|/**    * It removes recovering regions under /hbase/recovering-regions/[encoded region name] so that the    * region server hosting the region can allow reads to the recovered region    * @param serverNames servers which are just recovered    * @param isMetaRecovery whether current recovery is for the meta region on    *<code>serverNames<code>    */
specifier|private
name|void
name|removeRecoveringRegionsFromZK
parameter_list|(
specifier|final
name|Set
argument_list|<
name|ServerName
argument_list|>
name|serverNames
parameter_list|,
name|Boolean
name|isMetaRecovery
parameter_list|)
block|{
if|if
condition|(
operator|!
name|this
operator|.
name|distributedLogReplay
condition|)
block|{
comment|// the function is only used in WALEdit direct replay mode
return|return;
block|}
specifier|final
name|String
name|metaEncodeRegionName
init|=
name|HRegionInfo
operator|.
name|FIRST_META_REGIONINFO
operator|.
name|getEncodedName
argument_list|()
decl_stmt|;
name|int
name|count
init|=
literal|0
decl_stmt|;
name|Set
argument_list|<
name|String
argument_list|>
name|recoveredServerNameSet
init|=
operator|new
name|HashSet
argument_list|<
name|String
argument_list|>
argument_list|()
decl_stmt|;
if|if
condition|(
name|serverNames
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|ServerName
name|tmpServerName
range|:
name|serverNames
control|)
block|{
name|recoveredServerNameSet
operator|.
name|add
argument_list|(
name|tmpServerName
operator|.
name|getServerName
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
try|try
block|{
name|this
operator|.
name|recoveringRegionLock
operator|.
name|lock
argument_list|()
expr_stmt|;
name|List
argument_list|<
name|String
argument_list|>
name|tasks
init|=
name|ZKUtil
operator|.
name|listChildrenNoWatch
argument_list|(
name|watcher
argument_list|,
name|watcher
operator|.
name|splitLogZNode
argument_list|)
decl_stmt|;
if|if
condition|(
name|tasks
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|String
name|t
range|:
name|tasks
control|)
block|{
if|if
condition|(
operator|!
name|ZKSplitLog
operator|.
name|isRescanNode
argument_list|(
name|watcher
argument_list|,
name|t
argument_list|)
condition|)
block|{
name|count
operator|++
expr_stmt|;
block|}
block|}
block|}
if|if
condition|(
name|count
operator|==
literal|0
operator|&&
name|this
operator|.
name|master
operator|.
name|isInitialized
argument_list|()
operator|&&
operator|!
name|this
operator|.
name|master
operator|.
name|getServerManager
argument_list|()
operator|.
name|areDeadServersInProgress
argument_list|()
condition|)
block|{
comment|// no splitting work items left
name|deleteRecoveringRegionZNodes
argument_list|(
literal|null
argument_list|)
expr_stmt|;
comment|// reset lastRecoveringNodeCreationTime because we cleared all recovering znodes at
comment|// this point.
name|lastRecoveringNodeCreationTime
operator|=
name|Long
operator|.
name|MAX_VALUE
expr_stmt|;
block|}
elseif|else
if|if
condition|(
operator|!
name|recoveredServerNameSet
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
comment|// remove recovering regions which doesn't have any RS associated with it
name|List
argument_list|<
name|String
argument_list|>
name|regions
init|=
name|ZKUtil
operator|.
name|listChildrenNoWatch
argument_list|(
name|watcher
argument_list|,
name|watcher
operator|.
name|recoveringRegionsZNode
argument_list|)
decl_stmt|;
if|if
condition|(
name|regions
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|String
name|region
range|:
name|regions
control|)
block|{
if|if
condition|(
name|isMetaRecovery
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
operator|(
name|isMetaRecovery
operator|&&
operator|!
name|region
operator|.
name|equalsIgnoreCase
argument_list|(
name|metaEncodeRegionName
argument_list|)
operator|)
operator|||
operator|(
operator|!
name|isMetaRecovery
operator|&&
name|region
operator|.
name|equalsIgnoreCase
argument_list|(
name|metaEncodeRegionName
argument_list|)
operator|)
condition|)
block|{
comment|// skip non-meta regions when recovering the meta region or
comment|// skip the meta region when recovering user regions
continue|continue;
block|}
block|}
name|String
name|nodePath
init|=
name|ZKUtil
operator|.
name|joinZNode
argument_list|(
name|watcher
operator|.
name|recoveringRegionsZNode
argument_list|,
name|region
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|String
argument_list|>
name|failedServers
init|=
name|ZKUtil
operator|.
name|listChildrenNoWatch
argument_list|(
name|watcher
argument_list|,
name|nodePath
argument_list|)
decl_stmt|;
if|if
condition|(
name|failedServers
operator|==
literal|null
operator|||
name|failedServers
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|ZKUtil
operator|.
name|deleteNode
argument_list|(
name|watcher
argument_list|,
name|nodePath
argument_list|)
expr_stmt|;
continue|continue;
block|}
if|if
condition|(
name|recoveredServerNameSet
operator|.
name|containsAll
argument_list|(
name|failedServers
argument_list|)
condition|)
block|{
name|ZKUtil
operator|.
name|deleteNodeRecursively
argument_list|(
name|watcher
argument_list|,
name|nodePath
argument_list|)
expr_stmt|;
block|}
else|else
block|{
for|for
control|(
name|String
name|failedServer
range|:
name|failedServers
control|)
block|{
if|if
condition|(
name|recoveredServerNameSet
operator|.
name|contains
argument_list|(
name|failedServer
argument_list|)
condition|)
block|{
name|String
name|tmpPath
init|=
name|ZKUtil
operator|.
name|joinZNode
argument_list|(
name|nodePath
argument_list|,
name|failedServer
argument_list|)
decl_stmt|;
name|ZKUtil
operator|.
name|deleteNode
argument_list|(
name|watcher
argument_list|,
name|tmpPath
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
block|}
block|}
block|}
catch|catch
parameter_list|(
name|KeeperException
name|ke
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"removeRecoveringRegionsFromZK got zookeeper exception. Will retry"
argument_list|,
name|ke
argument_list|)
expr_stmt|;
if|if
condition|(
name|serverNames
operator|!=
literal|null
operator|&&
operator|!
name|serverNames
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|this
operator|.
name|failedRecoveringRegionDeletions
operator|.
name|add
argument_list|(
operator|new
name|Pair
argument_list|<
name|Set
argument_list|<
name|ServerName
argument_list|>
argument_list|,
name|Boolean
argument_list|>
argument_list|(
name|serverNames
argument_list|,
name|isMetaRecovery
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
finally|finally
block|{
name|this
operator|.
name|recoveringRegionLock
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**    * It removes stale recovering regions under /hbase/recovering-regions/[encoded region name]    * during master initialization phase.    * @param failedServers A set of known failed servers    * @throws KeeperException    */
name|void
name|removeStaleRecoveringRegionsFromZK
parameter_list|(
specifier|final
name|Set
argument_list|<
name|ServerName
argument_list|>
name|failedServers
parameter_list|)
throws|throws
name|KeeperException
block|{
if|if
condition|(
operator|!
name|this
operator|.
name|distributedLogReplay
condition|)
block|{
comment|// the function is only used in distributedLogReplay mode when master is in initialization
return|return;
block|}
name|Set
argument_list|<
name|String
argument_list|>
name|knownFailedServers
init|=
operator|new
name|HashSet
argument_list|<
name|String
argument_list|>
argument_list|()
decl_stmt|;
if|if
condition|(
name|failedServers
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|ServerName
name|tmpServerName
range|:
name|failedServers
control|)
block|{
name|knownFailedServers
operator|.
name|add
argument_list|(
name|tmpServerName
operator|.
name|getServerName
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
name|this
operator|.
name|recoveringRegionLock
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
name|List
argument_list|<
name|String
argument_list|>
name|tasks
init|=
name|ZKUtil
operator|.
name|listChildrenNoWatch
argument_list|(
name|watcher
argument_list|,
name|watcher
operator|.
name|splitLogZNode
argument_list|)
decl_stmt|;
if|if
condition|(
name|tasks
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|String
name|t
range|:
name|tasks
control|)
block|{
name|byte
index|[]
name|data
init|=
name|ZKUtil
operator|.
name|getData
argument_list|(
name|this
operator|.
name|watcher
argument_list|,
name|ZKUtil
operator|.
name|joinZNode
argument_list|(
name|watcher
operator|.
name|splitLogZNode
argument_list|,
name|t
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|data
operator|!=
literal|null
condition|)
block|{
name|SplitLogTask
name|slt
init|=
literal|null
decl_stmt|;
try|try
block|{
name|slt
operator|=
name|SplitLogTask
operator|.
name|parseFrom
argument_list|(
name|data
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|DeserializationException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failed parse data for znode "
operator|+
name|t
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|slt
operator|!=
literal|null
operator|&&
name|slt
operator|.
name|isDone
argument_list|()
condition|)
block|{
continue|continue;
block|}
block|}
comment|// decode the file name
name|t
operator|=
name|ZKSplitLog
operator|.
name|getFileName
argument_list|(
name|t
argument_list|)
expr_stmt|;
name|ServerName
name|serverName
init|=
name|HLogUtil
operator|.
name|getServerNameFromHLogDirectoryName
argument_list|(
operator|new
name|Path
argument_list|(
name|t
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|serverName
operator|!=
literal|null
condition|)
block|{
name|knownFailedServers
operator|.
name|add
argument_list|(
name|serverName
operator|.
name|getServerName
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Found invalid WAL log file name:"
operator|+
name|t
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|// remove recovering regions which doesn't have any RS associated with it
name|List
argument_list|<
name|String
argument_list|>
name|regions
init|=
name|ZKUtil
operator|.
name|listChildrenNoWatch
argument_list|(
name|watcher
argument_list|,
name|watcher
operator|.
name|recoveringRegionsZNode
argument_list|)
decl_stmt|;
if|if
condition|(
name|regions
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|String
name|region
range|:
name|regions
control|)
block|{
name|String
name|nodePath
init|=
name|ZKUtil
operator|.
name|joinZNode
argument_list|(
name|watcher
operator|.
name|recoveringRegionsZNode
argument_list|,
name|region
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|String
argument_list|>
name|regionFailedServers
init|=
name|ZKUtil
operator|.
name|listChildrenNoWatch
argument_list|(
name|watcher
argument_list|,
name|nodePath
argument_list|)
decl_stmt|;
if|if
condition|(
name|regionFailedServers
operator|==
literal|null
operator|||
name|regionFailedServers
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|ZKUtil
operator|.
name|deleteNode
argument_list|(
name|watcher
argument_list|,
name|nodePath
argument_list|)
expr_stmt|;
continue|continue;
block|}
name|boolean
name|needMoreRecovery
init|=
literal|false
decl_stmt|;
for|for
control|(
name|String
name|tmpFailedServer
range|:
name|regionFailedServers
control|)
block|{
if|if
condition|(
name|knownFailedServers
operator|.
name|contains
argument_list|(
name|tmpFailedServer
argument_list|)
condition|)
block|{
name|needMoreRecovery
operator|=
literal|true
expr_stmt|;
break|break;
block|}
block|}
if|if
condition|(
operator|!
name|needMoreRecovery
condition|)
block|{
name|ZKUtil
operator|.
name|deleteNodeRecursively
argument_list|(
name|watcher
argument_list|,
name|nodePath
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
finally|finally
block|{
name|this
operator|.
name|recoveringRegionLock
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
specifier|private
name|void
name|deleteRecoveringRegionZNodes
parameter_list|(
name|List
argument_list|<
name|String
argument_list|>
name|regions
parameter_list|)
block|{
try|try
block|{
if|if
condition|(
name|regions
operator|==
literal|null
condition|)
block|{
comment|// remove all children under /home/recovering-regions
name|LOG
operator|.
name|info
argument_list|(
literal|"Garbage collecting all recovering regions."
argument_list|)
expr_stmt|;
name|ZKUtil
operator|.
name|deleteChildrenRecursively
argument_list|(
name|watcher
argument_list|,
name|watcher
operator|.
name|recoveringRegionsZNode
argument_list|)
expr_stmt|;
block|}
else|else
block|{
for|for
control|(
name|String
name|curRegion
range|:
name|regions
control|)
block|{
name|String
name|nodePath
init|=
name|ZKUtil
operator|.
name|joinZNode
argument_list|(
name|watcher
operator|.
name|recoveringRegionsZNode
argument_list|,
name|curRegion
argument_list|)
decl_stmt|;
name|ZKUtil
operator|.
name|deleteNodeRecursively
argument_list|(
name|watcher
argument_list|,
name|nodePath
argument_list|)
expr_stmt|;
block|}
block|}
block|}
catch|catch
parameter_list|(
name|KeeperException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Cannot remove recovering regions from ZooKeeper"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
block|}
specifier|private
name|void
name|setDone
parameter_list|(
name|String
name|path
parameter_list|,
name|TerminationStatus
name|status
parameter_list|)
block|{
name|Task
name|task
init|=
name|tasks
operator|.
name|get
argument_list|(
name|path
argument_list|)
decl_stmt|;
if|if
condition|(
name|task
operator|==
literal|null
condition|)
block|{
if|if
condition|(
operator|!
name|ZKSplitLog
operator|.
name|isRescanNode
argument_list|(
name|watcher
argument_list|,
name|path
argument_list|)
condition|)
block|{
name|SplitLogCounters
operator|.
name|tot_mgr_unacquired_orphan_done
operator|.
name|incrementAndGet
argument_list|()
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"unacquired orphan task is done "
operator|+
name|path
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
synchronized|synchronized
init|(
name|task
init|)
block|{
if|if
condition|(
name|task
operator|.
name|status
operator|==
name|IN_PROGRESS
condition|)
block|{
if|if
condition|(
name|status
operator|==
name|SUCCESS
condition|)
block|{
name|SplitLogCounters
operator|.
name|tot_mgr_log_split_success
operator|.
name|incrementAndGet
argument_list|()
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Done splitting "
operator|+
name|path
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|SplitLogCounters
operator|.
name|tot_mgr_log_split_err
operator|.
name|incrementAndGet
argument_list|()
expr_stmt|;
name|LOG
operator|.
name|warn
argument_list|(
literal|"Error splitting "
operator|+
name|path
argument_list|)
expr_stmt|;
block|}
name|task
operator|.
name|status
operator|=
name|status
expr_stmt|;
if|if
condition|(
name|task
operator|.
name|batch
operator|!=
literal|null
condition|)
block|{
synchronized|synchronized
init|(
name|task
operator|.
name|batch
init|)
block|{
if|if
condition|(
name|status
operator|==
name|SUCCESS
condition|)
block|{
name|task
operator|.
name|batch
operator|.
name|done
operator|++
expr_stmt|;
block|}
else|else
block|{
name|task
operator|.
name|batch
operator|.
name|error
operator|++
expr_stmt|;
block|}
name|task
operator|.
name|batch
operator|.
name|notify
argument_list|()
expr_stmt|;
block|}
block|}
block|}
block|}
block|}
comment|// delete the task node in zk. It's an async
comment|// call and no one is blocked waiting for this node to be deleted. All
comment|// task names are unique (log.<timestamp>) there is no risk of deleting
comment|// a future task.
comment|// if a deletion fails, TimeoutMonitor will retry the same deletion later
name|deleteNode
argument_list|(
name|path
argument_list|,
name|zkretries
argument_list|)
expr_stmt|;
return|return;
block|}
specifier|private
name|void
name|createNode
parameter_list|(
name|String
name|path
parameter_list|,
name|Long
name|retry_count
parameter_list|)
block|{
name|SplitLogTask
name|slt
init|=
operator|new
name|SplitLogTask
operator|.
name|Unassigned
argument_list|(
name|serverName
argument_list|)
decl_stmt|;
name|ZKUtil
operator|.
name|asyncCreate
argument_list|(
name|this
operator|.
name|watcher
argument_list|,
name|path
argument_list|,
name|slt
operator|.
name|toByteArray
argument_list|()
argument_list|,
operator|new
name|CreateAsyncCallback
argument_list|()
argument_list|,
name|retry_count
argument_list|)
expr_stmt|;
name|SplitLogCounters
operator|.
name|tot_mgr_node_create_queued
operator|.
name|incrementAndGet
argument_list|()
expr_stmt|;
return|return;
block|}
specifier|private
name|void
name|createNodeSuccess
parameter_list|(
name|String
name|path
parameter_list|)
block|{
name|lastNodeCreateTime
operator|=
name|EnvironmentEdgeManager
operator|.
name|currentTimeMillis
argument_list|()
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"put up splitlog task at znode "
operator|+
name|path
argument_list|)
expr_stmt|;
name|getDataSetWatch
argument_list|(
name|path
argument_list|,
name|zkretries
argument_list|)
expr_stmt|;
block|}
specifier|private
name|void
name|createNodeFailure
parameter_list|(
name|String
name|path
parameter_list|)
block|{
comment|// TODO the Manager should split the log locally instead of giving up
name|LOG
operator|.
name|warn
argument_list|(
literal|"failed to create task node"
operator|+
name|path
argument_list|)
expr_stmt|;
name|setDone
argument_list|(
name|path
argument_list|,
name|FAILURE
argument_list|)
expr_stmt|;
block|}
specifier|private
name|void
name|getDataSetWatch
parameter_list|(
name|String
name|path
parameter_list|,
name|Long
name|retry_count
parameter_list|)
block|{
name|this
operator|.
name|watcher
operator|.
name|getRecoverableZooKeeper
argument_list|()
operator|.
name|getZooKeeper
argument_list|()
operator|.
name|getData
argument_list|(
name|path
argument_list|,
name|this
operator|.
name|watcher
argument_list|,
operator|new
name|GetDataAsyncCallback
argument_list|()
argument_list|,
name|retry_count
argument_list|)
expr_stmt|;
name|SplitLogCounters
operator|.
name|tot_mgr_get_data_queued
operator|.
name|incrementAndGet
argument_list|()
expr_stmt|;
block|}
specifier|private
name|void
name|tryGetDataSetWatch
parameter_list|(
name|String
name|path
parameter_list|)
block|{
comment|// A negative retry count will lead to ignoring all error processing.
name|this
operator|.
name|watcher
operator|.
name|getRecoverableZooKeeper
argument_list|()
operator|.
name|getZooKeeper
argument_list|()
operator|.
name|getData
argument_list|(
name|path
argument_list|,
name|this
operator|.
name|watcher
argument_list|,
operator|new
name|GetDataAsyncCallback
argument_list|()
argument_list|,
name|Long
operator|.
name|valueOf
argument_list|(
operator|-
literal|1
argument_list|)
comment|/* retry count */
argument_list|)
expr_stmt|;
name|SplitLogCounters
operator|.
name|tot_mgr_get_data_queued
operator|.
name|incrementAndGet
argument_list|()
expr_stmt|;
block|}
specifier|private
name|void
name|getDataSetWatchSuccess
parameter_list|(
name|String
name|path
parameter_list|,
name|byte
index|[]
name|data
parameter_list|,
name|int
name|version
parameter_list|)
throws|throws
name|DeserializationException
block|{
if|if
condition|(
name|data
operator|==
literal|null
condition|)
block|{
if|if
condition|(
name|version
operator|==
name|Integer
operator|.
name|MIN_VALUE
condition|)
block|{
comment|// assume all done. The task znode suddenly disappeared.
name|setDone
argument_list|(
name|path
argument_list|,
name|SUCCESS
argument_list|)
expr_stmt|;
return|return;
block|}
name|SplitLogCounters
operator|.
name|tot_mgr_null_data
operator|.
name|incrementAndGet
argument_list|()
expr_stmt|;
name|LOG
operator|.
name|fatal
argument_list|(
literal|"logic error - got null data "
operator|+
name|path
argument_list|)
expr_stmt|;
name|setDone
argument_list|(
name|path
argument_list|,
name|FAILURE
argument_list|)
expr_stmt|;
return|return;
block|}
name|data
operator|=
name|this
operator|.
name|watcher
operator|.
name|getRecoverableZooKeeper
argument_list|()
operator|.
name|removeMetaData
argument_list|(
name|data
argument_list|)
expr_stmt|;
name|SplitLogTask
name|slt
init|=
name|SplitLogTask
operator|.
name|parseFrom
argument_list|(
name|data
argument_list|)
decl_stmt|;
if|if
condition|(
name|slt
operator|.
name|isUnassigned
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"task not yet acquired "
operator|+
name|path
operator|+
literal|" ver = "
operator|+
name|version
argument_list|)
expr_stmt|;
name|handleUnassignedTask
argument_list|(
name|path
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|slt
operator|.
name|isOwned
argument_list|()
condition|)
block|{
name|heartbeat
argument_list|(
name|path
argument_list|,
name|version
argument_list|,
name|slt
operator|.
name|getServerName
argument_list|()
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|slt
operator|.
name|isResigned
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"task "
operator|+
name|path
operator|+
literal|" entered state: "
operator|+
name|slt
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
name|resubmitOrFail
argument_list|(
name|path
argument_list|,
name|FORCE
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|slt
operator|.
name|isDone
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"task "
operator|+
name|path
operator|+
literal|" entered state: "
operator|+
name|slt
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|taskFinisher
operator|!=
literal|null
operator|&&
operator|!
name|ZKSplitLog
operator|.
name|isRescanNode
argument_list|(
name|watcher
argument_list|,
name|path
argument_list|)
condition|)
block|{
if|if
condition|(
name|taskFinisher
operator|.
name|finish
argument_list|(
name|slt
operator|.
name|getServerName
argument_list|()
argument_list|,
name|ZKSplitLog
operator|.
name|getFileName
argument_list|(
name|path
argument_list|)
argument_list|)
operator|==
name|Status
operator|.
name|DONE
condition|)
block|{
name|setDone
argument_list|(
name|path
argument_list|,
name|SUCCESS
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|resubmitOrFail
argument_list|(
name|path
argument_list|,
name|CHECK
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
name|setDone
argument_list|(
name|path
argument_list|,
name|SUCCESS
argument_list|)
expr_stmt|;
block|}
block|}
elseif|else
if|if
condition|(
name|slt
operator|.
name|isErr
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"task "
operator|+
name|path
operator|+
literal|" entered state: "
operator|+
name|slt
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
name|resubmitOrFail
argument_list|(
name|path
argument_list|,
name|CHECK
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|LOG
operator|.
name|fatal
argument_list|(
literal|"logic error - unexpected zk state for path = "
operator|+
name|path
operator|+
literal|" data = "
operator|+
name|slt
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
name|setDone
argument_list|(
name|path
argument_list|,
name|FAILURE
argument_list|)
expr_stmt|;
block|}
block|}
specifier|private
name|void
name|getDataSetWatchFailure
parameter_list|(
name|String
name|path
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"failed to set data watch "
operator|+
name|path
argument_list|)
expr_stmt|;
name|setDone
argument_list|(
name|path
argument_list|,
name|FAILURE
argument_list|)
expr_stmt|;
block|}
comment|/**    * It is possible for a task to stay in UNASSIGNED state indefinitely - say    * SplitLogManager wants to resubmit a task. It forces the task to UNASSIGNED    * state but it dies before it could create the RESCAN task node to signal    * the SplitLogWorkers to pick up the task. To prevent this scenario the    * SplitLogManager resubmits all orphan and UNASSIGNED tasks at startup.    *    * @param path    */
specifier|private
name|void
name|handleUnassignedTask
parameter_list|(
name|String
name|path
parameter_list|)
block|{
if|if
condition|(
name|ZKSplitLog
operator|.
name|isRescanNode
argument_list|(
name|watcher
argument_list|,
name|path
argument_list|)
condition|)
block|{
return|return;
block|}
name|Task
name|task
init|=
name|findOrCreateOrphanTask
argument_list|(
name|path
argument_list|)
decl_stmt|;
if|if
condition|(
name|task
operator|.
name|isOrphan
argument_list|()
operator|&&
operator|(
name|task
operator|.
name|incarnation
operator|==
literal|0
operator|)
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"resubmitting unassigned orphan task "
operator|+
name|path
argument_list|)
expr_stmt|;
comment|// ignore failure to resubmit. The timeout-monitor will handle it later
comment|// albeit in a more crude fashion
name|resubmit
argument_list|(
name|path
argument_list|,
name|task
argument_list|,
name|FORCE
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Helper function to check whether to abandon retries in ZooKeeper AsyncCallback functions    * @param statusCode integer value of a ZooKeeper exception code    * @param action description message about the retried action    * @return true when need to abandon retries otherwise false    */
specifier|private
name|boolean
name|needAbandonRetries
parameter_list|(
name|int
name|statusCode
parameter_list|,
name|String
name|action
parameter_list|)
block|{
if|if
condition|(
name|statusCode
operator|==
name|KeeperException
operator|.
name|Code
operator|.
name|SESSIONEXPIRED
operator|.
name|intValue
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"ZK session expired. Master is expected to shut down. Abandoning retries for "
operator|+
literal|"action="
operator|+
name|action
argument_list|)
expr_stmt|;
return|return
literal|true
return|;
block|}
return|return
literal|false
return|;
block|}
specifier|private
name|void
name|heartbeat
parameter_list|(
name|String
name|path
parameter_list|,
name|int
name|new_version
parameter_list|,
name|ServerName
name|workerName
parameter_list|)
block|{
name|Task
name|task
init|=
name|findOrCreateOrphanTask
argument_list|(
name|path
argument_list|)
decl_stmt|;
if|if
condition|(
name|new_version
operator|!=
name|task
operator|.
name|last_version
condition|)
block|{
if|if
condition|(
name|task
operator|.
name|isUnassigned
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"task "
operator|+
name|path
operator|+
literal|" acquired by "
operator|+
name|workerName
argument_list|)
expr_stmt|;
block|}
name|task
operator|.
name|heartbeat
argument_list|(
name|EnvironmentEdgeManager
operator|.
name|currentTimeMillis
argument_list|()
argument_list|,
name|new_version
argument_list|,
name|workerName
argument_list|)
expr_stmt|;
name|SplitLogCounters
operator|.
name|tot_mgr_heartbeat
operator|.
name|incrementAndGet
argument_list|()
expr_stmt|;
block|}
else|else
block|{
comment|// duplicate heartbeats - heartbeats w/o zk node version
comment|// changing - are possible. The timeout thread does
comment|// getDataSetWatch() just to check whether a node still
comment|// exists or not
block|}
return|return;
block|}
specifier|private
name|boolean
name|resubmit
parameter_list|(
name|String
name|path
parameter_list|,
name|Task
name|task
parameter_list|,
name|ResubmitDirective
name|directive
parameter_list|)
block|{
comment|// its ok if this thread misses the update to task.deleted. It will fail later
if|if
condition|(
name|task
operator|.
name|status
operator|!=
name|IN_PROGRESS
condition|)
block|{
return|return
literal|false
return|;
block|}
name|int
name|version
decl_stmt|;
if|if
condition|(
name|directive
operator|!=
name|FORCE
condition|)
block|{
comment|// We're going to resubmit:
comment|//  1) immediately if the worker server is now marked as dead
comment|//  2) after a configurable timeout if the server is not marked as dead but has still not
comment|//       finished the task. This allows to continue if the worker cannot actually handle it,
comment|//       for any reason.
specifier|final
name|long
name|time
init|=
name|EnvironmentEdgeManager
operator|.
name|currentTimeMillis
argument_list|()
operator|-
name|task
operator|.
name|last_update
decl_stmt|;
specifier|final
name|boolean
name|alive
init|=
name|master
operator|.
name|getServerManager
argument_list|()
operator|!=
literal|null
condition|?
name|master
operator|.
name|getServerManager
argument_list|()
operator|.
name|isServerOnline
argument_list|(
name|task
operator|.
name|cur_worker_name
argument_list|)
else|:
literal|true
decl_stmt|;
if|if
condition|(
name|alive
operator|&&
name|time
operator|<
name|timeout
condition|)
block|{
name|LOG
operator|.
name|trace
argument_list|(
literal|"Skipping the resubmit of "
operator|+
name|task
operator|.
name|toString
argument_list|()
operator|+
literal|"  because the server "
operator|+
name|task
operator|.
name|cur_worker_name
operator|+
literal|" is not marked as dead, we waited for "
operator|+
name|time
operator|+
literal|" while the timeout is "
operator|+
name|timeout
argument_list|)
expr_stmt|;
return|return
literal|false
return|;
block|}
if|if
condition|(
name|task
operator|.
name|unforcedResubmits
operator|>=
name|resubmit_threshold
condition|)
block|{
if|if
condition|(
operator|!
name|task
operator|.
name|resubmitThresholdReached
condition|)
block|{
name|task
operator|.
name|resubmitThresholdReached
operator|=
literal|true
expr_stmt|;
name|SplitLogCounters
operator|.
name|tot_mgr_resubmit_threshold_reached
operator|.
name|incrementAndGet
argument_list|()
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Skipping resubmissions of task "
operator|+
name|path
operator|+
literal|" because threshold "
operator|+
name|resubmit_threshold
operator|+
literal|" reached"
argument_list|)
expr_stmt|;
block|}
return|return
literal|false
return|;
block|}
comment|// race with heartbeat() that might be changing last_version
name|version
operator|=
name|task
operator|.
name|last_version
expr_stmt|;
block|}
else|else
block|{
name|SplitLogCounters
operator|.
name|tot_mgr_resubmit_force
operator|.
name|incrementAndGet
argument_list|()
expr_stmt|;
name|version
operator|=
operator|-
literal|1
expr_stmt|;
block|}
name|LOG
operator|.
name|info
argument_list|(
literal|"resubmitting task "
operator|+
name|path
argument_list|)
expr_stmt|;
name|task
operator|.
name|incarnation
operator|++
expr_stmt|;
try|try
block|{
comment|// blocking zk call but this is done from the timeout thread
name|SplitLogTask
name|slt
init|=
operator|new
name|SplitLogTask
operator|.
name|Unassigned
argument_list|(
name|this
operator|.
name|serverName
argument_list|)
decl_stmt|;
if|if
condition|(
name|ZKUtil
operator|.
name|setData
argument_list|(
name|this
operator|.
name|watcher
argument_list|,
name|path
argument_list|,
name|slt
operator|.
name|toByteArray
argument_list|()
argument_list|,
name|version
argument_list|)
operator|==
literal|false
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"failed to resubmit task "
operator|+
name|path
operator|+
literal|" version changed"
argument_list|)
expr_stmt|;
name|task
operator|.
name|heartbeatNoDetails
argument_list|(
name|EnvironmentEdgeManager
operator|.
name|currentTimeMillis
argument_list|()
argument_list|)
expr_stmt|;
return|return
literal|false
return|;
block|}
block|}
catch|catch
parameter_list|(
name|NoNodeException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"failed to resubmit because znode doesn't exist "
operator|+
name|path
operator|+
literal|" task done (or forced done by removing the znode)"
argument_list|)
expr_stmt|;
try|try
block|{
name|getDataSetWatchSuccess
argument_list|(
name|path
argument_list|,
literal|null
argument_list|,
name|Integer
operator|.
name|MIN_VALUE
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|DeserializationException
name|e1
parameter_list|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Failed to re-resubmit task "
operator|+
name|path
operator|+
literal|" because of deserialization issue"
argument_list|,
name|e1
argument_list|)
expr_stmt|;
name|task
operator|.
name|heartbeatNoDetails
argument_list|(
name|EnvironmentEdgeManager
operator|.
name|currentTimeMillis
argument_list|()
argument_list|)
expr_stmt|;
return|return
literal|false
return|;
block|}
return|return
literal|false
return|;
block|}
catch|catch
parameter_list|(
name|KeeperException
operator|.
name|BadVersionException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"failed to resubmit task "
operator|+
name|path
operator|+
literal|" version changed"
argument_list|)
expr_stmt|;
name|task
operator|.
name|heartbeatNoDetails
argument_list|(
name|EnvironmentEdgeManager
operator|.
name|currentTimeMillis
argument_list|()
argument_list|)
expr_stmt|;
return|return
literal|false
return|;
block|}
catch|catch
parameter_list|(
name|KeeperException
name|e
parameter_list|)
block|{
name|SplitLogCounters
operator|.
name|tot_mgr_resubmit_failed
operator|.
name|incrementAndGet
argument_list|()
expr_stmt|;
name|LOG
operator|.
name|warn
argument_list|(
literal|"failed to resubmit "
operator|+
name|path
argument_list|,
name|e
argument_list|)
expr_stmt|;
return|return
literal|false
return|;
block|}
comment|// don't count forced resubmits
if|if
condition|(
name|directive
operator|!=
name|FORCE
condition|)
block|{
name|task
operator|.
name|unforcedResubmits
operator|++
expr_stmt|;
block|}
name|task
operator|.
name|setUnassigned
argument_list|()
expr_stmt|;
name|createRescanNode
argument_list|(
name|Long
operator|.
name|MAX_VALUE
argument_list|)
expr_stmt|;
name|SplitLogCounters
operator|.
name|tot_mgr_resubmit
operator|.
name|incrementAndGet
argument_list|()
expr_stmt|;
return|return
literal|true
return|;
block|}
specifier|private
name|void
name|resubmitOrFail
parameter_list|(
name|String
name|path
parameter_list|,
name|ResubmitDirective
name|directive
parameter_list|)
block|{
if|if
condition|(
name|resubmit
argument_list|(
name|path
argument_list|,
name|findOrCreateOrphanTask
argument_list|(
name|path
argument_list|)
argument_list|,
name|directive
argument_list|)
operator|==
literal|false
condition|)
block|{
name|setDone
argument_list|(
name|path
argument_list|,
name|FAILURE
argument_list|)
expr_stmt|;
block|}
block|}
specifier|private
name|void
name|deleteNode
parameter_list|(
name|String
name|path
parameter_list|,
name|Long
name|retries
parameter_list|)
block|{
name|SplitLogCounters
operator|.
name|tot_mgr_node_delete_queued
operator|.
name|incrementAndGet
argument_list|()
expr_stmt|;
comment|// Once a task znode is ready for delete, that is it is in the TASK_DONE
comment|// state, then no one should be writing to it anymore. That is no one
comment|// will be updating the znode version any more.
name|this
operator|.
name|watcher
operator|.
name|getRecoverableZooKeeper
argument_list|()
operator|.
name|getZooKeeper
argument_list|()
operator|.
name|delete
argument_list|(
name|path
argument_list|,
operator|-
literal|1
argument_list|,
operator|new
name|DeleteAsyncCallback
argument_list|()
argument_list|,
name|retries
argument_list|)
expr_stmt|;
block|}
specifier|private
name|void
name|deleteNodeSuccess
parameter_list|(
name|String
name|path
parameter_list|)
block|{
if|if
condition|(
name|ignoreZKDeleteForTesting
condition|)
block|{
return|return;
block|}
name|Task
name|task
decl_stmt|;
name|task
operator|=
name|tasks
operator|.
name|remove
argument_list|(
name|path
argument_list|)
expr_stmt|;
if|if
condition|(
name|task
operator|==
literal|null
condition|)
block|{
if|if
condition|(
name|ZKSplitLog
operator|.
name|isRescanNode
argument_list|(
name|watcher
argument_list|,
name|path
argument_list|)
condition|)
block|{
name|SplitLogCounters
operator|.
name|tot_mgr_rescan_deleted
operator|.
name|incrementAndGet
argument_list|()
expr_stmt|;
block|}
name|SplitLogCounters
operator|.
name|tot_mgr_missing_state_in_delete
operator|.
name|incrementAndGet
argument_list|()
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"deleted task without in memory state "
operator|+
name|path
argument_list|)
expr_stmt|;
return|return;
block|}
synchronized|synchronized
init|(
name|task
init|)
block|{
name|task
operator|.
name|status
operator|=
name|DELETED
expr_stmt|;
name|task
operator|.
name|notify
argument_list|()
expr_stmt|;
block|}
name|SplitLogCounters
operator|.
name|tot_mgr_task_deleted
operator|.
name|incrementAndGet
argument_list|()
expr_stmt|;
block|}
specifier|private
name|void
name|deleteNodeFailure
parameter_list|(
name|String
name|path
parameter_list|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Failed to delete node "
operator|+
name|path
operator|+
literal|" and will retry soon."
argument_list|)
expr_stmt|;
return|return;
block|}
comment|/**    * signal the workers that a task was resubmitted by creating the    * RESCAN node.    * @throws KeeperException     */
specifier|private
name|void
name|createRescanNode
parameter_list|(
name|long
name|retries
parameter_list|)
block|{
comment|// The RESCAN node will be deleted almost immediately by the
comment|// SplitLogManager as soon as it is created because it is being
comment|// created in the DONE state. This behavior prevents a buildup
comment|// of RESCAN nodes. But there is also a chance that a SplitLogWorker
comment|// might miss the watch-trigger that creation of RESCAN node provides.
comment|// Since the TimeoutMonitor will keep resubmitting UNASSIGNED tasks
comment|// therefore this behavior is safe.
name|SplitLogTask
name|slt
init|=
operator|new
name|SplitLogTask
operator|.
name|Done
argument_list|(
name|this
operator|.
name|serverName
argument_list|)
decl_stmt|;
name|this
operator|.
name|watcher
operator|.
name|getRecoverableZooKeeper
argument_list|()
operator|.
name|getZooKeeper
argument_list|()
operator|.
name|create
argument_list|(
name|ZKSplitLog
operator|.
name|getRescanNode
argument_list|(
name|watcher
argument_list|)
argument_list|,
name|slt
operator|.
name|toByteArray
argument_list|()
argument_list|,
name|Ids
operator|.
name|OPEN_ACL_UNSAFE
argument_list|,
name|CreateMode
operator|.
name|EPHEMERAL_SEQUENTIAL
argument_list|,
operator|new
name|CreateRescanAsyncCallback
argument_list|()
argument_list|,
name|Long
operator|.
name|valueOf
argument_list|(
name|retries
argument_list|)
argument_list|)
expr_stmt|;
block|}
specifier|private
name|void
name|createRescanSuccess
parameter_list|(
name|String
name|path
parameter_list|)
block|{
name|lastNodeCreateTime
operator|=
name|EnvironmentEdgeManager
operator|.
name|currentTimeMillis
argument_list|()
expr_stmt|;
name|SplitLogCounters
operator|.
name|tot_mgr_rescan
operator|.
name|incrementAndGet
argument_list|()
expr_stmt|;
name|getDataSetWatch
argument_list|(
name|path
argument_list|,
name|zkretries
argument_list|)
expr_stmt|;
block|}
specifier|private
name|void
name|createRescanFailure
parameter_list|()
block|{
name|LOG
operator|.
name|fatal
argument_list|(
literal|"logic failure, rescan failure must not happen"
argument_list|)
expr_stmt|;
block|}
comment|/**    * @param path    * @param batch    * @return null on success, existing task on error    */
specifier|private
name|Task
name|createTaskIfAbsent
parameter_list|(
name|String
name|path
parameter_list|,
name|TaskBatch
name|batch
parameter_list|)
block|{
name|Task
name|oldtask
decl_stmt|;
comment|// batch.installed is only changed via this function and
comment|// a single thread touches batch.installed.
name|Task
name|newtask
init|=
operator|new
name|Task
argument_list|()
decl_stmt|;
name|newtask
operator|.
name|batch
operator|=
name|batch
expr_stmt|;
name|oldtask
operator|=
name|tasks
operator|.
name|putIfAbsent
argument_list|(
name|path
argument_list|,
name|newtask
argument_list|)
expr_stmt|;
if|if
condition|(
name|oldtask
operator|==
literal|null
condition|)
block|{
name|batch
operator|.
name|installed
operator|++
expr_stmt|;
return|return
literal|null
return|;
block|}
comment|// new task was not used.
synchronized|synchronized
init|(
name|oldtask
init|)
block|{
if|if
condition|(
name|oldtask
operator|.
name|isOrphan
argument_list|()
condition|)
block|{
if|if
condition|(
name|oldtask
operator|.
name|status
operator|==
name|SUCCESS
condition|)
block|{
comment|// The task is already done. Do not install the batch for this
comment|// task because it might be too late for setDone() to update
comment|// batch.done. There is no need for the batch creator to wait for
comment|// this task to complete.
return|return
operator|(
literal|null
operator|)
return|;
block|}
if|if
condition|(
name|oldtask
operator|.
name|status
operator|==
name|IN_PROGRESS
condition|)
block|{
name|oldtask
operator|.
name|batch
operator|=
name|batch
expr_stmt|;
name|batch
operator|.
name|installed
operator|++
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Previously orphan task "
operator|+
name|path
operator|+
literal|" is now being waited upon"
argument_list|)
expr_stmt|;
return|return
literal|null
return|;
block|}
while|while
condition|(
name|oldtask
operator|.
name|status
operator|==
name|FAILURE
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"wait for status of task "
operator|+
name|path
operator|+
literal|" to change to DELETED"
argument_list|)
expr_stmt|;
name|SplitLogCounters
operator|.
name|tot_mgr_wait_for_zk_delete
operator|.
name|incrementAndGet
argument_list|()
expr_stmt|;
try|try
block|{
name|oldtask
operator|.
name|wait
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|interrupt
argument_list|()
expr_stmt|;
name|LOG
operator|.
name|warn
argument_list|(
literal|"Interrupted when waiting for znode delete callback"
argument_list|)
expr_stmt|;
comment|// fall through to return failure
break|break;
block|}
block|}
if|if
condition|(
name|oldtask
operator|.
name|status
operator|!=
name|DELETED
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failure because previously failed task"
operator|+
literal|" state still present. Waiting for znode delete callback"
operator|+
literal|" path="
operator|+
name|path
argument_list|)
expr_stmt|;
return|return
name|oldtask
return|;
block|}
comment|// reinsert the newTask and it must succeed this time
name|Task
name|t
init|=
name|tasks
operator|.
name|putIfAbsent
argument_list|(
name|path
argument_list|,
name|newtask
argument_list|)
decl_stmt|;
if|if
condition|(
name|t
operator|==
literal|null
condition|)
block|{
name|batch
operator|.
name|installed
operator|++
expr_stmt|;
return|return
literal|null
return|;
block|}
name|LOG
operator|.
name|fatal
argument_list|(
literal|"Logic error. Deleted task still present in tasks map"
argument_list|)
expr_stmt|;
assert|assert
literal|false
operator|:
literal|"Deleted task still present in tasks map"
assert|;
return|return
name|t
return|;
block|}
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failure because two threads can't wait for the same task; path="
operator|+
name|path
argument_list|)
expr_stmt|;
return|return
name|oldtask
return|;
block|}
block|}
name|Task
name|findOrCreateOrphanTask
parameter_list|(
name|String
name|path
parameter_list|)
block|{
name|Task
name|orphanTask
init|=
operator|new
name|Task
argument_list|()
decl_stmt|;
name|Task
name|task
decl_stmt|;
name|task
operator|=
name|tasks
operator|.
name|putIfAbsent
argument_list|(
name|path
argument_list|,
name|orphanTask
argument_list|)
expr_stmt|;
if|if
condition|(
name|task
operator|==
literal|null
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"creating orphan task "
operator|+
name|path
argument_list|)
expr_stmt|;
name|SplitLogCounters
operator|.
name|tot_mgr_orphan_task_acquired
operator|.
name|incrementAndGet
argument_list|()
expr_stmt|;
name|task
operator|=
name|orphanTask
expr_stmt|;
block|}
return|return
name|task
return|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|nodeDataChanged
parameter_list|(
name|String
name|path
parameter_list|)
block|{
name|Task
name|task
decl_stmt|;
name|task
operator|=
name|tasks
operator|.
name|get
argument_list|(
name|path
argument_list|)
expr_stmt|;
if|if
condition|(
name|task
operator|!=
literal|null
operator|||
name|ZKSplitLog
operator|.
name|isRescanNode
argument_list|(
name|watcher
argument_list|,
name|path
argument_list|)
condition|)
block|{
if|if
condition|(
name|task
operator|!=
literal|null
condition|)
block|{
name|task
operator|.
name|heartbeatNoDetails
argument_list|(
name|EnvironmentEdgeManager
operator|.
name|currentTimeMillis
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|getDataSetWatch
argument_list|(
name|path
argument_list|,
name|zkretries
argument_list|)
expr_stmt|;
block|}
block|}
specifier|public
name|void
name|stop
parameter_list|()
block|{
if|if
condition|(
name|timeoutMonitor
operator|!=
literal|null
condition|)
block|{
name|timeoutMonitor
operator|.
name|interrupt
argument_list|()
expr_stmt|;
block|}
block|}
specifier|private
name|void
name|lookForOrphans
parameter_list|()
block|{
name|List
argument_list|<
name|String
argument_list|>
name|orphans
decl_stmt|;
try|try
block|{
name|orphans
operator|=
name|ZKUtil
operator|.
name|listChildrenNoWatch
argument_list|(
name|this
operator|.
name|watcher
argument_list|,
name|this
operator|.
name|watcher
operator|.
name|splitLogZNode
argument_list|)
expr_stmt|;
if|if
condition|(
name|orphans
operator|==
literal|null
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"could not get children of "
operator|+
name|this
operator|.
name|watcher
operator|.
name|splitLogZNode
argument_list|)
expr_stmt|;
return|return;
block|}
block|}
catch|catch
parameter_list|(
name|KeeperException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"could not get children of "
operator|+
name|this
operator|.
name|watcher
operator|.
name|splitLogZNode
operator|+
literal|" "
operator|+
name|StringUtils
operator|.
name|stringifyException
argument_list|(
name|e
argument_list|)
argument_list|)
expr_stmt|;
return|return;
block|}
name|int
name|rescan_nodes
init|=
literal|0
decl_stmt|;
for|for
control|(
name|String
name|path
range|:
name|orphans
control|)
block|{
name|String
name|nodepath
init|=
name|ZKUtil
operator|.
name|joinZNode
argument_list|(
name|watcher
operator|.
name|splitLogZNode
argument_list|,
name|path
argument_list|)
decl_stmt|;
if|if
condition|(
name|ZKSplitLog
operator|.
name|isRescanNode
argument_list|(
name|watcher
argument_list|,
name|nodepath
argument_list|)
condition|)
block|{
name|rescan_nodes
operator|++
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"found orphan rescan node "
operator|+
name|path
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"found orphan task "
operator|+
name|path
argument_list|)
expr_stmt|;
block|}
name|getDataSetWatch
argument_list|(
name|nodepath
argument_list|,
name|zkretries
argument_list|)
expr_stmt|;
block|}
name|LOG
operator|.
name|info
argument_list|(
literal|"Found "
operator|+
operator|(
name|orphans
operator|.
name|size
argument_list|()
operator|-
name|rescan_nodes
operator|)
operator|+
literal|" orphan tasks and "
operator|+
name|rescan_nodes
operator|+
literal|" rescan nodes"
argument_list|)
expr_stmt|;
block|}
comment|/**    * Create znodes /hbase/recovering-regions/[region_ids...]/[failed region server names ...] for    * all regions of the passed in region servers    * @param serverName the name of a region server    * @param userRegions user regiones assigned on the region server    */
name|void
name|markRegionsRecoveringInZK
parameter_list|(
specifier|final
name|ServerName
name|serverName
parameter_list|,
name|Set
argument_list|<
name|HRegionInfo
argument_list|>
name|userRegions
parameter_list|)
throws|throws
name|KeeperException
block|{
if|if
condition|(
name|userRegions
operator|==
literal|null
operator|||
operator|!
name|this
operator|.
name|distributedLogReplay
condition|)
block|{
return|return;
block|}
try|try
block|{
name|this
operator|.
name|recoveringRegionLock
operator|.
name|lock
argument_list|()
expr_stmt|;
comment|// mark that we're creating recovering znodes
name|this
operator|.
name|lastRecoveringNodeCreationTime
operator|=
name|EnvironmentEdgeManager
operator|.
name|currentTimeMillis
argument_list|()
expr_stmt|;
for|for
control|(
name|HRegionInfo
name|region
range|:
name|userRegions
control|)
block|{
name|String
name|regionEncodeName
init|=
name|region
operator|.
name|getEncodedName
argument_list|()
decl_stmt|;
name|long
name|retries
init|=
name|this
operator|.
name|zkretries
decl_stmt|;
do|do
block|{
name|String
name|nodePath
init|=
name|ZKUtil
operator|.
name|joinZNode
argument_list|(
name|watcher
operator|.
name|recoveringRegionsZNode
argument_list|,
name|regionEncodeName
argument_list|)
decl_stmt|;
name|long
name|lastRecordedFlushedSequenceId
init|=
operator|-
literal|1
decl_stmt|;
try|try
block|{
name|long
name|lastSequenceId
init|=
name|this
operator|.
name|master
operator|.
name|getServerManager
argument_list|()
operator|.
name|getLastFlushedSequenceId
argument_list|(
name|regionEncodeName
operator|.
name|getBytes
argument_list|()
argument_list|)
decl_stmt|;
comment|/*              * znode layout: .../region_id[last known flushed sequence id]/failed server[last known              * flushed sequence id for the server]              */
name|byte
index|[]
name|data
init|=
name|ZKUtil
operator|.
name|getData
argument_list|(
name|this
operator|.
name|watcher
argument_list|,
name|nodePath
argument_list|)
decl_stmt|;
if|if
condition|(
name|data
operator|==
literal|null
condition|)
block|{
name|ZKUtil
operator|.
name|createSetData
argument_list|(
name|this
operator|.
name|watcher
argument_list|,
name|nodePath
argument_list|,
name|ZKUtil
operator|.
name|positionToByteArray
argument_list|(
name|lastSequenceId
argument_list|)
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|lastRecordedFlushedSequenceId
operator|=
name|SplitLogManager
operator|.
name|parseLastFlushedSequenceIdFrom
argument_list|(
name|data
argument_list|)
expr_stmt|;
if|if
condition|(
name|lastRecordedFlushedSequenceId
operator|<
name|lastSequenceId
condition|)
block|{
comment|// update last flushed sequence id in the region level
name|ZKUtil
operator|.
name|setData
argument_list|(
name|this
operator|.
name|watcher
argument_list|,
name|nodePath
argument_list|,
name|ZKUtil
operator|.
name|positionToByteArray
argument_list|(
name|lastSequenceId
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
comment|// go one level deeper with server name
name|nodePath
operator|=
name|ZKUtil
operator|.
name|joinZNode
argument_list|(
name|nodePath
argument_list|,
name|serverName
operator|.
name|getServerName
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|lastSequenceId
operator|<=
name|lastRecordedFlushedSequenceId
condition|)
block|{
comment|// the newly assigned RS failed even before any flush to the region
name|lastSequenceId
operator|=
name|lastRecordedFlushedSequenceId
expr_stmt|;
block|}
name|ZKUtil
operator|.
name|createSetData
argument_list|(
name|this
operator|.
name|watcher
argument_list|,
name|nodePath
argument_list|,
name|ZKUtil
operator|.
name|regionSequenceIdsToByteArray
argument_list|(
name|lastSequenceId
argument_list|,
literal|null
argument_list|)
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Mark region "
operator|+
name|regionEncodeName
operator|+
literal|" recovering from failed region server "
operator|+
name|serverName
argument_list|)
expr_stmt|;
comment|// break retry loop
break|break;
block|}
catch|catch
parameter_list|(
name|KeeperException
name|e
parameter_list|)
block|{
comment|// ignore ZooKeeper exceptions inside retry loop
if|if
condition|(
name|retries
operator|<=
literal|1
condition|)
block|{
throw|throw
name|e
throw|;
block|}
comment|// wait a little bit for retry
try|try
block|{
name|Thread
operator|.
name|sleep
argument_list|(
literal|20
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|ignoreE
parameter_list|)
block|{
comment|// ignore
block|}
block|}
block|}
do|while
condition|(
operator|(
operator|--
name|retries
operator|)
operator|>
literal|0
operator|&&
operator|(
operator|!
name|this
operator|.
name|stopper
operator|.
name|isStopped
argument_list|()
operator|)
condition|)
do|;
block|}
block|}
finally|finally
block|{
name|this
operator|.
name|recoveringRegionLock
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**    * @param bytes - Content of a failed region server or recovering region znode.    * @return long - The last flushed sequence Id for the region server    */
specifier|public
specifier|static
name|long
name|parseLastFlushedSequenceIdFrom
parameter_list|(
specifier|final
name|byte
index|[]
name|bytes
parameter_list|)
block|{
name|long
name|lastRecordedFlushedSequenceId
init|=
operator|-
literal|1l
decl_stmt|;
try|try
block|{
name|lastRecordedFlushedSequenceId
operator|=
name|ZKUtil
operator|.
name|parseHLogPositionFrom
argument_list|(
name|bytes
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|DeserializationException
name|e
parameter_list|)
block|{
name|lastRecordedFlushedSequenceId
operator|=
operator|-
literal|1l
expr_stmt|;
name|LOG
operator|.
name|warn
argument_list|(
literal|"Can't parse last flushed sequence Id"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
return|return
name|lastRecordedFlushedSequenceId
return|;
block|}
comment|/**    * check if /hbase/recovering-regions/<current region encoded name> exists. Returns true if exists    * and set watcher as well.    * @param zkw    * @param regionEncodedName region encode name    * @return true when /hbase/recovering-regions/<current region encoded name> exists    * @throws KeeperException    */
specifier|public
specifier|static
name|boolean
name|isRegionMarkedRecoveringInZK
parameter_list|(
name|ZooKeeperWatcher
name|zkw
parameter_list|,
name|String
name|regionEncodedName
parameter_list|)
throws|throws
name|KeeperException
block|{
name|boolean
name|result
init|=
literal|false
decl_stmt|;
name|String
name|nodePath
init|=
name|ZKUtil
operator|.
name|joinZNode
argument_list|(
name|zkw
operator|.
name|recoveringRegionsZNode
argument_list|,
name|regionEncodedName
argument_list|)
decl_stmt|;
name|byte
index|[]
name|node
init|=
name|ZKUtil
operator|.
name|getDataAndWatch
argument_list|(
name|zkw
argument_list|,
name|nodePath
argument_list|)
decl_stmt|;
if|if
condition|(
name|node
operator|!=
literal|null
condition|)
block|{
name|result
operator|=
literal|true
expr_stmt|;
block|}
return|return
name|result
return|;
block|}
comment|/**    * This function is used in distributedLogReplay to fetch last flushed sequence id from ZK    * @param zkw    * @param serverName    * @param encodedRegionName    * @return the last flushed sequence ids recorded in ZK of the region for<code>serverName<code>    * @throws IOException    */
specifier|public
specifier|static
name|RegionStoreSequenceIds
name|getRegionFlushedSequenceId
parameter_list|(
name|ZooKeeperWatcher
name|zkw
parameter_list|,
name|String
name|serverName
parameter_list|,
name|String
name|encodedRegionName
parameter_list|)
throws|throws
name|IOException
block|{
comment|// when SplitLogWorker recovers a region by directly replaying unflushed WAL edits,
comment|// last flushed sequence Id changes when newly assigned RS flushes writes to the region.
comment|// If the newly assigned RS fails again(a chained RS failures scenario), the last flushed
comment|// sequence Id name space (sequence Id only valid for a particular RS instance), changes
comment|// when different newly assigned RS flushes the region.
comment|// Therefore, in this mode we need to fetch last sequence Ids from ZK where we keep history of
comment|// last flushed sequence Id for each failed RS instance.
name|RegionStoreSequenceIds
name|result
init|=
literal|null
decl_stmt|;
name|String
name|nodePath
init|=
name|ZKUtil
operator|.
name|joinZNode
argument_list|(
name|zkw
operator|.
name|recoveringRegionsZNode
argument_list|,
name|encodedRegionName
argument_list|)
decl_stmt|;
name|nodePath
operator|=
name|ZKUtil
operator|.
name|joinZNode
argument_list|(
name|nodePath
argument_list|,
name|serverName
argument_list|)
expr_stmt|;
try|try
block|{
name|byte
index|[]
name|data
init|=
name|ZKUtil
operator|.
name|getData
argument_list|(
name|zkw
argument_list|,
name|nodePath
argument_list|)
decl_stmt|;
if|if
condition|(
name|data
operator|!=
literal|null
condition|)
block|{
name|result
operator|=
name|ZKUtil
operator|.
name|parseRegionStoreSequenceIds
argument_list|(
name|data
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|KeeperException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Cannot get lastFlushedSequenceId from ZooKeeper for server="
operator|+
name|serverName
operator|+
literal|"; region="
operator|+
name|encodedRegionName
argument_list|,
name|e
argument_list|)
throw|;
block|}
catch|catch
parameter_list|(
name|DeserializationException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Can't parse last flushed sequence Id from znode:"
operator|+
name|nodePath
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
return|return
name|result
return|;
block|}
comment|/**    * Keeps track of the batch of tasks submitted together by a caller in splitLogDistributed().    * Clients threads use this object to wait for all their tasks to be done.    *<p>    * All access is synchronized.    */
specifier|static
class|class
name|TaskBatch
block|{
name|int
name|installed
init|=
literal|0
decl_stmt|;
name|int
name|done
init|=
literal|0
decl_stmt|;
name|int
name|error
init|=
literal|0
decl_stmt|;
specifier|volatile
name|boolean
name|isDead
init|=
literal|false
decl_stmt|;
annotation|@
name|Override
specifier|public
name|String
name|toString
parameter_list|()
block|{
return|return
operator|(
literal|"installed = "
operator|+
name|installed
operator|+
literal|" done = "
operator|+
name|done
operator|+
literal|" error = "
operator|+
name|error
operator|)
return|;
block|}
block|}
comment|/**    * in memory state of an active task.    */
specifier|static
class|class
name|Task
block|{
specifier|volatile
name|long
name|last_update
decl_stmt|;
specifier|volatile
name|int
name|last_version
decl_stmt|;
specifier|volatile
name|ServerName
name|cur_worker_name
decl_stmt|;
specifier|volatile
name|TaskBatch
name|batch
decl_stmt|;
specifier|volatile
name|TerminationStatus
name|status
decl_stmt|;
specifier|volatile
name|int
name|incarnation
decl_stmt|;
specifier|volatile
name|int
name|unforcedResubmits
decl_stmt|;
specifier|volatile
name|boolean
name|resubmitThresholdReached
decl_stmt|;
annotation|@
name|Override
specifier|public
name|String
name|toString
parameter_list|()
block|{
return|return
operator|(
literal|"last_update = "
operator|+
name|last_update
operator|+
literal|" last_version = "
operator|+
name|last_version
operator|+
literal|" cur_worker_name = "
operator|+
name|cur_worker_name
operator|+
literal|" status = "
operator|+
name|status
operator|+
literal|" incarnation = "
operator|+
name|incarnation
operator|+
literal|" resubmits = "
operator|+
name|unforcedResubmits
operator|+
literal|" batch = "
operator|+
name|batch
operator|)
return|;
block|}
name|Task
parameter_list|()
block|{
name|incarnation
operator|=
literal|0
expr_stmt|;
name|last_version
operator|=
operator|-
literal|1
expr_stmt|;
name|status
operator|=
name|IN_PROGRESS
expr_stmt|;
name|setUnassigned
argument_list|()
expr_stmt|;
block|}
specifier|public
name|boolean
name|isOrphan
parameter_list|()
block|{
return|return
operator|(
name|batch
operator|==
literal|null
operator|||
name|batch
operator|.
name|isDead
operator|)
return|;
block|}
specifier|public
name|boolean
name|isUnassigned
parameter_list|()
block|{
return|return
operator|(
name|cur_worker_name
operator|==
literal|null
operator|)
return|;
block|}
specifier|public
name|void
name|heartbeatNoDetails
parameter_list|(
name|long
name|time
parameter_list|)
block|{
name|last_update
operator|=
name|time
expr_stmt|;
block|}
specifier|public
name|void
name|heartbeat
parameter_list|(
name|long
name|time
parameter_list|,
name|int
name|version
parameter_list|,
name|ServerName
name|worker
parameter_list|)
block|{
name|last_version
operator|=
name|version
expr_stmt|;
name|last_update
operator|=
name|time
expr_stmt|;
name|cur_worker_name
operator|=
name|worker
expr_stmt|;
block|}
specifier|public
name|void
name|setUnassigned
parameter_list|()
block|{
name|cur_worker_name
operator|=
literal|null
expr_stmt|;
name|last_update
operator|=
operator|-
literal|1
expr_stmt|;
block|}
block|}
name|void
name|handleDeadWorker
parameter_list|(
name|ServerName
name|workerName
parameter_list|)
block|{
comment|// resubmit the tasks on the TimeoutMonitor thread. Makes it easier
comment|// to reason about concurrency. Makes it easier to retry.
synchronized|synchronized
init|(
name|deadWorkersLock
init|)
block|{
if|if
condition|(
name|deadWorkers
operator|==
literal|null
condition|)
block|{
name|deadWorkers
operator|=
operator|new
name|HashSet
argument_list|<
name|ServerName
argument_list|>
argument_list|(
literal|100
argument_list|)
expr_stmt|;
block|}
name|deadWorkers
operator|.
name|add
argument_list|(
name|workerName
argument_list|)
expr_stmt|;
block|}
name|LOG
operator|.
name|info
argument_list|(
literal|"dead splitlog worker "
operator|+
name|workerName
argument_list|)
expr_stmt|;
block|}
name|void
name|handleDeadWorkers
parameter_list|(
name|Set
argument_list|<
name|ServerName
argument_list|>
name|serverNames
parameter_list|)
block|{
synchronized|synchronized
init|(
name|deadWorkersLock
init|)
block|{
if|if
condition|(
name|deadWorkers
operator|==
literal|null
condition|)
block|{
name|deadWorkers
operator|=
operator|new
name|HashSet
argument_list|<
name|ServerName
argument_list|>
argument_list|(
literal|100
argument_list|)
expr_stmt|;
block|}
name|deadWorkers
operator|.
name|addAll
argument_list|(
name|serverNames
argument_list|)
expr_stmt|;
block|}
name|LOG
operator|.
name|info
argument_list|(
literal|"dead splitlog workers "
operator|+
name|serverNames
argument_list|)
expr_stmt|;
block|}
comment|/**    * Periodically checks all active tasks and resubmits the ones that have timed    * out    */
specifier|private
class|class
name|TimeoutMonitor
extends|extends
name|Chore
block|{
specifier|private
name|long
name|lastLog
init|=
literal|0
decl_stmt|;
specifier|public
name|TimeoutMonitor
parameter_list|(
specifier|final
name|int
name|period
parameter_list|,
name|Stoppable
name|stopper
parameter_list|)
block|{
name|super
argument_list|(
literal|"SplitLogManager Timeout Monitor"
argument_list|,
name|period
argument_list|,
name|stopper
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|protected
name|void
name|chore
parameter_list|()
block|{
name|int
name|resubmitted
init|=
literal|0
decl_stmt|;
name|int
name|unassigned
init|=
literal|0
decl_stmt|;
name|int
name|tot
init|=
literal|0
decl_stmt|;
name|boolean
name|found_assigned_task
init|=
literal|false
decl_stmt|;
name|Set
argument_list|<
name|ServerName
argument_list|>
name|localDeadWorkers
decl_stmt|;
synchronized|synchronized
init|(
name|deadWorkersLock
init|)
block|{
name|localDeadWorkers
operator|=
name|deadWorkers
expr_stmt|;
name|deadWorkers
operator|=
literal|null
expr_stmt|;
block|}
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|String
argument_list|,
name|Task
argument_list|>
name|e
range|:
name|tasks
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|String
name|path
init|=
name|e
operator|.
name|getKey
argument_list|()
decl_stmt|;
name|Task
name|task
init|=
name|e
operator|.
name|getValue
argument_list|()
decl_stmt|;
name|ServerName
name|cur_worker
init|=
name|task
operator|.
name|cur_worker_name
decl_stmt|;
name|tot
operator|++
expr_stmt|;
comment|// don't easily resubmit a task which hasn't been picked up yet. It
comment|// might be a long while before a SplitLogWorker is free to pick up a
comment|// task. This is because a SplitLogWorker picks up a task one at a
comment|// time. If we want progress when there are no region servers then we
comment|// will have to run a SplitLogWorker thread in the Master.
if|if
condition|(
name|task
operator|.
name|isUnassigned
argument_list|()
condition|)
block|{
name|unassigned
operator|++
expr_stmt|;
continue|continue;
block|}
name|found_assigned_task
operator|=
literal|true
expr_stmt|;
if|if
condition|(
name|localDeadWorkers
operator|!=
literal|null
operator|&&
name|localDeadWorkers
operator|.
name|contains
argument_list|(
name|cur_worker
argument_list|)
condition|)
block|{
name|SplitLogCounters
operator|.
name|tot_mgr_resubmit_dead_server_task
operator|.
name|incrementAndGet
argument_list|()
expr_stmt|;
if|if
condition|(
name|resubmit
argument_list|(
name|path
argument_list|,
name|task
argument_list|,
name|FORCE
argument_list|)
condition|)
block|{
name|resubmitted
operator|++
expr_stmt|;
block|}
else|else
block|{
name|handleDeadWorker
argument_list|(
name|cur_worker
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failed to resubmit task "
operator|+
name|path
operator|+
literal|" owned by dead "
operator|+
name|cur_worker
operator|+
literal|", will retry."
argument_list|)
expr_stmt|;
block|}
block|}
elseif|else
if|if
condition|(
name|resubmit
argument_list|(
name|path
argument_list|,
name|task
argument_list|,
name|CHECK
argument_list|)
condition|)
block|{
name|resubmitted
operator|++
expr_stmt|;
block|}
block|}
if|if
condition|(
name|tot
operator|>
literal|0
condition|)
block|{
name|long
name|now
init|=
name|EnvironmentEdgeManager
operator|.
name|currentTimeMillis
argument_list|()
decl_stmt|;
if|if
condition|(
name|now
operator|>
name|lastLog
operator|+
literal|5000
condition|)
block|{
name|lastLog
operator|=
name|now
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"total tasks = "
operator|+
name|tot
operator|+
literal|" unassigned = "
operator|+
name|unassigned
operator|+
literal|" tasks="
operator|+
name|tasks
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|resubmitted
operator|>
literal|0
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"resubmitted "
operator|+
name|resubmitted
operator|+
literal|" out of "
operator|+
name|tot
operator|+
literal|" tasks"
argument_list|)
expr_stmt|;
block|}
comment|// If there are pending tasks and all of them have been unassigned for
comment|// some time then put up a RESCAN node to ping the workers.
comment|// ZKSplitlog.DEFAULT_UNASSIGNED_TIMEOUT is of the order of minutes
comment|// because a. it is very unlikely that every worker had a
comment|// transient error when trying to grab the task b. if there are no
comment|// workers then all tasks wills stay unassigned indefinitely and the
comment|// manager will be indefinitely creating RESCAN nodes. TODO may be the
comment|// master should spawn both a manager and a worker thread to guarantee
comment|// that there is always one worker in the system
if|if
condition|(
name|tot
operator|>
literal|0
operator|&&
operator|!
name|found_assigned_task
operator|&&
operator|(
operator|(
name|EnvironmentEdgeManager
operator|.
name|currentTimeMillis
argument_list|()
operator|-
name|lastNodeCreateTime
operator|)
operator|>
name|unassignedTimeout
operator|)
condition|)
block|{
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|String
argument_list|,
name|Task
argument_list|>
name|e
range|:
name|tasks
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|String
name|path
init|=
name|e
operator|.
name|getKey
argument_list|()
decl_stmt|;
name|Task
name|task
init|=
name|e
operator|.
name|getValue
argument_list|()
decl_stmt|;
comment|// we have to do task.isUnassigned() check again because tasks might
comment|// have been asynchronously assigned. There is no locking required
comment|// for these checks ... it is OK even if tryGetDataSetWatch() is
comment|// called unnecessarily for a task
if|if
condition|(
name|task
operator|.
name|isUnassigned
argument_list|()
operator|&&
operator|(
name|task
operator|.
name|status
operator|!=
name|FAILURE
operator|)
condition|)
block|{
comment|// We just touch the znode to make sure its still there
name|tryGetDataSetWatch
argument_list|(
name|path
argument_list|)
expr_stmt|;
block|}
block|}
name|createRescanNode
argument_list|(
name|Long
operator|.
name|MAX_VALUE
argument_list|)
expr_stmt|;
name|SplitLogCounters
operator|.
name|tot_mgr_resubmit_unassigned
operator|.
name|incrementAndGet
argument_list|()
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"resubmitting unassigned task(s) after timeout"
argument_list|)
expr_stmt|;
block|}
comment|// Retry previously failed deletes
if|if
condition|(
name|failedDeletions
operator|.
name|size
argument_list|()
operator|>
literal|0
condition|)
block|{
name|List
argument_list|<
name|String
argument_list|>
name|tmpPaths
init|=
operator|new
name|ArrayList
argument_list|<
name|String
argument_list|>
argument_list|(
name|failedDeletions
argument_list|)
decl_stmt|;
for|for
control|(
name|String
name|tmpPath
range|:
name|tmpPaths
control|)
block|{
comment|// deleteNode is an async call
name|deleteNode
argument_list|(
name|tmpPath
argument_list|,
name|zkretries
argument_list|)
expr_stmt|;
block|}
name|failedDeletions
operator|.
name|removeAll
argument_list|(
name|tmpPaths
argument_list|)
expr_stmt|;
block|}
comment|// Garbage collect left-over /hbase/recovering-regions/... znode
name|long
name|timeInterval
init|=
name|EnvironmentEdgeManager
operator|.
name|currentTimeMillis
argument_list|()
operator|-
name|lastRecoveringNodeCreationTime
decl_stmt|;
if|if
condition|(
operator|!
name|failedRecoveringRegionDeletions
operator|.
name|isEmpty
argument_list|()
operator|||
operator|(
name|tot
operator|==
literal|0
operator|&&
name|tasks
operator|.
name|size
argument_list|()
operator|==
literal|0
operator|&&
operator|(
name|timeInterval
operator|>
name|checkRecoveringTimeThreshold
operator|)
operator|)
condition|)
block|{
comment|// inside the function there have more checks before GC anything
if|if
condition|(
operator|!
name|failedRecoveringRegionDeletions
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|List
argument_list|<
name|Pair
argument_list|<
name|Set
argument_list|<
name|ServerName
argument_list|>
argument_list|,
name|Boolean
argument_list|>
argument_list|>
name|previouslyFailedDeletions
init|=
operator|new
name|ArrayList
argument_list|<
name|Pair
argument_list|<
name|Set
argument_list|<
name|ServerName
argument_list|>
argument_list|,
name|Boolean
argument_list|>
argument_list|>
argument_list|(
name|failedRecoveringRegionDeletions
argument_list|)
decl_stmt|;
name|failedRecoveringRegionDeletions
operator|.
name|removeAll
argument_list|(
name|previouslyFailedDeletions
argument_list|)
expr_stmt|;
for|for
control|(
name|Pair
argument_list|<
name|Set
argument_list|<
name|ServerName
argument_list|>
argument_list|,
name|Boolean
argument_list|>
name|failedDeletion
range|:
name|previouslyFailedDeletions
control|)
block|{
name|removeRecoveringRegionsFromZK
argument_list|(
name|failedDeletion
operator|.
name|getFirst
argument_list|()
argument_list|,
name|failedDeletion
operator|.
name|getSecond
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
name|removeRecoveringRegionsFromZK
argument_list|(
literal|null
argument_list|,
literal|null
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
comment|/**    * Asynchronous handler for zk create node results.    * Retries on failures.    */
class|class
name|CreateAsyncCallback
implements|implements
name|AsyncCallback
operator|.
name|StringCallback
block|{
specifier|private
specifier|final
name|Log
name|LOG
init|=
name|LogFactory
operator|.
name|getLog
argument_list|(
name|CreateAsyncCallback
operator|.
name|class
argument_list|)
decl_stmt|;
annotation|@
name|Override
specifier|public
name|void
name|processResult
parameter_list|(
name|int
name|rc
parameter_list|,
name|String
name|path
parameter_list|,
name|Object
name|ctx
parameter_list|,
name|String
name|name
parameter_list|)
block|{
name|SplitLogCounters
operator|.
name|tot_mgr_node_create_result
operator|.
name|incrementAndGet
argument_list|()
expr_stmt|;
if|if
condition|(
name|rc
operator|!=
literal|0
condition|)
block|{
if|if
condition|(
name|needAbandonRetries
argument_list|(
name|rc
argument_list|,
literal|"Create znode "
operator|+
name|path
argument_list|)
condition|)
block|{
name|createNodeFailure
argument_list|(
name|path
argument_list|)
expr_stmt|;
return|return;
block|}
if|if
condition|(
name|rc
operator|==
name|KeeperException
operator|.
name|Code
operator|.
name|NODEEXISTS
operator|.
name|intValue
argument_list|()
condition|)
block|{
comment|// What if there is a delete pending against this pre-existing
comment|// znode? Then this soon-to-be-deleted task znode must be in TASK_DONE
comment|// state. Only operations that will be carried out on this node by
comment|// this manager are get-znode-data, task-finisher and delete-znode.
comment|// And all code pieces correctly handle the case of suddenly
comment|// disappearing task-znode.
name|LOG
operator|.
name|debug
argument_list|(
literal|"found pre-existing znode "
operator|+
name|path
argument_list|)
expr_stmt|;
name|SplitLogCounters
operator|.
name|tot_mgr_node_already_exists
operator|.
name|incrementAndGet
argument_list|()
expr_stmt|;
block|}
else|else
block|{
name|Long
name|retry_count
init|=
operator|(
name|Long
operator|)
name|ctx
decl_stmt|;
name|LOG
operator|.
name|warn
argument_list|(
literal|"create rc ="
operator|+
name|KeeperException
operator|.
name|Code
operator|.
name|get
argument_list|(
name|rc
argument_list|)
operator|+
literal|" for "
operator|+
name|path
operator|+
literal|" remaining retries="
operator|+
name|retry_count
argument_list|)
expr_stmt|;
if|if
condition|(
name|retry_count
operator|==
literal|0
condition|)
block|{
name|SplitLogCounters
operator|.
name|tot_mgr_node_create_err
operator|.
name|incrementAndGet
argument_list|()
expr_stmt|;
name|createNodeFailure
argument_list|(
name|path
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|SplitLogCounters
operator|.
name|tot_mgr_node_create_retry
operator|.
name|incrementAndGet
argument_list|()
expr_stmt|;
name|createNode
argument_list|(
name|path
argument_list|,
name|retry_count
operator|-
literal|1
argument_list|)
expr_stmt|;
block|}
return|return;
block|}
block|}
name|createNodeSuccess
argument_list|(
name|path
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Asynchronous handler for zk get-data-set-watch on node results.    * Retries on failures.    */
class|class
name|GetDataAsyncCallback
implements|implements
name|AsyncCallback
operator|.
name|DataCallback
block|{
specifier|private
specifier|final
name|Log
name|LOG
init|=
name|LogFactory
operator|.
name|getLog
argument_list|(
name|GetDataAsyncCallback
operator|.
name|class
argument_list|)
decl_stmt|;
annotation|@
name|Override
specifier|public
name|void
name|processResult
parameter_list|(
name|int
name|rc
parameter_list|,
name|String
name|path
parameter_list|,
name|Object
name|ctx
parameter_list|,
name|byte
index|[]
name|data
parameter_list|,
name|Stat
name|stat
parameter_list|)
block|{
name|SplitLogCounters
operator|.
name|tot_mgr_get_data_result
operator|.
name|incrementAndGet
argument_list|()
expr_stmt|;
if|if
condition|(
name|rc
operator|!=
literal|0
condition|)
block|{
if|if
condition|(
name|needAbandonRetries
argument_list|(
name|rc
argument_list|,
literal|"GetData from znode "
operator|+
name|path
argument_list|)
condition|)
block|{
return|return;
block|}
if|if
condition|(
name|rc
operator|==
name|KeeperException
operator|.
name|Code
operator|.
name|NONODE
operator|.
name|intValue
argument_list|()
condition|)
block|{
name|SplitLogCounters
operator|.
name|tot_mgr_get_data_nonode
operator|.
name|incrementAndGet
argument_list|()
expr_stmt|;
comment|// The task znode has been deleted. Must be some pending delete
comment|// that deleted the task. Assume success because a task-znode is
comment|// is only deleted after TaskFinisher is successful.
name|LOG
operator|.
name|warn
argument_list|(
literal|"task znode "
operator|+
name|path
operator|+
literal|" vanished."
argument_list|)
expr_stmt|;
try|try
block|{
name|getDataSetWatchSuccess
argument_list|(
name|path
argument_list|,
literal|null
argument_list|,
name|Integer
operator|.
name|MIN_VALUE
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|DeserializationException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Deserialization problem"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
return|return;
block|}
name|Long
name|retry_count
init|=
operator|(
name|Long
operator|)
name|ctx
decl_stmt|;
if|if
condition|(
name|retry_count
operator|<
literal|0
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"getdata rc = "
operator|+
name|KeeperException
operator|.
name|Code
operator|.
name|get
argument_list|(
name|rc
argument_list|)
operator|+
literal|" "
operator|+
name|path
operator|+
literal|". Ignoring error. No error handling. No retrying."
argument_list|)
expr_stmt|;
return|return;
block|}
name|LOG
operator|.
name|warn
argument_list|(
literal|"getdata rc = "
operator|+
name|KeeperException
operator|.
name|Code
operator|.
name|get
argument_list|(
name|rc
argument_list|)
operator|+
literal|" "
operator|+
name|path
operator|+
literal|" remaining retries="
operator|+
name|retry_count
argument_list|)
expr_stmt|;
if|if
condition|(
name|retry_count
operator|==
literal|0
condition|)
block|{
name|SplitLogCounters
operator|.
name|tot_mgr_get_data_err
operator|.
name|incrementAndGet
argument_list|()
expr_stmt|;
name|getDataSetWatchFailure
argument_list|(
name|path
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|SplitLogCounters
operator|.
name|tot_mgr_get_data_retry
operator|.
name|incrementAndGet
argument_list|()
expr_stmt|;
name|getDataSetWatch
argument_list|(
name|path
argument_list|,
name|retry_count
operator|-
literal|1
argument_list|)
expr_stmt|;
block|}
return|return;
block|}
try|try
block|{
name|getDataSetWatchSuccess
argument_list|(
name|path
argument_list|,
name|data
argument_list|,
name|stat
operator|.
name|getVersion
argument_list|()
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|DeserializationException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Deserialization problem"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
return|return;
block|}
block|}
comment|/**    * Asynchronous handler for zk delete node results.    * Retries on failures.    */
class|class
name|DeleteAsyncCallback
implements|implements
name|AsyncCallback
operator|.
name|VoidCallback
block|{
specifier|private
specifier|final
name|Log
name|LOG
init|=
name|LogFactory
operator|.
name|getLog
argument_list|(
name|DeleteAsyncCallback
operator|.
name|class
argument_list|)
decl_stmt|;
annotation|@
name|Override
specifier|public
name|void
name|processResult
parameter_list|(
name|int
name|rc
parameter_list|,
name|String
name|path
parameter_list|,
name|Object
name|ctx
parameter_list|)
block|{
name|SplitLogCounters
operator|.
name|tot_mgr_node_delete_result
operator|.
name|incrementAndGet
argument_list|()
expr_stmt|;
if|if
condition|(
name|rc
operator|!=
literal|0
condition|)
block|{
if|if
condition|(
name|needAbandonRetries
argument_list|(
name|rc
argument_list|,
literal|"Delete znode "
operator|+
name|path
argument_list|)
condition|)
block|{
name|failedDeletions
operator|.
name|add
argument_list|(
name|path
argument_list|)
expr_stmt|;
return|return;
block|}
if|if
condition|(
name|rc
operator|!=
name|KeeperException
operator|.
name|Code
operator|.
name|NONODE
operator|.
name|intValue
argument_list|()
condition|)
block|{
name|SplitLogCounters
operator|.
name|tot_mgr_node_delete_err
operator|.
name|incrementAndGet
argument_list|()
expr_stmt|;
name|Long
name|retry_count
init|=
operator|(
name|Long
operator|)
name|ctx
decl_stmt|;
name|LOG
operator|.
name|warn
argument_list|(
literal|"delete rc="
operator|+
name|KeeperException
operator|.
name|Code
operator|.
name|get
argument_list|(
name|rc
argument_list|)
operator|+
literal|" for "
operator|+
name|path
operator|+
literal|" remaining retries="
operator|+
name|retry_count
argument_list|)
expr_stmt|;
if|if
condition|(
name|retry_count
operator|==
literal|0
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"delete failed "
operator|+
name|path
argument_list|)
expr_stmt|;
name|failedDeletions
operator|.
name|add
argument_list|(
name|path
argument_list|)
expr_stmt|;
name|deleteNodeFailure
argument_list|(
name|path
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|deleteNode
argument_list|(
name|path
argument_list|,
name|retry_count
operator|-
literal|1
argument_list|)
expr_stmt|;
block|}
return|return;
block|}
else|else
block|{
name|LOG
operator|.
name|info
argument_list|(
name|path
operator|+
literal|" does not exist. Either was created but deleted behind our"
operator|+
literal|" back by another pending delete OR was deleted"
operator|+
literal|" in earlier retry rounds. zkretries = "
operator|+
operator|(
name|Long
operator|)
name|ctx
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"deleted "
operator|+
name|path
argument_list|)
expr_stmt|;
block|}
name|deleteNodeSuccess
argument_list|(
name|path
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Asynchronous handler for zk create RESCAN-node results.    * Retries on failures.    *<p>    * A RESCAN node is created using PERSISTENT_SEQUENTIAL flag. It is a signal    * for all the {@link SplitLogWorker}s to rescan for new tasks.    */
class|class
name|CreateRescanAsyncCallback
implements|implements
name|AsyncCallback
operator|.
name|StringCallback
block|{
specifier|private
specifier|final
name|Log
name|LOG
init|=
name|LogFactory
operator|.
name|getLog
argument_list|(
name|CreateRescanAsyncCallback
operator|.
name|class
argument_list|)
decl_stmt|;
annotation|@
name|Override
specifier|public
name|void
name|processResult
parameter_list|(
name|int
name|rc
parameter_list|,
name|String
name|path
parameter_list|,
name|Object
name|ctx
parameter_list|,
name|String
name|name
parameter_list|)
block|{
if|if
condition|(
name|rc
operator|!=
literal|0
condition|)
block|{
if|if
condition|(
name|needAbandonRetries
argument_list|(
name|rc
argument_list|,
literal|"CreateRescan znode "
operator|+
name|path
argument_list|)
condition|)
block|{
return|return;
block|}
name|Long
name|retry_count
init|=
operator|(
name|Long
operator|)
name|ctx
decl_stmt|;
name|LOG
operator|.
name|warn
argument_list|(
literal|"rc="
operator|+
name|KeeperException
operator|.
name|Code
operator|.
name|get
argument_list|(
name|rc
argument_list|)
operator|+
literal|" for "
operator|+
name|path
operator|+
literal|" remaining retries="
operator|+
name|retry_count
argument_list|)
expr_stmt|;
if|if
condition|(
name|retry_count
operator|==
literal|0
condition|)
block|{
name|createRescanFailure
argument_list|()
expr_stmt|;
block|}
else|else
block|{
name|createRescanNode
argument_list|(
name|retry_count
operator|-
literal|1
argument_list|)
expr_stmt|;
block|}
return|return;
block|}
comment|// path is the original arg, name is the actual name that was created
name|createRescanSuccess
argument_list|(
name|name
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * {@link SplitLogManager} can use objects implementing this interface to    * finish off a partially done task by {@link SplitLogWorker}. This provides    * a serialization point at the end of the task processing. Must be    * restartable and idempotent.    */
specifier|public
interface|interface
name|TaskFinisher
block|{
comment|/**      * status that can be returned finish()      */
enum|enum
name|Status
block|{
comment|/**        * task completed successfully        */
name|DONE
parameter_list|()
operator|,
comment|/**        * task completed with error        */
constructor|ERR(
block|)
enum|;
block|}
comment|/**      * finish the partially done task. workername provides clue to where the      * partial results of the partially done tasks are present. taskname is the      * name of the task that was put up in zookeeper.      *<p>      * @param workerName      * @param taskname      * @return DONE if task completed successfully, ERR otherwise      */
name|Status
name|finish
parameter_list|(
name|ServerName
name|workerName
parameter_list|,
name|String
name|taskname
parameter_list|)
function_decl|;
block|}
end_class

begin_enum
enum|enum
name|ResubmitDirective
block|{
name|CHECK
parameter_list|()
operator|,
constructor|FORCE(
block|)
enum|;
end_enum

begin_expr_stmt
unit|}    enum
name|TerminationStatus
block|{
name|IN_PROGRESS
argument_list|(
literal|"in_progress"
argument_list|)
block|,
name|SUCCESS
argument_list|(
literal|"success"
argument_list|)
block|,
name|FAILURE
argument_list|(
literal|"failure"
argument_list|)
block|,
name|DELETED
argument_list|(
literal|"deleted"
argument_list|)
block|;
name|String
name|statusMsg
block|;
name|TerminationStatus
argument_list|(
name|String
name|msg
argument_list|)
block|{
name|statusMsg
operator|=
name|msg
block|;     }
expr|@
name|Override
specifier|public
name|String
name|toString
argument_list|()
block|{
return|return
name|statusMsg
return|;
block|}
end_expr_stmt

unit|} }
end_unit

