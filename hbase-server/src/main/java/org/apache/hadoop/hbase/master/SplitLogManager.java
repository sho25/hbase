begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|master
package|;
end_package

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|master
operator|.
name|SplitLogManager
operator|.
name|ResubmitDirective
operator|.
name|CHECK
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|master
operator|.
name|SplitLogManager
operator|.
name|ResubmitDirective
operator|.
name|FORCE
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|master
operator|.
name|SplitLogManager
operator|.
name|TerminationStatus
operator|.
name|DELETED
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|master
operator|.
name|SplitLogManager
operator|.
name|TerminationStatus
operator|.
name|FAILURE
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|master
operator|.
name|SplitLogManager
operator|.
name|TerminationStatus
operator|.
name|IN_PROGRESS
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|master
operator|.
name|SplitLogManager
operator|.
name|TerminationStatus
operator|.
name|SUCCESS
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|shaded
operator|.
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|annotations
operator|.
name|VisibleForTesting
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|InterruptedIOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Arrays
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collections
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Set
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ConcurrentHashMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ConcurrentMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|atomic
operator|.
name|AtomicInteger
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|locks
operator|.
name|ReentrantLock
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|Log
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|LogFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileStatus
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|PathFilter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|ChoreService
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HRegionInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|ScheduledChore
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|ServerName
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|SplitLogCounters
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|Stoppable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|yetus
operator|.
name|audience
operator|.
name|InterfaceAudience
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|coordination
operator|.
name|BaseCoordinatedStateManager
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|coordination
operator|.
name|SplitLogManagerCoordination
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|coordination
operator|.
name|SplitLogManagerCoordination
operator|.
name|SplitLogManagerDetails
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|monitoring
operator|.
name|MonitoredTask
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|monitoring
operator|.
name|TaskMonitor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|shaded
operator|.
name|protobuf
operator|.
name|generated
operator|.
name|ZooKeeperProtos
operator|.
name|SplitLogTask
operator|.
name|RecoveryMode
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|EnvironmentEdgeManager
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|FSUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|Pair
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|wal
operator|.
name|AbstractFSWALProvider
import|;
end_import

begin_comment
comment|/**  * Distributes the task of log splitting to the available region servers.  * Coordination happens via coordination engine. For every log file that has to be split a  * task is created. SplitLogWorkers race to grab a task.  *  *<p>SplitLogManager monitors the tasks that it creates using the  * timeoutMonitor thread. If a task's progress is slow then  * {@link SplitLogManagerCoordination#checkTasks} will take away the  * task from the owner {@link org.apache.hadoop.hbase.regionserver.SplitLogWorker}  * and the task will be up for grabs again. When the task is done then it is  * deleted by SplitLogManager.  *  *<p>Clients call {@link #splitLogDistributed(Path)} to split a region server's  * log files. The caller thread waits in this method until all the log files  * have been split.  *  *<p>All the coordination calls made by this class are asynchronous. This is mainly  * to help reduce response time seen by the callers.  *  *<p>There is race in this design between the SplitLogManager and the  * SplitLogWorker. SplitLogManager might re-queue a task that has in reality  * already been completed by a SplitLogWorker. We rely on the idempotency of  * the log splitting task for correctness.  *  *<p>It is also assumed that every log splitting task is unique and once  * completed (either with success or with error) it will be not be submitted  * again. If a task is resubmitted then there is a risk that old "delete task"  * can delete the re-submission.  */
end_comment

begin_class
annotation|@
name|InterfaceAudience
operator|.
name|Private
specifier|public
class|class
name|SplitLogManager
block|{
specifier|private
specifier|static
specifier|final
name|Log
name|LOG
init|=
name|LogFactory
operator|.
name|getLog
argument_list|(
name|SplitLogManager
operator|.
name|class
argument_list|)
decl_stmt|;
specifier|private
specifier|final
name|MasterServices
name|server
decl_stmt|;
specifier|private
specifier|final
name|Configuration
name|conf
decl_stmt|;
specifier|private
specifier|final
name|ChoreService
name|choreService
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|int
name|DEFAULT_UNASSIGNED_TIMEOUT
init|=
operator|(
literal|3
operator|*
literal|60
operator|*
literal|1000
operator|)
decl_stmt|;
comment|// 3 min
specifier|private
name|long
name|unassignedTimeout
decl_stmt|;
specifier|private
name|long
name|lastTaskCreateTime
init|=
name|Long
operator|.
name|MAX_VALUE
decl_stmt|;
specifier|private
name|long
name|checkRecoveringTimeThreshold
init|=
literal|15000
decl_stmt|;
comment|// 15 seconds
specifier|private
specifier|final
name|List
argument_list|<
name|Pair
argument_list|<
name|Set
argument_list|<
name|ServerName
argument_list|>
argument_list|,
name|Boolean
argument_list|>
argument_list|>
name|failedRecoveringRegionDeletions
init|=
name|Collections
operator|.
name|synchronizedList
argument_list|(
operator|new
name|ArrayList
argument_list|<
name|Pair
argument_list|<
name|Set
argument_list|<
name|ServerName
argument_list|>
argument_list|,
name|Boolean
argument_list|>
argument_list|>
argument_list|()
argument_list|)
decl_stmt|;
comment|/**    * In distributedLogReplay mode, we need touch both splitlog and recovering-regions znodes in one    * operation. So the lock is used to guard such cases.    */
specifier|protected
specifier|final
name|ReentrantLock
name|recoveringRegionLock
init|=
operator|new
name|ReentrantLock
argument_list|()
decl_stmt|;
annotation|@
name|VisibleForTesting
specifier|final
name|ConcurrentMap
argument_list|<
name|String
argument_list|,
name|Task
argument_list|>
name|tasks
init|=
operator|new
name|ConcurrentHashMap
argument_list|<>
argument_list|()
decl_stmt|;
specifier|private
name|TimeoutMonitor
name|timeoutMonitor
decl_stmt|;
specifier|private
specifier|volatile
name|Set
argument_list|<
name|ServerName
argument_list|>
name|deadWorkers
init|=
literal|null
decl_stmt|;
specifier|private
specifier|final
name|Object
name|deadWorkersLock
init|=
operator|new
name|Object
argument_list|()
decl_stmt|;
comment|/**    * Its OK to construct this object even when region-servers are not online. It does lookup the    * orphan tasks in coordination engine but it doesn't block waiting for them to be done.    * @param master the master services    * @param conf the HBase configuration    * @throws IOException    */
specifier|public
name|SplitLogManager
parameter_list|(
name|MasterServices
name|master
parameter_list|,
name|Configuration
name|conf
parameter_list|)
throws|throws
name|IOException
block|{
name|this
operator|.
name|server
operator|=
name|master
expr_stmt|;
name|this
operator|.
name|conf
operator|=
name|conf
expr_stmt|;
name|this
operator|.
name|choreService
operator|=
operator|new
name|ChoreService
argument_list|(
name|master
operator|.
name|getServerName
argument_list|()
operator|+
literal|"_splitLogManager_"
argument_list|)
expr_stmt|;
if|if
condition|(
name|server
operator|.
name|getCoordinatedStateManager
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|SplitLogManagerCoordination
name|coordination
init|=
name|getSplitLogManagerCoordination
argument_list|()
decl_stmt|;
name|Set
argument_list|<
name|String
argument_list|>
name|failedDeletions
init|=
name|Collections
operator|.
name|synchronizedSet
argument_list|(
operator|new
name|HashSet
argument_list|<
name|String
argument_list|>
argument_list|()
argument_list|)
decl_stmt|;
name|SplitLogManagerDetails
name|details
init|=
operator|new
name|SplitLogManagerDetails
argument_list|(
name|tasks
argument_list|,
name|master
argument_list|,
name|failedDeletions
argument_list|)
decl_stmt|;
name|coordination
operator|.
name|setDetails
argument_list|(
name|details
argument_list|)
expr_stmt|;
name|coordination
operator|.
name|init
argument_list|()
expr_stmt|;
comment|// Determine recovery mode
block|}
name|this
operator|.
name|unassignedTimeout
operator|=
name|conf
operator|.
name|getInt
argument_list|(
literal|"hbase.splitlog.manager.unassigned.timeout"
argument_list|,
name|DEFAULT_UNASSIGNED_TIMEOUT
argument_list|)
expr_stmt|;
name|this
operator|.
name|timeoutMonitor
operator|=
operator|new
name|TimeoutMonitor
argument_list|(
name|conf
operator|.
name|getInt
argument_list|(
literal|"hbase.splitlog.manager.timeoutmonitor.period"
argument_list|,
literal|1000
argument_list|)
argument_list|,
name|master
argument_list|)
expr_stmt|;
name|choreService
operator|.
name|scheduleChore
argument_list|(
name|timeoutMonitor
argument_list|)
expr_stmt|;
block|}
specifier|private
name|SplitLogManagerCoordination
name|getSplitLogManagerCoordination
parameter_list|()
block|{
return|return
operator|(
operator|(
name|BaseCoordinatedStateManager
operator|)
name|server
operator|.
name|getCoordinatedStateManager
argument_list|()
operator|)
operator|.
name|getSplitLogManagerCoordination
argument_list|()
return|;
block|}
specifier|private
name|FileStatus
index|[]
name|getFileList
parameter_list|(
name|List
argument_list|<
name|Path
argument_list|>
name|logDirs
parameter_list|,
name|PathFilter
name|filter
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|getFileList
argument_list|(
name|conf
argument_list|,
name|logDirs
argument_list|,
name|filter
argument_list|)
return|;
block|}
comment|/**    * Get a list of paths that need to be split given a set of server-specific directories and    * optionally  a filter.    *    * See {@link AbstractFSWALProvider#getServerNameFromWALDirectoryName} for more info on directory    * layout.    *    * Should be package-private, but is needed by    * {@link org.apache.hadoop.hbase.wal.WALSplitter#split(Path, Path, Path, FileSystem,    *     Configuration, org.apache.hadoop.hbase.wal.WALFactory)} for tests.    */
annotation|@
name|VisibleForTesting
specifier|public
specifier|static
name|FileStatus
index|[]
name|getFileList
parameter_list|(
specifier|final
name|Configuration
name|conf
parameter_list|,
specifier|final
name|List
argument_list|<
name|Path
argument_list|>
name|logDirs
parameter_list|,
specifier|final
name|PathFilter
name|filter
parameter_list|)
throws|throws
name|IOException
block|{
name|List
argument_list|<
name|FileStatus
argument_list|>
name|fileStatus
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
for|for
control|(
name|Path
name|logDir
range|:
name|logDirs
control|)
block|{
specifier|final
name|FileSystem
name|fs
init|=
name|logDir
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|fs
operator|.
name|exists
argument_list|(
name|logDir
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
name|logDir
operator|+
literal|" doesn't exist. Nothing to do!"
argument_list|)
expr_stmt|;
continue|continue;
block|}
name|FileStatus
index|[]
name|logfiles
init|=
name|FSUtils
operator|.
name|listStatus
argument_list|(
name|fs
argument_list|,
name|logDir
argument_list|,
name|filter
argument_list|)
decl_stmt|;
if|if
condition|(
name|logfiles
operator|==
literal|null
operator|||
name|logfiles
operator|.
name|length
operator|==
literal|0
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
name|logDir
operator|+
literal|" is empty dir, no logs to split"
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|Collections
operator|.
name|addAll
argument_list|(
name|fileStatus
argument_list|,
name|logfiles
argument_list|)
expr_stmt|;
block|}
block|}
name|FileStatus
index|[]
name|a
init|=
operator|new
name|FileStatus
index|[
name|fileStatus
operator|.
name|size
argument_list|()
index|]
decl_stmt|;
return|return
name|fileStatus
operator|.
name|toArray
argument_list|(
name|a
argument_list|)
return|;
block|}
comment|/**    * @param logDir one region sever wal dir path in .logs    * @throws IOException if there was an error while splitting any log file    * @return cumulative size of the logfiles split    * @throws IOException    */
specifier|public
name|long
name|splitLogDistributed
parameter_list|(
specifier|final
name|Path
name|logDir
parameter_list|)
throws|throws
name|IOException
block|{
name|List
argument_list|<
name|Path
argument_list|>
name|logDirs
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
name|logDirs
operator|.
name|add
argument_list|(
name|logDir
argument_list|)
expr_stmt|;
return|return
name|splitLogDistributed
argument_list|(
name|logDirs
argument_list|)
return|;
block|}
comment|/**    * The caller will block until all the log files of the given region server have been processed -    * successfully split or an error is encountered - by an available worker region server. This    * method must only be called after the region servers have been brought online.    * @param logDirs List of log dirs to split    * @throws IOException If there was an error while splitting any log file    * @return cumulative size of the logfiles split    */
specifier|public
name|long
name|splitLogDistributed
parameter_list|(
specifier|final
name|List
argument_list|<
name|Path
argument_list|>
name|logDirs
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|logDirs
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
return|return
literal|0
return|;
block|}
name|Set
argument_list|<
name|ServerName
argument_list|>
name|serverNames
init|=
operator|new
name|HashSet
argument_list|<>
argument_list|()
decl_stmt|;
for|for
control|(
name|Path
name|logDir
range|:
name|logDirs
control|)
block|{
try|try
block|{
name|ServerName
name|serverName
init|=
name|AbstractFSWALProvider
operator|.
name|getServerNameFromWALDirectoryName
argument_list|(
name|logDir
argument_list|)
decl_stmt|;
if|if
condition|(
name|serverName
operator|!=
literal|null
condition|)
block|{
name|serverNames
operator|.
name|add
argument_list|(
name|serverName
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|IllegalArgumentException
name|e
parameter_list|)
block|{
comment|// ignore invalid format error.
name|LOG
operator|.
name|warn
argument_list|(
literal|"Cannot parse server name from "
operator|+
name|logDir
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|splitLogDistributed
argument_list|(
name|serverNames
argument_list|,
name|logDirs
argument_list|,
literal|null
argument_list|)
return|;
block|}
comment|/**    * The caller will block until all the hbase:meta log files of the given region server have been    * processed - successfully split or an error is encountered - by an available worker region    * server. This method must only be called after the region servers have been brought online.    * @param logDirs List of log dirs to split    * @param filter the Path filter to select specific files for considering    * @throws IOException If there was an error while splitting any log file    * @return cumulative size of the logfiles split    */
specifier|public
name|long
name|splitLogDistributed
parameter_list|(
specifier|final
name|Set
argument_list|<
name|ServerName
argument_list|>
name|serverNames
parameter_list|,
specifier|final
name|List
argument_list|<
name|Path
argument_list|>
name|logDirs
parameter_list|,
name|PathFilter
name|filter
parameter_list|)
throws|throws
name|IOException
block|{
name|MonitoredTask
name|status
init|=
name|TaskMonitor
operator|.
name|get
argument_list|()
operator|.
name|createStatus
argument_list|(
literal|"Doing distributed log split in "
operator|+
name|logDirs
operator|+
literal|" for serverName="
operator|+
name|serverNames
argument_list|)
decl_stmt|;
name|FileStatus
index|[]
name|logfiles
init|=
name|getFileList
argument_list|(
name|logDirs
argument_list|,
name|filter
argument_list|)
decl_stmt|;
name|status
operator|.
name|setStatus
argument_list|(
literal|"Checking directory contents..."
argument_list|)
expr_stmt|;
name|SplitLogCounters
operator|.
name|tot_mgr_log_split_batch_start
operator|.
name|increment
argument_list|()
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Started splitting "
operator|+
name|logfiles
operator|.
name|length
operator|+
literal|" logs in "
operator|+
name|logDirs
operator|+
literal|" for "
operator|+
name|serverNames
argument_list|)
expr_stmt|;
name|long
name|t
init|=
name|EnvironmentEdgeManager
operator|.
name|currentTime
argument_list|()
decl_stmt|;
name|long
name|totalSize
init|=
literal|0
decl_stmt|;
name|TaskBatch
name|batch
init|=
operator|new
name|TaskBatch
argument_list|()
decl_stmt|;
name|Boolean
name|isMetaRecovery
init|=
operator|(
name|filter
operator|==
literal|null
operator|)
condition|?
literal|null
else|:
literal|false
decl_stmt|;
for|for
control|(
name|FileStatus
name|lf
range|:
name|logfiles
control|)
block|{
comment|// TODO If the log file is still being written to - which is most likely
comment|// the case for the last log file - then its length will show up here
comment|// as zero. The size of such a file can only be retrieved after
comment|// recover-lease is done. totalSize will be under in most cases and the
comment|// metrics that it drives will also be under-reported.
name|totalSize
operator|+=
name|lf
operator|.
name|getLen
argument_list|()
expr_stmt|;
name|String
name|pathToLog
init|=
name|FSUtils
operator|.
name|removeWALRootPath
argument_list|(
name|lf
operator|.
name|getPath
argument_list|()
argument_list|,
name|conf
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|enqueueSplitTask
argument_list|(
name|pathToLog
argument_list|,
name|batch
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"duplicate log split scheduled for "
operator|+
name|lf
operator|.
name|getPath
argument_list|()
argument_list|)
throw|;
block|}
block|}
name|waitForSplittingCompletion
argument_list|(
name|batch
argument_list|,
name|status
argument_list|)
expr_stmt|;
comment|// remove recovering regions
if|if
condition|(
name|filter
operator|==
name|MasterWalManager
operator|.
name|META_FILTER
comment|/* reference comparison */
condition|)
block|{
comment|// we split meta regions and user regions separately therefore logfiles are either all for
comment|// meta or user regions but won't for both( we could have mixed situations in tests)
name|isMetaRecovery
operator|=
literal|true
expr_stmt|;
block|}
name|removeRecoveringRegions
argument_list|(
name|serverNames
argument_list|,
name|isMetaRecovery
argument_list|)
expr_stmt|;
if|if
condition|(
name|batch
operator|.
name|done
operator|!=
name|batch
operator|.
name|installed
condition|)
block|{
name|batch
operator|.
name|isDead
operator|=
literal|true
expr_stmt|;
name|SplitLogCounters
operator|.
name|tot_mgr_log_split_batch_err
operator|.
name|increment
argument_list|()
expr_stmt|;
name|LOG
operator|.
name|warn
argument_list|(
literal|"error while splitting logs in "
operator|+
name|logDirs
operator|+
literal|" installed = "
operator|+
name|batch
operator|.
name|installed
operator|+
literal|" but only "
operator|+
name|batch
operator|.
name|done
operator|+
literal|" done"
argument_list|)
expr_stmt|;
name|String
name|msg
init|=
literal|"error or interrupted while splitting logs in "
operator|+
name|logDirs
operator|+
literal|" Task = "
operator|+
name|batch
decl_stmt|;
name|status
operator|.
name|abort
argument_list|(
name|msg
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|IOException
argument_list|(
name|msg
argument_list|)
throw|;
block|}
for|for
control|(
name|Path
name|logDir
range|:
name|logDirs
control|)
block|{
name|status
operator|.
name|setStatus
argument_list|(
literal|"Cleaning up log directory..."
argument_list|)
expr_stmt|;
specifier|final
name|FileSystem
name|fs
init|=
name|logDir
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
decl_stmt|;
try|try
block|{
if|if
condition|(
name|fs
operator|.
name|exists
argument_list|(
name|logDir
argument_list|)
operator|&&
operator|!
name|fs
operator|.
name|delete
argument_list|(
name|logDir
argument_list|,
literal|false
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Unable to delete log src dir. Ignoring. "
operator|+
name|logDir
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|ioe
parameter_list|)
block|{
name|FileStatus
index|[]
name|files
init|=
name|fs
operator|.
name|listStatus
argument_list|(
name|logDir
argument_list|)
decl_stmt|;
if|if
condition|(
name|files
operator|!=
literal|null
operator|&&
name|files
operator|.
name|length
operator|>
literal|0
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Returning success without actually splitting and "
operator|+
literal|"deleting all the log files in path "
operator|+
name|logDir
operator|+
literal|": "
operator|+
name|Arrays
operator|.
name|toString
argument_list|(
name|files
argument_list|)
argument_list|,
name|ioe
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Unable to delete log src dir. Ignoring. "
operator|+
name|logDir
argument_list|,
name|ioe
argument_list|)
expr_stmt|;
block|}
block|}
name|SplitLogCounters
operator|.
name|tot_mgr_log_split_batch_success
operator|.
name|increment
argument_list|()
expr_stmt|;
block|}
name|String
name|msg
init|=
literal|"finished splitting (more than or equal to) "
operator|+
name|totalSize
operator|+
literal|" bytes in "
operator|+
name|batch
operator|.
name|installed
operator|+
literal|" log files in "
operator|+
name|logDirs
operator|+
literal|" in "
operator|+
operator|(
name|EnvironmentEdgeManager
operator|.
name|currentTime
argument_list|()
operator|-
name|t
operator|)
operator|+
literal|"ms"
decl_stmt|;
name|status
operator|.
name|markComplete
argument_list|(
name|msg
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
name|msg
argument_list|)
expr_stmt|;
return|return
name|totalSize
return|;
block|}
comment|/**    * Add a task entry to coordination if it is not already there.    * @param taskname the path of the log to be split    * @param batch the batch this task belongs to    * @return true if a new entry is created, false if it is already there.    */
name|boolean
name|enqueueSplitTask
parameter_list|(
name|String
name|taskname
parameter_list|,
name|TaskBatch
name|batch
parameter_list|)
block|{
name|lastTaskCreateTime
operator|=
name|EnvironmentEdgeManager
operator|.
name|currentTime
argument_list|()
expr_stmt|;
name|String
name|task
init|=
name|getSplitLogManagerCoordination
argument_list|()
operator|.
name|prepareTask
argument_list|(
name|taskname
argument_list|)
decl_stmt|;
name|Task
name|oldtask
init|=
name|createTaskIfAbsent
argument_list|(
name|task
argument_list|,
name|batch
argument_list|)
decl_stmt|;
if|if
condition|(
name|oldtask
operator|==
literal|null
condition|)
block|{
comment|// publish the task in the coordination engine
name|getSplitLogManagerCoordination
argument_list|()
operator|.
name|submitTask
argument_list|(
name|task
argument_list|)
expr_stmt|;
return|return
literal|true
return|;
block|}
return|return
literal|false
return|;
block|}
specifier|private
name|void
name|waitForSplittingCompletion
parameter_list|(
name|TaskBatch
name|batch
parameter_list|,
name|MonitoredTask
name|status
parameter_list|)
block|{
synchronized|synchronized
init|(
name|batch
init|)
block|{
while|while
condition|(
operator|(
name|batch
operator|.
name|done
operator|+
name|batch
operator|.
name|error
operator|)
operator|!=
name|batch
operator|.
name|installed
condition|)
block|{
try|try
block|{
name|status
operator|.
name|setStatus
argument_list|(
literal|"Waiting for distributed tasks to finish. "
operator|+
literal|" scheduled="
operator|+
name|batch
operator|.
name|installed
operator|+
literal|" done="
operator|+
name|batch
operator|.
name|done
operator|+
literal|" error="
operator|+
name|batch
operator|.
name|error
argument_list|)
expr_stmt|;
name|int
name|remaining
init|=
name|batch
operator|.
name|installed
operator|-
operator|(
name|batch
operator|.
name|done
operator|+
name|batch
operator|.
name|error
operator|)
decl_stmt|;
name|int
name|actual
init|=
name|activeTasks
argument_list|(
name|batch
argument_list|)
decl_stmt|;
if|if
condition|(
name|remaining
operator|!=
name|actual
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Expected "
operator|+
name|remaining
operator|+
literal|" active tasks, but actually there are "
operator|+
name|actual
argument_list|)
expr_stmt|;
block|}
name|int
name|remainingTasks
init|=
name|getSplitLogManagerCoordination
argument_list|()
operator|.
name|remainingTasksInCoordination
argument_list|()
decl_stmt|;
if|if
condition|(
name|remainingTasks
operator|>=
literal|0
operator|&&
name|actual
operator|>
name|remainingTasks
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Expected at least"
operator|+
name|actual
operator|+
literal|" tasks remaining, but actually there are "
operator|+
name|remainingTasks
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|remainingTasks
operator|==
literal|0
operator|||
name|actual
operator|==
literal|0
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"No more task remaining, splitting "
operator|+
literal|"should have completed. Remaining tasks is "
operator|+
name|remainingTasks
operator|+
literal|", active tasks in map "
operator|+
name|actual
argument_list|)
expr_stmt|;
if|if
condition|(
name|remainingTasks
operator|==
literal|0
operator|&&
name|actual
operator|==
literal|0
condition|)
block|{
return|return;
block|}
block|}
name|batch
operator|.
name|wait
argument_list|(
literal|100
argument_list|)
expr_stmt|;
if|if
condition|(
name|server
operator|.
name|isStopped
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Stopped while waiting for log splits to be completed"
argument_list|)
expr_stmt|;
return|return;
block|}
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Interrupted while waiting for log splits to be completed"
argument_list|)
expr_stmt|;
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|interrupt
argument_list|()
expr_stmt|;
return|return;
block|}
block|}
block|}
block|}
annotation|@
name|VisibleForTesting
name|ConcurrentMap
argument_list|<
name|String
argument_list|,
name|Task
argument_list|>
name|getTasks
parameter_list|()
block|{
return|return
name|tasks
return|;
block|}
specifier|private
name|int
name|activeTasks
parameter_list|(
specifier|final
name|TaskBatch
name|batch
parameter_list|)
block|{
name|int
name|count
init|=
literal|0
decl_stmt|;
for|for
control|(
name|Task
name|t
range|:
name|tasks
operator|.
name|values
argument_list|()
control|)
block|{
if|if
condition|(
name|t
operator|.
name|batch
operator|==
name|batch
operator|&&
name|t
operator|.
name|status
operator|==
name|TerminationStatus
operator|.
name|IN_PROGRESS
condition|)
block|{
name|count
operator|++
expr_stmt|;
block|}
block|}
return|return
name|count
return|;
block|}
comment|/**    * It removes recovering regions under /hbase/recovering-regions/[encoded region name] so that the    * region server hosting the region can allow reads to the recovered region    * @param serverNames servers which are just recovered    * @param isMetaRecovery whether current recovery is for the meta region on {@code serverNames}    */
specifier|private
name|void
name|removeRecoveringRegions
parameter_list|(
specifier|final
name|Set
argument_list|<
name|ServerName
argument_list|>
name|serverNames
parameter_list|,
name|Boolean
name|isMetaRecovery
parameter_list|)
block|{
if|if
condition|(
operator|!
name|isLogReplaying
argument_list|()
condition|)
block|{
comment|// the function is only used in WALEdit direct replay mode
return|return;
block|}
if|if
condition|(
name|serverNames
operator|==
literal|null
operator|||
name|serverNames
operator|.
name|isEmpty
argument_list|()
condition|)
return|return;
name|Set
argument_list|<
name|String
argument_list|>
name|recoveredServerNameSet
init|=
operator|new
name|HashSet
argument_list|<>
argument_list|()
decl_stmt|;
for|for
control|(
name|ServerName
name|tmpServerName
range|:
name|serverNames
control|)
block|{
name|recoveredServerNameSet
operator|.
name|add
argument_list|(
name|tmpServerName
operator|.
name|getServerName
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|this
operator|.
name|recoveringRegionLock
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
name|getSplitLogManagerCoordination
argument_list|()
operator|.
name|removeRecoveringRegions
argument_list|(
name|recoveredServerNameSet
argument_list|,
name|isMetaRecovery
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"removeRecoveringRegions got exception. Will retry"
argument_list|,
name|e
argument_list|)
expr_stmt|;
if|if
condition|(
name|serverNames
operator|!=
literal|null
operator|&&
operator|!
name|serverNames
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|this
operator|.
name|failedRecoveringRegionDeletions
operator|.
name|add
argument_list|(
operator|new
name|Pair
argument_list|<>
argument_list|(
name|serverNames
argument_list|,
name|isMetaRecovery
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
finally|finally
block|{
name|this
operator|.
name|recoveringRegionLock
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**    * It removes stale recovering regions under /hbase/recovering-regions/[encoded region name]    * during master initialization phase.    * @param failedServers A set of known failed servers    * @throws IOException    */
name|void
name|removeStaleRecoveringRegions
parameter_list|(
specifier|final
name|Set
argument_list|<
name|ServerName
argument_list|>
name|failedServers
parameter_list|)
throws|throws
name|IOException
throws|,
name|InterruptedIOException
block|{
name|Set
argument_list|<
name|String
argument_list|>
name|knownFailedServers
init|=
operator|new
name|HashSet
argument_list|<>
argument_list|()
decl_stmt|;
if|if
condition|(
name|failedServers
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|ServerName
name|tmpServerName
range|:
name|failedServers
control|)
block|{
name|knownFailedServers
operator|.
name|add
argument_list|(
name|tmpServerName
operator|.
name|getServerName
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
name|this
operator|.
name|recoveringRegionLock
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
name|getSplitLogManagerCoordination
argument_list|()
operator|.
name|removeStaleRecoveringRegions
argument_list|(
name|knownFailedServers
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|this
operator|.
name|recoveringRegionLock
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**    * @param path    * @param batch    * @return null on success, existing task on error    */
specifier|private
name|Task
name|createTaskIfAbsent
parameter_list|(
name|String
name|path
parameter_list|,
name|TaskBatch
name|batch
parameter_list|)
block|{
name|Task
name|oldtask
decl_stmt|;
comment|// batch.installed is only changed via this function and
comment|// a single thread touches batch.installed.
name|Task
name|newtask
init|=
operator|new
name|Task
argument_list|()
decl_stmt|;
name|newtask
operator|.
name|batch
operator|=
name|batch
expr_stmt|;
name|oldtask
operator|=
name|tasks
operator|.
name|putIfAbsent
argument_list|(
name|path
argument_list|,
name|newtask
argument_list|)
expr_stmt|;
if|if
condition|(
name|oldtask
operator|==
literal|null
condition|)
block|{
name|batch
operator|.
name|installed
operator|++
expr_stmt|;
return|return
literal|null
return|;
block|}
comment|// new task was not used.
synchronized|synchronized
init|(
name|oldtask
init|)
block|{
if|if
condition|(
name|oldtask
operator|.
name|isOrphan
argument_list|()
condition|)
block|{
if|if
condition|(
name|oldtask
operator|.
name|status
operator|==
name|SUCCESS
condition|)
block|{
comment|// The task is already done. Do not install the batch for this
comment|// task because it might be too late for setDone() to update
comment|// batch.done. There is no need for the batch creator to wait for
comment|// this task to complete.
return|return
operator|(
literal|null
operator|)
return|;
block|}
if|if
condition|(
name|oldtask
operator|.
name|status
operator|==
name|IN_PROGRESS
condition|)
block|{
name|oldtask
operator|.
name|batch
operator|=
name|batch
expr_stmt|;
name|batch
operator|.
name|installed
operator|++
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Previously orphan task "
operator|+
name|path
operator|+
literal|" is now being waited upon"
argument_list|)
expr_stmt|;
return|return
literal|null
return|;
block|}
while|while
condition|(
name|oldtask
operator|.
name|status
operator|==
name|FAILURE
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"wait for status of task "
operator|+
name|path
operator|+
literal|" to change to DELETED"
argument_list|)
expr_stmt|;
name|SplitLogCounters
operator|.
name|tot_mgr_wait_for_zk_delete
operator|.
name|increment
argument_list|()
expr_stmt|;
try|try
block|{
name|oldtask
operator|.
name|wait
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|interrupt
argument_list|()
expr_stmt|;
name|LOG
operator|.
name|warn
argument_list|(
literal|"Interrupted when waiting for znode delete callback"
argument_list|)
expr_stmt|;
comment|// fall through to return failure
break|break;
block|}
block|}
if|if
condition|(
name|oldtask
operator|.
name|status
operator|!=
name|DELETED
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failure because previously failed task"
operator|+
literal|" state still present. Waiting for znode delete callback"
operator|+
literal|" path="
operator|+
name|path
argument_list|)
expr_stmt|;
return|return
name|oldtask
return|;
block|}
comment|// reinsert the newTask and it must succeed this time
name|Task
name|t
init|=
name|tasks
operator|.
name|putIfAbsent
argument_list|(
name|path
argument_list|,
name|newtask
argument_list|)
decl_stmt|;
if|if
condition|(
name|t
operator|==
literal|null
condition|)
block|{
name|batch
operator|.
name|installed
operator|++
expr_stmt|;
return|return
literal|null
return|;
block|}
name|LOG
operator|.
name|fatal
argument_list|(
literal|"Logic error. Deleted task still present in tasks map"
argument_list|)
expr_stmt|;
assert|assert
literal|false
operator|:
literal|"Deleted task still present in tasks map"
assert|;
return|return
name|t
return|;
block|}
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failure because two threads can't wait for the same task; path="
operator|+
name|path
argument_list|)
expr_stmt|;
return|return
name|oldtask
return|;
block|}
block|}
specifier|public
name|void
name|stop
parameter_list|()
block|{
if|if
condition|(
name|choreService
operator|!=
literal|null
condition|)
block|{
name|choreService
operator|.
name|shutdown
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|timeoutMonitor
operator|!=
literal|null
condition|)
block|{
name|timeoutMonitor
operator|.
name|cancel
argument_list|(
literal|true
argument_list|)
expr_stmt|;
block|}
block|}
name|void
name|handleDeadWorker
parameter_list|(
name|ServerName
name|workerName
parameter_list|)
block|{
comment|// resubmit the tasks on the TimeoutMonitor thread. Makes it easier
comment|// to reason about concurrency. Makes it easier to retry.
synchronized|synchronized
init|(
name|deadWorkersLock
init|)
block|{
if|if
condition|(
name|deadWorkers
operator|==
literal|null
condition|)
block|{
name|deadWorkers
operator|=
operator|new
name|HashSet
argument_list|<>
argument_list|(
literal|100
argument_list|)
expr_stmt|;
block|}
name|deadWorkers
operator|.
name|add
argument_list|(
name|workerName
argument_list|)
expr_stmt|;
block|}
name|LOG
operator|.
name|info
argument_list|(
literal|"dead splitlog worker "
operator|+
name|workerName
argument_list|)
expr_stmt|;
block|}
name|void
name|handleDeadWorkers
parameter_list|(
name|Set
argument_list|<
name|ServerName
argument_list|>
name|serverNames
parameter_list|)
block|{
synchronized|synchronized
init|(
name|deadWorkersLock
init|)
block|{
if|if
condition|(
name|deadWorkers
operator|==
literal|null
condition|)
block|{
name|deadWorkers
operator|=
operator|new
name|HashSet
argument_list|<>
argument_list|(
literal|100
argument_list|)
expr_stmt|;
block|}
name|deadWorkers
operator|.
name|addAll
argument_list|(
name|serverNames
argument_list|)
expr_stmt|;
block|}
name|LOG
operator|.
name|info
argument_list|(
literal|"dead splitlog workers "
operator|+
name|serverNames
argument_list|)
expr_stmt|;
block|}
comment|/**    * This function is to set recovery mode from outstanding split log tasks from before or current    * configuration setting    * @param isForInitialization    * @throws IOException throws if it's impossible to set recovery mode    */
specifier|public
name|void
name|setRecoveryMode
parameter_list|(
name|boolean
name|isForInitialization
parameter_list|)
throws|throws
name|IOException
block|{
name|getSplitLogManagerCoordination
argument_list|()
operator|.
name|setRecoveryMode
argument_list|(
name|isForInitialization
argument_list|)
expr_stmt|;
block|}
specifier|public
name|void
name|markRegionsRecovering
parameter_list|(
name|ServerName
name|server
parameter_list|,
name|Set
argument_list|<
name|HRegionInfo
argument_list|>
name|userRegions
parameter_list|)
throws|throws
name|InterruptedIOException
throws|,
name|IOException
block|{
if|if
condition|(
name|userRegions
operator|==
literal|null
operator|||
operator|(
operator|!
name|isLogReplaying
argument_list|()
operator|)
condition|)
block|{
return|return;
block|}
try|try
block|{
name|this
operator|.
name|recoveringRegionLock
operator|.
name|lock
argument_list|()
expr_stmt|;
comment|// mark that we're creating recovering regions
name|getSplitLogManagerCoordination
argument_list|()
operator|.
name|markRegionsRecovering
argument_list|(
name|server
argument_list|,
name|userRegions
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|this
operator|.
name|recoveringRegionLock
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**    * @return whether log is replaying    */
specifier|public
name|boolean
name|isLogReplaying
parameter_list|()
block|{
if|if
condition|(
name|server
operator|.
name|getCoordinatedStateManager
argument_list|()
operator|==
literal|null
condition|)
return|return
literal|false
return|;
return|return
name|getSplitLogManagerCoordination
argument_list|()
operator|.
name|isReplaying
argument_list|()
return|;
block|}
comment|/**    * @return whether log is splitting    */
specifier|public
name|boolean
name|isLogSplitting
parameter_list|()
block|{
if|if
condition|(
name|server
operator|.
name|getCoordinatedStateManager
argument_list|()
operator|==
literal|null
condition|)
return|return
literal|false
return|;
return|return
name|getSplitLogManagerCoordination
argument_list|()
operator|.
name|isSplitting
argument_list|()
return|;
block|}
comment|/**    * @return the current log recovery mode    */
specifier|public
name|RecoveryMode
name|getRecoveryMode
parameter_list|()
block|{
return|return
name|getSplitLogManagerCoordination
argument_list|()
operator|.
name|getRecoveryMode
argument_list|()
return|;
block|}
comment|/**    * Keeps track of the batch of tasks submitted together by a caller in splitLogDistributed().    * Clients threads use this object to wait for all their tasks to be done.    *<p>    * All access is synchronized.    */
annotation|@
name|InterfaceAudience
operator|.
name|Private
specifier|public
specifier|static
class|class
name|TaskBatch
block|{
specifier|public
name|int
name|installed
init|=
literal|0
decl_stmt|;
specifier|public
name|int
name|done
init|=
literal|0
decl_stmt|;
specifier|public
name|int
name|error
init|=
literal|0
decl_stmt|;
specifier|public
specifier|volatile
name|boolean
name|isDead
init|=
literal|false
decl_stmt|;
annotation|@
name|Override
specifier|public
name|String
name|toString
parameter_list|()
block|{
return|return
operator|(
literal|"installed = "
operator|+
name|installed
operator|+
literal|" done = "
operator|+
name|done
operator|+
literal|" error = "
operator|+
name|error
operator|)
return|;
block|}
block|}
comment|/**    * in memory state of an active task.    */
annotation|@
name|InterfaceAudience
operator|.
name|Private
specifier|public
specifier|static
class|class
name|Task
block|{
specifier|public
specifier|volatile
name|long
name|last_update
decl_stmt|;
specifier|public
specifier|volatile
name|int
name|last_version
decl_stmt|;
specifier|public
specifier|volatile
name|ServerName
name|cur_worker_name
decl_stmt|;
specifier|public
specifier|volatile
name|TaskBatch
name|batch
decl_stmt|;
specifier|public
specifier|volatile
name|TerminationStatus
name|status
decl_stmt|;
specifier|public
specifier|volatile
name|AtomicInteger
name|incarnation
init|=
operator|new
name|AtomicInteger
argument_list|(
literal|0
argument_list|)
decl_stmt|;
specifier|public
specifier|final
name|AtomicInteger
name|unforcedResubmits
init|=
operator|new
name|AtomicInteger
argument_list|()
decl_stmt|;
specifier|public
specifier|volatile
name|boolean
name|resubmitThresholdReached
decl_stmt|;
annotation|@
name|Override
specifier|public
name|String
name|toString
parameter_list|()
block|{
return|return
operator|(
literal|"last_update = "
operator|+
name|last_update
operator|+
literal|" last_version = "
operator|+
name|last_version
operator|+
literal|" cur_worker_name = "
operator|+
name|cur_worker_name
operator|+
literal|" status = "
operator|+
name|status
operator|+
literal|" incarnation = "
operator|+
name|incarnation
operator|+
literal|" resubmits = "
operator|+
name|unforcedResubmits
operator|.
name|get
argument_list|()
operator|+
literal|" batch = "
operator|+
name|batch
operator|)
return|;
block|}
specifier|public
name|Task
parameter_list|()
block|{
name|last_version
operator|=
operator|-
literal|1
expr_stmt|;
name|status
operator|=
name|IN_PROGRESS
expr_stmt|;
name|setUnassigned
argument_list|()
expr_stmt|;
block|}
specifier|public
name|boolean
name|isOrphan
parameter_list|()
block|{
return|return
operator|(
name|batch
operator|==
literal|null
operator|||
name|batch
operator|.
name|isDead
operator|)
return|;
block|}
specifier|public
name|boolean
name|isUnassigned
parameter_list|()
block|{
return|return
operator|(
name|cur_worker_name
operator|==
literal|null
operator|)
return|;
block|}
specifier|public
name|void
name|heartbeatNoDetails
parameter_list|(
name|long
name|time
parameter_list|)
block|{
name|last_update
operator|=
name|time
expr_stmt|;
block|}
specifier|public
name|void
name|heartbeat
parameter_list|(
name|long
name|time
parameter_list|,
name|int
name|version
parameter_list|,
name|ServerName
name|worker
parameter_list|)
block|{
name|last_version
operator|=
name|version
expr_stmt|;
name|last_update
operator|=
name|time
expr_stmt|;
name|cur_worker_name
operator|=
name|worker
expr_stmt|;
block|}
specifier|public
name|void
name|setUnassigned
parameter_list|()
block|{
name|cur_worker_name
operator|=
literal|null
expr_stmt|;
name|last_update
operator|=
operator|-
literal|1
expr_stmt|;
block|}
block|}
comment|/**    * Periodically checks all active tasks and resubmits the ones that have timed out    */
specifier|private
class|class
name|TimeoutMonitor
extends|extends
name|ScheduledChore
block|{
specifier|private
name|long
name|lastLog
init|=
literal|0
decl_stmt|;
specifier|public
name|TimeoutMonitor
parameter_list|(
specifier|final
name|int
name|period
parameter_list|,
name|Stoppable
name|stopper
parameter_list|)
block|{
name|super
argument_list|(
literal|"SplitLogManager Timeout Monitor"
argument_list|,
name|stopper
argument_list|,
name|period
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|protected
name|void
name|chore
parameter_list|()
block|{
if|if
condition|(
name|server
operator|.
name|getCoordinatedStateManager
argument_list|()
operator|==
literal|null
condition|)
return|return;
name|int
name|resubmitted
init|=
literal|0
decl_stmt|;
name|int
name|unassigned
init|=
literal|0
decl_stmt|;
name|int
name|tot
init|=
literal|0
decl_stmt|;
name|boolean
name|found_assigned_task
init|=
literal|false
decl_stmt|;
name|Set
argument_list|<
name|ServerName
argument_list|>
name|localDeadWorkers
decl_stmt|;
synchronized|synchronized
init|(
name|deadWorkersLock
init|)
block|{
name|localDeadWorkers
operator|=
name|deadWorkers
expr_stmt|;
name|deadWorkers
operator|=
literal|null
expr_stmt|;
block|}
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|String
argument_list|,
name|Task
argument_list|>
name|e
range|:
name|tasks
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|String
name|path
init|=
name|e
operator|.
name|getKey
argument_list|()
decl_stmt|;
name|Task
name|task
init|=
name|e
operator|.
name|getValue
argument_list|()
decl_stmt|;
name|ServerName
name|cur_worker
init|=
name|task
operator|.
name|cur_worker_name
decl_stmt|;
name|tot
operator|++
expr_stmt|;
comment|// don't easily resubmit a task which hasn't been picked up yet. It
comment|// might be a long while before a SplitLogWorker is free to pick up a
comment|// task. This is because a SplitLogWorker picks up a task one at a
comment|// time. If we want progress when there are no region servers then we
comment|// will have to run a SplitLogWorker thread in the Master.
if|if
condition|(
name|task
operator|.
name|isUnassigned
argument_list|()
condition|)
block|{
name|unassigned
operator|++
expr_stmt|;
continue|continue;
block|}
name|found_assigned_task
operator|=
literal|true
expr_stmt|;
if|if
condition|(
name|localDeadWorkers
operator|!=
literal|null
operator|&&
name|localDeadWorkers
operator|.
name|contains
argument_list|(
name|cur_worker
argument_list|)
condition|)
block|{
name|SplitLogCounters
operator|.
name|tot_mgr_resubmit_dead_server_task
operator|.
name|increment
argument_list|()
expr_stmt|;
if|if
condition|(
name|getSplitLogManagerCoordination
argument_list|()
operator|.
name|resubmitTask
argument_list|(
name|path
argument_list|,
name|task
argument_list|,
name|FORCE
argument_list|)
condition|)
block|{
name|resubmitted
operator|++
expr_stmt|;
block|}
else|else
block|{
name|handleDeadWorker
argument_list|(
name|cur_worker
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failed to resubmit task "
operator|+
name|path
operator|+
literal|" owned by dead "
operator|+
name|cur_worker
operator|+
literal|", will retry."
argument_list|)
expr_stmt|;
block|}
block|}
elseif|else
if|if
condition|(
name|getSplitLogManagerCoordination
argument_list|()
operator|.
name|resubmitTask
argument_list|(
name|path
argument_list|,
name|task
argument_list|,
name|CHECK
argument_list|)
condition|)
block|{
name|resubmitted
operator|++
expr_stmt|;
block|}
block|}
if|if
condition|(
name|tot
operator|>
literal|0
condition|)
block|{
name|long
name|now
init|=
name|EnvironmentEdgeManager
operator|.
name|currentTime
argument_list|()
decl_stmt|;
if|if
condition|(
name|now
operator|>
name|lastLog
operator|+
literal|5000
condition|)
block|{
name|lastLog
operator|=
name|now
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"total="
operator|+
name|tot
operator|+
literal|", unassigned="
operator|+
name|unassigned
operator|+
literal|", tasks="
operator|+
name|tasks
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|resubmitted
operator|>
literal|0
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"resubmitted "
operator|+
name|resubmitted
operator|+
literal|" out of "
operator|+
name|tot
operator|+
literal|" tasks"
argument_list|)
expr_stmt|;
block|}
comment|// If there are pending tasks and all of them have been unassigned for
comment|// some time then put up a RESCAN node to ping the workers.
comment|// ZKSplitlog.DEFAULT_UNASSIGNED_TIMEOUT is of the order of minutes
comment|// because a. it is very unlikely that every worker had a
comment|// transient error when trying to grab the task b. if there are no
comment|// workers then all tasks wills stay unassigned indefinitely and the
comment|// manager will be indefinitely creating RESCAN nodes. TODO may be the
comment|// master should spawn both a manager and a worker thread to guarantee
comment|// that there is always one worker in the system
if|if
condition|(
name|tot
operator|>
literal|0
operator|&&
operator|!
name|found_assigned_task
operator|&&
operator|(
operator|(
name|EnvironmentEdgeManager
operator|.
name|currentTime
argument_list|()
operator|-
name|lastTaskCreateTime
operator|)
operator|>
name|unassignedTimeout
operator|)
condition|)
block|{
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|String
argument_list|,
name|Task
argument_list|>
name|e
range|:
name|tasks
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|String
name|key
init|=
name|e
operator|.
name|getKey
argument_list|()
decl_stmt|;
name|Task
name|task
init|=
name|e
operator|.
name|getValue
argument_list|()
decl_stmt|;
comment|// we have to do task.isUnassigned() check again because tasks might
comment|// have been asynchronously assigned. There is no locking required
comment|// for these checks ... it is OK even if tryGetDataSetWatch() is
comment|// called unnecessarily for a taskpath
if|if
condition|(
name|task
operator|.
name|isUnassigned
argument_list|()
operator|&&
operator|(
name|task
operator|.
name|status
operator|!=
name|FAILURE
operator|)
condition|)
block|{
comment|// We just touch the znode to make sure its still there
name|getSplitLogManagerCoordination
argument_list|()
operator|.
name|checkTaskStillAvailable
argument_list|(
name|key
argument_list|)
expr_stmt|;
block|}
block|}
name|getSplitLogManagerCoordination
argument_list|()
operator|.
name|checkTasks
argument_list|()
expr_stmt|;
name|SplitLogCounters
operator|.
name|tot_mgr_resubmit_unassigned
operator|.
name|increment
argument_list|()
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"resubmitting unassigned task(s) after timeout"
argument_list|)
expr_stmt|;
block|}
name|Set
argument_list|<
name|String
argument_list|>
name|failedDeletions
init|=
name|getSplitLogManagerCoordination
argument_list|()
operator|.
name|getDetails
argument_list|()
operator|.
name|getFailedDeletions
argument_list|()
decl_stmt|;
comment|// Retry previously failed deletes
if|if
condition|(
name|failedDeletions
operator|.
name|size
argument_list|()
operator|>
literal|0
condition|)
block|{
name|List
argument_list|<
name|String
argument_list|>
name|tmpPaths
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
name|failedDeletions
argument_list|)
decl_stmt|;
for|for
control|(
name|String
name|tmpPath
range|:
name|tmpPaths
control|)
block|{
comment|// deleteNode is an async call
name|getSplitLogManagerCoordination
argument_list|()
operator|.
name|deleteTask
argument_list|(
name|tmpPath
argument_list|)
expr_stmt|;
block|}
name|failedDeletions
operator|.
name|removeAll
argument_list|(
name|tmpPaths
argument_list|)
expr_stmt|;
block|}
comment|// Garbage collect left-over
name|long
name|timeInterval
init|=
name|EnvironmentEdgeManager
operator|.
name|currentTime
argument_list|()
operator|-
name|getSplitLogManagerCoordination
argument_list|()
operator|.
name|getLastRecoveryTime
argument_list|()
decl_stmt|;
if|if
condition|(
operator|!
name|failedRecoveringRegionDeletions
operator|.
name|isEmpty
argument_list|()
operator|||
operator|(
name|tot
operator|==
literal|0
operator|&&
name|tasks
operator|.
name|isEmpty
argument_list|()
operator|&&
operator|(
name|timeInterval
operator|>
name|checkRecoveringTimeThreshold
operator|)
operator|)
condition|)
block|{
comment|// inside the function there have more checks before GC anything
if|if
condition|(
operator|!
name|failedRecoveringRegionDeletions
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|List
argument_list|<
name|Pair
argument_list|<
name|Set
argument_list|<
name|ServerName
argument_list|>
argument_list|,
name|Boolean
argument_list|>
argument_list|>
name|previouslyFailedDeletions
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
name|failedRecoveringRegionDeletions
argument_list|)
decl_stmt|;
name|failedRecoveringRegionDeletions
operator|.
name|removeAll
argument_list|(
name|previouslyFailedDeletions
argument_list|)
expr_stmt|;
for|for
control|(
name|Pair
argument_list|<
name|Set
argument_list|<
name|ServerName
argument_list|>
argument_list|,
name|Boolean
argument_list|>
name|failedDeletion
range|:
name|previouslyFailedDeletions
control|)
block|{
name|removeRecoveringRegions
argument_list|(
name|failedDeletion
operator|.
name|getFirst
argument_list|()
argument_list|,
name|failedDeletion
operator|.
name|getSecond
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
name|removeRecoveringRegions
argument_list|(
literal|null
argument_list|,
literal|null
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
specifier|public
enum|enum
name|ResubmitDirective
block|{
name|CHECK
parameter_list|()
operator|,
constructor|FORCE(
block|)
enum|;
block|}
end_class

begin_enum
specifier|public
enum|enum
name|TerminationStatus
block|{
name|IN_PROGRESS
argument_list|(
literal|"in_progress"
argument_list|)
block|,
name|SUCCESS
argument_list|(
literal|"success"
argument_list|)
block|,
name|FAILURE
argument_list|(
literal|"failure"
argument_list|)
block|,
name|DELETED
argument_list|(
literal|"deleted"
argument_list|)
block|;
name|String
name|statusMsg
decl_stmt|;
name|TerminationStatus
parameter_list|(
name|String
name|msg
parameter_list|)
block|{
name|statusMsg
operator|=
name|msg
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|String
name|toString
parameter_list|()
block|{
return|return
name|statusMsg
return|;
block|}
block|}
end_enum

unit|}
end_unit

