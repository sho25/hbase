begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  *  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|math
operator|.
name|BigInteger
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Arrays
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collections
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Comparator
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|LinkedList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Set
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|TreeMap
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|cli
operator|.
name|CommandLine
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|cli
operator|.
name|GnuParser
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|cli
operator|.
name|HelpFormatter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|cli
operator|.
name|OptionBuilder
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|cli
operator|.
name|Options
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|cli
operator|.
name|ParseException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|lang
operator|.
name|ArrayUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|lang
operator|.
name|StringUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|Log
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|LogFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|classification
operator|.
name|InterfaceAudience
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FSDataInputStream
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FSDataOutputStream
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileStatus
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HBaseConfiguration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HColumnDescriptor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HConstants
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HRegionInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HRegionLocation
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HTableDescriptor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|ServerName
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|HBaseAdmin
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|HTable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|NoServerForRegionException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|HStore
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|StoreFile
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Preconditions
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|Lists
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|Maps
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|Sets
import|;
end_import

begin_comment
comment|/**  * The {@link RegionSplitter} class provides several utilities to help in the  * administration lifecycle for developers who choose to manually split regions  * instead of having HBase handle that automatically. The most useful utilities  * are:  *<p>  *<ul>  *<li>Create a table with a specified number of pre-split regions  *<li>Execute a rolling split of all regions on an existing table  *</ul>  *<p>  * Both operations can be safely done on a live server.  *<p>  *<b>Question:</b> How do I turn off automatic splitting?<br>  *<b>Answer:</b> Automatic splitting is determined by the configuration value  *<i>HConstants.HREGION_MAX_FILESIZE</i>. It is not recommended that you set this  * to Long.MAX_VALUE in case you forget about manual splits. A suggested setting  * is 100GB, which would result in> 1hr major compactions if reached.  *<p>  *<b>Question:</b> Why did the original authors decide to manually split?<br>  *<b>Answer:</b> Specific workload characteristics of our use case allowed us  * to benefit from a manual split system.  *<p>  *<ul>  *<li>Data (~1k) that would grow instead of being replaced  *<li>Data growth was roughly uniform across all regions  *<li>OLTP workload. Data loss is a big deal.  *</ul>  *<p>  *<b>Question:</b> Why is manual splitting good for this workload?<br>  *<b>Answer:</b> Although automated splitting is not a bad option, there are  * benefits to manual splitting.  *<p>  *<ul>  *<li>With growing amounts of data, splits will continually be needed. Since  * you always know exactly what regions you have, long-term debugging and  * profiling is much easier with manual splits. It is hard to trace the logs to  * understand region level problems if it keeps splitting and getting renamed.  *<li>Data offlining bugs + unknown number of split regions == oh crap! If an  * HLog or StoreFile was mistakenly unprocessed by HBase due to a weird bug and  * you notice it a day or so later, you can be assured that the regions  * specified in these files are the same as the current regions and you have  * less headaches trying to restore/replay your data.  *<li>You can finely tune your compaction algorithm. With roughly uniform data  * growth, it's easy to cause split / compaction storms as the regions all  * roughly hit the same data size at the same time. With manual splits, you can  * let staggered, time-based major compactions spread out your network IO load.  *</ul>  *<p>  *<b>Question:</b> What's the optimal number of pre-split regions to create?<br>  *<b>Answer:</b> Mileage will vary depending upon your application.  *<p>  * The short answer for our application is that we started with 10 pre-split  * regions / server and watched our data growth over time. It's better to err on  * the side of too little regions and rolling split later.  *<p>  * The more complicated answer is that this depends upon the largest storefile  * in your region. With a growing data size, this will get larger over time. You  * want the largest region to be just big enough that the {@link HStore} compact  * selection algorithm only compacts it due to a timed major. If you don't, your  * cluster can be prone to compaction storms as the algorithm decides to run  * major compactions on a large series of regions all at once. Note that  * compaction storms are due to the uniform data growth, not the manual split  * decision.  *<p>  * If you pre-split your regions too thin, you can increase the major compaction  * interval by configuring HConstants.MAJOR_COMPACTION_PERIOD. If your data size  * grows too large, use this script to perform a network IO safe rolling split  * of all regions.  */
end_comment

begin_class
annotation|@
name|InterfaceAudience
operator|.
name|Private
specifier|public
class|class
name|RegionSplitter
block|{
specifier|static
specifier|final
name|Log
name|LOG
init|=
name|LogFactory
operator|.
name|getLog
argument_list|(
name|RegionSplitter
operator|.
name|class
argument_list|)
decl_stmt|;
comment|/**    * A generic interface for the RegionSplitter code to use for all it's    * functionality. Note that the original authors of this code use    * {@link HexStringSplit} to partition their table and set it as default, but    * provided this for your custom algorithm. To use, create a new derived class    * from this interface and call {@link RegionSplitter#createPresplitTable} or    * {@link RegionSplitter#rollingSplit(String, String, Configuration)} with the    * argument splitClassName giving the name of your class.    */
specifier|public
specifier|static
interface|interface
name|SplitAlgorithm
block|{
comment|/**      * Split a pre-existing region into 2 regions.      *      * @param start      *          first row (inclusive)      * @param end      *          last row (exclusive)      * @return the split row to use      */
name|byte
index|[]
name|split
parameter_list|(
name|byte
index|[]
name|start
parameter_list|,
name|byte
index|[]
name|end
parameter_list|)
function_decl|;
comment|/**      * Split an entire table.      *      * @param numRegions      *          number of regions to split the table into      *      * @throws RuntimeException      *           user input is validated at this time. may throw a runtime      *           exception in response to a parse failure      * @return array of split keys for the initial regions of the table. The      *         length of the returned array should be numRegions-1.      */
name|byte
index|[]
index|[]
name|split
parameter_list|(
name|int
name|numRegions
parameter_list|)
function_decl|;
comment|/**      * In HBase, the first row is represented by an empty byte array. This might      * cause problems with your split algorithm or row printing. All your APIs      * will be passed firstRow() instead of empty array.      *      * @return your representation of your first row      */
name|byte
index|[]
name|firstRow
parameter_list|()
function_decl|;
comment|/**      * In HBase, the last row is represented by an empty byte array. This might      * cause problems with your split algorithm or row printing. All your APIs      * will be passed firstRow() instead of empty array.      *      * @return your representation of your last row      */
name|byte
index|[]
name|lastRow
parameter_list|()
function_decl|;
comment|/**      * In HBase, the last row is represented by an empty byte array. Set this      * value to help the split code understand how to evenly divide the first      * region.      *      * @param userInput      *          raw user input (may throw RuntimeException on parse failure)      */
name|void
name|setFirstRow
parameter_list|(
name|String
name|userInput
parameter_list|)
function_decl|;
comment|/**      * In HBase, the last row is represented by an empty byte array. Set this      * value to help the split code understand how to evenly divide the last      * region. Note that this last row is inclusive for all rows sharing the      * same prefix.      *      * @param userInput      *          raw user input (may throw RuntimeException on parse failure)      */
name|void
name|setLastRow
parameter_list|(
name|String
name|userInput
parameter_list|)
function_decl|;
comment|/**      * @param input      *          user or file input for row      * @return byte array representation of this row for HBase      */
name|byte
index|[]
name|strToRow
parameter_list|(
name|String
name|input
parameter_list|)
function_decl|;
comment|/**      * @param row      *          byte array representing a row in HBase      * @return String to use for debug& file printing      */
name|String
name|rowToStr
parameter_list|(
name|byte
index|[]
name|row
parameter_list|)
function_decl|;
comment|/**      * @return the separator character to use when storing / printing the row      */
name|String
name|separator
parameter_list|()
function_decl|;
block|}
comment|/**    * The main function for the RegionSplitter application. Common uses:    *<p>    *<ul>    *<li>create a table named 'myTable' with 60 pre-split regions containing 2    * column families 'test'& 'rs', assuming the keys are hex-encoded ASCII:    *<ul>    *<li>bin/hbase org.apache.hadoop.hbase.util.RegionSplitter -c 60 -f test:rs    * myTable HexStringSplit    *</ul>    *<li>perform a rolling split of 'myTable' (i.e. 60 => 120 regions), # 2    * outstanding splits at a time, assuming keys are uniformly distributed    * bytes:    *<ul>    *<li>bin/hbase org.apache.hadoop.hbase.util.RegionSplitter -r -o 2 myTable    * UniformSplit    *</ul>    *</ul>    *    * There are two SplitAlgorithms built into RegionSplitter, HexStringSplit    * and UniformSplit. These are different strategies for choosing region    * boundaries. See their source code for details.    *    * @param args    *          Usage: RegionSplitter&lt;TABLE&gt;&lt;SPLITALGORITHM&gt;    *&lt;-c&lt;# regions&gt; -f&lt;family:family:...&gt; | -r    *          [-o&lt;# outstanding splits&gt;]&gt;    *          [-D&lt;conf.param=value&gt;]    * @throws IOException    *           HBase IO problem    * @throws InterruptedException    *           user requested exit    * @throws ParseException    *           problem parsing user input    */
annotation|@
name|SuppressWarnings
argument_list|(
literal|"static-access"
argument_list|)
specifier|public
specifier|static
name|void
name|main
parameter_list|(
name|String
index|[]
name|args
parameter_list|)
throws|throws
name|IOException
throws|,
name|InterruptedException
throws|,
name|ParseException
block|{
name|Configuration
name|conf
init|=
name|HBaseConfiguration
operator|.
name|create
argument_list|()
decl_stmt|;
comment|// parse user input
name|Options
name|opt
init|=
operator|new
name|Options
argument_list|()
decl_stmt|;
name|opt
operator|.
name|addOption
argument_list|(
name|OptionBuilder
operator|.
name|withArgName
argument_list|(
literal|"property=value"
argument_list|)
operator|.
name|hasArg
argument_list|()
operator|.
name|withDescription
argument_list|(
literal|"Override HBase Configuration Settings"
argument_list|)
operator|.
name|create
argument_list|(
literal|"D"
argument_list|)
argument_list|)
expr_stmt|;
name|opt
operator|.
name|addOption
argument_list|(
name|OptionBuilder
operator|.
name|withArgName
argument_list|(
literal|"region count"
argument_list|)
operator|.
name|hasArg
argument_list|()
operator|.
name|withDescription
argument_list|(
literal|"Create a new table with a pre-split number of regions"
argument_list|)
operator|.
name|create
argument_list|(
literal|"c"
argument_list|)
argument_list|)
expr_stmt|;
name|opt
operator|.
name|addOption
argument_list|(
name|OptionBuilder
operator|.
name|withArgName
argument_list|(
literal|"family:family:..."
argument_list|)
operator|.
name|hasArg
argument_list|()
operator|.
name|withDescription
argument_list|(
literal|"Column Families to create with new table.  Required with -c"
argument_list|)
operator|.
name|create
argument_list|(
literal|"f"
argument_list|)
argument_list|)
expr_stmt|;
name|opt
operator|.
name|addOption
argument_list|(
literal|"h"
argument_list|,
literal|false
argument_list|,
literal|"Print this usage help"
argument_list|)
expr_stmt|;
name|opt
operator|.
name|addOption
argument_list|(
literal|"r"
argument_list|,
literal|false
argument_list|,
literal|"Perform a rolling split of an existing region"
argument_list|)
expr_stmt|;
name|opt
operator|.
name|addOption
argument_list|(
name|OptionBuilder
operator|.
name|withArgName
argument_list|(
literal|"count"
argument_list|)
operator|.
name|hasArg
argument_list|()
operator|.
name|withDescription
argument_list|(
literal|"Max outstanding splits that have unfinished major compactions"
argument_list|)
operator|.
name|create
argument_list|(
literal|"o"
argument_list|)
argument_list|)
expr_stmt|;
name|opt
operator|.
name|addOption
argument_list|(
literal|null
argument_list|,
literal|"firstrow"
argument_list|,
literal|true
argument_list|,
literal|"First Row in Table for Split Algorithm"
argument_list|)
expr_stmt|;
name|opt
operator|.
name|addOption
argument_list|(
literal|null
argument_list|,
literal|"lastrow"
argument_list|,
literal|true
argument_list|,
literal|"Last Row in Table for Split Algorithm"
argument_list|)
expr_stmt|;
name|opt
operator|.
name|addOption
argument_list|(
literal|null
argument_list|,
literal|"risky"
argument_list|,
literal|false
argument_list|,
literal|"Skip verification steps to complete quickly."
operator|+
literal|"STRONGLY DISCOURAGED for production systems.  "
argument_list|)
expr_stmt|;
name|CommandLine
name|cmd
init|=
operator|new
name|GnuParser
argument_list|()
operator|.
name|parse
argument_list|(
name|opt
argument_list|,
name|args
argument_list|)
decl_stmt|;
if|if
condition|(
name|cmd
operator|.
name|hasOption
argument_list|(
literal|"D"
argument_list|)
condition|)
block|{
for|for
control|(
name|String
name|confOpt
range|:
name|cmd
operator|.
name|getOptionValues
argument_list|(
literal|"D"
argument_list|)
control|)
block|{
name|String
index|[]
name|kv
init|=
name|confOpt
operator|.
name|split
argument_list|(
literal|"="
argument_list|,
literal|2
argument_list|)
decl_stmt|;
if|if
condition|(
name|kv
operator|.
name|length
operator|==
literal|2
condition|)
block|{
name|conf
operator|.
name|set
argument_list|(
name|kv
index|[
literal|0
index|]
argument_list|,
name|kv
index|[
literal|1
index|]
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"-D configuration override: "
operator|+
name|kv
index|[
literal|0
index|]
operator|+
literal|"="
operator|+
name|kv
index|[
literal|1
index|]
argument_list|)
expr_stmt|;
block|}
else|else
block|{
throw|throw
operator|new
name|ParseException
argument_list|(
literal|"-D option format invalid: "
operator|+
name|confOpt
argument_list|)
throw|;
block|}
block|}
block|}
if|if
condition|(
name|cmd
operator|.
name|hasOption
argument_list|(
literal|"risky"
argument_list|)
condition|)
block|{
name|conf
operator|.
name|setBoolean
argument_list|(
literal|"split.verify"
argument_list|,
literal|false
argument_list|)
expr_stmt|;
block|}
name|boolean
name|createTable
init|=
name|cmd
operator|.
name|hasOption
argument_list|(
literal|"c"
argument_list|)
operator|&&
name|cmd
operator|.
name|hasOption
argument_list|(
literal|"f"
argument_list|)
decl_stmt|;
name|boolean
name|rollingSplit
init|=
name|cmd
operator|.
name|hasOption
argument_list|(
literal|"r"
argument_list|)
decl_stmt|;
name|boolean
name|oneOperOnly
init|=
name|createTable
operator|^
name|rollingSplit
decl_stmt|;
if|if
condition|(
literal|2
operator|!=
name|cmd
operator|.
name|getArgList
argument_list|()
operator|.
name|size
argument_list|()
operator|||
operator|!
name|oneOperOnly
operator|||
name|cmd
operator|.
name|hasOption
argument_list|(
literal|"h"
argument_list|)
condition|)
block|{
operator|new
name|HelpFormatter
argument_list|()
operator|.
name|printHelp
argument_list|(
literal|"RegionSplitter<TABLE><SPLITALGORITHM>\n"
operator|+
literal|"SPLITALGORITHM is a java class name of a class implementing "
operator|+
literal|"SplitAlgorithm, or one of the special strings HexStringSplit "
operator|+
literal|"or UniformSplit, which are built-in split algorithms. "
operator|+
literal|"HexStringSplit treats keys as hexadecimal ASCII, and "
operator|+
literal|"UniformSplit treats keys as arbitrary bytes."
argument_list|,
name|opt
argument_list|)
expr_stmt|;
return|return;
block|}
name|String
name|tableName
init|=
name|cmd
operator|.
name|getArgs
argument_list|()
index|[
literal|0
index|]
decl_stmt|;
name|String
name|splitClass
init|=
name|cmd
operator|.
name|getArgs
argument_list|()
index|[
literal|1
index|]
decl_stmt|;
name|SplitAlgorithm
name|splitAlgo
init|=
name|newSplitAlgoInstance
argument_list|(
name|conf
argument_list|,
name|splitClass
argument_list|)
decl_stmt|;
if|if
condition|(
name|cmd
operator|.
name|hasOption
argument_list|(
literal|"firstrow"
argument_list|)
condition|)
block|{
name|splitAlgo
operator|.
name|setFirstRow
argument_list|(
name|cmd
operator|.
name|getOptionValue
argument_list|(
literal|"firstrow"
argument_list|)
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|cmd
operator|.
name|hasOption
argument_list|(
literal|"lastrow"
argument_list|)
condition|)
block|{
name|splitAlgo
operator|.
name|setLastRow
argument_list|(
name|cmd
operator|.
name|getOptionValue
argument_list|(
literal|"lastrow"
argument_list|)
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|createTable
condition|)
block|{
name|conf
operator|.
name|set
argument_list|(
literal|"split.count"
argument_list|,
name|cmd
operator|.
name|getOptionValue
argument_list|(
literal|"c"
argument_list|)
argument_list|)
expr_stmt|;
name|createPresplitTable
argument_list|(
name|tableName
argument_list|,
name|splitAlgo
argument_list|,
name|cmd
operator|.
name|getOptionValue
argument_list|(
literal|"f"
argument_list|)
operator|.
name|split
argument_list|(
literal|":"
argument_list|)
argument_list|,
name|conf
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|rollingSplit
condition|)
block|{
if|if
condition|(
name|cmd
operator|.
name|hasOption
argument_list|(
literal|"o"
argument_list|)
condition|)
block|{
name|conf
operator|.
name|set
argument_list|(
literal|"split.outstanding"
argument_list|,
name|cmd
operator|.
name|getOptionValue
argument_list|(
literal|"o"
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|rollingSplit
argument_list|(
name|tableName
argument_list|,
name|splitAlgo
argument_list|,
name|conf
argument_list|)
expr_stmt|;
block|}
block|}
specifier|static
name|void
name|createPresplitTable
parameter_list|(
name|String
name|tableName
parameter_list|,
name|SplitAlgorithm
name|splitAlgo
parameter_list|,
name|String
index|[]
name|columnFamilies
parameter_list|,
name|Configuration
name|conf
parameter_list|)
throws|throws
name|IOException
throws|,
name|InterruptedException
block|{
specifier|final
name|int
name|splitCount
init|=
name|conf
operator|.
name|getInt
argument_list|(
literal|"split.count"
argument_list|,
literal|0
argument_list|)
decl_stmt|;
name|Preconditions
operator|.
name|checkArgument
argument_list|(
name|splitCount
operator|>
literal|1
argument_list|,
literal|"Split count must be> 1"
argument_list|)
expr_stmt|;
name|Preconditions
operator|.
name|checkArgument
argument_list|(
name|columnFamilies
operator|.
name|length
operator|>
literal|0
argument_list|,
literal|"Must specify at least one column family. "
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Creating table "
operator|+
name|tableName
operator|+
literal|" with "
operator|+
name|columnFamilies
operator|.
name|length
operator|+
literal|" column families.  Presplitting to "
operator|+
name|splitCount
operator|+
literal|" regions"
argument_list|)
expr_stmt|;
name|HTableDescriptor
name|desc
init|=
operator|new
name|HTableDescriptor
argument_list|(
name|tableName
argument_list|)
decl_stmt|;
for|for
control|(
name|String
name|cf
range|:
name|columnFamilies
control|)
block|{
name|desc
operator|.
name|addFamily
argument_list|(
operator|new
name|HColumnDescriptor
argument_list|(
name|Bytes
operator|.
name|toBytes
argument_list|(
name|cf
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|HBaseAdmin
name|admin
init|=
operator|new
name|HBaseAdmin
argument_list|(
name|conf
argument_list|)
decl_stmt|;
name|Preconditions
operator|.
name|checkArgument
argument_list|(
operator|!
name|admin
operator|.
name|tableExists
argument_list|(
name|tableName
argument_list|)
argument_list|,
literal|"Table already exists: "
operator|+
name|tableName
argument_list|)
expr_stmt|;
name|admin
operator|.
name|createTable
argument_list|(
name|desc
argument_list|,
name|splitAlgo
operator|.
name|split
argument_list|(
name|splitCount
argument_list|)
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Table created!  Waiting for regions to show online in META..."
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|conf
operator|.
name|getBoolean
argument_list|(
literal|"split.verify"
argument_list|,
literal|true
argument_list|)
condition|)
block|{
comment|// NOTE: createTable is synchronous on the table, but not on the regions
name|HTable
name|table
init|=
operator|new
name|HTable
argument_list|(
name|conf
argument_list|,
name|tableName
argument_list|)
decl_stmt|;
name|int
name|onlineRegions
init|=
literal|0
decl_stmt|;
while|while
condition|(
name|onlineRegions
operator|<
name|splitCount
condition|)
block|{
name|onlineRegions
operator|=
name|table
operator|.
name|getRegionsInfo
argument_list|()
operator|.
name|size
argument_list|()
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
name|onlineRegions
operator|+
literal|" of "
operator|+
name|splitCount
operator|+
literal|" regions online..."
argument_list|)
expr_stmt|;
if|if
condition|(
name|onlineRegions
operator|<
name|splitCount
condition|)
block|{
name|Thread
operator|.
name|sleep
argument_list|(
literal|10
operator|*
literal|1000
argument_list|)
expr_stmt|;
comment|// sleep
block|}
block|}
name|table
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
name|LOG
operator|.
name|debug
argument_list|(
literal|"Finished creating table with "
operator|+
name|splitCount
operator|+
literal|" regions"
argument_list|)
expr_stmt|;
block|}
specifier|static
name|void
name|rollingSplit
parameter_list|(
name|String
name|tableName
parameter_list|,
name|SplitAlgorithm
name|splitAlgo
parameter_list|,
name|Configuration
name|conf
parameter_list|)
throws|throws
name|IOException
throws|,
name|InterruptedException
block|{
specifier|final
name|int
name|minOS
init|=
name|conf
operator|.
name|getInt
argument_list|(
literal|"split.outstanding"
argument_list|,
literal|2
argument_list|)
decl_stmt|;
name|HTable
name|table
init|=
operator|new
name|HTable
argument_list|(
name|conf
argument_list|,
name|tableName
argument_list|)
decl_stmt|;
comment|// max outstanding splits. default == 50% of servers
specifier|final
name|int
name|MAX_OUTSTANDING
init|=
name|Math
operator|.
name|max
argument_list|(
name|table
operator|.
name|getConnection
argument_list|()
operator|.
name|getCurrentNrHRS
argument_list|()
operator|/
literal|2
argument_list|,
name|minOS
argument_list|)
decl_stmt|;
name|Path
name|hbDir
init|=
operator|new
name|Path
argument_list|(
name|conf
operator|.
name|get
argument_list|(
name|HConstants
operator|.
name|HBASE_DIR
argument_list|)
argument_list|)
decl_stmt|;
name|Path
name|tableDir
init|=
name|HTableDescriptor
operator|.
name|getTableDir
argument_list|(
name|hbDir
argument_list|,
name|table
operator|.
name|getTableName
argument_list|()
argument_list|)
decl_stmt|;
name|Path
name|splitFile
init|=
operator|new
name|Path
argument_list|(
name|tableDir
argument_list|,
literal|"_balancedSplit"
argument_list|)
decl_stmt|;
name|FileSystem
name|fs
init|=
name|FileSystem
operator|.
name|get
argument_list|(
name|conf
argument_list|)
decl_stmt|;
comment|// get a list of daughter regions to create
name|LinkedList
argument_list|<
name|Pair
argument_list|<
name|byte
index|[]
argument_list|,
name|byte
index|[]
argument_list|>
argument_list|>
name|tmpRegionSet
init|=
name|getSplits
argument_list|(
name|table
argument_list|,
name|splitAlgo
argument_list|)
decl_stmt|;
name|LinkedList
argument_list|<
name|Pair
argument_list|<
name|byte
index|[]
argument_list|,
name|byte
index|[]
argument_list|>
argument_list|>
name|outstanding
init|=
name|Lists
operator|.
name|newLinkedList
argument_list|()
decl_stmt|;
name|int
name|splitCount
init|=
literal|0
decl_stmt|;
specifier|final
name|int
name|origCount
init|=
name|tmpRegionSet
operator|.
name|size
argument_list|()
decl_stmt|;
comment|// all splits must compact& we have 1 compact thread, so 2 split
comment|// requests to the same RS can stall the outstanding split queue.
comment|// To fix, group the regions into an RS pool and round-robin through it
name|LOG
operator|.
name|debug
argument_list|(
literal|"Bucketing regions by regionserver..."
argument_list|)
expr_stmt|;
name|TreeMap
argument_list|<
name|String
argument_list|,
name|LinkedList
argument_list|<
name|Pair
argument_list|<
name|byte
index|[]
argument_list|,
name|byte
index|[]
argument_list|>
argument_list|>
argument_list|>
name|daughterRegions
init|=
name|Maps
operator|.
name|newTreeMap
argument_list|()
decl_stmt|;
for|for
control|(
name|Pair
argument_list|<
name|byte
index|[]
argument_list|,
name|byte
index|[]
argument_list|>
name|dr
range|:
name|tmpRegionSet
control|)
block|{
name|String
name|rsLocation
init|=
name|table
operator|.
name|getRegionLocation
argument_list|(
name|dr
operator|.
name|getSecond
argument_list|()
argument_list|)
operator|.
name|getHostnamePort
argument_list|()
decl_stmt|;
if|if
condition|(
operator|!
name|daughterRegions
operator|.
name|containsKey
argument_list|(
name|rsLocation
argument_list|)
condition|)
block|{
name|LinkedList
argument_list|<
name|Pair
argument_list|<
name|byte
index|[]
argument_list|,
name|byte
index|[]
argument_list|>
argument_list|>
name|entry
init|=
name|Lists
operator|.
name|newLinkedList
argument_list|()
decl_stmt|;
name|daughterRegions
operator|.
name|put
argument_list|(
name|rsLocation
argument_list|,
name|entry
argument_list|)
expr_stmt|;
block|}
name|daughterRegions
operator|.
name|get
argument_list|(
name|rsLocation
argument_list|)
operator|.
name|add
argument_list|(
name|dr
argument_list|)
expr_stmt|;
block|}
name|LOG
operator|.
name|debug
argument_list|(
literal|"Done with bucketing.  Split time!"
argument_list|)
expr_stmt|;
name|long
name|startTime
init|=
name|EnvironmentEdgeManager
operator|.
name|currentTimeMillis
argument_list|()
decl_stmt|;
comment|// open the split file and modify it as splits finish
name|FSDataInputStream
name|tmpIn
init|=
name|fs
operator|.
name|open
argument_list|(
name|splitFile
argument_list|)
decl_stmt|;
name|byte
index|[]
name|rawData
init|=
operator|new
name|byte
index|[
name|tmpIn
operator|.
name|available
argument_list|()
index|]
decl_stmt|;
name|tmpIn
operator|.
name|readFully
argument_list|(
name|rawData
argument_list|)
expr_stmt|;
name|tmpIn
operator|.
name|close
argument_list|()
expr_stmt|;
name|FSDataOutputStream
name|splitOut
init|=
name|fs
operator|.
name|create
argument_list|(
name|splitFile
argument_list|)
decl_stmt|;
name|splitOut
operator|.
name|write
argument_list|(
name|rawData
argument_list|)
expr_stmt|;
try|try
block|{
comment|// *** split code ***
while|while
condition|(
operator|!
name|daughterRegions
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
name|daughterRegions
operator|.
name|size
argument_list|()
operator|+
literal|" RS have regions to splt."
argument_list|)
expr_stmt|;
comment|// Get RegionServer : region count mapping
specifier|final
name|TreeMap
argument_list|<
name|ServerName
argument_list|,
name|Integer
argument_list|>
name|rsSizes
init|=
name|Maps
operator|.
name|newTreeMap
argument_list|()
decl_stmt|;
name|Map
argument_list|<
name|HRegionInfo
argument_list|,
name|ServerName
argument_list|>
name|regionsInfo
init|=
name|table
operator|.
name|getRegionLocations
argument_list|()
decl_stmt|;
for|for
control|(
name|ServerName
name|rs
range|:
name|regionsInfo
operator|.
name|values
argument_list|()
control|)
block|{
if|if
condition|(
name|rsSizes
operator|.
name|containsKey
argument_list|(
name|rs
argument_list|)
condition|)
block|{
name|rsSizes
operator|.
name|put
argument_list|(
name|rs
argument_list|,
name|rsSizes
operator|.
name|get
argument_list|(
name|rs
argument_list|)
operator|+
literal|1
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|rsSizes
operator|.
name|put
argument_list|(
name|rs
argument_list|,
literal|1
argument_list|)
expr_stmt|;
block|}
block|}
comment|// sort the RS by the number of regions they have
name|List
argument_list|<
name|String
argument_list|>
name|serversLeft
init|=
name|Lists
operator|.
name|newArrayList
argument_list|(
name|daughterRegions
operator|.
name|keySet
argument_list|()
argument_list|)
decl_stmt|;
name|Collections
operator|.
name|sort
argument_list|(
name|serversLeft
argument_list|,
operator|new
name|Comparator
argument_list|<
name|String
argument_list|>
argument_list|()
block|{
specifier|public
name|int
name|compare
parameter_list|(
name|String
name|o1
parameter_list|,
name|String
name|o2
parameter_list|)
block|{
return|return
name|rsSizes
operator|.
name|get
argument_list|(
name|o1
argument_list|)
operator|.
name|compareTo
argument_list|(
name|rsSizes
operator|.
name|get
argument_list|(
name|o2
argument_list|)
argument_list|)
return|;
block|}
block|}
argument_list|)
expr_stmt|;
comment|// round-robin through the RS list. Choose the lightest-loaded servers
comment|// first to keep the master from load-balancing regions as we split.
for|for
control|(
name|String
name|rsLoc
range|:
name|serversLeft
control|)
block|{
name|Pair
argument_list|<
name|byte
index|[]
argument_list|,
name|byte
index|[]
argument_list|>
name|dr
init|=
literal|null
decl_stmt|;
comment|// find a region in the RS list that hasn't been moved
name|LOG
operator|.
name|debug
argument_list|(
literal|"Finding a region on "
operator|+
name|rsLoc
argument_list|)
expr_stmt|;
name|LinkedList
argument_list|<
name|Pair
argument_list|<
name|byte
index|[]
argument_list|,
name|byte
index|[]
argument_list|>
argument_list|>
name|regionList
init|=
name|daughterRegions
operator|.
name|get
argument_list|(
name|rsLoc
argument_list|)
decl_stmt|;
while|while
condition|(
operator|!
name|regionList
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|dr
operator|=
name|regionList
operator|.
name|pop
argument_list|()
expr_stmt|;
comment|// get current region info
name|byte
index|[]
name|split
init|=
name|dr
operator|.
name|getSecond
argument_list|()
decl_stmt|;
name|HRegionLocation
name|regionLoc
init|=
name|table
operator|.
name|getRegionLocation
argument_list|(
name|split
argument_list|)
decl_stmt|;
comment|// if this region moved locations
name|String
name|newRs
init|=
name|regionLoc
operator|.
name|getHostnamePort
argument_list|()
decl_stmt|;
if|if
condition|(
name|newRs
operator|.
name|compareTo
argument_list|(
name|rsLoc
argument_list|)
operator|!=
literal|0
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Region with "
operator|+
name|splitAlgo
operator|.
name|rowToStr
argument_list|(
name|split
argument_list|)
operator|+
literal|" moved to "
operator|+
name|newRs
operator|+
literal|". Relocating..."
argument_list|)
expr_stmt|;
comment|// relocate it, don't use it right now
if|if
condition|(
operator|!
name|daughterRegions
operator|.
name|containsKey
argument_list|(
name|newRs
argument_list|)
condition|)
block|{
name|LinkedList
argument_list|<
name|Pair
argument_list|<
name|byte
index|[]
argument_list|,
name|byte
index|[]
argument_list|>
argument_list|>
name|entry
init|=
name|Lists
operator|.
name|newLinkedList
argument_list|()
decl_stmt|;
name|daughterRegions
operator|.
name|put
argument_list|(
name|newRs
argument_list|,
name|entry
argument_list|)
expr_stmt|;
block|}
name|daughterRegions
operator|.
name|get
argument_list|(
name|newRs
argument_list|)
operator|.
name|add
argument_list|(
name|dr
argument_list|)
expr_stmt|;
name|dr
operator|=
literal|null
expr_stmt|;
continue|continue;
block|}
comment|// make sure this region wasn't already split
name|byte
index|[]
name|sk
init|=
name|regionLoc
operator|.
name|getRegionInfo
argument_list|()
operator|.
name|getStartKey
argument_list|()
decl_stmt|;
if|if
condition|(
name|sk
operator|.
name|length
operator|!=
literal|0
condition|)
block|{
if|if
condition|(
name|Bytes
operator|.
name|equals
argument_list|(
name|split
argument_list|,
name|sk
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Region already split on "
operator|+
name|splitAlgo
operator|.
name|rowToStr
argument_list|(
name|split
argument_list|)
operator|+
literal|".  Skipping this region..."
argument_list|)
expr_stmt|;
operator|++
name|splitCount
expr_stmt|;
name|dr
operator|=
literal|null
expr_stmt|;
continue|continue;
block|}
name|byte
index|[]
name|start
init|=
name|dr
operator|.
name|getFirst
argument_list|()
decl_stmt|;
name|Preconditions
operator|.
name|checkArgument
argument_list|(
name|Bytes
operator|.
name|equals
argument_list|(
name|start
argument_list|,
name|sk
argument_list|)
argument_list|,
name|splitAlgo
operator|.
name|rowToStr
argument_list|(
name|start
argument_list|)
operator|+
literal|" != "
operator|+
name|splitAlgo
operator|.
name|rowToStr
argument_list|(
name|sk
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|// passed all checks! found a good region
break|break;
block|}
if|if
condition|(
name|regionList
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|daughterRegions
operator|.
name|remove
argument_list|(
name|rsLoc
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|dr
operator|==
literal|null
condition|)
continue|continue;
comment|// we have a good region, time to split!
name|byte
index|[]
name|split
init|=
name|dr
operator|.
name|getSecond
argument_list|()
decl_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Splitting at "
operator|+
name|splitAlgo
operator|.
name|rowToStr
argument_list|(
name|split
argument_list|)
argument_list|)
expr_stmt|;
name|HBaseAdmin
name|admin
init|=
operator|new
name|HBaseAdmin
argument_list|(
name|table
operator|.
name|getConfiguration
argument_list|()
argument_list|)
decl_stmt|;
name|admin
operator|.
name|split
argument_list|(
name|table
operator|.
name|getTableName
argument_list|()
argument_list|,
name|split
argument_list|)
expr_stmt|;
name|LinkedList
argument_list|<
name|Pair
argument_list|<
name|byte
index|[]
argument_list|,
name|byte
index|[]
argument_list|>
argument_list|>
name|finished
init|=
name|Lists
operator|.
name|newLinkedList
argument_list|()
decl_stmt|;
if|if
condition|(
name|conf
operator|.
name|getBoolean
argument_list|(
literal|"split.verify"
argument_list|,
literal|true
argument_list|)
condition|)
block|{
comment|// we need to verify and rate-limit our splits
name|outstanding
operator|.
name|addLast
argument_list|(
name|dr
argument_list|)
expr_stmt|;
comment|// with too many outstanding splits, wait for some to finish
while|while
condition|(
name|outstanding
operator|.
name|size
argument_list|()
operator|>=
name|MAX_OUTSTANDING
condition|)
block|{
name|finished
operator|=
name|splitScan
argument_list|(
name|outstanding
argument_list|,
name|table
argument_list|,
name|splitAlgo
argument_list|)
expr_stmt|;
if|if
condition|(
name|finished
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|Thread
operator|.
name|sleep
argument_list|(
literal|30
operator|*
literal|1000
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|outstanding
operator|.
name|removeAll
argument_list|(
name|finished
argument_list|)
expr_stmt|;
block|}
block|}
block|}
else|else
block|{
name|finished
operator|.
name|add
argument_list|(
name|dr
argument_list|)
expr_stmt|;
block|}
comment|// mark each finished region as successfully split.
for|for
control|(
name|Pair
argument_list|<
name|byte
index|[]
argument_list|,
name|byte
index|[]
argument_list|>
name|region
range|:
name|finished
control|)
block|{
name|splitOut
operator|.
name|writeChars
argument_list|(
literal|"- "
operator|+
name|splitAlgo
operator|.
name|rowToStr
argument_list|(
name|region
operator|.
name|getFirst
argument_list|()
argument_list|)
operator|+
literal|" "
operator|+
name|splitAlgo
operator|.
name|rowToStr
argument_list|(
name|region
operator|.
name|getSecond
argument_list|()
argument_list|)
operator|+
literal|"\n"
argument_list|)
expr_stmt|;
name|splitCount
operator|++
expr_stmt|;
if|if
condition|(
name|splitCount
operator|%
literal|10
operator|==
literal|0
condition|)
block|{
name|long
name|tDiff
init|=
operator|(
name|EnvironmentEdgeManager
operator|.
name|currentTimeMillis
argument_list|()
operator|-
name|startTime
operator|)
operator|/
name|splitCount
decl_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"STATUS UPDATE: "
operator|+
name|splitCount
operator|+
literal|" / "
operator|+
name|origCount
operator|+
literal|". Avg Time / Split = "
operator|+
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|StringUtils
operator|.
name|formatTime
argument_list|(
name|tDiff
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
if|if
condition|(
name|conf
operator|.
name|getBoolean
argument_list|(
literal|"split.verify"
argument_list|,
literal|true
argument_list|)
condition|)
block|{
while|while
condition|(
operator|!
name|outstanding
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|LinkedList
argument_list|<
name|Pair
argument_list|<
name|byte
index|[]
argument_list|,
name|byte
index|[]
argument_list|>
argument_list|>
name|finished
init|=
name|splitScan
argument_list|(
name|outstanding
argument_list|,
name|table
argument_list|,
name|splitAlgo
argument_list|)
decl_stmt|;
if|if
condition|(
name|finished
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|Thread
operator|.
name|sleep
argument_list|(
literal|30
operator|*
literal|1000
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|outstanding
operator|.
name|removeAll
argument_list|(
name|finished
argument_list|)
expr_stmt|;
for|for
control|(
name|Pair
argument_list|<
name|byte
index|[]
argument_list|,
name|byte
index|[]
argument_list|>
name|region
range|:
name|finished
control|)
block|{
name|splitOut
operator|.
name|writeChars
argument_list|(
literal|"- "
operator|+
name|splitAlgo
operator|.
name|rowToStr
argument_list|(
name|region
operator|.
name|getFirst
argument_list|()
argument_list|)
operator|+
literal|" "
operator|+
name|splitAlgo
operator|.
name|rowToStr
argument_list|(
name|region
operator|.
name|getSecond
argument_list|()
argument_list|)
operator|+
literal|"\n"
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
name|LOG
operator|.
name|debug
argument_list|(
literal|"All regions have been successfully split!"
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|long
name|tDiff
init|=
name|EnvironmentEdgeManager
operator|.
name|currentTimeMillis
argument_list|()
operator|-
name|startTime
decl_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"TOTAL TIME = "
operator|+
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|StringUtils
operator|.
name|formatTime
argument_list|(
name|tDiff
argument_list|)
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Splits = "
operator|+
name|splitCount
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Avg Time / Split = "
operator|+
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|StringUtils
operator|.
name|formatTime
argument_list|(
name|tDiff
operator|/
name|splitCount
argument_list|)
argument_list|)
expr_stmt|;
name|splitOut
operator|.
name|close
argument_list|()
expr_stmt|;
if|if
condition|(
name|table
operator|!=
literal|null
condition|)
block|{
name|table
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
block|}
name|fs
operator|.
name|delete
argument_list|(
name|splitFile
argument_list|,
literal|false
argument_list|)
expr_stmt|;
block|}
comment|/**    * @throws IOException if the specified SplitAlgorithm class couldn't be    * instantiated    */
specifier|public
specifier|static
name|SplitAlgorithm
name|newSplitAlgoInstance
parameter_list|(
name|Configuration
name|conf
parameter_list|,
name|String
name|splitClassName
parameter_list|)
throws|throws
name|IOException
block|{
name|Class
argument_list|<
name|?
argument_list|>
name|splitClass
decl_stmt|;
comment|// For split algorithms builtin to RegionSplitter, the user can specify
comment|// their simple class name instead of a fully qualified class name.
if|if
condition|(
name|splitClassName
operator|.
name|equals
argument_list|(
name|HexStringSplit
operator|.
name|class
operator|.
name|getSimpleName
argument_list|()
argument_list|)
condition|)
block|{
name|splitClass
operator|=
name|HexStringSplit
operator|.
name|class
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|splitClassName
operator|.
name|equals
argument_list|(
name|UniformSplit
operator|.
name|class
operator|.
name|getSimpleName
argument_list|()
argument_list|)
condition|)
block|{
name|splitClass
operator|=
name|UniformSplit
operator|.
name|class
expr_stmt|;
block|}
else|else
block|{
try|try
block|{
name|splitClass
operator|=
name|conf
operator|.
name|getClassByName
argument_list|(
name|splitClassName
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|ClassNotFoundException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Couldn't load split class "
operator|+
name|splitClassName
argument_list|,
name|e
argument_list|)
throw|;
block|}
if|if
condition|(
name|splitClass
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Failed loading split class "
operator|+
name|splitClassName
argument_list|)
throw|;
block|}
if|if
condition|(
operator|!
name|SplitAlgorithm
operator|.
name|class
operator|.
name|isAssignableFrom
argument_list|(
name|splitClass
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Specified split class doesn't implement SplitAlgorithm"
argument_list|)
throw|;
block|}
block|}
try|try
block|{
return|return
name|splitClass
operator|.
name|asSubclass
argument_list|(
name|SplitAlgorithm
operator|.
name|class
argument_list|)
operator|.
name|newInstance
argument_list|()
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Problem loading split algorithm: "
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
specifier|static
name|LinkedList
argument_list|<
name|Pair
argument_list|<
name|byte
index|[]
argument_list|,
name|byte
index|[]
argument_list|>
argument_list|>
name|splitScan
parameter_list|(
name|LinkedList
argument_list|<
name|Pair
argument_list|<
name|byte
index|[]
argument_list|,
name|byte
index|[]
argument_list|>
argument_list|>
name|regionList
parameter_list|,
name|HTable
name|table
parameter_list|,
name|SplitAlgorithm
name|splitAlgo
parameter_list|)
throws|throws
name|IOException
throws|,
name|InterruptedException
block|{
name|LinkedList
argument_list|<
name|Pair
argument_list|<
name|byte
index|[]
argument_list|,
name|byte
index|[]
argument_list|>
argument_list|>
name|finished
init|=
name|Lists
operator|.
name|newLinkedList
argument_list|()
decl_stmt|;
name|LinkedList
argument_list|<
name|Pair
argument_list|<
name|byte
index|[]
argument_list|,
name|byte
index|[]
argument_list|>
argument_list|>
name|logicalSplitting
init|=
name|Lists
operator|.
name|newLinkedList
argument_list|()
decl_stmt|;
name|LinkedList
argument_list|<
name|Pair
argument_list|<
name|byte
index|[]
argument_list|,
name|byte
index|[]
argument_list|>
argument_list|>
name|physicalSplitting
init|=
name|Lists
operator|.
name|newLinkedList
argument_list|()
decl_stmt|;
comment|// get table info
name|Path
name|hbDir
init|=
operator|new
name|Path
argument_list|(
name|table
operator|.
name|getConfiguration
argument_list|()
operator|.
name|get
argument_list|(
name|HConstants
operator|.
name|HBASE_DIR
argument_list|)
argument_list|)
decl_stmt|;
name|Path
name|tableDir
init|=
name|HTableDescriptor
operator|.
name|getTableDir
argument_list|(
name|hbDir
argument_list|,
name|table
operator|.
name|getTableName
argument_list|()
argument_list|)
decl_stmt|;
name|FileSystem
name|fs
init|=
name|FileSystem
operator|.
name|get
argument_list|(
name|table
operator|.
name|getConfiguration
argument_list|()
argument_list|)
decl_stmt|;
comment|// clear the cache to forcibly refresh region information
name|table
operator|.
name|clearRegionCache
argument_list|()
expr_stmt|;
comment|// for every region that hasn't been verified as a finished split
for|for
control|(
name|Pair
argument_list|<
name|byte
index|[]
argument_list|,
name|byte
index|[]
argument_list|>
name|region
range|:
name|regionList
control|)
block|{
name|byte
index|[]
name|start
init|=
name|region
operator|.
name|getFirst
argument_list|()
decl_stmt|;
name|byte
index|[]
name|split
init|=
name|region
operator|.
name|getSecond
argument_list|()
decl_stmt|;
comment|// see if the new split daughter region has come online
try|try
block|{
name|HRegionInfo
name|dri
init|=
name|table
operator|.
name|getRegionLocation
argument_list|(
name|split
argument_list|)
operator|.
name|getRegionInfo
argument_list|()
decl_stmt|;
if|if
condition|(
name|dri
operator|.
name|isOffline
argument_list|()
operator|||
operator|!
name|Bytes
operator|.
name|equals
argument_list|(
name|dri
operator|.
name|getStartKey
argument_list|()
argument_list|,
name|split
argument_list|)
condition|)
block|{
name|logicalSplitting
operator|.
name|add
argument_list|(
name|region
argument_list|)
expr_stmt|;
continue|continue;
block|}
block|}
catch|catch
parameter_list|(
name|NoServerForRegionException
name|nsfre
parameter_list|)
block|{
comment|// NSFRE will occur if the old META entry has no server assigned
name|LOG
operator|.
name|info
argument_list|(
name|nsfre
argument_list|)
expr_stmt|;
name|logicalSplitting
operator|.
name|add
argument_list|(
name|region
argument_list|)
expr_stmt|;
continue|continue;
block|}
try|try
block|{
comment|// when a daughter region is opened, a compaction is triggered
comment|// wait until compaction completes for both daughter regions
name|LinkedList
argument_list|<
name|HRegionInfo
argument_list|>
name|check
init|=
name|Lists
operator|.
name|newLinkedList
argument_list|()
decl_stmt|;
name|check
operator|.
name|add
argument_list|(
name|table
operator|.
name|getRegionLocation
argument_list|(
name|start
argument_list|)
operator|.
name|getRegionInfo
argument_list|()
argument_list|)
expr_stmt|;
name|check
operator|.
name|add
argument_list|(
name|table
operator|.
name|getRegionLocation
argument_list|(
name|split
argument_list|)
operator|.
name|getRegionInfo
argument_list|()
argument_list|)
expr_stmt|;
for|for
control|(
name|HRegionInfo
name|hri
range|:
name|check
operator|.
name|toArray
argument_list|(
operator|new
name|HRegionInfo
index|[]
block|{}
argument_list|)
control|)
block|{
name|boolean
name|refFound
init|=
literal|false
decl_stmt|;
name|byte
index|[]
name|sk
init|=
name|hri
operator|.
name|getStartKey
argument_list|()
decl_stmt|;
if|if
condition|(
name|sk
operator|.
name|length
operator|==
literal|0
condition|)
name|sk
operator|=
name|splitAlgo
operator|.
name|firstRow
argument_list|()
expr_stmt|;
name|String
name|startKey
init|=
name|splitAlgo
operator|.
name|rowToStr
argument_list|(
name|sk
argument_list|)
decl_stmt|;
name|HTableDescriptor
name|htd
init|=
name|table
operator|.
name|getTableDescriptor
argument_list|()
decl_stmt|;
comment|// check every Column Family for that region
for|for
control|(
name|HColumnDescriptor
name|c
range|:
name|htd
operator|.
name|getFamilies
argument_list|()
control|)
block|{
name|Path
name|cfDir
init|=
name|HStore
operator|.
name|getStoreHomedir
argument_list|(
name|tableDir
argument_list|,
name|hri
operator|.
name|getEncodedName
argument_list|()
argument_list|,
name|c
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|fs
operator|.
name|exists
argument_list|(
name|cfDir
argument_list|)
condition|)
block|{
for|for
control|(
name|FileStatus
name|file
range|:
name|fs
operator|.
name|listStatus
argument_list|(
name|cfDir
argument_list|)
control|)
block|{
name|refFound
operator||=
name|StoreFile
operator|.
name|isReference
argument_list|(
name|file
operator|.
name|getPath
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|refFound
condition|)
break|break;
block|}
block|}
if|if
condition|(
name|refFound
condition|)
break|break;
block|}
comment|// compaction is completed when all reference files are gone
if|if
condition|(
operator|!
name|refFound
condition|)
block|{
name|check
operator|.
name|remove
argument_list|(
name|hri
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|check
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|finished
operator|.
name|add
argument_list|(
name|region
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|physicalSplitting
operator|.
name|add
argument_list|(
name|region
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|NoServerForRegionException
name|nsfre
parameter_list|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"No Server Exception thrown for: "
operator|+
name|splitAlgo
operator|.
name|rowToStr
argument_list|(
name|start
argument_list|)
argument_list|)
expr_stmt|;
name|physicalSplitting
operator|.
name|add
argument_list|(
name|region
argument_list|)
expr_stmt|;
name|table
operator|.
name|clearRegionCache
argument_list|()
expr_stmt|;
block|}
block|}
name|LOG
operator|.
name|debug
argument_list|(
literal|"Split Scan: "
operator|+
name|finished
operator|.
name|size
argument_list|()
operator|+
literal|" finished / "
operator|+
name|logicalSplitting
operator|.
name|size
argument_list|()
operator|+
literal|" split wait / "
operator|+
name|physicalSplitting
operator|.
name|size
argument_list|()
operator|+
literal|" reference wait"
argument_list|)
expr_stmt|;
return|return
name|finished
return|;
block|}
specifier|static
name|LinkedList
argument_list|<
name|Pair
argument_list|<
name|byte
index|[]
argument_list|,
name|byte
index|[]
argument_list|>
argument_list|>
name|getSplits
parameter_list|(
name|HTable
name|table
parameter_list|,
name|SplitAlgorithm
name|splitAlgo
parameter_list|)
throws|throws
name|IOException
block|{
name|Path
name|hbDir
init|=
operator|new
name|Path
argument_list|(
name|table
operator|.
name|getConfiguration
argument_list|()
operator|.
name|get
argument_list|(
name|HConstants
operator|.
name|HBASE_DIR
argument_list|)
argument_list|)
decl_stmt|;
name|Path
name|tableDir
init|=
name|HTableDescriptor
operator|.
name|getTableDir
argument_list|(
name|hbDir
argument_list|,
name|table
operator|.
name|getTableName
argument_list|()
argument_list|)
decl_stmt|;
name|Path
name|splitFile
init|=
operator|new
name|Path
argument_list|(
name|tableDir
argument_list|,
literal|"_balancedSplit"
argument_list|)
decl_stmt|;
name|FileSystem
name|fs
init|=
name|FileSystem
operator|.
name|get
argument_list|(
name|table
operator|.
name|getConfiguration
argument_list|()
argument_list|)
decl_stmt|;
comment|// using strings because (new byte[]{0}).equals(new byte[]{0}) == false
name|Set
argument_list|<
name|Pair
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
argument_list|>
name|daughterRegions
init|=
name|Sets
operator|.
name|newHashSet
argument_list|()
decl_stmt|;
comment|// does a split file exist?
if|if
condition|(
operator|!
name|fs
operator|.
name|exists
argument_list|(
name|splitFile
argument_list|)
condition|)
block|{
comment|// NO = fresh start. calculate splits to make
name|LOG
operator|.
name|debug
argument_list|(
literal|"No _balancedSplit file.  Calculating splits..."
argument_list|)
expr_stmt|;
comment|// query meta for all regions in the table
name|Set
argument_list|<
name|Pair
argument_list|<
name|byte
index|[]
argument_list|,
name|byte
index|[]
argument_list|>
argument_list|>
name|rows
init|=
name|Sets
operator|.
name|newHashSet
argument_list|()
decl_stmt|;
name|Pair
argument_list|<
name|byte
index|[]
index|[]
argument_list|,
name|byte
index|[]
index|[]
argument_list|>
name|tmp
init|=
name|table
operator|.
name|getStartEndKeys
argument_list|()
decl_stmt|;
name|Preconditions
operator|.
name|checkArgument
argument_list|(
name|tmp
operator|.
name|getFirst
argument_list|()
operator|.
name|length
operator|==
name|tmp
operator|.
name|getSecond
argument_list|()
operator|.
name|length
argument_list|,
literal|"Start and End rows should be equivalent"
argument_list|)
expr_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|tmp
operator|.
name|getFirst
argument_list|()
operator|.
name|length
condition|;
operator|++
name|i
control|)
block|{
name|byte
index|[]
name|start
init|=
name|tmp
operator|.
name|getFirst
argument_list|()
index|[
name|i
index|]
decl_stmt|,
name|end
init|=
name|tmp
operator|.
name|getSecond
argument_list|()
index|[
name|i
index|]
decl_stmt|;
if|if
condition|(
name|start
operator|.
name|length
operator|==
literal|0
condition|)
name|start
operator|=
name|splitAlgo
operator|.
name|firstRow
argument_list|()
expr_stmt|;
if|if
condition|(
name|end
operator|.
name|length
operator|==
literal|0
condition|)
name|end
operator|=
name|splitAlgo
operator|.
name|lastRow
argument_list|()
expr_stmt|;
name|rows
operator|.
name|add
argument_list|(
name|Pair
operator|.
name|newPair
argument_list|(
name|start
argument_list|,
name|end
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|LOG
operator|.
name|debug
argument_list|(
literal|"Table "
operator|+
name|Bytes
operator|.
name|toString
argument_list|(
name|table
operator|.
name|getTableName
argument_list|()
argument_list|)
operator|+
literal|" has "
operator|+
name|rows
operator|.
name|size
argument_list|()
operator|+
literal|" regions that will be split."
argument_list|)
expr_stmt|;
comment|// prepare the split file
name|Path
name|tmpFile
init|=
operator|new
name|Path
argument_list|(
name|tableDir
argument_list|,
literal|"_balancedSplit_prepare"
argument_list|)
decl_stmt|;
name|FSDataOutputStream
name|tmpOut
init|=
name|fs
operator|.
name|create
argument_list|(
name|tmpFile
argument_list|)
decl_stmt|;
comment|// calculate all the splits == [daughterRegions] = [(start, splitPoint)]
for|for
control|(
name|Pair
argument_list|<
name|byte
index|[]
argument_list|,
name|byte
index|[]
argument_list|>
name|r
range|:
name|rows
control|)
block|{
name|byte
index|[]
name|splitPoint
init|=
name|splitAlgo
operator|.
name|split
argument_list|(
name|r
operator|.
name|getFirst
argument_list|()
argument_list|,
name|r
operator|.
name|getSecond
argument_list|()
argument_list|)
decl_stmt|;
name|String
name|startStr
init|=
name|splitAlgo
operator|.
name|rowToStr
argument_list|(
name|r
operator|.
name|getFirst
argument_list|()
argument_list|)
decl_stmt|;
name|String
name|splitStr
init|=
name|splitAlgo
operator|.
name|rowToStr
argument_list|(
name|splitPoint
argument_list|)
decl_stmt|;
name|daughterRegions
operator|.
name|add
argument_list|(
name|Pair
operator|.
name|newPair
argument_list|(
name|startStr
argument_list|,
name|splitStr
argument_list|)
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Will Split ["
operator|+
name|startStr
operator|+
literal|" , "
operator|+
name|splitAlgo
operator|.
name|rowToStr
argument_list|(
name|r
operator|.
name|getSecond
argument_list|()
argument_list|)
operator|+
literal|") at "
operator|+
name|splitStr
argument_list|)
expr_stmt|;
name|tmpOut
operator|.
name|writeChars
argument_list|(
literal|"+ "
operator|+
name|startStr
operator|+
name|splitAlgo
operator|.
name|separator
argument_list|()
operator|+
name|splitStr
operator|+
literal|"\n"
argument_list|)
expr_stmt|;
block|}
name|tmpOut
operator|.
name|close
argument_list|()
expr_stmt|;
name|fs
operator|.
name|rename
argument_list|(
name|tmpFile
argument_list|,
name|splitFile
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"_balancedSplit file found. Replay log to restore state..."
argument_list|)
expr_stmt|;
name|FSUtils
operator|.
name|getInstance
argument_list|(
name|fs
argument_list|,
name|table
operator|.
name|getConfiguration
argument_list|()
argument_list|)
operator|.
name|recoverFileLease
argument_list|(
name|fs
argument_list|,
name|splitFile
argument_list|,
name|table
operator|.
name|getConfiguration
argument_list|()
argument_list|)
expr_stmt|;
comment|// parse split file and process remaining splits
name|FSDataInputStream
name|tmpIn
init|=
name|fs
operator|.
name|open
argument_list|(
name|splitFile
argument_list|)
decl_stmt|;
name|StringBuilder
name|sb
init|=
operator|new
name|StringBuilder
argument_list|(
name|tmpIn
operator|.
name|available
argument_list|()
argument_list|)
decl_stmt|;
while|while
condition|(
name|tmpIn
operator|.
name|available
argument_list|()
operator|>
literal|0
condition|)
block|{
name|sb
operator|.
name|append
argument_list|(
name|tmpIn
operator|.
name|readChar
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|tmpIn
operator|.
name|close
argument_list|()
expr_stmt|;
for|for
control|(
name|String
name|line
range|:
name|sb
operator|.
name|toString
argument_list|()
operator|.
name|split
argument_list|(
literal|"\n"
argument_list|)
control|)
block|{
name|String
index|[]
name|cmd
init|=
name|line
operator|.
name|split
argument_list|(
name|splitAlgo
operator|.
name|separator
argument_list|()
argument_list|)
decl_stmt|;
name|Preconditions
operator|.
name|checkArgument
argument_list|(
literal|3
operator|==
name|cmd
operator|.
name|length
argument_list|)
expr_stmt|;
name|byte
index|[]
name|start
init|=
name|splitAlgo
operator|.
name|strToRow
argument_list|(
name|cmd
index|[
literal|1
index|]
argument_list|)
decl_stmt|;
name|String
name|startStr
init|=
name|splitAlgo
operator|.
name|rowToStr
argument_list|(
name|start
argument_list|)
decl_stmt|;
name|byte
index|[]
name|splitPoint
init|=
name|splitAlgo
operator|.
name|strToRow
argument_list|(
name|cmd
index|[
literal|2
index|]
argument_list|)
decl_stmt|;
name|String
name|splitStr
init|=
name|splitAlgo
operator|.
name|rowToStr
argument_list|(
name|splitPoint
argument_list|)
decl_stmt|;
name|Pair
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|r
init|=
name|Pair
operator|.
name|newPair
argument_list|(
name|startStr
argument_list|,
name|splitStr
argument_list|)
decl_stmt|;
if|if
condition|(
name|cmd
index|[
literal|0
index|]
operator|.
name|equals
argument_list|(
literal|"+"
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Adding: "
operator|+
name|r
argument_list|)
expr_stmt|;
name|daughterRegions
operator|.
name|add
argument_list|(
name|r
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Removing: "
operator|+
name|r
argument_list|)
expr_stmt|;
name|Preconditions
operator|.
name|checkArgument
argument_list|(
name|cmd
index|[
literal|0
index|]
operator|.
name|equals
argument_list|(
literal|"-"
argument_list|)
argument_list|,
literal|"Unknown option: "
operator|+
name|cmd
index|[
literal|0
index|]
argument_list|)
expr_stmt|;
name|Preconditions
operator|.
name|checkState
argument_list|(
name|daughterRegions
operator|.
name|contains
argument_list|(
name|r
argument_list|)
argument_list|,
literal|"Missing row: "
operator|+
name|r
argument_list|)
expr_stmt|;
name|daughterRegions
operator|.
name|remove
argument_list|(
name|r
argument_list|)
expr_stmt|;
block|}
block|}
name|LOG
operator|.
name|debug
argument_list|(
literal|"Done reading. "
operator|+
name|daughterRegions
operator|.
name|size
argument_list|()
operator|+
literal|" regions left."
argument_list|)
expr_stmt|;
block|}
name|LinkedList
argument_list|<
name|Pair
argument_list|<
name|byte
index|[]
argument_list|,
name|byte
index|[]
argument_list|>
argument_list|>
name|ret
init|=
name|Lists
operator|.
name|newLinkedList
argument_list|()
decl_stmt|;
for|for
control|(
name|Pair
argument_list|<
name|String
argument_list|,
name|String
argument_list|>
name|r
range|:
name|daughterRegions
control|)
block|{
name|ret
operator|.
name|add
argument_list|(
name|Pair
operator|.
name|newPair
argument_list|(
name|splitAlgo
operator|.
name|strToRow
argument_list|(
name|r
operator|.
name|getFirst
argument_list|()
argument_list|)
argument_list|,
name|splitAlgo
operator|.
name|strToRow
argument_list|(
name|r
operator|.
name|getSecond
argument_list|()
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
block|}
return|return
name|ret
return|;
block|}
comment|/**    * HexStringSplit is a well-known {@link SplitAlgorithm} for choosing region    * boundaries. The format of a HexStringSplit region boundary is the ASCII    * representation of an MD5 checksum, or any other uniformly distributed    * hexadecimal value. Row are hex-encoded long values in the range    *<b>"00000000" => "FFFFFFFF"</b> and are left-padded with zeros to keep the    * same order lexicographically as if they were binary.    *    * Since this split algorithm uses hex strings as keys, it is easy to read&    * write in the shell but takes up more space and may be non-intuitive.    */
specifier|public
specifier|static
class|class
name|HexStringSplit
implements|implements
name|SplitAlgorithm
block|{
specifier|final
specifier|static
name|String
name|DEFAULT_MIN_HEX
init|=
literal|"00000000"
decl_stmt|;
specifier|final
specifier|static
name|String
name|DEFAULT_MAX_HEX
init|=
literal|"FFFFFFFF"
decl_stmt|;
name|String
name|firstRow
init|=
name|DEFAULT_MIN_HEX
decl_stmt|;
name|BigInteger
name|firstRowInt
init|=
name|BigInteger
operator|.
name|ZERO
decl_stmt|;
name|String
name|lastRow
init|=
name|DEFAULT_MAX_HEX
decl_stmt|;
name|BigInteger
name|lastRowInt
init|=
operator|new
name|BigInteger
argument_list|(
name|lastRow
argument_list|,
literal|16
argument_list|)
decl_stmt|;
name|int
name|rowComparisonLength
init|=
name|lastRow
operator|.
name|length
argument_list|()
decl_stmt|;
specifier|public
name|byte
index|[]
name|split
parameter_list|(
name|byte
index|[]
name|start
parameter_list|,
name|byte
index|[]
name|end
parameter_list|)
block|{
name|BigInteger
name|s
init|=
name|convertToBigInteger
argument_list|(
name|start
argument_list|)
decl_stmt|;
name|BigInteger
name|e
init|=
name|convertToBigInteger
argument_list|(
name|end
argument_list|)
decl_stmt|;
name|Preconditions
operator|.
name|checkArgument
argument_list|(
operator|!
name|e
operator|.
name|equals
argument_list|(
name|BigInteger
operator|.
name|ZERO
argument_list|)
argument_list|)
expr_stmt|;
return|return
name|convertToByte
argument_list|(
name|split2
argument_list|(
name|s
argument_list|,
name|e
argument_list|)
argument_list|)
return|;
block|}
specifier|public
name|byte
index|[]
index|[]
name|split
parameter_list|(
name|int
name|n
parameter_list|)
block|{
name|Preconditions
operator|.
name|checkArgument
argument_list|(
name|lastRowInt
operator|.
name|compareTo
argument_list|(
name|firstRowInt
argument_list|)
operator|>
literal|0
argument_list|,
literal|"last row (%s) is configured less than first row (%s)"
argument_list|,
name|lastRow
argument_list|,
name|firstRow
argument_list|)
expr_stmt|;
comment|// +1 to range because the last row is inclusive
name|BigInteger
name|range
init|=
name|lastRowInt
operator|.
name|subtract
argument_list|(
name|firstRowInt
argument_list|)
operator|.
name|add
argument_list|(
name|BigInteger
operator|.
name|ONE
argument_list|)
decl_stmt|;
name|Preconditions
operator|.
name|checkState
argument_list|(
name|range
operator|.
name|compareTo
argument_list|(
name|BigInteger
operator|.
name|valueOf
argument_list|(
name|n
argument_list|)
argument_list|)
operator|>=
literal|0
argument_list|,
literal|"split granularity (%s) is greater than the range (%s)"
argument_list|,
name|n
argument_list|,
name|range
argument_list|)
expr_stmt|;
name|BigInteger
index|[]
name|splits
init|=
operator|new
name|BigInteger
index|[
name|n
operator|-
literal|1
index|]
decl_stmt|;
name|BigInteger
name|sizeOfEachSplit
init|=
name|range
operator|.
name|divide
argument_list|(
name|BigInteger
operator|.
name|valueOf
argument_list|(
name|n
argument_list|)
argument_list|)
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|1
init|;
name|i
operator|<
name|n
condition|;
name|i
operator|++
control|)
block|{
comment|// NOTE: this means the last region gets all the slop.
comment|// This is not a big deal if we're assuming n<< MAXHEX
name|splits
index|[
name|i
operator|-
literal|1
index|]
operator|=
name|firstRowInt
operator|.
name|add
argument_list|(
name|sizeOfEachSplit
operator|.
name|multiply
argument_list|(
name|BigInteger
operator|.
name|valueOf
argument_list|(
name|i
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
block|}
return|return
name|convertToBytes
argument_list|(
name|splits
argument_list|)
return|;
block|}
specifier|public
name|byte
index|[]
name|firstRow
parameter_list|()
block|{
return|return
name|convertToByte
argument_list|(
name|firstRowInt
argument_list|)
return|;
block|}
specifier|public
name|byte
index|[]
name|lastRow
parameter_list|()
block|{
return|return
name|convertToByte
argument_list|(
name|lastRowInt
argument_list|)
return|;
block|}
specifier|public
name|void
name|setFirstRow
parameter_list|(
name|String
name|userInput
parameter_list|)
block|{
name|firstRow
operator|=
name|userInput
expr_stmt|;
name|firstRowInt
operator|=
operator|new
name|BigInteger
argument_list|(
name|firstRow
argument_list|,
literal|16
argument_list|)
expr_stmt|;
block|}
specifier|public
name|void
name|setLastRow
parameter_list|(
name|String
name|userInput
parameter_list|)
block|{
name|lastRow
operator|=
name|userInput
expr_stmt|;
name|lastRowInt
operator|=
operator|new
name|BigInteger
argument_list|(
name|lastRow
argument_list|,
literal|16
argument_list|)
expr_stmt|;
comment|// Precondition: lastRow> firstRow, so last's length is the greater
name|rowComparisonLength
operator|=
name|lastRow
operator|.
name|length
argument_list|()
expr_stmt|;
block|}
specifier|public
name|byte
index|[]
name|strToRow
parameter_list|(
name|String
name|in
parameter_list|)
block|{
return|return
name|convertToByte
argument_list|(
operator|new
name|BigInteger
argument_list|(
name|in
argument_list|,
literal|16
argument_list|)
argument_list|)
return|;
block|}
specifier|public
name|String
name|rowToStr
parameter_list|(
name|byte
index|[]
name|row
parameter_list|)
block|{
return|return
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|row
argument_list|)
return|;
block|}
specifier|public
name|String
name|separator
parameter_list|()
block|{
return|return
literal|" "
return|;
block|}
comment|/**      * Divide 2 numbers in half (for split algorithm)      *      * @param a number #1      * @param b number #2      * @return the midpoint of the 2 numbers      */
specifier|public
name|BigInteger
name|split2
parameter_list|(
name|BigInteger
name|a
parameter_list|,
name|BigInteger
name|b
parameter_list|)
block|{
return|return
name|a
operator|.
name|add
argument_list|(
name|b
argument_list|)
operator|.
name|divide
argument_list|(
name|BigInteger
operator|.
name|valueOf
argument_list|(
literal|2
argument_list|)
argument_list|)
operator|.
name|abs
argument_list|()
return|;
block|}
comment|/**      * Returns an array of bytes corresponding to an array of BigIntegers      *      * @param bigIntegers numbers to convert      * @return bytes corresponding to the bigIntegers      */
specifier|public
name|byte
index|[]
index|[]
name|convertToBytes
parameter_list|(
name|BigInteger
index|[]
name|bigIntegers
parameter_list|)
block|{
name|byte
index|[]
index|[]
name|returnBytes
init|=
operator|new
name|byte
index|[
name|bigIntegers
operator|.
name|length
index|]
index|[]
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|bigIntegers
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|returnBytes
index|[
name|i
index|]
operator|=
name|convertToByte
argument_list|(
name|bigIntegers
index|[
name|i
index|]
argument_list|)
expr_stmt|;
block|}
return|return
name|returnBytes
return|;
block|}
comment|/**      * Returns the bytes corresponding to the BigInteger      *      * @param bigInteger number to convert      * @param pad padding length      * @return byte corresponding to input BigInteger      */
specifier|public
specifier|static
name|byte
index|[]
name|convertToByte
parameter_list|(
name|BigInteger
name|bigInteger
parameter_list|,
name|int
name|pad
parameter_list|)
block|{
name|String
name|bigIntegerString
init|=
name|bigInteger
operator|.
name|toString
argument_list|(
literal|16
argument_list|)
decl_stmt|;
name|bigIntegerString
operator|=
name|StringUtils
operator|.
name|leftPad
argument_list|(
name|bigIntegerString
argument_list|,
name|pad
argument_list|,
literal|'0'
argument_list|)
expr_stmt|;
return|return
name|Bytes
operator|.
name|toBytes
argument_list|(
name|bigIntegerString
argument_list|)
return|;
block|}
comment|/**      * Returns the bytes corresponding to the BigInteger      *      * @param bigInteger number to convert      * @return corresponding bytes      */
specifier|public
name|byte
index|[]
name|convertToByte
parameter_list|(
name|BigInteger
name|bigInteger
parameter_list|)
block|{
return|return
name|convertToByte
argument_list|(
name|bigInteger
argument_list|,
name|rowComparisonLength
argument_list|)
return|;
block|}
comment|/**      * Returns the BigInteger represented by the byte array      *      * @param row byte array representing row      * @return the corresponding BigInteger      */
specifier|public
name|BigInteger
name|convertToBigInteger
parameter_list|(
name|byte
index|[]
name|row
parameter_list|)
block|{
return|return
operator|(
name|row
operator|.
name|length
operator|>
literal|0
operator|)
condition|?
operator|new
name|BigInteger
argument_list|(
name|Bytes
operator|.
name|toString
argument_list|(
name|row
argument_list|)
argument_list|,
literal|16
argument_list|)
else|:
name|BigInteger
operator|.
name|ZERO
return|;
block|}
annotation|@
name|Override
specifier|public
name|String
name|toString
parameter_list|()
block|{
return|return
name|this
operator|.
name|getClass
argument_list|()
operator|.
name|getSimpleName
argument_list|()
operator|+
literal|" ["
operator|+
name|rowToStr
argument_list|(
name|firstRow
argument_list|()
argument_list|)
operator|+
literal|","
operator|+
name|rowToStr
argument_list|(
name|lastRow
argument_list|()
argument_list|)
operator|+
literal|"]"
return|;
block|}
block|}
comment|/**    * A SplitAlgorithm that divides the space of possible keys evenly. Useful    * when the keys are approximately uniform random bytes (e.g. hashes). Rows    * are raw byte values in the range<b>00 => FF</b> and are right-padded with    * zeros to keep the same memcmp() order. This is the natural algorithm to use    * for a byte[] environment and saves space, but is not necessarily the    * easiest for readability.    */
specifier|public
specifier|static
class|class
name|UniformSplit
implements|implements
name|SplitAlgorithm
block|{
specifier|static
specifier|final
name|byte
name|xFF
init|=
operator|(
name|byte
operator|)
literal|0xFF
decl_stmt|;
name|byte
index|[]
name|firstRowBytes
init|=
name|ArrayUtils
operator|.
name|EMPTY_BYTE_ARRAY
decl_stmt|;
name|byte
index|[]
name|lastRowBytes
init|=
operator|new
name|byte
index|[]
block|{
name|xFF
block|,
name|xFF
block|,
name|xFF
block|,
name|xFF
block|,
name|xFF
block|,
name|xFF
block|,
name|xFF
block|,
name|xFF
block|}
decl_stmt|;
specifier|public
name|byte
index|[]
name|split
parameter_list|(
name|byte
index|[]
name|start
parameter_list|,
name|byte
index|[]
name|end
parameter_list|)
block|{
return|return
name|Bytes
operator|.
name|split
argument_list|(
name|start
argument_list|,
name|end
argument_list|,
literal|1
argument_list|)
index|[
literal|1
index|]
return|;
block|}
annotation|@
name|Override
specifier|public
name|byte
index|[]
index|[]
name|split
parameter_list|(
name|int
name|numRegions
parameter_list|)
block|{
name|Preconditions
operator|.
name|checkArgument
argument_list|(
name|Bytes
operator|.
name|compareTo
argument_list|(
name|lastRowBytes
argument_list|,
name|firstRowBytes
argument_list|)
operator|>
literal|0
argument_list|,
literal|"last row (%s) is configured less than first row (%s)"
argument_list|,
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|lastRowBytes
argument_list|)
argument_list|,
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|firstRowBytes
argument_list|)
argument_list|)
expr_stmt|;
name|byte
index|[]
index|[]
name|splits
init|=
name|Bytes
operator|.
name|split
argument_list|(
name|firstRowBytes
argument_list|,
name|lastRowBytes
argument_list|,
literal|true
argument_list|,
name|numRegions
operator|-
literal|1
argument_list|)
decl_stmt|;
name|Preconditions
operator|.
name|checkState
argument_list|(
name|splits
operator|!=
literal|null
argument_list|,
literal|"Could not split region with given user input: "
operator|+
name|this
argument_list|)
expr_stmt|;
comment|// remove endpoints, which are included in the splits list
return|return
name|Arrays
operator|.
name|copyOfRange
argument_list|(
name|splits
argument_list|,
literal|1
argument_list|,
name|splits
operator|.
name|length
operator|-
literal|1
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|byte
index|[]
name|firstRow
parameter_list|()
block|{
return|return
name|firstRowBytes
return|;
block|}
annotation|@
name|Override
specifier|public
name|byte
index|[]
name|lastRow
parameter_list|()
block|{
return|return
name|lastRowBytes
return|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|setFirstRow
parameter_list|(
name|String
name|userInput
parameter_list|)
block|{
name|firstRowBytes
operator|=
name|Bytes
operator|.
name|toBytesBinary
argument_list|(
name|userInput
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|setLastRow
parameter_list|(
name|String
name|userInput
parameter_list|)
block|{
name|lastRowBytes
operator|=
name|Bytes
operator|.
name|toBytesBinary
argument_list|(
name|userInput
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|byte
index|[]
name|strToRow
parameter_list|(
name|String
name|input
parameter_list|)
block|{
return|return
name|Bytes
operator|.
name|toBytesBinary
argument_list|(
name|input
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|String
name|rowToStr
parameter_list|(
name|byte
index|[]
name|row
parameter_list|)
block|{
return|return
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|row
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|String
name|separator
parameter_list|()
block|{
return|return
literal|","
return|;
block|}
annotation|@
name|Override
specifier|public
name|String
name|toString
parameter_list|()
block|{
return|return
name|this
operator|.
name|getClass
argument_list|()
operator|.
name|getSimpleName
argument_list|()
operator|+
literal|" ["
operator|+
name|rowToStr
argument_list|(
name|firstRow
argument_list|()
argument_list|)
operator|+
literal|","
operator|+
name|rowToStr
argument_list|(
name|lastRow
argument_list|()
argument_list|)
operator|+
literal|"]"
return|;
block|}
block|}
block|}
end_class

end_unit

