begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|replication
operator|.
name|regionserver
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|ConnectException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|SocketTimeoutException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|UnknownHostException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collections
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|TreeMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|Callable
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|CompletionService
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ExecutionException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ExecutorCompletionService
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|Future
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ThreadPoolExecutor
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|TimeUnit
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|regex
operator|.
name|Matcher
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|regex
operator|.
name|Pattern
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|stream
operator|.
name|Collectors
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|stream
operator|.
name|Stream
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|lang3
operator|.
name|StringUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|Abortable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HBaseConfiguration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HConstants
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|TableName
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|TableNotFoundException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|AsyncClusterConnection
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|AsyncRegionServerAdmin
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|ClusterConnectionFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|Connection
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|ConnectionFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|ipc
operator|.
name|RpcServer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|protobuf
operator|.
name|ReplicationProtbufUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|replication
operator|.
name|HBaseReplicationEndpoint
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|replication
operator|.
name|regionserver
operator|.
name|ReplicationSinkManager
operator|.
name|SinkPeer
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|security
operator|.
name|User
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|Bytes
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|FSUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|Threads
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|wal
operator|.
name|WAL
operator|.
name|Entry
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|ipc
operator|.
name|RemoteException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hbase
operator|.
name|thirdparty
operator|.
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ThreadFactoryBuilder
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|yetus
operator|.
name|audience
operator|.
name|InterfaceAudience
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|Logger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|LoggerFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hbase
operator|.
name|thirdparty
operator|.
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|annotations
operator|.
name|VisibleForTesting
import|;
end_import

begin_comment
comment|/**  * A {@link org.apache.hadoop.hbase.replication.ReplicationEndpoint}  * implementation for replicating to another HBase cluster.  * For the slave cluster it selects a random number of peers  * using a replication ratio. For example, if replication ration = 0.1  * and slave cluster has 100 region servers, 10 will be selected.  *<p>  * A stream is considered down when we cannot contact a region server on the  * peer cluster for more than 55 seconds by default.  *</p>  */
end_comment

begin_class
annotation|@
name|InterfaceAudience
operator|.
name|Private
specifier|public
class|class
name|HBaseInterClusterReplicationEndpoint
extends|extends
name|HBaseReplicationEndpoint
block|{
specifier|private
specifier|static
specifier|final
name|Logger
name|LOG
init|=
name|LoggerFactory
operator|.
name|getLogger
argument_list|(
name|HBaseInterClusterReplicationEndpoint
operator|.
name|class
argument_list|)
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|long
name|DEFAULT_MAX_TERMINATION_WAIT_MULTIPLIER
init|=
literal|2
decl_stmt|;
specifier|private
name|AsyncClusterConnection
name|conn
decl_stmt|;
specifier|private
name|Configuration
name|conf
decl_stmt|;
comment|// How long should we sleep for each retry
specifier|private
name|long
name|sleepForRetries
decl_stmt|;
comment|// Maximum number of retries before taking bold actions
specifier|private
name|int
name|maxRetriesMultiplier
decl_stmt|;
comment|// Socket timeouts require even bolder actions since we don't want to DDOS
specifier|private
name|int
name|socketTimeoutMultiplier
decl_stmt|;
comment|// Amount of time for shutdown to wait for all tasks to complete
specifier|private
name|long
name|maxTerminationWait
decl_stmt|;
comment|// Size limit for replication RPCs, in bytes
specifier|private
name|int
name|replicationRpcLimit
decl_stmt|;
comment|//Metrics for this source
specifier|private
name|MetricsSource
name|metrics
decl_stmt|;
comment|// Handles connecting to peer region servers
specifier|private
name|ReplicationSinkManager
name|replicationSinkMgr
decl_stmt|;
specifier|private
name|boolean
name|peersSelected
init|=
literal|false
decl_stmt|;
specifier|private
name|String
name|replicationClusterId
init|=
literal|""
decl_stmt|;
specifier|private
name|ThreadPoolExecutor
name|exec
decl_stmt|;
specifier|private
name|int
name|maxThreads
decl_stmt|;
specifier|private
name|Path
name|baseNamespaceDir
decl_stmt|;
specifier|private
name|Path
name|hfileArchiveDir
decl_stmt|;
specifier|private
name|boolean
name|replicationBulkLoadDataEnabled
decl_stmt|;
specifier|private
name|Abortable
name|abortable
decl_stmt|;
specifier|private
name|boolean
name|dropOnDeletedTables
decl_stmt|;
specifier|private
name|boolean
name|isSerial
init|=
literal|false
decl_stmt|;
annotation|@
name|Override
specifier|public
name|void
name|init
parameter_list|(
name|Context
name|context
parameter_list|)
throws|throws
name|IOException
block|{
name|super
operator|.
name|init
argument_list|(
name|context
argument_list|)
expr_stmt|;
name|this
operator|.
name|conf
operator|=
name|HBaseConfiguration
operator|.
name|create
argument_list|(
name|ctx
operator|.
name|getConfiguration
argument_list|()
argument_list|)
expr_stmt|;
name|decorateConf
argument_list|()
expr_stmt|;
name|this
operator|.
name|maxRetriesMultiplier
operator|=
name|this
operator|.
name|conf
operator|.
name|getInt
argument_list|(
literal|"replication.source.maxretriesmultiplier"
argument_list|,
literal|300
argument_list|)
expr_stmt|;
name|this
operator|.
name|socketTimeoutMultiplier
operator|=
name|this
operator|.
name|conf
operator|.
name|getInt
argument_list|(
literal|"replication.source.socketTimeoutMultiplier"
argument_list|,
name|maxRetriesMultiplier
argument_list|)
expr_stmt|;
comment|// A Replicator job is bound by the RPC timeout. We will wait this long for all Replicator
comment|// tasks to terminate when doStop() is called.
name|long
name|maxTerminationWaitMultiplier
init|=
name|this
operator|.
name|conf
operator|.
name|getLong
argument_list|(
literal|"replication.source.maxterminationmultiplier"
argument_list|,
name|DEFAULT_MAX_TERMINATION_WAIT_MULTIPLIER
argument_list|)
decl_stmt|;
name|this
operator|.
name|maxTerminationWait
operator|=
name|maxTerminationWaitMultiplier
operator|*
name|this
operator|.
name|conf
operator|.
name|getLong
argument_list|(
name|HConstants
operator|.
name|HBASE_RPC_TIMEOUT_KEY
argument_list|,
name|HConstants
operator|.
name|DEFAULT_HBASE_RPC_TIMEOUT
argument_list|)
expr_stmt|;
comment|// TODO: This connection is replication specific or we should make it particular to
comment|// replication and make replication specific settings such as compression or codec to use
comment|// passing Cells.
name|this
operator|.
name|conn
operator|=
name|ClusterConnectionFactory
operator|.
name|createAsyncClusterConnection
argument_list|(
name|conf
argument_list|,
literal|null
argument_list|,
name|User
operator|.
name|getCurrent
argument_list|()
argument_list|)
expr_stmt|;
name|this
operator|.
name|sleepForRetries
operator|=
name|this
operator|.
name|conf
operator|.
name|getLong
argument_list|(
literal|"replication.source.sleepforretries"
argument_list|,
literal|1000
argument_list|)
expr_stmt|;
name|this
operator|.
name|metrics
operator|=
name|context
operator|.
name|getMetrics
argument_list|()
expr_stmt|;
comment|// ReplicationQueueInfo parses the peerId out of the znode for us
name|this
operator|.
name|replicationSinkMgr
operator|=
operator|new
name|ReplicationSinkManager
argument_list|(
name|conn
argument_list|,
name|this
argument_list|,
name|this
operator|.
name|conf
argument_list|)
expr_stmt|;
comment|// per sink thread pool
name|this
operator|.
name|maxThreads
operator|=
name|this
operator|.
name|conf
operator|.
name|getInt
argument_list|(
name|HConstants
operator|.
name|REPLICATION_SOURCE_MAXTHREADS_KEY
argument_list|,
name|HConstants
operator|.
name|REPLICATION_SOURCE_MAXTHREADS_DEFAULT
argument_list|)
expr_stmt|;
name|this
operator|.
name|exec
operator|=
name|Threads
operator|.
name|getBoundedCachedThreadPool
argument_list|(
name|maxThreads
argument_list|,
literal|60
argument_list|,
name|TimeUnit
operator|.
name|SECONDS
argument_list|,
operator|new
name|ThreadFactoryBuilder
argument_list|()
operator|.
name|setDaemon
argument_list|(
literal|true
argument_list|)
operator|.
name|setNameFormat
argument_list|(
literal|"SinkThread-%d"
argument_list|)
operator|.
name|build
argument_list|()
argument_list|)
expr_stmt|;
name|this
operator|.
name|abortable
operator|=
name|ctx
operator|.
name|getAbortable
argument_list|()
expr_stmt|;
comment|// Set the size limit for replication RPCs to 95% of the max request size.
comment|// We could do with less slop if we have an accurate estimate of encoded size. Being
comment|// conservative for now.
name|this
operator|.
name|replicationRpcLimit
operator|=
call|(
name|int
call|)
argument_list|(
literal|0.95
operator|*
name|conf
operator|.
name|getLong
argument_list|(
name|RpcServer
operator|.
name|MAX_REQUEST_SIZE
argument_list|,
name|RpcServer
operator|.
name|DEFAULT_MAX_REQUEST_SIZE
argument_list|)
argument_list|)
expr_stmt|;
name|this
operator|.
name|dropOnDeletedTables
operator|=
name|this
operator|.
name|conf
operator|.
name|getBoolean
argument_list|(
name|HConstants
operator|.
name|REPLICATION_DROP_ON_DELETED_TABLE_KEY
argument_list|,
literal|false
argument_list|)
expr_stmt|;
name|this
operator|.
name|replicationBulkLoadDataEnabled
operator|=
name|conf
operator|.
name|getBoolean
argument_list|(
name|HConstants
operator|.
name|REPLICATION_BULKLOAD_ENABLE_KEY
argument_list|,
name|HConstants
operator|.
name|REPLICATION_BULKLOAD_ENABLE_DEFAULT
argument_list|)
expr_stmt|;
if|if
condition|(
name|this
operator|.
name|replicationBulkLoadDataEnabled
condition|)
block|{
name|replicationClusterId
operator|=
name|this
operator|.
name|conf
operator|.
name|get
argument_list|(
name|HConstants
operator|.
name|REPLICATION_CLUSTER_ID
argument_list|)
expr_stmt|;
block|}
comment|// Construct base namespace directory and hfile archive directory path
name|Path
name|rootDir
init|=
name|FSUtils
operator|.
name|getRootDir
argument_list|(
name|conf
argument_list|)
decl_stmt|;
name|Path
name|baseNSDir
init|=
operator|new
name|Path
argument_list|(
name|HConstants
operator|.
name|BASE_NAMESPACE_DIR
argument_list|)
decl_stmt|;
name|baseNamespaceDir
operator|=
operator|new
name|Path
argument_list|(
name|rootDir
argument_list|,
name|baseNSDir
argument_list|)
expr_stmt|;
name|hfileArchiveDir
operator|=
operator|new
name|Path
argument_list|(
name|rootDir
argument_list|,
operator|new
name|Path
argument_list|(
name|HConstants
operator|.
name|HFILE_ARCHIVE_DIRECTORY
argument_list|,
name|baseNSDir
argument_list|)
argument_list|)
expr_stmt|;
name|isSerial
operator|=
name|context
operator|.
name|getPeerConfig
argument_list|()
operator|.
name|isSerial
argument_list|()
expr_stmt|;
block|}
specifier|private
name|void
name|decorateConf
parameter_list|()
block|{
name|String
name|replicationCodec
init|=
name|this
operator|.
name|conf
operator|.
name|get
argument_list|(
name|HConstants
operator|.
name|REPLICATION_CODEC_CONF_KEY
argument_list|)
decl_stmt|;
if|if
condition|(
name|StringUtils
operator|.
name|isNotEmpty
argument_list|(
name|replicationCodec
argument_list|)
condition|)
block|{
name|this
operator|.
name|conf
operator|.
name|set
argument_list|(
name|HConstants
operator|.
name|RPC_CODEC_CONF_KEY
argument_list|,
name|replicationCodec
argument_list|)
expr_stmt|;
block|}
block|}
specifier|private
name|void
name|connectToPeers
parameter_list|()
block|{
name|getRegionServers
argument_list|()
expr_stmt|;
name|int
name|sleepMultiplier
init|=
literal|1
decl_stmt|;
comment|// Connect to peer cluster first, unless we have to stop
while|while
condition|(
name|this
operator|.
name|isRunning
argument_list|()
operator|&&
name|replicationSinkMgr
operator|.
name|getNumSinks
argument_list|()
operator|==
literal|0
condition|)
block|{
name|replicationSinkMgr
operator|.
name|chooseSinks
argument_list|()
expr_stmt|;
if|if
condition|(
name|this
operator|.
name|isRunning
argument_list|()
operator|&&
name|replicationSinkMgr
operator|.
name|getNumSinks
argument_list|()
operator|==
literal|0
condition|)
block|{
if|if
condition|(
name|sleepForRetries
argument_list|(
literal|"Waiting for peers"
argument_list|,
name|sleepMultiplier
argument_list|)
condition|)
block|{
name|sleepMultiplier
operator|++
expr_stmt|;
block|}
block|}
block|}
block|}
comment|/**    * Do the sleeping logic    * @param msg Why we sleep    * @param sleepMultiplier by how many times the default sleeping time is augmented    * @return True if<code>sleepMultiplier</code> is&lt;<code>maxRetriesMultiplier</code>    */
specifier|protected
name|boolean
name|sleepForRetries
parameter_list|(
name|String
name|msg
parameter_list|,
name|int
name|sleepMultiplier
parameter_list|)
block|{
try|try
block|{
if|if
condition|(
name|LOG
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|trace
argument_list|(
literal|"{} {}, sleeping {} times {}"
argument_list|,
name|logPeerId
argument_list|()
argument_list|,
name|msg
argument_list|,
name|sleepForRetries
argument_list|,
name|sleepMultiplier
argument_list|)
expr_stmt|;
block|}
name|Thread
operator|.
name|sleep
argument_list|(
name|this
operator|.
name|sleepForRetries
operator|*
name|sleepMultiplier
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"{} Interrupted while sleeping between retries"
argument_list|,
name|logPeerId
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|sleepMultiplier
operator|<
name|maxRetriesMultiplier
return|;
block|}
specifier|private
name|int
name|getEstimatedEntrySize
parameter_list|(
name|Entry
name|e
parameter_list|)
block|{
name|long
name|size
init|=
name|e
operator|.
name|getKey
argument_list|()
operator|.
name|estimatedSerializedSizeOf
argument_list|()
operator|+
name|e
operator|.
name|getEdit
argument_list|()
operator|.
name|estimatedSerializedSizeOf
argument_list|()
decl_stmt|;
return|return
operator|(
name|int
operator|)
name|size
return|;
block|}
specifier|private
name|List
argument_list|<
name|List
argument_list|<
name|Entry
argument_list|>
argument_list|>
name|createParallelBatches
parameter_list|(
specifier|final
name|List
argument_list|<
name|Entry
argument_list|>
name|entries
parameter_list|)
block|{
name|int
name|numSinks
init|=
name|Math
operator|.
name|max
argument_list|(
name|replicationSinkMgr
operator|.
name|getNumSinks
argument_list|()
argument_list|,
literal|1
argument_list|)
decl_stmt|;
name|int
name|n
init|=
name|Math
operator|.
name|min
argument_list|(
name|Math
operator|.
name|min
argument_list|(
name|this
operator|.
name|maxThreads
argument_list|,
name|entries
operator|.
name|size
argument_list|()
operator|/
literal|100
operator|+
literal|1
argument_list|)
argument_list|,
name|numSinks
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|List
argument_list|<
name|Entry
argument_list|>
argument_list|>
name|entryLists
init|=
name|Stream
operator|.
name|generate
argument_list|(
name|ArrayList
argument_list|<
name|Entry
argument_list|>
operator|::
operator|new
argument_list|)
operator|.
name|limit
argument_list|(
name|n
argument_list|)
operator|.
name|collect
argument_list|(
name|Collectors
operator|.
name|toList
argument_list|()
argument_list|)
decl_stmt|;
name|int
index|[]
name|sizes
init|=
operator|new
name|int
index|[
name|n
index|]
decl_stmt|;
for|for
control|(
name|Entry
name|e
range|:
name|entries
control|)
block|{
name|int
name|index
init|=
name|Math
operator|.
name|abs
argument_list|(
name|Bytes
operator|.
name|hashCode
argument_list|(
name|e
operator|.
name|getKey
argument_list|()
operator|.
name|getEncodedRegionName
argument_list|()
argument_list|)
operator|%
name|n
argument_list|)
decl_stmt|;
name|int
name|entrySize
init|=
name|getEstimatedEntrySize
argument_list|(
name|e
argument_list|)
decl_stmt|;
comment|// If this batch has at least one entry and is over sized, move it to the tail of list and
comment|// initialize the entryLists[index] to be a empty list.
if|if
condition|(
name|sizes
index|[
name|index
index|]
operator|>
literal|0
operator|&&
name|sizes
index|[
name|index
index|]
operator|+
name|entrySize
operator|>
name|replicationRpcLimit
condition|)
block|{
name|entryLists
operator|.
name|add
argument_list|(
name|entryLists
operator|.
name|get
argument_list|(
name|index
argument_list|)
argument_list|)
expr_stmt|;
name|entryLists
operator|.
name|set
argument_list|(
name|index
argument_list|,
operator|new
name|ArrayList
argument_list|<>
argument_list|()
argument_list|)
expr_stmt|;
name|sizes
index|[
name|index
index|]
operator|=
literal|0
expr_stmt|;
block|}
name|entryLists
operator|.
name|get
argument_list|(
name|index
argument_list|)
operator|.
name|add
argument_list|(
name|e
argument_list|)
expr_stmt|;
name|sizes
index|[
name|index
index|]
operator|+=
name|entrySize
expr_stmt|;
block|}
return|return
name|entryLists
return|;
block|}
specifier|private
name|List
argument_list|<
name|List
argument_list|<
name|Entry
argument_list|>
argument_list|>
name|createSerialBatches
parameter_list|(
specifier|final
name|List
argument_list|<
name|Entry
argument_list|>
name|entries
parameter_list|)
block|{
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|List
argument_list|<
name|Entry
argument_list|>
argument_list|>
name|regionEntries
init|=
operator|new
name|TreeMap
argument_list|<>
argument_list|(
name|Bytes
operator|.
name|BYTES_COMPARATOR
argument_list|)
decl_stmt|;
for|for
control|(
name|Entry
name|e
range|:
name|entries
control|)
block|{
name|regionEntries
operator|.
name|computeIfAbsent
argument_list|(
name|e
operator|.
name|getKey
argument_list|()
operator|.
name|getEncodedRegionName
argument_list|()
argument_list|,
name|key
lambda|->
operator|new
name|ArrayList
argument_list|<>
argument_list|()
argument_list|)
operator|.
name|add
argument_list|(
name|e
argument_list|)
expr_stmt|;
block|}
return|return
operator|new
name|ArrayList
argument_list|<>
argument_list|(
name|regionEntries
operator|.
name|values
argument_list|()
argument_list|)
return|;
block|}
comment|/**    * Divide the entries into multiple batches, so that we can replicate each batch in a thread pool    * concurrently. Note that, for serial replication, we need to make sure that entries from the    * same region to be replicated serially, so entries from the same region consist of a batch, and    * we will divide a batch into several batches by replicationRpcLimit in method    * serialReplicateRegionEntries()    */
specifier|private
name|List
argument_list|<
name|List
argument_list|<
name|Entry
argument_list|>
argument_list|>
name|createBatches
parameter_list|(
specifier|final
name|List
argument_list|<
name|Entry
argument_list|>
name|entries
parameter_list|)
block|{
if|if
condition|(
name|isSerial
condition|)
block|{
return|return
name|createSerialBatches
argument_list|(
name|entries
argument_list|)
return|;
block|}
else|else
block|{
return|return
name|createParallelBatches
argument_list|(
name|entries
argument_list|)
return|;
block|}
block|}
specifier|private
name|TableName
name|parseTable
parameter_list|(
name|String
name|msg
parameter_list|)
block|{
comment|// ... TableNotFoundException: '<table>'/n...
name|Pattern
name|p
init|=
name|Pattern
operator|.
name|compile
argument_list|(
literal|"TableNotFoundException: '([\\S]*)'"
argument_list|)
decl_stmt|;
name|Matcher
name|m
init|=
name|p
operator|.
name|matcher
argument_list|(
name|msg
argument_list|)
decl_stmt|;
if|if
condition|(
name|m
operator|.
name|find
argument_list|()
condition|)
block|{
name|String
name|table
init|=
name|m
operator|.
name|group
argument_list|(
literal|1
argument_list|)
decl_stmt|;
try|try
block|{
comment|// double check that table is a valid table name
name|TableName
operator|.
name|valueOf
argument_list|(
name|TableName
operator|.
name|isLegalFullyQualifiedTableName
argument_list|(
name|Bytes
operator|.
name|toBytes
argument_list|(
name|table
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
return|return
name|TableName
operator|.
name|valueOf
argument_list|(
name|table
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|IllegalArgumentException
name|ignore
parameter_list|)
block|{       }
block|}
return|return
literal|null
return|;
block|}
comment|// Filter a set of batches by TableName
specifier|private
name|List
argument_list|<
name|List
argument_list|<
name|Entry
argument_list|>
argument_list|>
name|filterBatches
parameter_list|(
specifier|final
name|List
argument_list|<
name|List
argument_list|<
name|Entry
argument_list|>
argument_list|>
name|oldEntryList
parameter_list|,
name|TableName
name|table
parameter_list|)
block|{
return|return
name|oldEntryList
operator|.
name|stream
argument_list|()
operator|.
name|map
argument_list|(
name|entries
lambda|->
name|entries
operator|.
name|stream
argument_list|()
operator|.
name|filter
argument_list|(
name|e
lambda|->
operator|!
name|e
operator|.
name|getKey
argument_list|()
operator|.
name|getTableName
argument_list|()
operator|.
name|equals
argument_list|(
name|table
argument_list|)
argument_list|)
operator|.
name|collect
argument_list|(
name|Collectors
operator|.
name|toList
argument_list|()
argument_list|)
argument_list|)
operator|.
name|collect
argument_list|(
name|Collectors
operator|.
name|toList
argument_list|()
argument_list|)
return|;
block|}
specifier|private
name|void
name|reconnectToPeerCluster
parameter_list|()
block|{
name|AsyncClusterConnection
name|connection
init|=
literal|null
decl_stmt|;
try|try
block|{
name|connection
operator|=
name|ClusterConnectionFactory
operator|.
name|createAsyncClusterConnection
argument_list|(
name|conf
argument_list|,
literal|null
argument_list|,
name|User
operator|.
name|getCurrent
argument_list|()
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ioe
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"{} Failed to create connection for peer cluster"
argument_list|,
name|logPeerId
argument_list|()
argument_list|,
name|ioe
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|connection
operator|!=
literal|null
condition|)
block|{
name|this
operator|.
name|conn
operator|=
name|connection
expr_stmt|;
block|}
block|}
specifier|private
name|long
name|parallelReplicate
parameter_list|(
name|CompletionService
argument_list|<
name|Integer
argument_list|>
name|pool
parameter_list|,
name|ReplicateContext
name|replicateContext
parameter_list|,
name|List
argument_list|<
name|List
argument_list|<
name|Entry
argument_list|>
argument_list|>
name|batches
parameter_list|)
throws|throws
name|IOException
block|{
name|int
name|futures
init|=
literal|0
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|batches
operator|.
name|size
argument_list|()
condition|;
name|i
operator|++
control|)
block|{
name|List
argument_list|<
name|Entry
argument_list|>
name|entries
init|=
name|batches
operator|.
name|get
argument_list|(
name|i
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|entries
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
if|if
condition|(
name|LOG
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|trace
argument_list|(
literal|"{} Submitting {} entries of total size {}"
argument_list|,
name|logPeerId
argument_list|()
argument_list|,
name|entries
operator|.
name|size
argument_list|()
argument_list|,
name|replicateContext
operator|.
name|getSize
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|// RuntimeExceptions encountered here bubble up and are handled in ReplicationSource
name|pool
operator|.
name|submit
argument_list|(
name|createReplicator
argument_list|(
name|entries
argument_list|,
name|i
argument_list|,
name|replicateContext
operator|.
name|getTimeout
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
name|futures
operator|++
expr_stmt|;
block|}
block|}
name|IOException
name|iox
init|=
literal|null
decl_stmt|;
name|long
name|lastWriteTime
init|=
literal|0
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|futures
condition|;
name|i
operator|++
control|)
block|{
try|try
block|{
comment|// wait for all futures, remove successful parts
comment|// (only the remaining parts will be retried)
name|Future
argument_list|<
name|Integer
argument_list|>
name|f
init|=
name|pool
operator|.
name|take
argument_list|()
decl_stmt|;
name|int
name|index
init|=
name|f
operator|.
name|get
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|Entry
argument_list|>
name|batch
init|=
name|batches
operator|.
name|get
argument_list|(
name|index
argument_list|)
decl_stmt|;
name|batches
operator|.
name|set
argument_list|(
name|index
argument_list|,
name|Collections
operator|.
name|emptyList
argument_list|()
argument_list|)
expr_stmt|;
comment|// remove successful batch
comment|// Find the most recent write time in the batch
name|long
name|writeTime
init|=
name|batch
operator|.
name|get
argument_list|(
name|batch
operator|.
name|size
argument_list|()
operator|-
literal|1
argument_list|)
operator|.
name|getKey
argument_list|()
operator|.
name|getWriteTime
argument_list|()
decl_stmt|;
if|if
condition|(
name|writeTime
operator|>
name|lastWriteTime
condition|)
block|{
name|lastWriteTime
operator|=
name|writeTime
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|ie
parameter_list|)
block|{
name|iox
operator|=
operator|new
name|IOException
argument_list|(
name|ie
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|ExecutionException
name|ee
parameter_list|)
block|{
comment|// cause must be an IOException
name|iox
operator|=
operator|(
name|IOException
operator|)
name|ee
operator|.
name|getCause
argument_list|()
expr_stmt|;
block|}
block|}
if|if
condition|(
name|iox
operator|!=
literal|null
condition|)
block|{
comment|// if we had any exceptions, try again
throw|throw
name|iox
throw|;
block|}
return|return
name|lastWriteTime
return|;
block|}
comment|/**    * Do the shipping logic    */
annotation|@
name|Override
specifier|public
name|boolean
name|replicate
parameter_list|(
name|ReplicateContext
name|replicateContext
parameter_list|)
block|{
name|CompletionService
argument_list|<
name|Integer
argument_list|>
name|pool
init|=
operator|new
name|ExecutorCompletionService
argument_list|<>
argument_list|(
name|this
operator|.
name|exec
argument_list|)
decl_stmt|;
name|int
name|sleepMultiplier
init|=
literal|1
decl_stmt|;
if|if
condition|(
operator|!
name|peersSelected
operator|&&
name|this
operator|.
name|isRunning
argument_list|()
condition|)
block|{
name|connectToPeers
argument_list|()
expr_stmt|;
name|peersSelected
operator|=
literal|true
expr_stmt|;
block|}
name|int
name|numSinks
init|=
name|replicationSinkMgr
operator|.
name|getNumSinks
argument_list|()
decl_stmt|;
if|if
condition|(
name|numSinks
operator|==
literal|0
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"{} No replication sinks found, returning without replicating. "
operator|+
literal|"The source should retry with the same set of edits."
argument_list|,
name|logPeerId
argument_list|()
argument_list|)
expr_stmt|;
return|return
literal|false
return|;
block|}
name|List
argument_list|<
name|List
argument_list|<
name|Entry
argument_list|>
argument_list|>
name|batches
init|=
name|createBatches
argument_list|(
name|replicateContext
operator|.
name|getEntries
argument_list|()
argument_list|)
decl_stmt|;
while|while
condition|(
name|this
operator|.
name|isRunning
argument_list|()
operator|&&
operator|!
name|exec
operator|.
name|isShutdown
argument_list|()
condition|)
block|{
if|if
condition|(
operator|!
name|isPeerEnabled
argument_list|()
condition|)
block|{
if|if
condition|(
name|sleepForRetries
argument_list|(
literal|"Replication is disabled"
argument_list|,
name|sleepMultiplier
argument_list|)
condition|)
block|{
name|sleepMultiplier
operator|++
expr_stmt|;
block|}
continue|continue;
block|}
if|if
condition|(
name|this
operator|.
name|conn
operator|==
literal|null
condition|)
block|{
name|reconnectToPeerCluster
argument_list|()
expr_stmt|;
block|}
try|try
block|{
comment|// replicate the batches to sink side.
name|parallelReplicate
argument_list|(
name|pool
argument_list|,
name|replicateContext
argument_list|,
name|batches
argument_list|)
expr_stmt|;
return|return
literal|true
return|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ioe
parameter_list|)
block|{
if|if
condition|(
name|ioe
operator|instanceof
name|RemoteException
condition|)
block|{
name|ioe
operator|=
operator|(
operator|(
name|RemoteException
operator|)
name|ioe
operator|)
operator|.
name|unwrapRemoteException
argument_list|()
expr_stmt|;
name|LOG
operator|.
name|warn
argument_list|(
literal|"{} Can't replicate because of an error on the remote cluster: "
argument_list|,
name|logPeerId
argument_list|()
argument_list|,
name|ioe
argument_list|)
expr_stmt|;
if|if
condition|(
name|ioe
operator|instanceof
name|TableNotFoundException
condition|)
block|{
if|if
condition|(
name|dropOnDeletedTables
condition|)
block|{
comment|// this is a bit fragile, but cannot change how TNFE is serialized
comment|// at least check whether the table name is legal
name|TableName
name|table
init|=
name|parseTable
argument_list|(
name|ioe
operator|.
name|getMessage
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|table
operator|!=
literal|null
condition|)
block|{
try|try
init|(
name|Connection
name|localConn
init|=
name|ConnectionFactory
operator|.
name|createConnection
argument_list|(
name|ctx
operator|.
name|getLocalConfiguration
argument_list|()
argument_list|)
init|)
block|{
if|if
condition|(
operator|!
name|localConn
operator|.
name|getAdmin
argument_list|()
operator|.
name|tableExists
argument_list|(
name|table
argument_list|)
condition|)
block|{
comment|// Would potentially be better to retry in one of the outer loops
comment|// and add a table filter there; but that would break the encapsulation,
comment|// so we're doing the filtering here.
name|LOG
operator|.
name|info
argument_list|(
literal|"{} Missing table detected at sink, local table also does not "
operator|+
literal|"exist, filtering edits for '{}'"
argument_list|,
name|logPeerId
argument_list|()
argument_list|,
name|table
argument_list|)
expr_stmt|;
name|batches
operator|=
name|filterBatches
argument_list|(
name|batches
argument_list|,
name|table
argument_list|)
expr_stmt|;
continue|continue;
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|iox
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"{} Exception checking for local table: "
argument_list|,
name|logPeerId
argument_list|()
argument_list|,
name|iox
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|// fall through and sleep below
block|}
else|else
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"{} Peer encountered RemoteException, rechecking all sinks: "
argument_list|,
name|logPeerId
argument_list|()
argument_list|,
name|ioe
argument_list|)
expr_stmt|;
name|replicationSinkMgr
operator|.
name|chooseSinks
argument_list|()
expr_stmt|;
block|}
block|}
else|else
block|{
if|if
condition|(
name|ioe
operator|instanceof
name|SocketTimeoutException
condition|)
block|{
comment|// This exception means we waited for more than 60s and nothing
comment|// happened, the cluster is alive and calling it right away
comment|// even for a test just makes things worse.
name|sleepForRetries
argument_list|(
literal|"Encountered a SocketTimeoutException. Since the "
operator|+
literal|"call to the remote cluster timed out, which is usually "
operator|+
literal|"caused by a machine failure or a massive slowdown"
argument_list|,
name|this
operator|.
name|socketTimeoutMultiplier
argument_list|)
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|ioe
operator|instanceof
name|ConnectException
operator|||
name|ioe
operator|instanceof
name|UnknownHostException
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"{} Peer is unavailable, rechecking all sinks: "
argument_list|,
name|logPeerId
argument_list|()
argument_list|,
name|ioe
argument_list|)
expr_stmt|;
name|replicationSinkMgr
operator|.
name|chooseSinks
argument_list|()
expr_stmt|;
block|}
else|else
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"{} Can't replicate because of a local or network error: "
argument_list|,
name|logPeerId
argument_list|()
argument_list|,
name|ioe
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|sleepForRetries
argument_list|(
literal|"Since we are unable to replicate"
argument_list|,
name|sleepMultiplier
argument_list|)
condition|)
block|{
name|sleepMultiplier
operator|++
expr_stmt|;
block|}
block|}
block|}
return|return
literal|false
return|;
comment|// in case we exited before replicating
block|}
specifier|protected
name|boolean
name|isPeerEnabled
parameter_list|()
block|{
return|return
name|ctx
operator|.
name|getReplicationPeer
argument_list|()
operator|.
name|isPeerEnabled
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|protected
name|void
name|doStop
parameter_list|()
block|{
name|disconnect
argument_list|()
expr_stmt|;
comment|// don't call super.doStop()
if|if
condition|(
name|this
operator|.
name|conn
operator|!=
literal|null
condition|)
block|{
try|try
block|{
name|this
operator|.
name|conn
operator|.
name|close
argument_list|()
expr_stmt|;
name|this
operator|.
name|conn
operator|=
literal|null
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"{} Failed to close the connection"
argument_list|,
name|logPeerId
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
comment|// Allow currently running replication tasks to finish
name|exec
operator|.
name|shutdown
argument_list|()
expr_stmt|;
try|try
block|{
name|exec
operator|.
name|awaitTermination
argument_list|(
name|maxTerminationWait
argument_list|,
name|TimeUnit
operator|.
name|MILLISECONDS
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{     }
comment|// Abort if the tasks did not terminate in time
if|if
condition|(
operator|!
name|exec
operator|.
name|isTerminated
argument_list|()
condition|)
block|{
name|String
name|errMsg
init|=
literal|"HBaseInterClusterReplicationEndpoint termination failed. The "
operator|+
literal|"ThreadPoolExecutor failed to finish all tasks within "
operator|+
name|maxTerminationWait
operator|+
literal|"ms. "
operator|+
literal|"Aborting to prevent Replication from deadlocking. See HBASE-16081."
decl_stmt|;
name|abortable
operator|.
name|abort
argument_list|(
name|errMsg
argument_list|,
operator|new
name|IOException
argument_list|(
name|errMsg
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|notifyStopped
argument_list|()
expr_stmt|;
block|}
annotation|@
name|VisibleForTesting
specifier|protected
name|int
name|replicateEntries
parameter_list|(
name|List
argument_list|<
name|Entry
argument_list|>
name|entries
parameter_list|,
name|int
name|batchIndex
parameter_list|,
name|int
name|timeout
parameter_list|)
throws|throws
name|IOException
block|{
name|SinkPeer
name|sinkPeer
init|=
literal|null
decl_stmt|;
try|try
block|{
name|int
name|entriesHashCode
init|=
name|System
operator|.
name|identityHashCode
argument_list|(
name|entries
argument_list|)
decl_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|long
name|size
init|=
name|entries
operator|.
name|stream
argument_list|()
operator|.
name|mapToLong
argument_list|(
name|this
operator|::
name|getEstimatedEntrySize
argument_list|)
operator|.
name|sum
argument_list|()
decl_stmt|;
name|LOG
operator|.
name|trace
argument_list|(
literal|"{} Replicating batch {} of {} entries with total size {} bytes to {}"
argument_list|,
name|logPeerId
argument_list|()
argument_list|,
name|entriesHashCode
argument_list|,
name|entries
operator|.
name|size
argument_list|()
argument_list|,
name|size
argument_list|,
name|replicationClusterId
argument_list|)
expr_stmt|;
block|}
name|sinkPeer
operator|=
name|replicationSinkMgr
operator|.
name|getReplicationSink
argument_list|()
expr_stmt|;
name|AsyncRegionServerAdmin
name|rsAdmin
init|=
name|sinkPeer
operator|.
name|getRegionServer
argument_list|()
decl_stmt|;
try|try
block|{
name|ReplicationProtbufUtil
operator|.
name|replicateWALEntry
argument_list|(
name|rsAdmin
argument_list|,
name|entries
operator|.
name|toArray
argument_list|(
operator|new
name|Entry
index|[
name|entries
operator|.
name|size
argument_list|()
index|]
argument_list|)
argument_list|,
name|replicationClusterId
argument_list|,
name|baseNamespaceDir
argument_list|,
name|hfileArchiveDir
argument_list|,
name|timeout
argument_list|)
expr_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|trace
argument_list|(
literal|"{} Completed replicating batch {}"
argument_list|,
name|logPeerId
argument_list|()
argument_list|,
name|entriesHashCode
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
if|if
condition|(
name|LOG
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|trace
argument_list|(
literal|"{} Failed replicating batch {}"
argument_list|,
name|logPeerId
argument_list|()
argument_list|,
name|entriesHashCode
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
throw|throw
name|e
throw|;
block|}
name|replicationSinkMgr
operator|.
name|reportSinkSuccess
argument_list|(
name|sinkPeer
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ioe
parameter_list|)
block|{
if|if
condition|(
name|sinkPeer
operator|!=
literal|null
condition|)
block|{
name|replicationSinkMgr
operator|.
name|reportBadSink
argument_list|(
name|sinkPeer
argument_list|)
expr_stmt|;
block|}
throw|throw
name|ioe
throw|;
block|}
return|return
name|batchIndex
return|;
block|}
specifier|private
name|int
name|serialReplicateRegionEntries
parameter_list|(
name|List
argument_list|<
name|Entry
argument_list|>
name|entries
parameter_list|,
name|int
name|batchIndex
parameter_list|,
name|int
name|timeout
parameter_list|)
throws|throws
name|IOException
block|{
name|int
name|batchSize
init|=
literal|0
decl_stmt|,
name|index
init|=
literal|0
decl_stmt|;
name|List
argument_list|<
name|Entry
argument_list|>
name|batch
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
for|for
control|(
name|Entry
name|entry
range|:
name|entries
control|)
block|{
name|int
name|entrySize
init|=
name|getEstimatedEntrySize
argument_list|(
name|entry
argument_list|)
decl_stmt|;
if|if
condition|(
name|batchSize
operator|>
literal|0
operator|&&
name|batchSize
operator|+
name|entrySize
operator|>
name|replicationRpcLimit
condition|)
block|{
name|replicateEntries
argument_list|(
name|batch
argument_list|,
name|index
operator|++
argument_list|,
name|timeout
argument_list|)
expr_stmt|;
name|batch
operator|.
name|clear
argument_list|()
expr_stmt|;
name|batchSize
operator|=
literal|0
expr_stmt|;
block|}
name|batch
operator|.
name|add
argument_list|(
name|entry
argument_list|)
expr_stmt|;
name|batchSize
operator|+=
name|entrySize
expr_stmt|;
block|}
if|if
condition|(
name|batchSize
operator|>
literal|0
condition|)
block|{
name|replicateEntries
argument_list|(
name|batch
argument_list|,
name|index
argument_list|,
name|timeout
argument_list|)
expr_stmt|;
block|}
return|return
name|batchIndex
return|;
block|}
annotation|@
name|VisibleForTesting
specifier|protected
name|Callable
argument_list|<
name|Integer
argument_list|>
name|createReplicator
parameter_list|(
name|List
argument_list|<
name|Entry
argument_list|>
name|entries
parameter_list|,
name|int
name|batchIndex
parameter_list|,
name|int
name|timeout
parameter_list|)
block|{
return|return
name|isSerial
condition|?
parameter_list|()
lambda|->
name|serialReplicateRegionEntries
argument_list|(
name|entries
argument_list|,
name|batchIndex
argument_list|,
name|timeout
argument_list|)
else|:
parameter_list|()
lambda|->
name|replicateEntries
argument_list|(
name|entries
argument_list|,
name|batchIndex
argument_list|,
name|timeout
argument_list|)
return|;
block|}
specifier|private
name|String
name|logPeerId
parameter_list|()
block|{
return|return
literal|"[Source for peer "
operator|+
name|this
operator|.
name|ctx
operator|.
name|getPeerId
argument_list|()
operator|+
literal|"]:"
return|;
block|}
block|}
end_class

end_unit

