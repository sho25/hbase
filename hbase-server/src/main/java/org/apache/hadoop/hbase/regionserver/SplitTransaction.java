begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  *  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ListIterator
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|Callable
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ExecutionException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|Executors
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|Future
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ThreadFactory
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ThreadPoolExecutor
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|TimeUnit
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|Log
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|LogFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|classification
operator|.
name|InterfaceAudience
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileStatus
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HRegionInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|RegionTransition
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|Server
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|ServerName
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|catalog
operator|.
name|MetaEditor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|executor
operator|.
name|EventType
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|Bytes
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|CancelableProgressable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|EnvironmentEdgeManager
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|FSUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|HasThread
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|PairOfSameType
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|zookeeper
operator|.
name|ZKAssign
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|zookeeper
operator|.
name|ZKUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|zookeeper
operator|.
name|ZooKeeperWatcher
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|zookeeper
operator|.
name|KeeperException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|zookeeper
operator|.
name|KeeperException
operator|.
name|NodeExistsException
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ThreadFactoryBuilder
import|;
end_import

begin_comment
comment|/**  * Executes region split as a "transaction".  Call {@link #prepare()} to setup  * the transaction, {@link #execute(Server, RegionServerServices)} to run the  * transaction and {@link #rollback(Server, RegionServerServices)} to cleanup if execute fails.  *  *<p>Here is an example of how you would use this class:  *<pre>  *  SplitTransaction st = new SplitTransaction(this.conf, parent, midKey)  *  if (!st.prepare()) return;  *  try {  *    st.execute(server, services);  *  } catch (IOException ioe) {  *    try {  *      st.rollback(server, services);  *      return;  *    } catch (RuntimeException e) {  *      myAbortable.abort("Failed split, abort");  *    }  *  }  *</Pre>  *<p>This class is not thread safe.  Caller needs ensure split is run by  * one thread only.  */
end_comment

begin_class
annotation|@
name|InterfaceAudience
operator|.
name|Private
specifier|public
class|class
name|SplitTransaction
block|{
specifier|private
specifier|static
specifier|final
name|Log
name|LOG
init|=
name|LogFactory
operator|.
name|getLog
argument_list|(
name|SplitTransaction
operator|.
name|class
argument_list|)
decl_stmt|;
comment|/*    * Region to split    */
specifier|private
specifier|final
name|HRegion
name|parent
decl_stmt|;
specifier|private
name|HRegionInfo
name|hri_a
decl_stmt|;
specifier|private
name|HRegionInfo
name|hri_b
decl_stmt|;
specifier|private
name|Path
name|splitdir
decl_stmt|;
specifier|private
name|long
name|fileSplitTimeout
init|=
literal|30000
decl_stmt|;
specifier|private
name|int
name|znodeVersion
init|=
operator|-
literal|1
decl_stmt|;
comment|/*    * Row to split around    */
specifier|private
specifier|final
name|byte
index|[]
name|splitrow
decl_stmt|;
comment|/**    * Types to add to the transaction journal.    * Each enum is a step in the split transaction. Used to figure how much    * we need to rollback.    */
enum|enum
name|JournalEntry
block|{
comment|/**      * Set region as in transition, set it into SPLITTING state.      */
name|SET_SPLITTING_IN_ZK
block|,
comment|/**      * We created the temporary split data directory.      */
name|CREATE_SPLIT_DIR
block|,
comment|/**      * Closed the parent region.      */
name|CLOSED_PARENT_REGION
block|,
comment|/**      * The parent has been taken out of the server's online regions list.      */
name|OFFLINED_PARENT
block|,
comment|/**      * Started in on creation of the first daughter region.      */
name|STARTED_REGION_A_CREATION
block|,
comment|/**      * Started in on the creation of the second daughter region.      */
name|STARTED_REGION_B_CREATION
block|,
comment|/**      * Point of no return.      * If we got here, then transaction is not recoverable other than by      * crashing out the regionserver.      */
name|PONR
block|}
comment|/*    * Journal of how far the split transaction has progressed.    */
specifier|private
specifier|final
name|List
argument_list|<
name|JournalEntry
argument_list|>
name|journal
init|=
operator|new
name|ArrayList
argument_list|<
name|JournalEntry
argument_list|>
argument_list|()
decl_stmt|;
comment|/**    * Constructor    * @param r Region to split    * @param splitrow Row to split around    */
specifier|public
name|SplitTransaction
parameter_list|(
specifier|final
name|HRegion
name|r
parameter_list|,
specifier|final
name|byte
index|[]
name|splitrow
parameter_list|)
block|{
name|this
operator|.
name|parent
operator|=
name|r
expr_stmt|;
name|this
operator|.
name|splitrow
operator|=
name|splitrow
expr_stmt|;
name|this
operator|.
name|splitdir
operator|=
name|getSplitDir
argument_list|(
name|this
operator|.
name|parent
argument_list|)
expr_stmt|;
block|}
comment|/**    * Does checks on split inputs.    * @return<code>true</code> if the region is splittable else    *<code>false</code> if it is not (e.g. its already closed, etc.).    */
specifier|public
name|boolean
name|prepare
parameter_list|()
block|{
if|if
condition|(
operator|!
name|this
operator|.
name|parent
operator|.
name|isSplittable
argument_list|()
condition|)
return|return
literal|false
return|;
comment|// Split key can be null if this region is unsplittable; i.e. has refs.
if|if
condition|(
name|this
operator|.
name|splitrow
operator|==
literal|null
condition|)
return|return
literal|false
return|;
name|HRegionInfo
name|hri
init|=
name|this
operator|.
name|parent
operator|.
name|getRegionInfo
argument_list|()
decl_stmt|;
name|parent
operator|.
name|prepareToSplit
argument_list|()
expr_stmt|;
comment|// Check splitrow.
name|byte
index|[]
name|startKey
init|=
name|hri
operator|.
name|getStartKey
argument_list|()
decl_stmt|;
name|byte
index|[]
name|endKey
init|=
name|hri
operator|.
name|getEndKey
argument_list|()
decl_stmt|;
if|if
condition|(
name|Bytes
operator|.
name|equals
argument_list|(
name|startKey
argument_list|,
name|splitrow
argument_list|)
operator|||
operator|!
name|this
operator|.
name|parent
operator|.
name|getRegionInfo
argument_list|()
operator|.
name|containsRow
argument_list|(
name|splitrow
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Split row is not inside region key range or is equal to "
operator|+
literal|"startkey: "
operator|+
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|this
operator|.
name|splitrow
argument_list|)
argument_list|)
expr_stmt|;
return|return
literal|false
return|;
block|}
name|long
name|rid
init|=
name|getDaughterRegionIdTimestamp
argument_list|(
name|hri
argument_list|)
decl_stmt|;
name|this
operator|.
name|hri_a
operator|=
operator|new
name|HRegionInfo
argument_list|(
name|hri
operator|.
name|getTableName
argument_list|()
argument_list|,
name|startKey
argument_list|,
name|this
operator|.
name|splitrow
argument_list|,
literal|false
argument_list|,
name|rid
argument_list|)
expr_stmt|;
name|this
operator|.
name|hri_b
operator|=
operator|new
name|HRegionInfo
argument_list|(
name|hri
operator|.
name|getTableName
argument_list|()
argument_list|,
name|this
operator|.
name|splitrow
argument_list|,
name|endKey
argument_list|,
literal|false
argument_list|,
name|rid
argument_list|)
expr_stmt|;
return|return
literal|true
return|;
block|}
comment|/**    * Calculate daughter regionid to use.    * @param hri Parent {@link HRegionInfo}    * @return Daughter region id (timestamp) to use.    */
specifier|private
specifier|static
name|long
name|getDaughterRegionIdTimestamp
parameter_list|(
specifier|final
name|HRegionInfo
name|hri
parameter_list|)
block|{
name|long
name|rid
init|=
name|EnvironmentEdgeManager
operator|.
name|currentTimeMillis
argument_list|()
decl_stmt|;
comment|// Regionid is timestamp.  Can't be less than that of parent else will insert
comment|// at wrong location in .META. (See HBASE-710).
if|if
condition|(
name|rid
operator|<
name|hri
operator|.
name|getRegionId
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Clock skew; parent regions id is "
operator|+
name|hri
operator|.
name|getRegionId
argument_list|()
operator|+
literal|" but current time here is "
operator|+
name|rid
argument_list|)
expr_stmt|;
name|rid
operator|=
name|hri
operator|.
name|getRegionId
argument_list|()
operator|+
literal|1
expr_stmt|;
block|}
return|return
name|rid
return|;
block|}
specifier|private
specifier|static
name|IOException
name|closedByOtherException
init|=
operator|new
name|IOException
argument_list|(
literal|"Failed to close region: already closed by another thread"
argument_list|)
decl_stmt|;
comment|/**    * Prepare the regions and region files.    * @param server Hosting server instance.  Can be null when testing (won't try    * and update in zk if a null server)    * @param services Used to online/offline regions.    * @throws IOException If thrown, transaction failed. Call {@link #rollback(Server, RegionServerServices)}    * @return Regions created    */
comment|/* package */
name|PairOfSameType
argument_list|<
name|HRegion
argument_list|>
name|createDaughters
parameter_list|(
specifier|final
name|Server
name|server
parameter_list|,
specifier|final
name|RegionServerServices
name|services
parameter_list|)
throws|throws
name|IOException
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Starting split of region "
operator|+
name|this
operator|.
name|parent
argument_list|)
expr_stmt|;
if|if
condition|(
operator|(
name|server
operator|!=
literal|null
operator|&&
name|server
operator|.
name|isStopped
argument_list|()
operator|)
operator|||
operator|(
name|services
operator|!=
literal|null
operator|&&
name|services
operator|.
name|isStopping
argument_list|()
operator|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Server is stopped or stopping"
argument_list|)
throw|;
block|}
assert|assert
operator|!
name|this
operator|.
name|parent
operator|.
name|lock
operator|.
name|writeLock
argument_list|()
operator|.
name|isHeldByCurrentThread
argument_list|()
operator|:
literal|"Unsafe to hold write lock while performing RPCs"
assert|;
comment|// Coprocessor callback
if|if
condition|(
name|this
operator|.
name|parent
operator|.
name|getCoprocessorHost
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|this
operator|.
name|parent
operator|.
name|getCoprocessorHost
argument_list|()
operator|.
name|preSplit
argument_list|()
expr_stmt|;
block|}
comment|// Coprocessor callback
if|if
condition|(
name|this
operator|.
name|parent
operator|.
name|getCoprocessorHost
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|this
operator|.
name|parent
operator|.
name|getCoprocessorHost
argument_list|()
operator|.
name|preSplit
argument_list|(
name|this
operator|.
name|splitrow
argument_list|)
expr_stmt|;
block|}
comment|// If true, no cluster to write meta edits to or to update znodes in.
name|boolean
name|testing
init|=
name|server
operator|==
literal|null
condition|?
literal|true
else|:
name|server
operator|.
name|getConfiguration
argument_list|()
operator|.
name|getBoolean
argument_list|(
literal|"hbase.testing.nocluster"
argument_list|,
literal|false
argument_list|)
decl_stmt|;
name|this
operator|.
name|fileSplitTimeout
operator|=
name|testing
condition|?
name|this
operator|.
name|fileSplitTimeout
else|:
name|server
operator|.
name|getConfiguration
argument_list|()
operator|.
name|getLong
argument_list|(
literal|"hbase.regionserver.fileSplitTimeout"
argument_list|,
name|this
operator|.
name|fileSplitTimeout
argument_list|)
expr_stmt|;
comment|// Set ephemeral SPLITTING znode up in zk.  Mocked servers sometimes don't
comment|// have zookeeper so don't do zk stuff if server or zookeeper is null
if|if
condition|(
name|server
operator|!=
literal|null
operator|&&
name|server
operator|.
name|getZooKeeper
argument_list|()
operator|!=
literal|null
condition|)
block|{
try|try
block|{
name|createNodeSplitting
argument_list|(
name|server
operator|.
name|getZooKeeper
argument_list|()
argument_list|,
name|this
operator|.
name|parent
operator|.
name|getRegionInfo
argument_list|()
argument_list|,
name|server
operator|.
name|getServerName
argument_list|()
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|KeeperException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Failed creating SPLITTING znode on "
operator|+
name|this
operator|.
name|parent
operator|.
name|getRegionNameAsString
argument_list|()
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
name|this
operator|.
name|journal
operator|.
name|add
argument_list|(
name|JournalEntry
operator|.
name|SET_SPLITTING_IN_ZK
argument_list|)
expr_stmt|;
if|if
condition|(
name|server
operator|!=
literal|null
operator|&&
name|server
operator|.
name|getZooKeeper
argument_list|()
operator|!=
literal|null
condition|)
block|{
try|try
block|{
comment|// Transition node from SPLITTING to SPLITTING after creating the split node.
comment|// Master will get the callback for node change only if the transition is successful.
comment|// Note that if the transition fails then the rollback will delete the created znode
comment|// as the journal entry SET_SPLITTING_IN_ZK is added.
comment|// TODO : May be we can add some new state to znode and handle the new state incase of success/failure
name|this
operator|.
name|znodeVersion
operator|=
name|transitionNodeSplitting
argument_list|(
name|server
operator|.
name|getZooKeeper
argument_list|()
argument_list|,
name|this
operator|.
name|parent
operator|.
name|getRegionInfo
argument_list|()
argument_list|,
name|server
operator|.
name|getServerName
argument_list|()
argument_list|,
operator|-
literal|1
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|KeeperException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Failed setting SPLITTING znode on "
operator|+
name|this
operator|.
name|parent
operator|.
name|getRegionNameAsString
argument_list|()
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
name|createSplitDir
argument_list|(
name|this
operator|.
name|parent
operator|.
name|getFilesystem
argument_list|()
argument_list|,
name|this
operator|.
name|splitdir
argument_list|)
expr_stmt|;
name|this
operator|.
name|journal
operator|.
name|add
argument_list|(
name|JournalEntry
operator|.
name|CREATE_SPLIT_DIR
argument_list|)
expr_stmt|;
name|List
argument_list|<
name|StoreFile
argument_list|>
name|hstoreFilesToSplit
init|=
literal|null
decl_stmt|;
name|Exception
name|exceptionToThrow
init|=
literal|null
decl_stmt|;
try|try
block|{
name|hstoreFilesToSplit
operator|=
name|this
operator|.
name|parent
operator|.
name|close
argument_list|(
literal|false
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|exceptionToThrow
operator|=
name|e
expr_stmt|;
block|}
if|if
condition|(
name|exceptionToThrow
operator|==
literal|null
operator|&&
name|hstoreFilesToSplit
operator|==
literal|null
condition|)
block|{
comment|// The region was closed by a concurrent thread.  We can't continue
comment|// with the split, instead we must just abandon the split.  If we
comment|// reopen or split this could cause problems because the region has
comment|// probably already been moved to a different server, or is in the
comment|// process of moving to a different server.
name|exceptionToThrow
operator|=
name|closedByOtherException
expr_stmt|;
block|}
if|if
condition|(
name|exceptionToThrow
operator|!=
name|closedByOtherException
condition|)
block|{
name|this
operator|.
name|journal
operator|.
name|add
argument_list|(
name|JournalEntry
operator|.
name|CLOSED_PARENT_REGION
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|exceptionToThrow
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
name|exceptionToThrow
operator|instanceof
name|IOException
condition|)
throw|throw
operator|(
name|IOException
operator|)
name|exceptionToThrow
throw|;
throw|throw
operator|new
name|IOException
argument_list|(
name|exceptionToThrow
argument_list|)
throw|;
block|}
if|if
condition|(
operator|!
name|testing
condition|)
block|{
name|services
operator|.
name|removeFromOnlineRegions
argument_list|(
name|this
operator|.
name|parent
argument_list|,
literal|null
argument_list|)
expr_stmt|;
block|}
name|this
operator|.
name|journal
operator|.
name|add
argument_list|(
name|JournalEntry
operator|.
name|OFFLINED_PARENT
argument_list|)
expr_stmt|;
comment|// TODO: If splitStoreFiles were multithreaded would we complete steps in
comment|// less elapsed time?  St.Ack 20100920
comment|//
comment|// splitStoreFiles creates daughter region dirs under the parent splits dir
comment|// Nothing to unroll here if failure -- clean up of CREATE_SPLIT_DIR will
comment|// clean this up.
name|splitStoreFiles
argument_list|(
name|this
operator|.
name|splitdir
argument_list|,
name|hstoreFilesToSplit
argument_list|)
expr_stmt|;
comment|// Log to the journal that we are creating region A, the first daughter
comment|// region.  We could fail halfway through.  If we do, we could have left
comment|// stuff in fs that needs cleanup -- a storefile or two.  Thats why we
comment|// add entry to journal BEFORE rather than AFTER the change.
name|this
operator|.
name|journal
operator|.
name|add
argument_list|(
name|JournalEntry
operator|.
name|STARTED_REGION_A_CREATION
argument_list|)
expr_stmt|;
name|HRegion
name|a
init|=
name|createDaughterRegion
argument_list|(
name|this
operator|.
name|hri_a
argument_list|)
decl_stmt|;
comment|// Ditto
name|this
operator|.
name|journal
operator|.
name|add
argument_list|(
name|JournalEntry
operator|.
name|STARTED_REGION_B_CREATION
argument_list|)
expr_stmt|;
name|HRegion
name|b
init|=
name|createDaughterRegion
argument_list|(
name|this
operator|.
name|hri_b
argument_list|)
decl_stmt|;
comment|// This is the point of no return.  Adding subsequent edits to .META. as we
comment|// do below when we do the daughter opens adding each to .META. can fail in
comment|// various interesting ways the most interesting of which is a timeout
comment|// BUT the edits all go through (See HBASE-3872).  IF we reach the PONR
comment|// then subsequent failures need to crash out this regionserver; the
comment|// server shutdown processing should be able to fix-up the incomplete split.
comment|// The offlined parent will have the daughters as extra columns.  If
comment|// we leave the daughter regions in place and do not remove them when we
comment|// crash out, then they will have their references to the parent in place
comment|// still and the server shutdown fixup of .META. will point to these
comment|// regions.
comment|// We should add PONR JournalEntry before offlineParentInMeta,so even if
comment|// OfflineParentInMeta timeout,this will cause regionserver exit,and then
comment|// master ServerShutdownHandler will fix daughter& avoid data loss. (See
comment|// HBase-4562).
name|this
operator|.
name|journal
operator|.
name|add
argument_list|(
name|JournalEntry
operator|.
name|PONR
argument_list|)
expr_stmt|;
comment|// Edit parent in meta.  Offlines parent region and adds splita and splitb
comment|// as an atomic update. See HBASE-7721. This update to META makes the region
comment|// will determine whether the region is split or not in case of failures.
comment|// If it is successful, master will roll-forward, if not, master will rollback
comment|// and assign the parent region.
if|if
condition|(
operator|!
name|testing
condition|)
block|{
name|MetaEditor
operator|.
name|splitRegion
argument_list|(
name|server
operator|.
name|getCatalogTracker
argument_list|()
argument_list|,
name|parent
operator|.
name|getRegionInfo
argument_list|()
argument_list|,
name|a
operator|.
name|getRegionInfo
argument_list|()
argument_list|,
name|b
operator|.
name|getRegionInfo
argument_list|()
argument_list|,
name|server
operator|.
name|getServerName
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
operator|new
name|PairOfSameType
argument_list|<
name|HRegion
argument_list|>
argument_list|(
name|a
argument_list|,
name|b
argument_list|)
return|;
block|}
comment|/**    * Perform time consuming opening of the daughter regions.    * @param server Hosting server instance.  Can be null when testing (won't try    * and update in zk if a null server)    * @param services Used to online/offline regions.    * @param a first daughter region    * @param a second daughter region    * @throws IOException If thrown, transaction failed. Call {@link #rollback(Server, RegionServerServices)}    */
comment|/* package */
name|void
name|openDaughters
parameter_list|(
specifier|final
name|Server
name|server
parameter_list|,
specifier|final
name|RegionServerServices
name|services
parameter_list|,
name|HRegion
name|a
parameter_list|,
name|HRegion
name|b
parameter_list|)
throws|throws
name|IOException
block|{
name|boolean
name|stopped
init|=
name|server
operator|!=
literal|null
operator|&&
name|server
operator|.
name|isStopped
argument_list|()
decl_stmt|;
name|boolean
name|stopping
init|=
name|services
operator|!=
literal|null
operator|&&
name|services
operator|.
name|isStopping
argument_list|()
decl_stmt|;
comment|// TODO: Is this check needed here?
if|if
condition|(
name|stopped
operator|||
name|stopping
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Not opening daughters "
operator|+
name|b
operator|.
name|getRegionInfo
argument_list|()
operator|.
name|getRegionNameAsString
argument_list|()
operator|+
literal|" and "
operator|+
name|a
operator|.
name|getRegionInfo
argument_list|()
operator|.
name|getRegionNameAsString
argument_list|()
operator|+
literal|" because stopping="
operator|+
name|stopping
operator|+
literal|", stopped="
operator|+
name|stopped
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// Open daughters in parallel.
name|DaughterOpener
name|aOpener
init|=
operator|new
name|DaughterOpener
argument_list|(
name|server
argument_list|,
name|a
argument_list|)
decl_stmt|;
name|DaughterOpener
name|bOpener
init|=
operator|new
name|DaughterOpener
argument_list|(
name|server
argument_list|,
name|b
argument_list|)
decl_stmt|;
name|aOpener
operator|.
name|start
argument_list|()
expr_stmt|;
name|bOpener
operator|.
name|start
argument_list|()
expr_stmt|;
try|try
block|{
name|aOpener
operator|.
name|join
argument_list|()
expr_stmt|;
name|bOpener
operator|.
name|join
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|interrupt
argument_list|()
expr_stmt|;
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Interrupted "
operator|+
name|e
operator|.
name|getMessage
argument_list|()
argument_list|)
throw|;
block|}
if|if
condition|(
name|aOpener
operator|.
name|getException
argument_list|()
operator|!=
literal|null
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Failed "
operator|+
name|aOpener
operator|.
name|getName
argument_list|()
argument_list|,
name|aOpener
operator|.
name|getException
argument_list|()
argument_list|)
throw|;
block|}
if|if
condition|(
name|bOpener
operator|.
name|getException
argument_list|()
operator|!=
literal|null
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Failed "
operator|+
name|bOpener
operator|.
name|getName
argument_list|()
argument_list|,
name|bOpener
operator|.
name|getException
argument_list|()
argument_list|)
throw|;
block|}
if|if
condition|(
name|services
operator|!=
literal|null
condition|)
block|{
try|try
block|{
comment|// add 2nd daughter first (see HBASE-4335)
name|services
operator|.
name|postOpenDeployTasks
argument_list|(
name|b
argument_list|,
name|server
operator|.
name|getCatalogTracker
argument_list|()
argument_list|)
expr_stmt|;
comment|// Should add it to OnlineRegions
name|services
operator|.
name|addToOnlineRegions
argument_list|(
name|b
argument_list|)
expr_stmt|;
name|services
operator|.
name|postOpenDeployTasks
argument_list|(
name|a
argument_list|,
name|server
operator|.
name|getCatalogTracker
argument_list|()
argument_list|)
expr_stmt|;
name|services
operator|.
name|addToOnlineRegions
argument_list|(
name|a
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|KeeperException
name|ke
parameter_list|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|ke
argument_list|)
throw|;
block|}
block|}
block|}
block|}
comment|/**    * Finish off split transaction, transition the zknode    * @param server Hosting server instance.  Can be null when testing (won't try    * and update in zk if a null server)    * @param services Used to online/offline regions.    * @param a first daughter region    * @param a second daughter region    * @throws IOException If thrown, transaction failed. Call {@link #rollback(Server, RegionServerServices)}    */
comment|/* package */
name|void
name|transitionZKNode
parameter_list|(
specifier|final
name|Server
name|server
parameter_list|,
specifier|final
name|RegionServerServices
name|services
parameter_list|,
name|HRegion
name|a
parameter_list|,
name|HRegion
name|b
parameter_list|)
throws|throws
name|IOException
block|{
comment|// Tell master about split by updating zk.  If we fail, abort.
if|if
condition|(
name|server
operator|!=
literal|null
operator|&&
name|server
operator|.
name|getZooKeeper
argument_list|()
operator|!=
literal|null
condition|)
block|{
try|try
block|{
name|this
operator|.
name|znodeVersion
operator|=
name|transitionNodeSplit
argument_list|(
name|server
operator|.
name|getZooKeeper
argument_list|()
argument_list|,
name|parent
operator|.
name|getRegionInfo
argument_list|()
argument_list|,
name|a
operator|.
name|getRegionInfo
argument_list|()
argument_list|,
name|b
operator|.
name|getRegionInfo
argument_list|()
argument_list|,
name|server
operator|.
name|getServerName
argument_list|()
argument_list|,
name|this
operator|.
name|znodeVersion
argument_list|)
expr_stmt|;
name|int
name|spins
init|=
literal|0
decl_stmt|;
comment|// Now wait for the master to process the split. We know it's done
comment|// when the znode is deleted. The reason we keep tickling the znode is
comment|// that it's possible for the master to miss an event.
do|do
block|{
if|if
condition|(
name|spins
operator|%
literal|10
operator|==
literal|0
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Still waiting on the master to process the split for "
operator|+
name|this
operator|.
name|parent
operator|.
name|getRegionInfo
argument_list|()
operator|.
name|getEncodedName
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|Thread
operator|.
name|sleep
argument_list|(
literal|100
argument_list|)
expr_stmt|;
comment|// When this returns -1 it means the znode doesn't exist
name|this
operator|.
name|znodeVersion
operator|=
name|tickleNodeSplit
argument_list|(
name|server
operator|.
name|getZooKeeper
argument_list|()
argument_list|,
name|parent
operator|.
name|getRegionInfo
argument_list|()
argument_list|,
name|a
operator|.
name|getRegionInfo
argument_list|()
argument_list|,
name|b
operator|.
name|getRegionInfo
argument_list|()
argument_list|,
name|server
operator|.
name|getServerName
argument_list|()
argument_list|,
name|this
operator|.
name|znodeVersion
argument_list|)
expr_stmt|;
name|spins
operator|++
expr_stmt|;
block|}
do|while
condition|(
name|this
operator|.
name|znodeVersion
operator|!=
operator|-
literal|1
operator|&&
operator|!
name|server
operator|.
name|isStopped
argument_list|()
operator|&&
operator|!
name|services
operator|.
name|isStopping
argument_list|()
condition|)
do|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
if|if
condition|(
name|e
operator|instanceof
name|InterruptedException
condition|)
block|{
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|interrupt
argument_list|()
expr_stmt|;
block|}
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Failed telling master about split"
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
comment|// Coprocessor callback
if|if
condition|(
name|this
operator|.
name|parent
operator|.
name|getCoprocessorHost
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|this
operator|.
name|parent
operator|.
name|getCoprocessorHost
argument_list|()
operator|.
name|postSplit
argument_list|(
name|a
argument_list|,
name|b
argument_list|)
expr_stmt|;
block|}
comment|// Leaving here, the splitdir with its dross will be in place but since the
comment|// split was successful, just leave it; it'll be cleaned when parent is
comment|// deleted and cleaned up.
block|}
comment|/**    * Run the transaction.    * @param server Hosting server instance.  Can be null when testing (won't try    * and update in zk if a null server)    * @param services Used to online/offline regions.    * @throws IOException If thrown, transaction failed. Call {@link #rollback(Server, RegionServerServices)}    * @return Regions created    * @throws IOException    * @see #rollback(Server, RegionServerServices)    */
specifier|public
name|PairOfSameType
argument_list|<
name|HRegion
argument_list|>
name|execute
parameter_list|(
specifier|final
name|Server
name|server
parameter_list|,
specifier|final
name|RegionServerServices
name|services
parameter_list|)
throws|throws
name|IOException
block|{
name|PairOfSameType
argument_list|<
name|HRegion
argument_list|>
name|regions
init|=
name|createDaughters
argument_list|(
name|server
argument_list|,
name|services
argument_list|)
decl_stmt|;
name|openDaughters
argument_list|(
name|server
argument_list|,
name|services
argument_list|,
name|regions
operator|.
name|getFirst
argument_list|()
argument_list|,
name|regions
operator|.
name|getSecond
argument_list|()
argument_list|)
expr_stmt|;
name|transitionZKNode
argument_list|(
name|server
argument_list|,
name|services
argument_list|,
name|regions
operator|.
name|getFirst
argument_list|()
argument_list|,
name|regions
operator|.
name|getSecond
argument_list|()
argument_list|)
expr_stmt|;
return|return
name|regions
return|;
block|}
comment|/*    * Open daughter region in its own thread.    * If we fail, abort this hosting server.    */
class|class
name|DaughterOpener
extends|extends
name|HasThread
block|{
specifier|private
specifier|final
name|Server
name|server
decl_stmt|;
specifier|private
specifier|final
name|HRegion
name|r
decl_stmt|;
specifier|private
name|Throwable
name|t
init|=
literal|null
decl_stmt|;
name|DaughterOpener
parameter_list|(
specifier|final
name|Server
name|s
parameter_list|,
specifier|final
name|HRegion
name|r
parameter_list|)
block|{
name|super
argument_list|(
operator|(
name|s
operator|==
literal|null
condition|?
literal|"null-services"
else|:
name|s
operator|.
name|getServerName
argument_list|()
operator|)
operator|+
literal|"-daughterOpener="
operator|+
name|r
operator|.
name|getRegionInfo
argument_list|()
operator|.
name|getEncodedName
argument_list|()
argument_list|)
expr_stmt|;
name|setDaemon
argument_list|(
literal|true
argument_list|)
expr_stmt|;
name|this
operator|.
name|server
operator|=
name|s
expr_stmt|;
name|this
operator|.
name|r
operator|=
name|r
expr_stmt|;
block|}
comment|/**      * @return Null if open succeeded else exception that causes us fail open.      * Call it after this thread exits else you may get wrong view on result.      */
name|Throwable
name|getException
parameter_list|()
block|{
return|return
name|this
operator|.
name|t
return|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|run
parameter_list|()
block|{
try|try
block|{
name|openDaughterRegion
argument_list|(
name|this
operator|.
name|server
argument_list|,
name|r
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Throwable
name|t
parameter_list|)
block|{
name|this
operator|.
name|t
operator|=
name|t
expr_stmt|;
block|}
block|}
block|}
comment|/**    * Open daughter regions, add them to online list and update meta.    * @param server    * @param daughter    * @throws IOException    * @throws KeeperException    */
name|void
name|openDaughterRegion
parameter_list|(
specifier|final
name|Server
name|server
parameter_list|,
specifier|final
name|HRegion
name|daughter
parameter_list|)
throws|throws
name|IOException
throws|,
name|KeeperException
block|{
name|HRegionInfo
name|hri
init|=
name|daughter
operator|.
name|getRegionInfo
argument_list|()
decl_stmt|;
name|LoggingProgressable
name|reporter
init|=
name|server
operator|==
literal|null
condition|?
literal|null
else|:
operator|new
name|LoggingProgressable
argument_list|(
name|hri
argument_list|,
name|server
operator|.
name|getConfiguration
argument_list|()
argument_list|)
decl_stmt|;
name|daughter
operator|.
name|openHRegion
argument_list|(
name|reporter
argument_list|)
expr_stmt|;
block|}
specifier|static
class|class
name|LoggingProgressable
implements|implements
name|CancelableProgressable
block|{
specifier|private
specifier|final
name|HRegionInfo
name|hri
decl_stmt|;
specifier|private
name|long
name|lastLog
init|=
operator|-
literal|1
decl_stmt|;
specifier|private
specifier|final
name|long
name|interval
decl_stmt|;
name|LoggingProgressable
parameter_list|(
specifier|final
name|HRegionInfo
name|hri
parameter_list|,
specifier|final
name|Configuration
name|c
parameter_list|)
block|{
name|this
operator|.
name|hri
operator|=
name|hri
expr_stmt|;
name|this
operator|.
name|interval
operator|=
name|c
operator|.
name|getLong
argument_list|(
literal|"hbase.regionserver.split.daughter.open.log.interval"
argument_list|,
literal|10000
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|progress
parameter_list|()
block|{
name|long
name|now
init|=
name|System
operator|.
name|currentTimeMillis
argument_list|()
decl_stmt|;
if|if
condition|(
name|now
operator|-
name|lastLog
operator|>
name|this
operator|.
name|interval
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Opening "
operator|+
name|this
operator|.
name|hri
operator|.
name|getRegionNameAsString
argument_list|()
argument_list|)
expr_stmt|;
name|this
operator|.
name|lastLog
operator|=
name|now
expr_stmt|;
block|}
return|return
literal|true
return|;
block|}
block|}
specifier|private
specifier|static
name|Path
name|getSplitDir
parameter_list|(
specifier|final
name|HRegion
name|r
parameter_list|)
block|{
return|return
operator|new
name|Path
argument_list|(
name|r
operator|.
name|getRegionDir
argument_list|()
argument_list|,
name|HRegionFileSystem
operator|.
name|REGION_SPLITS_DIR
argument_list|)
return|;
block|}
comment|/**    * @param fs Filesystem to use    * @param splitdir Directory to store temporary split data in    * @throws IOException If<code>splitdir</code> already exists or we fail    * to create it.    * @see #cleanupSplitDir(FileSystem, Path)    */
specifier|private
specifier|static
name|void
name|createSplitDir
parameter_list|(
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Path
name|splitdir
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|fs
operator|.
name|exists
argument_list|(
name|splitdir
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"The "
operator|+
name|splitdir
operator|+
literal|" directory exists.  Hence deleting it to recreate it"
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|fs
operator|.
name|delete
argument_list|(
name|splitdir
argument_list|,
literal|true
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Failed deletion of "
operator|+
name|splitdir
operator|+
literal|" before creating them again."
argument_list|)
throw|;
block|}
block|}
if|if
condition|(
operator|!
name|fs
operator|.
name|mkdirs
argument_list|(
name|splitdir
argument_list|)
condition|)
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Failed create of "
operator|+
name|splitdir
argument_list|)
throw|;
block|}
specifier|private
specifier|static
name|void
name|cleanupSplitDir
parameter_list|(
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Path
name|splitdir
parameter_list|)
throws|throws
name|IOException
block|{
comment|// Splitdir may have been cleaned up by reopen of the parent dir.
name|deleteDir
argument_list|(
name|fs
argument_list|,
name|splitdir
argument_list|,
literal|false
argument_list|)
expr_stmt|;
block|}
comment|/**    * @param fs Filesystem to use    * @param dir Directory to delete    * @param mustPreExist If true, we'll throw exception if<code>dir</code>    * does not preexist, else we'll just pass.    * @throws IOException Thrown if we fail to delete passed<code>dir</code>    */
specifier|private
specifier|static
name|void
name|deleteDir
parameter_list|(
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Path
name|dir
parameter_list|,
specifier|final
name|boolean
name|mustPreExist
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
operator|!
name|fs
operator|.
name|exists
argument_list|(
name|dir
argument_list|)
condition|)
block|{
if|if
condition|(
name|mustPreExist
condition|)
throw|throw
operator|new
name|IOException
argument_list|(
name|dir
operator|.
name|toString
argument_list|()
operator|+
literal|" does not exist!"
argument_list|)
throw|;
block|}
elseif|else
if|if
condition|(
operator|!
name|fs
operator|.
name|delete
argument_list|(
name|dir
argument_list|,
literal|true
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Failed delete of "
operator|+
name|dir
argument_list|)
throw|;
block|}
block|}
specifier|private
name|void
name|splitStoreFiles
parameter_list|(
specifier|final
name|Path
name|splitdir
parameter_list|,
specifier|final
name|List
argument_list|<
name|StoreFile
argument_list|>
name|hstoreFilesToSplit
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|hstoreFilesToSplit
operator|==
literal|null
condition|)
block|{
comment|// Could be null because close didn't succeed -- for now consider it fatal
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Close returned empty list of StoreFiles"
argument_list|)
throw|;
block|}
comment|// The following code sets up a thread pool executor with as many slots as
comment|// there's files to split. It then fires up everything, waits for
comment|// completion and finally checks for any exception
name|int
name|nbFiles
init|=
name|hstoreFilesToSplit
operator|.
name|size
argument_list|()
decl_stmt|;
if|if
condition|(
name|nbFiles
operator|==
literal|0
condition|)
block|{
comment|// no file needs to be splitted.
return|return;
block|}
name|ThreadFactoryBuilder
name|builder
init|=
operator|new
name|ThreadFactoryBuilder
argument_list|()
decl_stmt|;
name|builder
operator|.
name|setNameFormat
argument_list|(
literal|"StoreFileSplitter-%1$d"
argument_list|)
expr_stmt|;
name|ThreadFactory
name|factory
init|=
name|builder
operator|.
name|build
argument_list|()
decl_stmt|;
name|ThreadPoolExecutor
name|threadPool
init|=
operator|(
name|ThreadPoolExecutor
operator|)
name|Executors
operator|.
name|newFixedThreadPool
argument_list|(
name|nbFiles
argument_list|,
name|factory
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|Future
argument_list|<
name|Void
argument_list|>
argument_list|>
name|futures
init|=
operator|new
name|ArrayList
argument_list|<
name|Future
argument_list|<
name|Void
argument_list|>
argument_list|>
argument_list|(
name|nbFiles
argument_list|)
decl_stmt|;
comment|// Split each store file.
for|for
control|(
name|StoreFile
name|sf
range|:
name|hstoreFilesToSplit
control|)
block|{
comment|//splitStoreFile(sf, splitdir);
name|StoreFileSplitter
name|sfs
init|=
operator|new
name|StoreFileSplitter
argument_list|(
name|sf
argument_list|,
name|splitdir
argument_list|)
decl_stmt|;
name|futures
operator|.
name|add
argument_list|(
name|threadPool
operator|.
name|submit
argument_list|(
name|sfs
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|// Shutdown the pool
name|threadPool
operator|.
name|shutdown
argument_list|()
expr_stmt|;
comment|// Wait for all the tasks to finish
try|try
block|{
name|boolean
name|stillRunning
init|=
operator|!
name|threadPool
operator|.
name|awaitTermination
argument_list|(
name|this
operator|.
name|fileSplitTimeout
argument_list|,
name|TimeUnit
operator|.
name|MILLISECONDS
argument_list|)
decl_stmt|;
if|if
condition|(
name|stillRunning
condition|)
block|{
name|threadPool
operator|.
name|shutdownNow
argument_list|()
expr_stmt|;
comment|// wait for the thread to shutdown completely.
while|while
condition|(
operator|!
name|threadPool
operator|.
name|isTerminated
argument_list|()
condition|)
block|{
name|Thread
operator|.
name|sleep
argument_list|(
literal|50
argument_list|)
expr_stmt|;
block|}
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Took too long to split the"
operator|+
literal|" files and create the references, aborting split"
argument_list|)
throw|;
block|}
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|interrupt
argument_list|()
expr_stmt|;
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Interrupted while waiting for file splitters"
argument_list|,
name|e
argument_list|)
throw|;
block|}
comment|// Look for any exception
for|for
control|(
name|Future
argument_list|<
name|Void
argument_list|>
name|future
range|:
name|futures
control|)
block|{
try|try
block|{
name|future
operator|.
name|get
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|interrupt
argument_list|()
expr_stmt|;
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Interrupted while trying to get the results of file splitters"
argument_list|,
name|e
argument_list|)
throw|;
block|}
catch|catch
parameter_list|(
name|ExecutionException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
block|}
specifier|private
name|void
name|splitStoreFile
parameter_list|(
specifier|final
name|StoreFile
name|sf
parameter_list|,
specifier|final
name|Path
name|splitdir
parameter_list|)
throws|throws
name|IOException
block|{
name|FileSystem
name|fs
init|=
name|this
operator|.
name|parent
operator|.
name|getFilesystem
argument_list|()
decl_stmt|;
name|byte
index|[]
name|family
init|=
name|sf
operator|.
name|getFamily
argument_list|()
decl_stmt|;
name|Path
name|storedir
init|=
name|HStore
operator|.
name|getStoreHomedir
argument_list|(
name|splitdir
argument_list|,
name|this
operator|.
name|hri_a
argument_list|,
name|family
argument_list|)
decl_stmt|;
name|StoreFile
operator|.
name|split
argument_list|(
name|fs
argument_list|,
name|storedir
argument_list|,
name|sf
argument_list|,
name|this
operator|.
name|splitrow
argument_list|,
literal|false
argument_list|)
expr_stmt|;
name|storedir
operator|=
name|HStore
operator|.
name|getStoreHomedir
argument_list|(
name|splitdir
argument_list|,
name|this
operator|.
name|hri_b
argument_list|,
name|family
argument_list|)
expr_stmt|;
name|StoreFile
operator|.
name|split
argument_list|(
name|fs
argument_list|,
name|storedir
argument_list|,
name|sf
argument_list|,
name|this
operator|.
name|splitrow
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
comment|/**    * Utility class used to do the file splitting / reference writing    * in parallel instead of sequentially.    */
class|class
name|StoreFileSplitter
implements|implements
name|Callable
argument_list|<
name|Void
argument_list|>
block|{
specifier|private
specifier|final
name|StoreFile
name|sf
decl_stmt|;
specifier|private
specifier|final
name|Path
name|splitdir
decl_stmt|;
comment|/**      * Constructor that takes what it needs to split      * @param sf which file      * @param splitdir where the splitting is done      */
specifier|public
name|StoreFileSplitter
parameter_list|(
specifier|final
name|StoreFile
name|sf
parameter_list|,
specifier|final
name|Path
name|splitdir
parameter_list|)
block|{
name|this
operator|.
name|sf
operator|=
name|sf
expr_stmt|;
name|this
operator|.
name|splitdir
operator|=
name|splitdir
expr_stmt|;
block|}
specifier|public
name|Void
name|call
parameter_list|()
throws|throws
name|IOException
block|{
name|splitStoreFile
argument_list|(
name|sf
argument_list|,
name|splitdir
argument_list|)
expr_stmt|;
return|return
literal|null
return|;
block|}
block|}
comment|/**    * @param hri Spec. for daughter region to open.    * @param rsServices RegionServerServices this region should use.    * @return Created daughter HRegion.    * @throws IOException    * @see #cleanupDaughterRegion(FileSystem, Path, String)    */
name|HRegion
name|createDaughterRegion
parameter_list|(
specifier|final
name|HRegionInfo
name|hri
parameter_list|)
throws|throws
name|IOException
block|{
comment|// Package private so unit tests have access.
name|Path
name|regionDir
init|=
name|getSplitDirForDaughter
argument_list|(
name|this
operator|.
name|splitdir
argument_list|,
name|hri
argument_list|)
decl_stmt|;
return|return
name|this
operator|.
name|parent
operator|.
name|createDaughterRegion
argument_list|(
name|hri
argument_list|,
name|regionDir
argument_list|)
return|;
block|}
specifier|private
specifier|static
name|void
name|cleanupDaughterRegion
parameter_list|(
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Path
name|tabledir
parameter_list|,
specifier|final
name|String
name|encodedName
parameter_list|)
throws|throws
name|IOException
block|{
name|Path
name|regiondir
init|=
name|HRegion
operator|.
name|getRegionDir
argument_list|(
name|tabledir
argument_list|,
name|encodedName
argument_list|)
decl_stmt|;
comment|// Dir may not preexist.
name|deleteDir
argument_list|(
name|fs
argument_list|,
name|regiondir
argument_list|,
literal|false
argument_list|)
expr_stmt|;
block|}
comment|/*    * Get the daughter directories in the splits dir.  The splits dir is under    * the parent regions' directory.    * @param splitdir    * @param hri    * @return Path to daughter split dir.    * @throws IOException    */
specifier|private
specifier|static
name|Path
name|getSplitDirForDaughter
parameter_list|(
specifier|final
name|Path
name|splitdir
parameter_list|,
specifier|final
name|HRegionInfo
name|hri
parameter_list|)
throws|throws
name|IOException
block|{
return|return
operator|new
name|Path
argument_list|(
name|splitdir
argument_list|,
name|hri
operator|.
name|getEncodedName
argument_list|()
argument_list|)
return|;
block|}
comment|/**    * @param server Hosting server instance (May be null when testing).    * @param services    * @throws IOException If thrown, rollback failed.  Take drastic action.    * @return True if we successfully rolled back, false if we got to the point    * of no return and so now need to abort the server to minimize damage.    */
specifier|public
name|boolean
name|rollback
parameter_list|(
specifier|final
name|Server
name|server
parameter_list|,
specifier|final
name|RegionServerServices
name|services
parameter_list|)
throws|throws
name|IOException
block|{
comment|// Coprocessor callback
if|if
condition|(
name|this
operator|.
name|parent
operator|.
name|getCoprocessorHost
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|this
operator|.
name|parent
operator|.
name|getCoprocessorHost
argument_list|()
operator|.
name|preRollBackSplit
argument_list|()
expr_stmt|;
block|}
name|boolean
name|result
init|=
literal|true
decl_stmt|;
name|FileSystem
name|fs
init|=
name|this
operator|.
name|parent
operator|.
name|getFilesystem
argument_list|()
decl_stmt|;
name|ListIterator
argument_list|<
name|JournalEntry
argument_list|>
name|iterator
init|=
name|this
operator|.
name|journal
operator|.
name|listIterator
argument_list|(
name|this
operator|.
name|journal
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
comment|// Iterate in reverse.
while|while
condition|(
name|iterator
operator|.
name|hasPrevious
argument_list|()
condition|)
block|{
name|JournalEntry
name|je
init|=
name|iterator
operator|.
name|previous
argument_list|()
decl_stmt|;
switch|switch
condition|(
name|je
condition|)
block|{
case|case
name|SET_SPLITTING_IN_ZK
case|:
if|if
condition|(
name|server
operator|!=
literal|null
operator|&&
name|server
operator|.
name|getZooKeeper
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|cleanZK
argument_list|(
name|server
argument_list|,
name|this
operator|.
name|parent
operator|.
name|getRegionInfo
argument_list|()
argument_list|)
expr_stmt|;
block|}
break|break;
case|case
name|CREATE_SPLIT_DIR
case|:
name|this
operator|.
name|parent
operator|.
name|writestate
operator|.
name|writesEnabled
operator|=
literal|true
expr_stmt|;
name|cleanupSplitDir
argument_list|(
name|fs
argument_list|,
name|this
operator|.
name|splitdir
argument_list|)
expr_stmt|;
break|break;
case|case
name|CLOSED_PARENT_REGION
case|:
try|try
block|{
comment|// So, this returns a seqid but if we just closed and then reopened, we
comment|// should be ok. On close, we flushed using sequenceid obtained from
comment|// hosting regionserver so no need to propagate the sequenceid returned
comment|// out of initialize below up into regionserver as we normally do.
comment|// TODO: Verify.
name|this
operator|.
name|parent
operator|.
name|initialize
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Failed rollbacking CLOSED_PARENT_REGION of region "
operator|+
name|this
operator|.
name|parent
operator|.
name|getRegionNameAsString
argument_list|()
argument_list|,
name|e
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|RuntimeException
argument_list|(
name|e
argument_list|)
throw|;
block|}
break|break;
case|case
name|STARTED_REGION_A_CREATION
case|:
name|cleanupDaughterRegion
argument_list|(
name|fs
argument_list|,
name|this
operator|.
name|parent
operator|.
name|getTableDir
argument_list|()
argument_list|,
name|this
operator|.
name|hri_a
operator|.
name|getEncodedName
argument_list|()
argument_list|)
expr_stmt|;
break|break;
case|case
name|STARTED_REGION_B_CREATION
case|:
name|cleanupDaughterRegion
argument_list|(
name|fs
argument_list|,
name|this
operator|.
name|parent
operator|.
name|getTableDir
argument_list|()
argument_list|,
name|this
operator|.
name|hri_b
operator|.
name|getEncodedName
argument_list|()
argument_list|)
expr_stmt|;
break|break;
case|case
name|OFFLINED_PARENT
case|:
if|if
condition|(
name|services
operator|!=
literal|null
condition|)
name|services
operator|.
name|addToOnlineRegions
argument_list|(
name|this
operator|.
name|parent
argument_list|)
expr_stmt|;
break|break;
case|case
name|PONR
case|:
comment|// We got to the point-of-no-return so we need to just abort. Return
comment|// immediately.  Do not clean up created daughter regions.  They need
comment|// to be in place so we don't delete the parent region mistakenly.
comment|// See HBASE-3872.
return|return
literal|false
return|;
default|default:
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"Unhandled journal entry: "
operator|+
name|je
argument_list|)
throw|;
block|}
block|}
comment|// Coprocessor callback
if|if
condition|(
name|this
operator|.
name|parent
operator|.
name|getCoprocessorHost
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|this
operator|.
name|parent
operator|.
name|getCoprocessorHost
argument_list|()
operator|.
name|postRollBackSplit
argument_list|()
expr_stmt|;
block|}
return|return
name|result
return|;
block|}
name|HRegionInfo
name|getFirstDaughter
parameter_list|()
block|{
return|return
name|hri_a
return|;
block|}
name|HRegionInfo
name|getSecondDaughter
parameter_list|()
block|{
return|return
name|hri_b
return|;
block|}
comment|// For unit testing.
name|Path
name|getSplitDir
parameter_list|()
block|{
return|return
name|this
operator|.
name|splitdir
return|;
block|}
comment|/**    * Clean up any split detritus that may have been left around from previous    * split attempts.    * Call this method on initial region deploy.  Cleans up any mess    * left by previous deploys of passed<code>r</code> region.    * @param r    * @throws IOException    */
specifier|static
name|void
name|cleanupAnySplitDetritus
parameter_list|(
specifier|final
name|HRegion
name|r
parameter_list|)
throws|throws
name|IOException
block|{
name|Path
name|splitdir
init|=
name|getSplitDir
argument_list|(
name|r
argument_list|)
decl_stmt|;
name|FileSystem
name|fs
init|=
name|r
operator|.
name|getFilesystem
argument_list|()
decl_stmt|;
if|if
condition|(
operator|!
name|fs
operator|.
name|exists
argument_list|(
name|splitdir
argument_list|)
condition|)
return|return;
comment|// Look at the splitdir.  It could have the encoded names of the daughter
comment|// regions we tried to make.  See if the daughter regions actually got made
comment|// out under the tabledir.  If here under splitdir still, then the split did
comment|// not complete.  Try and do cleanup.  This code WILL NOT catch the case
comment|// where we successfully created daughter a but regionserver crashed during
comment|// the creation of region b.  In this case, there'll be an orphan daughter
comment|// dir in the filesystem.  TOOD: Fix.
name|FileStatus
index|[]
name|daughters
init|=
name|fs
operator|.
name|listStatus
argument_list|(
name|splitdir
argument_list|,
operator|new
name|FSUtils
operator|.
name|DirFilter
argument_list|(
name|fs
argument_list|)
argument_list|)
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|daughters
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|cleanupDaughterRegion
argument_list|(
name|fs
argument_list|,
name|r
operator|.
name|getTableDir
argument_list|()
argument_list|,
name|daughters
index|[
name|i
index|]
operator|.
name|getPath
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|cleanupSplitDir
argument_list|(
name|r
operator|.
name|getFilesystem
argument_list|()
argument_list|,
name|splitdir
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Cleaned up old failed split transaction detritus: "
operator|+
name|splitdir
argument_list|)
expr_stmt|;
block|}
specifier|private
specifier|static
name|void
name|cleanZK
parameter_list|(
specifier|final
name|Server
name|server
parameter_list|,
specifier|final
name|HRegionInfo
name|hri
parameter_list|)
block|{
try|try
block|{
comment|// Only delete if its in expected state; could have been hijacked.
name|ZKAssign
operator|.
name|deleteNode
argument_list|(
name|server
operator|.
name|getZooKeeper
argument_list|()
argument_list|,
name|hri
operator|.
name|getEncodedName
argument_list|()
argument_list|,
name|EventType
operator|.
name|RS_ZK_REGION_SPLITTING
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|KeeperException
name|e
parameter_list|)
block|{
name|server
operator|.
name|abort
argument_list|(
literal|"Failed cleanup of "
operator|+
name|hri
operator|.
name|getRegionNameAsString
argument_list|()
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Creates a new ephemeral node in the SPLITTING state for the specified region.    * Create it ephemeral in case regionserver dies mid-split.    *    *<p>Does not transition nodes from other states.  If a node already exists    * for this region, a {@link NodeExistsException} will be thrown.    *    * @param zkw zk reference    * @param region region to be created as offline    * @param serverName server event originates from    * @return Version of znode created.    * @throws KeeperException    * @throws IOException    */
name|int
name|createNodeSplitting
parameter_list|(
specifier|final
name|ZooKeeperWatcher
name|zkw
parameter_list|,
specifier|final
name|HRegionInfo
name|region
parameter_list|,
specifier|final
name|ServerName
name|serverName
parameter_list|)
throws|throws
name|KeeperException
throws|,
name|IOException
block|{
name|LOG
operator|.
name|debug
argument_list|(
name|zkw
operator|.
name|prefix
argument_list|(
literal|"Creating ephemeral node for "
operator|+
name|region
operator|.
name|getEncodedName
argument_list|()
operator|+
literal|" in SPLITTING state"
argument_list|)
argument_list|)
expr_stmt|;
name|RegionTransition
name|rt
init|=
name|RegionTransition
operator|.
name|createRegionTransition
argument_list|(
name|EventType
operator|.
name|RS_ZK_REGION_SPLITTING
argument_list|,
name|region
operator|.
name|getRegionName
argument_list|()
argument_list|,
name|serverName
argument_list|)
decl_stmt|;
name|String
name|node
init|=
name|ZKAssign
operator|.
name|getNodeName
argument_list|(
name|zkw
argument_list|,
name|region
operator|.
name|getEncodedName
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|ZKUtil
operator|.
name|createEphemeralNodeAndWatch
argument_list|(
name|zkw
argument_list|,
name|node
argument_list|,
name|rt
operator|.
name|toByteArray
argument_list|()
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Failed create of ephemeral "
operator|+
name|node
argument_list|)
throw|;
block|}
comment|// Transition node from SPLITTING to SPLITTING and pick up version so we
comment|// can be sure this znode is ours; version is needed deleting.
return|return
name|transitionNodeSplitting
argument_list|(
name|zkw
argument_list|,
name|region
argument_list|,
name|serverName
argument_list|,
operator|-
literal|1
argument_list|)
return|;
block|}
comment|/**    * Transitions an existing node for the specified region which is    * currently in the SPLITTING state to be in the SPLIT state.  Converts the    * ephemeral SPLITTING znode to an ephemeral SPLIT node.  Master cleans up    * SPLIT znode when it reads it (or if we crash, zk will clean it up).    *    *<p>Does not transition nodes from other states.  If for some reason the    * node could not be transitioned, the method returns -1.  If the transition    * is successful, the version of the node after transition is returned.    *    *<p>This method can fail and return false for three different reasons:    *<ul><li>Node for this region does not exist</li>    *<li>Node for this region is not in SPLITTING state</li>    *<li>After verifying SPLITTING state, update fails because of wrong version    * (this should never actually happen since an RS only does this transition    * following a transition to SPLITTING.  if two RS are conflicting, one would    * fail the original transition to SPLITTING and not this transition)</li>    *</ul>    *    *<p>Does not set any watches.    *    *<p>This method should only be used by a RegionServer when completing the    * open of a region.    *    * @param zkw zk reference    * @param parent region to be transitioned to opened    * @param a Daughter a of split    * @param b Daughter b of split    * @param serverName server event originates from    * @return version of node after transition, -1 if unsuccessful transition    * @throws KeeperException if unexpected zookeeper exception    * @throws IOException    */
specifier|private
specifier|static
name|int
name|transitionNodeSplit
parameter_list|(
name|ZooKeeperWatcher
name|zkw
parameter_list|,
name|HRegionInfo
name|parent
parameter_list|,
name|HRegionInfo
name|a
parameter_list|,
name|HRegionInfo
name|b
parameter_list|,
name|ServerName
name|serverName
parameter_list|,
specifier|final
name|int
name|znodeVersion
parameter_list|)
throws|throws
name|KeeperException
throws|,
name|IOException
block|{
name|byte
index|[]
name|payload
init|=
name|HRegionInfo
operator|.
name|toDelimitedByteArray
argument_list|(
name|a
argument_list|,
name|b
argument_list|)
decl_stmt|;
return|return
name|ZKAssign
operator|.
name|transitionNode
argument_list|(
name|zkw
argument_list|,
name|parent
argument_list|,
name|serverName
argument_list|,
name|EventType
operator|.
name|RS_ZK_REGION_SPLITTING
argument_list|,
name|EventType
operator|.
name|RS_ZK_REGION_SPLIT
argument_list|,
name|znodeVersion
argument_list|,
name|payload
argument_list|)
return|;
block|}
comment|/**    *    * @param zkw zk reference    * @param parent region to be transitioned to splitting    * @param serverName server event originates from    * @param version znode version    * @return version of node after transition, -1 if unsuccessful transition    * @throws KeeperException    * @throws IOException    */
name|int
name|transitionNodeSplitting
parameter_list|(
specifier|final
name|ZooKeeperWatcher
name|zkw
parameter_list|,
specifier|final
name|HRegionInfo
name|parent
parameter_list|,
specifier|final
name|ServerName
name|serverName
parameter_list|,
specifier|final
name|int
name|version
parameter_list|)
throws|throws
name|KeeperException
throws|,
name|IOException
block|{
return|return
name|ZKAssign
operator|.
name|transitionNode
argument_list|(
name|zkw
argument_list|,
name|parent
argument_list|,
name|serverName
argument_list|,
name|EventType
operator|.
name|RS_ZK_REGION_SPLITTING
argument_list|,
name|EventType
operator|.
name|RS_ZK_REGION_SPLITTING
argument_list|,
name|version
argument_list|)
return|;
block|}
specifier|private
specifier|static
name|int
name|tickleNodeSplit
parameter_list|(
name|ZooKeeperWatcher
name|zkw
parameter_list|,
name|HRegionInfo
name|parent
parameter_list|,
name|HRegionInfo
name|a
parameter_list|,
name|HRegionInfo
name|b
parameter_list|,
name|ServerName
name|serverName
parameter_list|,
specifier|final
name|int
name|znodeVersion
parameter_list|)
throws|throws
name|KeeperException
throws|,
name|IOException
block|{
name|byte
index|[]
name|payload
init|=
name|HRegionInfo
operator|.
name|toDelimitedByteArray
argument_list|(
name|a
argument_list|,
name|b
argument_list|)
decl_stmt|;
return|return
name|ZKAssign
operator|.
name|transitionNode
argument_list|(
name|zkw
argument_list|,
name|parent
argument_list|,
name|serverName
argument_list|,
name|EventType
operator|.
name|RS_ZK_REGION_SPLIT
argument_list|,
name|EventType
operator|.
name|RS_ZK_REGION_SPLIT
argument_list|,
name|znodeVersion
argument_list|,
name|payload
argument_list|)
return|;
block|}
block|}
end_class

end_unit

