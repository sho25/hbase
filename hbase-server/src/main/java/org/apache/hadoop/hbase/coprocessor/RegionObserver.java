begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/*  *  * Licensed under the Apache License, Version 2.0 (the "License");  * you may not use this file except in compliance with the License.  * You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|coprocessor
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|NavigableSet
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|classification
operator|.
name|InterfaceAudience
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|classification
operator|.
name|InterfaceStability
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|Cell
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|Coprocessor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HBaseInterfaceAudience
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HRegionInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|KeyValue
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|Append
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|Delete
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|Durability
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|Get
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|Increment
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|Mutation
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|Put
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|Result
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|Scan
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|filter
operator|.
name|ByteArrayComparable
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|filter
operator|.
name|CompareFilter
operator|.
name|CompareOp
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|FSDataInputStreamWrapper
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|Reference
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|hfile
operator|.
name|CacheConfig
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|DeleteTracker
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|HRegion
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|HRegion
operator|.
name|Operation
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|InternalScanner
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|KeyValueScanner
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|MiniBatchOperationInProgress
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|OperationStatus
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|RegionScanner
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|ScanType
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|Store
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|StoreFile
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|StoreFileScanner
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|compactions
operator|.
name|CompactionRequest
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|wal
operator|.
name|HLogKey
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|wal
operator|.
name|WALKey
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|wal
operator|.
name|WALEdit
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|Pair
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|ImmutableList
import|;
end_import

begin_comment
comment|/**  * Coprocessors implement this interface to observe and mediate client actions  * on the region.  */
end_comment

begin_interface
annotation|@
name|InterfaceAudience
operator|.
name|LimitedPrivate
argument_list|(
name|HBaseInterfaceAudience
operator|.
name|COPROC
argument_list|)
annotation|@
name|InterfaceStability
operator|.
name|Evolving
comment|// TODO as method signatures need to break, update to
comment|// ObserverContext<? extends RegionCoprocessorEnvironment>
comment|// so we can use additional environment state that isn't exposed to coprocessors.
specifier|public
interface|interface
name|RegionObserver
extends|extends
name|Coprocessor
block|{
comment|/** Mutation type for postMutationBeforeWAL hook */
specifier|public
enum|enum
name|MutationType
block|{
name|APPEND
block|,
name|INCREMENT
block|}
comment|/**    * Called before the region is reported as open to the master.    * @param c the environment provided by the region server    * @throws IOException if an error occurred on the coprocessor    */
name|void
name|preOpen
parameter_list|(
specifier|final
name|ObserverContext
argument_list|<
name|RegionCoprocessorEnvironment
argument_list|>
name|c
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Called after the region is reported as open to the master.    * @param c the environment provided by the region server    */
name|void
name|postOpen
parameter_list|(
specifier|final
name|ObserverContext
argument_list|<
name|RegionCoprocessorEnvironment
argument_list|>
name|c
parameter_list|)
function_decl|;
comment|/**    * Called after the log replay on the region is over.    * @param c the environment provided by the region server    */
name|void
name|postLogReplay
parameter_list|(
specifier|final
name|ObserverContext
argument_list|<
name|RegionCoprocessorEnvironment
argument_list|>
name|c
parameter_list|)
function_decl|;
comment|/**    * Called before a memstore is flushed to disk and prior to creating the scanner to read from    * the memstore.  To override or modify how a memstore is flushed,    * implementing classes can return a new scanner to provide the KeyValues to be    * stored into the new {@code StoreFile} or null to perform the default processing.    * Calling {@link org.apache.hadoop.hbase.coprocessor.ObserverContext#bypass()} has no    * effect in this hook.    * @param c the environment provided by the region server    * @param store the store being flushed    * @param memstoreScanner the scanner for the memstore that is flushed    * @param s the base scanner, if not {@code null}, from previous RegionObserver in the chain    * @return the scanner to use during the flush.  {@code null} if the default implementation    * is to be used.    * @throws IOException if an error occurred on the coprocessor    */
name|InternalScanner
name|preFlushScannerOpen
parameter_list|(
specifier|final
name|ObserverContext
argument_list|<
name|RegionCoprocessorEnvironment
argument_list|>
name|c
parameter_list|,
specifier|final
name|Store
name|store
parameter_list|,
specifier|final
name|KeyValueScanner
name|memstoreScanner
parameter_list|,
specifier|final
name|InternalScanner
name|s
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Called before the memstore is flushed to disk.    * @param c the environment provided by the region server    * @throws IOException if an error occurred on the coprocessor    * @deprecated use {@link #preFlush(ObserverContext, Store, InternalScanner)} instead    */
annotation|@
name|Deprecated
name|void
name|preFlush
parameter_list|(
specifier|final
name|ObserverContext
argument_list|<
name|RegionCoprocessorEnvironment
argument_list|>
name|c
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Called before a Store's memstore is flushed to disk.    * @param c the environment provided by the region server    * @param store the store where compaction is being requested    * @param scanner the scanner over existing data used in the store file    * @return the scanner to use during compaction.  Should not be {@code null}    * unless the implementation is writing new store files on its own.    * @throws IOException if an error occurred on the coprocessor    */
name|InternalScanner
name|preFlush
parameter_list|(
specifier|final
name|ObserverContext
argument_list|<
name|RegionCoprocessorEnvironment
argument_list|>
name|c
parameter_list|,
specifier|final
name|Store
name|store
parameter_list|,
specifier|final
name|InternalScanner
name|scanner
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Called after the memstore is flushed to disk.    * @param c the environment provided by the region server    * @throws IOException if an error occurred on the coprocessor    * @deprecated use {@link #preFlush(ObserverContext, Store, InternalScanner)} instead.    */
annotation|@
name|Deprecated
name|void
name|postFlush
parameter_list|(
specifier|final
name|ObserverContext
argument_list|<
name|RegionCoprocessorEnvironment
argument_list|>
name|c
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Called after a Store's memstore is flushed to disk.    * @param c the environment provided by the region server    * @param store the store being flushed    * @param resultFile the new store file written out during compaction    * @throws IOException if an error occurred on the coprocessor    */
name|void
name|postFlush
parameter_list|(
specifier|final
name|ObserverContext
argument_list|<
name|RegionCoprocessorEnvironment
argument_list|>
name|c
parameter_list|,
specifier|final
name|Store
name|store
parameter_list|,
specifier|final
name|StoreFile
name|resultFile
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Called prior to selecting the {@link StoreFile StoreFiles} to compact from the list of    * available candidates. To alter the files used for compaction, you may mutate the passed in list    * of candidates.    * @param c the environment provided by the region server    * @param store the store where compaction is being requested    * @param candidates the store files currently available for compaction    * @param request custom compaction request    * @throws IOException if an error occurred on the coprocessor    */
name|void
name|preCompactSelection
parameter_list|(
specifier|final
name|ObserverContext
argument_list|<
name|RegionCoprocessorEnvironment
argument_list|>
name|c
parameter_list|,
specifier|final
name|Store
name|store
parameter_list|,
specifier|final
name|List
argument_list|<
name|StoreFile
argument_list|>
name|candidates
parameter_list|,
specifier|final
name|CompactionRequest
name|request
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Called prior to selecting the {@link StoreFile}s to compact from the list of available    * candidates. To alter the files used for compaction, you may mutate the passed in list of    * candidates.    * @param c the environment provided by the region server    * @param store the store where compaction is being requested    * @param candidates the store files currently available for compaction    * @throws IOException if an error occurred on the coprocessor    * @deprecated Use {@link #preCompactSelection(ObserverContext, Store, List, CompactionRequest)}    *             instead    */
annotation|@
name|Deprecated
name|void
name|preCompactSelection
parameter_list|(
specifier|final
name|ObserverContext
argument_list|<
name|RegionCoprocessorEnvironment
argument_list|>
name|c
parameter_list|,
specifier|final
name|Store
name|store
parameter_list|,
specifier|final
name|List
argument_list|<
name|StoreFile
argument_list|>
name|candidates
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Called after the {@link StoreFile}s to compact have been selected from the available    * candidates.    * @param c the environment provided by the region server    * @param store the store being compacted    * @param selected the store files selected to compact    * @param request custom compaction request    */
name|void
name|postCompactSelection
parameter_list|(
specifier|final
name|ObserverContext
argument_list|<
name|RegionCoprocessorEnvironment
argument_list|>
name|c
parameter_list|,
specifier|final
name|Store
name|store
parameter_list|,
specifier|final
name|ImmutableList
argument_list|<
name|StoreFile
argument_list|>
name|selected
parameter_list|,
name|CompactionRequest
name|request
parameter_list|)
function_decl|;
comment|/**    * Called after the {@link StoreFile}s to compact have been selected from the available    * candidates.    * @param c the environment provided by the region server    * @param store the store being compacted    * @param selected the store files selected to compact    * @deprecated use {@link #postCompactSelection(ObserverContext, Store, ImmutableList,    *             CompactionRequest)} instead.    */
annotation|@
name|Deprecated
name|void
name|postCompactSelection
parameter_list|(
specifier|final
name|ObserverContext
argument_list|<
name|RegionCoprocessorEnvironment
argument_list|>
name|c
parameter_list|,
specifier|final
name|Store
name|store
parameter_list|,
specifier|final
name|ImmutableList
argument_list|<
name|StoreFile
argument_list|>
name|selected
parameter_list|)
function_decl|;
comment|/**    * Called prior to writing the {@link StoreFile}s selected for compaction into a new    * {@code StoreFile}. To override or modify the compaction process, implementing classes have two    * options:    *<ul>    *<li>Wrap the provided {@link InternalScanner} with a custom implementation that is returned    * from this method. The custom scanner can then inspect {@link KeyValue}s from the wrapped    * scanner, applying its own policy to what gets written.</li>    *<li>Call {@link org.apache.hadoop.hbase.coprocessor.ObserverContext#bypass()} and provide a    * custom implementation for writing of new {@link StoreFile}s.<strong>Note: any implementations    * bypassing core compaction using this approach must write out new store files themselves or the    * existing data will no longer be available after compaction.</strong></li>    *</ul>    * @param c the environment provided by the region server    * @param store the store being compacted    * @param scanner the scanner over existing data used in the store file rewriting    * @param scanType type of Scan    * @param request the requested compaction    * @return the scanner to use during compaction. Should not be {@code null} unless the    *         implementation is writing new store files on its own.    * @throws IOException if an error occurred on the coprocessor    */
name|InternalScanner
name|preCompact
parameter_list|(
specifier|final
name|ObserverContext
argument_list|<
name|RegionCoprocessorEnvironment
argument_list|>
name|c
parameter_list|,
specifier|final
name|Store
name|store
parameter_list|,
specifier|final
name|InternalScanner
name|scanner
parameter_list|,
specifier|final
name|ScanType
name|scanType
parameter_list|,
name|CompactionRequest
name|request
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Called prior to writing the {@link StoreFile}s selected for compaction into a new    * {@code StoreFile}. To override or modify the compaction process, implementing classes have two    * options:    *<ul>    *<li>Wrap the provided {@link InternalScanner} with a custom implementation that is returned    * from this method. The custom scanner can then inspect {@link KeyValue}s from the wrapped    * scanner, applying its own policy to what gets written.</li>    *<li>Call {@link org.apache.hadoop.hbase.coprocessor.ObserverContext#bypass()} and provide a    * custom implementation for writing of new {@link StoreFile}s.<strong>Note: any implementations    * bypassing core compaction using this approach must write out new store files themselves or the    * existing data will no longer be available after compaction.</strong></li>    *</ul>    * @param c the environment provided by the region server    * @param store the store being compacted    * @param scanner the scanner over existing data used in the store file rewriting    * @param scanType type of Scan    * @return the scanner to use during compaction. Should not be {@code null} unless the    *         implementation is writing new store files on its own.    * @throws IOException if an error occurred on the coprocessor    * @deprecated use    *             {@link #preCompact(ObserverContext, Store, InternalScanner,    *             ScanType, CompactionRequest)} instead    */
annotation|@
name|Deprecated
name|InternalScanner
name|preCompact
parameter_list|(
specifier|final
name|ObserverContext
argument_list|<
name|RegionCoprocessorEnvironment
argument_list|>
name|c
parameter_list|,
specifier|final
name|Store
name|store
parameter_list|,
specifier|final
name|InternalScanner
name|scanner
parameter_list|,
specifier|final
name|ScanType
name|scanType
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Called prior to writing the {@link StoreFile}s selected for compaction into a new    * {@code StoreFile} and prior to creating the scanner used to read the input files. To override    * or modify the compaction process, implementing classes can return a new scanner to provide the    * KeyValues to be stored into the new {@code StoreFile} or null to perform the default    * processing. Calling {@link org.apache.hadoop.hbase.coprocessor.ObserverContext#bypass()} has no    * effect in this hook.    * @param c the environment provided by the region server    * @param store the store being compacted    * @param scanners the list {@link StoreFileScanner}s to be read from    * @param scanType the {@link ScanType} indicating whether this is a major or minor compaction    * @param earliestPutTs timestamp of the earliest put that was found in any of the involved store    *          files    * @param s the base scanner, if not {@code null}, from previous RegionObserver in the chain    * @param request the requested compaction    * @return the scanner to use during compaction. {@code null} if the default implementation is to    *         be used.    * @throws IOException if an error occurred on the coprocessor    */
name|InternalScanner
name|preCompactScannerOpen
parameter_list|(
specifier|final
name|ObserverContext
argument_list|<
name|RegionCoprocessorEnvironment
argument_list|>
name|c
parameter_list|,
specifier|final
name|Store
name|store
parameter_list|,
name|List
argument_list|<
name|?
extends|extends
name|KeyValueScanner
argument_list|>
name|scanners
parameter_list|,
specifier|final
name|ScanType
name|scanType
parameter_list|,
specifier|final
name|long
name|earliestPutTs
parameter_list|,
specifier|final
name|InternalScanner
name|s
parameter_list|,
name|CompactionRequest
name|request
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Called prior to writing the {@link StoreFile}s selected for compaction into a new    * {@code StoreFile} and prior to creating the scanner used to read the input files. To override    * or modify the compaction process, implementing classes can return a new scanner to provide the    * KeyValues to be stored into the new {@code StoreFile} or null to perform the default    * processing. Calling {@link org.apache.hadoop.hbase.coprocessor.ObserverContext#bypass()} has no    * effect in this hook.    * @param c the environment provided by the region server    * @param store the store being compacted    * @param scanners the list {@link StoreFileScanner}s to be read from    * @param scanType the {@link ScanType} indicating whether this is a major or minor compaction    * @param earliestPutTs timestamp of the earliest put that was found in any of the involved store    *          files    * @param s the base scanner, if not {@code null}, from previous RegionObserver in the chain    * @return the scanner to use during compaction. {@code null} if the default implementation is to    *         be used.    * @throws IOException if an error occurred on the coprocessor    * @deprecated Use    *             {@link #preCompactScannerOpen(ObserverContext, Store, List, ScanType, long,    *             InternalScanner, CompactionRequest)} instead.    */
annotation|@
name|Deprecated
name|InternalScanner
name|preCompactScannerOpen
parameter_list|(
specifier|final
name|ObserverContext
argument_list|<
name|RegionCoprocessorEnvironment
argument_list|>
name|c
parameter_list|,
specifier|final
name|Store
name|store
parameter_list|,
name|List
argument_list|<
name|?
extends|extends
name|KeyValueScanner
argument_list|>
name|scanners
parameter_list|,
specifier|final
name|ScanType
name|scanType
parameter_list|,
specifier|final
name|long
name|earliestPutTs
parameter_list|,
specifier|final
name|InternalScanner
name|s
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Called after compaction has completed and the new store file has been moved in to place.    * @param c the environment provided by the region server    * @param store the store being compacted    * @param resultFile the new store file written out during compaction    * @param request the requested compaction    * @throws IOException if an error occurred on the coprocessor    */
name|void
name|postCompact
parameter_list|(
specifier|final
name|ObserverContext
argument_list|<
name|RegionCoprocessorEnvironment
argument_list|>
name|c
parameter_list|,
specifier|final
name|Store
name|store
parameter_list|,
name|StoreFile
name|resultFile
parameter_list|,
name|CompactionRequest
name|request
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Called after compaction has completed and the new store file has been moved in to place.    * @param c the environment provided by the region server    * @param store the store being compacted    * @param resultFile the new store file written out during compaction    * @throws IOException if an error occurred on the coprocessor    * @deprecated Use {@link #postCompact(ObserverContext, Store, StoreFile, CompactionRequest)}    *             instead    */
annotation|@
name|Deprecated
name|void
name|postCompact
parameter_list|(
specifier|final
name|ObserverContext
argument_list|<
name|RegionCoprocessorEnvironment
argument_list|>
name|c
parameter_list|,
specifier|final
name|Store
name|store
parameter_list|,
name|StoreFile
name|resultFile
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Called before the region is split.    * @param c the environment provided by the region server    * (e.getRegion() returns the parent region)    * @throws IOException if an error occurred on the coprocessor    * @deprecated Use preSplit(    *    final ObserverContext<RegionCoprocessorEnvironment> c, byte[] splitRow)    */
annotation|@
name|Deprecated
name|void
name|preSplit
parameter_list|(
specifier|final
name|ObserverContext
argument_list|<
name|RegionCoprocessorEnvironment
argument_list|>
name|c
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Called before the region is split.    * @param c the environment provided by the region server    * (e.getRegion() returns the parent region)    * @throws IOException if an error occurred on the coprocessor    */
name|void
name|preSplit
parameter_list|(
specifier|final
name|ObserverContext
argument_list|<
name|RegionCoprocessorEnvironment
argument_list|>
name|c
parameter_list|,
name|byte
index|[]
name|splitRow
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Called after the region is split.    * @param c the environment provided by the region server    * (e.getRegion() returns the parent region)    * @param l the left daughter region    * @param r the right daughter region    * @throws IOException if an error occurred on the coprocessor    * @deprecated Use postCompleteSplit() instead    */
annotation|@
name|Deprecated
name|void
name|postSplit
parameter_list|(
specifier|final
name|ObserverContext
argument_list|<
name|RegionCoprocessorEnvironment
argument_list|>
name|c
parameter_list|,
specifier|final
name|HRegion
name|l
parameter_list|,
specifier|final
name|HRegion
name|r
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * This will be called before PONR step as part of split transaction. Calling    * {@link org.apache.hadoop.hbase.coprocessor.ObserverContext#bypass()} rollback the split    * @param ctx    * @param splitKey    * @param metaEntries    * @throws IOException    */
name|void
name|preSplitBeforePONR
parameter_list|(
specifier|final
name|ObserverContext
argument_list|<
name|RegionCoprocessorEnvironment
argument_list|>
name|ctx
parameter_list|,
name|byte
index|[]
name|splitKey
parameter_list|,
name|List
argument_list|<
name|Mutation
argument_list|>
name|metaEntries
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * This will be called after PONR step as part of split transaction    * Calling {@link org.apache.hadoop.hbase.coprocessor.ObserverContext#bypass()} has no    * effect in this hook.    * @param ctx    * @throws IOException    */
name|void
name|preSplitAfterPONR
parameter_list|(
specifier|final
name|ObserverContext
argument_list|<
name|RegionCoprocessorEnvironment
argument_list|>
name|ctx
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * This will be called before the roll back of the split region is completed     * @param ctx    * @throws IOException    */
name|void
name|preRollBackSplit
parameter_list|(
specifier|final
name|ObserverContext
argument_list|<
name|RegionCoprocessorEnvironment
argument_list|>
name|ctx
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * This will be called after the roll back of the split region is completed    * @param ctx    * @throws IOException    */
name|void
name|postRollBackSplit
parameter_list|(
specifier|final
name|ObserverContext
argument_list|<
name|RegionCoprocessorEnvironment
argument_list|>
name|ctx
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Called after any split request is processed.  This will be called irrespective of success or    * failure of the split.    * @param ctx    * @throws IOException    */
name|void
name|postCompleteSplit
parameter_list|(
specifier|final
name|ObserverContext
argument_list|<
name|RegionCoprocessorEnvironment
argument_list|>
name|ctx
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Called before the region is reported as closed to the master.    * @param c the environment provided by the region server    * @param abortRequested true if the region server is aborting    * @throws IOException     */
name|void
name|preClose
parameter_list|(
specifier|final
name|ObserverContext
argument_list|<
name|RegionCoprocessorEnvironment
argument_list|>
name|c
parameter_list|,
name|boolean
name|abortRequested
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Called after the region is reported as closed to the master.    * @param c the environment provided by the region server    * @param abortRequested true if the region server is aborting    */
name|void
name|postClose
parameter_list|(
specifier|final
name|ObserverContext
argument_list|<
name|RegionCoprocessorEnvironment
argument_list|>
name|c
parameter_list|,
name|boolean
name|abortRequested
parameter_list|)
function_decl|;
comment|/**    * Called before a client makes a GetClosestRowBefore request.    *<p>    * Call CoprocessorEnvironment#bypass to skip default actions    *<p>    * Call CoprocessorEnvironment#complete to skip any subsequent chained    * coprocessors    * @param c the environment provided by the region server    * @param row the row    * @param family the family    * @param result The result to return to the client if default processing    * is bypassed. Can be modified. Will not be used if default processing    * is not bypassed.    * @throws IOException if an error occurred on the coprocessor    */
name|void
name|preGetClosestRowBefore
parameter_list|(
specifier|final
name|ObserverContext
argument_list|<
name|RegionCoprocessorEnvironment
argument_list|>
name|c
parameter_list|,
specifier|final
name|byte
index|[]
name|row
parameter_list|,
specifier|final
name|byte
index|[]
name|family
parameter_list|,
specifier|final
name|Result
name|result
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Called after a client makes a GetClosestRowBefore request.    *<p>    * Call CoprocessorEnvironment#complete to skip any subsequent chained    * coprocessors    * @param c the environment provided by the region server    * @param row the row    * @param family the desired family    * @param result the result to return to the client, modify as necessary    * @throws IOException if an error occurred on the coprocessor    */
name|void
name|postGetClosestRowBefore
parameter_list|(
specifier|final
name|ObserverContext
argument_list|<
name|RegionCoprocessorEnvironment
argument_list|>
name|c
parameter_list|,
specifier|final
name|byte
index|[]
name|row
parameter_list|,
specifier|final
name|byte
index|[]
name|family
parameter_list|,
specifier|final
name|Result
name|result
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Called before the client performs a Get    *<p>    * Call CoprocessorEnvironment#bypass to skip default actions    *<p>    * Call CoprocessorEnvironment#complete to skip any subsequent chained    * coprocessors    * @param c the environment provided by the region server    * @param get the Get request    * @param result The result to return to the client if default processing    * is bypassed. Can be modified. Will not be used if default processing    * is not bypassed.    * @throws IOException if an error occurred on the coprocessor    */
name|void
name|preGetOp
parameter_list|(
specifier|final
name|ObserverContext
argument_list|<
name|RegionCoprocessorEnvironment
argument_list|>
name|c
parameter_list|,
specifier|final
name|Get
name|get
parameter_list|,
specifier|final
name|List
argument_list|<
name|Cell
argument_list|>
name|result
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Called after the client performs a Get    *<p>    * Call CoprocessorEnvironment#complete to skip any subsequent chained    * coprocessors    * @param c the environment provided by the region server    * @param get the Get request    * @param result the result to return to the client, modify as necessary    * @throws IOException if an error occurred on the coprocessor    */
name|void
name|postGetOp
parameter_list|(
specifier|final
name|ObserverContext
argument_list|<
name|RegionCoprocessorEnvironment
argument_list|>
name|c
parameter_list|,
specifier|final
name|Get
name|get
parameter_list|,
specifier|final
name|List
argument_list|<
name|Cell
argument_list|>
name|result
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Called before the client tests for existence using a Get.    *<p>    * Call CoprocessorEnvironment#bypass to skip default actions    *<p>    * Call CoprocessorEnvironment#complete to skip any subsequent chained    * coprocessors    * @param c the environment provided by the region server    * @param get the Get request    * @param exists    * @return the value to return to the client if bypassing default processing    * @throws IOException if an error occurred on the coprocessor    */
name|boolean
name|preExists
parameter_list|(
specifier|final
name|ObserverContext
argument_list|<
name|RegionCoprocessorEnvironment
argument_list|>
name|c
parameter_list|,
specifier|final
name|Get
name|get
parameter_list|,
specifier|final
name|boolean
name|exists
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Called after the client tests for existence using a Get.    *<p>    * Call CoprocessorEnvironment#complete to skip any subsequent chained    * coprocessors    * @param c the environment provided by the region server    * @param get the Get request    * @param exists the result returned by the region server    * @return the result to return to the client    * @throws IOException if an error occurred on the coprocessor    */
name|boolean
name|postExists
parameter_list|(
specifier|final
name|ObserverContext
argument_list|<
name|RegionCoprocessorEnvironment
argument_list|>
name|c
parameter_list|,
specifier|final
name|Get
name|get
parameter_list|,
specifier|final
name|boolean
name|exists
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Called before the client stores a value.    *<p>    * Call CoprocessorEnvironment#bypass to skip default actions    *<p>    * Call CoprocessorEnvironment#complete to skip any subsequent chained    * coprocessors    * @param c the environment provided by the region server    * @param put The Put object    * @param edit The WALEdit object that will be written to the wal    * @param durability Persistence guarantee for this Put    * @throws IOException if an error occurred on the coprocessor    */
name|void
name|prePut
parameter_list|(
specifier|final
name|ObserverContext
argument_list|<
name|RegionCoprocessorEnvironment
argument_list|>
name|c
parameter_list|,
specifier|final
name|Put
name|put
parameter_list|,
specifier|final
name|WALEdit
name|edit
parameter_list|,
specifier|final
name|Durability
name|durability
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Called after the client stores a value.    *<p>    * Call CoprocessorEnvironment#complete to skip any subsequent chained    * coprocessors    * @param c the environment provided by the region server    * @param put The Put object    * @param edit The WALEdit object for the wal    * @param durability Persistence guarantee for this Put    * @throws IOException if an error occurred on the coprocessor    */
name|void
name|postPut
parameter_list|(
specifier|final
name|ObserverContext
argument_list|<
name|RegionCoprocessorEnvironment
argument_list|>
name|c
parameter_list|,
specifier|final
name|Put
name|put
parameter_list|,
specifier|final
name|WALEdit
name|edit
parameter_list|,
specifier|final
name|Durability
name|durability
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Called before the client deletes a value.    *<p>    * Call CoprocessorEnvironment#bypass to skip default actions    *<p>    * Call CoprocessorEnvironment#complete to skip any subsequent chained    * coprocessors    * @param c the environment provided by the region server    * @param delete The Delete object    * @param edit The WALEdit object for the wal    * @param durability Persistence guarantee for this Delete    * @throws IOException if an error occurred on the coprocessor    */
name|void
name|preDelete
parameter_list|(
specifier|final
name|ObserverContext
argument_list|<
name|RegionCoprocessorEnvironment
argument_list|>
name|c
parameter_list|,
specifier|final
name|Delete
name|delete
parameter_list|,
specifier|final
name|WALEdit
name|edit
parameter_list|,
specifier|final
name|Durability
name|durability
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**  * Called before the server updates the timestamp for version delete with latest timestamp.  *<p>  * Call CoprocessorEnvironment#bypass to skip default actions  *<p>  * Call CoprocessorEnvironment#complete to skip any subsequent chained  * coprocessors  * @param c the environment provided by the region server  * @param mutation - the parent mutation associated with this delete cell  * @param cell - The deleteColumn with latest version cell  * @param byteNow - timestamp bytes  * @param get - the get formed using the current cell's row.  * Note that the get does not specify the family and qualifier  * @throws IOException  */
name|void
name|prePrepareTimeStampForDeleteVersion
parameter_list|(
specifier|final
name|ObserverContext
argument_list|<
name|RegionCoprocessorEnvironment
argument_list|>
name|c
parameter_list|,
specifier|final
name|Mutation
name|mutation
parameter_list|,
specifier|final
name|Cell
name|cell
parameter_list|,
specifier|final
name|byte
index|[]
name|byteNow
parameter_list|,
specifier|final
name|Get
name|get
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Called after the client deletes a value.    *<p>    * Call CoprocessorEnvironment#complete to skip any subsequent chained    * coprocessors    * @param c the environment provided by the region server    * @param delete The Delete object    * @param edit The WALEdit object for the wal    * @param durability Persistence guarantee for this Delete    * @throws IOException if an error occurred on the coprocessor    */
name|void
name|postDelete
parameter_list|(
specifier|final
name|ObserverContext
argument_list|<
name|RegionCoprocessorEnvironment
argument_list|>
name|c
parameter_list|,
specifier|final
name|Delete
name|delete
parameter_list|,
specifier|final
name|WALEdit
name|edit
parameter_list|,
specifier|final
name|Durability
name|durability
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * This will be called for every batch mutation operation happening at the server. This will be    * called after acquiring the locks on the mutating rows and after applying the proper timestamp    * for each Mutation at the server. The batch may contain Put/Delete. By setting OperationStatus    * of Mutations ({@link MiniBatchOperationInProgress#setOperationStatus(int, OperationStatus)}),    * {@link RegionObserver} can make HRegion to skip these Mutations.    * @param c the environment provided by the region server    * @param miniBatchOp batch of Mutations getting applied to region.    * @throws IOException if an error occurred on the coprocessor    */
name|void
name|preBatchMutate
parameter_list|(
specifier|final
name|ObserverContext
argument_list|<
name|RegionCoprocessorEnvironment
argument_list|>
name|c
parameter_list|,
specifier|final
name|MiniBatchOperationInProgress
argument_list|<
name|Mutation
argument_list|>
name|miniBatchOp
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * This will be called after applying a batch of Mutations on a region. The Mutations are added to    * memstore and WAL.    * @param c the environment provided by the region server    * @param miniBatchOp batch of Mutations applied to region.    * @throws IOException if an error occurred on the coprocessor    */
name|void
name|postBatchMutate
parameter_list|(
specifier|final
name|ObserverContext
argument_list|<
name|RegionCoprocessorEnvironment
argument_list|>
name|c
parameter_list|,
specifier|final
name|MiniBatchOperationInProgress
argument_list|<
name|Mutation
argument_list|>
name|miniBatchOp
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * This will be called for region operations where read lock is acquired in    * {@link HRegion#startRegionOperation()}.    * @param ctx    * @param operation The operation is about to be taken on the region    * @throws IOException    */
name|void
name|postStartRegionOperation
parameter_list|(
specifier|final
name|ObserverContext
argument_list|<
name|RegionCoprocessorEnvironment
argument_list|>
name|ctx
parameter_list|,
name|Operation
name|operation
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Called after releasing read lock in {@link HRegion#closeRegionOperation(Operation)}.    * @param ctx    * @param operation    * @throws IOException    */
name|void
name|postCloseRegionOperation
parameter_list|(
specifier|final
name|ObserverContext
argument_list|<
name|RegionCoprocessorEnvironment
argument_list|>
name|ctx
parameter_list|,
name|Operation
name|operation
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Called after the completion of batch put/delete and will be called even if the batch operation    * fails    * @param ctx    * @param miniBatchOp     * @param success true if batch operation is successful otherwise false.    * @throws IOException    */
name|void
name|postBatchMutateIndispensably
parameter_list|(
specifier|final
name|ObserverContext
argument_list|<
name|RegionCoprocessorEnvironment
argument_list|>
name|ctx
parameter_list|,
name|MiniBatchOperationInProgress
argument_list|<
name|Mutation
argument_list|>
name|miniBatchOp
parameter_list|,
specifier|final
name|boolean
name|success
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Called before checkAndPut.    *<p>    * Call CoprocessorEnvironment#bypass to skip default actions    *<p>    * Call CoprocessorEnvironment#complete to skip any subsequent chained    * coprocessors    * @param c the environment provided by the region server    * @param row row to check    * @param family column family    * @param qualifier column qualifier    * @param compareOp the comparison operation    * @param comparator the comparator    * @param put data to put if check succeeds    * @param result     * @return the return value to return to client if bypassing default    * processing    * @throws IOException if an error occurred on the coprocessor    */
name|boolean
name|preCheckAndPut
parameter_list|(
specifier|final
name|ObserverContext
argument_list|<
name|RegionCoprocessorEnvironment
argument_list|>
name|c
parameter_list|,
specifier|final
name|byte
index|[]
name|row
parameter_list|,
specifier|final
name|byte
index|[]
name|family
parameter_list|,
specifier|final
name|byte
index|[]
name|qualifier
parameter_list|,
specifier|final
name|CompareOp
name|compareOp
parameter_list|,
specifier|final
name|ByteArrayComparable
name|comparator
parameter_list|,
specifier|final
name|Put
name|put
parameter_list|,
specifier|final
name|boolean
name|result
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Called before checkAndPut but after acquiring rowlock.    *<p>    *<b>Note:</b> Caution to be taken for not doing any long time operation in this hook.     * Row will be locked for longer time. Trying to acquire lock on another row, within this,     * can lead to potential deadlock.    *<p>    * Call CoprocessorEnvironment#bypass to skip default actions    *<p>    * Call CoprocessorEnvironment#complete to skip any subsequent chained    * coprocessors    * @param c the environment provided by the region server    * @param row row to check    * @param family column family    * @param qualifier column qualifier    * @param compareOp the comparison operation    * @param comparator the comparator    * @param put data to put if check succeeds    * @param result     * @return the return value to return to client if bypassing default    * processing    * @throws IOException if an error occurred on the coprocessor    */
name|boolean
name|preCheckAndPutAfterRowLock
parameter_list|(
specifier|final
name|ObserverContext
argument_list|<
name|RegionCoprocessorEnvironment
argument_list|>
name|c
parameter_list|,
specifier|final
name|byte
index|[]
name|row
parameter_list|,
specifier|final
name|byte
index|[]
name|family
parameter_list|,
specifier|final
name|byte
index|[]
name|qualifier
parameter_list|,
specifier|final
name|CompareOp
name|compareOp
parameter_list|,
specifier|final
name|ByteArrayComparable
name|comparator
parameter_list|,
specifier|final
name|Put
name|put
parameter_list|,
specifier|final
name|boolean
name|result
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Called after checkAndPut    *<p>    * Call CoprocessorEnvironment#complete to skip any subsequent chained    * coprocessors    * @param c the environment provided by the region server    * @param row row to check    * @param family column family    * @param qualifier column qualifier    * @param compareOp the comparison operation    * @param comparator the comparator    * @param put data to put if check succeeds    * @param result from the checkAndPut    * @return the possibly transformed return value to return to client    * @throws IOException if an error occurred on the coprocessor    */
name|boolean
name|postCheckAndPut
parameter_list|(
specifier|final
name|ObserverContext
argument_list|<
name|RegionCoprocessorEnvironment
argument_list|>
name|c
parameter_list|,
specifier|final
name|byte
index|[]
name|row
parameter_list|,
specifier|final
name|byte
index|[]
name|family
parameter_list|,
specifier|final
name|byte
index|[]
name|qualifier
parameter_list|,
specifier|final
name|CompareOp
name|compareOp
parameter_list|,
specifier|final
name|ByteArrayComparable
name|comparator
parameter_list|,
specifier|final
name|Put
name|put
parameter_list|,
specifier|final
name|boolean
name|result
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Called before checkAndDelete.    *<p>    * Call CoprocessorEnvironment#bypass to skip default actions    *<p>    * Call CoprocessorEnvironment#complete to skip any subsequent chained    * coprocessors    * @param c the environment provided by the region server    * @param row row to check    * @param family column family    * @param qualifier column qualifier    * @param compareOp the comparison operation    * @param comparator the comparator    * @param delete delete to commit if check succeeds    * @param result     * @return the value to return to client if bypassing default processing    * @throws IOException if an error occurred on the coprocessor    */
name|boolean
name|preCheckAndDelete
parameter_list|(
specifier|final
name|ObserverContext
argument_list|<
name|RegionCoprocessorEnvironment
argument_list|>
name|c
parameter_list|,
specifier|final
name|byte
index|[]
name|row
parameter_list|,
specifier|final
name|byte
index|[]
name|family
parameter_list|,
specifier|final
name|byte
index|[]
name|qualifier
parameter_list|,
specifier|final
name|CompareOp
name|compareOp
parameter_list|,
specifier|final
name|ByteArrayComparable
name|comparator
parameter_list|,
specifier|final
name|Delete
name|delete
parameter_list|,
specifier|final
name|boolean
name|result
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Called before checkAndDelete but after acquiring rowock.    *<p>    *<b>Note:</b> Caution to be taken for not doing any long time operation in this hook.     * Row will be locked for longer time. Trying to acquire lock on another row, within this,     * can lead to potential deadlock.    *<p>    * Call CoprocessorEnvironment#bypass to skip default actions    *<p>    * Call CoprocessorEnvironment#complete to skip any subsequent chained    * coprocessors    * @param c the environment provided by the region server    * @param row row to check    * @param family column family    * @param qualifier column qualifier    * @param compareOp the comparison operation    * @param comparator the comparator    * @param delete delete to commit if check succeeds    * @param result     * @return the value to return to client if bypassing default processing    * @throws IOException if an error occurred on the coprocessor    */
name|boolean
name|preCheckAndDeleteAfterRowLock
parameter_list|(
specifier|final
name|ObserverContext
argument_list|<
name|RegionCoprocessorEnvironment
argument_list|>
name|c
parameter_list|,
specifier|final
name|byte
index|[]
name|row
parameter_list|,
specifier|final
name|byte
index|[]
name|family
parameter_list|,
specifier|final
name|byte
index|[]
name|qualifier
parameter_list|,
specifier|final
name|CompareOp
name|compareOp
parameter_list|,
specifier|final
name|ByteArrayComparable
name|comparator
parameter_list|,
specifier|final
name|Delete
name|delete
parameter_list|,
specifier|final
name|boolean
name|result
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Called after checkAndDelete    *<p>    * Call CoprocessorEnvironment#complete to skip any subsequent chained    * coprocessors    * @param c the environment provided by the region server    * @param row row to check    * @param family column family    * @param qualifier column qualifier    * @param compareOp the comparison operation    * @param comparator the comparator    * @param delete delete to commit if check succeeds    * @param result from the CheckAndDelete    * @return the possibly transformed returned value to return to client    * @throws IOException if an error occurred on the coprocessor    */
name|boolean
name|postCheckAndDelete
parameter_list|(
specifier|final
name|ObserverContext
argument_list|<
name|RegionCoprocessorEnvironment
argument_list|>
name|c
parameter_list|,
specifier|final
name|byte
index|[]
name|row
parameter_list|,
specifier|final
name|byte
index|[]
name|family
parameter_list|,
specifier|final
name|byte
index|[]
name|qualifier
parameter_list|,
specifier|final
name|CompareOp
name|compareOp
parameter_list|,
specifier|final
name|ByteArrayComparable
name|comparator
parameter_list|,
specifier|final
name|Delete
name|delete
parameter_list|,
specifier|final
name|boolean
name|result
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Called before incrementColumnValue    *<p>    * Call CoprocessorEnvironment#bypass to skip default actions    *<p>    * Call CoprocessorEnvironment#complete to skip any subsequent chained    * coprocessors    * @param c the environment provided by the region server    * @param row row to check    * @param family column family    * @param qualifier column qualifier    * @param amount long amount to increment    * @param writeToWAL true if the change should be written to the WAL    * @return value to return to the client if bypassing default processing    * @throws IOException if an error occurred on the coprocessor    * @deprecated This hook is no longer called by the RegionServer    */
annotation|@
name|Deprecated
name|long
name|preIncrementColumnValue
parameter_list|(
specifier|final
name|ObserverContext
argument_list|<
name|RegionCoprocessorEnvironment
argument_list|>
name|c
parameter_list|,
specifier|final
name|byte
index|[]
name|row
parameter_list|,
specifier|final
name|byte
index|[]
name|family
parameter_list|,
specifier|final
name|byte
index|[]
name|qualifier
parameter_list|,
specifier|final
name|long
name|amount
parameter_list|,
specifier|final
name|boolean
name|writeToWAL
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Called after incrementColumnValue    *<p>    * Call CoprocessorEnvironment#complete to skip any subsequent chained    * coprocessors    * @param c the environment provided by the region server    * @param row row to check    * @param family column family    * @param qualifier column qualifier    * @param amount long amount to increment    * @param writeToWAL true if the change should be written to the WAL    * @param result the result returned by incrementColumnValue    * @return the result to return to the client    * @throws IOException if an error occurred on the coprocessor    * @deprecated This hook is no longer called by the RegionServer    */
annotation|@
name|Deprecated
name|long
name|postIncrementColumnValue
parameter_list|(
specifier|final
name|ObserverContext
argument_list|<
name|RegionCoprocessorEnvironment
argument_list|>
name|c
parameter_list|,
specifier|final
name|byte
index|[]
name|row
parameter_list|,
specifier|final
name|byte
index|[]
name|family
parameter_list|,
specifier|final
name|byte
index|[]
name|qualifier
parameter_list|,
specifier|final
name|long
name|amount
parameter_list|,
specifier|final
name|boolean
name|writeToWAL
parameter_list|,
specifier|final
name|long
name|result
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Called before Append.    *<p>    * Call CoprocessorEnvironment#bypass to skip default actions    *<p>    * Call CoprocessorEnvironment#complete to skip any subsequent chained    * coprocessors    * @param c the environment provided by the region server    * @param append Append object    * @return result to return to the client if bypassing default processing    * @throws IOException if an error occurred on the coprocessor    */
name|Result
name|preAppend
parameter_list|(
specifier|final
name|ObserverContext
argument_list|<
name|RegionCoprocessorEnvironment
argument_list|>
name|c
parameter_list|,
specifier|final
name|Append
name|append
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Called before Append but after acquiring rowlock.    *<p>    *<b>Note:</b> Caution to be taken for not doing any long time operation in this hook.     * Row will be locked for longer time. Trying to acquire lock on another row, within this,     * can lead to potential deadlock.    *<p>    * Call CoprocessorEnvironment#bypass to skip default actions    *<p>    * Call CoprocessorEnvironment#complete to skip any subsequent chained    * coprocessors    * @param c the environment provided by the region server    * @param append Append object    * @return result to return to the client if bypassing default processing    * @throws IOException if an error occurred on the coprocessor    */
name|Result
name|preAppendAfterRowLock
parameter_list|(
specifier|final
name|ObserverContext
argument_list|<
name|RegionCoprocessorEnvironment
argument_list|>
name|c
parameter_list|,
specifier|final
name|Append
name|append
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Called after Append    *<p>    * Call CoprocessorEnvironment#complete to skip any subsequent chained    * coprocessors    * @param c the environment provided by the region server    * @param append Append object    * @param result the result returned by increment    * @return the result to return to the client    * @throws IOException if an error occurred on the coprocessor    */
name|Result
name|postAppend
parameter_list|(
specifier|final
name|ObserverContext
argument_list|<
name|RegionCoprocessorEnvironment
argument_list|>
name|c
parameter_list|,
specifier|final
name|Append
name|append
parameter_list|,
specifier|final
name|Result
name|result
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Called before Increment.    *<p>    * Call CoprocessorEnvironment#bypass to skip default actions    *<p>    * Call CoprocessorEnvironment#complete to skip any subsequent chained    * coprocessors    * @param c the environment provided by the region server    * @param increment increment object    * @return result to return to the client if bypassing default processing    * @throws IOException if an error occurred on the coprocessor    */
name|Result
name|preIncrement
parameter_list|(
specifier|final
name|ObserverContext
argument_list|<
name|RegionCoprocessorEnvironment
argument_list|>
name|c
parameter_list|,
specifier|final
name|Increment
name|increment
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Called before Increment but after acquiring rowlock.    *<p>    *<b>Note:</b> Caution to be taken for not doing any long time operation in this hook.     * Row will be locked for longer time. Trying to acquire lock on another row, within this,     * can lead to potential deadlock.    *<p>    * Call CoprocessorEnvironment#bypass to skip default actions    *<p>    * Call CoprocessorEnvironment#complete to skip any subsequent chained coprocessors    *     * @param c    *          the environment provided by the region server    * @param increment    *          increment object    * @return result to return to the client if bypassing default processing    * @throws IOException    *           if an error occurred on the coprocessor    */
name|Result
name|preIncrementAfterRowLock
parameter_list|(
specifier|final
name|ObserverContext
argument_list|<
name|RegionCoprocessorEnvironment
argument_list|>
name|c
parameter_list|,
specifier|final
name|Increment
name|increment
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Called after increment    *<p>    * Call CoprocessorEnvironment#complete to skip any subsequent chained    * coprocessors    * @param c the environment provided by the region server    * @param increment increment object    * @param result the result returned by increment    * @return the result to return to the client    * @throws IOException if an error occurred on the coprocessor    */
name|Result
name|postIncrement
parameter_list|(
specifier|final
name|ObserverContext
argument_list|<
name|RegionCoprocessorEnvironment
argument_list|>
name|c
parameter_list|,
specifier|final
name|Increment
name|increment
parameter_list|,
specifier|final
name|Result
name|result
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Called before the client opens a new scanner.    *<p>    * Call CoprocessorEnvironment#bypass to skip default actions    *<p>    * Call CoprocessorEnvironment#complete to skip any subsequent chained    * coprocessors    * @param c the environment provided by the region server    * @param scan the Scan specification    * @param s if not null, the base scanner    * @return an RegionScanner instance to use instead of the base scanner if    * overriding default behavior, null otherwise    * @throws IOException if an error occurred on the coprocessor    */
name|RegionScanner
name|preScannerOpen
parameter_list|(
specifier|final
name|ObserverContext
argument_list|<
name|RegionCoprocessorEnvironment
argument_list|>
name|c
parameter_list|,
specifier|final
name|Scan
name|scan
parameter_list|,
specifier|final
name|RegionScanner
name|s
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Called before a store opens a new scanner.    * This hook is called when a "user" scanner is opened.    *<p>    * See {@link #preFlushScannerOpen(ObserverContext, Store, KeyValueScanner, InternalScanner)}    * and {@link #preCompactScannerOpen(ObserverContext,    *  Store, List, ScanType, long, InternalScanner)}    * to override scanners created for flushes or compactions, resp.    *<p>    * Call CoprocessorEnvironment#complete to skip any subsequent chained    * coprocessors.    * Calling {@link org.apache.hadoop.hbase.coprocessor.ObserverContext#bypass()} has no    * effect in this hook.    * @param c the environment provided by the region server    * @param store the store being scanned    * @param scan the Scan specification    * @param targetCols columns to be used in the scanner    * @param s the base scanner, if not {@code null}, from previous RegionObserver in the chain    * @return a KeyValueScanner instance to use or {@code null} to use the default implementation    * @throws IOException if an error occurred on the coprocessor    */
name|KeyValueScanner
name|preStoreScannerOpen
parameter_list|(
specifier|final
name|ObserverContext
argument_list|<
name|RegionCoprocessorEnvironment
argument_list|>
name|c
parameter_list|,
specifier|final
name|Store
name|store
parameter_list|,
specifier|final
name|Scan
name|scan
parameter_list|,
specifier|final
name|NavigableSet
argument_list|<
name|byte
index|[]
argument_list|>
name|targetCols
parameter_list|,
specifier|final
name|KeyValueScanner
name|s
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Called after the client opens a new scanner.    *<p>    * Call CoprocessorEnvironment#complete to skip any subsequent chained    * coprocessors    * @param c the environment provided by the region server    * @param scan the Scan specification    * @param s if not null, the base scanner    * @return the scanner instance to use    * @throws IOException if an error occurred on the coprocessor    */
name|RegionScanner
name|postScannerOpen
parameter_list|(
specifier|final
name|ObserverContext
argument_list|<
name|RegionCoprocessorEnvironment
argument_list|>
name|c
parameter_list|,
specifier|final
name|Scan
name|scan
parameter_list|,
specifier|final
name|RegionScanner
name|s
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Called before the client asks for the next row on a scanner.    *<p>    * Call CoprocessorEnvironment#bypass to skip default actions    *<p>    * Call CoprocessorEnvironment#complete to skip any subsequent chained    * coprocessors    * @param c the environment provided by the region server    * @param s the scanner    * @param result The result to return to the client if default processing    * is bypassed. Can be modified. Will not be returned if default processing    * is not bypassed.    * @param limit the maximum number of results to return    * @param hasNext the 'has more' indication    * @return 'has more' indication that should be sent to client    * @throws IOException if an error occurred on the coprocessor    */
name|boolean
name|preScannerNext
parameter_list|(
specifier|final
name|ObserverContext
argument_list|<
name|RegionCoprocessorEnvironment
argument_list|>
name|c
parameter_list|,
specifier|final
name|InternalScanner
name|s
parameter_list|,
specifier|final
name|List
argument_list|<
name|Result
argument_list|>
name|result
parameter_list|,
specifier|final
name|int
name|limit
parameter_list|,
specifier|final
name|boolean
name|hasNext
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Called after the client asks for the next row on a scanner.    *<p>    * Call CoprocessorEnvironment#complete to skip any subsequent chained    * coprocessors    * @param c the environment provided by the region server    * @param s the scanner    * @param result the result to return to the client, can be modified    * @param limit the maximum number of results to return    * @param hasNext the 'has more' indication    * @return 'has more' indication that should be sent to client    * @throws IOException if an error occurred on the coprocessor    */
name|boolean
name|postScannerNext
parameter_list|(
specifier|final
name|ObserverContext
argument_list|<
name|RegionCoprocessorEnvironment
argument_list|>
name|c
parameter_list|,
specifier|final
name|InternalScanner
name|s
parameter_list|,
specifier|final
name|List
argument_list|<
name|Result
argument_list|>
name|result
parameter_list|,
specifier|final
name|int
name|limit
parameter_list|,
specifier|final
name|boolean
name|hasNext
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * This will be called by the scan flow when the current scanned row is being filtered out by the    * filter. The filter may be filtering out the row via any of the below scenarios    *<ol>    *<li>    *<code>boolean filterRowKey(byte [] buffer, int offset, int length)</code> returning true</li>    *<li>    *<code>boolean filterRow()</code> returning true</li>    *<li>    *<code>void filterRow(List<KeyValue> kvs)</code> removing all the kvs from the passed List</li>    *</ol>    * @param c the environment provided by the region server    * @param s the scanner    * @param currentRow The current rowkey which got filtered out    * @param offset offset to rowkey    * @param length length of rowkey    * @param hasMore the 'has more' indication    * @return whether more rows are available for the scanner or not    * @throws IOException    */
name|boolean
name|postScannerFilterRow
parameter_list|(
specifier|final
name|ObserverContext
argument_list|<
name|RegionCoprocessorEnvironment
argument_list|>
name|c
parameter_list|,
specifier|final
name|InternalScanner
name|s
parameter_list|,
specifier|final
name|byte
index|[]
name|currentRow
parameter_list|,
specifier|final
name|int
name|offset
parameter_list|,
specifier|final
name|short
name|length
parameter_list|,
specifier|final
name|boolean
name|hasMore
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Called before the client closes a scanner.    *<p>    * Call CoprocessorEnvironment#bypass to skip default actions    *<p>    * Call CoprocessorEnvironment#complete to skip any subsequent chained    * coprocessors    * @param c the environment provided by the region server    * @param s the scanner    * @throws IOException if an error occurred on the coprocessor    */
name|void
name|preScannerClose
parameter_list|(
specifier|final
name|ObserverContext
argument_list|<
name|RegionCoprocessorEnvironment
argument_list|>
name|c
parameter_list|,
specifier|final
name|InternalScanner
name|s
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Called after the client closes a scanner.    *<p>    * Call CoprocessorEnvironment#complete to skip any subsequent chained    * coprocessors    * @param c the environment provided by the region server    * @param s the scanner    * @throws IOException if an error occurred on the coprocessor    */
name|void
name|postScannerClose
parameter_list|(
specifier|final
name|ObserverContext
argument_list|<
name|RegionCoprocessorEnvironment
argument_list|>
name|c
parameter_list|,
specifier|final
name|InternalScanner
name|s
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Called before a {@link org.apache.hadoop.hbase.regionserver.wal.WALEdit}    * replayed for this region.    */
name|void
name|preWALRestore
parameter_list|(
specifier|final
name|ObserverContext
argument_list|<
name|?
extends|extends
name|RegionCoprocessorEnvironment
argument_list|>
name|ctx
parameter_list|,
name|HRegionInfo
name|info
parameter_list|,
name|WALKey
name|logKey
parameter_list|,
name|WALEdit
name|logEdit
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Called before a {@link org.apache.hadoop.hbase.regionserver.wal.WALEdit}    * replayed for this region.    *    * This method is left in place to maintain binary compatibility with older    * {@link RegionObserver}s. If an implementation directly overrides    * {@link #preWALRestore(ObserverContext, HRegionInfo, WALKey, WALEdit)} then this version    * won't be called at all, barring problems with the Security Manager. To work correctly    * in the presence of a strict Security Manager, or in the case of an implementation that    * relies on a parent class to implement preWALRestore, you should implement this method    * as a call to the non-deprecated version.    *    * Users of this method will see all edits that can be treated as HLogKey. If there are    * edits that can't be treated as HLogKey they won't be offered to coprocessors that rely    * on this method. If a coprocessor gets skipped because of this mechanism, a log message    * at ERROR will be generated per coprocessor on the logger for {@link CoprocessorHost} once per    * classloader.    *    * @deprecated use {@link #preWALRestore(ObserverContext, HRegionInfo, WALKey, WALEdit)}    */
annotation|@
name|Deprecated
name|void
name|preWALRestore
parameter_list|(
specifier|final
name|ObserverContext
argument_list|<
name|RegionCoprocessorEnvironment
argument_list|>
name|ctx
parameter_list|,
name|HRegionInfo
name|info
parameter_list|,
name|HLogKey
name|logKey
parameter_list|,
name|WALEdit
name|logEdit
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Called after a {@link org.apache.hadoop.hbase.regionserver.wal.WALEdit}    * replayed for this region.    */
name|void
name|postWALRestore
parameter_list|(
specifier|final
name|ObserverContext
argument_list|<
name|?
extends|extends
name|RegionCoprocessorEnvironment
argument_list|>
name|ctx
parameter_list|,
name|HRegionInfo
name|info
parameter_list|,
name|WALKey
name|logKey
parameter_list|,
name|WALEdit
name|logEdit
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Called after a {@link org.apache.hadoop.hbase.regionserver.wal.WALEdit}    * replayed for this region.    *    * This method is left in place to maintain binary compatibility with older    * {@link RegionObserver}s. If an implementation directly overrides    * {@link #postWALRestore(ObserverContext, HRegionInfo, WALKey, WALEdit)} then this version    * won't be called at all, barring problems with the Security Manager. To work correctly    * in the presence of a strict Security Manager, or in the case of an implementation that    * relies on a parent class to implement preWALRestore, you should implement this method    * as a call to the non-deprecated version.    *    * Users of this method will see all edits that can be treated as HLogKey. If there are    * edits that can't be treated as HLogKey they won't be offered to coprocessors that rely    * on this method. If a coprocessor gets skipped because of this mechanism, a log message    * at ERROR will be generated per coprocessor on the logger for {@link CoprocessorHost} once per    * classloader.    *    * @deprecated use {@link #postWALRestore(ObserverContext, HRegionInfo, WALKey, WALEdit)}    */
annotation|@
name|Deprecated
name|void
name|postWALRestore
parameter_list|(
specifier|final
name|ObserverContext
argument_list|<
name|RegionCoprocessorEnvironment
argument_list|>
name|ctx
parameter_list|,
name|HRegionInfo
name|info
parameter_list|,
name|HLogKey
name|logKey
parameter_list|,
name|WALEdit
name|logEdit
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Called before bulkLoadHFile. Users can create a StoreFile instance to    * access the contents of a HFile.    *    * @param ctx    * @param familyPaths pairs of { CF, HFile path } submitted for bulk load. Adding    * or removing from this list will add or remove HFiles to be bulk loaded.    * @throws IOException    */
name|void
name|preBulkLoadHFile
parameter_list|(
specifier|final
name|ObserverContext
argument_list|<
name|RegionCoprocessorEnvironment
argument_list|>
name|ctx
parameter_list|,
name|List
argument_list|<
name|Pair
argument_list|<
name|byte
index|[]
argument_list|,
name|String
argument_list|>
argument_list|>
name|familyPaths
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Called after bulkLoadHFile.    *    * @param ctx    * @param familyPaths pairs of { CF, HFile path } submitted for bulk load    * @param hasLoaded whether the bulkLoad was successful    * @return the new value of hasLoaded    * @throws IOException    */
name|boolean
name|postBulkLoadHFile
parameter_list|(
specifier|final
name|ObserverContext
argument_list|<
name|RegionCoprocessorEnvironment
argument_list|>
name|ctx
parameter_list|,
name|List
argument_list|<
name|Pair
argument_list|<
name|byte
index|[]
argument_list|,
name|String
argument_list|>
argument_list|>
name|familyPaths
parameter_list|,
name|boolean
name|hasLoaded
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Called before creation of Reader for a store file.    * Calling {@link org.apache.hadoop.hbase.coprocessor.ObserverContext#bypass()} has no    * effect in this hook.    *     * @param ctx the environment provided by the region server    * @param fs fileystem to read from    * @param p path to the file    * @param in {@link FSDataInputStreamWrapper}    * @param size Full size of the file    * @param cacheConf    * @param r original reference file. This will be not null only when reading a split file.    * @param reader the base reader, if not {@code null}, from previous RegionObserver in the chain    * @return a Reader instance to use instead of the base reader if overriding    * default behavior, null otherwise    * @throws IOException    */
name|StoreFile
operator|.
name|Reader
name|preStoreFileReaderOpen
parameter_list|(
specifier|final
name|ObserverContext
argument_list|<
name|RegionCoprocessorEnvironment
argument_list|>
name|ctx
parameter_list|,
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Path
name|p
parameter_list|,
specifier|final
name|FSDataInputStreamWrapper
name|in
parameter_list|,
name|long
name|size
parameter_list|,
specifier|final
name|CacheConfig
name|cacheConf
parameter_list|,
specifier|final
name|Reference
name|r
parameter_list|,
name|StoreFile
operator|.
name|Reader
name|reader
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Called after the creation of Reader for a store file.    *     * @param ctx the environment provided by the region server    * @param fs fileystem to read from    * @param p path to the file    * @param in {@link FSDataInputStreamWrapper}    * @param size Full size of the file    * @param cacheConf    * @param r original reference file. This will be not null only when reading a split file.    * @param reader the base reader instance    * @return The reader to use    * @throws IOException    */
name|StoreFile
operator|.
name|Reader
name|postStoreFileReaderOpen
parameter_list|(
specifier|final
name|ObserverContext
argument_list|<
name|RegionCoprocessorEnvironment
argument_list|>
name|ctx
parameter_list|,
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Path
name|p
parameter_list|,
specifier|final
name|FSDataInputStreamWrapper
name|in
parameter_list|,
name|long
name|size
parameter_list|,
specifier|final
name|CacheConfig
name|cacheConf
parameter_list|,
specifier|final
name|Reference
name|r
parameter_list|,
name|StoreFile
operator|.
name|Reader
name|reader
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Called after a new cell has been created during an increment operation, but before    * it is committed to the WAL or memstore.    * Calling {@link org.apache.hadoop.hbase.coprocessor.ObserverContext#bypass()} has no    * effect in this hook.    * @param ctx the environment provided by the region server    * @param opType the operation type    * @param mutation the current mutation    * @param oldCell old cell containing previous value    * @param newCell the new cell containing the computed value    * @return the new cell, possibly changed    * @throws IOException    */
name|Cell
name|postMutationBeforeWAL
parameter_list|(
name|ObserverContext
argument_list|<
name|RegionCoprocessorEnvironment
argument_list|>
name|ctx
parameter_list|,
name|MutationType
name|opType
parameter_list|,
name|Mutation
name|mutation
parameter_list|,
name|Cell
name|oldCell
parameter_list|,
name|Cell
name|newCell
parameter_list|)
throws|throws
name|IOException
function_decl|;
comment|/**    * Called after the ScanQueryMatcher creates ScanDeleteTracker. Implementing    * this hook would help in creating customised DeleteTracker and returning    * the newly created DeleteTracker    *    * @param ctx the environment provided by the region server    * @param delTracker the deleteTracker that is created by the QueryMatcher    * @return the Delete Tracker    * @throws IOException    */
name|DeleteTracker
name|postInstantiateDeleteTracker
parameter_list|(
specifier|final
name|ObserverContext
argument_list|<
name|RegionCoprocessorEnvironment
argument_list|>
name|ctx
parameter_list|,
name|DeleteTracker
name|delTracker
parameter_list|)
throws|throws
name|IOException
function_decl|;
block|}
end_interface

end_unit

