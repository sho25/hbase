begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|FileNotFoundException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Arrays
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Comparator
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|TreeMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ConcurrentHashMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|regex
operator|.
name|Matcher
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|regex
operator|.
name|Pattern
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|lang
operator|.
name|NotImplementedException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|Log
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|LogFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|classification
operator|.
name|InterfaceAudience
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FSDataInputStream
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FSDataOutputStream
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileStatus
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|PathFilter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|DeserializationException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HConstants
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HTableDescriptor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|TableDescriptors
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|TableInfoMissingException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|protobuf
operator|.
name|ProtobufUtil
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|primitives
operator|.
name|Ints
import|;
end_import

begin_comment
comment|/**  * Implementation of {@link TableDescriptors} that reads descriptors from the  * passed filesystem.  It expects descriptors to be in a file under the  * table's directory in FS.  Can be read-only -- i.e. does not modify  * the filesystem or can be read and write.  *   *<p>Also has utility for keeping up the table descriptors tableinfo file.  * The table schema file is kept under the table directory in the filesystem.  * It has a {@link #TABLEINFO_NAME} prefix and then a suffix that is the  * edit sequenceid: e.g.<code>.tableinfo.0000000003</code>.  This sequenceid  * is always increasing.  It starts at zero.  The table schema file with the  * highest sequenceid has the most recent schema edit. Usually there is one file  * only, the most recent but there may be short periods where there are more  * than one file. Old files are eventually cleaned.  Presumption is that there  * will not be lots of concurrent clients making table schema edits.  If so,  * the below needs a bit of a reworking and perhaps some supporting api in hdfs.  */
end_comment

begin_class
annotation|@
name|InterfaceAudience
operator|.
name|Private
specifier|public
class|class
name|FSTableDescriptors
implements|implements
name|TableDescriptors
block|{
specifier|private
specifier|static
specifier|final
name|Log
name|LOG
init|=
name|LogFactory
operator|.
name|getLog
argument_list|(
name|FSTableDescriptors
operator|.
name|class
argument_list|)
decl_stmt|;
specifier|private
specifier|final
name|FileSystem
name|fs
decl_stmt|;
specifier|private
specifier|final
name|Path
name|rootdir
decl_stmt|;
specifier|private
specifier|final
name|boolean
name|fsreadonly
decl_stmt|;
name|long
name|cachehits
init|=
literal|0
decl_stmt|;
name|long
name|invocations
init|=
literal|0
decl_stmt|;
comment|/** The file name used to store HTD in HDFS  */
specifier|public
specifier|static
specifier|final
name|String
name|TABLEINFO_NAME
init|=
literal|".tableinfo"
decl_stmt|;
comment|// This cache does not age out the old stuff.  Thinking is that the amount
comment|// of data we keep up in here is so small, no need to do occasional purge.
comment|// TODO.
specifier|private
specifier|final
name|Map
argument_list|<
name|String
argument_list|,
name|TableDescriptorModtime
argument_list|>
name|cache
init|=
operator|new
name|ConcurrentHashMap
argument_list|<
name|String
argument_list|,
name|TableDescriptorModtime
argument_list|>
argument_list|()
decl_stmt|;
comment|/**    * Data structure to hold modification time and table descriptor.    */
specifier|static
class|class
name|TableDescriptorModtime
block|{
specifier|private
specifier|final
name|HTableDescriptor
name|descriptor
decl_stmt|;
specifier|private
specifier|final
name|long
name|modtime
decl_stmt|;
name|TableDescriptorModtime
parameter_list|(
specifier|final
name|long
name|modtime
parameter_list|,
specifier|final
name|HTableDescriptor
name|htd
parameter_list|)
block|{
name|this
operator|.
name|descriptor
operator|=
name|htd
expr_stmt|;
name|this
operator|.
name|modtime
operator|=
name|modtime
expr_stmt|;
block|}
name|long
name|getModtime
parameter_list|()
block|{
return|return
name|this
operator|.
name|modtime
return|;
block|}
name|HTableDescriptor
name|getTableDescriptor
parameter_list|()
block|{
return|return
name|this
operator|.
name|descriptor
return|;
block|}
block|}
specifier|public
name|FSTableDescriptors
parameter_list|(
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Path
name|rootdir
parameter_list|)
block|{
name|this
argument_list|(
name|fs
argument_list|,
name|rootdir
argument_list|,
literal|false
argument_list|)
expr_stmt|;
block|}
comment|/**    * @param fs    * @param rootdir    * @param fsreadOnly True if we are read-only when it comes to filesystem    * operations; i.e. on remove, we do not do delete in fs.    */
specifier|public
name|FSTableDescriptors
parameter_list|(
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Path
name|rootdir
parameter_list|,
specifier|final
name|boolean
name|fsreadOnly
parameter_list|)
block|{
name|super
argument_list|()
expr_stmt|;
name|this
operator|.
name|fs
operator|=
name|fs
expr_stmt|;
name|this
operator|.
name|rootdir
operator|=
name|rootdir
expr_stmt|;
name|this
operator|.
name|fsreadonly
operator|=
name|fsreadOnly
expr_stmt|;
block|}
comment|/* (non-Javadoc)    * @see org.apache.hadoop.hbase.TableDescriptors#getHTableDescriptor(java.lang.String)    */
annotation|@
name|Override
specifier|public
name|HTableDescriptor
name|get
parameter_list|(
specifier|final
name|byte
index|[]
name|tablename
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|get
argument_list|(
name|Bytes
operator|.
name|toString
argument_list|(
name|tablename
argument_list|)
argument_list|)
return|;
block|}
comment|/* (non-Javadoc)    * @see org.apache.hadoop.hbase.TableDescriptors#getTableDescriptor(byte[])    */
annotation|@
name|Override
specifier|public
name|HTableDescriptor
name|get
parameter_list|(
specifier|final
name|String
name|tablename
parameter_list|)
throws|throws
name|IOException
block|{
name|invocations
operator|++
expr_stmt|;
if|if
condition|(
name|HTableDescriptor
operator|.
name|ROOT_TABLEDESC
operator|.
name|getNameAsString
argument_list|()
operator|.
name|equals
argument_list|(
name|tablename
argument_list|)
condition|)
block|{
name|cachehits
operator|++
expr_stmt|;
return|return
name|HTableDescriptor
operator|.
name|ROOT_TABLEDESC
return|;
block|}
if|if
condition|(
name|HTableDescriptor
operator|.
name|META_TABLEDESC
operator|.
name|getNameAsString
argument_list|()
operator|.
name|equals
argument_list|(
name|tablename
argument_list|)
condition|)
block|{
name|cachehits
operator|++
expr_stmt|;
return|return
name|HTableDescriptor
operator|.
name|META_TABLEDESC
return|;
block|}
comment|// .META. and -ROOT- is already handled. If some one tries to get the descriptor for
comment|// .logs, .oldlogs or .corrupt throw an exception.
if|if
condition|(
name|HConstants
operator|.
name|HBASE_NON_USER_TABLE_DIRS
operator|.
name|contains
argument_list|(
name|tablename
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"No descriptor found for table = "
operator|+
name|tablename
argument_list|)
throw|;
block|}
comment|// Look in cache of descriptors.
name|TableDescriptorModtime
name|cachedtdm
init|=
name|this
operator|.
name|cache
operator|.
name|get
argument_list|(
name|tablename
argument_list|)
decl_stmt|;
if|if
condition|(
name|cachedtdm
operator|!=
literal|null
condition|)
block|{
comment|// Check mod time has not changed (this is trip to NN).
if|if
condition|(
name|getTableInfoModtime
argument_list|(
name|this
operator|.
name|fs
argument_list|,
name|this
operator|.
name|rootdir
argument_list|,
name|tablename
argument_list|)
operator|<=
name|cachedtdm
operator|.
name|getModtime
argument_list|()
condition|)
block|{
name|cachehits
operator|++
expr_stmt|;
return|return
name|cachedtdm
operator|.
name|getTableDescriptor
argument_list|()
return|;
block|}
block|}
name|TableDescriptorModtime
name|tdmt
init|=
literal|null
decl_stmt|;
try|try
block|{
name|tdmt
operator|=
name|getTableDescriptorModtime
argument_list|(
name|this
operator|.
name|fs
argument_list|,
name|this
operator|.
name|rootdir
argument_list|,
name|tablename
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|NullPointerException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Exception during readTableDecriptor. Current table name = "
operator|+
name|tablename
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ioe
parameter_list|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Exception during readTableDecriptor. Current table name = "
operator|+
name|tablename
argument_list|,
name|ioe
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|tdmt
operator|==
literal|null
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"The following folder is in HBase's root directory and "
operator|+
literal|"doesn't contain a table descriptor, "
operator|+
literal|"do consider deleting it: "
operator|+
name|tablename
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|this
operator|.
name|cache
operator|.
name|put
argument_list|(
name|tablename
argument_list|,
name|tdmt
argument_list|)
expr_stmt|;
block|}
return|return
name|tdmt
operator|==
literal|null
condition|?
literal|null
else|:
name|tdmt
operator|.
name|getTableDescriptor
argument_list|()
return|;
block|}
comment|/* (non-Javadoc)    * @see org.apache.hadoop.hbase.TableDescriptors#getTableDescriptors(org.apache.hadoop.fs.FileSystem, org.apache.hadoop.fs.Path)    */
annotation|@
name|Override
specifier|public
name|Map
argument_list|<
name|String
argument_list|,
name|HTableDescriptor
argument_list|>
name|getAll
parameter_list|()
throws|throws
name|IOException
block|{
name|Map
argument_list|<
name|String
argument_list|,
name|HTableDescriptor
argument_list|>
name|htds
init|=
operator|new
name|TreeMap
argument_list|<
name|String
argument_list|,
name|HTableDescriptor
argument_list|>
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|Path
argument_list|>
name|tableDirs
init|=
name|FSUtils
operator|.
name|getTableDirs
argument_list|(
name|fs
argument_list|,
name|rootdir
argument_list|)
decl_stmt|;
for|for
control|(
name|Path
name|d
range|:
name|tableDirs
control|)
block|{
name|HTableDescriptor
name|htd
init|=
literal|null
decl_stmt|;
try|try
block|{
name|htd
operator|=
name|get
argument_list|(
name|d
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|FileNotFoundException
name|fnfe
parameter_list|)
block|{
comment|// inability of retrieving one HTD shouldn't stop getting the remaining
name|LOG
operator|.
name|warn
argument_list|(
literal|"Trouble retrieving htd"
argument_list|,
name|fnfe
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|htd
operator|==
literal|null
condition|)
continue|continue;
name|htds
operator|.
name|put
argument_list|(
name|d
operator|.
name|getName
argument_list|()
argument_list|,
name|htd
argument_list|)
expr_stmt|;
block|}
return|return
name|htds
return|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|add
parameter_list|(
name|HTableDescriptor
name|htd
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|Bytes
operator|.
name|equals
argument_list|(
name|HConstants
operator|.
name|ROOT_TABLE_NAME
argument_list|,
name|htd
operator|.
name|getName
argument_list|()
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|NotImplementedException
argument_list|()
throw|;
block|}
if|if
condition|(
name|Bytes
operator|.
name|equals
argument_list|(
name|HConstants
operator|.
name|META_TABLE_NAME
argument_list|,
name|htd
operator|.
name|getName
argument_list|()
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|NotImplementedException
argument_list|()
throw|;
block|}
if|if
condition|(
name|HConstants
operator|.
name|HBASE_NON_USER_TABLE_DIRS
operator|.
name|contains
argument_list|(
name|htd
operator|.
name|getNameAsString
argument_list|()
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|NotImplementedException
argument_list|()
throw|;
block|}
if|if
condition|(
operator|!
name|this
operator|.
name|fsreadonly
condition|)
name|updateHTableDescriptor
argument_list|(
name|this
operator|.
name|fs
argument_list|,
name|this
operator|.
name|rootdir
argument_list|,
name|htd
argument_list|)
expr_stmt|;
name|long
name|modtime
init|=
name|getTableInfoModtime
argument_list|(
name|this
operator|.
name|fs
argument_list|,
name|this
operator|.
name|rootdir
argument_list|,
name|htd
operator|.
name|getNameAsString
argument_list|()
argument_list|)
decl_stmt|;
name|this
operator|.
name|cache
operator|.
name|put
argument_list|(
name|htd
operator|.
name|getNameAsString
argument_list|()
argument_list|,
operator|new
name|TableDescriptorModtime
argument_list|(
name|modtime
argument_list|,
name|htd
argument_list|)
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|HTableDescriptor
name|remove
parameter_list|(
specifier|final
name|String
name|tablename
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
operator|!
name|this
operator|.
name|fsreadonly
condition|)
block|{
name|Path
name|tabledir
init|=
name|FSUtils
operator|.
name|getTablePath
argument_list|(
name|this
operator|.
name|rootdir
argument_list|,
name|tablename
argument_list|)
decl_stmt|;
if|if
condition|(
name|this
operator|.
name|fs
operator|.
name|exists
argument_list|(
name|tabledir
argument_list|)
condition|)
block|{
if|if
condition|(
operator|!
name|this
operator|.
name|fs
operator|.
name|delete
argument_list|(
name|tabledir
argument_list|,
literal|true
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Failed delete of "
operator|+
name|tabledir
operator|.
name|toString
argument_list|()
argument_list|)
throw|;
block|}
block|}
block|}
name|TableDescriptorModtime
name|tdm
init|=
name|this
operator|.
name|cache
operator|.
name|remove
argument_list|(
name|tablename
argument_list|)
decl_stmt|;
return|return
name|tdm
operator|==
literal|null
condition|?
literal|null
else|:
name|tdm
operator|.
name|getTableDescriptor
argument_list|()
return|;
block|}
comment|/**    * Checks if<code>.tableinfo<code> exists for given table    *     * @param fs file system    * @param rootdir root directory of HBase installation    * @param tableName name of table    * @return true if exists    * @throws IOException    */
specifier|public
specifier|static
name|boolean
name|isTableInfoExists
parameter_list|(
name|FileSystem
name|fs
parameter_list|,
name|Path
name|rootdir
parameter_list|,
name|String
name|tableName
parameter_list|)
throws|throws
name|IOException
block|{
name|FileStatus
name|status
init|=
name|getTableInfoPath
argument_list|(
name|fs
argument_list|,
name|rootdir
argument_list|,
name|tableName
argument_list|)
decl_stmt|;
return|return
name|status
operator|==
literal|null
condition|?
literal|false
else|:
name|fs
operator|.
name|exists
argument_list|(
name|status
operator|.
name|getPath
argument_list|()
argument_list|)
return|;
block|}
specifier|private
specifier|static
name|FileStatus
name|getTableInfoPath
parameter_list|(
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Path
name|rootdir
parameter_list|,
specifier|final
name|String
name|tableName
parameter_list|)
throws|throws
name|IOException
block|{
name|Path
name|tabledir
init|=
name|FSUtils
operator|.
name|getTablePath
argument_list|(
name|rootdir
argument_list|,
name|tableName
argument_list|)
decl_stmt|;
return|return
name|getTableInfoPath
argument_list|(
name|fs
argument_list|,
name|tabledir
argument_list|)
return|;
block|}
comment|/**    * Looks under the table directory in the filesystem for files with a    * {@link #TABLEINFO_NAME} prefix.  Returns reference to the 'latest' instance.    * @param fs    * @param tabledir    * @return The 'current' tableinfo file.    * @throws IOException    */
specifier|public
specifier|static
name|FileStatus
name|getTableInfoPath
parameter_list|(
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Path
name|tabledir
parameter_list|)
throws|throws
name|IOException
block|{
name|FileStatus
index|[]
name|status
init|=
name|FSUtils
operator|.
name|listStatus
argument_list|(
name|fs
argument_list|,
name|tabledir
argument_list|,
operator|new
name|PathFilter
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|boolean
name|accept
parameter_list|(
name|Path
name|p
parameter_list|)
block|{
comment|// Accept any file that starts with TABLEINFO_NAME
return|return
name|p
operator|.
name|getName
argument_list|()
operator|.
name|startsWith
argument_list|(
name|TABLEINFO_NAME
argument_list|)
return|;
block|}
block|}
argument_list|)
decl_stmt|;
if|if
condition|(
name|status
operator|==
literal|null
operator|||
name|status
operator|.
name|length
operator|<
literal|1
condition|)
return|return
literal|null
return|;
name|Arrays
operator|.
name|sort
argument_list|(
name|status
argument_list|,
operator|new
name|FileStatusFileNameComparator
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|status
operator|.
name|length
operator|>
literal|1
condition|)
block|{
comment|// Clean away old versions of .tableinfo
for|for
control|(
name|int
name|i
init|=
literal|1
init|;
name|i
operator|<
name|status
operator|.
name|length
condition|;
name|i
operator|++
control|)
block|{
name|Path
name|p
init|=
name|status
index|[
name|i
index|]
operator|.
name|getPath
argument_list|()
decl_stmt|;
comment|// Clean up old versions
if|if
condition|(
operator|!
name|fs
operator|.
name|delete
argument_list|(
name|p
argument_list|,
literal|false
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failed cleanup of "
operator|+
name|p
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Cleaned up old tableinfo file "
operator|+
name|p
argument_list|)
expr_stmt|;
block|}
block|}
block|}
return|return
name|status
index|[
literal|0
index|]
return|;
block|}
comment|/**    * Compare {@link FileStatus} instances by {@link Path#getName()}.    * Returns in reverse order.    */
specifier|static
class|class
name|FileStatusFileNameComparator
implements|implements
name|Comparator
argument_list|<
name|FileStatus
argument_list|>
block|{
annotation|@
name|Override
specifier|public
name|int
name|compare
parameter_list|(
name|FileStatus
name|left
parameter_list|,
name|FileStatus
name|right
parameter_list|)
block|{
return|return
operator|-
name|left
operator|.
name|compareTo
argument_list|(
name|right
argument_list|)
return|;
block|}
block|}
comment|/**    * Width of the sequenceid that is a suffix on a tableinfo file.    */
specifier|static
specifier|final
name|int
name|WIDTH_OF_SEQUENCE_ID
init|=
literal|10
decl_stmt|;
comment|/*    * @param number Number to use as suffix.    * @return Returns zero-prefixed 5-byte wide decimal version of passed    * number (Does absolute in case number is negative).    */
specifier|static
name|String
name|formatTableInfoSequenceId
parameter_list|(
specifier|final
name|int
name|number
parameter_list|)
block|{
name|byte
index|[]
name|b
init|=
operator|new
name|byte
index|[
name|WIDTH_OF_SEQUENCE_ID
index|]
decl_stmt|;
name|int
name|d
init|=
name|Math
operator|.
name|abs
argument_list|(
name|number
argument_list|)
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
name|b
operator|.
name|length
operator|-
literal|1
init|;
name|i
operator|>=
literal|0
condition|;
name|i
operator|--
control|)
block|{
name|b
index|[
name|i
index|]
operator|=
call|(
name|byte
call|)
argument_list|(
operator|(
name|d
operator|%
literal|10
operator|)
operator|+
literal|'0'
argument_list|)
expr_stmt|;
name|d
operator|/=
literal|10
expr_stmt|;
block|}
return|return
name|Bytes
operator|.
name|toString
argument_list|(
name|b
argument_list|)
return|;
block|}
comment|/**    * Regex to eat up sequenceid suffix on a .tableinfo file.    * Use regex because may encounter oldstyle .tableinfos where there is no    * sequenceid on the end.    */
specifier|private
specifier|static
specifier|final
name|Pattern
name|SUFFIX
init|=
name|Pattern
operator|.
name|compile
argument_list|(
name|TABLEINFO_NAME
operator|+
literal|"(\\.([0-9]{"
operator|+
name|WIDTH_OF_SEQUENCE_ID
operator|+
literal|"}))?$"
argument_list|)
decl_stmt|;
comment|/**    * @param p Path to a<code>.tableinfo</code> file.    * @return The current editid or 0 if none found.    */
specifier|static
name|int
name|getTableInfoSequenceid
parameter_list|(
specifier|final
name|Path
name|p
parameter_list|)
block|{
if|if
condition|(
name|p
operator|==
literal|null
condition|)
return|return
literal|0
return|;
name|Matcher
name|m
init|=
name|SUFFIX
operator|.
name|matcher
argument_list|(
name|p
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|m
operator|.
name|matches
argument_list|()
condition|)
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
name|p
operator|.
name|toString
argument_list|()
argument_list|)
throw|;
name|String
name|suffix
init|=
name|m
operator|.
name|group
argument_list|(
literal|2
argument_list|)
decl_stmt|;
if|if
condition|(
name|suffix
operator|==
literal|null
operator|||
name|suffix
operator|.
name|length
argument_list|()
operator|<=
literal|0
condition|)
return|return
literal|0
return|;
return|return
name|Integer
operator|.
name|parseInt
argument_list|(
name|m
operator|.
name|group
argument_list|(
literal|2
argument_list|)
argument_list|)
return|;
block|}
comment|/**    * @param tabledir    * @param sequenceid    * @return Name of tableinfo file.    */
specifier|static
name|Path
name|getTableInfoFileName
parameter_list|(
specifier|final
name|Path
name|tabledir
parameter_list|,
specifier|final
name|int
name|sequenceid
parameter_list|)
block|{
return|return
operator|new
name|Path
argument_list|(
name|tabledir
argument_list|,
name|TABLEINFO_NAME
operator|+
literal|"."
operator|+
name|formatTableInfoSequenceId
argument_list|(
name|sequenceid
argument_list|)
argument_list|)
return|;
block|}
comment|/**    * @param fs    * @param rootdir    * @param tableName    * @return Modification time for the table {@link #TABLEINFO_NAME} file    * or<code>0</code> if no tableinfo file found.    * @throws IOException    */
specifier|static
name|long
name|getTableInfoModtime
parameter_list|(
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Path
name|rootdir
parameter_list|,
specifier|final
name|String
name|tableName
parameter_list|)
throws|throws
name|IOException
block|{
name|FileStatus
name|status
init|=
name|getTableInfoPath
argument_list|(
name|fs
argument_list|,
name|rootdir
argument_list|,
name|tableName
argument_list|)
decl_stmt|;
return|return
name|status
operator|==
literal|null
condition|?
literal|0
else|:
name|status
operator|.
name|getModificationTime
argument_list|()
return|;
block|}
comment|/**    * Get HTD from HDFS.    * @param fs    * @param hbaseRootDir    * @param tableName    * @return Descriptor or null if none found.    * @throws IOException    */
specifier|public
specifier|static
name|HTableDescriptor
name|getTableDescriptor
parameter_list|(
name|FileSystem
name|fs
parameter_list|,
name|Path
name|hbaseRootDir
parameter_list|,
name|byte
index|[]
name|tableName
parameter_list|)
throws|throws
name|IOException
block|{
name|HTableDescriptor
name|htd
init|=
literal|null
decl_stmt|;
try|try
block|{
name|TableDescriptorModtime
name|tdmt
init|=
name|getTableDescriptorModtime
argument_list|(
name|fs
argument_list|,
name|hbaseRootDir
argument_list|,
name|Bytes
operator|.
name|toString
argument_list|(
name|tableName
argument_list|)
argument_list|)
decl_stmt|;
name|htd
operator|=
name|tdmt
operator|==
literal|null
condition|?
literal|null
else|:
name|tdmt
operator|.
name|getTableDescriptor
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|NullPointerException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Exception during readTableDecriptor. Current table name = "
operator|+
name|Bytes
operator|.
name|toString
argument_list|(
name|tableName
argument_list|)
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
return|return
name|htd
return|;
block|}
specifier|static
name|HTableDescriptor
name|getTableDescriptor
parameter_list|(
name|FileSystem
name|fs
parameter_list|,
name|Path
name|hbaseRootDir
parameter_list|,
name|String
name|tableName
parameter_list|)
throws|throws
name|NullPointerException
throws|,
name|IOException
block|{
name|TableDescriptorModtime
name|tdmt
init|=
name|getTableDescriptorModtime
argument_list|(
name|fs
argument_list|,
name|hbaseRootDir
argument_list|,
name|tableName
argument_list|)
decl_stmt|;
return|return
name|tdmt
operator|==
literal|null
condition|?
literal|null
else|:
name|tdmt
operator|.
name|getTableDescriptor
argument_list|()
return|;
block|}
specifier|static
name|TableDescriptorModtime
name|getTableDescriptorModtime
parameter_list|(
name|FileSystem
name|fs
parameter_list|,
name|Path
name|hbaseRootDir
parameter_list|,
name|String
name|tableName
parameter_list|)
throws|throws
name|NullPointerException
throws|,
name|IOException
block|{
comment|// ignore both -ROOT- and .META. tables
if|if
condition|(
name|Bytes
operator|.
name|compareTo
argument_list|(
name|Bytes
operator|.
name|toBytes
argument_list|(
name|tableName
argument_list|)
argument_list|,
name|HConstants
operator|.
name|ROOT_TABLE_NAME
argument_list|)
operator|==
literal|0
operator|||
name|Bytes
operator|.
name|compareTo
argument_list|(
name|Bytes
operator|.
name|toBytes
argument_list|(
name|tableName
argument_list|)
argument_list|,
name|HConstants
operator|.
name|META_TABLE_NAME
argument_list|)
operator|==
literal|0
condition|)
block|{
return|return
literal|null
return|;
block|}
return|return
name|getTableDescriptorModtime
argument_list|(
name|fs
argument_list|,
name|FSUtils
operator|.
name|getTablePath
argument_list|(
name|hbaseRootDir
argument_list|,
name|tableName
argument_list|)
argument_list|)
return|;
block|}
specifier|static
name|TableDescriptorModtime
name|getTableDescriptorModtime
parameter_list|(
name|FileSystem
name|fs
parameter_list|,
name|Path
name|tableDir
parameter_list|)
throws|throws
name|NullPointerException
throws|,
name|IOException
block|{
if|if
condition|(
name|tableDir
operator|==
literal|null
condition|)
throw|throw
operator|new
name|NullPointerException
argument_list|()
throw|;
name|FileStatus
name|status
init|=
name|getTableInfoPath
argument_list|(
name|fs
argument_list|,
name|tableDir
argument_list|)
decl_stmt|;
if|if
condition|(
name|status
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|TableInfoMissingException
argument_list|(
literal|"No .tableinfo file under "
operator|+
name|tableDir
operator|.
name|toUri
argument_list|()
argument_list|)
throw|;
block|}
name|int
name|len
init|=
name|Ints
operator|.
name|checkedCast
argument_list|(
name|status
operator|.
name|getLen
argument_list|()
argument_list|)
decl_stmt|;
name|byte
index|[]
name|content
init|=
operator|new
name|byte
index|[
name|len
index|]
decl_stmt|;
name|FSDataInputStream
name|fsDataInputStream
init|=
name|fs
operator|.
name|open
argument_list|(
name|status
operator|.
name|getPath
argument_list|()
argument_list|)
decl_stmt|;
try|try
block|{
name|fsDataInputStream
operator|.
name|readFully
argument_list|(
name|content
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|fsDataInputStream
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
name|HTableDescriptor
name|htd
init|=
literal|null
decl_stmt|;
try|try
block|{
name|htd
operator|=
name|HTableDescriptor
operator|.
name|parseFrom
argument_list|(
name|content
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|DeserializationException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"content="
operator|+
name|Bytes
operator|.
name|toShort
argument_list|(
name|content
argument_list|)
argument_list|,
name|e
argument_list|)
throw|;
block|}
if|if
condition|(
operator|!
name|ProtobufUtil
operator|.
name|isPBMagicPrefix
argument_list|(
name|content
argument_list|)
condition|)
block|{
comment|// Convert the file over to be pb before leaving here.
name|createTableDescriptor
argument_list|(
name|fs
argument_list|,
name|tableDir
operator|.
name|getParent
argument_list|()
argument_list|,
name|htd
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
return|return
operator|new
name|TableDescriptorModtime
argument_list|(
name|status
operator|.
name|getModificationTime
argument_list|()
argument_list|,
name|htd
argument_list|)
return|;
block|}
specifier|public
specifier|static
name|HTableDescriptor
name|getTableDescriptor
parameter_list|(
name|FileSystem
name|fs
parameter_list|,
name|Path
name|tableDir
parameter_list|)
throws|throws
name|IOException
throws|,
name|NullPointerException
block|{
name|TableDescriptorModtime
name|tdmt
init|=
name|getTableDescriptorModtime
argument_list|(
name|fs
argument_list|,
name|tableDir
argument_list|)
decl_stmt|;
return|return
name|tdmt
operator|==
literal|null
condition|?
literal|null
else|:
name|tdmt
operator|.
name|getTableDescriptor
argument_list|()
return|;
block|}
comment|/**    * Update table descriptor    * @param fs    * @param conf    * @param hTableDescriptor    * @return New tableinfo or null if we failed update.    * @throws IOException Thrown if failed update.    */
specifier|static
name|Path
name|updateHTableDescriptor
parameter_list|(
name|FileSystem
name|fs
parameter_list|,
name|Path
name|rootdir
parameter_list|,
name|HTableDescriptor
name|hTableDescriptor
parameter_list|)
throws|throws
name|IOException
block|{
name|Path
name|tableDir
init|=
name|FSUtils
operator|.
name|getTablePath
argument_list|(
name|rootdir
argument_list|,
name|hTableDescriptor
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
name|Path
name|p
init|=
name|writeTableDescriptor
argument_list|(
name|fs
argument_list|,
name|hTableDescriptor
argument_list|,
name|tableDir
argument_list|,
name|getTableInfoPath
argument_list|(
name|fs
argument_list|,
name|tableDir
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|p
operator|==
literal|null
condition|)
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Failed update"
argument_list|)
throw|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Updated tableinfo="
operator|+
name|p
argument_list|)
expr_stmt|;
return|return
name|p
return|;
block|}
comment|/**    * Deletes a table's directory from the file system if exists. Used in unit    * tests.    */
specifier|public
specifier|static
name|void
name|deleteTableDescriptorIfExists
parameter_list|(
name|String
name|tableName
parameter_list|,
name|Configuration
name|conf
parameter_list|)
throws|throws
name|IOException
block|{
name|FileSystem
name|fs
init|=
name|FSUtils
operator|.
name|getCurrentFileSystem
argument_list|(
name|conf
argument_list|)
decl_stmt|;
name|FileStatus
name|status
init|=
name|getTableInfoPath
argument_list|(
name|fs
argument_list|,
name|FSUtils
operator|.
name|getRootDir
argument_list|(
name|conf
argument_list|)
argument_list|,
name|tableName
argument_list|)
decl_stmt|;
comment|// The below deleteDirectory works for either file or directory.
if|if
condition|(
name|status
operator|!=
literal|null
operator|&&
name|fs
operator|.
name|exists
argument_list|(
name|status
operator|.
name|getPath
argument_list|()
argument_list|)
condition|)
block|{
name|FSUtils
operator|.
name|deleteDirectory
argument_list|(
name|fs
argument_list|,
name|status
operator|.
name|getPath
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * @param fs    * @param hTableDescriptor    * @param tableDir    * @param status    * @return Descriptor file or null if we failed write.    * @throws IOException     */
specifier|private
specifier|static
name|Path
name|writeTableDescriptor
parameter_list|(
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|HTableDescriptor
name|hTableDescriptor
parameter_list|,
specifier|final
name|Path
name|tableDir
parameter_list|,
specifier|final
name|FileStatus
name|status
parameter_list|)
throws|throws
name|IOException
block|{
comment|// Get temporary dir into which we'll first write a file to avoid half-written file phenomenon.
name|Path
name|tmpTableDir
init|=
operator|new
name|Path
argument_list|(
name|tableDir
argument_list|,
literal|".tmp"
argument_list|)
decl_stmt|;
comment|// What is current sequenceid?  We read the current sequenceid from
comment|// the current file.  After we read it, another thread could come in and
comment|// compete with us writing out next version of file.  The below retries
comment|// should help in this case some but its hard to do guarantees in face of
comment|// concurrent schema edits.
name|int
name|currentSequenceid
init|=
name|status
operator|==
literal|null
condition|?
literal|0
else|:
name|getTableInfoSequenceid
argument_list|(
name|status
operator|.
name|getPath
argument_list|()
argument_list|)
decl_stmt|;
name|int
name|sequenceid
init|=
name|currentSequenceid
decl_stmt|;
comment|// Put arbitrary upperbound on how often we retry
name|int
name|retries
init|=
literal|10
decl_stmt|;
name|int
name|retrymax
init|=
name|currentSequenceid
operator|+
name|retries
decl_stmt|;
name|Path
name|tableInfoPath
init|=
literal|null
decl_stmt|;
do|do
block|{
name|sequenceid
operator|+=
literal|1
expr_stmt|;
name|Path
name|p
init|=
name|getTableInfoFileName
argument_list|(
name|tmpTableDir
argument_list|,
name|sequenceid
argument_list|)
decl_stmt|;
if|if
condition|(
name|fs
operator|.
name|exists
argument_list|(
name|p
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
name|p
operator|+
literal|" exists; retrying up to "
operator|+
name|retries
operator|+
literal|" times"
argument_list|)
expr_stmt|;
continue|continue;
block|}
try|try
block|{
name|writeHTD
argument_list|(
name|fs
argument_list|,
name|p
argument_list|,
name|hTableDescriptor
argument_list|)
expr_stmt|;
name|tableInfoPath
operator|=
name|getTableInfoFileName
argument_list|(
name|tableDir
argument_list|,
name|sequenceid
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|fs
operator|.
name|rename
argument_list|(
name|p
argument_list|,
name|tableInfoPath
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Failed rename of "
operator|+
name|p
operator|+
literal|" to "
operator|+
name|tableInfoPath
argument_list|)
throw|;
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|ioe
parameter_list|)
block|{
comment|// Presume clash of names or something; go around again.
name|LOG
operator|.
name|debug
argument_list|(
literal|"Failed write and/or rename; retrying"
argument_list|,
name|ioe
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|FSUtils
operator|.
name|deleteDirectory
argument_list|(
name|fs
argument_list|,
name|p
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failed cleanup of "
operator|+
name|p
argument_list|)
expr_stmt|;
block|}
name|tableInfoPath
operator|=
literal|null
expr_stmt|;
continue|continue;
block|}
comment|// Cleanup old schema file.
if|if
condition|(
name|status
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
operator|!
name|FSUtils
operator|.
name|deleteDirectory
argument_list|(
name|fs
argument_list|,
name|status
operator|.
name|getPath
argument_list|()
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failed delete of "
operator|+
name|status
operator|.
name|getPath
argument_list|()
operator|+
literal|"; continuing"
argument_list|)
expr_stmt|;
block|}
block|}
break|break;
block|}
do|while
condition|(
name|sequenceid
operator|<
name|retrymax
condition|)
do|;
return|return
name|tableInfoPath
return|;
block|}
specifier|private
specifier|static
name|void
name|writeHTD
parameter_list|(
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Path
name|p
parameter_list|,
specifier|final
name|HTableDescriptor
name|htd
parameter_list|)
throws|throws
name|IOException
block|{
name|FSDataOutputStream
name|out
init|=
name|fs
operator|.
name|create
argument_list|(
name|p
argument_list|,
literal|false
argument_list|)
decl_stmt|;
try|try
block|{
comment|// We used to write this file out as a serialized HTD Writable followed by two '\n's and then
comment|// the toString version of HTD.  Now we just write out the pb serialization.
name|out
operator|.
name|write
argument_list|(
name|htd
operator|.
name|toByteArray
argument_list|()
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|out
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**    * Create new HTableDescriptor in HDFS. Happens when we are creating table.    *     * @param htableDescriptor    * @param conf    */
specifier|public
specifier|static
name|boolean
name|createTableDescriptor
parameter_list|(
specifier|final
name|HTableDescriptor
name|htableDescriptor
parameter_list|,
name|Configuration
name|conf
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|createTableDescriptor
argument_list|(
name|htableDescriptor
argument_list|,
name|conf
argument_list|,
literal|false
argument_list|)
return|;
block|}
comment|/**    * Create new HTableDescriptor in HDFS. Happens when we are creating table. If    * forceCreation is true then even if previous table descriptor is present it    * will be overwritten    *     * @param htableDescriptor    * @param conf    * @param forceCreation True if we are to overwrite existing file.    */
specifier|static
name|boolean
name|createTableDescriptor
parameter_list|(
specifier|final
name|HTableDescriptor
name|htableDescriptor
parameter_list|,
specifier|final
name|Configuration
name|conf
parameter_list|,
name|boolean
name|forceCreation
parameter_list|)
throws|throws
name|IOException
block|{
name|FileSystem
name|fs
init|=
name|FSUtils
operator|.
name|getCurrentFileSystem
argument_list|(
name|conf
argument_list|)
decl_stmt|;
return|return
name|createTableDescriptor
argument_list|(
name|fs
argument_list|,
name|FSUtils
operator|.
name|getRootDir
argument_list|(
name|conf
argument_list|)
argument_list|,
name|htableDescriptor
argument_list|,
name|forceCreation
argument_list|)
return|;
block|}
comment|/**    * Create new HTableDescriptor in HDFS. Happens when we are creating table.    * Used by tests.    * @param fs    * @param htableDescriptor    * @param rootdir    */
specifier|public
specifier|static
name|boolean
name|createTableDescriptor
parameter_list|(
name|FileSystem
name|fs
parameter_list|,
name|Path
name|rootdir
parameter_list|,
name|HTableDescriptor
name|htableDescriptor
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|createTableDescriptor
argument_list|(
name|fs
argument_list|,
name|rootdir
argument_list|,
name|htableDescriptor
argument_list|,
literal|false
argument_list|)
return|;
block|}
comment|/**    * Create new HTableDescriptor in HDFS. Happens when we are creating table. If    * forceCreation is true then even if previous table descriptor is present it    * will be overwritten    *     * @param fs    * @param htableDescriptor    * @param rootdir    * @param forceCreation    * @return True if we successfully created file.    */
specifier|public
specifier|static
name|boolean
name|createTableDescriptor
parameter_list|(
name|FileSystem
name|fs
parameter_list|,
name|Path
name|rootdir
parameter_list|,
name|HTableDescriptor
name|htableDescriptor
parameter_list|,
name|boolean
name|forceCreation
parameter_list|)
throws|throws
name|IOException
block|{
name|Path
name|tabledir
init|=
name|FSUtils
operator|.
name|getTablePath
argument_list|(
name|rootdir
argument_list|,
name|htableDescriptor
operator|.
name|getNameAsString
argument_list|()
argument_list|)
decl_stmt|;
return|return
name|createTableDescriptorForTableDirectory
argument_list|(
name|fs
argument_list|,
name|tabledir
argument_list|,
name|htableDescriptor
argument_list|,
name|forceCreation
argument_list|)
return|;
block|}
comment|/**    * Create a new HTableDescriptor in HDFS in the specified table directory. Happens when we create    * a new table or snapshot a table.    * @param fs filesystem where the descriptor should be written    * @param tabledir directory under which we should write the file    * @param htableDescriptor description of the table to write    * @param forceCreation if<tt>true</tt>,then even if previous table descriptor is present it will    *          be overwritten    * @return<tt>true</tt> if the we successfully created the file,<tt>false</tt> if the file    *         already exists and we weren't forcing the descriptor creation.    * @throws IOException if a filesystem error occurs    */
specifier|public
specifier|static
name|boolean
name|createTableDescriptorForTableDirectory
parameter_list|(
name|FileSystem
name|fs
parameter_list|,
name|Path
name|tabledir
parameter_list|,
name|HTableDescriptor
name|htableDescriptor
parameter_list|,
name|boolean
name|forceCreation
parameter_list|)
throws|throws
name|IOException
block|{
name|FileStatus
name|status
init|=
name|getTableInfoPath
argument_list|(
name|fs
argument_list|,
name|tabledir
argument_list|)
decl_stmt|;
if|if
condition|(
name|status
operator|!=
literal|null
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Current tableInfoPath = "
operator|+
name|status
operator|.
name|getPath
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|forceCreation
condition|)
block|{
if|if
condition|(
name|fs
operator|.
name|exists
argument_list|(
name|status
operator|.
name|getPath
argument_list|()
argument_list|)
operator|&&
name|status
operator|.
name|getLen
argument_list|()
operator|>
literal|0
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"TableInfo already exists.. Skipping creation"
argument_list|)
expr_stmt|;
return|return
literal|false
return|;
block|}
block|}
block|}
name|Path
name|p
init|=
name|writeTableDescriptor
argument_list|(
name|fs
argument_list|,
name|htableDescriptor
argument_list|,
name|tabledir
argument_list|,
name|status
argument_list|)
decl_stmt|;
return|return
name|p
operator|!=
literal|null
return|;
block|}
block|}
end_class

end_unit

