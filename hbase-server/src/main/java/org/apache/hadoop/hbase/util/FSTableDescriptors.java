begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/*  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
package|;
end_package

begin_import
import|import
name|edu
operator|.
name|umd
operator|.
name|cs
operator|.
name|findbugs
operator|.
name|annotations
operator|.
name|Nullable
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|FileNotFoundException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Comparator
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|TreeMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ConcurrentHashMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|function
operator|.
name|Function
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|regex
operator|.
name|Matcher
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|regex
operator|.
name|Pattern
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|lang3
operator|.
name|NotImplementedException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FSDataInputStream
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FSDataOutputStream
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileStatus
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|PathFilter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|Coprocessor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HConstants
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|TableDescriptors
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|TableInfoMissingException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|TableName
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|ColumnFamilyDescriptorBuilder
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|CoprocessorDescriptorBuilder
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|TableDescriptor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|TableDescriptorBuilder
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|coprocessor
operator|.
name|MultiRowMutationEndpoint
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|exceptions
operator|.
name|DeserializationException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|BloomType
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|yetus
operator|.
name|audience
operator|.
name|InterfaceAudience
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|Logger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|LoggerFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hbase
operator|.
name|thirdparty
operator|.
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|annotations
operator|.
name|VisibleForTesting
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hbase
operator|.
name|thirdparty
operator|.
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|primitives
operator|.
name|Ints
import|;
end_import

begin_comment
comment|/**  * Implementation of {@link TableDescriptors} that reads descriptors from the  * passed filesystem.  It expects descriptors to be in a file in the  * {@link #TABLEINFO_DIR} subdir of the table's directory in FS.  Can be read-only  *  -- i.e. does not modify the filesystem or can be read and write.  *  *<p>Also has utility for keeping up the table descriptors tableinfo file.  * The table schema file is kept in the {@link #TABLEINFO_DIR} subdir  * of the table directory in the filesystem.  * It has a {@link #TABLEINFO_FILE_PREFIX} and then a suffix that is the  * edit sequenceid: e.g.<code>.tableinfo.0000000003</code>.  This sequenceid  * is always increasing.  It starts at zero.  The table schema file with the  * highest sequenceid has the most recent schema edit. Usually there is one file  * only, the most recent but there may be short periods where there are more  * than one file. Old files are eventually cleaned.  Presumption is that there  * will not be lots of concurrent clients making table schema edits.  If so,  * the below needs a bit of a reworking and perhaps some supporting api in hdfs.  */
end_comment

begin_class
annotation|@
name|InterfaceAudience
operator|.
name|Private
specifier|public
class|class
name|FSTableDescriptors
implements|implements
name|TableDescriptors
block|{
specifier|private
specifier|static
specifier|final
name|Logger
name|LOG
init|=
name|LoggerFactory
operator|.
name|getLogger
argument_list|(
name|FSTableDescriptors
operator|.
name|class
argument_list|)
decl_stmt|;
specifier|private
specifier|final
name|FileSystem
name|fs
decl_stmt|;
specifier|private
specifier|final
name|Path
name|rootdir
decl_stmt|;
specifier|private
specifier|final
name|boolean
name|fsreadonly
decl_stmt|;
specifier|private
specifier|volatile
name|boolean
name|usecache
decl_stmt|;
specifier|private
specifier|volatile
name|boolean
name|fsvisited
decl_stmt|;
annotation|@
name|VisibleForTesting
name|long
name|cachehits
init|=
literal|0
decl_stmt|;
annotation|@
name|VisibleForTesting
name|long
name|invocations
init|=
literal|0
decl_stmt|;
comment|/**    * The file name prefix used to store HTD in HDFS    */
specifier|public
specifier|static
specifier|final
name|String
name|TABLEINFO_FILE_PREFIX
init|=
literal|".tableinfo"
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|String
name|TABLEINFO_DIR
init|=
literal|".tabledesc"
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|String
name|TMP_DIR
init|=
literal|".tmp"
decl_stmt|;
comment|// This cache does not age out the old stuff.  Thinking is that the amount
comment|// of data we keep up in here is so small, no need to do occasional purge.
comment|// TODO.
specifier|private
specifier|final
name|Map
argument_list|<
name|TableName
argument_list|,
name|TableDescriptor
argument_list|>
name|cache
init|=
operator|new
name|ConcurrentHashMap
argument_list|<>
argument_list|()
decl_stmt|;
comment|/**    * Construct a FSTableDescriptors instance using the hbase root dir of the given conf and the    * filesystem where that root dir lives. This instance can do write operations (is not read only).    */
specifier|public
name|FSTableDescriptors
parameter_list|(
specifier|final
name|Configuration
name|conf
parameter_list|)
throws|throws
name|IOException
block|{
name|this
argument_list|(
name|FSUtils
operator|.
name|getCurrentFileSystem
argument_list|(
name|conf
argument_list|)
argument_list|,
name|FSUtils
operator|.
name|getRootDir
argument_list|(
name|conf
argument_list|)
argument_list|)
expr_stmt|;
block|}
specifier|public
name|FSTableDescriptors
parameter_list|(
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Path
name|rootdir
parameter_list|)
block|{
name|this
argument_list|(
name|fs
argument_list|,
name|rootdir
argument_list|,
literal|false
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
specifier|public
name|FSTableDescriptors
parameter_list|(
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Path
name|rootdir
parameter_list|,
specifier|final
name|boolean
name|fsreadonly
parameter_list|,
specifier|final
name|boolean
name|usecache
parameter_list|)
block|{
name|this
operator|.
name|fs
operator|=
name|fs
expr_stmt|;
name|this
operator|.
name|rootdir
operator|=
name|rootdir
expr_stmt|;
name|this
operator|.
name|fsreadonly
operator|=
name|fsreadonly
expr_stmt|;
name|this
operator|.
name|usecache
operator|=
name|usecache
expr_stmt|;
block|}
specifier|public
specifier|static
name|void
name|tryUpdateMetaTableDescriptor
parameter_list|(
name|Configuration
name|conf
parameter_list|)
throws|throws
name|IOException
block|{
name|tryUpdateMetaTableDescriptor
argument_list|(
name|conf
argument_list|,
name|FSUtils
operator|.
name|getCurrentFileSystem
argument_list|(
name|conf
argument_list|)
argument_list|,
name|FSUtils
operator|.
name|getRootDir
argument_list|(
name|conf
argument_list|)
argument_list|,
literal|null
argument_list|)
expr_stmt|;
block|}
specifier|public
specifier|static
name|void
name|tryUpdateMetaTableDescriptor
parameter_list|(
name|Configuration
name|conf
parameter_list|,
name|FileSystem
name|fs
parameter_list|,
name|Path
name|rootdir
parameter_list|,
name|Function
argument_list|<
name|TableDescriptorBuilder
argument_list|,
name|TableDescriptorBuilder
argument_list|>
name|metaObserver
parameter_list|)
throws|throws
name|IOException
block|{
comment|// see if we already have meta descriptor on fs. Write one if not.
try|try
block|{
name|getTableDescriptorFromFs
argument_list|(
name|fs
argument_list|,
name|rootdir
argument_list|,
name|TableName
operator|.
name|META_TABLE_NAME
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|TableInfoMissingException
name|e
parameter_list|)
block|{
name|TableDescriptorBuilder
name|builder
init|=
name|createMetaTableDescriptorBuilder
argument_list|(
name|conf
argument_list|)
decl_stmt|;
if|if
condition|(
name|metaObserver
operator|!=
literal|null
condition|)
block|{
name|builder
operator|=
name|metaObserver
operator|.
name|apply
argument_list|(
name|builder
argument_list|)
expr_stmt|;
block|}
name|TableDescriptor
name|td
init|=
name|builder
operator|.
name|build
argument_list|()
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Creating new hbase:meta table descriptor {}"
argument_list|,
name|td
argument_list|)
expr_stmt|;
name|TableName
name|tableName
init|=
name|td
operator|.
name|getTableName
argument_list|()
decl_stmt|;
name|Path
name|tableDir
init|=
name|FSUtils
operator|.
name|getTableDir
argument_list|(
name|rootdir
argument_list|,
name|tableName
argument_list|)
decl_stmt|;
name|Path
name|p
init|=
name|writeTableDescriptor
argument_list|(
name|fs
argument_list|,
name|td
argument_list|,
name|tableDir
argument_list|,
name|getTableInfoPath
argument_list|(
name|fs
argument_list|,
name|tableDir
argument_list|,
literal|true
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|p
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Failed update hbase:meta table descriptor"
argument_list|)
throw|;
block|}
name|LOG
operator|.
name|info
argument_list|(
literal|"Updated hbase:meta table descriptor to {}"
argument_list|,
name|p
argument_list|)
expr_stmt|;
block|}
block|}
specifier|private
specifier|static
name|TableDescriptorBuilder
name|createMetaTableDescriptorBuilder
parameter_list|(
specifier|final
name|Configuration
name|conf
parameter_list|)
throws|throws
name|IOException
block|{
comment|// TODO We used to set CacheDataInL1 for META table. When we have BucketCache in file mode, now
comment|// the META table data goes to File mode BC only. Test how that affect the system. If too much,
comment|// we have to rethink about adding back the setCacheDataInL1 for META table CFs.
return|return
name|TableDescriptorBuilder
operator|.
name|newBuilder
argument_list|(
name|TableName
operator|.
name|META_TABLE_NAME
argument_list|)
operator|.
name|setColumnFamily
argument_list|(
name|ColumnFamilyDescriptorBuilder
operator|.
name|newBuilder
argument_list|(
name|HConstants
operator|.
name|CATALOG_FAMILY
argument_list|)
operator|.
name|setMaxVersions
argument_list|(
name|conf
operator|.
name|getInt
argument_list|(
name|HConstants
operator|.
name|HBASE_META_VERSIONS
argument_list|,
name|HConstants
operator|.
name|DEFAULT_HBASE_META_VERSIONS
argument_list|)
argument_list|)
operator|.
name|setInMemory
argument_list|(
literal|true
argument_list|)
operator|.
name|setBlocksize
argument_list|(
name|conf
operator|.
name|getInt
argument_list|(
name|HConstants
operator|.
name|HBASE_META_BLOCK_SIZE
argument_list|,
name|HConstants
operator|.
name|DEFAULT_HBASE_META_BLOCK_SIZE
argument_list|)
argument_list|)
operator|.
name|setScope
argument_list|(
name|HConstants
operator|.
name|REPLICATION_SCOPE_LOCAL
argument_list|)
operator|.
name|setBloomFilterType
argument_list|(
name|BloomType
operator|.
name|ROWCOL
argument_list|)
operator|.
name|setDataBlockEncoding
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|encoding
operator|.
name|DataBlockEncoding
operator|.
name|ROW_INDEX_V1
argument_list|)
operator|.
name|build
argument_list|()
argument_list|)
operator|.
name|setColumnFamily
argument_list|(
name|ColumnFamilyDescriptorBuilder
operator|.
name|newBuilder
argument_list|(
name|HConstants
operator|.
name|TABLE_FAMILY
argument_list|)
operator|.
name|setMaxVersions
argument_list|(
name|conf
operator|.
name|getInt
argument_list|(
name|HConstants
operator|.
name|HBASE_META_VERSIONS
argument_list|,
name|HConstants
operator|.
name|DEFAULT_HBASE_META_VERSIONS
argument_list|)
argument_list|)
operator|.
name|setInMemory
argument_list|(
literal|true
argument_list|)
operator|.
name|setBlocksize
argument_list|(
literal|8
operator|*
literal|1024
argument_list|)
operator|.
name|setScope
argument_list|(
name|HConstants
operator|.
name|REPLICATION_SCOPE_LOCAL
argument_list|)
operator|.
name|setDataBlockEncoding
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|encoding
operator|.
name|DataBlockEncoding
operator|.
name|ROW_INDEX_V1
argument_list|)
operator|.
name|setBloomFilterType
argument_list|(
name|BloomType
operator|.
name|ROWCOL
argument_list|)
operator|.
name|build
argument_list|()
argument_list|)
operator|.
name|setColumnFamily
argument_list|(
name|ColumnFamilyDescriptorBuilder
operator|.
name|newBuilder
argument_list|(
name|HConstants
operator|.
name|REPLICATION_BARRIER_FAMILY
argument_list|)
operator|.
name|setMaxVersions
argument_list|(
name|HConstants
operator|.
name|ALL_VERSIONS
argument_list|)
operator|.
name|setInMemory
argument_list|(
literal|true
argument_list|)
operator|.
name|setScope
argument_list|(
name|HConstants
operator|.
name|REPLICATION_SCOPE_LOCAL
argument_list|)
operator|.
name|setDataBlockEncoding
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|encoding
operator|.
name|DataBlockEncoding
operator|.
name|ROW_INDEX_V1
argument_list|)
operator|.
name|setBloomFilterType
argument_list|(
name|BloomType
operator|.
name|ROWCOL
argument_list|)
operator|.
name|build
argument_list|()
argument_list|)
operator|.
name|setColumnFamily
argument_list|(
name|ColumnFamilyDescriptorBuilder
operator|.
name|newBuilder
argument_list|(
name|HConstants
operator|.
name|NAMESPACE_FAMILY
argument_list|)
operator|.
name|setMaxVersions
argument_list|(
name|conf
operator|.
name|getInt
argument_list|(
name|HConstants
operator|.
name|HBASE_META_VERSIONS
argument_list|,
name|HConstants
operator|.
name|DEFAULT_HBASE_META_VERSIONS
argument_list|)
argument_list|)
operator|.
name|setInMemory
argument_list|(
literal|true
argument_list|)
operator|.
name|setBlocksize
argument_list|(
name|conf
operator|.
name|getInt
argument_list|(
name|HConstants
operator|.
name|HBASE_META_BLOCK_SIZE
argument_list|,
name|HConstants
operator|.
name|DEFAULT_HBASE_META_BLOCK_SIZE
argument_list|)
argument_list|)
operator|.
name|setScope
argument_list|(
name|HConstants
operator|.
name|REPLICATION_SCOPE_LOCAL
argument_list|)
operator|.
name|setDataBlockEncoding
argument_list|(
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|encoding
operator|.
name|DataBlockEncoding
operator|.
name|ROW_INDEX_V1
argument_list|)
operator|.
name|setBloomFilterType
argument_list|(
name|BloomType
operator|.
name|ROWCOL
argument_list|)
operator|.
name|build
argument_list|()
argument_list|)
operator|.
name|setCoprocessor
argument_list|(
name|CoprocessorDescriptorBuilder
operator|.
name|newBuilder
argument_list|(
name|MultiRowMutationEndpoint
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|)
operator|.
name|setPriority
argument_list|(
name|Coprocessor
operator|.
name|PRIORITY_SYSTEM
argument_list|)
operator|.
name|build
argument_list|()
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|setCacheOn
parameter_list|()
throws|throws
name|IOException
block|{
name|this
operator|.
name|cache
operator|.
name|clear
argument_list|()
expr_stmt|;
name|this
operator|.
name|usecache
operator|=
literal|true
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|setCacheOff
parameter_list|()
throws|throws
name|IOException
block|{
name|this
operator|.
name|usecache
operator|=
literal|false
expr_stmt|;
name|this
operator|.
name|cache
operator|.
name|clear
argument_list|()
expr_stmt|;
block|}
annotation|@
name|VisibleForTesting
specifier|public
name|boolean
name|isUsecache
parameter_list|()
block|{
return|return
name|this
operator|.
name|usecache
return|;
block|}
comment|/**    * Get the current table descriptor for the given table, or null if none exists.    *    * Uses a local cache of the descriptor but still checks the filesystem on each call    * to see if a newer file has been created since the cached one was read.    */
annotation|@
name|Override
annotation|@
name|Nullable
specifier|public
name|TableDescriptor
name|get
parameter_list|(
specifier|final
name|TableName
name|tablename
parameter_list|)
throws|throws
name|IOException
block|{
name|invocations
operator|++
expr_stmt|;
if|if
condition|(
name|usecache
condition|)
block|{
comment|// Look in cache of descriptors.
name|TableDescriptor
name|cachedtdm
init|=
name|this
operator|.
name|cache
operator|.
name|get
argument_list|(
name|tablename
argument_list|)
decl_stmt|;
if|if
condition|(
name|cachedtdm
operator|!=
literal|null
condition|)
block|{
name|cachehits
operator|++
expr_stmt|;
return|return
name|cachedtdm
return|;
block|}
block|}
name|TableDescriptor
name|tdmt
init|=
literal|null
decl_stmt|;
try|try
block|{
name|tdmt
operator|=
name|getTableDescriptorFromFs
argument_list|(
name|fs
argument_list|,
name|rootdir
argument_list|,
name|tablename
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|NullPointerException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Exception during readTableDecriptor. Current table name = "
operator|+
name|tablename
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|TableInfoMissingException
name|e
parameter_list|)
block|{
comment|// ignore. This is regular operation
block|}
catch|catch
parameter_list|(
name|IOException
name|ioe
parameter_list|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Exception during readTableDecriptor. Current table name = "
operator|+
name|tablename
argument_list|,
name|ioe
argument_list|)
expr_stmt|;
block|}
comment|// last HTD written wins
if|if
condition|(
name|usecache
operator|&&
name|tdmt
operator|!=
literal|null
condition|)
block|{
name|this
operator|.
name|cache
operator|.
name|put
argument_list|(
name|tablename
argument_list|,
name|tdmt
argument_list|)
expr_stmt|;
block|}
return|return
name|tdmt
return|;
block|}
comment|/**    * Returns a map from table name to table descriptor for all tables.    */
annotation|@
name|Override
specifier|public
name|Map
argument_list|<
name|String
argument_list|,
name|TableDescriptor
argument_list|>
name|getAll
parameter_list|()
throws|throws
name|IOException
block|{
name|Map
argument_list|<
name|String
argument_list|,
name|TableDescriptor
argument_list|>
name|tds
init|=
operator|new
name|TreeMap
argument_list|<>
argument_list|()
decl_stmt|;
if|if
condition|(
name|fsvisited
operator|&&
name|usecache
condition|)
block|{
for|for
control|(
name|Map
operator|.
name|Entry
argument_list|<
name|TableName
argument_list|,
name|TableDescriptor
argument_list|>
name|entry
range|:
name|this
operator|.
name|cache
operator|.
name|entrySet
argument_list|()
control|)
block|{
name|tds
operator|.
name|put
argument_list|(
name|entry
operator|.
name|getKey
argument_list|()
operator|.
name|getNameWithNamespaceInclAsString
argument_list|()
argument_list|,
name|entry
operator|.
name|getValue
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
name|LOG
operator|.
name|trace
argument_list|(
literal|"Fetching table descriptors from the filesystem."
argument_list|)
expr_stmt|;
name|boolean
name|allvisited
init|=
literal|true
decl_stmt|;
for|for
control|(
name|Path
name|d
range|:
name|FSUtils
operator|.
name|getTableDirs
argument_list|(
name|fs
argument_list|,
name|rootdir
argument_list|)
control|)
block|{
name|TableDescriptor
name|htd
init|=
literal|null
decl_stmt|;
try|try
block|{
name|htd
operator|=
name|get
argument_list|(
name|FSUtils
operator|.
name|getTableName
argument_list|(
name|d
argument_list|)
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|FileNotFoundException
name|fnfe
parameter_list|)
block|{
comment|// inability of retrieving one HTD shouldn't stop getting the remaining
name|LOG
operator|.
name|warn
argument_list|(
literal|"Trouble retrieving htd"
argument_list|,
name|fnfe
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|htd
operator|==
literal|null
condition|)
block|{
name|allvisited
operator|=
literal|false
expr_stmt|;
continue|continue;
block|}
else|else
block|{
name|tds
operator|.
name|put
argument_list|(
name|htd
operator|.
name|getTableName
argument_list|()
operator|.
name|getNameWithNamespaceInclAsString
argument_list|()
argument_list|,
name|htd
argument_list|)
expr_stmt|;
block|}
name|fsvisited
operator|=
name|allvisited
expr_stmt|;
block|}
block|}
return|return
name|tds
return|;
block|}
comment|/**     * Find descriptors by namespace.     * @see #get(org.apache.hadoop.hbase.TableName)     */
annotation|@
name|Override
specifier|public
name|Map
argument_list|<
name|String
argument_list|,
name|TableDescriptor
argument_list|>
name|getByNamespace
parameter_list|(
name|String
name|name
parameter_list|)
throws|throws
name|IOException
block|{
name|Map
argument_list|<
name|String
argument_list|,
name|TableDescriptor
argument_list|>
name|htds
init|=
operator|new
name|TreeMap
argument_list|<>
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|Path
argument_list|>
name|tableDirs
init|=
name|FSUtils
operator|.
name|getLocalTableDirs
argument_list|(
name|fs
argument_list|,
name|FSUtils
operator|.
name|getNamespaceDir
argument_list|(
name|rootdir
argument_list|,
name|name
argument_list|)
argument_list|)
decl_stmt|;
for|for
control|(
name|Path
name|d
range|:
name|tableDirs
control|)
block|{
name|TableDescriptor
name|htd
init|=
literal|null
decl_stmt|;
try|try
block|{
name|htd
operator|=
name|get
argument_list|(
name|FSUtils
operator|.
name|getTableName
argument_list|(
name|d
argument_list|)
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|FileNotFoundException
name|fnfe
parameter_list|)
block|{
comment|// inability of retrieving one HTD shouldn't stop getting the remaining
name|LOG
operator|.
name|warn
argument_list|(
literal|"Trouble retrieving htd"
argument_list|,
name|fnfe
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|htd
operator|==
literal|null
condition|)
continue|continue;
name|htds
operator|.
name|put
argument_list|(
name|FSUtils
operator|.
name|getTableName
argument_list|(
name|d
argument_list|)
operator|.
name|getNameAsString
argument_list|()
argument_list|,
name|htd
argument_list|)
expr_stmt|;
block|}
return|return
name|htds
return|;
block|}
comment|/**    * Adds (or updates) the table descriptor to the FileSystem    * and updates the local cache with it.    */
annotation|@
name|Override
specifier|public
name|void
name|update
parameter_list|(
name|TableDescriptor
name|htd
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|fsreadonly
condition|)
block|{
throw|throw
operator|new
name|NotImplementedException
argument_list|(
literal|"Cannot add a table descriptor - in read only mode"
argument_list|)
throw|;
block|}
name|updateTableDescriptor
argument_list|(
name|htd
argument_list|)
expr_stmt|;
block|}
comment|/**    * Removes the table descriptor from the local cache and returns it.    * If not in read only mode, it also deletes the entire table directory(!)    * from the FileSystem.    */
annotation|@
name|Override
specifier|public
name|TableDescriptor
name|remove
parameter_list|(
specifier|final
name|TableName
name|tablename
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|fsreadonly
condition|)
block|{
throw|throw
operator|new
name|NotImplementedException
argument_list|(
literal|"Cannot remove a table descriptor - in read only mode"
argument_list|)
throw|;
block|}
name|Path
name|tabledir
init|=
name|getTableDir
argument_list|(
name|tablename
argument_list|)
decl_stmt|;
if|if
condition|(
name|this
operator|.
name|fs
operator|.
name|exists
argument_list|(
name|tabledir
argument_list|)
condition|)
block|{
if|if
condition|(
operator|!
name|this
operator|.
name|fs
operator|.
name|delete
argument_list|(
name|tabledir
argument_list|,
literal|true
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Failed delete of "
operator|+
name|tabledir
operator|.
name|toString
argument_list|()
argument_list|)
throw|;
block|}
block|}
name|TableDescriptor
name|descriptor
init|=
name|this
operator|.
name|cache
operator|.
name|remove
argument_list|(
name|tablename
argument_list|)
decl_stmt|;
return|return
name|descriptor
return|;
block|}
specifier|private
name|FileStatus
name|getTableInfoPath
parameter_list|(
name|Path
name|tableDir
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|getTableInfoPath
argument_list|(
name|fs
argument_list|,
name|tableDir
argument_list|,
operator|!
name|fsreadonly
argument_list|)
return|;
block|}
comment|/**    * Find the most current table info file for the table located in the given table directory.    *    * Looks within the {@link #TABLEINFO_DIR} subdirectory of the given directory for any table info    * files and takes the 'current' one - meaning the one with the highest sequence number if present    * or no sequence number at all if none exist (for backward compatibility from before there    * were sequence numbers).    *    * @return The file status of the current table info file or null if it does not exist    */
specifier|public
specifier|static
name|FileStatus
name|getTableInfoPath
parameter_list|(
name|FileSystem
name|fs
parameter_list|,
name|Path
name|tableDir
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|getTableInfoPath
argument_list|(
name|fs
argument_list|,
name|tableDir
argument_list|,
literal|false
argument_list|)
return|;
block|}
comment|/**    * Find the most current table info file for the table in the given table directory.    *    * Looks within the {@link #TABLEINFO_DIR} subdirectory of the given directory for any table info    * files and takes the 'current' one - meaning the one with the highest sequence number if    * present or no sequence number at all if none exist (for backward compatibility from before    * there were sequence numbers).    * If there are multiple table info files found and removeOldFiles is true it also deletes the    * older files.    *    * @return The file status of the current table info file or null if none exist    */
specifier|private
specifier|static
name|FileStatus
name|getTableInfoPath
parameter_list|(
name|FileSystem
name|fs
parameter_list|,
name|Path
name|tableDir
parameter_list|,
name|boolean
name|removeOldFiles
parameter_list|)
throws|throws
name|IOException
block|{
name|Path
name|tableInfoDir
init|=
operator|new
name|Path
argument_list|(
name|tableDir
argument_list|,
name|TABLEINFO_DIR
argument_list|)
decl_stmt|;
return|return
name|getCurrentTableInfoStatus
argument_list|(
name|fs
argument_list|,
name|tableInfoDir
argument_list|,
name|removeOldFiles
argument_list|)
return|;
block|}
comment|/**    * Find the most current table info file in the given directory    *    * Looks within the given directory for any table info files    * and takes the 'current' one - meaning the one with the highest sequence number if present    * or no sequence number at all if none exist (for backward compatibility from before there    * were sequence numbers).    * If there are multiple possible files found    * and the we're not in read only mode it also deletes the older files.    *    * @return The file status of the current table info file or null if it does not exist    * @throws IOException    */
comment|// only visible for FSTableDescriptorMigrationToSubdir, can be removed with that
specifier|static
name|FileStatus
name|getCurrentTableInfoStatus
parameter_list|(
name|FileSystem
name|fs
parameter_list|,
name|Path
name|dir
parameter_list|,
name|boolean
name|removeOldFiles
parameter_list|)
throws|throws
name|IOException
block|{
name|FileStatus
index|[]
name|status
init|=
name|FSUtils
operator|.
name|listStatus
argument_list|(
name|fs
argument_list|,
name|dir
argument_list|,
name|TABLEINFO_PATHFILTER
argument_list|)
decl_stmt|;
if|if
condition|(
name|status
operator|==
literal|null
operator|||
name|status
operator|.
name|length
operator|<
literal|1
condition|)
return|return
literal|null
return|;
name|FileStatus
name|mostCurrent
init|=
literal|null
decl_stmt|;
for|for
control|(
name|FileStatus
name|file
range|:
name|status
control|)
block|{
if|if
condition|(
name|mostCurrent
operator|==
literal|null
operator|||
name|TABLEINFO_FILESTATUS_COMPARATOR
operator|.
name|compare
argument_list|(
name|file
argument_list|,
name|mostCurrent
argument_list|)
operator|<
literal|0
condition|)
block|{
name|mostCurrent
operator|=
name|file
expr_stmt|;
block|}
block|}
if|if
condition|(
name|removeOldFiles
operator|&&
name|status
operator|.
name|length
operator|>
literal|1
condition|)
block|{
comment|// Clean away old versions
for|for
control|(
name|FileStatus
name|file
range|:
name|status
control|)
block|{
name|Path
name|path
init|=
name|file
operator|.
name|getPath
argument_list|()
decl_stmt|;
if|if
condition|(
operator|!
name|file
operator|.
name|equals
argument_list|(
name|mostCurrent
argument_list|)
condition|)
block|{
if|if
condition|(
operator|!
name|fs
operator|.
name|delete
argument_list|(
name|file
operator|.
name|getPath
argument_list|()
argument_list|,
literal|false
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failed cleanup of "
operator|+
name|path
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Cleaned up old tableinfo file "
operator|+
name|path
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
return|return
name|mostCurrent
return|;
block|}
comment|/**    * Compare {@link FileStatus} instances by {@link Path#getName()}. Returns in    * reverse order.    */
annotation|@
name|VisibleForTesting
specifier|static
specifier|final
name|Comparator
argument_list|<
name|FileStatus
argument_list|>
name|TABLEINFO_FILESTATUS_COMPARATOR
init|=
operator|new
name|Comparator
argument_list|<
name|FileStatus
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|int
name|compare
parameter_list|(
name|FileStatus
name|left
parameter_list|,
name|FileStatus
name|right
parameter_list|)
block|{
return|return
name|right
operator|.
name|compareTo
argument_list|(
name|left
argument_list|)
return|;
block|}
block|}
decl_stmt|;
comment|/**    * Return the table directory in HDFS    */
annotation|@
name|VisibleForTesting
name|Path
name|getTableDir
parameter_list|(
specifier|final
name|TableName
name|tableName
parameter_list|)
block|{
return|return
name|FSUtils
operator|.
name|getTableDir
argument_list|(
name|rootdir
argument_list|,
name|tableName
argument_list|)
return|;
block|}
specifier|private
specifier|static
specifier|final
name|PathFilter
name|TABLEINFO_PATHFILTER
init|=
operator|new
name|PathFilter
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|boolean
name|accept
parameter_list|(
name|Path
name|p
parameter_list|)
block|{
comment|// Accept any file that starts with TABLEINFO_NAME
return|return
name|p
operator|.
name|getName
argument_list|()
operator|.
name|startsWith
argument_list|(
name|TABLEINFO_FILE_PREFIX
argument_list|)
return|;
block|}
block|}
decl_stmt|;
comment|/**    * Width of the sequenceid that is a suffix on a tableinfo file.    */
annotation|@
name|VisibleForTesting
specifier|static
specifier|final
name|int
name|WIDTH_OF_SEQUENCE_ID
init|=
literal|10
decl_stmt|;
comment|/*    * @param number Number to use as suffix.    * @return Returns zero-prefixed decimal version of passed    * number (Does absolute in case number is negative).    */
specifier|private
specifier|static
name|String
name|formatTableInfoSequenceId
parameter_list|(
specifier|final
name|int
name|number
parameter_list|)
block|{
name|byte
index|[]
name|b
init|=
operator|new
name|byte
index|[
name|WIDTH_OF_SEQUENCE_ID
index|]
decl_stmt|;
name|int
name|d
init|=
name|Math
operator|.
name|abs
argument_list|(
name|number
argument_list|)
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
name|b
operator|.
name|length
operator|-
literal|1
init|;
name|i
operator|>=
literal|0
condition|;
name|i
operator|--
control|)
block|{
name|b
index|[
name|i
index|]
operator|=
call|(
name|byte
call|)
argument_list|(
operator|(
name|d
operator|%
literal|10
operator|)
operator|+
literal|'0'
argument_list|)
expr_stmt|;
name|d
operator|/=
literal|10
expr_stmt|;
block|}
return|return
name|Bytes
operator|.
name|toString
argument_list|(
name|b
argument_list|)
return|;
block|}
comment|/**    * Regex to eat up sequenceid suffix on a .tableinfo file.    * Use regex because may encounter oldstyle .tableinfos where there is no    * sequenceid on the end.    */
specifier|private
specifier|static
specifier|final
name|Pattern
name|TABLEINFO_FILE_REGEX
init|=
name|Pattern
operator|.
name|compile
argument_list|(
name|TABLEINFO_FILE_PREFIX
operator|+
literal|"(\\.([0-9]{"
operator|+
name|WIDTH_OF_SEQUENCE_ID
operator|+
literal|"}))?$"
argument_list|)
decl_stmt|;
comment|/**    * @param p Path to a<code>.tableinfo</code> file.    * @return The current editid or 0 if none found.    */
annotation|@
name|VisibleForTesting
specifier|static
name|int
name|getTableInfoSequenceId
parameter_list|(
specifier|final
name|Path
name|p
parameter_list|)
block|{
if|if
condition|(
name|p
operator|==
literal|null
condition|)
return|return
literal|0
return|;
name|Matcher
name|m
init|=
name|TABLEINFO_FILE_REGEX
operator|.
name|matcher
argument_list|(
name|p
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|m
operator|.
name|matches
argument_list|()
condition|)
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
name|p
operator|.
name|toString
argument_list|()
argument_list|)
throw|;
name|String
name|suffix
init|=
name|m
operator|.
name|group
argument_list|(
literal|2
argument_list|)
decl_stmt|;
if|if
condition|(
name|suffix
operator|==
literal|null
operator|||
name|suffix
operator|.
name|length
argument_list|()
operator|<=
literal|0
condition|)
return|return
literal|0
return|;
return|return
name|Integer
operator|.
name|parseInt
argument_list|(
name|m
operator|.
name|group
argument_list|(
literal|2
argument_list|)
argument_list|)
return|;
block|}
comment|/**    * @param sequenceid    * @return Name of tableinfo file.    */
annotation|@
name|VisibleForTesting
specifier|static
name|String
name|getTableInfoFileName
parameter_list|(
specifier|final
name|int
name|sequenceid
parameter_list|)
block|{
return|return
name|TABLEINFO_FILE_PREFIX
operator|+
literal|"."
operator|+
name|formatTableInfoSequenceId
argument_list|(
name|sequenceid
argument_list|)
return|;
block|}
comment|/**    * Returns the latest table descriptor for the given table directly from the file system    * if it exists, bypassing the local cache.    * Returns null if it's not found.    */
specifier|public
specifier|static
name|TableDescriptor
name|getTableDescriptorFromFs
parameter_list|(
name|FileSystem
name|fs
parameter_list|,
name|Path
name|hbaseRootDir
parameter_list|,
name|TableName
name|tableName
parameter_list|)
throws|throws
name|IOException
block|{
name|Path
name|tableDir
init|=
name|FSUtils
operator|.
name|getTableDir
argument_list|(
name|hbaseRootDir
argument_list|,
name|tableName
argument_list|)
decl_stmt|;
return|return
name|getTableDescriptorFromFs
argument_list|(
name|fs
argument_list|,
name|tableDir
argument_list|)
return|;
block|}
comment|/**    * Returns the latest table descriptor for the table located at the given directory    * directly from the file system if it exists.    * @throws TableInfoMissingException if there is no descriptor    */
specifier|public
specifier|static
name|TableDescriptor
name|getTableDescriptorFromFs
parameter_list|(
name|FileSystem
name|fs
parameter_list|,
name|Path
name|tableDir
parameter_list|)
throws|throws
name|IOException
block|{
name|FileStatus
name|status
init|=
name|getTableInfoPath
argument_list|(
name|fs
argument_list|,
name|tableDir
argument_list|,
literal|false
argument_list|)
decl_stmt|;
if|if
condition|(
name|status
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|TableInfoMissingException
argument_list|(
literal|"No table descriptor file under "
operator|+
name|tableDir
argument_list|)
throw|;
block|}
return|return
name|readTableDescriptor
argument_list|(
name|fs
argument_list|,
name|status
argument_list|)
return|;
block|}
specifier|private
specifier|static
name|TableDescriptor
name|readTableDescriptor
parameter_list|(
name|FileSystem
name|fs
parameter_list|,
name|FileStatus
name|status
parameter_list|)
throws|throws
name|IOException
block|{
name|int
name|len
init|=
name|Ints
operator|.
name|checkedCast
argument_list|(
name|status
operator|.
name|getLen
argument_list|()
argument_list|)
decl_stmt|;
name|byte
index|[]
name|content
init|=
operator|new
name|byte
index|[
name|len
index|]
decl_stmt|;
name|FSDataInputStream
name|fsDataInputStream
init|=
name|fs
operator|.
name|open
argument_list|(
name|status
operator|.
name|getPath
argument_list|()
argument_list|)
decl_stmt|;
try|try
block|{
name|fsDataInputStream
operator|.
name|readFully
argument_list|(
name|content
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|fsDataInputStream
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
name|TableDescriptor
name|htd
init|=
literal|null
decl_stmt|;
try|try
block|{
name|htd
operator|=
name|TableDescriptorBuilder
operator|.
name|parseFrom
argument_list|(
name|content
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|DeserializationException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"content="
operator|+
name|Bytes
operator|.
name|toShort
argument_list|(
name|content
argument_list|)
argument_list|,
name|e
argument_list|)
throw|;
block|}
return|return
name|htd
return|;
block|}
comment|/**    * Update table descriptor on the file system    * @throws IOException Thrown if failed update.    * @throws NotImplementedException if in read only mode    */
annotation|@
name|VisibleForTesting
name|Path
name|updateTableDescriptor
parameter_list|(
name|TableDescriptor
name|td
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|fsreadonly
condition|)
block|{
throw|throw
operator|new
name|NotImplementedException
argument_list|(
literal|"Cannot update a table descriptor - in read only mode"
argument_list|)
throw|;
block|}
name|TableName
name|tableName
init|=
name|td
operator|.
name|getTableName
argument_list|()
decl_stmt|;
name|Path
name|tableDir
init|=
name|getTableDir
argument_list|(
name|tableName
argument_list|)
decl_stmt|;
name|Path
name|p
init|=
name|writeTableDescriptor
argument_list|(
name|fs
argument_list|,
name|td
argument_list|,
name|tableDir
argument_list|,
name|getTableInfoPath
argument_list|(
name|tableDir
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|p
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Failed update"
argument_list|)
throw|;
block|}
name|LOG
operator|.
name|info
argument_list|(
literal|"Updated tableinfo="
operator|+
name|p
argument_list|)
expr_stmt|;
if|if
condition|(
name|usecache
condition|)
block|{
name|this
operator|.
name|cache
operator|.
name|put
argument_list|(
name|td
operator|.
name|getTableName
argument_list|()
argument_list|,
name|td
argument_list|)
expr_stmt|;
block|}
return|return
name|p
return|;
block|}
comment|/**    * Deletes files matching the table info file pattern within the given directory    * whose sequenceId is at most the given max sequenceId.    */
specifier|private
specifier|static
name|void
name|deleteTableDescriptorFiles
parameter_list|(
name|FileSystem
name|fs
parameter_list|,
name|Path
name|dir
parameter_list|,
name|int
name|maxSequenceId
parameter_list|)
throws|throws
name|IOException
block|{
name|FileStatus
index|[]
name|status
init|=
name|FSUtils
operator|.
name|listStatus
argument_list|(
name|fs
argument_list|,
name|dir
argument_list|,
name|TABLEINFO_PATHFILTER
argument_list|)
decl_stmt|;
for|for
control|(
name|FileStatus
name|file
range|:
name|status
control|)
block|{
name|Path
name|path
init|=
name|file
operator|.
name|getPath
argument_list|()
decl_stmt|;
name|int
name|sequenceId
init|=
name|getTableInfoSequenceId
argument_list|(
name|path
argument_list|)
decl_stmt|;
if|if
condition|(
name|sequenceId
operator|<=
name|maxSequenceId
condition|)
block|{
name|boolean
name|success
init|=
name|FSUtils
operator|.
name|delete
argument_list|(
name|fs
argument_list|,
name|path
argument_list|,
literal|false
argument_list|)
decl_stmt|;
if|if
condition|(
name|success
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Deleted "
operator|+
name|path
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Failed to delete table descriptor at "
operator|+
name|path
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
comment|/**    * Attempts to write a new table descriptor to the given table's directory.    * It first writes it to the .tmp dir then uses an atomic rename to move it into place.    * It begins at the currentSequenceId + 1 and tries 10 times to find a new sequence number    * not already in use.    * Removes the current descriptor file if passed in.    *    * @return Descriptor file or null if we failed write.    */
specifier|private
specifier|static
name|Path
name|writeTableDescriptor
parameter_list|(
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|TableDescriptor
name|htd
parameter_list|,
specifier|final
name|Path
name|tableDir
parameter_list|,
specifier|final
name|FileStatus
name|currentDescriptorFile
parameter_list|)
throws|throws
name|IOException
block|{
comment|// Get temporary dir into which we'll first write a file to avoid half-written file phenomenon.
comment|// This directory is never removed to avoid removing it out from under a concurrent writer.
name|Path
name|tmpTableDir
init|=
operator|new
name|Path
argument_list|(
name|tableDir
argument_list|,
name|TMP_DIR
argument_list|)
decl_stmt|;
name|Path
name|tableInfoDir
init|=
operator|new
name|Path
argument_list|(
name|tableDir
argument_list|,
name|TABLEINFO_DIR
argument_list|)
decl_stmt|;
comment|// What is current sequenceid?  We read the current sequenceid from
comment|// the current file.  After we read it, another thread could come in and
comment|// compete with us writing out next version of file.  The below retries
comment|// should help in this case some but its hard to do guarantees in face of
comment|// concurrent schema edits.
name|int
name|currentSequenceId
init|=
name|currentDescriptorFile
operator|==
literal|null
condition|?
literal|0
else|:
name|getTableInfoSequenceId
argument_list|(
name|currentDescriptorFile
operator|.
name|getPath
argument_list|()
argument_list|)
decl_stmt|;
name|int
name|newSequenceId
init|=
name|currentSequenceId
decl_stmt|;
comment|// Put arbitrary upperbound on how often we retry
name|int
name|retries
init|=
literal|10
decl_stmt|;
name|int
name|retrymax
init|=
name|currentSequenceId
operator|+
name|retries
decl_stmt|;
name|Path
name|tableInfoDirPath
init|=
literal|null
decl_stmt|;
do|do
block|{
name|newSequenceId
operator|+=
literal|1
expr_stmt|;
name|String
name|filename
init|=
name|getTableInfoFileName
argument_list|(
name|newSequenceId
argument_list|)
decl_stmt|;
name|Path
name|tempPath
init|=
operator|new
name|Path
argument_list|(
name|tmpTableDir
argument_list|,
name|filename
argument_list|)
decl_stmt|;
if|if
condition|(
name|fs
operator|.
name|exists
argument_list|(
name|tempPath
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
name|tempPath
operator|+
literal|" exists; retrying up to "
operator|+
name|retries
operator|+
literal|" times"
argument_list|)
expr_stmt|;
continue|continue;
block|}
name|tableInfoDirPath
operator|=
operator|new
name|Path
argument_list|(
name|tableInfoDir
argument_list|,
name|filename
argument_list|)
expr_stmt|;
try|try
block|{
name|writeTD
argument_list|(
name|fs
argument_list|,
name|tempPath
argument_list|,
name|htd
argument_list|)
expr_stmt|;
name|fs
operator|.
name|mkdirs
argument_list|(
name|tableInfoDirPath
operator|.
name|getParent
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|fs
operator|.
name|rename
argument_list|(
name|tempPath
argument_list|,
name|tableInfoDirPath
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Failed rename of "
operator|+
name|tempPath
operator|+
literal|" to "
operator|+
name|tableInfoDirPath
argument_list|)
throw|;
block|}
name|LOG
operator|.
name|debug
argument_list|(
literal|"Wrote into "
operator|+
name|tableInfoDirPath
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ioe
parameter_list|)
block|{
comment|// Presume clash of names or something; go around again.
name|LOG
operator|.
name|debug
argument_list|(
literal|"Failed write and/or rename; retrying"
argument_list|,
name|ioe
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|FSUtils
operator|.
name|deleteDirectory
argument_list|(
name|fs
argument_list|,
name|tempPath
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failed cleanup of "
operator|+
name|tempPath
argument_list|)
expr_stmt|;
block|}
name|tableInfoDirPath
operator|=
literal|null
expr_stmt|;
continue|continue;
block|}
break|break;
block|}
do|while
condition|(
name|newSequenceId
operator|<
name|retrymax
condition|)
do|;
if|if
condition|(
name|tableInfoDirPath
operator|!=
literal|null
condition|)
block|{
comment|// if we succeeded, remove old table info files.
name|deleteTableDescriptorFiles
argument_list|(
name|fs
argument_list|,
name|tableInfoDir
argument_list|,
name|newSequenceId
operator|-
literal|1
argument_list|)
expr_stmt|;
block|}
return|return
name|tableInfoDirPath
return|;
block|}
specifier|private
specifier|static
name|void
name|writeTD
parameter_list|(
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Path
name|p
parameter_list|,
specifier|final
name|TableDescriptor
name|htd
parameter_list|)
throws|throws
name|IOException
block|{
name|FSDataOutputStream
name|out
init|=
name|fs
operator|.
name|create
argument_list|(
name|p
argument_list|,
literal|false
argument_list|)
decl_stmt|;
try|try
block|{
comment|// We used to write this file out as a serialized HTD Writable followed by two '\n's and then
comment|// the toString version of HTD.  Now we just write out the pb serialization.
name|out
operator|.
name|write
argument_list|(
name|TableDescriptorBuilder
operator|.
name|toByteArray
argument_list|(
name|htd
argument_list|)
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|out
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**    * Create new TableDescriptor in HDFS. Happens when we are creating table.    * Used by tests.    * @return True if we successfully created file.    */
specifier|public
name|boolean
name|createTableDescriptor
parameter_list|(
name|TableDescriptor
name|htd
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|createTableDescriptor
argument_list|(
name|htd
argument_list|,
literal|false
argument_list|)
return|;
block|}
comment|/**    * Create new TableDescriptor in HDFS. Happens when we are creating table. If    * forceCreation is true then even if previous table descriptor is present it    * will be overwritten    *    * @return True if we successfully created file.    */
specifier|public
name|boolean
name|createTableDescriptor
parameter_list|(
name|TableDescriptor
name|htd
parameter_list|,
name|boolean
name|forceCreation
parameter_list|)
throws|throws
name|IOException
block|{
name|Path
name|tableDir
init|=
name|getTableDir
argument_list|(
name|htd
operator|.
name|getTableName
argument_list|()
argument_list|)
decl_stmt|;
return|return
name|createTableDescriptorForTableDirectory
argument_list|(
name|tableDir
argument_list|,
name|htd
argument_list|,
name|forceCreation
argument_list|)
return|;
block|}
comment|/**    * Create a new TableDescriptor in HDFS in the specified table directory. Happens when we create    * a new table during cluster start or in Clone and Create Table Procedures. Checks readOnly flag    * passed on construction.    * @param tableDir table directory under which we should write the file    * @param htd description of the table to write    * @param forceCreation if<tt>true</tt>,then even if previous table descriptor is present it will    *          be overwritten    * @return<tt>true</tt> if the we successfully created the file,<tt>false</tt> if the file    *         already exists and we weren't forcing the descriptor creation.    * @throws IOException if a filesystem error occurs    */
specifier|public
name|boolean
name|createTableDescriptorForTableDirectory
parameter_list|(
name|Path
name|tableDir
parameter_list|,
name|TableDescriptor
name|htd
parameter_list|,
name|boolean
name|forceCreation
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|this
operator|.
name|fsreadonly
condition|)
block|{
throw|throw
operator|new
name|NotImplementedException
argument_list|(
literal|"Cannot create a table descriptor - in read only mode"
argument_list|)
throw|;
block|}
return|return
name|createTableDescriptorForTableDirectory
argument_list|(
name|this
operator|.
name|fs
argument_list|,
name|tableDir
argument_list|,
name|htd
argument_list|,
name|forceCreation
argument_list|)
return|;
block|}
comment|/**    * Create a new TableDescriptor in HDFS in the specified table directory. Happens when we create    * a new table snapshoting. Does not enforce read-only. That is for caller to determine.    * @param fs Filesystem to use.    * @param tableDir table directory under which we should write the file    * @param htd description of the table to write    * @param forceCreation if<tt>true</tt>,then even if previous table descriptor is present it will    *          be overwritten    * @return<tt>true</tt> if the we successfully created the file,<tt>false</tt> if the file    *         already exists and we weren't forcing the descriptor creation.    * @throws IOException if a filesystem error occurs    */
specifier|public
specifier|static
name|boolean
name|createTableDescriptorForTableDirectory
parameter_list|(
name|FileSystem
name|fs
parameter_list|,
name|Path
name|tableDir
parameter_list|,
name|TableDescriptor
name|htd
parameter_list|,
name|boolean
name|forceCreation
parameter_list|)
throws|throws
name|IOException
block|{
name|FileStatus
name|status
init|=
name|getTableInfoPath
argument_list|(
name|fs
argument_list|,
name|tableDir
argument_list|)
decl_stmt|;
if|if
condition|(
name|status
operator|!=
literal|null
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Current path="
operator|+
name|status
operator|.
name|getPath
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|forceCreation
condition|)
block|{
if|if
condition|(
name|fs
operator|.
name|exists
argument_list|(
name|status
operator|.
name|getPath
argument_list|()
argument_list|)
operator|&&
name|status
operator|.
name|getLen
argument_list|()
operator|>
literal|0
condition|)
block|{
if|if
condition|(
name|readTableDescriptor
argument_list|(
name|fs
argument_list|,
name|status
argument_list|)
operator|.
name|equals
argument_list|(
name|htd
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|trace
argument_list|(
literal|"TableInfo already exists.. Skipping creation"
argument_list|)
expr_stmt|;
return|return
literal|false
return|;
block|}
block|}
block|}
block|}
return|return
name|writeTableDescriptor
argument_list|(
name|fs
argument_list|,
name|htd
argument_list|,
name|tableDir
argument_list|,
name|status
argument_list|)
operator|!=
literal|null
return|;
block|}
block|}
end_class

end_unit

