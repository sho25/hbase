begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/*  *  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|InterruptedIOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|InetSocketAddress
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collection
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collections
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Iterator
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
operator|.
name|Entry
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|NavigableSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Optional
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|OptionalDouble
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|OptionalInt
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|OptionalLong
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Set
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|Callable
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|CompletionService
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ConcurrentHashMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ExecutionException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ExecutorCompletionService
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|Future
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ThreadPoolExecutor
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|atomic
operator|.
name|AtomicBoolean
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|atomic
operator|.
name|AtomicInteger
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|atomic
operator|.
name|AtomicLong
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|locks
operator|.
name|ReentrantLock
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|locks
operator|.
name|ReentrantReadWriteLock
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|function
operator|.
name|Predicate
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|function
operator|.
name|ToLongFunction
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|stream
operator|.
name|Collectors
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|stream
operator|.
name|LongStream
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|permission
operator|.
name|FsAction
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|Cell
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|CellComparator
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|CellUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|CompoundConfiguration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HConstants
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|MemoryCompactionPolicy
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|TableName
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|backup
operator|.
name|FailedArchiveException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|ColumnFamilyDescriptor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|RegionInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|Scan
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|conf
operator|.
name|ConfigurationManager
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|conf
operator|.
name|PropagatingConfigurationObserver
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|HeapSize
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|compress
operator|.
name|Compression
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|crypto
operator|.
name|Encryption
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|hfile
operator|.
name|CacheConfig
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|hfile
operator|.
name|HFile
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|hfile
operator|.
name|HFileContext
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|hfile
operator|.
name|HFileContextBuilder
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|hfile
operator|.
name|HFileDataBlockEncoder
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|hfile
operator|.
name|HFileDataBlockEncoderImpl
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|hfile
operator|.
name|HFileScanner
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|hfile
operator|.
name|InvalidHFileException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|log
operator|.
name|HBaseMarkers
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|monitoring
operator|.
name|MonitoredTask
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|quotas
operator|.
name|RegionSizeStore
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|compactions
operator|.
name|CompactionContext
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|compactions
operator|.
name|CompactionLifeCycleTracker
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|compactions
operator|.
name|CompactionProgress
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|compactions
operator|.
name|CompactionRequestImpl
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|compactions
operator|.
name|DefaultCompactor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|compactions
operator|.
name|OffPeakHours
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|querymatcher
operator|.
name|ScanQueryMatcher
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|throttle
operator|.
name|ThroughputController
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|wal
operator|.
name|WALUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|security
operator|.
name|EncryptionUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|security
operator|.
name|User
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|Bytes
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|ChecksumType
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|ClassSize
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|EnvironmentEdgeManager
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|Pair
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|ReflectionUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|StringUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|StringUtils
operator|.
name|TraditionalBinaryPrefix
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|yetus
operator|.
name|audience
operator|.
name|InterfaceAudience
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|Logger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|slf4j
operator|.
name|LoggerFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hbase
operator|.
name|thirdparty
operator|.
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|annotations
operator|.
name|VisibleForTesting
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hbase
operator|.
name|thirdparty
operator|.
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Preconditions
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hbase
operator|.
name|thirdparty
operator|.
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|ImmutableCollection
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hbase
operator|.
name|thirdparty
operator|.
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|ImmutableList
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hbase
operator|.
name|thirdparty
operator|.
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|Lists
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hbase
operator|.
name|thirdparty
operator|.
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|Maps
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hbase
operator|.
name|thirdparty
operator|.
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|Sets
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hbase
operator|.
name|thirdparty
operator|.
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|collections4
operator|.
name|CollectionUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hbase
operator|.
name|thirdparty
operator|.
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|collections4
operator|.
name|IterableUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|shaded
operator|.
name|protobuf
operator|.
name|ProtobufUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|shaded
operator|.
name|protobuf
operator|.
name|generated
operator|.
name|WALProtos
operator|.
name|CompactionDescriptor
import|;
end_import

begin_comment
comment|/**  * A Store holds a column family in a Region.  Its a memstore and a set of zero  * or more StoreFiles, which stretch backwards over time.  *  *<p>There's no reason to consider append-logging at this level; all logging  * and locking is handled at the HRegion level.  Store just provides  * services to manage sets of StoreFiles.  One of the most important of those  * services is compaction services where files are aggregated once they pass  * a configurable threshold.  *  *<p>Locking and transactions are handled at a higher level.  This API should  * not be called directly but by an HRegion manager.  */
end_comment

begin_class
annotation|@
name|InterfaceAudience
operator|.
name|Private
specifier|public
class|class
name|HStore
implements|implements
name|Store
implements|,
name|HeapSize
implements|,
name|StoreConfigInformation
implements|,
name|PropagatingConfigurationObserver
block|{
specifier|public
specifier|static
specifier|final
name|String
name|MEMSTORE_CLASS_NAME
init|=
literal|"hbase.regionserver.memstore.class"
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|String
name|COMPACTCHECKER_INTERVAL_MULTIPLIER_KEY
init|=
literal|"hbase.server.compactchecker.interval.multiplier"
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|String
name|BLOCKING_STOREFILES_KEY
init|=
literal|"hbase.hstore.blockingStoreFiles"
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|String
name|BLOCK_STORAGE_POLICY_KEY
init|=
literal|"hbase.hstore.block.storage.policy"
decl_stmt|;
comment|// keep in accordance with HDFS default storage policy
specifier|public
specifier|static
specifier|final
name|String
name|DEFAULT_BLOCK_STORAGE_POLICY
init|=
literal|"HOT"
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|int
name|DEFAULT_COMPACTCHECKER_INTERVAL_MULTIPLIER
init|=
literal|1000
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|int
name|DEFAULT_BLOCKING_STOREFILE_COUNT
init|=
literal|16
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|Logger
name|LOG
init|=
name|LoggerFactory
operator|.
name|getLogger
argument_list|(
name|HStore
operator|.
name|class
argument_list|)
decl_stmt|;
specifier|protected
specifier|final
name|MemStore
name|memstore
decl_stmt|;
comment|// This stores directory in the filesystem.
specifier|protected
specifier|final
name|HRegion
name|region
decl_stmt|;
specifier|private
specifier|final
name|ColumnFamilyDescriptor
name|family
decl_stmt|;
specifier|private
specifier|final
name|HRegionFileSystem
name|fs
decl_stmt|;
specifier|protected
name|Configuration
name|conf
decl_stmt|;
specifier|protected
name|CacheConfig
name|cacheConf
decl_stmt|;
specifier|private
name|long
name|lastCompactSize
init|=
literal|0
decl_stmt|;
specifier|volatile
name|boolean
name|forceMajor
init|=
literal|false
decl_stmt|;
comment|/* how many bytes to write between status checks */
specifier|static
name|int
name|closeCheckInterval
init|=
literal|0
decl_stmt|;
specifier|private
name|AtomicLong
name|storeSize
init|=
operator|new
name|AtomicLong
argument_list|()
decl_stmt|;
specifier|private
name|AtomicLong
name|totalUncompressedBytes
init|=
operator|new
name|AtomicLong
argument_list|()
decl_stmt|;
specifier|private
name|boolean
name|cacheOnWriteLogged
decl_stmt|;
comment|/**    * RWLock for store operations.    * Locked in shared mode when the list of component stores is looked at:    *   - all reads/writes to table data    *   - checking for split    * Locked in exclusive mode when the list of component stores is modified:    *   - closing    *   - completing a compaction    */
specifier|final
name|ReentrantReadWriteLock
name|lock
init|=
operator|new
name|ReentrantReadWriteLock
argument_list|()
decl_stmt|;
comment|/**    * Lock specific to archiving compacted store files.  This avoids races around    * the combination of retrieving the list of compacted files and moving them to    * the archive directory.  Since this is usually a background process (other than    * on close), we don't want to handle this with the store write lock, which would    * block readers and degrade performance.    *    * Locked by:    *   - CompactedHFilesDispatchHandler via closeAndArchiveCompactedFiles()    *   - close()    */
specifier|final
name|ReentrantLock
name|archiveLock
init|=
operator|new
name|ReentrantLock
argument_list|()
decl_stmt|;
specifier|private
specifier|final
name|boolean
name|verifyBulkLoads
decl_stmt|;
comment|/**    * Use this counter to track concurrent puts. If TRACE-log is enabled, if we are over the    * threshold set by hbase.region.store.parallel.put.print.threshold (Default is 50) we will    * log a message that identifies the Store experience this high-level of concurrency.    */
specifier|private
specifier|final
name|AtomicInteger
name|currentParallelPutCount
init|=
operator|new
name|AtomicInteger
argument_list|(
literal|0
argument_list|)
decl_stmt|;
specifier|private
specifier|final
name|int
name|parallelPutCountPrintThreshold
decl_stmt|;
specifier|private
name|ScanInfo
name|scanInfo
decl_stmt|;
comment|// All access must be synchronized.
comment|// TODO: ideally, this should be part of storeFileManager, as we keep passing this to it.
specifier|private
specifier|final
name|List
argument_list|<
name|HStoreFile
argument_list|>
name|filesCompacting
init|=
name|Lists
operator|.
name|newArrayList
argument_list|()
decl_stmt|;
comment|// All access must be synchronized.
specifier|private
specifier|final
name|Set
argument_list|<
name|ChangedReadersObserver
argument_list|>
name|changedReaderObservers
init|=
name|Collections
operator|.
name|newSetFromMap
argument_list|(
operator|new
name|ConcurrentHashMap
argument_list|<
name|ChangedReadersObserver
argument_list|,
name|Boolean
argument_list|>
argument_list|()
argument_list|)
decl_stmt|;
specifier|protected
specifier|final
name|int
name|blocksize
decl_stmt|;
specifier|private
name|HFileDataBlockEncoder
name|dataBlockEncoder
decl_stmt|;
comment|/** Checksum configuration */
specifier|protected
name|ChecksumType
name|checksumType
decl_stmt|;
specifier|protected
name|int
name|bytesPerChecksum
decl_stmt|;
comment|// Comparing KeyValues
specifier|protected
specifier|final
name|CellComparator
name|comparator
decl_stmt|;
specifier|final
name|StoreEngine
argument_list|<
name|?
argument_list|,
name|?
argument_list|,
name|?
argument_list|,
name|?
argument_list|>
name|storeEngine
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|AtomicBoolean
name|offPeakCompactionTracker
init|=
operator|new
name|AtomicBoolean
argument_list|()
decl_stmt|;
specifier|private
specifier|volatile
name|OffPeakHours
name|offPeakHours
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|int
name|DEFAULT_FLUSH_RETRIES_NUMBER
init|=
literal|10
decl_stmt|;
specifier|private
name|int
name|flushRetriesNumber
decl_stmt|;
specifier|private
name|int
name|pauseTime
decl_stmt|;
specifier|private
name|long
name|blockingFileCount
decl_stmt|;
specifier|private
name|int
name|compactionCheckMultiplier
decl_stmt|;
specifier|protected
name|Encryption
operator|.
name|Context
name|cryptoContext
init|=
name|Encryption
operator|.
name|Context
operator|.
name|NONE
decl_stmt|;
specifier|private
name|AtomicLong
name|flushedCellsCount
init|=
operator|new
name|AtomicLong
argument_list|()
decl_stmt|;
specifier|private
name|AtomicLong
name|compactedCellsCount
init|=
operator|new
name|AtomicLong
argument_list|()
decl_stmt|;
specifier|private
name|AtomicLong
name|majorCompactedCellsCount
init|=
operator|new
name|AtomicLong
argument_list|()
decl_stmt|;
specifier|private
name|AtomicLong
name|flushedCellsSize
init|=
operator|new
name|AtomicLong
argument_list|()
decl_stmt|;
specifier|private
name|AtomicLong
name|flushedOutputFileSize
init|=
operator|new
name|AtomicLong
argument_list|()
decl_stmt|;
specifier|private
name|AtomicLong
name|compactedCellsSize
init|=
operator|new
name|AtomicLong
argument_list|()
decl_stmt|;
specifier|private
name|AtomicLong
name|majorCompactedCellsSize
init|=
operator|new
name|AtomicLong
argument_list|()
decl_stmt|;
comment|/**    * Constructor    * @param region    * @param family HColumnDescriptor for this column    * @param confParam configuration object    * failed.  Can be null.    * @throws IOException    */
specifier|protected
name|HStore
parameter_list|(
specifier|final
name|HRegion
name|region
parameter_list|,
specifier|final
name|ColumnFamilyDescriptor
name|family
parameter_list|,
specifier|final
name|Configuration
name|confParam
parameter_list|,
name|boolean
name|warmup
parameter_list|)
throws|throws
name|IOException
block|{
name|this
operator|.
name|fs
operator|=
name|region
operator|.
name|getRegionFileSystem
argument_list|()
expr_stmt|;
comment|// Assemble the store's home directory and Ensure it exists.
name|fs
operator|.
name|createStoreDir
argument_list|(
name|family
operator|.
name|getNameAsString
argument_list|()
argument_list|)
expr_stmt|;
name|this
operator|.
name|region
operator|=
name|region
expr_stmt|;
name|this
operator|.
name|family
operator|=
name|family
expr_stmt|;
comment|// 'conf' renamed to 'confParam' b/c we use this.conf in the constructor
comment|// CompoundConfiguration will look for keys in reverse order of addition, so we'd
comment|// add global config first, then table and cf overrides, then cf metadata.
name|this
operator|.
name|conf
operator|=
operator|new
name|CompoundConfiguration
argument_list|()
operator|.
name|add
argument_list|(
name|confParam
argument_list|)
operator|.
name|addBytesMap
argument_list|(
name|region
operator|.
name|getTableDescriptor
argument_list|()
operator|.
name|getValues
argument_list|()
argument_list|)
operator|.
name|addStringMap
argument_list|(
name|family
operator|.
name|getConfiguration
argument_list|()
argument_list|)
operator|.
name|addBytesMap
argument_list|(
name|family
operator|.
name|getValues
argument_list|()
argument_list|)
expr_stmt|;
name|this
operator|.
name|blocksize
operator|=
name|family
operator|.
name|getBlocksize
argument_list|()
expr_stmt|;
comment|// set block storage policy for store directory
name|String
name|policyName
init|=
name|family
operator|.
name|getStoragePolicy
argument_list|()
decl_stmt|;
if|if
condition|(
literal|null
operator|==
name|policyName
condition|)
block|{
name|policyName
operator|=
name|this
operator|.
name|conf
operator|.
name|get
argument_list|(
name|BLOCK_STORAGE_POLICY_KEY
argument_list|,
name|DEFAULT_BLOCK_STORAGE_POLICY
argument_list|)
expr_stmt|;
block|}
name|this
operator|.
name|fs
operator|.
name|setStoragePolicy
argument_list|(
name|family
operator|.
name|getNameAsString
argument_list|()
argument_list|,
name|policyName
operator|.
name|trim
argument_list|()
argument_list|)
expr_stmt|;
name|this
operator|.
name|dataBlockEncoder
operator|=
operator|new
name|HFileDataBlockEncoderImpl
argument_list|(
name|family
operator|.
name|getDataBlockEncoding
argument_list|()
argument_list|)
expr_stmt|;
name|this
operator|.
name|comparator
operator|=
name|region
operator|.
name|getCellComparator
argument_list|()
expr_stmt|;
comment|// used by ScanQueryMatcher
name|long
name|timeToPurgeDeletes
init|=
name|Math
operator|.
name|max
argument_list|(
name|conf
operator|.
name|getLong
argument_list|(
literal|"hbase.hstore.time.to.purge.deletes"
argument_list|,
literal|0
argument_list|)
argument_list|,
literal|0
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|trace
argument_list|(
literal|"Time to purge deletes set to {}ms in store {}"
argument_list|,
name|timeToPurgeDeletes
argument_list|,
name|this
argument_list|)
expr_stmt|;
comment|// Get TTL
name|long
name|ttl
init|=
name|determineTTLFromFamily
argument_list|(
name|family
argument_list|)
decl_stmt|;
comment|// Why not just pass a HColumnDescriptor in here altogether?  Even if have
comment|// to clone it?
name|scanInfo
operator|=
operator|new
name|ScanInfo
argument_list|(
name|conf
argument_list|,
name|family
argument_list|,
name|ttl
argument_list|,
name|timeToPurgeDeletes
argument_list|,
name|this
operator|.
name|comparator
argument_list|)
expr_stmt|;
name|this
operator|.
name|memstore
operator|=
name|getMemstore
argument_list|()
expr_stmt|;
name|this
operator|.
name|offPeakHours
operator|=
name|OffPeakHours
operator|.
name|getInstance
argument_list|(
name|conf
argument_list|)
expr_stmt|;
comment|// Setting up cache configuration for this family
name|createCacheConf
argument_list|(
name|family
argument_list|)
expr_stmt|;
name|this
operator|.
name|verifyBulkLoads
operator|=
name|conf
operator|.
name|getBoolean
argument_list|(
literal|"hbase.hstore.bulkload.verify"
argument_list|,
literal|false
argument_list|)
expr_stmt|;
name|this
operator|.
name|blockingFileCount
operator|=
name|conf
operator|.
name|getInt
argument_list|(
name|BLOCKING_STOREFILES_KEY
argument_list|,
name|DEFAULT_BLOCKING_STOREFILE_COUNT
argument_list|)
expr_stmt|;
name|this
operator|.
name|compactionCheckMultiplier
operator|=
name|conf
operator|.
name|getInt
argument_list|(
name|COMPACTCHECKER_INTERVAL_MULTIPLIER_KEY
argument_list|,
name|DEFAULT_COMPACTCHECKER_INTERVAL_MULTIPLIER
argument_list|)
expr_stmt|;
if|if
condition|(
name|this
operator|.
name|compactionCheckMultiplier
operator|<=
literal|0
condition|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Compaction check period multiplier must be positive, setting default: {}"
argument_list|,
name|DEFAULT_COMPACTCHECKER_INTERVAL_MULTIPLIER
argument_list|)
expr_stmt|;
name|this
operator|.
name|compactionCheckMultiplier
operator|=
name|DEFAULT_COMPACTCHECKER_INTERVAL_MULTIPLIER
expr_stmt|;
block|}
if|if
condition|(
name|HStore
operator|.
name|closeCheckInterval
operator|==
literal|0
condition|)
block|{
name|HStore
operator|.
name|closeCheckInterval
operator|=
name|conf
operator|.
name|getInt
argument_list|(
literal|"hbase.hstore.close.check.interval"
argument_list|,
literal|10
operator|*
literal|1000
operator|*
literal|1000
comment|/* 10 MB */
argument_list|)
expr_stmt|;
block|}
name|this
operator|.
name|storeEngine
operator|=
name|createStoreEngine
argument_list|(
name|this
argument_list|,
name|this
operator|.
name|conf
argument_list|,
name|this
operator|.
name|comparator
argument_list|)
expr_stmt|;
name|List
argument_list|<
name|HStoreFile
argument_list|>
name|hStoreFiles
init|=
name|loadStoreFiles
argument_list|(
name|warmup
argument_list|)
decl_stmt|;
comment|// Move the storeSize calculation out of loadStoreFiles() method, because the secondary read
comment|// replica's refreshStoreFiles() will also use loadStoreFiles() to refresh its store files and
comment|// update the storeSize in the completeCompaction(..) finally (just like compaction) , so
comment|// no need calculate the storeSize twice.
name|this
operator|.
name|storeSize
operator|.
name|addAndGet
argument_list|(
name|getStorefilesSize
argument_list|(
name|hStoreFiles
argument_list|,
name|sf
lambda|->
literal|true
argument_list|)
argument_list|)
expr_stmt|;
name|this
operator|.
name|totalUncompressedBytes
operator|.
name|addAndGet
argument_list|(
name|getTotalUncompressedBytes
argument_list|(
name|hStoreFiles
argument_list|)
argument_list|)
expr_stmt|;
name|this
operator|.
name|storeEngine
operator|.
name|getStoreFileManager
argument_list|()
operator|.
name|loadFiles
argument_list|(
name|hStoreFiles
argument_list|)
expr_stmt|;
comment|// Initialize checksum type from name. The names are CRC32, CRC32C, etc.
name|this
operator|.
name|checksumType
operator|=
name|getChecksumType
argument_list|(
name|conf
argument_list|)
expr_stmt|;
comment|// Initialize bytes per checksum
name|this
operator|.
name|bytesPerChecksum
operator|=
name|getBytesPerChecksum
argument_list|(
name|conf
argument_list|)
expr_stmt|;
name|flushRetriesNumber
operator|=
name|conf
operator|.
name|getInt
argument_list|(
literal|"hbase.hstore.flush.retries.number"
argument_list|,
name|DEFAULT_FLUSH_RETRIES_NUMBER
argument_list|)
expr_stmt|;
name|pauseTime
operator|=
name|conf
operator|.
name|getInt
argument_list|(
name|HConstants
operator|.
name|HBASE_SERVER_PAUSE
argument_list|,
name|HConstants
operator|.
name|DEFAULT_HBASE_SERVER_PAUSE
argument_list|)
expr_stmt|;
if|if
condition|(
name|flushRetriesNumber
operator|<=
literal|0
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"hbase.hstore.flush.retries.number must be> 0, not "
operator|+
name|flushRetriesNumber
argument_list|)
throw|;
block|}
name|cryptoContext
operator|=
name|EncryptionUtil
operator|.
name|createEncryptionContext
argument_list|(
name|conf
argument_list|,
name|family
argument_list|)
expr_stmt|;
name|int
name|confPrintThreshold
init|=
name|this
operator|.
name|conf
operator|.
name|getInt
argument_list|(
literal|"hbase.region.store.parallel.put.print.threshold"
argument_list|,
literal|50
argument_list|)
decl_stmt|;
if|if
condition|(
name|confPrintThreshold
operator|<
literal|10
condition|)
block|{
name|confPrintThreshold
operator|=
literal|10
expr_stmt|;
block|}
name|this
operator|.
name|parallelPutCountPrintThreshold
operator|=
name|confPrintThreshold
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Store={},  memstore type={}, storagePolicy={}, verifyBulkLoads={}, "
operator|+
literal|"parallelPutCountPrintThreshold={}, encoding={}, compression={}"
argument_list|,
name|getColumnFamilyName
argument_list|()
argument_list|,
name|memstore
operator|.
name|getClass
argument_list|()
operator|.
name|getSimpleName
argument_list|()
argument_list|,
name|policyName
argument_list|,
name|verifyBulkLoads
argument_list|,
name|parallelPutCountPrintThreshold
argument_list|,
name|family
operator|.
name|getDataBlockEncoding
argument_list|()
argument_list|,
name|family
operator|.
name|getCompressionType
argument_list|()
argument_list|)
expr_stmt|;
name|cacheOnWriteLogged
operator|=
literal|false
expr_stmt|;
block|}
comment|/**    * @return MemStore Instance to use in this store.    */
specifier|private
name|MemStore
name|getMemstore
parameter_list|()
block|{
name|MemStore
name|ms
init|=
literal|null
decl_stmt|;
comment|// Check if in-memory-compaction configured. Note MemoryCompactionPolicy is an enum!
name|MemoryCompactionPolicy
name|inMemoryCompaction
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|this
operator|.
name|getTableName
argument_list|()
operator|.
name|isSystemTable
argument_list|()
condition|)
block|{
name|inMemoryCompaction
operator|=
name|MemoryCompactionPolicy
operator|.
name|valueOf
argument_list|(
name|conf
operator|.
name|get
argument_list|(
literal|"hbase.systemtables.compacting.memstore.type"
argument_list|,
literal|"NONE"
argument_list|)
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|inMemoryCompaction
operator|=
name|family
operator|.
name|getInMemoryCompaction
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|inMemoryCompaction
operator|==
literal|null
condition|)
block|{
name|inMemoryCompaction
operator|=
name|MemoryCompactionPolicy
operator|.
name|valueOf
argument_list|(
name|conf
operator|.
name|get
argument_list|(
name|CompactingMemStore
operator|.
name|COMPACTING_MEMSTORE_TYPE_KEY
argument_list|,
name|CompactingMemStore
operator|.
name|COMPACTING_MEMSTORE_TYPE_DEFAULT
argument_list|)
operator|.
name|toUpperCase
argument_list|()
argument_list|)
expr_stmt|;
block|}
switch|switch
condition|(
name|inMemoryCompaction
condition|)
block|{
case|case
name|NONE
case|:
name|ms
operator|=
name|ReflectionUtils
operator|.
name|newInstance
argument_list|(
name|DefaultMemStore
operator|.
name|class
argument_list|,
operator|new
name|Object
index|[]
block|{
name|conf
block|,
name|this
operator|.
name|comparator
block|,
name|this
operator|.
name|getHRegion
argument_list|()
operator|.
name|getRegionServicesForStores
argument_list|()
block|}
argument_list|)
expr_stmt|;
break|break;
default|default:
name|Class
argument_list|<
name|?
extends|extends
name|CompactingMemStore
argument_list|>
name|clz
init|=
name|conf
operator|.
name|getClass
argument_list|(
name|MEMSTORE_CLASS_NAME
argument_list|,
name|CompactingMemStore
operator|.
name|class
argument_list|,
name|CompactingMemStore
operator|.
name|class
argument_list|)
decl_stmt|;
name|ms
operator|=
name|ReflectionUtils
operator|.
name|newInstance
argument_list|(
name|clz
argument_list|,
operator|new
name|Object
index|[]
block|{
name|conf
block|,
name|this
operator|.
name|comparator
block|,
name|this
block|,
name|this
operator|.
name|getHRegion
argument_list|()
operator|.
name|getRegionServicesForStores
argument_list|()
block|,
name|inMemoryCompaction
block|}
argument_list|)
expr_stmt|;
block|}
return|return
name|ms
return|;
block|}
comment|/**    * Creates the cache config.    * @param family The current column family.    */
specifier|protected
name|void
name|createCacheConf
parameter_list|(
specifier|final
name|ColumnFamilyDescriptor
name|family
parameter_list|)
block|{
name|this
operator|.
name|cacheConf
operator|=
operator|new
name|CacheConfig
argument_list|(
name|conf
argument_list|,
name|family
argument_list|,
name|region
operator|.
name|getBlockCache
argument_list|()
argument_list|,
name|region
operator|.
name|getRegionServicesForStores
argument_list|()
operator|.
name|getByteBuffAllocator
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|/**    * Creates the store engine configured for the given Store.    * @param store The store. An unfortunate dependency needed due to it    *              being passed to coprocessors via the compactor.    * @param conf Store configuration.    * @param kvComparator KVComparator for storeFileManager.    * @return StoreEngine to use.    */
specifier|protected
name|StoreEngine
argument_list|<
name|?
argument_list|,
name|?
argument_list|,
name|?
argument_list|,
name|?
argument_list|>
name|createStoreEngine
parameter_list|(
name|HStore
name|store
parameter_list|,
name|Configuration
name|conf
parameter_list|,
name|CellComparator
name|kvComparator
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|StoreEngine
operator|.
name|create
argument_list|(
name|store
argument_list|,
name|conf
argument_list|,
name|comparator
argument_list|)
return|;
block|}
comment|/**    * @param family    * @return TTL in seconds of the specified family    */
specifier|public
specifier|static
name|long
name|determineTTLFromFamily
parameter_list|(
specifier|final
name|ColumnFamilyDescriptor
name|family
parameter_list|)
block|{
comment|// HCD.getTimeToLive returns ttl in seconds.  Convert to milliseconds.
name|long
name|ttl
init|=
name|family
operator|.
name|getTimeToLive
argument_list|()
decl_stmt|;
if|if
condition|(
name|ttl
operator|==
name|HConstants
operator|.
name|FOREVER
condition|)
block|{
comment|// Default is unlimited ttl.
name|ttl
operator|=
name|Long
operator|.
name|MAX_VALUE
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|ttl
operator|==
operator|-
literal|1
condition|)
block|{
name|ttl
operator|=
name|Long
operator|.
name|MAX_VALUE
expr_stmt|;
block|}
else|else
block|{
comment|// Second -> ms adjust for user data
name|ttl
operator|*=
literal|1000
expr_stmt|;
block|}
return|return
name|ttl
return|;
block|}
annotation|@
name|Override
specifier|public
name|String
name|getColumnFamilyName
parameter_list|()
block|{
return|return
name|this
operator|.
name|family
operator|.
name|getNameAsString
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|TableName
name|getTableName
parameter_list|()
block|{
return|return
name|this
operator|.
name|getRegionInfo
argument_list|()
operator|.
name|getTable
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|FileSystem
name|getFileSystem
parameter_list|()
block|{
return|return
name|this
operator|.
name|fs
operator|.
name|getFileSystem
argument_list|()
return|;
block|}
specifier|public
name|HRegionFileSystem
name|getRegionFileSystem
parameter_list|()
block|{
return|return
name|this
operator|.
name|fs
return|;
block|}
comment|/* Implementation of StoreConfigInformation */
annotation|@
name|Override
specifier|public
name|long
name|getStoreFileTtl
parameter_list|()
block|{
comment|// TTL only applies if there's no MIN_VERSIONs setting on the column.
return|return
operator|(
name|this
operator|.
name|scanInfo
operator|.
name|getMinVersions
argument_list|()
operator|==
literal|0
operator|)
condition|?
name|this
operator|.
name|scanInfo
operator|.
name|getTtl
argument_list|()
else|:
name|Long
operator|.
name|MAX_VALUE
return|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|getMemStoreFlushSize
parameter_list|()
block|{
comment|// TODO: Why is this in here?  The flushsize of the region rather than the store?  St.Ack
return|return
name|this
operator|.
name|region
operator|.
name|memstoreFlushSize
return|;
block|}
annotation|@
name|Override
specifier|public
name|MemStoreSize
name|getFlushableSize
parameter_list|()
block|{
return|return
name|this
operator|.
name|memstore
operator|.
name|getFlushableSize
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|MemStoreSize
name|getSnapshotSize
parameter_list|()
block|{
return|return
name|this
operator|.
name|memstore
operator|.
name|getSnapshotSize
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|getCompactionCheckMultiplier
parameter_list|()
block|{
return|return
name|this
operator|.
name|compactionCheckMultiplier
return|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|getBlockingFileCount
parameter_list|()
block|{
return|return
name|blockingFileCount
return|;
block|}
comment|/* End implementation of StoreConfigInformation */
comment|/**    * Returns the configured bytesPerChecksum value.    * @param conf The configuration    * @return The bytesPerChecksum that is set in the configuration    */
specifier|public
specifier|static
name|int
name|getBytesPerChecksum
parameter_list|(
name|Configuration
name|conf
parameter_list|)
block|{
return|return
name|conf
operator|.
name|getInt
argument_list|(
name|HConstants
operator|.
name|BYTES_PER_CHECKSUM
argument_list|,
name|HFile
operator|.
name|DEFAULT_BYTES_PER_CHECKSUM
argument_list|)
return|;
block|}
comment|/**    * Returns the configured checksum algorithm.    * @param conf The configuration    * @return The checksum algorithm that is set in the configuration    */
specifier|public
specifier|static
name|ChecksumType
name|getChecksumType
parameter_list|(
name|Configuration
name|conf
parameter_list|)
block|{
name|String
name|checksumName
init|=
name|conf
operator|.
name|get
argument_list|(
name|HConstants
operator|.
name|CHECKSUM_TYPE_NAME
argument_list|)
decl_stmt|;
if|if
condition|(
name|checksumName
operator|==
literal|null
condition|)
block|{
return|return
name|ChecksumType
operator|.
name|getDefaultChecksumType
argument_list|()
return|;
block|}
else|else
block|{
return|return
name|ChecksumType
operator|.
name|nameToType
argument_list|(
name|checksumName
argument_list|)
return|;
block|}
block|}
comment|/**    * @return how many bytes to write between status checks    */
specifier|public
specifier|static
name|int
name|getCloseCheckInterval
parameter_list|()
block|{
return|return
name|closeCheckInterval
return|;
block|}
annotation|@
name|Override
specifier|public
name|ColumnFamilyDescriptor
name|getColumnFamilyDescriptor
parameter_list|()
block|{
return|return
name|this
operator|.
name|family
return|;
block|}
annotation|@
name|Override
specifier|public
name|OptionalLong
name|getMaxSequenceId
parameter_list|()
block|{
return|return
name|StoreUtils
operator|.
name|getMaxSequenceIdInList
argument_list|(
name|this
operator|.
name|getStorefiles
argument_list|()
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|OptionalLong
name|getMaxMemStoreTS
parameter_list|()
block|{
return|return
name|StoreUtils
operator|.
name|getMaxMemStoreTSInList
argument_list|(
name|this
operator|.
name|getStorefiles
argument_list|()
argument_list|)
return|;
block|}
comment|/**    * @param tabledir {@link Path} to where the table is being stored    * @param hri {@link RegionInfo} for the region.    * @param family {@link ColumnFamilyDescriptor} describing the column family    * @return Path to family/Store home directory.    */
annotation|@
name|Deprecated
specifier|public
specifier|static
name|Path
name|getStoreHomedir
parameter_list|(
specifier|final
name|Path
name|tabledir
parameter_list|,
specifier|final
name|RegionInfo
name|hri
parameter_list|,
specifier|final
name|byte
index|[]
name|family
parameter_list|)
block|{
return|return
name|getStoreHomedir
argument_list|(
name|tabledir
argument_list|,
name|hri
operator|.
name|getEncodedName
argument_list|()
argument_list|,
name|family
argument_list|)
return|;
block|}
comment|/**    * @param tabledir {@link Path} to where the table is being stored    * @param encodedName Encoded region name.    * @param family {@link ColumnFamilyDescriptor} describing the column family    * @return Path to family/Store home directory.    */
annotation|@
name|Deprecated
specifier|public
specifier|static
name|Path
name|getStoreHomedir
parameter_list|(
specifier|final
name|Path
name|tabledir
parameter_list|,
specifier|final
name|String
name|encodedName
parameter_list|,
specifier|final
name|byte
index|[]
name|family
parameter_list|)
block|{
return|return
operator|new
name|Path
argument_list|(
name|tabledir
argument_list|,
operator|new
name|Path
argument_list|(
name|encodedName
argument_list|,
name|Bytes
operator|.
name|toString
argument_list|(
name|family
argument_list|)
argument_list|)
argument_list|)
return|;
block|}
comment|/**    * @return the data block encoder    */
specifier|public
name|HFileDataBlockEncoder
name|getDataBlockEncoder
parameter_list|()
block|{
return|return
name|dataBlockEncoder
return|;
block|}
comment|/**    * Should be used only in tests.    * @param blockEncoder the block delta encoder to use    */
name|void
name|setDataBlockEncoderInTest
parameter_list|(
name|HFileDataBlockEncoder
name|blockEncoder
parameter_list|)
block|{
name|this
operator|.
name|dataBlockEncoder
operator|=
name|blockEncoder
expr_stmt|;
block|}
comment|/**    * Creates an unsorted list of StoreFile loaded in parallel    * from the given directory.    * @throws IOException    */
specifier|private
name|List
argument_list|<
name|HStoreFile
argument_list|>
name|loadStoreFiles
parameter_list|(
name|boolean
name|warmup
parameter_list|)
throws|throws
name|IOException
block|{
name|Collection
argument_list|<
name|StoreFileInfo
argument_list|>
name|files
init|=
name|fs
operator|.
name|getStoreFiles
argument_list|(
name|getColumnFamilyName
argument_list|()
argument_list|)
decl_stmt|;
return|return
name|openStoreFiles
argument_list|(
name|files
argument_list|,
name|warmup
argument_list|)
return|;
block|}
specifier|private
name|List
argument_list|<
name|HStoreFile
argument_list|>
name|openStoreFiles
parameter_list|(
name|Collection
argument_list|<
name|StoreFileInfo
argument_list|>
name|files
parameter_list|,
name|boolean
name|warmup
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|CollectionUtils
operator|.
name|isEmpty
argument_list|(
name|files
argument_list|)
condition|)
block|{
return|return
name|Collections
operator|.
name|emptyList
argument_list|()
return|;
block|}
comment|// initialize the thread pool for opening store files in parallel..
name|ThreadPoolExecutor
name|storeFileOpenerThreadPool
init|=
name|this
operator|.
name|region
operator|.
name|getStoreFileOpenAndCloseThreadPool
argument_list|(
literal|"StoreFileOpenerThread-"
operator|+
name|this
operator|.
name|region
operator|.
name|getRegionInfo
argument_list|()
operator|.
name|getEncodedName
argument_list|()
operator|+
literal|"-"
operator|+
name|this
operator|.
name|getColumnFamilyName
argument_list|()
argument_list|)
decl_stmt|;
name|CompletionService
argument_list|<
name|HStoreFile
argument_list|>
name|completionService
init|=
operator|new
name|ExecutorCompletionService
argument_list|<>
argument_list|(
name|storeFileOpenerThreadPool
argument_list|)
decl_stmt|;
name|int
name|totalValidStoreFile
init|=
literal|0
decl_stmt|;
for|for
control|(
name|StoreFileInfo
name|storeFileInfo
range|:
name|files
control|)
block|{
comment|// open each store file in parallel
name|completionService
operator|.
name|submit
argument_list|(
parameter_list|()
lambda|->
name|this
operator|.
name|createStoreFileAndReader
argument_list|(
name|storeFileInfo
argument_list|)
argument_list|)
expr_stmt|;
name|totalValidStoreFile
operator|++
expr_stmt|;
block|}
name|Set
argument_list|<
name|String
argument_list|>
name|compactedStoreFiles
init|=
operator|new
name|HashSet
argument_list|<>
argument_list|()
decl_stmt|;
name|ArrayList
argument_list|<
name|HStoreFile
argument_list|>
name|results
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
name|files
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
name|IOException
name|ioe
init|=
literal|null
decl_stmt|;
try|try
block|{
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|totalValidStoreFile
condition|;
name|i
operator|++
control|)
block|{
try|try
block|{
name|HStoreFile
name|storeFile
init|=
name|completionService
operator|.
name|take
argument_list|()
operator|.
name|get
argument_list|()
decl_stmt|;
if|if
condition|(
name|storeFile
operator|!=
literal|null
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"loaded {}"
argument_list|,
name|storeFile
argument_list|)
expr_stmt|;
name|results
operator|.
name|add
argument_list|(
name|storeFile
argument_list|)
expr_stmt|;
name|compactedStoreFiles
operator|.
name|addAll
argument_list|(
name|storeFile
operator|.
name|getCompactedStoreFiles
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
if|if
condition|(
name|ioe
operator|==
literal|null
condition|)
name|ioe
operator|=
operator|new
name|InterruptedIOException
argument_list|(
name|e
operator|.
name|getMessage
argument_list|()
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|ExecutionException
name|e
parameter_list|)
block|{
if|if
condition|(
name|ioe
operator|==
literal|null
condition|)
name|ioe
operator|=
operator|new
name|IOException
argument_list|(
name|e
operator|.
name|getCause
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
block|}
finally|finally
block|{
name|storeFileOpenerThreadPool
operator|.
name|shutdownNow
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|ioe
operator|!=
literal|null
condition|)
block|{
comment|// close StoreFile readers
name|boolean
name|evictOnClose
init|=
name|cacheConf
operator|!=
literal|null
condition|?
name|cacheConf
operator|.
name|shouldEvictOnClose
argument_list|()
else|:
literal|true
decl_stmt|;
for|for
control|(
name|HStoreFile
name|file
range|:
name|results
control|)
block|{
try|try
block|{
if|if
condition|(
name|file
operator|!=
literal|null
condition|)
block|{
name|file
operator|.
name|closeStoreFile
argument_list|(
name|evictOnClose
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Could not close store file"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
block|}
throw|throw
name|ioe
throw|;
block|}
comment|// Should not archive the compacted store files when region warmup. See HBASE-22163.
if|if
condition|(
operator|!
name|warmup
condition|)
block|{
comment|// Remove the compacted files from result
name|List
argument_list|<
name|HStoreFile
argument_list|>
name|filesToRemove
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
name|compactedStoreFiles
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
for|for
control|(
name|HStoreFile
name|storeFile
range|:
name|results
control|)
block|{
if|if
condition|(
name|compactedStoreFiles
operator|.
name|contains
argument_list|(
name|storeFile
operator|.
name|getPath
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Clearing the compacted storefile {} from this store"
argument_list|,
name|storeFile
argument_list|)
expr_stmt|;
name|storeFile
operator|.
name|getReader
argument_list|()
operator|.
name|close
argument_list|(
literal|true
argument_list|)
expr_stmt|;
name|filesToRemove
operator|.
name|add
argument_list|(
name|storeFile
argument_list|)
expr_stmt|;
block|}
block|}
name|results
operator|.
name|removeAll
argument_list|(
name|filesToRemove
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|filesToRemove
operator|.
name|isEmpty
argument_list|()
operator|&&
name|this
operator|.
name|isPrimaryReplicaStore
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Moving the files {} to archive"
argument_list|,
name|filesToRemove
argument_list|)
expr_stmt|;
name|this
operator|.
name|fs
operator|.
name|removeStoreFiles
argument_list|(
name|this
operator|.
name|getColumnFamilyDescriptor
argument_list|()
operator|.
name|getNameAsString
argument_list|()
argument_list|,
name|filesToRemove
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|results
return|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|refreshStoreFiles
parameter_list|()
throws|throws
name|IOException
block|{
name|Collection
argument_list|<
name|StoreFileInfo
argument_list|>
name|newFiles
init|=
name|fs
operator|.
name|getStoreFiles
argument_list|(
name|getColumnFamilyName
argument_list|()
argument_list|)
decl_stmt|;
name|refreshStoreFilesInternal
argument_list|(
name|newFiles
argument_list|)
expr_stmt|;
block|}
comment|/**    * Replaces the store files that the store has with the given files. Mainly used by secondary    * region replicas to keep up to date with the primary region files.    * @throws IOException    */
specifier|public
name|void
name|refreshStoreFiles
parameter_list|(
name|Collection
argument_list|<
name|String
argument_list|>
name|newFiles
parameter_list|)
throws|throws
name|IOException
block|{
name|List
argument_list|<
name|StoreFileInfo
argument_list|>
name|storeFiles
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
name|newFiles
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
for|for
control|(
name|String
name|file
range|:
name|newFiles
control|)
block|{
name|storeFiles
operator|.
name|add
argument_list|(
name|fs
operator|.
name|getStoreFileInfo
argument_list|(
name|getColumnFamilyName
argument_list|()
argument_list|,
name|file
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|refreshStoreFilesInternal
argument_list|(
name|storeFiles
argument_list|)
expr_stmt|;
block|}
comment|/**    * Checks the underlying store files, and opens the files that  have not    * been opened, and removes the store file readers for store files no longer    * available. Mainly used by secondary region replicas to keep up to date with    * the primary region files.    * @throws IOException    */
specifier|private
name|void
name|refreshStoreFilesInternal
parameter_list|(
name|Collection
argument_list|<
name|StoreFileInfo
argument_list|>
name|newFiles
parameter_list|)
throws|throws
name|IOException
block|{
name|StoreFileManager
name|sfm
init|=
name|storeEngine
operator|.
name|getStoreFileManager
argument_list|()
decl_stmt|;
name|Collection
argument_list|<
name|HStoreFile
argument_list|>
name|currentFiles
init|=
name|sfm
operator|.
name|getStorefiles
argument_list|()
decl_stmt|;
name|Collection
argument_list|<
name|HStoreFile
argument_list|>
name|compactedFiles
init|=
name|sfm
operator|.
name|getCompactedfiles
argument_list|()
decl_stmt|;
if|if
condition|(
name|currentFiles
operator|==
literal|null
condition|)
name|currentFiles
operator|=
name|Collections
operator|.
name|emptySet
argument_list|()
expr_stmt|;
if|if
condition|(
name|newFiles
operator|==
literal|null
condition|)
name|newFiles
operator|=
name|Collections
operator|.
name|emptySet
argument_list|()
expr_stmt|;
if|if
condition|(
name|compactedFiles
operator|==
literal|null
condition|)
name|compactedFiles
operator|=
name|Collections
operator|.
name|emptySet
argument_list|()
expr_stmt|;
name|HashMap
argument_list|<
name|StoreFileInfo
argument_list|,
name|HStoreFile
argument_list|>
name|currentFilesSet
init|=
operator|new
name|HashMap
argument_list|<>
argument_list|(
name|currentFiles
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
for|for
control|(
name|HStoreFile
name|sf
range|:
name|currentFiles
control|)
block|{
name|currentFilesSet
operator|.
name|put
argument_list|(
name|sf
operator|.
name|getFileInfo
argument_list|()
argument_list|,
name|sf
argument_list|)
expr_stmt|;
block|}
name|HashMap
argument_list|<
name|StoreFileInfo
argument_list|,
name|HStoreFile
argument_list|>
name|compactedFilesSet
init|=
operator|new
name|HashMap
argument_list|<>
argument_list|(
name|compactedFiles
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
for|for
control|(
name|HStoreFile
name|sf
range|:
name|compactedFiles
control|)
block|{
name|compactedFilesSet
operator|.
name|put
argument_list|(
name|sf
operator|.
name|getFileInfo
argument_list|()
argument_list|,
name|sf
argument_list|)
expr_stmt|;
block|}
name|Set
argument_list|<
name|StoreFileInfo
argument_list|>
name|newFilesSet
init|=
operator|new
name|HashSet
argument_list|<
name|StoreFileInfo
argument_list|>
argument_list|(
name|newFiles
argument_list|)
decl_stmt|;
comment|// Exclude the files that have already been compacted
name|newFilesSet
operator|=
name|Sets
operator|.
name|difference
argument_list|(
name|newFilesSet
argument_list|,
name|compactedFilesSet
operator|.
name|keySet
argument_list|()
argument_list|)
expr_stmt|;
name|Set
argument_list|<
name|StoreFileInfo
argument_list|>
name|toBeAddedFiles
init|=
name|Sets
operator|.
name|difference
argument_list|(
name|newFilesSet
argument_list|,
name|currentFilesSet
operator|.
name|keySet
argument_list|()
argument_list|)
decl_stmt|;
name|Set
argument_list|<
name|StoreFileInfo
argument_list|>
name|toBeRemovedFiles
init|=
name|Sets
operator|.
name|difference
argument_list|(
name|currentFilesSet
operator|.
name|keySet
argument_list|()
argument_list|,
name|newFilesSet
argument_list|)
decl_stmt|;
if|if
condition|(
name|toBeAddedFiles
operator|.
name|isEmpty
argument_list|()
operator|&&
name|toBeRemovedFiles
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
return|return;
block|}
name|LOG
operator|.
name|info
argument_list|(
literal|"Refreshing store files for region "
operator|+
name|this
operator|.
name|getRegionInfo
argument_list|()
operator|.
name|getRegionNameAsString
argument_list|()
operator|+
literal|" files to add: "
operator|+
name|toBeAddedFiles
operator|+
literal|" files to remove: "
operator|+
name|toBeRemovedFiles
argument_list|)
expr_stmt|;
name|Set
argument_list|<
name|HStoreFile
argument_list|>
name|toBeRemovedStoreFiles
init|=
operator|new
name|HashSet
argument_list|<>
argument_list|(
name|toBeRemovedFiles
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
for|for
control|(
name|StoreFileInfo
name|sfi
range|:
name|toBeRemovedFiles
control|)
block|{
name|toBeRemovedStoreFiles
operator|.
name|add
argument_list|(
name|currentFilesSet
operator|.
name|get
argument_list|(
name|sfi
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|// try to open the files
name|List
argument_list|<
name|HStoreFile
argument_list|>
name|openedFiles
init|=
name|openStoreFiles
argument_list|(
name|toBeAddedFiles
argument_list|,
literal|false
argument_list|)
decl_stmt|;
comment|// propogate the file changes to the underlying store file manager
name|replaceStoreFiles
argument_list|(
name|toBeRemovedStoreFiles
argument_list|,
name|openedFiles
argument_list|)
expr_stmt|;
comment|//won't throw an exception
comment|// Advance the memstore read point to be at least the new store files seqIds so that
comment|// readers might pick it up. This assumes that the store is not getting any writes (otherwise
comment|// in-flight transactions might be made visible)
if|if
condition|(
operator|!
name|toBeAddedFiles
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
comment|// we must have the max sequence id here as we do have several store files
name|region
operator|.
name|getMVCC
argument_list|()
operator|.
name|advanceTo
argument_list|(
name|this
operator|.
name|getMaxSequenceId
argument_list|()
operator|.
name|getAsLong
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|completeCompaction
argument_list|(
name|toBeRemovedStoreFiles
argument_list|)
expr_stmt|;
block|}
annotation|@
name|VisibleForTesting
specifier|protected
name|HStoreFile
name|createStoreFileAndReader
parameter_list|(
specifier|final
name|Path
name|p
parameter_list|)
throws|throws
name|IOException
block|{
name|StoreFileInfo
name|info
init|=
operator|new
name|StoreFileInfo
argument_list|(
name|conf
argument_list|,
name|this
operator|.
name|getFileSystem
argument_list|()
argument_list|,
name|p
argument_list|,
name|isPrimaryReplicaStore
argument_list|()
argument_list|)
decl_stmt|;
return|return
name|createStoreFileAndReader
argument_list|(
name|info
argument_list|)
return|;
block|}
specifier|private
name|HStoreFile
name|createStoreFileAndReader
parameter_list|(
name|StoreFileInfo
name|info
parameter_list|)
throws|throws
name|IOException
block|{
name|info
operator|.
name|setRegionCoprocessorHost
argument_list|(
name|this
operator|.
name|region
operator|.
name|getCoprocessorHost
argument_list|()
argument_list|)
expr_stmt|;
name|HStoreFile
name|storeFile
init|=
operator|new
name|HStoreFile
argument_list|(
name|info
argument_list|,
name|this
operator|.
name|family
operator|.
name|getBloomFilterType
argument_list|()
argument_list|,
name|this
operator|.
name|cacheConf
argument_list|)
decl_stmt|;
name|storeFile
operator|.
name|initReader
argument_list|()
expr_stmt|;
return|return
name|storeFile
return|;
block|}
comment|/**    * This message intends to inform the MemStore that next coming updates    * are going to be part of the replaying edits from WAL    */
specifier|public
name|void
name|startReplayingFromWAL
parameter_list|()
block|{
name|this
operator|.
name|memstore
operator|.
name|startReplayingFromWAL
argument_list|()
expr_stmt|;
block|}
comment|/**    * This message intends to inform the MemStore that the replaying edits from WAL    * are done    */
specifier|public
name|void
name|stopReplayingFromWAL
parameter_list|()
block|{
name|this
operator|.
name|memstore
operator|.
name|stopReplayingFromWAL
argument_list|()
expr_stmt|;
block|}
comment|/**    * Adds a value to the memstore    */
specifier|public
name|void
name|add
parameter_list|(
specifier|final
name|Cell
name|cell
parameter_list|,
name|MemStoreSizing
name|memstoreSizing
parameter_list|)
block|{
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
if|if
condition|(
name|this
operator|.
name|currentParallelPutCount
operator|.
name|getAndIncrement
argument_list|()
operator|>
name|this
operator|.
name|parallelPutCountPrintThreshold
condition|)
block|{
name|LOG
operator|.
name|trace
argument_list|(
name|this
operator|.
name|getTableName
argument_list|()
operator|+
literal|"tableName={}, encodedName={}, columnFamilyName={} is "
operator|+
literal|"too busy!"
argument_list|,
name|this
operator|.
name|getRegionInfo
argument_list|()
operator|.
name|getEncodedName
argument_list|()
argument_list|,
name|this
operator|.
name|getColumnFamilyName
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|this
operator|.
name|memstore
operator|.
name|add
argument_list|(
name|cell
argument_list|,
name|memstoreSizing
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
name|currentParallelPutCount
operator|.
name|decrementAndGet
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**    * Adds the specified value to the memstore    */
specifier|public
name|void
name|add
parameter_list|(
specifier|final
name|Iterable
argument_list|<
name|Cell
argument_list|>
name|cells
parameter_list|,
name|MemStoreSizing
name|memstoreSizing
parameter_list|)
block|{
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
if|if
condition|(
name|this
operator|.
name|currentParallelPutCount
operator|.
name|getAndIncrement
argument_list|()
operator|>
name|this
operator|.
name|parallelPutCountPrintThreshold
condition|)
block|{
name|LOG
operator|.
name|trace
argument_list|(
name|this
operator|.
name|getTableName
argument_list|()
operator|+
literal|"tableName={}, encodedName={}, columnFamilyName={} is "
operator|+
literal|"too busy!"
argument_list|,
name|this
operator|.
name|getRegionInfo
argument_list|()
operator|.
name|getEncodedName
argument_list|()
argument_list|,
name|this
operator|.
name|getColumnFamilyName
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|memstore
operator|.
name|add
argument_list|(
name|cells
argument_list|,
name|memstoreSizing
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
name|currentParallelPutCount
operator|.
name|decrementAndGet
argument_list|()
expr_stmt|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|long
name|timeOfOldestEdit
parameter_list|()
block|{
return|return
name|memstore
operator|.
name|timeOfOldestEdit
argument_list|()
return|;
block|}
comment|/**    * @return All store files.    */
annotation|@
name|Override
specifier|public
name|Collection
argument_list|<
name|HStoreFile
argument_list|>
name|getStorefiles
parameter_list|()
block|{
return|return
name|this
operator|.
name|storeEngine
operator|.
name|getStoreFileManager
argument_list|()
operator|.
name|getStorefiles
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|Collection
argument_list|<
name|HStoreFile
argument_list|>
name|getCompactedFiles
parameter_list|()
block|{
return|return
name|this
operator|.
name|storeEngine
operator|.
name|getStoreFileManager
argument_list|()
operator|.
name|getCompactedfiles
argument_list|()
return|;
block|}
comment|/**    * This throws a WrongRegionException if the HFile does not fit in this region, or an    * InvalidHFileException if the HFile is not valid.    */
specifier|public
name|void
name|assertBulkLoadHFileOk
parameter_list|(
name|Path
name|srcPath
parameter_list|)
throws|throws
name|IOException
block|{
name|HFile
operator|.
name|Reader
name|reader
init|=
literal|null
decl_stmt|;
try|try
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Validating hfile at "
operator|+
name|srcPath
operator|+
literal|" for inclusion in "
operator|+
literal|"store "
operator|+
name|this
operator|+
literal|" region "
operator|+
name|this
operator|.
name|getRegionInfo
argument_list|()
operator|.
name|getRegionNameAsString
argument_list|()
argument_list|)
expr_stmt|;
name|FileSystem
name|srcFs
init|=
name|srcPath
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
decl_stmt|;
name|srcFs
operator|.
name|access
argument_list|(
name|srcPath
argument_list|,
name|FsAction
operator|.
name|READ_WRITE
argument_list|)
expr_stmt|;
name|reader
operator|=
name|HFile
operator|.
name|createReader
argument_list|(
name|srcFs
argument_list|,
name|srcPath
argument_list|,
name|cacheConf
argument_list|,
name|isPrimaryReplicaStore
argument_list|()
argument_list|,
name|conf
argument_list|)
expr_stmt|;
name|Optional
argument_list|<
name|byte
index|[]
argument_list|>
name|firstKey
init|=
name|reader
operator|.
name|getFirstRowKey
argument_list|()
decl_stmt|;
name|Preconditions
operator|.
name|checkState
argument_list|(
name|firstKey
operator|.
name|isPresent
argument_list|()
argument_list|,
literal|"First key can not be null"
argument_list|)
expr_stmt|;
name|Optional
argument_list|<
name|Cell
argument_list|>
name|lk
init|=
name|reader
operator|.
name|getLastKey
argument_list|()
decl_stmt|;
name|Preconditions
operator|.
name|checkState
argument_list|(
name|lk
operator|.
name|isPresent
argument_list|()
argument_list|,
literal|"Last key can not be null"
argument_list|)
expr_stmt|;
name|byte
index|[]
name|lastKey
init|=
name|CellUtil
operator|.
name|cloneRow
argument_list|(
name|lk
operator|.
name|get
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"HFile bounds: first="
operator|+
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|firstKey
operator|.
name|get
argument_list|()
argument_list|)
operator|+
literal|" last="
operator|+
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|lastKey
argument_list|)
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Region bounds: first="
operator|+
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|getRegionInfo
argument_list|()
operator|.
name|getStartKey
argument_list|()
argument_list|)
operator|+
literal|" last="
operator|+
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|getRegionInfo
argument_list|()
operator|.
name|getEndKey
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|!
name|this
operator|.
name|getRegionInfo
argument_list|()
operator|.
name|containsRange
argument_list|(
name|firstKey
operator|.
name|get
argument_list|()
argument_list|,
name|lastKey
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|WrongRegionException
argument_list|(
literal|"Bulk load file "
operator|+
name|srcPath
operator|.
name|toString
argument_list|()
operator|+
literal|" does not fit inside region "
operator|+
name|this
operator|.
name|getRegionInfo
argument_list|()
operator|.
name|getRegionNameAsString
argument_list|()
argument_list|)
throw|;
block|}
if|if
condition|(
name|reader
operator|.
name|length
argument_list|()
operator|>
name|conf
operator|.
name|getLong
argument_list|(
name|HConstants
operator|.
name|HREGION_MAX_FILESIZE
argument_list|,
name|HConstants
operator|.
name|DEFAULT_MAX_FILE_SIZE
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Trying to bulk load hfile "
operator|+
name|srcPath
operator|+
literal|" with size: "
operator|+
name|reader
operator|.
name|length
argument_list|()
operator|+
literal|" bytes can be problematic as it may lead to oversplitting."
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|verifyBulkLoads
condition|)
block|{
name|long
name|verificationStartTime
init|=
name|EnvironmentEdgeManager
operator|.
name|currentTime
argument_list|()
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Full verification started for bulk load hfile: {}"
argument_list|,
name|srcPath
argument_list|)
expr_stmt|;
name|Cell
name|prevCell
init|=
literal|null
decl_stmt|;
name|HFileScanner
name|scanner
init|=
name|reader
operator|.
name|getScanner
argument_list|(
literal|false
argument_list|,
literal|false
argument_list|,
literal|false
argument_list|)
decl_stmt|;
name|scanner
operator|.
name|seekTo
argument_list|()
expr_stmt|;
do|do
block|{
name|Cell
name|cell
init|=
name|scanner
operator|.
name|getCell
argument_list|()
decl_stmt|;
if|if
condition|(
name|prevCell
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
name|comparator
operator|.
name|compareRows
argument_list|(
name|prevCell
argument_list|,
name|cell
argument_list|)
operator|>
literal|0
condition|)
block|{
throw|throw
operator|new
name|InvalidHFileException
argument_list|(
literal|"Previous row is greater than"
operator|+
literal|" current row: path="
operator|+
name|srcPath
operator|+
literal|" previous="
operator|+
name|CellUtil
operator|.
name|getCellKeyAsString
argument_list|(
name|prevCell
argument_list|)
operator|+
literal|" current="
operator|+
name|CellUtil
operator|.
name|getCellKeyAsString
argument_list|(
name|cell
argument_list|)
argument_list|)
throw|;
block|}
if|if
condition|(
name|CellComparator
operator|.
name|getInstance
argument_list|()
operator|.
name|compareFamilies
argument_list|(
name|prevCell
argument_list|,
name|cell
argument_list|)
operator|!=
literal|0
condition|)
block|{
throw|throw
operator|new
name|InvalidHFileException
argument_list|(
literal|"Previous key had different"
operator|+
literal|" family compared to current key: path="
operator|+
name|srcPath
operator|+
literal|" previous="
operator|+
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|prevCell
operator|.
name|getFamilyArray
argument_list|()
argument_list|,
name|prevCell
operator|.
name|getFamilyOffset
argument_list|()
argument_list|,
name|prevCell
operator|.
name|getFamilyLength
argument_list|()
argument_list|)
operator|+
literal|" current="
operator|+
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|cell
operator|.
name|getFamilyArray
argument_list|()
argument_list|,
name|cell
operator|.
name|getFamilyOffset
argument_list|()
argument_list|,
name|cell
operator|.
name|getFamilyLength
argument_list|()
argument_list|)
argument_list|)
throw|;
block|}
block|}
name|prevCell
operator|=
name|cell
expr_stmt|;
block|}
do|while
condition|(
name|scanner
operator|.
name|next
argument_list|()
condition|)
do|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Full verification complete for bulk load hfile: "
operator|+
name|srcPath
operator|.
name|toString
argument_list|()
operator|+
literal|" took "
operator|+
operator|(
name|EnvironmentEdgeManager
operator|.
name|currentTime
argument_list|()
operator|-
name|verificationStartTime
operator|)
operator|+
literal|" ms"
argument_list|)
expr_stmt|;
block|}
block|}
finally|finally
block|{
if|if
condition|(
name|reader
operator|!=
literal|null
condition|)
name|reader
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**    * This method should only be called from Region. It is assumed that the ranges of values in the    * HFile fit within the stores assigned region. (assertBulkLoadHFileOk checks this)    *    * @param srcPathStr    * @param seqNum sequence Id associated with the HFile    */
specifier|public
name|Pair
argument_list|<
name|Path
argument_list|,
name|Path
argument_list|>
name|preBulkLoadHFile
parameter_list|(
name|String
name|srcPathStr
parameter_list|,
name|long
name|seqNum
parameter_list|)
throws|throws
name|IOException
block|{
name|Path
name|srcPath
init|=
operator|new
name|Path
argument_list|(
name|srcPathStr
argument_list|)
decl_stmt|;
return|return
name|fs
operator|.
name|bulkLoadStoreFile
argument_list|(
name|getColumnFamilyName
argument_list|()
argument_list|,
name|srcPath
argument_list|,
name|seqNum
argument_list|)
return|;
block|}
specifier|public
name|Path
name|bulkLoadHFile
parameter_list|(
name|byte
index|[]
name|family
parameter_list|,
name|String
name|srcPathStr
parameter_list|,
name|Path
name|dstPath
parameter_list|)
throws|throws
name|IOException
block|{
name|Path
name|srcPath
init|=
operator|new
name|Path
argument_list|(
name|srcPathStr
argument_list|)
decl_stmt|;
try|try
block|{
name|fs
operator|.
name|commitStoreFile
argument_list|(
name|srcPath
argument_list|,
name|dstPath
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
if|if
condition|(
name|this
operator|.
name|getCoprocessorHost
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|this
operator|.
name|getCoprocessorHost
argument_list|()
operator|.
name|postCommitStoreFile
argument_list|(
name|family
argument_list|,
name|srcPath
argument_list|,
name|dstPath
argument_list|)
expr_stmt|;
block|}
block|}
name|LOG
operator|.
name|info
argument_list|(
literal|"Loaded HFile "
operator|+
name|srcPath
operator|+
literal|" into store '"
operator|+
name|getColumnFamilyName
argument_list|()
operator|+
literal|"' as "
operator|+
name|dstPath
operator|+
literal|" - updating store file list."
argument_list|)
expr_stmt|;
name|HStoreFile
name|sf
init|=
name|createStoreFileAndReader
argument_list|(
name|dstPath
argument_list|)
decl_stmt|;
name|bulkLoadHFile
argument_list|(
name|sf
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Successfully loaded store file {} into store {} (new location: {})"
argument_list|,
name|srcPath
argument_list|,
name|this
argument_list|,
name|dstPath
argument_list|)
expr_stmt|;
return|return
name|dstPath
return|;
block|}
specifier|public
name|void
name|bulkLoadHFile
parameter_list|(
name|StoreFileInfo
name|fileInfo
parameter_list|)
throws|throws
name|IOException
block|{
name|HStoreFile
name|sf
init|=
name|createStoreFileAndReader
argument_list|(
name|fileInfo
argument_list|)
decl_stmt|;
name|bulkLoadHFile
argument_list|(
name|sf
argument_list|)
expr_stmt|;
block|}
specifier|private
name|void
name|bulkLoadHFile
parameter_list|(
name|HStoreFile
name|sf
parameter_list|)
throws|throws
name|IOException
block|{
name|StoreFileReader
name|r
init|=
name|sf
operator|.
name|getReader
argument_list|()
decl_stmt|;
name|this
operator|.
name|storeSize
operator|.
name|addAndGet
argument_list|(
name|r
operator|.
name|length
argument_list|()
argument_list|)
expr_stmt|;
name|this
operator|.
name|totalUncompressedBytes
operator|.
name|addAndGet
argument_list|(
name|r
operator|.
name|getTotalUncompressedBytes
argument_list|()
argument_list|)
expr_stmt|;
comment|// Append the new storefile into the list
name|this
operator|.
name|lock
operator|.
name|writeLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
name|this
operator|.
name|storeEngine
operator|.
name|getStoreFileManager
argument_list|()
operator|.
name|insertNewFiles
argument_list|(
name|Lists
operator|.
name|newArrayList
argument_list|(
name|sf
argument_list|)
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
comment|// We need the lock, as long as we are updating the storeFiles
comment|// or changing the memstore. Let us release it before calling
comment|// notifyChangeReadersObservers. See HBASE-4485 for a possible
comment|// deadlock scenario that could have happened if continue to hold
comment|// the lock.
name|this
operator|.
name|lock
operator|.
name|writeLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
name|LOG
operator|.
name|info
argument_list|(
literal|"Loaded HFile "
operator|+
name|sf
operator|.
name|getFileInfo
argument_list|()
operator|+
literal|" into store '"
operator|+
name|getColumnFamilyName
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|String
name|traceMessage
init|=
literal|"BULK LOAD time,size,store size,store files ["
operator|+
name|EnvironmentEdgeManager
operator|.
name|currentTime
argument_list|()
operator|+
literal|","
operator|+
name|r
operator|.
name|length
argument_list|()
operator|+
literal|","
operator|+
name|storeSize
operator|+
literal|","
operator|+
name|storeEngine
operator|.
name|getStoreFileManager
argument_list|()
operator|.
name|getStorefileCount
argument_list|()
operator|+
literal|"]"
decl_stmt|;
name|LOG
operator|.
name|trace
argument_list|(
name|traceMessage
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Close all the readers We don't need to worry about subsequent requests because the Region holds    * a write lock that will prevent any more reads or writes.    * @return the {@link StoreFile StoreFiles} that were previously being used.    * @throws IOException on failure    */
specifier|public
name|ImmutableCollection
argument_list|<
name|HStoreFile
argument_list|>
name|close
parameter_list|()
throws|throws
name|IOException
block|{
name|this
operator|.
name|archiveLock
operator|.
name|lock
argument_list|()
expr_stmt|;
name|this
operator|.
name|lock
operator|.
name|writeLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
comment|// Clear so metrics doesn't find them.
name|ImmutableCollection
argument_list|<
name|HStoreFile
argument_list|>
name|result
init|=
name|storeEngine
operator|.
name|getStoreFileManager
argument_list|()
operator|.
name|clearFiles
argument_list|()
decl_stmt|;
name|Collection
argument_list|<
name|HStoreFile
argument_list|>
name|compactedfiles
init|=
name|storeEngine
operator|.
name|getStoreFileManager
argument_list|()
operator|.
name|clearCompactedFiles
argument_list|()
decl_stmt|;
comment|// clear the compacted files
if|if
condition|(
name|CollectionUtils
operator|.
name|isNotEmpty
argument_list|(
name|compactedfiles
argument_list|)
condition|)
block|{
name|removeCompactedfiles
argument_list|(
name|compactedfiles
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|!
name|result
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
comment|// initialize the thread pool for closing store files in parallel.
name|ThreadPoolExecutor
name|storeFileCloserThreadPool
init|=
name|this
operator|.
name|region
operator|.
name|getStoreFileOpenAndCloseThreadPool
argument_list|(
literal|"StoreFileCloserThread-"
operator|+
name|this
operator|.
name|region
operator|.
name|getRegionInfo
argument_list|()
operator|.
name|getEncodedName
argument_list|()
operator|+
literal|"-"
operator|+
name|this
operator|.
name|getColumnFamilyName
argument_list|()
argument_list|)
decl_stmt|;
comment|// close each store file in parallel
name|CompletionService
argument_list|<
name|Void
argument_list|>
name|completionService
init|=
operator|new
name|ExecutorCompletionService
argument_list|<>
argument_list|(
name|storeFileCloserThreadPool
argument_list|)
decl_stmt|;
for|for
control|(
name|HStoreFile
name|f
range|:
name|result
control|)
block|{
name|completionService
operator|.
name|submit
argument_list|(
operator|new
name|Callable
argument_list|<
name|Void
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|Void
name|call
parameter_list|()
throws|throws
name|IOException
block|{
name|boolean
name|evictOnClose
init|=
name|cacheConf
operator|!=
literal|null
condition|?
name|cacheConf
operator|.
name|shouldEvictOnClose
argument_list|()
else|:
literal|true
decl_stmt|;
name|f
operator|.
name|closeStoreFile
argument_list|(
name|evictOnClose
argument_list|)
expr_stmt|;
return|return
literal|null
return|;
block|}
block|}
argument_list|)
expr_stmt|;
block|}
name|IOException
name|ioe
init|=
literal|null
decl_stmt|;
try|try
block|{
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|result
operator|.
name|size
argument_list|()
condition|;
name|i
operator|++
control|)
block|{
try|try
block|{
name|Future
argument_list|<
name|Void
argument_list|>
name|future
init|=
name|completionService
operator|.
name|take
argument_list|()
decl_stmt|;
name|future
operator|.
name|get
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
if|if
condition|(
name|ioe
operator|==
literal|null
condition|)
block|{
name|ioe
operator|=
operator|new
name|InterruptedIOException
argument_list|()
expr_stmt|;
name|ioe
operator|.
name|initCause
argument_list|(
name|e
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|ExecutionException
name|e
parameter_list|)
block|{
if|if
condition|(
name|ioe
operator|==
literal|null
condition|)
name|ioe
operator|=
operator|new
name|IOException
argument_list|(
name|e
operator|.
name|getCause
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
block|}
finally|finally
block|{
name|storeFileCloserThreadPool
operator|.
name|shutdownNow
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|ioe
operator|!=
literal|null
condition|)
throw|throw
name|ioe
throw|;
block|}
name|LOG
operator|.
name|trace
argument_list|(
literal|"Closed {}"
argument_list|,
name|this
argument_list|)
expr_stmt|;
return|return
name|result
return|;
block|}
finally|finally
block|{
name|this
operator|.
name|lock
operator|.
name|writeLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
name|this
operator|.
name|archiveLock
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**    * Snapshot this stores memstore. Call before running    * {@link #flushCache(long, MemStoreSnapshot, MonitoredTask, ThroughputController,    * FlushLifeCycleTracker)}    *  so it has some work to do.    */
name|void
name|snapshot
parameter_list|()
block|{
name|this
operator|.
name|lock
operator|.
name|writeLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
name|this
operator|.
name|memstore
operator|.
name|snapshot
argument_list|()
expr_stmt|;
block|}
finally|finally
block|{
name|this
operator|.
name|lock
operator|.
name|writeLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**    * Write out current snapshot. Presumes {@link #snapshot()} has been called previously.    * @param logCacheFlushId flush sequence number    * @param snapshot    * @param status    * @param throughputController    * @return The path name of the tmp file to which the store was flushed    * @throws IOException if exception occurs during process    */
specifier|protected
name|List
argument_list|<
name|Path
argument_list|>
name|flushCache
parameter_list|(
specifier|final
name|long
name|logCacheFlushId
parameter_list|,
name|MemStoreSnapshot
name|snapshot
parameter_list|,
name|MonitoredTask
name|status
parameter_list|,
name|ThroughputController
name|throughputController
parameter_list|,
name|FlushLifeCycleTracker
name|tracker
parameter_list|)
throws|throws
name|IOException
block|{
comment|// If an exception happens flushing, we let it out without clearing
comment|// the memstore snapshot.  The old snapshot will be returned when we say
comment|// 'snapshot', the next time flush comes around.
comment|// Retry after catching exception when flushing, otherwise server will abort
comment|// itself
name|StoreFlusher
name|flusher
init|=
name|storeEngine
operator|.
name|getStoreFlusher
argument_list|()
decl_stmt|;
name|IOException
name|lastException
init|=
literal|null
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|flushRetriesNumber
condition|;
name|i
operator|++
control|)
block|{
try|try
block|{
name|List
argument_list|<
name|Path
argument_list|>
name|pathNames
init|=
name|flusher
operator|.
name|flushSnapshot
argument_list|(
name|snapshot
argument_list|,
name|logCacheFlushId
argument_list|,
name|status
argument_list|,
name|throughputController
argument_list|,
name|tracker
argument_list|)
decl_stmt|;
name|Path
name|lastPathName
init|=
literal|null
decl_stmt|;
try|try
block|{
for|for
control|(
name|Path
name|pathName
range|:
name|pathNames
control|)
block|{
name|lastPathName
operator|=
name|pathName
expr_stmt|;
name|validateStoreFile
argument_list|(
name|pathName
argument_list|)
expr_stmt|;
block|}
return|return
name|pathNames
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failed validating store file {}, retrying num={}"
argument_list|,
name|lastPathName
argument_list|,
name|i
argument_list|,
name|e
argument_list|)
expr_stmt|;
if|if
condition|(
name|e
operator|instanceof
name|IOException
condition|)
block|{
name|lastException
operator|=
operator|(
name|IOException
operator|)
name|e
expr_stmt|;
block|}
else|else
block|{
name|lastException
operator|=
operator|new
name|IOException
argument_list|(
name|e
argument_list|)
expr_stmt|;
block|}
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failed flushing store file, retrying num={}"
argument_list|,
name|i
argument_list|,
name|e
argument_list|)
expr_stmt|;
name|lastException
operator|=
name|e
expr_stmt|;
block|}
if|if
condition|(
name|lastException
operator|!=
literal|null
operator|&&
name|i
operator|<
operator|(
name|flushRetriesNumber
operator|-
literal|1
operator|)
condition|)
block|{
try|try
block|{
name|Thread
operator|.
name|sleep
argument_list|(
name|pauseTime
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
name|IOException
name|iie
init|=
operator|new
name|InterruptedIOException
argument_list|()
decl_stmt|;
name|iie
operator|.
name|initCause
argument_list|(
name|e
argument_list|)
expr_stmt|;
throw|throw
name|iie
throw|;
block|}
block|}
block|}
throw|throw
name|lastException
throw|;
block|}
comment|/**    * @param path The pathname of the tmp file into which the store was flushed    * @param logCacheFlushId    * @param status    * @return store file created.    * @throws IOException    */
specifier|private
name|HStoreFile
name|commitFile
parameter_list|(
name|Path
name|path
parameter_list|,
name|long
name|logCacheFlushId
parameter_list|,
name|MonitoredTask
name|status
parameter_list|)
throws|throws
name|IOException
block|{
comment|// Write-out finished successfully, move into the right spot
name|Path
name|dstPath
init|=
name|fs
operator|.
name|commitStoreFile
argument_list|(
name|getColumnFamilyName
argument_list|()
argument_list|,
name|path
argument_list|)
decl_stmt|;
name|status
operator|.
name|setStatus
argument_list|(
literal|"Flushing "
operator|+
name|this
operator|+
literal|": reopening flushed file"
argument_list|)
expr_stmt|;
name|HStoreFile
name|sf
init|=
name|createStoreFileAndReader
argument_list|(
name|dstPath
argument_list|)
decl_stmt|;
name|StoreFileReader
name|r
init|=
name|sf
operator|.
name|getReader
argument_list|()
decl_stmt|;
name|this
operator|.
name|storeSize
operator|.
name|addAndGet
argument_list|(
name|r
operator|.
name|length
argument_list|()
argument_list|)
expr_stmt|;
name|this
operator|.
name|totalUncompressedBytes
operator|.
name|addAndGet
argument_list|(
name|r
operator|.
name|getTotalUncompressedBytes
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isInfoEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Added "
operator|+
name|sf
operator|+
literal|", entries="
operator|+
name|r
operator|.
name|getEntries
argument_list|()
operator|+
literal|", sequenceid="
operator|+
name|logCacheFlushId
operator|+
literal|", filesize="
operator|+
name|TraditionalBinaryPrefix
operator|.
name|long2String
argument_list|(
name|r
operator|.
name|length
argument_list|()
argument_list|,
literal|""
argument_list|,
literal|1
argument_list|)
argument_list|)
expr_stmt|;
block|}
return|return
name|sf
return|;
block|}
comment|/**    * @param maxKeyCount    * @param compression Compression algorithm to use    * @param isCompaction whether we are creating a new file in a compaction    * @param includeMVCCReadpoint - whether to include MVCC or not    * @param includesTag - includesTag or not    * @return Writer for a new StoreFile in the tmp dir.    */
comment|// TODO : allow the Writer factory to create Writers of ShipperListener type only in case of
comment|// compaction
specifier|public
name|StoreFileWriter
name|createWriterInTmp
parameter_list|(
name|long
name|maxKeyCount
parameter_list|,
name|Compression
operator|.
name|Algorithm
name|compression
parameter_list|,
name|boolean
name|isCompaction
parameter_list|,
name|boolean
name|includeMVCCReadpoint
parameter_list|,
name|boolean
name|includesTag
parameter_list|,
name|boolean
name|shouldDropBehind
parameter_list|)
throws|throws
name|IOException
block|{
specifier|final
name|CacheConfig
name|writerCacheConf
decl_stmt|;
if|if
condition|(
name|isCompaction
condition|)
block|{
comment|// Don't cache data on write on compactions, unless specifically configured to do so
name|writerCacheConf
operator|=
operator|new
name|CacheConfig
argument_list|(
name|cacheConf
argument_list|)
expr_stmt|;
specifier|final
name|boolean
name|cacheCompactedBlocksOnWrite
init|=
name|cacheConf
operator|.
name|shouldCacheCompactedBlocksOnWrite
argument_list|()
decl_stmt|;
comment|// if data blocks are to be cached on write
comment|// during compaction, we should forcefully
comment|// cache index and bloom blocks as well
if|if
condition|(
name|cacheCompactedBlocksOnWrite
condition|)
block|{
name|writerCacheConf
operator|.
name|enableCacheOnWrite
argument_list|()
expr_stmt|;
if|if
condition|(
operator|!
name|cacheOnWriteLogged
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"For Store {} , cacheCompactedBlocksOnWrite is true, hence enabled "
operator|+
literal|"cacheOnWrite for Data blocks, Index blocks and Bloom filter blocks"
argument_list|,
name|getColumnFamilyName
argument_list|()
argument_list|)
expr_stmt|;
name|cacheOnWriteLogged
operator|=
literal|true
expr_stmt|;
block|}
block|}
else|else
block|{
name|writerCacheConf
operator|.
name|setCacheDataOnWrite
argument_list|(
literal|false
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
name|writerCacheConf
operator|=
name|cacheConf
expr_stmt|;
specifier|final
name|boolean
name|shouldCacheDataOnWrite
init|=
name|cacheConf
operator|.
name|shouldCacheDataOnWrite
argument_list|()
decl_stmt|;
if|if
condition|(
name|shouldCacheDataOnWrite
condition|)
block|{
name|writerCacheConf
operator|.
name|enableCacheOnWrite
argument_list|()
expr_stmt|;
if|if
condition|(
operator|!
name|cacheOnWriteLogged
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"For Store {} , cacheDataOnWrite is true, hence enabled cacheOnWrite for "
operator|+
literal|"Index blocks and Bloom filter blocks"
argument_list|,
name|getColumnFamilyName
argument_list|()
argument_list|)
expr_stmt|;
name|cacheOnWriteLogged
operator|=
literal|true
expr_stmt|;
block|}
block|}
block|}
name|InetSocketAddress
index|[]
name|favoredNodes
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|region
operator|.
name|getRegionServerServices
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|favoredNodes
operator|=
name|region
operator|.
name|getRegionServerServices
argument_list|()
operator|.
name|getFavoredNodesForRegion
argument_list|(
name|region
operator|.
name|getRegionInfo
argument_list|()
operator|.
name|getEncodedName
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|HFileContext
name|hFileContext
init|=
name|createFileContext
argument_list|(
name|compression
argument_list|,
name|includeMVCCReadpoint
argument_list|,
name|includesTag
argument_list|,
name|cryptoContext
argument_list|)
decl_stmt|;
name|Path
name|familyTempDir
init|=
operator|new
name|Path
argument_list|(
name|fs
operator|.
name|getTempDir
argument_list|()
argument_list|,
name|family
operator|.
name|getNameAsString
argument_list|()
argument_list|)
decl_stmt|;
name|StoreFileWriter
operator|.
name|Builder
name|builder
init|=
operator|new
name|StoreFileWriter
operator|.
name|Builder
argument_list|(
name|conf
argument_list|,
name|writerCacheConf
argument_list|,
name|this
operator|.
name|getFileSystem
argument_list|()
argument_list|)
operator|.
name|withOutputDir
argument_list|(
name|familyTempDir
argument_list|)
operator|.
name|withComparator
argument_list|(
name|comparator
argument_list|)
operator|.
name|withBloomType
argument_list|(
name|family
operator|.
name|getBloomFilterType
argument_list|()
argument_list|)
operator|.
name|withMaxKeyCount
argument_list|(
name|maxKeyCount
argument_list|)
operator|.
name|withFavoredNodes
argument_list|(
name|favoredNodes
argument_list|)
operator|.
name|withFileContext
argument_list|(
name|hFileContext
argument_list|)
operator|.
name|withShouldDropCacheBehind
argument_list|(
name|shouldDropBehind
argument_list|)
operator|.
name|withCompactedFilesSupplier
argument_list|(
name|this
operator|::
name|getCompactedFiles
argument_list|)
decl_stmt|;
return|return
name|builder
operator|.
name|build
argument_list|()
return|;
block|}
specifier|private
name|HFileContext
name|createFileContext
parameter_list|(
name|Compression
operator|.
name|Algorithm
name|compression
parameter_list|,
name|boolean
name|includeMVCCReadpoint
parameter_list|,
name|boolean
name|includesTag
parameter_list|,
name|Encryption
operator|.
name|Context
name|cryptoContext
parameter_list|)
block|{
if|if
condition|(
name|compression
operator|==
literal|null
condition|)
block|{
name|compression
operator|=
name|HFile
operator|.
name|DEFAULT_COMPRESSION_ALGORITHM
expr_stmt|;
block|}
name|HFileContext
name|hFileContext
init|=
operator|new
name|HFileContextBuilder
argument_list|()
operator|.
name|withIncludesMvcc
argument_list|(
name|includeMVCCReadpoint
argument_list|)
operator|.
name|withIncludesTags
argument_list|(
name|includesTag
argument_list|)
operator|.
name|withCompression
argument_list|(
name|compression
argument_list|)
operator|.
name|withCompressTags
argument_list|(
name|family
operator|.
name|isCompressTags
argument_list|()
argument_list|)
operator|.
name|withChecksumType
argument_list|(
name|checksumType
argument_list|)
operator|.
name|withBytesPerCheckSum
argument_list|(
name|bytesPerChecksum
argument_list|)
operator|.
name|withBlockSize
argument_list|(
name|blocksize
argument_list|)
operator|.
name|withHBaseCheckSum
argument_list|(
literal|true
argument_list|)
operator|.
name|withDataBlockEncoding
argument_list|(
name|family
operator|.
name|getDataBlockEncoding
argument_list|()
argument_list|)
operator|.
name|withEncryptionContext
argument_list|(
name|cryptoContext
argument_list|)
operator|.
name|withCreateTime
argument_list|(
name|EnvironmentEdgeManager
operator|.
name|currentTime
argument_list|()
argument_list|)
operator|.
name|withColumnFamily
argument_list|(
name|family
operator|.
name|getName
argument_list|()
argument_list|)
operator|.
name|withTableName
argument_list|(
name|region
operator|.
name|getTableDescriptor
argument_list|()
operator|.
name|getTableName
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|)
operator|.
name|build
argument_list|()
decl_stmt|;
return|return
name|hFileContext
return|;
block|}
specifier|private
name|long
name|getTotalSize
parameter_list|(
name|Collection
argument_list|<
name|HStoreFile
argument_list|>
name|sfs
parameter_list|)
block|{
return|return
name|sfs
operator|.
name|stream
argument_list|()
operator|.
name|mapToLong
argument_list|(
name|sf
lambda|->
name|sf
operator|.
name|getReader
argument_list|()
operator|.
name|length
argument_list|()
argument_list|)
operator|.
name|sum
argument_list|()
return|;
block|}
comment|/**    * Change storeFiles adding into place the Reader produced by this new flush.    * @param sfs Store files    * @param snapshotId    * @throws IOException    * @return Whether compaction is required.    */
specifier|private
name|boolean
name|updateStorefiles
parameter_list|(
name|List
argument_list|<
name|HStoreFile
argument_list|>
name|sfs
parameter_list|,
name|long
name|snapshotId
parameter_list|)
throws|throws
name|IOException
block|{
name|this
operator|.
name|lock
operator|.
name|writeLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
name|this
operator|.
name|storeEngine
operator|.
name|getStoreFileManager
argument_list|()
operator|.
name|insertNewFiles
argument_list|(
name|sfs
argument_list|)
expr_stmt|;
if|if
condition|(
name|snapshotId
operator|>
literal|0
condition|)
block|{
name|this
operator|.
name|memstore
operator|.
name|clearSnapshot
argument_list|(
name|snapshotId
argument_list|)
expr_stmt|;
block|}
block|}
finally|finally
block|{
comment|// We need the lock, as long as we are updating the storeFiles
comment|// or changing the memstore. Let us release it before calling
comment|// notifyChangeReadersObservers. See HBASE-4485 for a possible
comment|// deadlock scenario that could have happened if continue to hold
comment|// the lock.
name|this
operator|.
name|lock
operator|.
name|writeLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
comment|// notify to be called here - only in case of flushes
name|notifyChangedReadersObservers
argument_list|(
name|sfs
argument_list|)
expr_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|long
name|totalSize
init|=
name|getTotalSize
argument_list|(
name|sfs
argument_list|)
decl_stmt|;
name|String
name|traceMessage
init|=
literal|"FLUSH time,count,size,store size,store files ["
operator|+
name|EnvironmentEdgeManager
operator|.
name|currentTime
argument_list|()
operator|+
literal|","
operator|+
name|sfs
operator|.
name|size
argument_list|()
operator|+
literal|","
operator|+
name|totalSize
operator|+
literal|","
operator|+
name|storeSize
operator|+
literal|","
operator|+
name|storeEngine
operator|.
name|getStoreFileManager
argument_list|()
operator|.
name|getStorefileCount
argument_list|()
operator|+
literal|"]"
decl_stmt|;
name|LOG
operator|.
name|trace
argument_list|(
name|traceMessage
argument_list|)
expr_stmt|;
block|}
return|return
name|needsCompaction
argument_list|()
return|;
block|}
comment|/**    * Notify all observers that set of Readers has changed.    * @throws IOException    */
specifier|private
name|void
name|notifyChangedReadersObservers
parameter_list|(
name|List
argument_list|<
name|HStoreFile
argument_list|>
name|sfs
parameter_list|)
throws|throws
name|IOException
block|{
for|for
control|(
name|ChangedReadersObserver
name|o
range|:
name|this
operator|.
name|changedReaderObservers
control|)
block|{
name|List
argument_list|<
name|KeyValueScanner
argument_list|>
name|memStoreScanners
decl_stmt|;
name|this
operator|.
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
name|memStoreScanners
operator|=
name|this
operator|.
name|memstore
operator|.
name|getScanners
argument_list|(
name|o
operator|.
name|getReadPoint
argument_list|()
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|this
operator|.
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
name|o
operator|.
name|updateReaders
argument_list|(
name|sfs
argument_list|,
name|memStoreScanners
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Get all scanners with no filtering based on TTL (that happens further down the line).    * @param cacheBlocks cache the blocks or not    * @param usePread true to use pread, false if not    * @param isCompaction true if the scanner is created for compaction    * @param matcher the scan query matcher    * @param startRow the start row    * @param stopRow the stop row    * @param readPt the read point of the current scan    * @return all scanners for this store    */
specifier|public
name|List
argument_list|<
name|KeyValueScanner
argument_list|>
name|getScanners
parameter_list|(
name|boolean
name|cacheBlocks
parameter_list|,
name|boolean
name|isGet
parameter_list|,
name|boolean
name|usePread
parameter_list|,
name|boolean
name|isCompaction
parameter_list|,
name|ScanQueryMatcher
name|matcher
parameter_list|,
name|byte
index|[]
name|startRow
parameter_list|,
name|byte
index|[]
name|stopRow
parameter_list|,
name|long
name|readPt
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|getScanners
argument_list|(
name|cacheBlocks
argument_list|,
name|usePread
argument_list|,
name|isCompaction
argument_list|,
name|matcher
argument_list|,
name|startRow
argument_list|,
literal|true
argument_list|,
name|stopRow
argument_list|,
literal|false
argument_list|,
name|readPt
argument_list|)
return|;
block|}
comment|/**    * Get all scanners with no filtering based on TTL (that happens further down the line).    * @param cacheBlocks cache the blocks or not    * @param usePread true to use pread, false if not    * @param isCompaction true if the scanner is created for compaction    * @param matcher the scan query matcher    * @param startRow the start row    * @param includeStartRow true to include start row, false if not    * @param stopRow the stop row    * @param includeStopRow true to include stop row, false if not    * @param readPt the read point of the current scan    * @return all scanners for this store    */
specifier|public
name|List
argument_list|<
name|KeyValueScanner
argument_list|>
name|getScanners
parameter_list|(
name|boolean
name|cacheBlocks
parameter_list|,
name|boolean
name|usePread
parameter_list|,
name|boolean
name|isCompaction
parameter_list|,
name|ScanQueryMatcher
name|matcher
parameter_list|,
name|byte
index|[]
name|startRow
parameter_list|,
name|boolean
name|includeStartRow
parameter_list|,
name|byte
index|[]
name|stopRow
parameter_list|,
name|boolean
name|includeStopRow
parameter_list|,
name|long
name|readPt
parameter_list|)
throws|throws
name|IOException
block|{
name|Collection
argument_list|<
name|HStoreFile
argument_list|>
name|storeFilesToScan
decl_stmt|;
name|List
argument_list|<
name|KeyValueScanner
argument_list|>
name|memStoreScanners
decl_stmt|;
name|this
operator|.
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
name|storeFilesToScan
operator|=
name|this
operator|.
name|storeEngine
operator|.
name|getStoreFileManager
argument_list|()
operator|.
name|getFilesForScan
argument_list|(
name|startRow
argument_list|,
name|includeStartRow
argument_list|,
name|stopRow
argument_list|,
name|includeStopRow
argument_list|)
expr_stmt|;
name|memStoreScanners
operator|=
name|this
operator|.
name|memstore
operator|.
name|getScanners
argument_list|(
name|readPt
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|this
operator|.
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
try|try
block|{
comment|// First the store file scanners
comment|// TODO this used to get the store files in descending order,
comment|// but now we get them in ascending order, which I think is
comment|// actually more correct, since memstore get put at the end.
name|List
argument_list|<
name|StoreFileScanner
argument_list|>
name|sfScanners
init|=
name|StoreFileScanner
operator|.
name|getScannersForStoreFiles
argument_list|(
name|storeFilesToScan
argument_list|,
name|cacheBlocks
argument_list|,
name|usePread
argument_list|,
name|isCompaction
argument_list|,
literal|false
argument_list|,
name|matcher
argument_list|,
name|readPt
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|KeyValueScanner
argument_list|>
name|scanners
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
name|sfScanners
operator|.
name|size
argument_list|()
operator|+
literal|1
argument_list|)
decl_stmt|;
name|scanners
operator|.
name|addAll
argument_list|(
name|sfScanners
argument_list|)
expr_stmt|;
comment|// Then the memstore scanners
name|scanners
operator|.
name|addAll
argument_list|(
name|memStoreScanners
argument_list|)
expr_stmt|;
return|return
name|scanners
return|;
block|}
catch|catch
parameter_list|(
name|Throwable
name|t
parameter_list|)
block|{
name|clearAndClose
argument_list|(
name|memStoreScanners
argument_list|)
expr_stmt|;
throw|throw
name|t
operator|instanceof
name|IOException
condition|?
operator|(
name|IOException
operator|)
name|t
else|:
operator|new
name|IOException
argument_list|(
name|t
argument_list|)
throw|;
block|}
block|}
specifier|private
specifier|static
name|void
name|clearAndClose
parameter_list|(
name|List
argument_list|<
name|KeyValueScanner
argument_list|>
name|scanners
parameter_list|)
block|{
if|if
condition|(
name|scanners
operator|==
literal|null
condition|)
block|{
return|return;
block|}
for|for
control|(
name|KeyValueScanner
name|s
range|:
name|scanners
control|)
block|{
name|s
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
name|scanners
operator|.
name|clear
argument_list|()
expr_stmt|;
block|}
comment|/**    * Create scanners on the given files and if needed on the memstore with no filtering based on TTL    * (that happens further down the line).    * @param files the list of files on which the scanners has to be created    * @param cacheBlocks cache the blocks or not    * @param usePread true to use pread, false if not    * @param isCompaction true if the scanner is created for compaction    * @param matcher the scan query matcher    * @param startRow the start row    * @param stopRow the stop row    * @param readPt the read point of the current scan    * @param includeMemstoreScanner true if memstore has to be included    * @return scanners on the given files and on the memstore if specified    */
specifier|public
name|List
argument_list|<
name|KeyValueScanner
argument_list|>
name|getScanners
parameter_list|(
name|List
argument_list|<
name|HStoreFile
argument_list|>
name|files
parameter_list|,
name|boolean
name|cacheBlocks
parameter_list|,
name|boolean
name|isGet
parameter_list|,
name|boolean
name|usePread
parameter_list|,
name|boolean
name|isCompaction
parameter_list|,
name|ScanQueryMatcher
name|matcher
parameter_list|,
name|byte
index|[]
name|startRow
parameter_list|,
name|byte
index|[]
name|stopRow
parameter_list|,
name|long
name|readPt
parameter_list|,
name|boolean
name|includeMemstoreScanner
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|getScanners
argument_list|(
name|files
argument_list|,
name|cacheBlocks
argument_list|,
name|usePread
argument_list|,
name|isCompaction
argument_list|,
name|matcher
argument_list|,
name|startRow
argument_list|,
literal|true
argument_list|,
name|stopRow
argument_list|,
literal|false
argument_list|,
name|readPt
argument_list|,
name|includeMemstoreScanner
argument_list|)
return|;
block|}
comment|/**    * Create scanners on the given files and if needed on the memstore with no filtering based on TTL    * (that happens further down the line).    * @param files the list of files on which the scanners has to be created    * @param cacheBlocks ache the blocks or not    * @param usePread true to use pread, false if not    * @param isCompaction true if the scanner is created for compaction    * @param matcher the scan query matcher    * @param startRow the start row    * @param includeStartRow true to include start row, false if not    * @param stopRow the stop row    * @param includeStopRow true to include stop row, false if not    * @param readPt the read point of the current scan    * @param includeMemstoreScanner true if memstore has to be included    * @return scanners on the given files and on the memstore if specified    */
specifier|public
name|List
argument_list|<
name|KeyValueScanner
argument_list|>
name|getScanners
parameter_list|(
name|List
argument_list|<
name|HStoreFile
argument_list|>
name|files
parameter_list|,
name|boolean
name|cacheBlocks
parameter_list|,
name|boolean
name|usePread
parameter_list|,
name|boolean
name|isCompaction
parameter_list|,
name|ScanQueryMatcher
name|matcher
parameter_list|,
name|byte
index|[]
name|startRow
parameter_list|,
name|boolean
name|includeStartRow
parameter_list|,
name|byte
index|[]
name|stopRow
parameter_list|,
name|boolean
name|includeStopRow
parameter_list|,
name|long
name|readPt
parameter_list|,
name|boolean
name|includeMemstoreScanner
parameter_list|)
throws|throws
name|IOException
block|{
name|List
argument_list|<
name|KeyValueScanner
argument_list|>
name|memStoreScanners
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|includeMemstoreScanner
condition|)
block|{
name|this
operator|.
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
name|memStoreScanners
operator|=
name|this
operator|.
name|memstore
operator|.
name|getScanners
argument_list|(
name|readPt
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|this
operator|.
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
try|try
block|{
name|List
argument_list|<
name|StoreFileScanner
argument_list|>
name|sfScanners
init|=
name|StoreFileScanner
operator|.
name|getScannersForStoreFiles
argument_list|(
name|files
argument_list|,
name|cacheBlocks
argument_list|,
name|usePread
argument_list|,
name|isCompaction
argument_list|,
literal|false
argument_list|,
name|matcher
argument_list|,
name|readPt
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|KeyValueScanner
argument_list|>
name|scanners
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
name|sfScanners
operator|.
name|size
argument_list|()
operator|+
literal|1
argument_list|)
decl_stmt|;
name|scanners
operator|.
name|addAll
argument_list|(
name|sfScanners
argument_list|)
expr_stmt|;
comment|// Then the memstore scanners
if|if
condition|(
name|memStoreScanners
operator|!=
literal|null
condition|)
block|{
name|scanners
operator|.
name|addAll
argument_list|(
name|memStoreScanners
argument_list|)
expr_stmt|;
block|}
return|return
name|scanners
return|;
block|}
catch|catch
parameter_list|(
name|Throwable
name|t
parameter_list|)
block|{
name|clearAndClose
argument_list|(
name|memStoreScanners
argument_list|)
expr_stmt|;
throw|throw
name|t
operator|instanceof
name|IOException
condition|?
operator|(
name|IOException
operator|)
name|t
else|:
operator|new
name|IOException
argument_list|(
name|t
argument_list|)
throw|;
block|}
block|}
comment|/**    * @param o Observer who wants to know about changes in set of Readers    */
specifier|public
name|void
name|addChangedReaderObserver
parameter_list|(
name|ChangedReadersObserver
name|o
parameter_list|)
block|{
name|this
operator|.
name|changedReaderObservers
operator|.
name|add
argument_list|(
name|o
argument_list|)
expr_stmt|;
block|}
comment|/**    * @param o Observer no longer interested in changes in set of Readers.    */
specifier|public
name|void
name|deleteChangedReaderObserver
parameter_list|(
name|ChangedReadersObserver
name|o
parameter_list|)
block|{
comment|// We don't check if observer present; it may not be (legitimately)
name|this
operator|.
name|changedReaderObservers
operator|.
name|remove
argument_list|(
name|o
argument_list|)
expr_stmt|;
block|}
comment|//////////////////////////////////////////////////////////////////////////////
comment|// Compaction
comment|//////////////////////////////////////////////////////////////////////////////
comment|/**    * Compact the StoreFiles.  This method may take some time, so the calling    * thread must be able to block for long periods.    *    *<p>During this time, the Store can work as usual, getting values from    * StoreFiles and writing new StoreFiles from the memstore.    *    * Existing StoreFiles are not destroyed until the new compacted StoreFile is    * completely written-out to disk.    *    *<p>The compactLock prevents multiple simultaneous compactions.    * The structureLock prevents us from interfering with other write operations.    *    *<p>We don't want to hold the structureLock for the whole time, as a compact()    * can be lengthy and we want to allow cache-flushes during this period.    *    *<p> Compaction event should be idempotent, since there is no IO Fencing for    * the region directory in hdfs. A region server might still try to complete the    * compaction after it lost the region. That is why the following events are carefully    * ordered for a compaction:    *  1. Compaction writes new files under region/.tmp directory (compaction output)    *  2. Compaction atomically moves the temporary file under region directory    *  3. Compaction appends a WAL edit containing the compaction input and output files.    *  Forces sync on WAL.    *  4. Compaction deletes the input files from the region directory.    *    * Failure conditions are handled like this:    *  - If RS fails before 2, compaction wont complete. Even if RS lives on and finishes    *  the compaction later, it will only write the new data file to the region directory.    *  Since we already have this data, this will be idempotent but we will have a redundant    *  copy of the data.    *  - If RS fails between 2 and 3, the region will have a redundant copy of the data. The    *  RS that failed won't be able to finish snyc() for WAL because of lease recovery in WAL.    *  - If RS fails after 3, the region region server who opens the region will pick up the    *  the compaction marker from the WAL and replay it by removing the compaction input files.    *  Failed RS can also attempt to delete those files, but the operation will be idempotent    *    * See HBASE-2231 for details.    *    * @param compaction compaction details obtained from requestCompaction()    * @throws IOException    * @return Storefile we compacted into or null if we failed or opted out early.    */
specifier|public
name|List
argument_list|<
name|HStoreFile
argument_list|>
name|compact
parameter_list|(
name|CompactionContext
name|compaction
parameter_list|,
name|ThroughputController
name|throughputController
parameter_list|,
name|User
name|user
parameter_list|)
throws|throws
name|IOException
block|{
assert|assert
name|compaction
operator|!=
literal|null
assert|;
name|CompactionRequestImpl
name|cr
init|=
name|compaction
operator|.
name|getRequest
argument_list|()
decl_stmt|;
try|try
block|{
comment|// Do all sanity checking in here if we have a valid CompactionRequestImpl
comment|// because we need to clean up after it on the way out in a finally
comment|// block below
name|long
name|compactionStartTime
init|=
name|EnvironmentEdgeManager
operator|.
name|currentTime
argument_list|()
decl_stmt|;
assert|assert
name|compaction
operator|.
name|hasSelection
argument_list|()
assert|;
name|Collection
argument_list|<
name|HStoreFile
argument_list|>
name|filesToCompact
init|=
name|cr
operator|.
name|getFiles
argument_list|()
decl_stmt|;
assert|assert
operator|!
name|filesToCompact
operator|.
name|isEmpty
argument_list|()
assert|;
synchronized|synchronized
init|(
name|filesCompacting
init|)
block|{
comment|// sanity check: we're compacting files that this store knows about
comment|// TODO: change this to LOG.error() after more debugging
name|Preconditions
operator|.
name|checkArgument
argument_list|(
name|filesCompacting
operator|.
name|containsAll
argument_list|(
name|filesToCompact
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|// Ready to go. Have list of files to compact.
name|LOG
operator|.
name|info
argument_list|(
literal|"Starting compaction of "
operator|+
name|filesToCompact
operator|+
literal|" into tmpdir="
operator|+
name|fs
operator|.
name|getTempDir
argument_list|()
operator|+
literal|", totalSize="
operator|+
name|TraditionalBinaryPrefix
operator|.
name|long2String
argument_list|(
name|cr
operator|.
name|getSize
argument_list|()
argument_list|,
literal|""
argument_list|,
literal|1
argument_list|)
argument_list|)
expr_stmt|;
return|return
name|doCompaction
argument_list|(
name|cr
argument_list|,
name|filesToCompact
argument_list|,
name|user
argument_list|,
name|compactionStartTime
argument_list|,
name|compaction
operator|.
name|compact
argument_list|(
name|throughputController
argument_list|,
name|user
argument_list|)
argument_list|)
return|;
block|}
finally|finally
block|{
name|finishCompactionRequest
argument_list|(
name|cr
argument_list|)
expr_stmt|;
block|}
block|}
annotation|@
name|VisibleForTesting
specifier|protected
name|List
argument_list|<
name|HStoreFile
argument_list|>
name|doCompaction
parameter_list|(
name|CompactionRequestImpl
name|cr
parameter_list|,
name|Collection
argument_list|<
name|HStoreFile
argument_list|>
name|filesToCompact
parameter_list|,
name|User
name|user
parameter_list|,
name|long
name|compactionStartTime
parameter_list|,
name|List
argument_list|<
name|Path
argument_list|>
name|newFiles
parameter_list|)
throws|throws
name|IOException
block|{
comment|// Do the steps necessary to complete the compaction.
name|List
argument_list|<
name|HStoreFile
argument_list|>
name|sfs
init|=
name|moveCompactedFilesIntoPlace
argument_list|(
name|cr
argument_list|,
name|newFiles
argument_list|,
name|user
argument_list|)
decl_stmt|;
name|writeCompactionWalRecord
argument_list|(
name|filesToCompact
argument_list|,
name|sfs
argument_list|)
expr_stmt|;
name|replaceStoreFiles
argument_list|(
name|filesToCompact
argument_list|,
name|sfs
argument_list|)
expr_stmt|;
if|if
condition|(
name|cr
operator|.
name|isMajor
argument_list|()
condition|)
block|{
name|majorCompactedCellsCount
operator|.
name|addAndGet
argument_list|(
name|getCompactionProgress
argument_list|()
operator|.
name|getTotalCompactingKVs
argument_list|()
argument_list|)
expr_stmt|;
name|majorCompactedCellsSize
operator|.
name|addAndGet
argument_list|(
name|getCompactionProgress
argument_list|()
operator|.
name|totalCompactedSize
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|compactedCellsCount
operator|.
name|addAndGet
argument_list|(
name|getCompactionProgress
argument_list|()
operator|.
name|getTotalCompactingKVs
argument_list|()
argument_list|)
expr_stmt|;
name|compactedCellsSize
operator|.
name|addAndGet
argument_list|(
name|getCompactionProgress
argument_list|()
operator|.
name|totalCompactedSize
argument_list|)
expr_stmt|;
block|}
name|long
name|outputBytes
init|=
name|getTotalSize
argument_list|(
name|sfs
argument_list|)
decl_stmt|;
comment|// At this point the store will use new files for all new scanners.
name|completeCompaction
argument_list|(
name|filesToCompact
argument_list|)
expr_stmt|;
comment|// update store size.
name|long
name|now
init|=
name|EnvironmentEdgeManager
operator|.
name|currentTime
argument_list|()
decl_stmt|;
if|if
condition|(
name|region
operator|.
name|getRegionServerServices
argument_list|()
operator|!=
literal|null
operator|&&
name|region
operator|.
name|getRegionServerServices
argument_list|()
operator|.
name|getMetrics
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|region
operator|.
name|getRegionServerServices
argument_list|()
operator|.
name|getMetrics
argument_list|()
operator|.
name|updateCompaction
argument_list|(
name|region
operator|.
name|getTableDescriptor
argument_list|()
operator|.
name|getTableName
argument_list|()
operator|.
name|getNameAsString
argument_list|()
argument_list|,
name|cr
operator|.
name|isMajor
argument_list|()
argument_list|,
name|now
operator|-
name|compactionStartTime
argument_list|,
name|cr
operator|.
name|getFiles
argument_list|()
operator|.
name|size
argument_list|()
argument_list|,
name|newFiles
operator|.
name|size
argument_list|()
argument_list|,
name|cr
operator|.
name|getSize
argument_list|()
argument_list|,
name|outputBytes
argument_list|)
expr_stmt|;
block|}
name|logCompactionEndMessage
argument_list|(
name|cr
argument_list|,
name|sfs
argument_list|,
name|now
argument_list|,
name|compactionStartTime
argument_list|)
expr_stmt|;
return|return
name|sfs
return|;
block|}
specifier|private
name|List
argument_list|<
name|HStoreFile
argument_list|>
name|moveCompactedFilesIntoPlace
parameter_list|(
name|CompactionRequestImpl
name|cr
parameter_list|,
name|List
argument_list|<
name|Path
argument_list|>
name|newFiles
parameter_list|,
name|User
name|user
parameter_list|)
throws|throws
name|IOException
block|{
name|List
argument_list|<
name|HStoreFile
argument_list|>
name|sfs
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
name|newFiles
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
for|for
control|(
name|Path
name|newFile
range|:
name|newFiles
control|)
block|{
assert|assert
name|newFile
operator|!=
literal|null
assert|;
name|HStoreFile
name|sf
init|=
name|moveFileIntoPlace
argument_list|(
name|newFile
argument_list|)
decl_stmt|;
if|if
condition|(
name|this
operator|.
name|getCoprocessorHost
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|getCoprocessorHost
argument_list|()
operator|.
name|postCompact
argument_list|(
name|this
argument_list|,
name|sf
argument_list|,
name|cr
operator|.
name|getTracker
argument_list|()
argument_list|,
name|cr
argument_list|,
name|user
argument_list|)
expr_stmt|;
block|}
assert|assert
name|sf
operator|!=
literal|null
assert|;
name|sfs
operator|.
name|add
argument_list|(
name|sf
argument_list|)
expr_stmt|;
block|}
return|return
name|sfs
return|;
block|}
comment|// Package-visible for tests
name|HStoreFile
name|moveFileIntoPlace
parameter_list|(
name|Path
name|newFile
parameter_list|)
throws|throws
name|IOException
block|{
name|validateStoreFile
argument_list|(
name|newFile
argument_list|)
expr_stmt|;
comment|// Move the file into the right spot
name|Path
name|destPath
init|=
name|fs
operator|.
name|commitStoreFile
argument_list|(
name|getColumnFamilyName
argument_list|()
argument_list|,
name|newFile
argument_list|)
decl_stmt|;
return|return
name|createStoreFileAndReader
argument_list|(
name|destPath
argument_list|)
return|;
block|}
comment|/**    * Writes the compaction WAL record.    * @param filesCompacted Files compacted (input).    * @param newFiles Files from compaction.    */
specifier|private
name|void
name|writeCompactionWalRecord
parameter_list|(
name|Collection
argument_list|<
name|HStoreFile
argument_list|>
name|filesCompacted
parameter_list|,
name|Collection
argument_list|<
name|HStoreFile
argument_list|>
name|newFiles
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|region
operator|.
name|getWAL
argument_list|()
operator|==
literal|null
condition|)
block|{
return|return;
block|}
name|List
argument_list|<
name|Path
argument_list|>
name|inputPaths
init|=
name|filesCompacted
operator|.
name|stream
argument_list|()
operator|.
name|map
argument_list|(
name|HStoreFile
operator|::
name|getPath
argument_list|)
operator|.
name|collect
argument_list|(
name|Collectors
operator|.
name|toList
argument_list|()
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|Path
argument_list|>
name|outputPaths
init|=
name|newFiles
operator|.
name|stream
argument_list|()
operator|.
name|map
argument_list|(
name|HStoreFile
operator|::
name|getPath
argument_list|)
operator|.
name|collect
argument_list|(
name|Collectors
operator|.
name|toList
argument_list|()
argument_list|)
decl_stmt|;
name|RegionInfo
name|info
init|=
name|this
operator|.
name|region
operator|.
name|getRegionInfo
argument_list|()
decl_stmt|;
name|CompactionDescriptor
name|compactionDescriptor
init|=
name|ProtobufUtil
operator|.
name|toCompactionDescriptor
argument_list|(
name|info
argument_list|,
name|family
operator|.
name|getName
argument_list|()
argument_list|,
name|inputPaths
argument_list|,
name|outputPaths
argument_list|,
name|fs
operator|.
name|getStoreDir
argument_list|(
name|getColumnFamilyDescriptor
argument_list|()
operator|.
name|getNameAsString
argument_list|()
argument_list|)
argument_list|)
decl_stmt|;
comment|// Fix reaching into Region to get the maxWaitForSeqId.
comment|// Does this method belong in Region altogether given it is making so many references up there?
comment|// Could be Region#writeCompactionMarker(compactionDescriptor);
name|WALUtil
operator|.
name|writeCompactionMarker
argument_list|(
name|this
operator|.
name|region
operator|.
name|getWAL
argument_list|()
argument_list|,
name|this
operator|.
name|region
operator|.
name|getReplicationScope
argument_list|()
argument_list|,
name|this
operator|.
name|region
operator|.
name|getRegionInfo
argument_list|()
argument_list|,
name|compactionDescriptor
argument_list|,
name|this
operator|.
name|region
operator|.
name|getMVCC
argument_list|()
argument_list|)
expr_stmt|;
block|}
annotation|@
name|VisibleForTesting
name|void
name|replaceStoreFiles
parameter_list|(
name|Collection
argument_list|<
name|HStoreFile
argument_list|>
name|compactedFiles
parameter_list|,
name|Collection
argument_list|<
name|HStoreFile
argument_list|>
name|result
parameter_list|)
throws|throws
name|IOException
block|{
name|this
operator|.
name|lock
operator|.
name|writeLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
name|this
operator|.
name|storeEngine
operator|.
name|getStoreFileManager
argument_list|()
operator|.
name|addCompactionResults
argument_list|(
name|compactedFiles
argument_list|,
name|result
argument_list|)
expr_stmt|;
synchronized|synchronized
init|(
name|filesCompacting
init|)
block|{
name|filesCompacting
operator|.
name|removeAll
argument_list|(
name|compactedFiles
argument_list|)
expr_stmt|;
block|}
comment|// These may be null when the RS is shutting down. The space quota Chores will fix the Region
comment|// sizes later so it's not super-critical if we miss these.
name|RegionServerServices
name|rsServices
init|=
name|region
operator|.
name|getRegionServerServices
argument_list|()
decl_stmt|;
if|if
condition|(
name|rsServices
operator|!=
literal|null
operator|&&
name|rsServices
operator|.
name|getRegionServerSpaceQuotaManager
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|updateSpaceQuotaAfterFileReplacement
argument_list|(
name|rsServices
operator|.
name|getRegionServerSpaceQuotaManager
argument_list|()
operator|.
name|getRegionSizeStore
argument_list|()
argument_list|,
name|getRegionInfo
argument_list|()
argument_list|,
name|compactedFiles
argument_list|,
name|result
argument_list|)
expr_stmt|;
block|}
block|}
finally|finally
block|{
name|this
operator|.
name|lock
operator|.
name|writeLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**    * Updates the space quota usage for this region, removing the size for files compacted away    * and adding in the size for new files.    *    * @param sizeStore The object tracking changes in region size for space quotas.    * @param regionInfo The identifier for the region whose size is being updated.    * @param oldFiles Files removed from this store's region.    * @param newFiles Files added to this store's region.    */
name|void
name|updateSpaceQuotaAfterFileReplacement
parameter_list|(
name|RegionSizeStore
name|sizeStore
parameter_list|,
name|RegionInfo
name|regionInfo
parameter_list|,
name|Collection
argument_list|<
name|HStoreFile
argument_list|>
name|oldFiles
parameter_list|,
name|Collection
argument_list|<
name|HStoreFile
argument_list|>
name|newFiles
parameter_list|)
block|{
name|long
name|delta
init|=
literal|0
decl_stmt|;
if|if
condition|(
name|oldFiles
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|HStoreFile
name|compactedFile
range|:
name|oldFiles
control|)
block|{
if|if
condition|(
name|compactedFile
operator|.
name|isHFile
argument_list|()
condition|)
block|{
name|delta
operator|-=
name|compactedFile
operator|.
name|getReader
argument_list|()
operator|.
name|length
argument_list|()
expr_stmt|;
block|}
block|}
block|}
if|if
condition|(
name|newFiles
operator|!=
literal|null
condition|)
block|{
for|for
control|(
name|HStoreFile
name|newFile
range|:
name|newFiles
control|)
block|{
if|if
condition|(
name|newFile
operator|.
name|isHFile
argument_list|()
condition|)
block|{
name|delta
operator|+=
name|newFile
operator|.
name|getReader
argument_list|()
operator|.
name|length
argument_list|()
expr_stmt|;
block|}
block|}
block|}
name|sizeStore
operator|.
name|incrementRegionSize
argument_list|(
name|regionInfo
argument_list|,
name|delta
argument_list|)
expr_stmt|;
block|}
comment|/**    * Log a very elaborate compaction completion message.    * @param cr Request.    * @param sfs Resulting files.    * @param compactionStartTime Start time.    */
specifier|private
name|void
name|logCompactionEndMessage
parameter_list|(
name|CompactionRequestImpl
name|cr
parameter_list|,
name|List
argument_list|<
name|HStoreFile
argument_list|>
name|sfs
parameter_list|,
name|long
name|now
parameter_list|,
name|long
name|compactionStartTime
parameter_list|)
block|{
name|StringBuilder
name|message
init|=
operator|new
name|StringBuilder
argument_list|(
literal|"Completed"
operator|+
operator|(
name|cr
operator|.
name|isMajor
argument_list|()
condition|?
literal|" major"
else|:
literal|""
operator|)
operator|+
literal|" compaction of "
operator|+
name|cr
operator|.
name|getFiles
argument_list|()
operator|.
name|size
argument_list|()
operator|+
operator|(
name|cr
operator|.
name|isAllFiles
argument_list|()
condition|?
literal|" (all)"
else|:
literal|""
operator|)
operator|+
literal|" file(s) in "
operator|+
name|this
operator|+
literal|" of "
operator|+
name|this
operator|.
name|getRegionInfo
argument_list|()
operator|.
name|getShortNameToLog
argument_list|()
operator|+
literal|" into "
argument_list|)
decl_stmt|;
if|if
condition|(
name|sfs
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|message
operator|.
name|append
argument_list|(
literal|"none, "
argument_list|)
expr_stmt|;
block|}
else|else
block|{
for|for
control|(
name|HStoreFile
name|sf
range|:
name|sfs
control|)
block|{
name|message
operator|.
name|append
argument_list|(
name|sf
operator|.
name|getPath
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
name|message
operator|.
name|append
argument_list|(
literal|"(size="
argument_list|)
expr_stmt|;
name|message
operator|.
name|append
argument_list|(
name|TraditionalBinaryPrefix
operator|.
name|long2String
argument_list|(
name|sf
operator|.
name|getReader
argument_list|()
operator|.
name|length
argument_list|()
argument_list|,
literal|""
argument_list|,
literal|1
argument_list|)
argument_list|)
expr_stmt|;
name|message
operator|.
name|append
argument_list|(
literal|"), "
argument_list|)
expr_stmt|;
block|}
block|}
name|message
operator|.
name|append
argument_list|(
literal|"total size for store is "
argument_list|)
operator|.
name|append
argument_list|(
name|StringUtils
operator|.
name|TraditionalBinaryPrefix
operator|.
name|long2String
argument_list|(
name|storeSize
operator|.
name|get
argument_list|()
argument_list|,
literal|""
argument_list|,
literal|1
argument_list|)
argument_list|)
operator|.
name|append
argument_list|(
literal|". This selection was in queue for "
argument_list|)
operator|.
name|append
argument_list|(
name|StringUtils
operator|.
name|formatTimeDiff
argument_list|(
name|compactionStartTime
argument_list|,
name|cr
operator|.
name|getSelectionTime
argument_list|()
argument_list|)
argument_list|)
operator|.
name|append
argument_list|(
literal|", and took "
argument_list|)
operator|.
name|append
argument_list|(
name|StringUtils
operator|.
name|formatTimeDiff
argument_list|(
name|now
argument_list|,
name|compactionStartTime
argument_list|)
argument_list|)
operator|.
name|append
argument_list|(
literal|" to execute."
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
name|message
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|int
name|fileCount
init|=
name|storeEngine
operator|.
name|getStoreFileManager
argument_list|()
operator|.
name|getStorefileCount
argument_list|()
decl_stmt|;
name|long
name|resultSize
init|=
name|getTotalSize
argument_list|(
name|sfs
argument_list|)
decl_stmt|;
name|String
name|traceMessage
init|=
literal|"COMPACTION start,end,size out,files in,files out,store size,"
operator|+
literal|"store files ["
operator|+
name|compactionStartTime
operator|+
literal|","
operator|+
name|now
operator|+
literal|","
operator|+
name|resultSize
operator|+
literal|","
operator|+
name|cr
operator|.
name|getFiles
argument_list|()
operator|.
name|size
argument_list|()
operator|+
literal|","
operator|+
name|sfs
operator|.
name|size
argument_list|()
operator|+
literal|","
operator|+
name|storeSize
operator|+
literal|","
operator|+
name|fileCount
operator|+
literal|"]"
decl_stmt|;
name|LOG
operator|.
name|trace
argument_list|(
name|traceMessage
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Call to complete a compaction. Its for the case where we find in the WAL a compaction    * that was not finished.  We could find one recovering a WAL after a regionserver crash.    * See HBASE-2231.    * @param compaction    */
specifier|public
name|void
name|replayCompactionMarker
parameter_list|(
name|CompactionDescriptor
name|compaction
parameter_list|,
name|boolean
name|pickCompactionFiles
parameter_list|,
name|boolean
name|removeFiles
parameter_list|)
throws|throws
name|IOException
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Completing compaction from the WAL marker"
argument_list|)
expr_stmt|;
name|List
argument_list|<
name|String
argument_list|>
name|compactionInputs
init|=
name|compaction
operator|.
name|getCompactionInputList
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|String
argument_list|>
name|compactionOutputs
init|=
name|Lists
operator|.
name|newArrayList
argument_list|(
name|compaction
operator|.
name|getCompactionOutputList
argument_list|()
argument_list|)
decl_stmt|;
comment|// The Compaction Marker is written after the compaction is completed,
comment|// and the files moved into the region/family folder.
comment|//
comment|// If we crash after the entry is written, we may not have removed the
comment|// input files, but the output file is present.
comment|// (The unremoved input files will be removed by this function)
comment|//
comment|// If we scan the directory and the file is not present, it can mean that:
comment|//   - The file was manually removed by the user
comment|//   - The file was removed as consequence of subsequent compaction
comment|// so, we can't do anything with the "compaction output list" because those
comment|// files have already been loaded when opening the region (by virtue of
comment|// being in the store's folder) or they may be missing due to a compaction.
name|String
name|familyName
init|=
name|this
operator|.
name|getColumnFamilyName
argument_list|()
decl_stmt|;
name|Set
argument_list|<
name|String
argument_list|>
name|inputFiles
init|=
operator|new
name|HashSet
argument_list|<>
argument_list|()
decl_stmt|;
for|for
control|(
name|String
name|compactionInput
range|:
name|compactionInputs
control|)
block|{
name|Path
name|inputPath
init|=
name|fs
operator|.
name|getStoreFilePath
argument_list|(
name|familyName
argument_list|,
name|compactionInput
argument_list|)
decl_stmt|;
name|inputFiles
operator|.
name|add
argument_list|(
name|inputPath
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|//some of the input files might already be deleted
name|List
argument_list|<
name|HStoreFile
argument_list|>
name|inputStoreFiles
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
name|compactionInputs
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
for|for
control|(
name|HStoreFile
name|sf
range|:
name|this
operator|.
name|getStorefiles
argument_list|()
control|)
block|{
if|if
condition|(
name|inputFiles
operator|.
name|contains
argument_list|(
name|sf
operator|.
name|getPath
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|)
condition|)
block|{
name|inputStoreFiles
operator|.
name|add
argument_list|(
name|sf
argument_list|)
expr_stmt|;
block|}
block|}
comment|// check whether we need to pick up the new files
name|List
argument_list|<
name|HStoreFile
argument_list|>
name|outputStoreFiles
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
name|compactionOutputs
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|pickCompactionFiles
condition|)
block|{
for|for
control|(
name|HStoreFile
name|sf
range|:
name|this
operator|.
name|getStorefiles
argument_list|()
control|)
block|{
name|compactionOutputs
operator|.
name|remove
argument_list|(
name|sf
operator|.
name|getPath
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
block|}
for|for
control|(
name|String
name|compactionOutput
range|:
name|compactionOutputs
control|)
block|{
name|StoreFileInfo
name|storeFileInfo
init|=
name|fs
operator|.
name|getStoreFileInfo
argument_list|(
name|getColumnFamilyName
argument_list|()
argument_list|,
name|compactionOutput
argument_list|)
decl_stmt|;
name|HStoreFile
name|storeFile
init|=
name|createStoreFileAndReader
argument_list|(
name|storeFileInfo
argument_list|)
decl_stmt|;
name|outputStoreFiles
operator|.
name|add
argument_list|(
name|storeFile
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
operator|!
name|inputStoreFiles
operator|.
name|isEmpty
argument_list|()
operator|||
operator|!
name|outputStoreFiles
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Replaying compaction marker, replacing input files: "
operator|+
name|inputStoreFiles
operator|+
literal|" with output files : "
operator|+
name|outputStoreFiles
argument_list|)
expr_stmt|;
name|this
operator|.
name|replaceStoreFiles
argument_list|(
name|inputStoreFiles
argument_list|,
name|outputStoreFiles
argument_list|)
expr_stmt|;
name|this
operator|.
name|completeCompaction
argument_list|(
name|inputStoreFiles
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * This method tries to compact N recent files for testing.    * Note that because compacting "recent" files only makes sense for some policies,    * e.g. the default one, it assumes default policy is used. It doesn't use policy,    * but instead makes a compaction candidate list by itself.    * @param N Number of files.    */
annotation|@
name|VisibleForTesting
specifier|public
name|void
name|compactRecentForTestingAssumingDefaultPolicy
parameter_list|(
name|int
name|N
parameter_list|)
throws|throws
name|IOException
block|{
name|List
argument_list|<
name|HStoreFile
argument_list|>
name|filesToCompact
decl_stmt|;
name|boolean
name|isMajor
decl_stmt|;
name|this
operator|.
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
synchronized|synchronized
init|(
name|filesCompacting
init|)
block|{
name|filesToCompact
operator|=
name|Lists
operator|.
name|newArrayList
argument_list|(
name|storeEngine
operator|.
name|getStoreFileManager
argument_list|()
operator|.
name|getStorefiles
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|filesCompacting
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
comment|// exclude all files older than the newest file we're currently
comment|// compacting. this allows us to preserve contiguity (HBASE-2856)
name|HStoreFile
name|last
init|=
name|filesCompacting
operator|.
name|get
argument_list|(
name|filesCompacting
operator|.
name|size
argument_list|()
operator|-
literal|1
argument_list|)
decl_stmt|;
name|int
name|idx
init|=
name|filesToCompact
operator|.
name|indexOf
argument_list|(
name|last
argument_list|)
decl_stmt|;
name|Preconditions
operator|.
name|checkArgument
argument_list|(
name|idx
operator|!=
operator|-
literal|1
argument_list|)
expr_stmt|;
name|filesToCompact
operator|.
name|subList
argument_list|(
literal|0
argument_list|,
name|idx
operator|+
literal|1
argument_list|)
operator|.
name|clear
argument_list|()
expr_stmt|;
block|}
name|int
name|count
init|=
name|filesToCompact
operator|.
name|size
argument_list|()
decl_stmt|;
if|if
condition|(
name|N
operator|>
name|count
condition|)
block|{
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"Not enough files"
argument_list|)
throw|;
block|}
name|filesToCompact
operator|=
name|filesToCompact
operator|.
name|subList
argument_list|(
name|count
operator|-
name|N
argument_list|,
name|count
argument_list|)
expr_stmt|;
name|isMajor
operator|=
operator|(
name|filesToCompact
operator|.
name|size
argument_list|()
operator|==
name|storeEngine
operator|.
name|getStoreFileManager
argument_list|()
operator|.
name|getStorefileCount
argument_list|()
operator|)
expr_stmt|;
name|filesCompacting
operator|.
name|addAll
argument_list|(
name|filesToCompact
argument_list|)
expr_stmt|;
name|Collections
operator|.
name|sort
argument_list|(
name|filesCompacting
argument_list|,
name|storeEngine
operator|.
name|getStoreFileManager
argument_list|()
operator|.
name|getStoreFileComparator
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
finally|finally
block|{
name|this
operator|.
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
try|try
block|{
comment|// Ready to go. Have list of files to compact.
name|List
argument_list|<
name|Path
argument_list|>
name|newFiles
init|=
operator|(
operator|(
name|DefaultCompactor
operator|)
name|this
operator|.
name|storeEngine
operator|.
name|getCompactor
argument_list|()
operator|)
operator|.
name|compactForTesting
argument_list|(
name|filesToCompact
argument_list|,
name|isMajor
argument_list|)
decl_stmt|;
for|for
control|(
name|Path
name|newFile
range|:
name|newFiles
control|)
block|{
comment|// Move the compaction into place.
name|HStoreFile
name|sf
init|=
name|moveFileIntoPlace
argument_list|(
name|newFile
argument_list|)
decl_stmt|;
if|if
condition|(
name|this
operator|.
name|getCoprocessorHost
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|this
operator|.
name|getCoprocessorHost
argument_list|()
operator|.
name|postCompact
argument_list|(
name|this
argument_list|,
name|sf
argument_list|,
literal|null
argument_list|,
literal|null
argument_list|,
literal|null
argument_list|)
expr_stmt|;
block|}
name|replaceStoreFiles
argument_list|(
name|filesToCompact
argument_list|,
name|Collections
operator|.
name|singletonList
argument_list|(
name|sf
argument_list|)
argument_list|)
expr_stmt|;
name|completeCompaction
argument_list|(
name|filesToCompact
argument_list|)
expr_stmt|;
block|}
block|}
finally|finally
block|{
synchronized|synchronized
init|(
name|filesCompacting
init|)
block|{
name|filesCompacting
operator|.
name|removeAll
argument_list|(
name|filesToCompact
argument_list|)
expr_stmt|;
block|}
block|}
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|hasReferences
parameter_list|()
block|{
comment|// Grab the read lock here, because we need to ensure that: only when the atomic
comment|// replaceStoreFiles(..) finished, we can get all the complete store file list.
name|this
operator|.
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
comment|// Merge the current store files with compacted files here due to HBASE-20940.
name|Collection
argument_list|<
name|HStoreFile
argument_list|>
name|allStoreFiles
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
name|getStorefiles
argument_list|()
argument_list|)
decl_stmt|;
name|allStoreFiles
operator|.
name|addAll
argument_list|(
name|getCompactedFiles
argument_list|()
argument_list|)
expr_stmt|;
return|return
name|StoreUtils
operator|.
name|hasReferences
argument_list|(
name|allStoreFiles
argument_list|)
return|;
block|}
finally|finally
block|{
name|this
operator|.
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**    * getter for CompactionProgress object    * @return CompactionProgress object; can be null    */
specifier|public
name|CompactionProgress
name|getCompactionProgress
parameter_list|()
block|{
return|return
name|this
operator|.
name|storeEngine
operator|.
name|getCompactor
argument_list|()
operator|.
name|getProgress
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|shouldPerformMajorCompaction
parameter_list|()
throws|throws
name|IOException
block|{
for|for
control|(
name|HStoreFile
name|sf
range|:
name|this
operator|.
name|storeEngine
operator|.
name|getStoreFileManager
argument_list|()
operator|.
name|getStorefiles
argument_list|()
control|)
block|{
comment|// TODO: what are these reader checks all over the place?
if|if
condition|(
name|sf
operator|.
name|getReader
argument_list|()
operator|==
literal|null
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"StoreFile {} has null Reader"
argument_list|,
name|sf
argument_list|)
expr_stmt|;
return|return
literal|false
return|;
block|}
block|}
return|return
name|storeEngine
operator|.
name|getCompactionPolicy
argument_list|()
operator|.
name|shouldPerformMajorCompaction
argument_list|(
name|this
operator|.
name|storeEngine
operator|.
name|getStoreFileManager
argument_list|()
operator|.
name|getStorefiles
argument_list|()
argument_list|)
return|;
block|}
specifier|public
name|Optional
argument_list|<
name|CompactionContext
argument_list|>
name|requestCompaction
parameter_list|()
throws|throws
name|IOException
block|{
return|return
name|requestCompaction
argument_list|(
name|NO_PRIORITY
argument_list|,
name|CompactionLifeCycleTracker
operator|.
name|DUMMY
argument_list|,
literal|null
argument_list|)
return|;
block|}
specifier|public
name|Optional
argument_list|<
name|CompactionContext
argument_list|>
name|requestCompaction
parameter_list|(
name|int
name|priority
parameter_list|,
name|CompactionLifeCycleTracker
name|tracker
parameter_list|,
name|User
name|user
parameter_list|)
throws|throws
name|IOException
block|{
comment|// don't even select for compaction if writes are disabled
if|if
condition|(
operator|!
name|this
operator|.
name|areWritesEnabled
argument_list|()
condition|)
block|{
return|return
name|Optional
operator|.
name|empty
argument_list|()
return|;
block|}
comment|// Before we do compaction, try to get rid of unneeded files to simplify things.
name|removeUnneededFiles
argument_list|()
expr_stmt|;
specifier|final
name|CompactionContext
name|compaction
init|=
name|storeEngine
operator|.
name|createCompaction
argument_list|()
decl_stmt|;
name|CompactionRequestImpl
name|request
init|=
literal|null
decl_stmt|;
name|this
operator|.
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
synchronized|synchronized
init|(
name|filesCompacting
init|)
block|{
comment|// First, see if coprocessor would want to override selection.
if|if
condition|(
name|this
operator|.
name|getCoprocessorHost
argument_list|()
operator|!=
literal|null
condition|)
block|{
specifier|final
name|List
argument_list|<
name|HStoreFile
argument_list|>
name|candidatesForCoproc
init|=
name|compaction
operator|.
name|preSelect
argument_list|(
name|this
operator|.
name|filesCompacting
argument_list|)
decl_stmt|;
name|boolean
name|override
init|=
name|getCoprocessorHost
argument_list|()
operator|.
name|preCompactSelection
argument_list|(
name|this
argument_list|,
name|candidatesForCoproc
argument_list|,
name|tracker
argument_list|,
name|user
argument_list|)
decl_stmt|;
if|if
condition|(
name|override
condition|)
block|{
comment|// Coprocessor is overriding normal file selection.
name|compaction
operator|.
name|forceSelect
argument_list|(
operator|new
name|CompactionRequestImpl
argument_list|(
name|candidatesForCoproc
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
comment|// Normal case - coprocessor is not overriding file selection.
if|if
condition|(
operator|!
name|compaction
operator|.
name|hasSelection
argument_list|()
condition|)
block|{
name|boolean
name|isUserCompaction
init|=
name|priority
operator|==
name|Store
operator|.
name|PRIORITY_USER
decl_stmt|;
name|boolean
name|mayUseOffPeak
init|=
name|offPeakHours
operator|.
name|isOffPeakHour
argument_list|()
operator|&&
name|offPeakCompactionTracker
operator|.
name|compareAndSet
argument_list|(
literal|false
argument_list|,
literal|true
argument_list|)
decl_stmt|;
try|try
block|{
name|compaction
operator|.
name|select
argument_list|(
name|this
operator|.
name|filesCompacting
argument_list|,
name|isUserCompaction
argument_list|,
name|mayUseOffPeak
argument_list|,
name|forceMajor
operator|&&
name|filesCompacting
operator|.
name|isEmpty
argument_list|()
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
if|if
condition|(
name|mayUseOffPeak
condition|)
block|{
name|offPeakCompactionTracker
operator|.
name|set
argument_list|(
literal|false
argument_list|)
expr_stmt|;
block|}
throw|throw
name|e
throw|;
block|}
assert|assert
name|compaction
operator|.
name|hasSelection
argument_list|()
assert|;
if|if
condition|(
name|mayUseOffPeak
operator|&&
operator|!
name|compaction
operator|.
name|getRequest
argument_list|()
operator|.
name|isOffPeak
argument_list|()
condition|)
block|{
comment|// Compaction policy doesn't want to take advantage of off-peak.
name|offPeakCompactionTracker
operator|.
name|set
argument_list|(
literal|false
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|this
operator|.
name|getCoprocessorHost
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|this
operator|.
name|getCoprocessorHost
argument_list|()
operator|.
name|postCompactSelection
argument_list|(
name|this
argument_list|,
name|ImmutableList
operator|.
name|copyOf
argument_list|(
name|compaction
operator|.
name|getRequest
argument_list|()
operator|.
name|getFiles
argument_list|()
argument_list|)
argument_list|,
name|tracker
argument_list|,
name|compaction
operator|.
name|getRequest
argument_list|()
argument_list|,
name|user
argument_list|)
expr_stmt|;
block|}
comment|// Finally, we have the resulting files list. Check if we have any files at all.
name|request
operator|=
name|compaction
operator|.
name|getRequest
argument_list|()
expr_stmt|;
name|Collection
argument_list|<
name|HStoreFile
argument_list|>
name|selectedFiles
init|=
name|request
operator|.
name|getFiles
argument_list|()
decl_stmt|;
if|if
condition|(
name|selectedFiles
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
return|return
name|Optional
operator|.
name|empty
argument_list|()
return|;
block|}
name|addToCompactingFiles
argument_list|(
name|selectedFiles
argument_list|)
expr_stmt|;
comment|// If we're enqueuing a major, clear the force flag.
name|this
operator|.
name|forceMajor
operator|=
name|this
operator|.
name|forceMajor
operator|&&
operator|!
name|request
operator|.
name|isMajor
argument_list|()
expr_stmt|;
comment|// Set common request properties.
comment|// Set priority, either override value supplied by caller or from store.
name|request
operator|.
name|setPriority
argument_list|(
operator|(
name|priority
operator|!=
name|Store
operator|.
name|NO_PRIORITY
operator|)
condition|?
name|priority
else|:
name|getCompactPriority
argument_list|()
argument_list|)
expr_stmt|;
name|request
operator|.
name|setDescription
argument_list|(
name|getRegionInfo
argument_list|()
operator|.
name|getRegionNameAsString
argument_list|()
argument_list|,
name|getColumnFamilyName
argument_list|()
argument_list|)
expr_stmt|;
name|request
operator|.
name|setTracker
argument_list|(
name|tracker
argument_list|)
expr_stmt|;
block|}
block|}
finally|finally
block|{
name|this
operator|.
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
name|getRegionInfo
argument_list|()
operator|.
name|getEncodedName
argument_list|()
operator|+
literal|" - "
operator|+
name|getColumnFamilyName
argument_list|()
operator|+
literal|": Initiating "
operator|+
operator|(
name|request
operator|.
name|isMajor
argument_list|()
condition|?
literal|"major"
else|:
literal|"minor"
operator|)
operator|+
literal|" compaction"
operator|+
operator|(
name|request
operator|.
name|isAllFiles
argument_list|()
condition|?
literal|" (all files)"
else|:
literal|""
operator|)
argument_list|)
expr_stmt|;
block|}
name|this
operator|.
name|region
operator|.
name|reportCompactionRequestStart
argument_list|(
name|request
operator|.
name|isMajor
argument_list|()
argument_list|)
expr_stmt|;
return|return
name|Optional
operator|.
name|of
argument_list|(
name|compaction
argument_list|)
return|;
block|}
comment|/** Adds the files to compacting files. filesCompacting must be locked. */
specifier|private
name|void
name|addToCompactingFiles
parameter_list|(
name|Collection
argument_list|<
name|HStoreFile
argument_list|>
name|filesToAdd
parameter_list|)
block|{
if|if
condition|(
name|CollectionUtils
operator|.
name|isEmpty
argument_list|(
name|filesToAdd
argument_list|)
condition|)
block|{
return|return;
block|}
comment|// Check that we do not try to compact the same StoreFile twice.
if|if
condition|(
operator|!
name|Collections
operator|.
name|disjoint
argument_list|(
name|filesCompacting
argument_list|,
name|filesToAdd
argument_list|)
condition|)
block|{
name|Preconditions
operator|.
name|checkArgument
argument_list|(
literal|false
argument_list|,
literal|"%s overlaps with %s"
argument_list|,
name|filesToAdd
argument_list|,
name|filesCompacting
argument_list|)
expr_stmt|;
block|}
name|filesCompacting
operator|.
name|addAll
argument_list|(
name|filesToAdd
argument_list|)
expr_stmt|;
name|Collections
operator|.
name|sort
argument_list|(
name|filesCompacting
argument_list|,
name|storeEngine
operator|.
name|getStoreFileManager
argument_list|()
operator|.
name|getStoreFileComparator
argument_list|()
argument_list|)
expr_stmt|;
block|}
specifier|private
name|void
name|removeUnneededFiles
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
operator|!
name|conf
operator|.
name|getBoolean
argument_list|(
literal|"hbase.store.delete.expired.storefile"
argument_list|,
literal|true
argument_list|)
condition|)
return|return;
if|if
condition|(
name|getColumnFamilyDescriptor
argument_list|()
operator|.
name|getMinVersions
argument_list|()
operator|>
literal|0
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Skipping expired store file removal due to min version being {}"
argument_list|,
name|getColumnFamilyDescriptor
argument_list|()
operator|.
name|getMinVersions
argument_list|()
argument_list|)
expr_stmt|;
return|return;
block|}
name|this
operator|.
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
name|Collection
argument_list|<
name|HStoreFile
argument_list|>
name|delSfs
init|=
literal|null
decl_stmt|;
try|try
block|{
synchronized|synchronized
init|(
name|filesCompacting
init|)
block|{
name|long
name|cfTtl
init|=
name|getStoreFileTtl
argument_list|()
decl_stmt|;
if|if
condition|(
name|cfTtl
operator|!=
name|Long
operator|.
name|MAX_VALUE
condition|)
block|{
name|delSfs
operator|=
name|storeEngine
operator|.
name|getStoreFileManager
argument_list|()
operator|.
name|getUnneededFiles
argument_list|(
name|EnvironmentEdgeManager
operator|.
name|currentTime
argument_list|()
operator|-
name|cfTtl
argument_list|,
name|filesCompacting
argument_list|)
expr_stmt|;
name|addToCompactingFiles
argument_list|(
name|delSfs
argument_list|)
expr_stmt|;
block|}
block|}
block|}
finally|finally
block|{
name|this
operator|.
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|CollectionUtils
operator|.
name|isEmpty
argument_list|(
name|delSfs
argument_list|)
condition|)
block|{
return|return;
block|}
name|Collection
argument_list|<
name|HStoreFile
argument_list|>
name|newFiles
init|=
name|Collections
operator|.
name|emptyList
argument_list|()
decl_stmt|;
comment|// No new files.
name|writeCompactionWalRecord
argument_list|(
name|delSfs
argument_list|,
name|newFiles
argument_list|)
expr_stmt|;
name|replaceStoreFiles
argument_list|(
name|delSfs
argument_list|,
name|newFiles
argument_list|)
expr_stmt|;
name|completeCompaction
argument_list|(
name|delSfs
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Completed removal of "
operator|+
name|delSfs
operator|.
name|size
argument_list|()
operator|+
literal|" unnecessary (expired) file(s) in "
operator|+
name|this
operator|+
literal|" of "
operator|+
name|this
operator|.
name|getRegionInfo
argument_list|()
operator|.
name|getRegionNameAsString
argument_list|()
operator|+
literal|"; total size for store is "
operator|+
name|TraditionalBinaryPrefix
operator|.
name|long2String
argument_list|(
name|storeSize
operator|.
name|get
argument_list|()
argument_list|,
literal|""
argument_list|,
literal|1
argument_list|)
argument_list|)
expr_stmt|;
block|}
specifier|public
name|void
name|cancelRequestedCompaction
parameter_list|(
name|CompactionContext
name|compaction
parameter_list|)
block|{
name|finishCompactionRequest
argument_list|(
name|compaction
operator|.
name|getRequest
argument_list|()
argument_list|)
expr_stmt|;
block|}
specifier|private
name|void
name|finishCompactionRequest
parameter_list|(
name|CompactionRequestImpl
name|cr
parameter_list|)
block|{
name|this
operator|.
name|region
operator|.
name|reportCompactionRequestEnd
argument_list|(
name|cr
operator|.
name|isMajor
argument_list|()
argument_list|,
name|cr
operator|.
name|getFiles
argument_list|()
operator|.
name|size
argument_list|()
argument_list|,
name|cr
operator|.
name|getSize
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|cr
operator|.
name|isOffPeak
argument_list|()
condition|)
block|{
name|offPeakCompactionTracker
operator|.
name|set
argument_list|(
literal|false
argument_list|)
expr_stmt|;
name|cr
operator|.
name|setOffPeak
argument_list|(
literal|false
argument_list|)
expr_stmt|;
block|}
synchronized|synchronized
init|(
name|filesCompacting
init|)
block|{
name|filesCompacting
operator|.
name|removeAll
argument_list|(
name|cr
operator|.
name|getFiles
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Validates a store file by opening and closing it. In HFileV2 this should not be an expensive    * operation.    * @param path the path to the store file    */
specifier|private
name|void
name|validateStoreFile
parameter_list|(
name|Path
name|path
parameter_list|)
throws|throws
name|IOException
block|{
name|HStoreFile
name|storeFile
init|=
literal|null
decl_stmt|;
try|try
block|{
name|storeFile
operator|=
name|createStoreFileAndReader
argument_list|(
name|path
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Failed to open store file : {}, keeping it in tmp location"
argument_list|,
name|path
argument_list|,
name|e
argument_list|)
expr_stmt|;
throw|throw
name|e
throw|;
block|}
finally|finally
block|{
if|if
condition|(
name|storeFile
operator|!=
literal|null
condition|)
block|{
name|storeFile
operator|.
name|closeStoreFile
argument_list|(
literal|false
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|/**    * Update counts.    * @param compactedFiles list of files that were compacted    */
annotation|@
name|VisibleForTesting
specifier|protected
name|void
name|completeCompaction
parameter_list|(
name|Collection
argument_list|<
name|HStoreFile
argument_list|>
name|compactedFiles
parameter_list|)
comment|// Rename this method! TODO.
throws|throws
name|IOException
block|{
name|this
operator|.
name|storeSize
operator|.
name|set
argument_list|(
literal|0L
argument_list|)
expr_stmt|;
name|this
operator|.
name|totalUncompressedBytes
operator|.
name|set
argument_list|(
literal|0L
argument_list|)
expr_stmt|;
for|for
control|(
name|HStoreFile
name|hsf
range|:
name|this
operator|.
name|storeEngine
operator|.
name|getStoreFileManager
argument_list|()
operator|.
name|getStorefiles
argument_list|()
control|)
block|{
name|StoreFileReader
name|r
init|=
name|hsf
operator|.
name|getReader
argument_list|()
decl_stmt|;
if|if
condition|(
name|r
operator|==
literal|null
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"StoreFile {} has a null Reader"
argument_list|,
name|hsf
argument_list|)
expr_stmt|;
continue|continue;
block|}
name|this
operator|.
name|storeSize
operator|.
name|addAndGet
argument_list|(
name|r
operator|.
name|length
argument_list|()
argument_list|)
expr_stmt|;
name|this
operator|.
name|totalUncompressedBytes
operator|.
name|addAndGet
argument_list|(
name|r
operator|.
name|getTotalUncompressedBytes
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
comment|/*    * @param wantedVersions How many versions were asked for.    * @return wantedVersions or this families' {@link HConstants#VERSIONS}.    */
name|int
name|versionsToReturn
parameter_list|(
specifier|final
name|int
name|wantedVersions
parameter_list|)
block|{
if|if
condition|(
name|wantedVersions
operator|<=
literal|0
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"Number of versions must be> 0"
argument_list|)
throw|;
block|}
comment|// Make sure we do not return more than maximum versions for this store.
name|int
name|maxVersions
init|=
name|this
operator|.
name|family
operator|.
name|getMaxVersions
argument_list|()
decl_stmt|;
return|return
name|wantedVersions
operator|>
name|maxVersions
condition|?
name|maxVersions
else|:
name|wantedVersions
return|;
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|canSplit
parameter_list|()
block|{
name|this
operator|.
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
comment|// Not split-able if we find a reference store file present in the store.
name|boolean
name|result
init|=
operator|!
name|hasReferences
argument_list|()
decl_stmt|;
if|if
condition|(
operator|!
name|result
condition|)
block|{
name|LOG
operator|.
name|trace
argument_list|(
literal|"Not splittable; has references: {}"
argument_list|,
name|this
argument_list|)
expr_stmt|;
block|}
return|return
name|result
return|;
block|}
finally|finally
block|{
name|this
operator|.
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**    * Determines if Store should be split.    */
specifier|public
name|Optional
argument_list|<
name|byte
index|[]
argument_list|>
name|getSplitPoint
parameter_list|()
block|{
name|this
operator|.
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
comment|// Should already be enforced by the split policy!
assert|assert
operator|!
name|this
operator|.
name|getRegionInfo
argument_list|()
operator|.
name|isMetaRegion
argument_list|()
assert|;
comment|// Not split-able if we find a reference store file present in the store.
if|if
condition|(
name|hasReferences
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|trace
argument_list|(
literal|"Not splittable; has references: {}"
argument_list|,
name|this
argument_list|)
expr_stmt|;
return|return
name|Optional
operator|.
name|empty
argument_list|()
return|;
block|}
return|return
name|this
operator|.
name|storeEngine
operator|.
name|getStoreFileManager
argument_list|()
operator|.
name|getSplitPoint
argument_list|()
return|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failed getting store size for {}"
argument_list|,
name|this
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|this
operator|.
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
return|return
name|Optional
operator|.
name|empty
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|getLastCompactSize
parameter_list|()
block|{
return|return
name|this
operator|.
name|lastCompactSize
return|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|getSize
parameter_list|()
block|{
return|return
name|storeSize
operator|.
name|get
argument_list|()
return|;
block|}
specifier|public
name|void
name|triggerMajorCompaction
parameter_list|()
block|{
name|this
operator|.
name|forceMajor
operator|=
literal|true
expr_stmt|;
block|}
comment|//////////////////////////////////////////////////////////////////////////////
comment|// File administration
comment|//////////////////////////////////////////////////////////////////////////////
comment|/**    * Return a scanner for both the memstore and the HStore files. Assumes we are not in a    * compaction.    * @param scan Scan to apply when scanning the stores    * @param targetCols columns to scan    * @return a scanner over the current key values    * @throws IOException on failure    */
specifier|public
name|KeyValueScanner
name|getScanner
parameter_list|(
name|Scan
name|scan
parameter_list|,
specifier|final
name|NavigableSet
argument_list|<
name|byte
index|[]
argument_list|>
name|targetCols
parameter_list|,
name|long
name|readPt
parameter_list|)
throws|throws
name|IOException
block|{
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
name|ScanInfo
name|scanInfo
decl_stmt|;
if|if
condition|(
name|this
operator|.
name|getCoprocessorHost
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|scanInfo
operator|=
name|this
operator|.
name|getCoprocessorHost
argument_list|()
operator|.
name|preStoreScannerOpen
argument_list|(
name|this
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|scanInfo
operator|=
name|getScanInfo
argument_list|()
expr_stmt|;
block|}
return|return
name|createScanner
argument_list|(
name|scan
argument_list|,
name|scanInfo
argument_list|,
name|targetCols
argument_list|,
name|readPt
argument_list|)
return|;
block|}
finally|finally
block|{
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
comment|// HMobStore will override this method to return its own implementation.
specifier|protected
name|KeyValueScanner
name|createScanner
parameter_list|(
name|Scan
name|scan
parameter_list|,
name|ScanInfo
name|scanInfo
parameter_list|,
name|NavigableSet
argument_list|<
name|byte
index|[]
argument_list|>
name|targetCols
parameter_list|,
name|long
name|readPt
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|scan
operator|.
name|isReversed
argument_list|()
condition|?
operator|new
name|ReversedStoreScanner
argument_list|(
name|this
argument_list|,
name|scanInfo
argument_list|,
name|scan
argument_list|,
name|targetCols
argument_list|,
name|readPt
argument_list|)
else|:
operator|new
name|StoreScanner
argument_list|(
name|this
argument_list|,
name|scanInfo
argument_list|,
name|scan
argument_list|,
name|targetCols
argument_list|,
name|readPt
argument_list|)
return|;
block|}
comment|/**    * Recreates the scanners on the current list of active store file scanners    * @param currentFileScanners the current set of active store file scanners    * @param cacheBlocks cache the blocks or not    * @param usePread use pread or not    * @param isCompaction is the scanner for compaction    * @param matcher the scan query matcher    * @param startRow the scan's start row    * @param includeStartRow should the scan include the start row    * @param stopRow the scan's stop row    * @param includeStopRow should the scan include the stop row    * @param readPt the read point of the current scane    * @param includeMemstoreScanner whether the current scanner should include memstorescanner    * @return list of scanners recreated on the current Scanners    * @throws IOException    */
specifier|public
name|List
argument_list|<
name|KeyValueScanner
argument_list|>
name|recreateScanners
parameter_list|(
name|List
argument_list|<
name|KeyValueScanner
argument_list|>
name|currentFileScanners
parameter_list|,
name|boolean
name|cacheBlocks
parameter_list|,
name|boolean
name|usePread
parameter_list|,
name|boolean
name|isCompaction
parameter_list|,
name|ScanQueryMatcher
name|matcher
parameter_list|,
name|byte
index|[]
name|startRow
parameter_list|,
name|boolean
name|includeStartRow
parameter_list|,
name|byte
index|[]
name|stopRow
parameter_list|,
name|boolean
name|includeStopRow
parameter_list|,
name|long
name|readPt
parameter_list|,
name|boolean
name|includeMemstoreScanner
parameter_list|)
throws|throws
name|IOException
block|{
name|this
operator|.
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
name|Map
argument_list|<
name|String
argument_list|,
name|HStoreFile
argument_list|>
name|name2File
init|=
operator|new
name|HashMap
argument_list|<>
argument_list|(
name|getStorefilesCount
argument_list|()
operator|+
name|getCompactedFilesCount
argument_list|()
argument_list|)
decl_stmt|;
for|for
control|(
name|HStoreFile
name|file
range|:
name|getStorefiles
argument_list|()
control|)
block|{
name|name2File
operator|.
name|put
argument_list|(
name|file
operator|.
name|getFileInfo
argument_list|()
operator|.
name|getActiveFileName
argument_list|()
argument_list|,
name|file
argument_list|)
expr_stmt|;
block|}
name|Collection
argument_list|<
name|HStoreFile
argument_list|>
name|compactedFiles
init|=
name|getCompactedFiles
argument_list|()
decl_stmt|;
for|for
control|(
name|HStoreFile
name|file
range|:
name|IterableUtils
operator|.
name|emptyIfNull
argument_list|(
name|compactedFiles
argument_list|)
control|)
block|{
name|name2File
operator|.
name|put
argument_list|(
name|file
operator|.
name|getFileInfo
argument_list|()
operator|.
name|getActiveFileName
argument_list|()
argument_list|,
name|file
argument_list|)
expr_stmt|;
block|}
name|List
argument_list|<
name|HStoreFile
argument_list|>
name|filesToReopen
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|()
decl_stmt|;
for|for
control|(
name|KeyValueScanner
name|kvs
range|:
name|currentFileScanners
control|)
block|{
assert|assert
name|kvs
operator|.
name|isFileScanner
argument_list|()
assert|;
if|if
condition|(
name|kvs
operator|.
name|peek
argument_list|()
operator|==
literal|null
condition|)
block|{
continue|continue;
block|}
name|filesToReopen
operator|.
name|add
argument_list|(
name|name2File
operator|.
name|get
argument_list|(
name|kvs
operator|.
name|getFilePath
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|filesToReopen
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
return|return
literal|null
return|;
block|}
return|return
name|getScanners
argument_list|(
name|filesToReopen
argument_list|,
name|cacheBlocks
argument_list|,
literal|false
argument_list|,
literal|false
argument_list|,
name|matcher
argument_list|,
name|startRow
argument_list|,
name|includeStartRow
argument_list|,
name|stopRow
argument_list|,
name|includeStopRow
argument_list|,
name|readPt
argument_list|,
literal|false
argument_list|)
return|;
block|}
finally|finally
block|{
name|this
operator|.
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|String
name|toString
parameter_list|()
block|{
return|return
name|this
operator|.
name|getColumnFamilyName
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|int
name|getStorefilesCount
parameter_list|()
block|{
return|return
name|this
operator|.
name|storeEngine
operator|.
name|getStoreFileManager
argument_list|()
operator|.
name|getStorefileCount
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|int
name|getCompactedFilesCount
parameter_list|()
block|{
return|return
name|this
operator|.
name|storeEngine
operator|.
name|getStoreFileManager
argument_list|()
operator|.
name|getCompactedFilesCount
argument_list|()
return|;
block|}
specifier|private
name|LongStream
name|getStoreFileAgeStream
parameter_list|()
block|{
return|return
name|this
operator|.
name|storeEngine
operator|.
name|getStoreFileManager
argument_list|()
operator|.
name|getStorefiles
argument_list|()
operator|.
name|stream
argument_list|()
operator|.
name|filter
argument_list|(
name|sf
lambda|->
block|{
if|if
condition|(
name|sf
operator|.
name|getReader
argument_list|()
operator|==
literal|null
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"StoreFile {} has a null Reader"
argument_list|,
name|sf
argument_list|)
expr_stmt|;
return|return
literal|false
return|;
block|}
else|else
block|{
return|return
literal|true
return|;
block|}
block|}
argument_list|)
operator|.
name|filter
argument_list|(
name|HStoreFile
operator|::
name|isHFile
argument_list|)
operator|.
name|mapToLong
argument_list|(
name|sf
lambda|->
name|sf
operator|.
name|getFileInfo
argument_list|()
operator|.
name|getCreatedTimestamp
argument_list|()
argument_list|)
operator|.
name|map
argument_list|(
name|t
lambda|->
name|EnvironmentEdgeManager
operator|.
name|currentTime
argument_list|()
operator|-
name|t
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|OptionalLong
name|getMaxStoreFileAge
parameter_list|()
block|{
return|return
name|getStoreFileAgeStream
argument_list|()
operator|.
name|max
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|OptionalLong
name|getMinStoreFileAge
parameter_list|()
block|{
return|return
name|getStoreFileAgeStream
argument_list|()
operator|.
name|min
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|OptionalDouble
name|getAvgStoreFileAge
parameter_list|()
block|{
return|return
name|getStoreFileAgeStream
argument_list|()
operator|.
name|average
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|getNumReferenceFiles
parameter_list|()
block|{
return|return
name|this
operator|.
name|storeEngine
operator|.
name|getStoreFileManager
argument_list|()
operator|.
name|getStorefiles
argument_list|()
operator|.
name|stream
argument_list|()
operator|.
name|filter
argument_list|(
name|HStoreFile
operator|::
name|isReference
argument_list|)
operator|.
name|count
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|getNumHFiles
parameter_list|()
block|{
return|return
name|this
operator|.
name|storeEngine
operator|.
name|getStoreFileManager
argument_list|()
operator|.
name|getStorefiles
argument_list|()
operator|.
name|stream
argument_list|()
operator|.
name|filter
argument_list|(
name|HStoreFile
operator|::
name|isHFile
argument_list|)
operator|.
name|count
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|getStoreSizeUncompressed
parameter_list|()
block|{
return|return
name|this
operator|.
name|totalUncompressedBytes
operator|.
name|get
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|getStorefilesSize
parameter_list|()
block|{
comment|// Include all StoreFiles
return|return
name|getStorefilesSize
argument_list|(
name|this
operator|.
name|storeEngine
operator|.
name|getStoreFileManager
argument_list|()
operator|.
name|getStorefiles
argument_list|()
argument_list|,
name|sf
lambda|->
literal|true
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|getHFilesSize
parameter_list|()
block|{
comment|// Include only StoreFiles which are HFiles
return|return
name|getStorefilesSize
argument_list|(
name|this
operator|.
name|storeEngine
operator|.
name|getStoreFileManager
argument_list|()
operator|.
name|getStorefiles
argument_list|()
argument_list|,
name|HStoreFile
operator|::
name|isHFile
argument_list|)
return|;
block|}
specifier|private
name|long
name|getTotalUncompressedBytes
parameter_list|(
name|List
argument_list|<
name|HStoreFile
argument_list|>
name|files
parameter_list|)
block|{
return|return
name|files
operator|.
name|stream
argument_list|()
operator|.
name|mapToLong
argument_list|(
name|file
lambda|->
name|getStorefileFieldSize
argument_list|(
name|file
argument_list|,
name|StoreFileReader
operator|::
name|getTotalUncompressedBytes
argument_list|)
argument_list|)
operator|.
name|sum
argument_list|()
return|;
block|}
specifier|private
name|long
name|getStorefilesSize
parameter_list|(
name|Collection
argument_list|<
name|HStoreFile
argument_list|>
name|files
parameter_list|,
name|Predicate
argument_list|<
name|HStoreFile
argument_list|>
name|predicate
parameter_list|)
block|{
return|return
name|files
operator|.
name|stream
argument_list|()
operator|.
name|filter
argument_list|(
name|predicate
argument_list|)
operator|.
name|mapToLong
argument_list|(
name|file
lambda|->
name|getStorefileFieldSize
argument_list|(
name|file
argument_list|,
name|StoreFileReader
operator|::
name|length
argument_list|)
argument_list|)
operator|.
name|sum
argument_list|()
return|;
block|}
specifier|private
name|long
name|getStorefileFieldSize
parameter_list|(
name|HStoreFile
name|file
parameter_list|,
name|ToLongFunction
argument_list|<
name|StoreFileReader
argument_list|>
name|f
parameter_list|)
block|{
if|if
condition|(
name|file
operator|==
literal|null
condition|)
block|{
return|return
literal|0L
return|;
block|}
name|StoreFileReader
name|reader
init|=
name|file
operator|.
name|getReader
argument_list|()
decl_stmt|;
if|if
condition|(
name|reader
operator|==
literal|null
condition|)
block|{
return|return
literal|0L
return|;
block|}
return|return
name|f
operator|.
name|applyAsLong
argument_list|(
name|reader
argument_list|)
return|;
block|}
specifier|private
name|long
name|getStorefilesFieldSize
parameter_list|(
name|ToLongFunction
argument_list|<
name|StoreFileReader
argument_list|>
name|f
parameter_list|)
block|{
return|return
name|this
operator|.
name|storeEngine
operator|.
name|getStoreFileManager
argument_list|()
operator|.
name|getStorefiles
argument_list|()
operator|.
name|stream
argument_list|()
operator|.
name|mapToLong
argument_list|(
name|file
lambda|->
name|getStorefileFieldSize
argument_list|(
name|file
argument_list|,
name|f
argument_list|)
argument_list|)
operator|.
name|sum
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|getStorefilesRootLevelIndexSize
parameter_list|()
block|{
return|return
name|getStorefilesFieldSize
argument_list|(
name|StoreFileReader
operator|::
name|indexSize
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|getTotalStaticIndexSize
parameter_list|()
block|{
return|return
name|getStorefilesFieldSize
argument_list|(
name|StoreFileReader
operator|::
name|getUncompressedDataIndexSize
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|getTotalStaticBloomSize
parameter_list|()
block|{
return|return
name|getStorefilesFieldSize
argument_list|(
name|StoreFileReader
operator|::
name|getTotalBloomSize
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|MemStoreSize
name|getMemStoreSize
parameter_list|()
block|{
return|return
name|this
operator|.
name|memstore
operator|.
name|size
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|int
name|getCompactPriority
parameter_list|()
block|{
name|int
name|priority
init|=
name|this
operator|.
name|storeEngine
operator|.
name|getStoreFileManager
argument_list|()
operator|.
name|getStoreCompactionPriority
argument_list|()
decl_stmt|;
if|if
condition|(
name|priority
operator|==
name|PRIORITY_USER
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Compaction priority is USER despite there being no user compaction"
argument_list|)
expr_stmt|;
block|}
return|return
name|priority
return|;
block|}
specifier|public
name|boolean
name|throttleCompaction
parameter_list|(
name|long
name|compactionSize
parameter_list|)
block|{
return|return
name|storeEngine
operator|.
name|getCompactionPolicy
argument_list|()
operator|.
name|throttleCompaction
argument_list|(
name|compactionSize
argument_list|)
return|;
block|}
specifier|public
name|HRegion
name|getHRegion
parameter_list|()
block|{
return|return
name|this
operator|.
name|region
return|;
block|}
specifier|public
name|RegionCoprocessorHost
name|getCoprocessorHost
parameter_list|()
block|{
return|return
name|this
operator|.
name|region
operator|.
name|getCoprocessorHost
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|RegionInfo
name|getRegionInfo
parameter_list|()
block|{
return|return
name|this
operator|.
name|fs
operator|.
name|getRegionInfo
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|areWritesEnabled
parameter_list|()
block|{
return|return
name|this
operator|.
name|region
operator|.
name|areWritesEnabled
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|getSmallestReadPoint
parameter_list|()
block|{
return|return
name|this
operator|.
name|region
operator|.
name|getSmallestReadPoint
argument_list|()
return|;
block|}
comment|/**    * Adds or replaces the specified KeyValues.    *<p>    * For each KeyValue specified, if a cell with the same row, family, and qualifier exists in    * MemStore, it will be replaced. Otherwise, it will just be inserted to MemStore.    *<p>    * This operation is atomic on each KeyValue (row/family/qualifier) but not necessarily atomic    * across all of them.    * @param readpoint readpoint below which we can safely remove duplicate KVs    * @throws IOException    */
specifier|public
name|void
name|upsert
parameter_list|(
name|Iterable
argument_list|<
name|Cell
argument_list|>
name|cells
parameter_list|,
name|long
name|readpoint
parameter_list|,
name|MemStoreSizing
name|memstoreSizing
parameter_list|)
throws|throws
name|IOException
block|{
name|this
operator|.
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
name|this
operator|.
name|memstore
operator|.
name|upsert
argument_list|(
name|cells
argument_list|,
name|readpoint
argument_list|,
name|memstoreSizing
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|this
operator|.
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
specifier|public
name|StoreFlushContext
name|createFlushContext
parameter_list|(
name|long
name|cacheFlushId
parameter_list|,
name|FlushLifeCycleTracker
name|tracker
parameter_list|)
block|{
return|return
operator|new
name|StoreFlusherImpl
argument_list|(
name|cacheFlushId
argument_list|,
name|tracker
argument_list|)
return|;
block|}
specifier|private
specifier|final
class|class
name|StoreFlusherImpl
implements|implements
name|StoreFlushContext
block|{
specifier|private
specifier|final
name|FlushLifeCycleTracker
name|tracker
decl_stmt|;
specifier|private
specifier|final
name|long
name|cacheFlushSeqNum
decl_stmt|;
specifier|private
name|MemStoreSnapshot
name|snapshot
decl_stmt|;
specifier|private
name|List
argument_list|<
name|Path
argument_list|>
name|tempFiles
decl_stmt|;
specifier|private
name|List
argument_list|<
name|Path
argument_list|>
name|committedFiles
decl_stmt|;
specifier|private
name|long
name|cacheFlushCount
decl_stmt|;
specifier|private
name|long
name|cacheFlushSize
decl_stmt|;
specifier|private
name|long
name|outputFileSize
decl_stmt|;
specifier|private
name|StoreFlusherImpl
parameter_list|(
name|long
name|cacheFlushSeqNum
parameter_list|,
name|FlushLifeCycleTracker
name|tracker
parameter_list|)
block|{
name|this
operator|.
name|cacheFlushSeqNum
operator|=
name|cacheFlushSeqNum
expr_stmt|;
name|this
operator|.
name|tracker
operator|=
name|tracker
expr_stmt|;
block|}
comment|/**      * This is not thread safe. The caller should have a lock on the region or the store.      * If necessary, the lock can be added with the patch provided in HBASE-10087      */
annotation|@
name|Override
specifier|public
name|MemStoreSize
name|prepare
parameter_list|()
block|{
comment|// passing the current sequence number of the wal - to allow bookkeeping in the memstore
name|this
operator|.
name|snapshot
operator|=
name|memstore
operator|.
name|snapshot
argument_list|()
expr_stmt|;
name|this
operator|.
name|cacheFlushCount
operator|=
name|snapshot
operator|.
name|getCellsCount
argument_list|()
expr_stmt|;
name|this
operator|.
name|cacheFlushSize
operator|=
name|snapshot
operator|.
name|getDataSize
argument_list|()
expr_stmt|;
name|committedFiles
operator|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
literal|1
argument_list|)
expr_stmt|;
return|return
name|snapshot
operator|.
name|getMemStoreSize
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|flushCache
parameter_list|(
name|MonitoredTask
name|status
parameter_list|)
throws|throws
name|IOException
block|{
name|RegionServerServices
name|rsService
init|=
name|region
operator|.
name|getRegionServerServices
argument_list|()
decl_stmt|;
name|ThroughputController
name|throughputController
init|=
name|rsService
operator|==
literal|null
condition|?
literal|null
else|:
name|rsService
operator|.
name|getFlushThroughputController
argument_list|()
decl_stmt|;
name|tempFiles
operator|=
name|HStore
operator|.
name|this
operator|.
name|flushCache
argument_list|(
name|cacheFlushSeqNum
argument_list|,
name|snapshot
argument_list|,
name|status
argument_list|,
name|throughputController
argument_list|,
name|tracker
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|commit
parameter_list|(
name|MonitoredTask
name|status
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|CollectionUtils
operator|.
name|isEmpty
argument_list|(
name|this
operator|.
name|tempFiles
argument_list|)
condition|)
block|{
return|return
literal|false
return|;
block|}
name|List
argument_list|<
name|HStoreFile
argument_list|>
name|storeFiles
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
name|this
operator|.
name|tempFiles
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
for|for
control|(
name|Path
name|storeFilePath
range|:
name|tempFiles
control|)
block|{
try|try
block|{
name|HStoreFile
name|sf
init|=
name|HStore
operator|.
name|this
operator|.
name|commitFile
argument_list|(
name|storeFilePath
argument_list|,
name|cacheFlushSeqNum
argument_list|,
name|status
argument_list|)
decl_stmt|;
name|outputFileSize
operator|+=
name|sf
operator|.
name|getReader
argument_list|()
operator|.
name|length
argument_list|()
expr_stmt|;
name|storeFiles
operator|.
name|add
argument_list|(
name|sf
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ex
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Failed to commit store file {}"
argument_list|,
name|storeFilePath
argument_list|,
name|ex
argument_list|)
expr_stmt|;
comment|// Try to delete the files we have committed before.
for|for
control|(
name|HStoreFile
name|sf
range|:
name|storeFiles
control|)
block|{
name|Path
name|pathToDelete
init|=
name|sf
operator|.
name|getPath
argument_list|()
decl_stmt|;
try|try
block|{
name|sf
operator|.
name|deleteStoreFile
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|deleteEx
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|HBaseMarkers
operator|.
name|FATAL
argument_list|,
literal|"Failed to delete store file we committed, "
operator|+
literal|"halting {}"
argument_list|,
name|pathToDelete
argument_list|,
name|ex
argument_list|)
expr_stmt|;
name|Runtime
operator|.
name|getRuntime
argument_list|()
operator|.
name|halt
argument_list|(
literal|1
argument_list|)
expr_stmt|;
block|}
block|}
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Failed to commit the flush"
argument_list|,
name|ex
argument_list|)
throw|;
block|}
block|}
for|for
control|(
name|HStoreFile
name|sf
range|:
name|storeFiles
control|)
block|{
if|if
condition|(
name|HStore
operator|.
name|this
operator|.
name|getCoprocessorHost
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|HStore
operator|.
name|this
operator|.
name|getCoprocessorHost
argument_list|()
operator|.
name|postFlush
argument_list|(
name|HStore
operator|.
name|this
argument_list|,
name|sf
argument_list|,
name|tracker
argument_list|)
expr_stmt|;
block|}
name|committedFiles
operator|.
name|add
argument_list|(
name|sf
operator|.
name|getPath
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|HStore
operator|.
name|this
operator|.
name|flushedCellsCount
operator|.
name|addAndGet
argument_list|(
name|cacheFlushCount
argument_list|)
expr_stmt|;
name|HStore
operator|.
name|this
operator|.
name|flushedCellsSize
operator|.
name|addAndGet
argument_list|(
name|cacheFlushSize
argument_list|)
expr_stmt|;
name|HStore
operator|.
name|this
operator|.
name|flushedOutputFileSize
operator|.
name|addAndGet
argument_list|(
name|outputFileSize
argument_list|)
expr_stmt|;
comment|// Add new file to store files.  Clear snapshot too while we have the Store write lock.
return|return
name|HStore
operator|.
name|this
operator|.
name|updateStorefiles
argument_list|(
name|storeFiles
argument_list|,
name|snapshot
operator|.
name|getId
argument_list|()
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|getOutputFileSize
parameter_list|()
block|{
return|return
name|outputFileSize
return|;
block|}
annotation|@
name|Override
specifier|public
name|List
argument_list|<
name|Path
argument_list|>
name|getCommittedFiles
parameter_list|()
block|{
return|return
name|committedFiles
return|;
block|}
comment|/**      * Similar to commit, but called in secondary region replicas for replaying the      * flush cache from primary region. Adds the new files to the store, and drops the      * snapshot depending on dropMemstoreSnapshot argument.      * @param fileNames names of the flushed files      * @param dropMemstoreSnapshot whether to drop the prepared memstore snapshot      * @throws IOException      */
annotation|@
name|Override
specifier|public
name|void
name|replayFlush
parameter_list|(
name|List
argument_list|<
name|String
argument_list|>
name|fileNames
parameter_list|,
name|boolean
name|dropMemstoreSnapshot
parameter_list|)
throws|throws
name|IOException
block|{
name|List
argument_list|<
name|HStoreFile
argument_list|>
name|storeFiles
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
name|fileNames
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
for|for
control|(
name|String
name|file
range|:
name|fileNames
control|)
block|{
comment|// open the file as a store file (hfile link, etc)
name|StoreFileInfo
name|storeFileInfo
init|=
name|fs
operator|.
name|getStoreFileInfo
argument_list|(
name|getColumnFamilyName
argument_list|()
argument_list|,
name|file
argument_list|)
decl_stmt|;
name|HStoreFile
name|storeFile
init|=
name|createStoreFileAndReader
argument_list|(
name|storeFileInfo
argument_list|)
decl_stmt|;
name|storeFiles
operator|.
name|add
argument_list|(
name|storeFile
argument_list|)
expr_stmt|;
name|HStore
operator|.
name|this
operator|.
name|storeSize
operator|.
name|addAndGet
argument_list|(
name|storeFile
operator|.
name|getReader
argument_list|()
operator|.
name|length
argument_list|()
argument_list|)
expr_stmt|;
name|HStore
operator|.
name|this
operator|.
name|totalUncompressedBytes
operator|.
name|addAndGet
argument_list|(
name|storeFile
operator|.
name|getReader
argument_list|()
operator|.
name|getTotalUncompressedBytes
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isInfoEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Region: "
operator|+
name|HStore
operator|.
name|this
operator|.
name|getRegionInfo
argument_list|()
operator|.
name|getEncodedName
argument_list|()
operator|+
literal|" added "
operator|+
name|storeFile
operator|+
literal|", entries="
operator|+
name|storeFile
operator|.
name|getReader
argument_list|()
operator|.
name|getEntries
argument_list|()
operator|+
literal|", sequenceid="
operator|+
name|storeFile
operator|.
name|getReader
argument_list|()
operator|.
name|getSequenceID
argument_list|()
operator|+
literal|", filesize="
operator|+
name|TraditionalBinaryPrefix
operator|.
name|long2String
argument_list|(
name|storeFile
operator|.
name|getReader
argument_list|()
operator|.
name|length
argument_list|()
argument_list|,
literal|""
argument_list|,
literal|1
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
name|long
name|snapshotId
init|=
operator|-
literal|1
decl_stmt|;
comment|// -1 means do not drop
if|if
condition|(
name|dropMemstoreSnapshot
operator|&&
name|snapshot
operator|!=
literal|null
condition|)
block|{
name|snapshotId
operator|=
name|snapshot
operator|.
name|getId
argument_list|()
expr_stmt|;
name|snapshot
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
name|HStore
operator|.
name|this
operator|.
name|updateStorefiles
argument_list|(
name|storeFiles
argument_list|,
name|snapshotId
argument_list|)
expr_stmt|;
block|}
comment|/**      * Abort the snapshot preparation. Drops the snapshot if any.      * @throws IOException      */
annotation|@
name|Override
specifier|public
name|void
name|abort
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|snapshot
operator|!=
literal|null
condition|)
block|{
comment|//We need to close the snapshot when aborting, otherwise, the segment scanner
comment|//won't be closed. If we are using MSLAB, the chunk referenced by those scanners
comment|//can't be released, thus memory leak
name|snapshot
operator|.
name|close
argument_list|()
expr_stmt|;
name|HStore
operator|.
name|this
operator|.
name|updateStorefiles
argument_list|(
name|Collections
operator|.
name|emptyList
argument_list|()
argument_list|,
name|snapshot
operator|.
name|getId
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|needsCompaction
parameter_list|()
block|{
name|List
argument_list|<
name|HStoreFile
argument_list|>
name|filesCompactingClone
init|=
literal|null
decl_stmt|;
synchronized|synchronized
init|(
name|filesCompacting
init|)
block|{
name|filesCompactingClone
operator|=
name|Lists
operator|.
name|newArrayList
argument_list|(
name|filesCompacting
argument_list|)
expr_stmt|;
block|}
return|return
name|this
operator|.
name|storeEngine
operator|.
name|needsCompaction
argument_list|(
name|filesCompactingClone
argument_list|)
return|;
block|}
comment|/**    * Used for tests.    * @return cache configuration for this Store.    */
annotation|@
name|VisibleForTesting
specifier|public
name|CacheConfig
name|getCacheConfig
parameter_list|()
block|{
return|return
name|this
operator|.
name|cacheConf
return|;
block|}
specifier|public
specifier|static
specifier|final
name|long
name|FIXED_OVERHEAD
init|=
name|ClassSize
operator|.
name|align
argument_list|(
name|ClassSize
operator|.
name|OBJECT
operator|+
operator|(
literal|27
operator|*
name|ClassSize
operator|.
name|REFERENCE
operator|)
operator|+
operator|(
literal|2
operator|*
name|Bytes
operator|.
name|SIZEOF_LONG
operator|)
operator|+
operator|(
literal|6
operator|*
name|Bytes
operator|.
name|SIZEOF_INT
operator|)
operator|+
operator|(
literal|2
operator|*
name|Bytes
operator|.
name|SIZEOF_BOOLEAN
operator|)
argument_list|)
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|long
name|DEEP_OVERHEAD
init|=
name|ClassSize
operator|.
name|align
argument_list|(
name|FIXED_OVERHEAD
operator|+
name|ClassSize
operator|.
name|OBJECT
operator|+
name|ClassSize
operator|.
name|REENTRANT_LOCK
operator|+
name|ClassSize
operator|.
name|CONCURRENT_SKIPLISTMAP
operator|+
name|ClassSize
operator|.
name|CONCURRENT_SKIPLISTMAP_ENTRY
operator|+
name|ClassSize
operator|.
name|OBJECT
operator|+
name|ScanInfo
operator|.
name|FIXED_OVERHEAD
argument_list|)
decl_stmt|;
annotation|@
name|Override
specifier|public
name|long
name|heapSize
parameter_list|()
block|{
name|MemStoreSize
name|memstoreSize
init|=
name|this
operator|.
name|memstore
operator|.
name|size
argument_list|()
decl_stmt|;
return|return
name|DEEP_OVERHEAD
operator|+
name|memstoreSize
operator|.
name|getHeapSize
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|CellComparator
name|getComparator
parameter_list|()
block|{
return|return
name|comparator
return|;
block|}
specifier|public
name|ScanInfo
name|getScanInfo
parameter_list|()
block|{
return|return
name|scanInfo
return|;
block|}
comment|/**    * Set scan info, used by test    * @param scanInfo new scan info to use for test    */
name|void
name|setScanInfo
parameter_list|(
name|ScanInfo
name|scanInfo
parameter_list|)
block|{
name|this
operator|.
name|scanInfo
operator|=
name|scanInfo
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|hasTooManyStoreFiles
parameter_list|()
block|{
return|return
name|getStorefilesCount
argument_list|()
operator|>
name|this
operator|.
name|blockingFileCount
return|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|getFlushedCellsCount
parameter_list|()
block|{
return|return
name|flushedCellsCount
operator|.
name|get
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|getFlushedCellsSize
parameter_list|()
block|{
return|return
name|flushedCellsSize
operator|.
name|get
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|getFlushedOutputFileSize
parameter_list|()
block|{
return|return
name|flushedOutputFileSize
operator|.
name|get
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|getCompactedCellsCount
parameter_list|()
block|{
return|return
name|compactedCellsCount
operator|.
name|get
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|getCompactedCellsSize
parameter_list|()
block|{
return|return
name|compactedCellsSize
operator|.
name|get
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|getMajorCompactedCellsCount
parameter_list|()
block|{
return|return
name|majorCompactedCellsCount
operator|.
name|get
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|getMajorCompactedCellsSize
parameter_list|()
block|{
return|return
name|majorCompactedCellsSize
operator|.
name|get
argument_list|()
return|;
block|}
comment|/**    * Returns the StoreEngine that is backing this concrete implementation of Store.    * @return Returns the {@link StoreEngine} object used internally inside this HStore object.    */
annotation|@
name|VisibleForTesting
specifier|public
name|StoreEngine
argument_list|<
name|?
argument_list|,
name|?
argument_list|,
name|?
argument_list|,
name|?
argument_list|>
name|getStoreEngine
parameter_list|()
block|{
return|return
name|this
operator|.
name|storeEngine
return|;
block|}
specifier|protected
name|OffPeakHours
name|getOffPeakHours
parameter_list|()
block|{
return|return
name|this
operator|.
name|offPeakHours
return|;
block|}
comment|/**    * {@inheritDoc}    */
annotation|@
name|Override
specifier|public
name|void
name|onConfigurationChange
parameter_list|(
name|Configuration
name|conf
parameter_list|)
block|{
name|this
operator|.
name|conf
operator|=
operator|new
name|CompoundConfiguration
argument_list|()
operator|.
name|add
argument_list|(
name|conf
argument_list|)
operator|.
name|addBytesMap
argument_list|(
name|family
operator|.
name|getValues
argument_list|()
argument_list|)
expr_stmt|;
name|this
operator|.
name|storeEngine
operator|.
name|compactionPolicy
operator|.
name|setConf
argument_list|(
name|conf
argument_list|)
expr_stmt|;
name|this
operator|.
name|offPeakHours
operator|=
name|OffPeakHours
operator|.
name|getInstance
argument_list|(
name|conf
argument_list|)
expr_stmt|;
block|}
comment|/**    * {@inheritDoc}    */
annotation|@
name|Override
specifier|public
name|void
name|registerChildren
parameter_list|(
name|ConfigurationManager
name|manager
parameter_list|)
block|{
comment|// No children to register
block|}
comment|/**    * {@inheritDoc}    */
annotation|@
name|Override
specifier|public
name|void
name|deregisterChildren
parameter_list|(
name|ConfigurationManager
name|manager
parameter_list|)
block|{
comment|// No children to deregister
block|}
annotation|@
name|Override
specifier|public
name|double
name|getCompactionPressure
parameter_list|()
block|{
return|return
name|storeEngine
operator|.
name|getStoreFileManager
argument_list|()
operator|.
name|getCompactionPressure
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|isPrimaryReplicaStore
parameter_list|()
block|{
return|return
name|getRegionInfo
argument_list|()
operator|.
name|getReplicaId
argument_list|()
operator|==
name|RegionInfo
operator|.
name|DEFAULT_REPLICA_ID
return|;
block|}
comment|/**    * Sets the store up for a region level snapshot operation.    * @see #postSnapshotOperation()    */
specifier|public
name|void
name|preSnapshotOperation
parameter_list|()
block|{
name|archiveLock
operator|.
name|lock
argument_list|()
expr_stmt|;
block|}
comment|/**    * Perform tasks needed after the completion of snapshot operation.    * @see #preSnapshotOperation()    */
specifier|public
name|void
name|postSnapshotOperation
parameter_list|()
block|{
name|archiveLock
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
comment|/**    * Closes and archives the compacted files under this store    */
specifier|public
specifier|synchronized
name|void
name|closeAndArchiveCompactedFiles
parameter_list|()
throws|throws
name|IOException
block|{
comment|// ensure other threads do not attempt to archive the same files on close()
name|archiveLock
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
name|Collection
argument_list|<
name|HStoreFile
argument_list|>
name|copyCompactedfiles
init|=
literal|null
decl_stmt|;
try|try
block|{
name|Collection
argument_list|<
name|HStoreFile
argument_list|>
name|compactedfiles
init|=
name|this
operator|.
name|getStoreEngine
argument_list|()
operator|.
name|getStoreFileManager
argument_list|()
operator|.
name|getCompactedfiles
argument_list|()
decl_stmt|;
if|if
condition|(
name|CollectionUtils
operator|.
name|isNotEmpty
argument_list|(
name|compactedfiles
argument_list|)
condition|)
block|{
comment|// Do a copy under read lock
name|copyCompactedfiles
operator|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
name|compactedfiles
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|LOG
operator|.
name|trace
argument_list|(
literal|"No compacted files to archive"
argument_list|)
expr_stmt|;
block|}
block|}
finally|finally
block|{
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|CollectionUtils
operator|.
name|isNotEmpty
argument_list|(
name|copyCompactedfiles
argument_list|)
condition|)
block|{
name|removeCompactedfiles
argument_list|(
name|copyCompactedfiles
argument_list|)
expr_stmt|;
block|}
block|}
finally|finally
block|{
name|archiveLock
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**    * Archives and removes the compacted files    * @param compactedfiles The compacted files in this store that are not active in reads    */
specifier|private
name|void
name|removeCompactedfiles
parameter_list|(
name|Collection
argument_list|<
name|HStoreFile
argument_list|>
name|compactedfiles
parameter_list|)
throws|throws
name|IOException
block|{
specifier|final
name|List
argument_list|<
name|HStoreFile
argument_list|>
name|filesToRemove
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
name|compactedfiles
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
specifier|final
name|List
argument_list|<
name|Long
argument_list|>
name|storeFileSizes
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
name|compactedfiles
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
for|for
control|(
specifier|final
name|HStoreFile
name|file
range|:
name|compactedfiles
control|)
block|{
synchronized|synchronized
init|(
name|file
init|)
block|{
try|try
block|{
name|StoreFileReader
name|r
init|=
name|file
operator|.
name|getReader
argument_list|()
decl_stmt|;
if|if
condition|(
name|r
operator|==
literal|null
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"The file {} was closed but still not archived"
argument_list|,
name|file
argument_list|)
expr_stmt|;
comment|// HACK: Temporarily re-open the reader so we can get the size of the file. Ideally,
comment|// we should know the size of an HStoreFile without having to ask the HStoreFileReader
comment|// for that.
name|long
name|length
init|=
name|getStoreFileSize
argument_list|(
name|file
argument_list|)
decl_stmt|;
name|filesToRemove
operator|.
name|add
argument_list|(
name|file
argument_list|)
expr_stmt|;
name|storeFileSizes
operator|.
name|add
argument_list|(
name|length
argument_list|)
expr_stmt|;
continue|continue;
block|}
if|if
condition|(
name|file
operator|.
name|isCompactedAway
argument_list|()
operator|&&
operator|!
name|file
operator|.
name|isReferencedInReads
argument_list|()
condition|)
block|{
comment|// Even if deleting fails we need not bother as any new scanners won't be
comment|// able to use the compacted file as the status is already compactedAway
name|LOG
operator|.
name|trace
argument_list|(
literal|"Closing and archiving the file {}"
argument_list|,
name|file
argument_list|)
expr_stmt|;
comment|// Copy the file size before closing the reader
specifier|final
name|long
name|length
init|=
name|r
operator|.
name|length
argument_list|()
decl_stmt|;
name|r
operator|.
name|close
argument_list|(
literal|true
argument_list|)
expr_stmt|;
comment|// Just close and return
name|filesToRemove
operator|.
name|add
argument_list|(
name|file
argument_list|)
expr_stmt|;
comment|// Only add the length if we successfully added the file to `filesToRemove`
name|storeFileSizes
operator|.
name|add
argument_list|(
name|length
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Can't archive compacted file "
operator|+
name|file
operator|.
name|getPath
argument_list|()
operator|+
literal|" because of either isCompactedAway="
operator|+
name|file
operator|.
name|isCompactedAway
argument_list|()
operator|+
literal|" or file has reference, isReferencedInReads="
operator|+
name|file
operator|.
name|isReferencedInReads
argument_list|()
operator|+
literal|", refCount="
operator|+
name|r
operator|.
name|getRefCount
argument_list|()
operator|+
literal|", skipping for now."
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Exception while trying to close the compacted store file {}"
argument_list|,
name|file
operator|.
name|getPath
argument_list|()
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
block|}
block|}
if|if
condition|(
name|this
operator|.
name|isPrimaryReplicaStore
argument_list|()
condition|)
block|{
comment|// Only the primary region is allowed to move the file to archive.
comment|// The secondary region does not move the files to archive. Any active reads from
comment|// the secondary region will still work because the file as such has active readers on it.
if|if
condition|(
operator|!
name|filesToRemove
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Moving the files {} to archive"
argument_list|,
name|filesToRemove
argument_list|)
expr_stmt|;
comment|// Only if this is successful it has to be removed
try|try
block|{
name|this
operator|.
name|fs
operator|.
name|removeStoreFiles
argument_list|(
name|this
operator|.
name|getColumnFamilyDescriptor
argument_list|()
operator|.
name|getNameAsString
argument_list|()
argument_list|,
name|filesToRemove
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|FailedArchiveException
name|fae
parameter_list|)
block|{
comment|// Even if archiving some files failed, we still need to clear out any of the
comment|// files which were successfully archived.  Otherwise we will receive a
comment|// FileNotFoundException when we attempt to re-archive them in the next go around.
name|Collection
argument_list|<
name|Path
argument_list|>
name|failedFiles
init|=
name|fae
operator|.
name|getFailedFiles
argument_list|()
decl_stmt|;
name|Iterator
argument_list|<
name|HStoreFile
argument_list|>
name|iter
init|=
name|filesToRemove
operator|.
name|iterator
argument_list|()
decl_stmt|;
name|Iterator
argument_list|<
name|Long
argument_list|>
name|sizeIter
init|=
name|storeFileSizes
operator|.
name|iterator
argument_list|()
decl_stmt|;
while|while
condition|(
name|iter
operator|.
name|hasNext
argument_list|()
condition|)
block|{
name|sizeIter
operator|.
name|next
argument_list|()
expr_stmt|;
if|if
condition|(
name|failedFiles
operator|.
name|contains
argument_list|(
name|iter
operator|.
name|next
argument_list|()
operator|.
name|getPath
argument_list|()
argument_list|)
condition|)
block|{
name|iter
operator|.
name|remove
argument_list|()
expr_stmt|;
name|sizeIter
operator|.
name|remove
argument_list|()
expr_stmt|;
block|}
block|}
if|if
condition|(
operator|!
name|filesToRemove
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|clearCompactedfiles
argument_list|(
name|filesToRemove
argument_list|)
expr_stmt|;
block|}
throw|throw
name|fae
throw|;
block|}
block|}
block|}
if|if
condition|(
operator|!
name|filesToRemove
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
comment|// Clear the compactedfiles from the store file manager
name|clearCompactedfiles
argument_list|(
name|filesToRemove
argument_list|)
expr_stmt|;
comment|// Try to send report of this archival to the Master for updating quota usage faster
name|reportArchivedFilesForQuota
argument_list|(
name|filesToRemove
argument_list|,
name|storeFileSizes
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Computes the length of a store file without succumbing to any errors along the way. If an    * error is encountered, the implementation returns {@code 0} instead of the actual size.    *    * @param file The file to compute the size of.    * @return The size in bytes of the provided {@code file}.    */
name|long
name|getStoreFileSize
parameter_list|(
name|HStoreFile
name|file
parameter_list|)
block|{
name|long
name|length
init|=
literal|0
decl_stmt|;
try|try
block|{
name|file
operator|.
name|initReader
argument_list|()
expr_stmt|;
name|length
operator|=
name|file
operator|.
name|getReader
argument_list|()
operator|.
name|length
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|trace
argument_list|(
literal|"Failed to open reader when trying to compute store file size, ignoring"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
try|try
block|{
name|file
operator|.
name|closeStoreFile
argument_list|(
name|file
operator|.
name|getCacheConf
argument_list|()
operator|!=
literal|null
condition|?
name|file
operator|.
name|getCacheConf
argument_list|()
operator|.
name|shouldEvictOnClose
argument_list|()
else|:
literal|true
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|trace
argument_list|(
literal|"Failed to close reader after computing store file size, ignoring"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|length
return|;
block|}
specifier|public
name|Long
name|preFlushSeqIDEstimation
parameter_list|()
block|{
return|return
name|memstore
operator|.
name|preFlushSeqIDEstimation
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|isSloppyMemStore
parameter_list|()
block|{
return|return
name|this
operator|.
name|memstore
operator|.
name|isSloppy
argument_list|()
return|;
block|}
specifier|private
name|void
name|clearCompactedfiles
parameter_list|(
name|List
argument_list|<
name|HStoreFile
argument_list|>
name|filesToRemove
parameter_list|)
throws|throws
name|IOException
block|{
name|LOG
operator|.
name|trace
argument_list|(
literal|"Clearing the compacted file {} from this store"
argument_list|,
name|filesToRemove
argument_list|)
expr_stmt|;
try|try
block|{
name|lock
operator|.
name|writeLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
name|this
operator|.
name|getStoreEngine
argument_list|()
operator|.
name|getStoreFileManager
argument_list|()
operator|.
name|removeCompactedFiles
argument_list|(
name|filesToRemove
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|lock
operator|.
name|writeLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
name|void
name|reportArchivedFilesForQuota
parameter_list|(
name|List
argument_list|<
name|?
extends|extends
name|StoreFile
argument_list|>
name|archivedFiles
parameter_list|,
name|List
argument_list|<
name|Long
argument_list|>
name|fileSizes
parameter_list|)
block|{
comment|// Sanity check from the caller
if|if
condition|(
name|archivedFiles
operator|.
name|size
argument_list|()
operator|!=
name|fileSizes
operator|.
name|size
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"Coding error: should never see lists of varying size"
argument_list|)
throw|;
block|}
name|RegionServerServices
name|rss
init|=
name|this
operator|.
name|region
operator|.
name|getRegionServerServices
argument_list|()
decl_stmt|;
if|if
condition|(
name|rss
operator|==
literal|null
condition|)
block|{
return|return;
block|}
name|List
argument_list|<
name|Entry
argument_list|<
name|String
argument_list|,
name|Long
argument_list|>
argument_list|>
name|filesWithSizes
init|=
operator|new
name|ArrayList
argument_list|<>
argument_list|(
name|archivedFiles
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
name|Iterator
argument_list|<
name|Long
argument_list|>
name|fileSizeIter
init|=
name|fileSizes
operator|.
name|iterator
argument_list|()
decl_stmt|;
for|for
control|(
name|StoreFile
name|storeFile
range|:
name|archivedFiles
control|)
block|{
specifier|final
name|long
name|fileSize
init|=
name|fileSizeIter
operator|.
name|next
argument_list|()
decl_stmt|;
if|if
condition|(
name|storeFile
operator|.
name|isHFile
argument_list|()
operator|&&
name|fileSize
operator|!=
literal|0
condition|)
block|{
name|filesWithSizes
operator|.
name|add
argument_list|(
name|Maps
operator|.
name|immutableEntry
argument_list|(
name|storeFile
operator|.
name|getPath
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|,
name|fileSize
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|LOG
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|trace
argument_list|(
literal|"Files archived: "
operator|+
name|archivedFiles
operator|+
literal|", reporting the following to the Master: "
operator|+
name|filesWithSizes
argument_list|)
expr_stmt|;
block|}
name|boolean
name|success
init|=
name|rss
operator|.
name|reportFileArchivalForQuotas
argument_list|(
name|getTableName
argument_list|()
argument_list|,
name|filesWithSizes
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|success
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failed to report archival of files: "
operator|+
name|filesWithSizes
argument_list|)
expr_stmt|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|int
name|getCurrentParallelPutCount
parameter_list|()
block|{
return|return
name|currentParallelPutCount
operator|.
name|get
argument_list|()
return|;
block|}
specifier|public
name|int
name|getStoreRefCount
parameter_list|()
block|{
return|return
name|this
operator|.
name|storeEngine
operator|.
name|getStoreFileManager
argument_list|()
operator|.
name|getStorefiles
argument_list|()
operator|.
name|stream
argument_list|()
operator|.
name|filter
argument_list|(
name|sf
lambda|->
name|sf
operator|.
name|getReader
argument_list|()
operator|!=
literal|null
argument_list|)
operator|.
name|filter
argument_list|(
name|HStoreFile
operator|::
name|isHFile
argument_list|)
operator|.
name|mapToInt
argument_list|(
name|HStoreFile
operator|::
name|getRefCount
argument_list|)
operator|.
name|sum
argument_list|()
return|;
block|}
comment|/**    * @return get maximum ref count of storeFile among all compacted HStore Files    *   for the HStore    */
specifier|public
name|int
name|getMaxCompactedStoreFileRefCount
parameter_list|()
block|{
name|OptionalInt
name|maxCompactedStoreFileRefCount
init|=
name|this
operator|.
name|storeEngine
operator|.
name|getStoreFileManager
argument_list|()
operator|.
name|getCompactedfiles
argument_list|()
operator|.
name|stream
argument_list|()
operator|.
name|filter
argument_list|(
name|sf
lambda|->
name|sf
operator|.
name|getReader
argument_list|()
operator|!=
literal|null
argument_list|)
operator|.
name|filter
argument_list|(
name|HStoreFile
operator|::
name|isHFile
argument_list|)
operator|.
name|mapToInt
argument_list|(
name|HStoreFile
operator|::
name|getRefCount
argument_list|)
operator|.
name|max
argument_list|()
decl_stmt|;
return|return
name|maxCompactedStoreFileRefCount
operator|.
name|isPresent
argument_list|()
condition|?
name|maxCompactedStoreFileRefCount
operator|.
name|getAsInt
argument_list|()
else|:
literal|0
return|;
block|}
block|}
end_class

end_unit

