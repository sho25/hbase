begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  *  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|InterruptedIOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|InetSocketAddress
import|;
end_import

begin_import
import|import
name|java
operator|.
name|security
operator|.
name|Key
import|;
end_import

begin_import
import|import
name|java
operator|.
name|security
operator|.
name|KeyException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collection
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collections
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Iterator
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|NavigableSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Set
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|Callable
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|CompletionService
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ConcurrentHashMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ExecutionException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ExecutorCompletionService
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|Future
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|ThreadPoolExecutor
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|atomic
operator|.
name|AtomicBoolean
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|locks
operator|.
name|ReentrantReadWriteLock
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|Log
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|LogFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|classification
operator|.
name|InterfaceAudience
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|Cell
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|CellUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|CompoundConfiguration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HColumnDescriptor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HConstants
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HRegionInfo
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|KeyValue
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|KeyValueUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|TableName
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|Scan
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|compress
operator|.
name|Compression
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|crypto
operator|.
name|Cipher
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|crypto
operator|.
name|Encryption
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|hfile
operator|.
name|CacheConfig
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|hfile
operator|.
name|HFile
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|hfile
operator|.
name|HFileContext
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|hfile
operator|.
name|HFileContextBuilder
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|hfile
operator|.
name|HFileDataBlockEncoder
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|hfile
operator|.
name|HFileDataBlockEncoderImpl
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|hfile
operator|.
name|HFileScanner
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|hfile
operator|.
name|InvalidHFileException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|monitoring
operator|.
name|MonitoredTask
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|protobuf
operator|.
name|ProtobufUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|protobuf
operator|.
name|generated
operator|.
name|WALProtos
operator|.
name|CompactionDescriptor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|compactions
operator|.
name|CompactionContext
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|compactions
operator|.
name|CompactionProgress
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|compactions
operator|.
name|CompactionRequest
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|compactions
operator|.
name|DefaultCompactor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|compactions
operator|.
name|OffPeakHours
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|wal
operator|.
name|HLogUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|security
operator|.
name|EncryptionUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|security
operator|.
name|User
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|Bytes
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|ChecksumType
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|ClassSize
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|EnvironmentEdgeManager
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|Pair
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|ReflectionUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|ipc
operator|.
name|RemoteException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|util
operator|.
name|StringUtils
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|annotations
operator|.
name|VisibleForTesting
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Preconditions
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|ImmutableCollection
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|ImmutableList
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|Lists
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|Sets
import|;
end_import

begin_comment
comment|/**  * A Store holds a column family in a Region.  Its a memstore and a set of zero  * or more StoreFiles, which stretch backwards over time.  *  *<p>There's no reason to consider append-logging at this level; all logging  * and locking is handled at the HRegion level.  Store just provides  * services to manage sets of StoreFiles.  One of the most important of those  * services is compaction services where files are aggregated once they pass  * a configurable threshold.  *  *<p>The only thing having to do with logs that Store needs to deal with is  * the reconstructionLog.  This is a segment of an HRegion's log that might  * NOT be present upon startup.  If the param is NULL, there's nothing to do.  * If the param is non-NULL, we need to process the log to reconstruct  * a TreeMap that might not have been written to disk before the process  * died.  *  *<p>It's assumed that after this constructor returns, the reconstructionLog  * file will be deleted (by whoever has instantiated the Store).  *  *<p>Locking and transactions are handled at a higher level.  This API should  * not be called directly but by an HRegion manager.  */
end_comment

begin_class
annotation|@
name|InterfaceAudience
operator|.
name|Private
specifier|public
class|class
name|HStore
implements|implements
name|Store
block|{
specifier|private
specifier|static
specifier|final
name|String
name|MEMSTORE_CLASS_NAME
init|=
literal|"hbase.regionserver.memstore.class"
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|String
name|COMPACTCHECKER_INTERVAL_MULTIPLIER_KEY
init|=
literal|"hbase.server.compactchecker.interval.multiplier"
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|String
name|BLOCKING_STOREFILES_KEY
init|=
literal|"hbase.hstore.blockingStoreFiles"
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|int
name|DEFAULT_COMPACTCHECKER_INTERVAL_MULTIPLIER
init|=
literal|1000
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|int
name|DEFAULT_BLOCKING_STOREFILE_COUNT
init|=
literal|7
decl_stmt|;
specifier|static
specifier|final
name|Log
name|LOG
init|=
name|LogFactory
operator|.
name|getLog
argument_list|(
name|HStore
operator|.
name|class
argument_list|)
decl_stmt|;
specifier|protected
specifier|final
name|MemStore
name|memstore
decl_stmt|;
comment|// This stores directory in the filesystem.
specifier|private
specifier|final
name|HRegion
name|region
decl_stmt|;
specifier|private
specifier|final
name|HColumnDescriptor
name|family
decl_stmt|;
specifier|private
specifier|final
name|HRegionFileSystem
name|fs
decl_stmt|;
specifier|private
specifier|final
name|Configuration
name|conf
decl_stmt|;
specifier|private
specifier|final
name|CacheConfig
name|cacheConf
decl_stmt|;
specifier|private
name|long
name|lastCompactSize
init|=
literal|0
decl_stmt|;
specifier|volatile
name|boolean
name|forceMajor
init|=
literal|false
decl_stmt|;
comment|/* how many bytes to write between status checks */
specifier|static
name|int
name|closeCheckInterval
init|=
literal|0
decl_stmt|;
specifier|private
specifier|volatile
name|long
name|storeSize
init|=
literal|0L
decl_stmt|;
specifier|private
specifier|volatile
name|long
name|totalUncompressedBytes
init|=
literal|0L
decl_stmt|;
comment|/**    * RWLock for store operations.    * Locked in shared mode when the list of component stores is looked at:    *   - all reads/writes to table data    *   - checking for split    * Locked in exclusive mode when the list of component stores is modified:    *   - closing    *   - completing a compaction    */
specifier|final
name|ReentrantReadWriteLock
name|lock
init|=
operator|new
name|ReentrantReadWriteLock
argument_list|()
decl_stmt|;
specifier|private
specifier|final
name|boolean
name|verifyBulkLoads
decl_stmt|;
specifier|private
name|ScanInfo
name|scanInfo
decl_stmt|;
comment|// TODO: ideally, this should be part of storeFileManager, as we keep passing this to it.
specifier|final
name|List
argument_list|<
name|StoreFile
argument_list|>
name|filesCompacting
init|=
name|Lists
operator|.
name|newArrayList
argument_list|()
decl_stmt|;
comment|// All access must be synchronized.
specifier|private
specifier|final
name|Set
argument_list|<
name|ChangedReadersObserver
argument_list|>
name|changedReaderObservers
init|=
name|Collections
operator|.
name|newSetFromMap
argument_list|(
operator|new
name|ConcurrentHashMap
argument_list|<
name|ChangedReadersObserver
argument_list|,
name|Boolean
argument_list|>
argument_list|()
argument_list|)
decl_stmt|;
specifier|private
specifier|final
name|int
name|blocksize
decl_stmt|;
specifier|private
name|HFileDataBlockEncoder
name|dataBlockEncoder
decl_stmt|;
comment|/** Checksum configuration */
specifier|private
name|ChecksumType
name|checksumType
decl_stmt|;
specifier|private
name|int
name|bytesPerChecksum
decl_stmt|;
comment|// Comparing KeyValues
specifier|private
specifier|final
name|KeyValue
operator|.
name|KVComparator
name|comparator
decl_stmt|;
specifier|final
name|StoreEngine
argument_list|<
name|?
argument_list|,
name|?
argument_list|,
name|?
argument_list|,
name|?
argument_list|>
name|storeEngine
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|AtomicBoolean
name|offPeakCompactionTracker
init|=
operator|new
name|AtomicBoolean
argument_list|()
decl_stmt|;
specifier|private
specifier|final
name|OffPeakHours
name|offPeakHours
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|int
name|DEFAULT_FLUSH_RETRIES_NUMBER
init|=
literal|10
decl_stmt|;
specifier|private
name|int
name|flushRetriesNumber
decl_stmt|;
specifier|private
name|int
name|pauseTime
decl_stmt|;
specifier|private
name|long
name|blockingFileCount
decl_stmt|;
specifier|private
name|int
name|compactionCheckMultiplier
decl_stmt|;
specifier|private
name|Encryption
operator|.
name|Context
name|cryptoContext
init|=
name|Encryption
operator|.
name|Context
operator|.
name|NONE
decl_stmt|;
specifier|private
specifier|volatile
name|long
name|flushedCellsCount
init|=
literal|0
decl_stmt|;
specifier|private
specifier|volatile
name|long
name|compactedCellsCount
init|=
literal|0
decl_stmt|;
specifier|private
specifier|volatile
name|long
name|majorCompactedCellsCount
init|=
literal|0
decl_stmt|;
specifier|private
specifier|volatile
name|long
name|flushedCellsSize
init|=
literal|0
decl_stmt|;
specifier|private
specifier|volatile
name|long
name|compactedCellsSize
init|=
literal|0
decl_stmt|;
specifier|private
specifier|volatile
name|long
name|majorCompactedCellsSize
init|=
literal|0
decl_stmt|;
comment|/**    * Constructor    * @param region    * @param family HColumnDescriptor for this column    * @param confParam configuration object    * failed.  Can be null.    * @throws IOException    */
specifier|protected
name|HStore
parameter_list|(
specifier|final
name|HRegion
name|region
parameter_list|,
specifier|final
name|HColumnDescriptor
name|family
parameter_list|,
specifier|final
name|Configuration
name|confParam
parameter_list|)
throws|throws
name|IOException
block|{
name|HRegionInfo
name|info
init|=
name|region
operator|.
name|getRegionInfo
argument_list|()
decl_stmt|;
name|this
operator|.
name|fs
operator|=
name|region
operator|.
name|getRegionFileSystem
argument_list|()
expr_stmt|;
comment|// Assemble the store's home directory and Ensure it exists.
name|fs
operator|.
name|createStoreDir
argument_list|(
name|family
operator|.
name|getNameAsString
argument_list|()
argument_list|)
expr_stmt|;
name|this
operator|.
name|region
operator|=
name|region
expr_stmt|;
name|this
operator|.
name|family
operator|=
name|family
expr_stmt|;
comment|// 'conf' renamed to 'confParam' b/c we use this.conf in the constructor
comment|// CompoundConfiguration will look for keys in reverse order of addition, so we'd
comment|// add global config first, then table and cf overrides, then cf metadata.
name|this
operator|.
name|conf
operator|=
operator|new
name|CompoundConfiguration
argument_list|()
operator|.
name|add
argument_list|(
name|confParam
argument_list|)
operator|.
name|addStringMap
argument_list|(
name|region
operator|.
name|getTableDesc
argument_list|()
operator|.
name|getConfiguration
argument_list|()
argument_list|)
operator|.
name|addStringMap
argument_list|(
name|family
operator|.
name|getConfiguration
argument_list|()
argument_list|)
operator|.
name|addWritableMap
argument_list|(
name|family
operator|.
name|getValues
argument_list|()
argument_list|)
expr_stmt|;
name|this
operator|.
name|blocksize
operator|=
name|family
operator|.
name|getBlocksize
argument_list|()
expr_stmt|;
name|this
operator|.
name|dataBlockEncoder
operator|=
operator|new
name|HFileDataBlockEncoderImpl
argument_list|(
name|family
operator|.
name|getDataBlockEncoding
argument_list|()
argument_list|)
expr_stmt|;
name|this
operator|.
name|comparator
operator|=
name|info
operator|.
name|getComparator
argument_list|()
expr_stmt|;
comment|// used by ScanQueryMatcher
name|long
name|timeToPurgeDeletes
init|=
name|Math
operator|.
name|max
argument_list|(
name|conf
operator|.
name|getLong
argument_list|(
literal|"hbase.hstore.time.to.purge.deletes"
argument_list|,
literal|0
argument_list|)
argument_list|,
literal|0
argument_list|)
decl_stmt|;
name|LOG
operator|.
name|trace
argument_list|(
literal|"Time to purge deletes set to "
operator|+
name|timeToPurgeDeletes
operator|+
literal|"ms in store "
operator|+
name|this
argument_list|)
expr_stmt|;
comment|// Get TTL
name|long
name|ttl
init|=
name|determineTTLFromFamily
argument_list|(
name|family
argument_list|)
decl_stmt|;
comment|// Why not just pass a HColumnDescriptor in here altogether?  Even if have
comment|// to clone it?
name|scanInfo
operator|=
operator|new
name|ScanInfo
argument_list|(
name|family
argument_list|,
name|ttl
argument_list|,
name|timeToPurgeDeletes
argument_list|,
name|this
operator|.
name|comparator
argument_list|)
expr_stmt|;
name|String
name|className
init|=
name|conf
operator|.
name|get
argument_list|(
name|MEMSTORE_CLASS_NAME
argument_list|,
name|DefaultMemStore
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
name|this
operator|.
name|memstore
operator|=
name|ReflectionUtils
operator|.
name|instantiateWithCustomCtor
argument_list|(
name|className
argument_list|,
operator|new
name|Class
index|[]
block|{
name|Configuration
operator|.
name|class
block|,
name|KeyValue
operator|.
name|KVComparator
operator|.
name|class
block|}
argument_list|,
operator|new
name|Object
index|[]
block|{
name|conf
block|,
name|this
operator|.
name|comparator
block|}
argument_list|)
expr_stmt|;
name|this
operator|.
name|offPeakHours
operator|=
name|OffPeakHours
operator|.
name|getInstance
argument_list|(
name|conf
argument_list|)
expr_stmt|;
comment|// Setting up cache configuration for this family
name|this
operator|.
name|cacheConf
operator|=
operator|new
name|CacheConfig
argument_list|(
name|conf
argument_list|,
name|family
argument_list|)
expr_stmt|;
name|this
operator|.
name|verifyBulkLoads
operator|=
name|conf
operator|.
name|getBoolean
argument_list|(
literal|"hbase.hstore.bulkload.verify"
argument_list|,
literal|false
argument_list|)
expr_stmt|;
name|this
operator|.
name|blockingFileCount
operator|=
name|conf
operator|.
name|getInt
argument_list|(
name|BLOCKING_STOREFILES_KEY
argument_list|,
name|DEFAULT_BLOCKING_STOREFILE_COUNT
argument_list|)
expr_stmt|;
name|this
operator|.
name|compactionCheckMultiplier
operator|=
name|conf
operator|.
name|getInt
argument_list|(
name|COMPACTCHECKER_INTERVAL_MULTIPLIER_KEY
argument_list|,
name|DEFAULT_COMPACTCHECKER_INTERVAL_MULTIPLIER
argument_list|)
expr_stmt|;
if|if
condition|(
name|this
operator|.
name|compactionCheckMultiplier
operator|<=
literal|0
condition|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Compaction check period multiplier must be positive, setting default: "
operator|+
name|DEFAULT_COMPACTCHECKER_INTERVAL_MULTIPLIER
argument_list|)
expr_stmt|;
name|this
operator|.
name|compactionCheckMultiplier
operator|=
name|DEFAULT_COMPACTCHECKER_INTERVAL_MULTIPLIER
expr_stmt|;
block|}
if|if
condition|(
name|HStore
operator|.
name|closeCheckInterval
operator|==
literal|0
condition|)
block|{
name|HStore
operator|.
name|closeCheckInterval
operator|=
name|conf
operator|.
name|getInt
argument_list|(
literal|"hbase.hstore.close.check.interval"
argument_list|,
literal|10
operator|*
literal|1000
operator|*
literal|1000
comment|/* 10 MB */
argument_list|)
expr_stmt|;
block|}
name|this
operator|.
name|storeEngine
operator|=
name|StoreEngine
operator|.
name|create
argument_list|(
name|this
argument_list|,
name|this
operator|.
name|conf
argument_list|,
name|this
operator|.
name|comparator
argument_list|)
expr_stmt|;
name|this
operator|.
name|storeEngine
operator|.
name|getStoreFileManager
argument_list|()
operator|.
name|loadFiles
argument_list|(
name|loadStoreFiles
argument_list|()
argument_list|)
expr_stmt|;
comment|// Initialize checksum type from name. The names are CRC32, CRC32C, etc.
name|this
operator|.
name|checksumType
operator|=
name|getChecksumType
argument_list|(
name|conf
argument_list|)
expr_stmt|;
comment|// initilize bytes per checksum
name|this
operator|.
name|bytesPerChecksum
operator|=
name|getBytesPerChecksum
argument_list|(
name|conf
argument_list|)
expr_stmt|;
name|flushRetriesNumber
operator|=
name|conf
operator|.
name|getInt
argument_list|(
literal|"hbase.hstore.flush.retries.number"
argument_list|,
name|DEFAULT_FLUSH_RETRIES_NUMBER
argument_list|)
expr_stmt|;
name|pauseTime
operator|=
name|conf
operator|.
name|getInt
argument_list|(
name|HConstants
operator|.
name|HBASE_SERVER_PAUSE
argument_list|,
name|HConstants
operator|.
name|DEFAULT_HBASE_SERVER_PAUSE
argument_list|)
expr_stmt|;
if|if
condition|(
name|flushRetriesNumber
operator|<=
literal|0
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"hbase.hstore.flush.retries.number must be> 0, not "
operator|+
name|flushRetriesNumber
argument_list|)
throw|;
block|}
comment|// Crypto context for new store files
name|String
name|cipherName
init|=
name|family
operator|.
name|getEncryptionType
argument_list|()
decl_stmt|;
if|if
condition|(
name|cipherName
operator|!=
literal|null
condition|)
block|{
name|Cipher
name|cipher
decl_stmt|;
name|Key
name|key
decl_stmt|;
name|byte
index|[]
name|keyBytes
init|=
name|family
operator|.
name|getEncryptionKey
argument_list|()
decl_stmt|;
if|if
condition|(
name|keyBytes
operator|!=
literal|null
condition|)
block|{
comment|// Family provides specific key material
name|String
name|masterKeyName
init|=
name|conf
operator|.
name|get
argument_list|(
name|HConstants
operator|.
name|CRYPTO_MASTERKEY_NAME_CONF_KEY
argument_list|,
name|User
operator|.
name|getCurrent
argument_list|()
operator|.
name|getShortName
argument_list|()
argument_list|)
decl_stmt|;
try|try
block|{
comment|// First try the master key
name|key
operator|=
name|EncryptionUtil
operator|.
name|unwrapKey
argument_list|(
name|conf
argument_list|,
name|masterKeyName
argument_list|,
name|keyBytes
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|KeyException
name|e
parameter_list|)
block|{
comment|// If the current master key fails to unwrap, try the alternate, if
comment|// one is configured
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Unable to unwrap key with current master key '"
operator|+
name|masterKeyName
operator|+
literal|"'"
argument_list|)
expr_stmt|;
block|}
name|String
name|alternateKeyName
init|=
name|conf
operator|.
name|get
argument_list|(
name|HConstants
operator|.
name|CRYPTO_MASTERKEY_ALTERNATE_NAME_CONF_KEY
argument_list|)
decl_stmt|;
if|if
condition|(
name|alternateKeyName
operator|!=
literal|null
condition|)
block|{
try|try
block|{
name|key
operator|=
name|EncryptionUtil
operator|.
name|unwrapKey
argument_list|(
name|conf
argument_list|,
name|alternateKeyName
argument_list|,
name|keyBytes
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|KeyException
name|ex
parameter_list|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|ex
argument_list|)
throw|;
block|}
block|}
else|else
block|{
throw|throw
operator|new
name|IOException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
comment|// Use the algorithm the key wants
name|cipher
operator|=
name|Encryption
operator|.
name|getCipher
argument_list|(
name|conf
argument_list|,
name|key
operator|.
name|getAlgorithm
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|cipher
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"Cipher '"
operator|+
name|cipher
operator|+
literal|"' is not available"
argument_list|)
throw|;
block|}
comment|// Fail if misconfigured
comment|// We use the encryption type specified in the column schema as a sanity check on
comment|// what the wrapped key is telling us
if|if
condition|(
operator|!
name|cipher
operator|.
name|getName
argument_list|()
operator|.
name|equalsIgnoreCase
argument_list|(
name|cipherName
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"Encryption for family '"
operator|+
name|family
operator|.
name|getNameAsString
argument_list|()
operator|+
literal|"' configured with type '"
operator|+
name|cipherName
operator|+
literal|"' but key specifies algorithm '"
operator|+
name|cipher
operator|.
name|getName
argument_list|()
operator|+
literal|"'"
argument_list|)
throw|;
block|}
block|}
else|else
block|{
comment|// Family does not provide key material, create a random key
name|cipher
operator|=
name|Encryption
operator|.
name|getCipher
argument_list|(
name|conf
argument_list|,
name|cipherName
argument_list|)
expr_stmt|;
if|if
condition|(
name|cipher
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"Cipher '"
operator|+
name|cipher
operator|+
literal|"' is not available"
argument_list|)
throw|;
block|}
name|key
operator|=
name|cipher
operator|.
name|getRandomKey
argument_list|()
expr_stmt|;
block|}
name|cryptoContext
operator|=
name|Encryption
operator|.
name|newContext
argument_list|(
name|conf
argument_list|)
expr_stmt|;
name|cryptoContext
operator|.
name|setCipher
argument_list|(
name|cipher
argument_list|)
expr_stmt|;
name|cryptoContext
operator|.
name|setKey
argument_list|(
name|key
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * @param family    * @return TTL in seconds of the specified family    */
specifier|private
specifier|static
name|long
name|determineTTLFromFamily
parameter_list|(
specifier|final
name|HColumnDescriptor
name|family
parameter_list|)
block|{
comment|// HCD.getTimeToLive returns ttl in seconds.  Convert to milliseconds.
name|long
name|ttl
init|=
name|family
operator|.
name|getTimeToLive
argument_list|()
decl_stmt|;
if|if
condition|(
name|ttl
operator|==
name|HConstants
operator|.
name|FOREVER
condition|)
block|{
comment|// Default is unlimited ttl.
name|ttl
operator|=
name|Long
operator|.
name|MAX_VALUE
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|ttl
operator|==
operator|-
literal|1
condition|)
block|{
name|ttl
operator|=
name|Long
operator|.
name|MAX_VALUE
expr_stmt|;
block|}
else|else
block|{
comment|// Second -> ms adjust for user data
name|ttl
operator|*=
literal|1000
expr_stmt|;
block|}
return|return
name|ttl
return|;
block|}
annotation|@
name|Override
specifier|public
name|String
name|getColumnFamilyName
parameter_list|()
block|{
return|return
name|this
operator|.
name|family
operator|.
name|getNameAsString
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|TableName
name|getTableName
parameter_list|()
block|{
return|return
name|this
operator|.
name|getRegionInfo
argument_list|()
operator|.
name|getTable
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|FileSystem
name|getFileSystem
parameter_list|()
block|{
return|return
name|this
operator|.
name|fs
operator|.
name|getFileSystem
argument_list|()
return|;
block|}
specifier|public
name|HRegionFileSystem
name|getRegionFileSystem
parameter_list|()
block|{
return|return
name|this
operator|.
name|fs
return|;
block|}
comment|/* Implementation of StoreConfigInformation */
annotation|@
name|Override
specifier|public
name|long
name|getStoreFileTtl
parameter_list|()
block|{
comment|// TTL only applies if there's no MIN_VERSIONs setting on the column.
return|return
operator|(
name|this
operator|.
name|scanInfo
operator|.
name|getMinVersions
argument_list|()
operator|==
literal|0
operator|)
condition|?
name|this
operator|.
name|scanInfo
operator|.
name|getTtl
argument_list|()
else|:
name|Long
operator|.
name|MAX_VALUE
return|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|getMemstoreFlushSize
parameter_list|()
block|{
comment|// TODO: Why is this in here?  The flushsize of the region rather than the store?  St.Ack
return|return
name|this
operator|.
name|region
operator|.
name|memstoreFlushSize
return|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|getFlushableSize
parameter_list|()
block|{
return|return
name|this
operator|.
name|memstore
operator|.
name|getFlushableSize
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|getCompactionCheckMultiplier
parameter_list|()
block|{
return|return
name|this
operator|.
name|compactionCheckMultiplier
return|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|getBlockingFileCount
parameter_list|()
block|{
return|return
name|blockingFileCount
return|;
block|}
comment|/* End implementation of StoreConfigInformation */
comment|/**    * Returns the configured bytesPerChecksum value.    * @param conf The configuration    * @return The bytesPerChecksum that is set in the configuration    */
specifier|public
specifier|static
name|int
name|getBytesPerChecksum
parameter_list|(
name|Configuration
name|conf
parameter_list|)
block|{
return|return
name|conf
operator|.
name|getInt
argument_list|(
name|HConstants
operator|.
name|BYTES_PER_CHECKSUM
argument_list|,
name|HFile
operator|.
name|DEFAULT_BYTES_PER_CHECKSUM
argument_list|)
return|;
block|}
comment|/**    * Returns the configured checksum algorithm.    * @param conf The configuration    * @return The checksum algorithm that is set in the configuration    */
specifier|public
specifier|static
name|ChecksumType
name|getChecksumType
parameter_list|(
name|Configuration
name|conf
parameter_list|)
block|{
name|String
name|checksumName
init|=
name|conf
operator|.
name|get
argument_list|(
name|HConstants
operator|.
name|CHECKSUM_TYPE_NAME
argument_list|)
decl_stmt|;
if|if
condition|(
name|checksumName
operator|==
literal|null
condition|)
block|{
return|return
name|HFile
operator|.
name|DEFAULT_CHECKSUM_TYPE
return|;
block|}
else|else
block|{
return|return
name|ChecksumType
operator|.
name|nameToType
argument_list|(
name|checksumName
argument_list|)
return|;
block|}
block|}
comment|/**    * @return how many bytes to write between status checks    */
specifier|public
specifier|static
name|int
name|getCloseCheckInterval
parameter_list|()
block|{
return|return
name|closeCheckInterval
return|;
block|}
annotation|@
name|Override
specifier|public
name|HColumnDescriptor
name|getFamily
parameter_list|()
block|{
return|return
name|this
operator|.
name|family
return|;
block|}
comment|/**    * @return The maximum sequence id in all store files. Used for log replay.    */
name|long
name|getMaxSequenceId
parameter_list|()
block|{
return|return
name|StoreFile
operator|.
name|getMaxSequenceIdInList
argument_list|(
name|this
operator|.
name|getStorefiles
argument_list|()
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|getMaxMemstoreTS
parameter_list|()
block|{
return|return
name|StoreFile
operator|.
name|getMaxMemstoreTSInList
argument_list|(
name|this
operator|.
name|getStorefiles
argument_list|()
argument_list|)
return|;
block|}
comment|/**    * @param tabledir {@link Path} to where the table is being stored    * @param hri {@link HRegionInfo} for the region.    * @param family {@link HColumnDescriptor} describing the column family    * @return Path to family/Store home directory.    */
annotation|@
name|Deprecated
specifier|public
specifier|static
name|Path
name|getStoreHomedir
parameter_list|(
specifier|final
name|Path
name|tabledir
parameter_list|,
specifier|final
name|HRegionInfo
name|hri
parameter_list|,
specifier|final
name|byte
index|[]
name|family
parameter_list|)
block|{
return|return
name|getStoreHomedir
argument_list|(
name|tabledir
argument_list|,
name|hri
operator|.
name|getEncodedName
argument_list|()
argument_list|,
name|family
argument_list|)
return|;
block|}
comment|/**    * @param tabledir {@link Path} to where the table is being stored    * @param encodedName Encoded region name.    * @param family {@link HColumnDescriptor} describing the column family    * @return Path to family/Store home directory.    */
annotation|@
name|Deprecated
specifier|public
specifier|static
name|Path
name|getStoreHomedir
parameter_list|(
specifier|final
name|Path
name|tabledir
parameter_list|,
specifier|final
name|String
name|encodedName
parameter_list|,
specifier|final
name|byte
index|[]
name|family
parameter_list|)
block|{
return|return
operator|new
name|Path
argument_list|(
name|tabledir
argument_list|,
operator|new
name|Path
argument_list|(
name|encodedName
argument_list|,
name|Bytes
operator|.
name|toString
argument_list|(
name|family
argument_list|)
argument_list|)
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|HFileDataBlockEncoder
name|getDataBlockEncoder
parameter_list|()
block|{
return|return
name|dataBlockEncoder
return|;
block|}
comment|/**    * Should be used only in tests.    * @param blockEncoder the block delta encoder to use    */
name|void
name|setDataBlockEncoderInTest
parameter_list|(
name|HFileDataBlockEncoder
name|blockEncoder
parameter_list|)
block|{
name|this
operator|.
name|dataBlockEncoder
operator|=
name|blockEncoder
expr_stmt|;
block|}
comment|/**    * Creates an unsorted list of StoreFile loaded in parallel    * from the given directory.    * @throws IOException    */
specifier|private
name|List
argument_list|<
name|StoreFile
argument_list|>
name|loadStoreFiles
parameter_list|()
throws|throws
name|IOException
block|{
name|Collection
argument_list|<
name|StoreFileInfo
argument_list|>
name|files
init|=
name|fs
operator|.
name|getStoreFiles
argument_list|(
name|getColumnFamilyName
argument_list|()
argument_list|)
decl_stmt|;
return|return
name|openStoreFiles
argument_list|(
name|files
argument_list|)
return|;
block|}
specifier|private
name|List
argument_list|<
name|StoreFile
argument_list|>
name|openStoreFiles
parameter_list|(
name|Collection
argument_list|<
name|StoreFileInfo
argument_list|>
name|files
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|files
operator|==
literal|null
operator|||
name|files
operator|.
name|size
argument_list|()
operator|==
literal|0
condition|)
block|{
return|return
operator|new
name|ArrayList
argument_list|<
name|StoreFile
argument_list|>
argument_list|()
return|;
block|}
comment|// initialize the thread pool for opening store files in parallel..
name|ThreadPoolExecutor
name|storeFileOpenerThreadPool
init|=
name|this
operator|.
name|region
operator|.
name|getStoreFileOpenAndCloseThreadPool
argument_list|(
literal|"StoreFileOpenerThread-"
operator|+
name|this
operator|.
name|getColumnFamilyName
argument_list|()
argument_list|)
decl_stmt|;
name|CompletionService
argument_list|<
name|StoreFile
argument_list|>
name|completionService
init|=
operator|new
name|ExecutorCompletionService
argument_list|<
name|StoreFile
argument_list|>
argument_list|(
name|storeFileOpenerThreadPool
argument_list|)
decl_stmt|;
name|int
name|totalValidStoreFile
init|=
literal|0
decl_stmt|;
for|for
control|(
specifier|final
name|StoreFileInfo
name|storeFileInfo
range|:
name|files
control|)
block|{
comment|// open each store file in parallel
name|completionService
operator|.
name|submit
argument_list|(
operator|new
name|Callable
argument_list|<
name|StoreFile
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|StoreFile
name|call
parameter_list|()
throws|throws
name|IOException
block|{
name|StoreFile
name|storeFile
init|=
name|createStoreFileAndReader
argument_list|(
name|storeFileInfo
argument_list|)
decl_stmt|;
return|return
name|storeFile
return|;
block|}
block|}
argument_list|)
expr_stmt|;
name|totalValidStoreFile
operator|++
expr_stmt|;
block|}
name|ArrayList
argument_list|<
name|StoreFile
argument_list|>
name|results
init|=
operator|new
name|ArrayList
argument_list|<
name|StoreFile
argument_list|>
argument_list|(
name|files
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
name|IOException
name|ioe
init|=
literal|null
decl_stmt|;
try|try
block|{
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|totalValidStoreFile
condition|;
name|i
operator|++
control|)
block|{
try|try
block|{
name|Future
argument_list|<
name|StoreFile
argument_list|>
name|future
init|=
name|completionService
operator|.
name|take
argument_list|()
decl_stmt|;
name|StoreFile
name|storeFile
init|=
name|future
operator|.
name|get
argument_list|()
decl_stmt|;
name|long
name|length
init|=
name|storeFile
operator|.
name|getReader
argument_list|()
operator|.
name|length
argument_list|()
decl_stmt|;
name|this
operator|.
name|storeSize
operator|+=
name|length
expr_stmt|;
name|this
operator|.
name|totalUncompressedBytes
operator|+=
name|storeFile
operator|.
name|getReader
argument_list|()
operator|.
name|getTotalUncompressedBytes
argument_list|()
expr_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"loaded "
operator|+
name|storeFile
operator|.
name|toStringDetailed
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|results
operator|.
name|add
argument_list|(
name|storeFile
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
if|if
condition|(
name|ioe
operator|==
literal|null
condition|)
name|ioe
operator|=
operator|new
name|InterruptedIOException
argument_list|(
name|e
operator|.
name|getMessage
argument_list|()
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|ExecutionException
name|e
parameter_list|)
block|{
if|if
condition|(
name|ioe
operator|==
literal|null
condition|)
name|ioe
operator|=
operator|new
name|IOException
argument_list|(
name|e
operator|.
name|getCause
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
block|}
finally|finally
block|{
name|storeFileOpenerThreadPool
operator|.
name|shutdownNow
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|ioe
operator|!=
literal|null
condition|)
block|{
comment|// close StoreFile readers
for|for
control|(
name|StoreFile
name|file
range|:
name|results
control|)
block|{
try|try
block|{
if|if
condition|(
name|file
operator|!=
literal|null
condition|)
name|file
operator|.
name|closeReader
argument_list|(
literal|true
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
name|e
operator|.
name|getMessage
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
throw|throw
name|ioe
throw|;
block|}
return|return
name|results
return|;
block|}
comment|/**    * Checks the underlying store files, and opens the files that  have not    * been opened, and removes the store file readers for store files no longer    * available. Mainly used by secondary region replicas to keep up to date with    * the primary region files.    * @throws IOException    */
annotation|@
name|Override
specifier|public
name|void
name|refreshStoreFiles
parameter_list|()
throws|throws
name|IOException
block|{
name|StoreFileManager
name|sfm
init|=
name|storeEngine
operator|.
name|getStoreFileManager
argument_list|()
decl_stmt|;
name|Collection
argument_list|<
name|StoreFile
argument_list|>
name|currentFiles
init|=
name|sfm
operator|.
name|getStorefiles
argument_list|()
decl_stmt|;
if|if
condition|(
name|currentFiles
operator|==
literal|null
condition|)
name|currentFiles
operator|=
operator|new
name|ArrayList
argument_list|<
name|StoreFile
argument_list|>
argument_list|(
literal|0
argument_list|)
expr_stmt|;
name|Collection
argument_list|<
name|StoreFileInfo
argument_list|>
name|newFiles
init|=
name|fs
operator|.
name|getStoreFiles
argument_list|(
name|getColumnFamilyName
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
name|newFiles
operator|==
literal|null
condition|)
name|newFiles
operator|=
operator|new
name|ArrayList
argument_list|<
name|StoreFileInfo
argument_list|>
argument_list|(
literal|0
argument_list|)
expr_stmt|;
name|HashMap
argument_list|<
name|StoreFileInfo
argument_list|,
name|StoreFile
argument_list|>
name|currentFilesSet
init|=
operator|new
name|HashMap
argument_list|<
name|StoreFileInfo
argument_list|,
name|StoreFile
argument_list|>
argument_list|(
name|currentFiles
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
for|for
control|(
name|StoreFile
name|sf
range|:
name|currentFiles
control|)
block|{
name|currentFilesSet
operator|.
name|put
argument_list|(
name|sf
operator|.
name|getFileInfo
argument_list|()
argument_list|,
name|sf
argument_list|)
expr_stmt|;
block|}
name|HashSet
argument_list|<
name|StoreFileInfo
argument_list|>
name|newFilesSet
init|=
operator|new
name|HashSet
argument_list|<
name|StoreFileInfo
argument_list|>
argument_list|(
name|newFiles
argument_list|)
decl_stmt|;
name|Set
argument_list|<
name|StoreFileInfo
argument_list|>
name|toBeAddedFiles
init|=
name|Sets
operator|.
name|difference
argument_list|(
name|newFilesSet
argument_list|,
name|currentFilesSet
operator|.
name|keySet
argument_list|()
argument_list|)
decl_stmt|;
name|Set
argument_list|<
name|StoreFileInfo
argument_list|>
name|toBeRemovedFiles
init|=
name|Sets
operator|.
name|difference
argument_list|(
name|currentFilesSet
operator|.
name|keySet
argument_list|()
argument_list|,
name|newFilesSet
argument_list|)
decl_stmt|;
if|if
condition|(
name|toBeAddedFiles
operator|.
name|isEmpty
argument_list|()
operator|&&
name|toBeRemovedFiles
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
return|return;
block|}
name|LOG
operator|.
name|info
argument_list|(
literal|"Refreshing store files for region "
operator|+
name|this
operator|.
name|getRegionInfo
argument_list|()
operator|.
name|getRegionNameAsString
argument_list|()
operator|+
literal|" files to add: "
operator|+
name|toBeAddedFiles
operator|+
literal|" files to remove: "
operator|+
name|toBeRemovedFiles
argument_list|)
expr_stmt|;
name|Set
argument_list|<
name|StoreFile
argument_list|>
name|toBeRemovedStoreFiles
init|=
operator|new
name|HashSet
argument_list|<
name|StoreFile
argument_list|>
argument_list|(
name|toBeRemovedFiles
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
for|for
control|(
name|StoreFileInfo
name|sfi
range|:
name|toBeRemovedFiles
control|)
block|{
name|toBeRemovedStoreFiles
operator|.
name|add
argument_list|(
name|currentFilesSet
operator|.
name|get
argument_list|(
name|sfi
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|// try to open the files
name|List
argument_list|<
name|StoreFile
argument_list|>
name|openedFiles
init|=
name|openStoreFiles
argument_list|(
name|toBeAddedFiles
argument_list|)
decl_stmt|;
comment|// propogate the file changes to the underlying store file manager
name|replaceStoreFiles
argument_list|(
name|toBeRemovedStoreFiles
argument_list|,
name|openedFiles
argument_list|)
expr_stmt|;
comment|//won't throw an exception
comment|// Advance the memstore read point to be at least the new store files seqIds so that
comment|// readers might pick it up. This assumes that the store is not getting any writes (otherwise
comment|// in-flight transactions might be made visible)
if|if
condition|(
operator|!
name|toBeAddedFiles
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|region
operator|.
name|getMVCC
argument_list|()
operator|.
name|advanceMemstoreReadPointIfNeeded
argument_list|(
name|this
operator|.
name|getMaxSequenceId
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|// notify scanners, close file readers, and recompute store size
name|completeCompaction
argument_list|(
name|toBeRemovedStoreFiles
argument_list|,
literal|false
argument_list|)
expr_stmt|;
block|}
specifier|private
name|StoreFile
name|createStoreFileAndReader
parameter_list|(
specifier|final
name|Path
name|p
parameter_list|)
throws|throws
name|IOException
block|{
name|StoreFileInfo
name|info
init|=
operator|new
name|StoreFileInfo
argument_list|(
name|conf
argument_list|,
name|this
operator|.
name|getFileSystem
argument_list|()
argument_list|,
name|p
argument_list|)
decl_stmt|;
return|return
name|createStoreFileAndReader
argument_list|(
name|info
argument_list|)
return|;
block|}
specifier|private
name|StoreFile
name|createStoreFileAndReader
parameter_list|(
specifier|final
name|StoreFileInfo
name|info
parameter_list|)
throws|throws
name|IOException
block|{
name|info
operator|.
name|setRegionCoprocessorHost
argument_list|(
name|this
operator|.
name|region
operator|.
name|getCoprocessorHost
argument_list|()
argument_list|)
expr_stmt|;
name|StoreFile
name|storeFile
init|=
operator|new
name|StoreFile
argument_list|(
name|this
operator|.
name|getFileSystem
argument_list|()
argument_list|,
name|info
argument_list|,
name|this
operator|.
name|conf
argument_list|,
name|this
operator|.
name|cacheConf
argument_list|,
name|this
operator|.
name|family
operator|.
name|getBloomFilterType
argument_list|()
argument_list|)
decl_stmt|;
name|storeFile
operator|.
name|createReader
argument_list|()
expr_stmt|;
return|return
name|storeFile
return|;
block|}
annotation|@
name|Override
specifier|public
name|Pair
argument_list|<
name|Long
argument_list|,
name|Cell
argument_list|>
name|add
parameter_list|(
specifier|final
name|KeyValue
name|kv
parameter_list|)
block|{
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
return|return
name|this
operator|.
name|memstore
operator|.
name|add
argument_list|(
name|kv
argument_list|)
return|;
block|}
finally|finally
block|{
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|long
name|timeOfOldestEdit
parameter_list|()
block|{
return|return
name|memstore
operator|.
name|timeOfOldestEdit
argument_list|()
return|;
block|}
comment|/**    * Adds a value to the memstore    *    * @param kv    * @return memstore size delta    */
specifier|protected
name|long
name|delete
parameter_list|(
specifier|final
name|KeyValue
name|kv
parameter_list|)
block|{
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
return|return
name|this
operator|.
name|memstore
operator|.
name|delete
argument_list|(
name|kv
argument_list|)
return|;
block|}
finally|finally
block|{
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|void
name|rollback
parameter_list|(
specifier|final
name|KeyValue
name|kv
parameter_list|)
block|{
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
name|this
operator|.
name|memstore
operator|.
name|rollback
argument_list|(
name|kv
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**    * @return All store files.    */
annotation|@
name|Override
specifier|public
name|Collection
argument_list|<
name|StoreFile
argument_list|>
name|getStorefiles
parameter_list|()
block|{
return|return
name|this
operator|.
name|storeEngine
operator|.
name|getStoreFileManager
argument_list|()
operator|.
name|getStorefiles
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|assertBulkLoadHFileOk
parameter_list|(
name|Path
name|srcPath
parameter_list|)
throws|throws
name|IOException
block|{
name|HFile
operator|.
name|Reader
name|reader
init|=
literal|null
decl_stmt|;
try|try
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Validating hfile at "
operator|+
name|srcPath
operator|+
literal|" for inclusion in "
operator|+
literal|"store "
operator|+
name|this
operator|+
literal|" region "
operator|+
name|this
operator|.
name|getRegionInfo
argument_list|()
operator|.
name|getRegionNameAsString
argument_list|()
argument_list|)
expr_stmt|;
name|reader
operator|=
name|HFile
operator|.
name|createReader
argument_list|(
name|srcPath
operator|.
name|getFileSystem
argument_list|(
name|conf
argument_list|)
argument_list|,
name|srcPath
argument_list|,
name|cacheConf
argument_list|,
name|conf
argument_list|)
expr_stmt|;
name|reader
operator|.
name|loadFileInfo
argument_list|()
expr_stmt|;
name|byte
index|[]
name|firstKey
init|=
name|reader
operator|.
name|getFirstRowKey
argument_list|()
decl_stmt|;
name|Preconditions
operator|.
name|checkState
argument_list|(
name|firstKey
operator|!=
literal|null
argument_list|,
literal|"First key can not be null"
argument_list|)
expr_stmt|;
name|byte
index|[]
name|lk
init|=
name|reader
operator|.
name|getLastKey
argument_list|()
decl_stmt|;
name|Preconditions
operator|.
name|checkState
argument_list|(
name|lk
operator|!=
literal|null
argument_list|,
literal|"Last key can not be null"
argument_list|)
expr_stmt|;
name|byte
index|[]
name|lastKey
init|=
name|KeyValue
operator|.
name|createKeyValueFromKey
argument_list|(
name|lk
argument_list|)
operator|.
name|getRow
argument_list|()
decl_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"HFile bounds: first="
operator|+
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|firstKey
argument_list|)
operator|+
literal|" last="
operator|+
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|lastKey
argument_list|)
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|debug
argument_list|(
literal|"Region bounds: first="
operator|+
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|getRegionInfo
argument_list|()
operator|.
name|getStartKey
argument_list|()
argument_list|)
operator|+
literal|" last="
operator|+
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|getRegionInfo
argument_list|()
operator|.
name|getEndKey
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|this
operator|.
name|getRegionInfo
argument_list|()
operator|.
name|containsRange
argument_list|(
name|firstKey
argument_list|,
name|lastKey
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|WrongRegionException
argument_list|(
literal|"Bulk load file "
operator|+
name|srcPath
operator|.
name|toString
argument_list|()
operator|+
literal|" does not fit inside region "
operator|+
name|this
operator|.
name|getRegionInfo
argument_list|()
operator|.
name|getRegionNameAsString
argument_list|()
argument_list|)
throw|;
block|}
if|if
condition|(
name|verifyBulkLoads
condition|)
block|{
name|long
name|verificationStartTime
init|=
name|EnvironmentEdgeManager
operator|.
name|currentTime
argument_list|()
decl_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Full verification started for bulk load hfile: "
operator|+
name|srcPath
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
name|Cell
name|prevKV
init|=
literal|null
decl_stmt|;
name|HFileScanner
name|scanner
init|=
name|reader
operator|.
name|getScanner
argument_list|(
literal|false
argument_list|,
literal|false
argument_list|,
literal|false
argument_list|)
decl_stmt|;
name|scanner
operator|.
name|seekTo
argument_list|()
expr_stmt|;
do|do
block|{
name|Cell
name|kv
init|=
name|scanner
operator|.
name|getKeyValue
argument_list|()
decl_stmt|;
if|if
condition|(
name|prevKV
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
name|Bytes
operator|.
name|compareTo
argument_list|(
name|prevKV
operator|.
name|getRowArray
argument_list|()
argument_list|,
name|prevKV
operator|.
name|getRowOffset
argument_list|()
argument_list|,
name|prevKV
operator|.
name|getRowLength
argument_list|()
argument_list|,
name|kv
operator|.
name|getRowArray
argument_list|()
argument_list|,
name|kv
operator|.
name|getRowOffset
argument_list|()
argument_list|,
name|kv
operator|.
name|getRowLength
argument_list|()
argument_list|)
operator|>
literal|0
condition|)
block|{
throw|throw
operator|new
name|InvalidHFileException
argument_list|(
literal|"Previous row is greater than"
operator|+
literal|" current row: path="
operator|+
name|srcPath
operator|+
literal|" previous="
operator|+
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|KeyValueUtil
operator|.
name|ensureKeyValue
argument_list|(
name|prevKV
argument_list|)
operator|.
name|getKey
argument_list|()
argument_list|)
operator|+
literal|" current="
operator|+
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|KeyValueUtil
operator|.
name|ensureKeyValue
argument_list|(
name|kv
argument_list|)
operator|.
name|getKey
argument_list|()
argument_list|)
argument_list|)
throw|;
block|}
if|if
condition|(
name|Bytes
operator|.
name|compareTo
argument_list|(
name|prevKV
operator|.
name|getFamilyArray
argument_list|()
argument_list|,
name|prevKV
operator|.
name|getFamilyOffset
argument_list|()
argument_list|,
name|prevKV
operator|.
name|getFamilyLength
argument_list|()
argument_list|,
name|kv
operator|.
name|getFamilyArray
argument_list|()
argument_list|,
name|kv
operator|.
name|getFamilyOffset
argument_list|()
argument_list|,
name|kv
operator|.
name|getFamilyLength
argument_list|()
argument_list|)
operator|!=
literal|0
condition|)
block|{
throw|throw
operator|new
name|InvalidHFileException
argument_list|(
literal|"Previous key had different"
operator|+
literal|" family compared to current key: path="
operator|+
name|srcPath
operator|+
literal|" previous="
operator|+
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|prevKV
operator|.
name|getFamily
argument_list|()
argument_list|)
operator|+
literal|" current="
operator|+
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|kv
operator|.
name|getFamily
argument_list|()
argument_list|)
argument_list|)
throw|;
block|}
block|}
name|prevKV
operator|=
name|kv
expr_stmt|;
block|}
do|while
condition|(
name|scanner
operator|.
name|next
argument_list|()
condition|)
do|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Full verification complete for bulk load hfile: "
operator|+
name|srcPath
operator|.
name|toString
argument_list|()
operator|+
literal|" took "
operator|+
operator|(
name|EnvironmentEdgeManager
operator|.
name|currentTime
argument_list|()
operator|-
name|verificationStartTime
operator|)
operator|+
literal|" ms"
argument_list|)
expr_stmt|;
block|}
block|}
finally|finally
block|{
if|if
condition|(
name|reader
operator|!=
literal|null
condition|)
name|reader
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|void
name|bulkLoadHFile
parameter_list|(
name|String
name|srcPathStr
parameter_list|,
name|long
name|seqNum
parameter_list|)
throws|throws
name|IOException
block|{
name|Path
name|srcPath
init|=
operator|new
name|Path
argument_list|(
name|srcPathStr
argument_list|)
decl_stmt|;
name|Path
name|dstPath
init|=
name|fs
operator|.
name|bulkLoadStoreFile
argument_list|(
name|getColumnFamilyName
argument_list|()
argument_list|,
name|srcPath
argument_list|,
name|seqNum
argument_list|)
decl_stmt|;
name|StoreFile
name|sf
init|=
name|createStoreFileAndReader
argument_list|(
name|dstPath
argument_list|)
decl_stmt|;
name|StoreFile
operator|.
name|Reader
name|r
init|=
name|sf
operator|.
name|getReader
argument_list|()
decl_stmt|;
name|this
operator|.
name|storeSize
operator|+=
name|r
operator|.
name|length
argument_list|()
expr_stmt|;
name|this
operator|.
name|totalUncompressedBytes
operator|+=
name|r
operator|.
name|getTotalUncompressedBytes
argument_list|()
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Loaded HFile "
operator|+
name|srcPath
operator|+
literal|" into store '"
operator|+
name|getColumnFamilyName
argument_list|()
operator|+
literal|"' as "
operator|+
name|dstPath
operator|+
literal|" - updating store file list."
argument_list|)
expr_stmt|;
comment|// Append the new storefile into the list
name|this
operator|.
name|lock
operator|.
name|writeLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
name|this
operator|.
name|storeEngine
operator|.
name|getStoreFileManager
argument_list|()
operator|.
name|insertNewFiles
argument_list|(
name|Lists
operator|.
name|newArrayList
argument_list|(
name|sf
argument_list|)
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
comment|// We need the lock, as long as we are updating the storeFiles
comment|// or changing the memstore. Let us release it before calling
comment|// notifyChangeReadersObservers. See HBASE-4485 for a possible
comment|// deadlock scenario that could have happened if continue to hold
comment|// the lock.
name|this
operator|.
name|lock
operator|.
name|writeLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
name|notifyChangedReadersObservers
argument_list|()
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Successfully loaded store file "
operator|+
name|srcPath
operator|+
literal|" into store "
operator|+
name|this
operator|+
literal|" (new location: "
operator|+
name|dstPath
operator|+
literal|")"
argument_list|)
expr_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|String
name|traceMessage
init|=
literal|"BULK LOAD time,size,store size,store files ["
operator|+
name|EnvironmentEdgeManager
operator|.
name|currentTime
argument_list|()
operator|+
literal|","
operator|+
name|r
operator|.
name|length
argument_list|()
operator|+
literal|","
operator|+
name|storeSize
operator|+
literal|","
operator|+
name|storeEngine
operator|.
name|getStoreFileManager
argument_list|()
operator|.
name|getStorefileCount
argument_list|()
operator|+
literal|"]"
decl_stmt|;
name|LOG
operator|.
name|trace
argument_list|(
name|traceMessage
argument_list|)
expr_stmt|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|ImmutableCollection
argument_list|<
name|StoreFile
argument_list|>
name|close
parameter_list|()
throws|throws
name|IOException
block|{
name|this
operator|.
name|lock
operator|.
name|writeLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
comment|// Clear so metrics doesn't find them.
name|ImmutableCollection
argument_list|<
name|StoreFile
argument_list|>
name|result
init|=
name|storeEngine
operator|.
name|getStoreFileManager
argument_list|()
operator|.
name|clearFiles
argument_list|()
decl_stmt|;
if|if
condition|(
operator|!
name|result
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
comment|// initialize the thread pool for closing store files in parallel.
name|ThreadPoolExecutor
name|storeFileCloserThreadPool
init|=
name|this
operator|.
name|region
operator|.
name|getStoreFileOpenAndCloseThreadPool
argument_list|(
literal|"StoreFileCloserThread-"
operator|+
name|this
operator|.
name|getColumnFamilyName
argument_list|()
argument_list|)
decl_stmt|;
comment|// close each store file in parallel
name|CompletionService
argument_list|<
name|Void
argument_list|>
name|completionService
init|=
operator|new
name|ExecutorCompletionService
argument_list|<
name|Void
argument_list|>
argument_list|(
name|storeFileCloserThreadPool
argument_list|)
decl_stmt|;
for|for
control|(
specifier|final
name|StoreFile
name|f
range|:
name|result
control|)
block|{
name|completionService
operator|.
name|submit
argument_list|(
operator|new
name|Callable
argument_list|<
name|Void
argument_list|>
argument_list|()
block|{
annotation|@
name|Override
specifier|public
name|Void
name|call
parameter_list|()
throws|throws
name|IOException
block|{
name|f
operator|.
name|closeReader
argument_list|(
literal|true
argument_list|)
expr_stmt|;
return|return
literal|null
return|;
block|}
block|}
argument_list|)
expr_stmt|;
block|}
name|IOException
name|ioe
init|=
literal|null
decl_stmt|;
try|try
block|{
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|result
operator|.
name|size
argument_list|()
condition|;
name|i
operator|++
control|)
block|{
try|try
block|{
name|Future
argument_list|<
name|Void
argument_list|>
name|future
init|=
name|completionService
operator|.
name|take
argument_list|()
decl_stmt|;
name|future
operator|.
name|get
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
if|if
condition|(
name|ioe
operator|==
literal|null
condition|)
block|{
name|ioe
operator|=
operator|new
name|InterruptedIOException
argument_list|()
expr_stmt|;
name|ioe
operator|.
name|initCause
argument_list|(
name|e
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|ExecutionException
name|e
parameter_list|)
block|{
if|if
condition|(
name|ioe
operator|==
literal|null
condition|)
name|ioe
operator|=
operator|new
name|IOException
argument_list|(
name|e
operator|.
name|getCause
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
block|}
finally|finally
block|{
name|storeFileCloserThreadPool
operator|.
name|shutdownNow
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|ioe
operator|!=
literal|null
condition|)
throw|throw
name|ioe
throw|;
block|}
name|LOG
operator|.
name|info
argument_list|(
literal|"Closed "
operator|+
name|this
argument_list|)
expr_stmt|;
return|return
name|result
return|;
block|}
finally|finally
block|{
name|this
operator|.
name|lock
operator|.
name|writeLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**    * Snapshot this stores memstore. Call before running    * {@link #flushCache(long, MemStoreSnapshot, MonitoredTask)}    *  so it has some work to do.    */
name|void
name|snapshot
parameter_list|()
block|{
name|this
operator|.
name|lock
operator|.
name|writeLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
name|this
operator|.
name|memstore
operator|.
name|snapshot
argument_list|()
expr_stmt|;
block|}
finally|finally
block|{
name|this
operator|.
name|lock
operator|.
name|writeLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**    * Write out current snapshot.  Presumes {@link #snapshot()} has been called    * previously.    * @param logCacheFlushId flush sequence number    * @param snapshot    * @param status    * @return The path name of the tmp file to which the store was flushed    * @throws IOException    */
specifier|protected
name|List
argument_list|<
name|Path
argument_list|>
name|flushCache
parameter_list|(
specifier|final
name|long
name|logCacheFlushId
parameter_list|,
name|MemStoreSnapshot
name|snapshot
parameter_list|,
name|MonitoredTask
name|status
parameter_list|)
throws|throws
name|IOException
block|{
comment|// If an exception happens flushing, we let it out without clearing
comment|// the memstore snapshot.  The old snapshot will be returned when we say
comment|// 'snapshot', the next time flush comes around.
comment|// Retry after catching exception when flushing, otherwise server will abort
comment|// itself
name|StoreFlusher
name|flusher
init|=
name|storeEngine
operator|.
name|getStoreFlusher
argument_list|()
decl_stmt|;
name|IOException
name|lastException
init|=
literal|null
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|flushRetriesNumber
condition|;
name|i
operator|++
control|)
block|{
try|try
block|{
name|List
argument_list|<
name|Path
argument_list|>
name|pathNames
init|=
name|flusher
operator|.
name|flushSnapshot
argument_list|(
name|snapshot
argument_list|,
name|logCacheFlushId
argument_list|,
name|status
argument_list|)
decl_stmt|;
name|Path
name|lastPathName
init|=
literal|null
decl_stmt|;
try|try
block|{
for|for
control|(
name|Path
name|pathName
range|:
name|pathNames
control|)
block|{
name|lastPathName
operator|=
name|pathName
expr_stmt|;
name|validateStoreFile
argument_list|(
name|pathName
argument_list|)
expr_stmt|;
block|}
return|return
name|pathNames
return|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failed validating store file "
operator|+
name|lastPathName
operator|+
literal|", retrying num="
operator|+
name|i
argument_list|,
name|e
argument_list|)
expr_stmt|;
if|if
condition|(
name|e
operator|instanceof
name|IOException
condition|)
block|{
name|lastException
operator|=
operator|(
name|IOException
operator|)
name|e
expr_stmt|;
block|}
else|else
block|{
name|lastException
operator|=
operator|new
name|IOException
argument_list|(
name|e
argument_list|)
expr_stmt|;
block|}
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failed flushing store file, retrying num="
operator|+
name|i
argument_list|,
name|e
argument_list|)
expr_stmt|;
name|lastException
operator|=
name|e
expr_stmt|;
block|}
if|if
condition|(
name|lastException
operator|!=
literal|null
operator|&&
name|i
operator|<
operator|(
name|flushRetriesNumber
operator|-
literal|1
operator|)
condition|)
block|{
try|try
block|{
name|Thread
operator|.
name|sleep
argument_list|(
name|pauseTime
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|InterruptedException
name|e
parameter_list|)
block|{
name|IOException
name|iie
init|=
operator|new
name|InterruptedIOException
argument_list|()
decl_stmt|;
name|iie
operator|.
name|initCause
argument_list|(
name|e
argument_list|)
expr_stmt|;
throw|throw
name|iie
throw|;
block|}
block|}
block|}
throw|throw
name|lastException
throw|;
block|}
comment|/*    * @param path The pathname of the tmp file into which the store was flushed    * @param logCacheFlushId    * @param status    * @return StoreFile created.    * @throws IOException    */
specifier|private
name|StoreFile
name|commitFile
parameter_list|(
specifier|final
name|Path
name|path
parameter_list|,
specifier|final
name|long
name|logCacheFlushId
parameter_list|,
name|MonitoredTask
name|status
parameter_list|)
throws|throws
name|IOException
block|{
comment|// Write-out finished successfully, move into the right spot
name|Path
name|dstPath
init|=
name|fs
operator|.
name|commitStoreFile
argument_list|(
name|getColumnFamilyName
argument_list|()
argument_list|,
name|path
argument_list|)
decl_stmt|;
name|status
operator|.
name|setStatus
argument_list|(
literal|"Flushing "
operator|+
name|this
operator|+
literal|": reopening flushed file"
argument_list|)
expr_stmt|;
name|StoreFile
name|sf
init|=
name|createStoreFileAndReader
argument_list|(
name|dstPath
argument_list|)
decl_stmt|;
name|StoreFile
operator|.
name|Reader
name|r
init|=
name|sf
operator|.
name|getReader
argument_list|()
decl_stmt|;
name|this
operator|.
name|storeSize
operator|+=
name|r
operator|.
name|length
argument_list|()
expr_stmt|;
name|this
operator|.
name|totalUncompressedBytes
operator|+=
name|r
operator|.
name|getTotalUncompressedBytes
argument_list|()
expr_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isInfoEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Added "
operator|+
name|sf
operator|+
literal|", entries="
operator|+
name|r
operator|.
name|getEntries
argument_list|()
operator|+
literal|", sequenceid="
operator|+
name|logCacheFlushId
operator|+
literal|", filesize="
operator|+
name|StringUtils
operator|.
name|humanReadableInt
argument_list|(
name|r
operator|.
name|length
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
return|return
name|sf
return|;
block|}
comment|/*    * @param maxKeyCount    * @param compression Compression algorithm to use    * @param isCompaction whether we are creating a new file in a compaction    * @param includesMVCCReadPoint - whether to include MVCC or not    * @param includesTag - includesTag or not    * @return Writer for a new StoreFile in the tmp dir.    */
annotation|@
name|Override
specifier|public
name|StoreFile
operator|.
name|Writer
name|createWriterInTmp
parameter_list|(
name|long
name|maxKeyCount
parameter_list|,
name|Compression
operator|.
name|Algorithm
name|compression
parameter_list|,
name|boolean
name|isCompaction
parameter_list|,
name|boolean
name|includeMVCCReadpoint
parameter_list|,
name|boolean
name|includesTag
parameter_list|)
throws|throws
name|IOException
block|{
specifier|final
name|CacheConfig
name|writerCacheConf
decl_stmt|;
if|if
condition|(
name|isCompaction
condition|)
block|{
comment|// Don't cache data on write on compactions.
name|writerCacheConf
operator|=
operator|new
name|CacheConfig
argument_list|(
name|cacheConf
argument_list|)
expr_stmt|;
name|writerCacheConf
operator|.
name|setCacheDataOnWrite
argument_list|(
literal|false
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|writerCacheConf
operator|=
name|cacheConf
expr_stmt|;
block|}
name|InetSocketAddress
index|[]
name|favoredNodes
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|region
operator|.
name|getRegionServerServices
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|favoredNodes
operator|=
name|region
operator|.
name|getRegionServerServices
argument_list|()
operator|.
name|getFavoredNodesForRegion
argument_list|(
name|region
operator|.
name|getRegionInfo
argument_list|()
operator|.
name|getEncodedName
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|HFileContext
name|hFileContext
init|=
name|createFileContext
argument_list|(
name|compression
argument_list|,
name|includeMVCCReadpoint
argument_list|,
name|includesTag
argument_list|,
name|cryptoContext
argument_list|)
decl_stmt|;
name|StoreFile
operator|.
name|Writer
name|w
init|=
operator|new
name|StoreFile
operator|.
name|WriterBuilder
argument_list|(
name|conf
argument_list|,
name|writerCacheConf
argument_list|,
name|this
operator|.
name|getFileSystem
argument_list|()
argument_list|)
operator|.
name|withFilePath
argument_list|(
name|fs
operator|.
name|createTempName
argument_list|()
argument_list|)
operator|.
name|withComparator
argument_list|(
name|comparator
argument_list|)
operator|.
name|withBloomType
argument_list|(
name|family
operator|.
name|getBloomFilterType
argument_list|()
argument_list|)
operator|.
name|withMaxKeyCount
argument_list|(
name|maxKeyCount
argument_list|)
operator|.
name|withFavoredNodes
argument_list|(
name|favoredNodes
argument_list|)
operator|.
name|withFileContext
argument_list|(
name|hFileContext
argument_list|)
operator|.
name|build
argument_list|()
decl_stmt|;
return|return
name|w
return|;
block|}
specifier|private
name|HFileContext
name|createFileContext
parameter_list|(
name|Compression
operator|.
name|Algorithm
name|compression
parameter_list|,
name|boolean
name|includeMVCCReadpoint
parameter_list|,
name|boolean
name|includesTag
parameter_list|,
name|Encryption
operator|.
name|Context
name|cryptoContext
parameter_list|)
block|{
if|if
condition|(
name|compression
operator|==
literal|null
condition|)
block|{
name|compression
operator|=
name|HFile
operator|.
name|DEFAULT_COMPRESSION_ALGORITHM
expr_stmt|;
block|}
name|HFileContext
name|hFileContext
init|=
operator|new
name|HFileContextBuilder
argument_list|()
operator|.
name|withIncludesMvcc
argument_list|(
name|includeMVCCReadpoint
argument_list|)
operator|.
name|withIncludesTags
argument_list|(
name|includesTag
argument_list|)
operator|.
name|withCompression
argument_list|(
name|compression
argument_list|)
operator|.
name|withCompressTags
argument_list|(
name|family
operator|.
name|shouldCompressTags
argument_list|()
argument_list|)
operator|.
name|withChecksumType
argument_list|(
name|checksumType
argument_list|)
operator|.
name|withBytesPerCheckSum
argument_list|(
name|bytesPerChecksum
argument_list|)
operator|.
name|withBlockSize
argument_list|(
name|blocksize
argument_list|)
operator|.
name|withHBaseCheckSum
argument_list|(
literal|true
argument_list|)
operator|.
name|withDataBlockEncoding
argument_list|(
name|family
operator|.
name|getDataBlockEncoding
argument_list|()
argument_list|)
operator|.
name|withEncryptionContext
argument_list|(
name|cryptoContext
argument_list|)
operator|.
name|build
argument_list|()
decl_stmt|;
return|return
name|hFileContext
return|;
block|}
comment|/*    * Change storeFiles adding into place the Reader produced by this new flush.    * @param sfs Store files    * @param snapshotId    * @throws IOException    * @return Whether compaction is required.    */
specifier|private
name|boolean
name|updateStorefiles
parameter_list|(
specifier|final
name|List
argument_list|<
name|StoreFile
argument_list|>
name|sfs
parameter_list|,
specifier|final
name|long
name|snapshotId
parameter_list|)
throws|throws
name|IOException
block|{
name|this
operator|.
name|lock
operator|.
name|writeLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
name|this
operator|.
name|storeEngine
operator|.
name|getStoreFileManager
argument_list|()
operator|.
name|insertNewFiles
argument_list|(
name|sfs
argument_list|)
expr_stmt|;
name|this
operator|.
name|memstore
operator|.
name|clearSnapshot
argument_list|(
name|snapshotId
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
comment|// We need the lock, as long as we are updating the storeFiles
comment|// or changing the memstore. Let us release it before calling
comment|// notifyChangeReadersObservers. See HBASE-4485 for a possible
comment|// deadlock scenario that could have happened if continue to hold
comment|// the lock.
name|this
operator|.
name|lock
operator|.
name|writeLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
comment|// Tell listeners of the change in readers.
name|notifyChangedReadersObservers
argument_list|()
expr_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|long
name|totalSize
init|=
literal|0
decl_stmt|;
for|for
control|(
name|StoreFile
name|sf
range|:
name|sfs
control|)
block|{
name|totalSize
operator|+=
name|sf
operator|.
name|getReader
argument_list|()
operator|.
name|length
argument_list|()
expr_stmt|;
block|}
name|String
name|traceMessage
init|=
literal|"FLUSH time,count,size,store size,store files ["
operator|+
name|EnvironmentEdgeManager
operator|.
name|currentTime
argument_list|()
operator|+
literal|","
operator|+
name|sfs
operator|.
name|size
argument_list|()
operator|+
literal|","
operator|+
name|totalSize
operator|+
literal|","
operator|+
name|storeSize
operator|+
literal|","
operator|+
name|storeEngine
operator|.
name|getStoreFileManager
argument_list|()
operator|.
name|getStorefileCount
argument_list|()
operator|+
literal|"]"
decl_stmt|;
name|LOG
operator|.
name|trace
argument_list|(
name|traceMessage
argument_list|)
expr_stmt|;
block|}
return|return
name|needsCompaction
argument_list|()
return|;
block|}
comment|/*    * Notify all observers that set of Readers has changed.    * @throws IOException    */
specifier|private
name|void
name|notifyChangedReadersObservers
parameter_list|()
throws|throws
name|IOException
block|{
for|for
control|(
name|ChangedReadersObserver
name|o
range|:
name|this
operator|.
name|changedReaderObservers
control|)
block|{
name|o
operator|.
name|updateReaders
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**    * Get all scanners with no filtering based on TTL (that happens further down    * the line).    * @return all scanners for this store    */
annotation|@
name|Override
specifier|public
name|List
argument_list|<
name|KeyValueScanner
argument_list|>
name|getScanners
parameter_list|(
name|boolean
name|cacheBlocks
parameter_list|,
name|boolean
name|isGet
parameter_list|,
name|boolean
name|usePread
parameter_list|,
name|boolean
name|isCompaction
parameter_list|,
name|ScanQueryMatcher
name|matcher
parameter_list|,
name|byte
index|[]
name|startRow
parameter_list|,
name|byte
index|[]
name|stopRow
parameter_list|,
name|long
name|readPt
parameter_list|)
throws|throws
name|IOException
block|{
name|Collection
argument_list|<
name|StoreFile
argument_list|>
name|storeFilesToScan
decl_stmt|;
name|List
argument_list|<
name|KeyValueScanner
argument_list|>
name|memStoreScanners
decl_stmt|;
name|this
operator|.
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
name|storeFilesToScan
operator|=
name|this
operator|.
name|storeEngine
operator|.
name|getStoreFileManager
argument_list|()
operator|.
name|getFilesForScanOrGet
argument_list|(
name|isGet
argument_list|,
name|startRow
argument_list|,
name|stopRow
argument_list|)
expr_stmt|;
name|memStoreScanners
operator|=
name|this
operator|.
name|memstore
operator|.
name|getScanners
argument_list|(
name|readPt
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|this
operator|.
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
comment|// First the store file scanners
comment|// TODO this used to get the store files in descending order,
comment|// but now we get them in ascending order, which I think is
comment|// actually more correct, since memstore get put at the end.
name|List
argument_list|<
name|StoreFileScanner
argument_list|>
name|sfScanners
init|=
name|StoreFileScanner
operator|.
name|getScannersForStoreFiles
argument_list|(
name|storeFilesToScan
argument_list|,
name|cacheBlocks
argument_list|,
name|usePread
argument_list|,
name|isCompaction
argument_list|,
name|matcher
argument_list|,
name|readPt
argument_list|)
decl_stmt|;
name|List
argument_list|<
name|KeyValueScanner
argument_list|>
name|scanners
init|=
operator|new
name|ArrayList
argument_list|<
name|KeyValueScanner
argument_list|>
argument_list|(
name|sfScanners
operator|.
name|size
argument_list|()
operator|+
literal|1
argument_list|)
decl_stmt|;
name|scanners
operator|.
name|addAll
argument_list|(
name|sfScanners
argument_list|)
expr_stmt|;
comment|// Then the memstore scanners
name|scanners
operator|.
name|addAll
argument_list|(
name|memStoreScanners
argument_list|)
expr_stmt|;
return|return
name|scanners
return|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|addChangedReaderObserver
parameter_list|(
name|ChangedReadersObserver
name|o
parameter_list|)
block|{
name|this
operator|.
name|changedReaderObservers
operator|.
name|add
argument_list|(
name|o
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|deleteChangedReaderObserver
parameter_list|(
name|ChangedReadersObserver
name|o
parameter_list|)
block|{
comment|// We don't check if observer present; it may not be (legitimately)
name|this
operator|.
name|changedReaderObservers
operator|.
name|remove
argument_list|(
name|o
argument_list|)
expr_stmt|;
block|}
comment|//////////////////////////////////////////////////////////////////////////////
comment|// Compaction
comment|//////////////////////////////////////////////////////////////////////////////
comment|/**    * Compact the StoreFiles.  This method may take some time, so the calling    * thread must be able to block for long periods.    *    *<p>During this time, the Store can work as usual, getting values from    * StoreFiles and writing new StoreFiles from the memstore.    *    * Existing StoreFiles are not destroyed until the new compacted StoreFile is    * completely written-out to disk.    *    *<p>The compactLock prevents multiple simultaneous compactions.    * The structureLock prevents us from interfering with other write operations.    *    *<p>We don't want to hold the structureLock for the whole time, as a compact()    * can be lengthy and we want to allow cache-flushes during this period.    *    *<p> Compaction event should be idempotent, since there is no IO Fencing for    * the region directory in hdfs. A region server might still try to complete the    * compaction after it lost the region. That is why the following events are carefully    * ordered for a compaction:    *  1. Compaction writes new files under region/.tmp directory (compaction output)    *  2. Compaction atomically moves the temporary file under region directory    *  3. Compaction appends a WAL edit containing the compaction input and output files.    *  Forces sync on WAL.    *  4. Compaction deletes the input files from the region directory.    *    * Failure conditions are handled like this:    *  - If RS fails before 2, compaction wont complete. Even if RS lives on and finishes    *  the compaction later, it will only write the new data file to the region directory.    *  Since we already have this data, this will be idempotent but we will have a redundant    *  copy of the data.    *  - If RS fails between 2 and 3, the region will have a redundant copy of the data. The    *  RS that failed won't be able to finish snyc() for WAL because of lease recovery in WAL.    *  - If RS fails after 3, the region region server who opens the region will pick up the    *  the compaction marker from the WAL and replay it by removing the compaction input files.    *  Failed RS can also attempt to delete those files, but the operation will be idempotent    *    * See HBASE-2231 for details.    *    * @param compaction compaction details obtained from requestCompaction()    * @throws IOException    * @return Storefile we compacted into or null if we failed or opted out early.    */
annotation|@
name|Override
specifier|public
name|List
argument_list|<
name|StoreFile
argument_list|>
name|compact
parameter_list|(
name|CompactionContext
name|compaction
parameter_list|)
throws|throws
name|IOException
block|{
assert|assert
name|compaction
operator|!=
literal|null
operator|&&
name|compaction
operator|.
name|hasSelection
argument_list|()
assert|;
name|CompactionRequest
name|cr
init|=
name|compaction
operator|.
name|getRequest
argument_list|()
decl_stmt|;
name|Collection
argument_list|<
name|StoreFile
argument_list|>
name|filesToCompact
init|=
name|cr
operator|.
name|getFiles
argument_list|()
decl_stmt|;
assert|assert
operator|!
name|filesToCompact
operator|.
name|isEmpty
argument_list|()
assert|;
synchronized|synchronized
init|(
name|filesCompacting
init|)
block|{
comment|// sanity check: we're compacting files that this store knows about
comment|// TODO: change this to LOG.error() after more debugging
name|Preconditions
operator|.
name|checkArgument
argument_list|(
name|filesCompacting
operator|.
name|containsAll
argument_list|(
name|filesToCompact
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|// Ready to go. Have list of files to compact.
name|LOG
operator|.
name|info
argument_list|(
literal|"Starting compaction of "
operator|+
name|filesToCompact
operator|.
name|size
argument_list|()
operator|+
literal|" file(s) in "
operator|+
name|this
operator|+
literal|" of "
operator|+
name|this
operator|.
name|getRegionInfo
argument_list|()
operator|.
name|getRegionNameAsString
argument_list|()
operator|+
literal|" into tmpdir="
operator|+
name|fs
operator|.
name|getTempDir
argument_list|()
operator|+
literal|", totalSize="
operator|+
name|StringUtils
operator|.
name|humanReadableInt
argument_list|(
name|cr
operator|.
name|getSize
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
name|long
name|compactionStartTime
init|=
name|EnvironmentEdgeManager
operator|.
name|currentTime
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|StoreFile
argument_list|>
name|sfs
init|=
literal|null
decl_stmt|;
try|try
block|{
comment|// Commence the compaction.
name|List
argument_list|<
name|Path
argument_list|>
name|newFiles
init|=
name|compaction
operator|.
name|compact
argument_list|()
decl_stmt|;
comment|// TODO: get rid of this!
if|if
condition|(
operator|!
name|this
operator|.
name|conf
operator|.
name|getBoolean
argument_list|(
literal|"hbase.hstore.compaction.complete"
argument_list|,
literal|true
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"hbase.hstore.compaction.complete is set to false"
argument_list|)
expr_stmt|;
name|sfs
operator|=
operator|new
name|ArrayList
argument_list|<
name|StoreFile
argument_list|>
argument_list|(
name|newFiles
operator|.
name|size
argument_list|()
argument_list|)
expr_stmt|;
for|for
control|(
name|Path
name|newFile
range|:
name|newFiles
control|)
block|{
comment|// Create storefile around what we wrote with a reader on it.
name|StoreFile
name|sf
init|=
name|createStoreFileAndReader
argument_list|(
name|newFile
argument_list|)
decl_stmt|;
name|sf
operator|.
name|closeReader
argument_list|(
literal|true
argument_list|)
expr_stmt|;
name|sfs
operator|.
name|add
argument_list|(
name|sf
argument_list|)
expr_stmt|;
block|}
return|return
name|sfs
return|;
block|}
comment|// Do the steps necessary to complete the compaction.
name|sfs
operator|=
name|moveCompatedFilesIntoPlace
argument_list|(
name|cr
argument_list|,
name|newFiles
argument_list|)
expr_stmt|;
name|writeCompactionWalRecord
argument_list|(
name|filesToCompact
argument_list|,
name|sfs
argument_list|)
expr_stmt|;
name|replaceStoreFiles
argument_list|(
name|filesToCompact
argument_list|,
name|sfs
argument_list|)
expr_stmt|;
if|if
condition|(
name|cr
operator|.
name|isMajor
argument_list|()
condition|)
block|{
name|majorCompactedCellsCount
operator|+=
name|getCompactionProgress
argument_list|()
operator|.
name|totalCompactingKVs
expr_stmt|;
name|majorCompactedCellsSize
operator|+=
name|getCompactionProgress
argument_list|()
operator|.
name|totalCompactedSize
expr_stmt|;
block|}
else|else
block|{
name|compactedCellsCount
operator|+=
name|getCompactionProgress
argument_list|()
operator|.
name|totalCompactingKVs
expr_stmt|;
name|compactedCellsSize
operator|+=
name|getCompactionProgress
argument_list|()
operator|.
name|totalCompactedSize
expr_stmt|;
block|}
comment|// At this point the store will use new files for all new scanners.
name|completeCompaction
argument_list|(
name|filesToCompact
argument_list|,
literal|true
argument_list|)
expr_stmt|;
comment|// Archive old files& update store size.
block|}
finally|finally
block|{
name|finishCompactionRequest
argument_list|(
name|cr
argument_list|)
expr_stmt|;
block|}
name|logCompactionEndMessage
argument_list|(
name|cr
argument_list|,
name|sfs
argument_list|,
name|compactionStartTime
argument_list|)
expr_stmt|;
return|return
name|sfs
return|;
block|}
specifier|private
name|List
argument_list|<
name|StoreFile
argument_list|>
name|moveCompatedFilesIntoPlace
parameter_list|(
name|CompactionRequest
name|cr
parameter_list|,
name|List
argument_list|<
name|Path
argument_list|>
name|newFiles
parameter_list|)
throws|throws
name|IOException
block|{
name|List
argument_list|<
name|StoreFile
argument_list|>
name|sfs
init|=
operator|new
name|ArrayList
argument_list|<
name|StoreFile
argument_list|>
argument_list|(
name|newFiles
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
for|for
control|(
name|Path
name|newFile
range|:
name|newFiles
control|)
block|{
assert|assert
name|newFile
operator|!=
literal|null
assert|;
name|StoreFile
name|sf
init|=
name|moveFileIntoPlace
argument_list|(
name|newFile
argument_list|)
decl_stmt|;
if|if
condition|(
name|this
operator|.
name|getCoprocessorHost
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|this
operator|.
name|getCoprocessorHost
argument_list|()
operator|.
name|postCompact
argument_list|(
name|this
argument_list|,
name|sf
argument_list|,
name|cr
argument_list|)
expr_stmt|;
block|}
assert|assert
name|sf
operator|!=
literal|null
assert|;
name|sfs
operator|.
name|add
argument_list|(
name|sf
argument_list|)
expr_stmt|;
block|}
return|return
name|sfs
return|;
block|}
comment|// Package-visible for tests
name|StoreFile
name|moveFileIntoPlace
parameter_list|(
specifier|final
name|Path
name|newFile
parameter_list|)
throws|throws
name|IOException
block|{
name|validateStoreFile
argument_list|(
name|newFile
argument_list|)
expr_stmt|;
comment|// Move the file into the right spot
name|Path
name|destPath
init|=
name|fs
operator|.
name|commitStoreFile
argument_list|(
name|getColumnFamilyName
argument_list|()
argument_list|,
name|newFile
argument_list|)
decl_stmt|;
return|return
name|createStoreFileAndReader
argument_list|(
name|destPath
argument_list|)
return|;
block|}
comment|/**    * Writes the compaction WAL record.    * @param filesCompacted Files compacted (input).    * @param newFiles Files from compaction.    */
specifier|private
name|void
name|writeCompactionWalRecord
parameter_list|(
name|Collection
argument_list|<
name|StoreFile
argument_list|>
name|filesCompacted
parameter_list|,
name|Collection
argument_list|<
name|StoreFile
argument_list|>
name|newFiles
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|region
operator|.
name|getLog
argument_list|()
operator|==
literal|null
condition|)
return|return;
name|List
argument_list|<
name|Path
argument_list|>
name|inputPaths
init|=
operator|new
name|ArrayList
argument_list|<
name|Path
argument_list|>
argument_list|(
name|filesCompacted
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
for|for
control|(
name|StoreFile
name|f
range|:
name|filesCompacted
control|)
block|{
name|inputPaths
operator|.
name|add
argument_list|(
name|f
operator|.
name|getPath
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|List
argument_list|<
name|Path
argument_list|>
name|outputPaths
init|=
operator|new
name|ArrayList
argument_list|<
name|Path
argument_list|>
argument_list|(
name|newFiles
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
for|for
control|(
name|StoreFile
name|f
range|:
name|newFiles
control|)
block|{
name|outputPaths
operator|.
name|add
argument_list|(
name|f
operator|.
name|getPath
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|HRegionInfo
name|info
init|=
name|this
operator|.
name|region
operator|.
name|getRegionInfo
argument_list|()
decl_stmt|;
name|CompactionDescriptor
name|compactionDescriptor
init|=
name|ProtobufUtil
operator|.
name|toCompactionDescriptor
argument_list|(
name|info
argument_list|,
name|family
operator|.
name|getName
argument_list|()
argument_list|,
name|inputPaths
argument_list|,
name|outputPaths
argument_list|,
name|fs
operator|.
name|getStoreDir
argument_list|(
name|getFamily
argument_list|()
operator|.
name|getNameAsString
argument_list|()
argument_list|)
argument_list|)
decl_stmt|;
name|HLogUtil
operator|.
name|writeCompactionMarker
argument_list|(
name|region
operator|.
name|getLog
argument_list|()
argument_list|,
name|this
operator|.
name|region
operator|.
name|getTableDesc
argument_list|()
argument_list|,
name|this
operator|.
name|region
operator|.
name|getRegionInfo
argument_list|()
argument_list|,
name|compactionDescriptor
argument_list|,
name|this
operator|.
name|region
operator|.
name|getSequenceId
argument_list|()
argument_list|)
expr_stmt|;
block|}
annotation|@
name|VisibleForTesting
name|void
name|replaceStoreFiles
parameter_list|(
specifier|final
name|Collection
argument_list|<
name|StoreFile
argument_list|>
name|compactedFiles
parameter_list|,
specifier|final
name|Collection
argument_list|<
name|StoreFile
argument_list|>
name|result
parameter_list|)
throws|throws
name|IOException
block|{
name|this
operator|.
name|lock
operator|.
name|writeLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
name|this
operator|.
name|storeEngine
operator|.
name|getStoreFileManager
argument_list|()
operator|.
name|addCompactionResults
argument_list|(
name|compactedFiles
argument_list|,
name|result
argument_list|)
expr_stmt|;
name|filesCompacting
operator|.
name|removeAll
argument_list|(
name|compactedFiles
argument_list|)
expr_stmt|;
comment|// safe bc: lock.writeLock();
block|}
finally|finally
block|{
name|this
operator|.
name|lock
operator|.
name|writeLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**    * Log a very elaborate compaction completion message.    * @param cr Request.    * @param sfs Resulting files.    * @param compactionStartTime Start time.    */
specifier|private
name|void
name|logCompactionEndMessage
parameter_list|(
name|CompactionRequest
name|cr
parameter_list|,
name|List
argument_list|<
name|StoreFile
argument_list|>
name|sfs
parameter_list|,
name|long
name|compactionStartTime
parameter_list|)
block|{
name|long
name|now
init|=
name|EnvironmentEdgeManager
operator|.
name|currentTime
argument_list|()
decl_stmt|;
name|StringBuilder
name|message
init|=
operator|new
name|StringBuilder
argument_list|(
literal|"Completed"
operator|+
operator|(
name|cr
operator|.
name|isMajor
argument_list|()
condition|?
literal|" major"
else|:
literal|""
operator|)
operator|+
literal|" compaction of "
operator|+
name|cr
operator|.
name|getFiles
argument_list|()
operator|.
name|size
argument_list|()
operator|+
operator|(
name|cr
operator|.
name|isAllFiles
argument_list|()
condition|?
literal|" (all)"
else|:
literal|""
operator|)
operator|+
literal|" file(s) in "
operator|+
name|this
operator|+
literal|" of "
operator|+
name|this
operator|.
name|getRegionInfo
argument_list|()
operator|.
name|getRegionNameAsString
argument_list|()
operator|+
literal|" into "
argument_list|)
decl_stmt|;
if|if
condition|(
name|sfs
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
name|message
operator|.
name|append
argument_list|(
literal|"none, "
argument_list|)
expr_stmt|;
block|}
else|else
block|{
for|for
control|(
name|StoreFile
name|sf
range|:
name|sfs
control|)
block|{
name|message
operator|.
name|append
argument_list|(
name|sf
operator|.
name|getPath
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
name|message
operator|.
name|append
argument_list|(
literal|"(size="
argument_list|)
expr_stmt|;
name|message
operator|.
name|append
argument_list|(
name|StringUtils
operator|.
name|humanReadableInt
argument_list|(
name|sf
operator|.
name|getReader
argument_list|()
operator|.
name|length
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
name|message
operator|.
name|append
argument_list|(
literal|"), "
argument_list|)
expr_stmt|;
block|}
block|}
name|message
operator|.
name|append
argument_list|(
literal|"total size for store is "
argument_list|)
operator|.
name|append
argument_list|(
name|StringUtils
operator|.
name|humanReadableInt
argument_list|(
name|storeSize
argument_list|)
argument_list|)
operator|.
name|append
argument_list|(
literal|". This selection was in queue for "
argument_list|)
operator|.
name|append
argument_list|(
name|StringUtils
operator|.
name|formatTimeDiff
argument_list|(
name|compactionStartTime
argument_list|,
name|cr
operator|.
name|getSelectionTime
argument_list|()
argument_list|)
argument_list|)
operator|.
name|append
argument_list|(
literal|", and took "
argument_list|)
operator|.
name|append
argument_list|(
name|StringUtils
operator|.
name|formatTimeDiff
argument_list|(
name|now
argument_list|,
name|compactionStartTime
argument_list|)
argument_list|)
operator|.
name|append
argument_list|(
literal|" to execute."
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
name|message
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|int
name|fileCount
init|=
name|storeEngine
operator|.
name|getStoreFileManager
argument_list|()
operator|.
name|getStorefileCount
argument_list|()
decl_stmt|;
name|long
name|resultSize
init|=
literal|0
decl_stmt|;
for|for
control|(
name|StoreFile
name|sf
range|:
name|sfs
control|)
block|{
name|resultSize
operator|+=
name|sf
operator|.
name|getReader
argument_list|()
operator|.
name|length
argument_list|()
expr_stmt|;
block|}
name|String
name|traceMessage
init|=
literal|"COMPACTION start,end,size out,files in,files out,store size,"
operator|+
literal|"store files ["
operator|+
name|compactionStartTime
operator|+
literal|","
operator|+
name|now
operator|+
literal|","
operator|+
name|resultSize
operator|+
literal|","
operator|+
name|cr
operator|.
name|getFiles
argument_list|()
operator|.
name|size
argument_list|()
operator|+
literal|","
operator|+
name|sfs
operator|.
name|size
argument_list|()
operator|+
literal|","
operator|+
name|storeSize
operator|+
literal|","
operator|+
name|fileCount
operator|+
literal|"]"
decl_stmt|;
name|LOG
operator|.
name|trace
argument_list|(
name|traceMessage
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Call to complete a compaction. Its for the case where we find in the WAL a compaction    * that was not finished.  We could find one recovering a WAL after a regionserver crash.    * See HBASE-2231.    * @param compaction    */
annotation|@
name|Override
specifier|public
name|void
name|completeCompactionMarker
parameter_list|(
name|CompactionDescriptor
name|compaction
parameter_list|)
throws|throws
name|IOException
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Completing compaction from the WAL marker"
argument_list|)
expr_stmt|;
name|List
argument_list|<
name|String
argument_list|>
name|compactionInputs
init|=
name|compaction
operator|.
name|getCompactionInputList
argument_list|()
decl_stmt|;
comment|// The Compaction Marker is written after the compaction is completed,
comment|// and the files moved into the region/family folder.
comment|//
comment|// If we crash after the entry is written, we may not have removed the
comment|// input files, but the output file is present.
comment|// (The unremoved input files will be removed by this function)
comment|//
comment|// If we scan the directory and the file is not present, it can mean that:
comment|//   - The file was manually removed by the user
comment|//   - The file was removed as consequence of subsequent compaction
comment|// so, we can't do anything with the "compaction output list" because those
comment|// files have already been loaded when opening the region (by virtue of
comment|// being in the store's folder) or they may be missing due to a compaction.
name|String
name|familyName
init|=
name|this
operator|.
name|getColumnFamilyName
argument_list|()
decl_stmt|;
name|List
argument_list|<
name|Path
argument_list|>
name|inputPaths
init|=
operator|new
name|ArrayList
argument_list|<
name|Path
argument_list|>
argument_list|(
name|compactionInputs
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
for|for
control|(
name|String
name|compactionInput
range|:
name|compactionInputs
control|)
block|{
name|Path
name|inputPath
init|=
name|fs
operator|.
name|getStoreFilePath
argument_list|(
name|familyName
argument_list|,
name|compactionInput
argument_list|)
decl_stmt|;
name|inputPaths
operator|.
name|add
argument_list|(
name|inputPath
argument_list|)
expr_stmt|;
block|}
comment|//some of the input files might already be deleted
name|List
argument_list|<
name|StoreFile
argument_list|>
name|inputStoreFiles
init|=
operator|new
name|ArrayList
argument_list|<
name|StoreFile
argument_list|>
argument_list|(
name|compactionInputs
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
for|for
control|(
name|StoreFile
name|sf
range|:
name|this
operator|.
name|getStorefiles
argument_list|()
control|)
block|{
if|if
condition|(
name|inputPaths
operator|.
name|contains
argument_list|(
name|sf
operator|.
name|getQualifiedPath
argument_list|()
argument_list|)
condition|)
block|{
name|inputStoreFiles
operator|.
name|add
argument_list|(
name|sf
argument_list|)
expr_stmt|;
block|}
block|}
name|this
operator|.
name|replaceStoreFiles
argument_list|(
name|inputStoreFiles
argument_list|,
name|Collections
operator|.
name|EMPTY_LIST
argument_list|)
expr_stmt|;
name|this
operator|.
name|completeCompaction
argument_list|(
name|inputStoreFiles
argument_list|)
expr_stmt|;
block|}
comment|/**    * This method tries to compact N recent files for testing.    * Note that because compacting "recent" files only makes sense for some policies,    * e.g. the default one, it assumes default policy is used. It doesn't use policy,    * but instead makes a compaction candidate list by itself.    * @param N Number of files.    */
specifier|public
name|void
name|compactRecentForTestingAssumingDefaultPolicy
parameter_list|(
name|int
name|N
parameter_list|)
throws|throws
name|IOException
block|{
name|List
argument_list|<
name|StoreFile
argument_list|>
name|filesToCompact
decl_stmt|;
name|boolean
name|isMajor
decl_stmt|;
name|this
operator|.
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
synchronized|synchronized
init|(
name|filesCompacting
init|)
block|{
name|filesToCompact
operator|=
name|Lists
operator|.
name|newArrayList
argument_list|(
name|storeEngine
operator|.
name|getStoreFileManager
argument_list|()
operator|.
name|getStorefiles
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|filesCompacting
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
comment|// exclude all files older than the newest file we're currently
comment|// compacting. this allows us to preserve contiguity (HBASE-2856)
name|StoreFile
name|last
init|=
name|filesCompacting
operator|.
name|get
argument_list|(
name|filesCompacting
operator|.
name|size
argument_list|()
operator|-
literal|1
argument_list|)
decl_stmt|;
name|int
name|idx
init|=
name|filesToCompact
operator|.
name|indexOf
argument_list|(
name|last
argument_list|)
decl_stmt|;
name|Preconditions
operator|.
name|checkArgument
argument_list|(
name|idx
operator|!=
operator|-
literal|1
argument_list|)
expr_stmt|;
name|filesToCompact
operator|.
name|subList
argument_list|(
literal|0
argument_list|,
name|idx
operator|+
literal|1
argument_list|)
operator|.
name|clear
argument_list|()
expr_stmt|;
block|}
name|int
name|count
init|=
name|filesToCompact
operator|.
name|size
argument_list|()
decl_stmt|;
if|if
condition|(
name|N
operator|>
name|count
condition|)
block|{
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"Not enough files"
argument_list|)
throw|;
block|}
name|filesToCompact
operator|=
name|filesToCompact
operator|.
name|subList
argument_list|(
name|count
operator|-
name|N
argument_list|,
name|count
argument_list|)
expr_stmt|;
name|isMajor
operator|=
operator|(
name|filesToCompact
operator|.
name|size
argument_list|()
operator|==
name|storeEngine
operator|.
name|getStoreFileManager
argument_list|()
operator|.
name|getStorefileCount
argument_list|()
operator|)
expr_stmt|;
name|filesCompacting
operator|.
name|addAll
argument_list|(
name|filesToCompact
argument_list|)
expr_stmt|;
name|Collections
operator|.
name|sort
argument_list|(
name|filesCompacting
argument_list|,
name|StoreFile
operator|.
name|Comparators
operator|.
name|SEQ_ID
argument_list|)
expr_stmt|;
block|}
block|}
finally|finally
block|{
name|this
operator|.
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
try|try
block|{
comment|// Ready to go. Have list of files to compact.
name|List
argument_list|<
name|Path
argument_list|>
name|newFiles
init|=
operator|(
operator|(
name|DefaultCompactor
operator|)
name|this
operator|.
name|storeEngine
operator|.
name|getCompactor
argument_list|()
operator|)
operator|.
name|compactForTesting
argument_list|(
name|filesToCompact
argument_list|,
name|isMajor
argument_list|)
decl_stmt|;
for|for
control|(
name|Path
name|newFile
range|:
name|newFiles
control|)
block|{
comment|// Move the compaction into place.
name|StoreFile
name|sf
init|=
name|moveFileIntoPlace
argument_list|(
name|newFile
argument_list|)
decl_stmt|;
if|if
condition|(
name|this
operator|.
name|getCoprocessorHost
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|this
operator|.
name|getCoprocessorHost
argument_list|()
operator|.
name|postCompact
argument_list|(
name|this
argument_list|,
name|sf
argument_list|,
literal|null
argument_list|)
expr_stmt|;
block|}
name|replaceStoreFiles
argument_list|(
name|filesToCompact
argument_list|,
name|Lists
operator|.
name|newArrayList
argument_list|(
name|sf
argument_list|)
argument_list|)
expr_stmt|;
name|completeCompaction
argument_list|(
name|filesToCompact
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
block|}
finally|finally
block|{
synchronized|synchronized
init|(
name|filesCompacting
init|)
block|{
name|filesCompacting
operator|.
name|removeAll
argument_list|(
name|filesToCompact
argument_list|)
expr_stmt|;
block|}
block|}
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|hasReferences
parameter_list|()
block|{
return|return
name|StoreUtils
operator|.
name|hasReferences
argument_list|(
name|this
operator|.
name|storeEngine
operator|.
name|getStoreFileManager
argument_list|()
operator|.
name|getStorefiles
argument_list|()
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|CompactionProgress
name|getCompactionProgress
parameter_list|()
block|{
return|return
name|this
operator|.
name|storeEngine
operator|.
name|getCompactor
argument_list|()
operator|.
name|getProgress
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|isMajorCompaction
parameter_list|()
throws|throws
name|IOException
block|{
for|for
control|(
name|StoreFile
name|sf
range|:
name|this
operator|.
name|storeEngine
operator|.
name|getStoreFileManager
argument_list|()
operator|.
name|getStorefiles
argument_list|()
control|)
block|{
comment|// TODO: what are these reader checks all over the place?
if|if
condition|(
name|sf
operator|.
name|getReader
argument_list|()
operator|==
literal|null
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"StoreFile "
operator|+
name|sf
operator|+
literal|" has null Reader"
argument_list|)
expr_stmt|;
return|return
literal|false
return|;
block|}
block|}
return|return
name|storeEngine
operator|.
name|getCompactionPolicy
argument_list|()
operator|.
name|isMajorCompaction
argument_list|(
name|this
operator|.
name|storeEngine
operator|.
name|getStoreFileManager
argument_list|()
operator|.
name|getStorefiles
argument_list|()
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|CompactionContext
name|requestCompaction
parameter_list|()
throws|throws
name|IOException
block|{
return|return
name|requestCompaction
argument_list|(
name|Store
operator|.
name|NO_PRIORITY
argument_list|,
literal|null
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|CompactionContext
name|requestCompaction
parameter_list|(
name|int
name|priority
parameter_list|,
name|CompactionRequest
name|baseRequest
parameter_list|)
throws|throws
name|IOException
block|{
comment|// don't even select for compaction if writes are disabled
if|if
condition|(
operator|!
name|this
operator|.
name|areWritesEnabled
argument_list|()
condition|)
block|{
return|return
literal|null
return|;
block|}
comment|// Before we do compaction, try to get rid of unneeded files to simplify things.
name|removeUnneededFiles
argument_list|()
expr_stmt|;
name|CompactionContext
name|compaction
init|=
name|storeEngine
operator|.
name|createCompaction
argument_list|()
decl_stmt|;
name|CompactionRequest
name|request
init|=
literal|null
decl_stmt|;
name|this
operator|.
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
synchronized|synchronized
init|(
name|filesCompacting
init|)
block|{
comment|// First, see if coprocessor would want to override selection.
if|if
condition|(
name|this
operator|.
name|getCoprocessorHost
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|List
argument_list|<
name|StoreFile
argument_list|>
name|candidatesForCoproc
init|=
name|compaction
operator|.
name|preSelect
argument_list|(
name|this
operator|.
name|filesCompacting
argument_list|)
decl_stmt|;
name|boolean
name|override
init|=
name|this
operator|.
name|getCoprocessorHost
argument_list|()
operator|.
name|preCompactSelection
argument_list|(
name|this
argument_list|,
name|candidatesForCoproc
argument_list|,
name|baseRequest
argument_list|)
decl_stmt|;
if|if
condition|(
name|override
condition|)
block|{
comment|// Coprocessor is overriding normal file selection.
name|compaction
operator|.
name|forceSelect
argument_list|(
operator|new
name|CompactionRequest
argument_list|(
name|candidatesForCoproc
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
comment|// Normal case - coprocessor is not overriding file selection.
if|if
condition|(
operator|!
name|compaction
operator|.
name|hasSelection
argument_list|()
condition|)
block|{
name|boolean
name|isUserCompaction
init|=
name|priority
operator|==
name|Store
operator|.
name|PRIORITY_USER
decl_stmt|;
name|boolean
name|mayUseOffPeak
init|=
name|offPeakHours
operator|.
name|isOffPeakHour
argument_list|()
operator|&&
name|offPeakCompactionTracker
operator|.
name|compareAndSet
argument_list|(
literal|false
argument_list|,
literal|true
argument_list|)
decl_stmt|;
try|try
block|{
name|compaction
operator|.
name|select
argument_list|(
name|this
operator|.
name|filesCompacting
argument_list|,
name|isUserCompaction
argument_list|,
name|mayUseOffPeak
argument_list|,
name|forceMajor
operator|&&
name|filesCompacting
operator|.
name|isEmpty
argument_list|()
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
if|if
condition|(
name|mayUseOffPeak
condition|)
block|{
name|offPeakCompactionTracker
operator|.
name|set
argument_list|(
literal|false
argument_list|)
expr_stmt|;
block|}
throw|throw
name|e
throw|;
block|}
assert|assert
name|compaction
operator|.
name|hasSelection
argument_list|()
assert|;
if|if
condition|(
name|mayUseOffPeak
operator|&&
operator|!
name|compaction
operator|.
name|getRequest
argument_list|()
operator|.
name|isOffPeak
argument_list|()
condition|)
block|{
comment|// Compaction policy doesn't want to take advantage of off-peak.
name|offPeakCompactionTracker
operator|.
name|set
argument_list|(
literal|false
argument_list|)
expr_stmt|;
block|}
block|}
if|if
condition|(
name|this
operator|.
name|getCoprocessorHost
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|this
operator|.
name|getCoprocessorHost
argument_list|()
operator|.
name|postCompactSelection
argument_list|(
name|this
argument_list|,
name|ImmutableList
operator|.
name|copyOf
argument_list|(
name|compaction
operator|.
name|getRequest
argument_list|()
operator|.
name|getFiles
argument_list|()
argument_list|)
argument_list|,
name|baseRequest
argument_list|)
expr_stmt|;
block|}
comment|// Selected files; see if we have a compaction with some custom base request.
if|if
condition|(
name|baseRequest
operator|!=
literal|null
condition|)
block|{
comment|// Update the request with what the system thinks the request should be;
comment|// its up to the request if it wants to listen.
name|compaction
operator|.
name|forceSelect
argument_list|(
name|baseRequest
operator|.
name|combineWith
argument_list|(
name|compaction
operator|.
name|getRequest
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|// Finally, we have the resulting files list. Check if we have any files at all.
name|request
operator|=
name|compaction
operator|.
name|getRequest
argument_list|()
expr_stmt|;
specifier|final
name|Collection
argument_list|<
name|StoreFile
argument_list|>
name|selectedFiles
init|=
name|request
operator|.
name|getFiles
argument_list|()
decl_stmt|;
if|if
condition|(
name|selectedFiles
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
return|return
literal|null
return|;
block|}
name|addToCompactingFiles
argument_list|(
name|selectedFiles
argument_list|)
expr_stmt|;
comment|// If we're enqueuing a major, clear the force flag.
name|this
operator|.
name|forceMajor
operator|=
name|this
operator|.
name|forceMajor
operator|&&
operator|!
name|request
operator|.
name|isMajor
argument_list|()
expr_stmt|;
comment|// Set common request properties.
comment|// Set priority, either override value supplied by caller or from store.
name|request
operator|.
name|setPriority
argument_list|(
operator|(
name|priority
operator|!=
name|Store
operator|.
name|NO_PRIORITY
operator|)
condition|?
name|priority
else|:
name|getCompactPriority
argument_list|()
argument_list|)
expr_stmt|;
name|request
operator|.
name|setDescription
argument_list|(
name|getRegionInfo
argument_list|()
operator|.
name|getRegionNameAsString
argument_list|()
argument_list|,
name|getColumnFamilyName
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
finally|finally
block|{
name|this
operator|.
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
name|LOG
operator|.
name|debug
argument_list|(
name|getRegionInfo
argument_list|()
operator|.
name|getEncodedName
argument_list|()
operator|+
literal|" - "
operator|+
name|getColumnFamilyName
argument_list|()
operator|+
literal|": Initiating "
operator|+
operator|(
name|request
operator|.
name|isMajor
argument_list|()
condition|?
literal|"major"
else|:
literal|"minor"
operator|)
operator|+
literal|" compaction"
operator|+
operator|(
name|request
operator|.
name|isAllFiles
argument_list|()
condition|?
literal|" (all files)"
else|:
literal|""
operator|)
argument_list|)
expr_stmt|;
name|this
operator|.
name|region
operator|.
name|reportCompactionRequestStart
argument_list|(
name|request
operator|.
name|isMajor
argument_list|()
argument_list|)
expr_stmt|;
return|return
name|compaction
return|;
block|}
comment|/** Adds the files to compacting files. filesCompacting must be locked. */
specifier|private
name|void
name|addToCompactingFiles
parameter_list|(
specifier|final
name|Collection
argument_list|<
name|StoreFile
argument_list|>
name|filesToAdd
parameter_list|)
block|{
if|if
condition|(
name|filesToAdd
operator|==
literal|null
condition|)
return|return;
comment|// Check that we do not try to compact the same StoreFile twice.
if|if
condition|(
operator|!
name|Collections
operator|.
name|disjoint
argument_list|(
name|filesCompacting
argument_list|,
name|filesToAdd
argument_list|)
condition|)
block|{
name|Preconditions
operator|.
name|checkArgument
argument_list|(
literal|false
argument_list|,
literal|"%s overlaps with %s"
argument_list|,
name|filesToAdd
argument_list|,
name|filesCompacting
argument_list|)
expr_stmt|;
block|}
name|filesCompacting
operator|.
name|addAll
argument_list|(
name|filesToAdd
argument_list|)
expr_stmt|;
name|Collections
operator|.
name|sort
argument_list|(
name|filesCompacting
argument_list|,
name|StoreFile
operator|.
name|Comparators
operator|.
name|SEQ_ID
argument_list|)
expr_stmt|;
block|}
specifier|private
name|void
name|removeUnneededFiles
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
operator|!
name|conf
operator|.
name|getBoolean
argument_list|(
literal|"hbase.store.delete.expired.storefile"
argument_list|,
literal|true
argument_list|)
condition|)
return|return;
name|this
operator|.
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
name|Collection
argument_list|<
name|StoreFile
argument_list|>
name|delSfs
init|=
literal|null
decl_stmt|;
try|try
block|{
synchronized|synchronized
init|(
name|filesCompacting
init|)
block|{
name|long
name|cfTtl
init|=
name|getStoreFileTtl
argument_list|()
decl_stmt|;
if|if
condition|(
name|cfTtl
operator|!=
name|Long
operator|.
name|MAX_VALUE
condition|)
block|{
name|delSfs
operator|=
name|storeEngine
operator|.
name|getStoreFileManager
argument_list|()
operator|.
name|getUnneededFiles
argument_list|(
name|EnvironmentEdgeManager
operator|.
name|currentTime
argument_list|()
operator|-
name|cfTtl
argument_list|,
name|filesCompacting
argument_list|)
expr_stmt|;
name|addToCompactingFiles
argument_list|(
name|delSfs
argument_list|)
expr_stmt|;
block|}
block|}
block|}
finally|finally
block|{
name|this
operator|.
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
name|delSfs
operator|==
literal|null
operator|||
name|delSfs
operator|.
name|isEmpty
argument_list|()
condition|)
return|return;
name|Collection
argument_list|<
name|StoreFile
argument_list|>
name|newFiles
init|=
operator|new
name|ArrayList
argument_list|<
name|StoreFile
argument_list|>
argument_list|()
decl_stmt|;
comment|// No new files.
name|writeCompactionWalRecord
argument_list|(
name|delSfs
argument_list|,
name|newFiles
argument_list|)
expr_stmt|;
name|replaceStoreFiles
argument_list|(
name|delSfs
argument_list|,
name|newFiles
argument_list|)
expr_stmt|;
name|completeCompaction
argument_list|(
name|delSfs
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Completed removal of "
operator|+
name|delSfs
operator|.
name|size
argument_list|()
operator|+
literal|" unnecessary (expired) file(s) in "
operator|+
name|this
operator|+
literal|" of "
operator|+
name|this
operator|.
name|getRegionInfo
argument_list|()
operator|.
name|getRegionNameAsString
argument_list|()
operator|+
literal|"; total size for store is "
operator|+
name|StringUtils
operator|.
name|humanReadableInt
argument_list|(
name|storeSize
argument_list|)
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|cancelRequestedCompaction
parameter_list|(
name|CompactionContext
name|compaction
parameter_list|)
block|{
name|finishCompactionRequest
argument_list|(
name|compaction
operator|.
name|getRequest
argument_list|()
argument_list|)
expr_stmt|;
block|}
specifier|private
name|void
name|finishCompactionRequest
parameter_list|(
name|CompactionRequest
name|cr
parameter_list|)
block|{
name|this
operator|.
name|region
operator|.
name|reportCompactionRequestEnd
argument_list|(
name|cr
operator|.
name|isMajor
argument_list|()
argument_list|,
name|cr
operator|.
name|getFiles
argument_list|()
operator|.
name|size
argument_list|()
argument_list|,
name|cr
operator|.
name|getSize
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|cr
operator|.
name|isOffPeak
argument_list|()
condition|)
block|{
name|offPeakCompactionTracker
operator|.
name|set
argument_list|(
literal|false
argument_list|)
expr_stmt|;
name|cr
operator|.
name|setOffPeak
argument_list|(
literal|false
argument_list|)
expr_stmt|;
block|}
synchronized|synchronized
init|(
name|filesCompacting
init|)
block|{
name|filesCompacting
operator|.
name|removeAll
argument_list|(
name|cr
operator|.
name|getFiles
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**    * Validates a store file by opening and closing it. In HFileV2 this should    * not be an expensive operation.    *    * @param path the path to the store file    */
specifier|private
name|void
name|validateStoreFile
parameter_list|(
name|Path
name|path
parameter_list|)
throws|throws
name|IOException
block|{
name|StoreFile
name|storeFile
init|=
literal|null
decl_stmt|;
try|try
block|{
name|storeFile
operator|=
name|createStoreFileAndReader
argument_list|(
name|path
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Failed to open store file : "
operator|+
name|path
operator|+
literal|", keeping it in tmp location"
argument_list|,
name|e
argument_list|)
expr_stmt|;
throw|throw
name|e
throw|;
block|}
finally|finally
block|{
if|if
condition|(
name|storeFile
operator|!=
literal|null
condition|)
block|{
name|storeFile
operator|.
name|closeReader
argument_list|(
literal|false
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|/**    *<p>It works by processing a compaction that's been written to disk.    *    *<p>It is usually invoked at the end of a compaction, but might also be    * invoked at HStore startup, if the prior execution died midway through.    *    *<p>Moving the compacted TreeMap into place means:    *<pre>    * 1) Unload all replaced StoreFile, close and collect list to delete.    * 2) Compute new store size    *</pre>    *    * @param compactedFiles list of files that were compacted    */
annotation|@
name|VisibleForTesting
specifier|protected
name|void
name|completeCompaction
parameter_list|(
specifier|final
name|Collection
argument_list|<
name|StoreFile
argument_list|>
name|compactedFiles
parameter_list|)
throws|throws
name|IOException
block|{
name|completeCompaction
argument_list|(
name|compactedFiles
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
comment|/**    *<p>It works by processing a compaction that's been written to disk.    *    *<p>It is usually invoked at the end of a compaction, but might also be    * invoked at HStore startup, if the prior execution died midway through.    *    *<p>Moving the compacted TreeMap into place means:    *<pre>    * 1) Unload all replaced StoreFile, close and collect list to delete.    * 2) Compute new store size    *</pre>    *    * @param compactedFiles list of files that were compacted    */
annotation|@
name|VisibleForTesting
specifier|protected
name|void
name|completeCompaction
parameter_list|(
specifier|final
name|Collection
argument_list|<
name|StoreFile
argument_list|>
name|compactedFiles
parameter_list|,
name|boolean
name|removeFiles
parameter_list|)
throws|throws
name|IOException
block|{
try|try
block|{
comment|// Do not delete old store files until we have sent out notification of
comment|// change in case old files are still being accessed by outstanding scanners.
comment|// Don't do this under writeLock; see HBASE-4485 for a possible deadlock
comment|// scenario that could have happened if continue to hold the lock.
name|notifyChangedReadersObservers
argument_list|()
expr_stmt|;
comment|// At this point the store will use new files for all scanners.
comment|// let the archive util decide if we should archive or delete the files
name|LOG
operator|.
name|debug
argument_list|(
literal|"Removing store files after compaction..."
argument_list|)
expr_stmt|;
for|for
control|(
name|StoreFile
name|compactedFile
range|:
name|compactedFiles
control|)
block|{
name|compactedFile
operator|.
name|closeReader
argument_list|(
literal|true
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|removeFiles
condition|)
block|{
name|this
operator|.
name|fs
operator|.
name|removeStoreFiles
argument_list|(
name|this
operator|.
name|getColumnFamilyName
argument_list|()
argument_list|,
name|compactedFiles
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|e
operator|=
name|e
operator|instanceof
name|RemoteException
condition|?
operator|(
operator|(
name|RemoteException
operator|)
name|e
operator|)
operator|.
name|unwrapRemoteException
argument_list|()
else|:
name|e
expr_stmt|;
name|LOG
operator|.
name|error
argument_list|(
literal|"Failed removing compacted files in "
operator|+
name|this
operator|+
literal|". Files we were trying to remove are "
operator|+
name|compactedFiles
operator|.
name|toString
argument_list|()
operator|+
literal|"; some of them may have been already removed"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
comment|// 4. Compute new store size
name|this
operator|.
name|storeSize
operator|=
literal|0L
expr_stmt|;
name|this
operator|.
name|totalUncompressedBytes
operator|=
literal|0L
expr_stmt|;
for|for
control|(
name|StoreFile
name|hsf
range|:
name|this
operator|.
name|storeEngine
operator|.
name|getStoreFileManager
argument_list|()
operator|.
name|getStorefiles
argument_list|()
control|)
block|{
name|StoreFile
operator|.
name|Reader
name|r
init|=
name|hsf
operator|.
name|getReader
argument_list|()
decl_stmt|;
if|if
condition|(
name|r
operator|==
literal|null
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"StoreFile "
operator|+
name|hsf
operator|+
literal|" has a null Reader"
argument_list|)
expr_stmt|;
continue|continue;
block|}
name|this
operator|.
name|storeSize
operator|+=
name|r
operator|.
name|length
argument_list|()
expr_stmt|;
name|this
operator|.
name|totalUncompressedBytes
operator|+=
name|r
operator|.
name|getTotalUncompressedBytes
argument_list|()
expr_stmt|;
block|}
block|}
comment|/*    * @param wantedVersions How many versions were asked for.    * @return wantedVersions or this families' {@link HConstants#VERSIONS}.    */
name|int
name|versionsToReturn
parameter_list|(
specifier|final
name|int
name|wantedVersions
parameter_list|)
block|{
if|if
condition|(
name|wantedVersions
operator|<=
literal|0
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"Number of versions must be> 0"
argument_list|)
throw|;
block|}
comment|// Make sure we do not return more than maximum versions for this store.
name|int
name|maxVersions
init|=
name|this
operator|.
name|family
operator|.
name|getMaxVersions
argument_list|()
decl_stmt|;
return|return
name|wantedVersions
operator|>
name|maxVersions
condition|?
name|maxVersions
else|:
name|wantedVersions
return|;
block|}
specifier|static
name|boolean
name|isExpired
parameter_list|(
specifier|final
name|Cell
name|key
parameter_list|,
specifier|final
name|long
name|oldestTimestamp
parameter_list|)
block|{
return|return
name|key
operator|.
name|getTimestamp
argument_list|()
operator|<
name|oldestTimestamp
return|;
block|}
annotation|@
name|Override
specifier|public
name|KeyValue
name|getRowKeyAtOrBefore
parameter_list|(
specifier|final
name|byte
index|[]
name|row
parameter_list|)
throws|throws
name|IOException
block|{
comment|// If minVersions is set, we will not ignore expired KVs.
comment|// As we're only looking for the latest matches, that should be OK.
comment|// With minVersions> 0 we guarantee that any KV that has any version
comment|// at all (expired or not) has at least one version that will not expire.
comment|// Note that this method used to take a KeyValue as arguments. KeyValue
comment|// can be back-dated, a row key cannot.
name|long
name|ttlToUse
init|=
name|scanInfo
operator|.
name|getMinVersions
argument_list|()
operator|>
literal|0
condition|?
name|Long
operator|.
name|MAX_VALUE
else|:
name|this
operator|.
name|scanInfo
operator|.
name|getTtl
argument_list|()
decl_stmt|;
name|KeyValue
name|kv
init|=
operator|new
name|KeyValue
argument_list|(
name|row
argument_list|,
name|HConstants
operator|.
name|LATEST_TIMESTAMP
argument_list|)
decl_stmt|;
name|GetClosestRowBeforeTracker
name|state
init|=
operator|new
name|GetClosestRowBeforeTracker
argument_list|(
name|this
operator|.
name|comparator
argument_list|,
name|kv
argument_list|,
name|ttlToUse
argument_list|,
name|this
operator|.
name|getRegionInfo
argument_list|()
operator|.
name|isMetaRegion
argument_list|()
argument_list|)
decl_stmt|;
name|this
operator|.
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
comment|// First go to the memstore.  Pick up deletes and candidates.
name|this
operator|.
name|memstore
operator|.
name|getRowKeyAtOrBefore
argument_list|(
name|state
argument_list|)
expr_stmt|;
comment|// Check if match, if we got a candidate on the asked for 'kv' row.
comment|// Process each relevant store file. Run through from newest to oldest.
name|Iterator
argument_list|<
name|StoreFile
argument_list|>
name|sfIterator
init|=
name|this
operator|.
name|storeEngine
operator|.
name|getStoreFileManager
argument_list|()
operator|.
name|getCandidateFilesForRowKeyBefore
argument_list|(
name|state
operator|.
name|getTargetKey
argument_list|()
argument_list|)
decl_stmt|;
while|while
condition|(
name|sfIterator
operator|.
name|hasNext
argument_list|()
condition|)
block|{
name|StoreFile
name|sf
init|=
name|sfIterator
operator|.
name|next
argument_list|()
decl_stmt|;
name|sfIterator
operator|.
name|remove
argument_list|()
expr_stmt|;
comment|// Remove sf from iterator.
name|boolean
name|haveNewCandidate
init|=
name|rowAtOrBeforeFromStoreFile
argument_list|(
name|sf
argument_list|,
name|state
argument_list|)
decl_stmt|;
name|KeyValue
name|keyv
init|=
name|KeyValueUtil
operator|.
name|ensureKeyValue
argument_list|(
name|state
operator|.
name|getCandidate
argument_list|()
argument_list|)
decl_stmt|;
comment|// we have an optimization here which stops the search if we find exact match.
if|if
condition|(
name|keyv
operator|!=
literal|null
operator|&&
name|CellUtil
operator|.
name|matchingRow
argument_list|(
name|keyv
argument_list|,
name|row
argument_list|)
condition|)
block|{
return|return
name|KeyValueUtil
operator|.
name|ensureKeyValue
argument_list|(
name|state
operator|.
name|getCandidate
argument_list|()
argument_list|)
return|;
block|}
if|if
condition|(
name|haveNewCandidate
condition|)
block|{
name|sfIterator
operator|=
name|this
operator|.
name|storeEngine
operator|.
name|getStoreFileManager
argument_list|()
operator|.
name|updateCandidateFilesForRowKeyBefore
argument_list|(
name|sfIterator
argument_list|,
name|state
operator|.
name|getTargetKey
argument_list|()
argument_list|,
name|KeyValueUtil
operator|.
name|ensureKeyValue
argument_list|(
name|state
operator|.
name|getCandidate
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|KeyValueUtil
operator|.
name|ensureKeyValue
argument_list|(
name|state
operator|.
name|getCandidate
argument_list|()
argument_list|)
return|;
block|}
finally|finally
block|{
name|this
operator|.
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
comment|/*    * Check an individual MapFile for the row at or before a given row.    * @param f    * @param state    * @throws IOException    * @return True iff the candidate has been updated in the state.    */
specifier|private
name|boolean
name|rowAtOrBeforeFromStoreFile
parameter_list|(
specifier|final
name|StoreFile
name|f
parameter_list|,
specifier|final
name|GetClosestRowBeforeTracker
name|state
parameter_list|)
throws|throws
name|IOException
block|{
name|StoreFile
operator|.
name|Reader
name|r
init|=
name|f
operator|.
name|getReader
argument_list|()
decl_stmt|;
if|if
condition|(
name|r
operator|==
literal|null
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"StoreFile "
operator|+
name|f
operator|+
literal|" has a null Reader"
argument_list|)
expr_stmt|;
return|return
literal|false
return|;
block|}
if|if
condition|(
name|r
operator|.
name|getEntries
argument_list|()
operator|==
literal|0
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"StoreFile "
operator|+
name|f
operator|+
literal|" is a empty store file"
argument_list|)
expr_stmt|;
return|return
literal|false
return|;
block|}
comment|// TODO: Cache these keys rather than make each time?
name|byte
index|[]
name|fk
init|=
name|r
operator|.
name|getFirstKey
argument_list|()
decl_stmt|;
if|if
condition|(
name|fk
operator|==
literal|null
condition|)
return|return
literal|false
return|;
name|KeyValue
name|firstKV
init|=
name|KeyValue
operator|.
name|createKeyValueFromKey
argument_list|(
name|fk
argument_list|,
literal|0
argument_list|,
name|fk
operator|.
name|length
argument_list|)
decl_stmt|;
name|byte
index|[]
name|lk
init|=
name|r
operator|.
name|getLastKey
argument_list|()
decl_stmt|;
name|KeyValue
name|lastKV
init|=
name|KeyValue
operator|.
name|createKeyValueFromKey
argument_list|(
name|lk
argument_list|,
literal|0
argument_list|,
name|lk
operator|.
name|length
argument_list|)
decl_stmt|;
name|KeyValue
name|firstOnRow
init|=
name|state
operator|.
name|getTargetKey
argument_list|()
decl_stmt|;
if|if
condition|(
name|this
operator|.
name|comparator
operator|.
name|compareRows
argument_list|(
name|lastKV
argument_list|,
name|firstOnRow
argument_list|)
operator|<
literal|0
condition|)
block|{
comment|// If last key in file is not of the target table, no candidates in this
comment|// file.  Return.
if|if
condition|(
operator|!
name|state
operator|.
name|isTargetTable
argument_list|(
name|lastKV
argument_list|)
condition|)
return|return
literal|false
return|;
comment|// If the row we're looking for is past the end of file, set search key to
comment|// last key. TODO: Cache last and first key rather than make each time.
name|firstOnRow
operator|=
operator|new
name|KeyValue
argument_list|(
name|lastKV
operator|.
name|getRow
argument_list|()
argument_list|,
name|HConstants
operator|.
name|LATEST_TIMESTAMP
argument_list|)
expr_stmt|;
block|}
comment|// Get a scanner that caches blocks and that uses pread.
name|HFileScanner
name|scanner
init|=
name|r
operator|.
name|getScanner
argument_list|(
literal|true
argument_list|,
literal|true
argument_list|,
literal|false
argument_list|)
decl_stmt|;
comment|// Seek scanner.  If can't seek it, return.
if|if
condition|(
operator|!
name|seekToScanner
argument_list|(
name|scanner
argument_list|,
name|firstOnRow
argument_list|,
name|firstKV
argument_list|)
condition|)
return|return
literal|false
return|;
comment|// If we found candidate on firstOnRow, just return. THIS WILL NEVER HAPPEN!
comment|// Unlikely that there'll be an instance of actual first row in table.
if|if
condition|(
name|walkForwardInSingleRow
argument_list|(
name|scanner
argument_list|,
name|firstOnRow
argument_list|,
name|state
argument_list|)
condition|)
return|return
literal|true
return|;
comment|// If here, need to start backing up.
while|while
condition|(
name|scanner
operator|.
name|seekBefore
argument_list|(
name|firstOnRow
operator|.
name|getBuffer
argument_list|()
argument_list|,
name|firstOnRow
operator|.
name|getKeyOffset
argument_list|()
argument_list|,
name|firstOnRow
operator|.
name|getKeyLength
argument_list|()
argument_list|)
condition|)
block|{
name|Cell
name|kv
init|=
name|scanner
operator|.
name|getKeyValue
argument_list|()
decl_stmt|;
if|if
condition|(
operator|!
name|state
operator|.
name|isTargetTable
argument_list|(
name|kv
argument_list|)
condition|)
break|break;
if|if
condition|(
operator|!
name|state
operator|.
name|isBetterCandidate
argument_list|(
name|kv
argument_list|)
condition|)
break|break;
comment|// Make new first on row.
name|firstOnRow
operator|=
operator|new
name|KeyValue
argument_list|(
name|kv
operator|.
name|getRow
argument_list|()
argument_list|,
name|HConstants
operator|.
name|LATEST_TIMESTAMP
argument_list|)
expr_stmt|;
comment|// Seek scanner.  If can't seek it, break.
if|if
condition|(
operator|!
name|seekToScanner
argument_list|(
name|scanner
argument_list|,
name|firstOnRow
argument_list|,
name|firstKV
argument_list|)
condition|)
return|return
literal|false
return|;
comment|// If we find something, break;
if|if
condition|(
name|walkForwardInSingleRow
argument_list|(
name|scanner
argument_list|,
name|firstOnRow
argument_list|,
name|state
argument_list|)
condition|)
return|return
literal|true
return|;
block|}
return|return
literal|false
return|;
block|}
comment|/*    * Seek the file scanner to firstOnRow or first entry in file.    * @param scanner    * @param firstOnRow    * @param firstKV    * @return True if we successfully seeked scanner.    * @throws IOException    */
specifier|private
name|boolean
name|seekToScanner
parameter_list|(
specifier|final
name|HFileScanner
name|scanner
parameter_list|,
specifier|final
name|KeyValue
name|firstOnRow
parameter_list|,
specifier|final
name|KeyValue
name|firstKV
parameter_list|)
throws|throws
name|IOException
block|{
name|KeyValue
name|kv
init|=
name|firstOnRow
decl_stmt|;
comment|// If firstOnRow< firstKV, set to firstKV
if|if
condition|(
name|this
operator|.
name|comparator
operator|.
name|compareRows
argument_list|(
name|firstKV
argument_list|,
name|firstOnRow
argument_list|)
operator|==
literal|0
condition|)
name|kv
operator|=
name|firstKV
expr_stmt|;
name|int
name|result
init|=
name|scanner
operator|.
name|seekTo
argument_list|(
name|kv
argument_list|)
decl_stmt|;
return|return
name|result
operator|!=
operator|-
literal|1
return|;
block|}
comment|/*    * When we come in here, we are probably at the kv just before we break into    * the row that firstOnRow is on.  Usually need to increment one time to get    * on to the row we are interested in.    * @param scanner    * @param firstOnRow    * @param state    * @return True we found a candidate.    * @throws IOException    */
specifier|private
name|boolean
name|walkForwardInSingleRow
parameter_list|(
specifier|final
name|HFileScanner
name|scanner
parameter_list|,
specifier|final
name|KeyValue
name|firstOnRow
parameter_list|,
specifier|final
name|GetClosestRowBeforeTracker
name|state
parameter_list|)
throws|throws
name|IOException
block|{
name|boolean
name|foundCandidate
init|=
literal|false
decl_stmt|;
do|do
block|{
name|Cell
name|kv
init|=
name|scanner
operator|.
name|getKeyValue
argument_list|()
decl_stmt|;
comment|// If we are not in the row, skip.
if|if
condition|(
name|this
operator|.
name|comparator
operator|.
name|compareRows
argument_list|(
name|kv
argument_list|,
name|firstOnRow
argument_list|)
operator|<
literal|0
condition|)
continue|continue;
comment|// Did we go beyond the target row? If so break.
if|if
condition|(
name|state
operator|.
name|isTooFar
argument_list|(
name|kv
argument_list|,
name|firstOnRow
argument_list|)
condition|)
break|break;
if|if
condition|(
name|state
operator|.
name|isExpired
argument_list|(
name|kv
argument_list|)
condition|)
block|{
continue|continue;
block|}
comment|// If we added something, this row is a contender. break.
if|if
condition|(
name|state
operator|.
name|handle
argument_list|(
name|kv
argument_list|)
condition|)
block|{
name|foundCandidate
operator|=
literal|true
expr_stmt|;
break|break;
block|}
block|}
do|while
condition|(
name|scanner
operator|.
name|next
argument_list|()
condition|)
do|;
return|return
name|foundCandidate
return|;
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|canSplit
parameter_list|()
block|{
name|this
operator|.
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
comment|// Not split-able if we find a reference store file present in the store.
name|boolean
name|result
init|=
operator|!
name|hasReferences
argument_list|()
decl_stmt|;
if|if
condition|(
operator|!
name|result
operator|&&
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"Cannot split region due to reference files being there"
argument_list|)
expr_stmt|;
block|}
return|return
name|result
return|;
block|}
finally|finally
block|{
name|this
operator|.
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|byte
index|[]
name|getSplitPoint
parameter_list|()
block|{
name|this
operator|.
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
comment|// Should already be enforced by the split policy!
assert|assert
operator|!
name|this
operator|.
name|getRegionInfo
argument_list|()
operator|.
name|isMetaRegion
argument_list|()
assert|;
comment|// Not split-able if we find a reference store file present in the store.
if|if
condition|(
name|hasReferences
argument_list|()
condition|)
block|{
return|return
literal|null
return|;
block|}
return|return
name|this
operator|.
name|storeEngine
operator|.
name|getStoreFileManager
argument_list|()
operator|.
name|getSplitPoint
argument_list|()
return|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failed getting store size for "
operator|+
name|this
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|this
operator|.
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
return|return
literal|null
return|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|getLastCompactSize
parameter_list|()
block|{
return|return
name|this
operator|.
name|lastCompactSize
return|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|getSize
parameter_list|()
block|{
return|return
name|storeSize
return|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|triggerMajorCompaction
parameter_list|()
block|{
name|this
operator|.
name|forceMajor
operator|=
literal|true
expr_stmt|;
block|}
comment|//////////////////////////////////////////////////////////////////////////////
comment|// File administration
comment|//////////////////////////////////////////////////////////////////////////////
annotation|@
name|Override
specifier|public
name|KeyValueScanner
name|getScanner
parameter_list|(
name|Scan
name|scan
parameter_list|,
specifier|final
name|NavigableSet
argument_list|<
name|byte
index|[]
argument_list|>
name|targetCols
parameter_list|,
name|long
name|readPt
parameter_list|)
throws|throws
name|IOException
block|{
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
name|KeyValueScanner
name|scanner
init|=
literal|null
decl_stmt|;
if|if
condition|(
name|this
operator|.
name|getCoprocessorHost
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|scanner
operator|=
name|this
operator|.
name|getCoprocessorHost
argument_list|()
operator|.
name|preStoreScannerOpen
argument_list|(
name|this
argument_list|,
name|scan
argument_list|,
name|targetCols
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|scanner
operator|==
literal|null
condition|)
block|{
name|scanner
operator|=
name|scan
operator|.
name|isReversed
argument_list|()
condition|?
operator|new
name|ReversedStoreScanner
argument_list|(
name|this
argument_list|,
name|getScanInfo
argument_list|()
argument_list|,
name|scan
argument_list|,
name|targetCols
argument_list|,
name|readPt
argument_list|)
else|:
operator|new
name|StoreScanner
argument_list|(
name|this
argument_list|,
name|getScanInfo
argument_list|()
argument_list|,
name|scan
argument_list|,
name|targetCols
argument_list|,
name|readPt
argument_list|)
expr_stmt|;
block|}
return|return
name|scanner
return|;
block|}
finally|finally
block|{
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|String
name|toString
parameter_list|()
block|{
return|return
name|this
operator|.
name|getColumnFamilyName
argument_list|()
return|;
block|}
annotation|@
name|Override
comment|// TODO: why is there this and also getNumberOfStorefiles?! Remove one.
specifier|public
name|int
name|getStorefilesCount
parameter_list|()
block|{
return|return
name|this
operator|.
name|storeEngine
operator|.
name|getStoreFileManager
argument_list|()
operator|.
name|getStorefileCount
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|getStoreSizeUncompressed
parameter_list|()
block|{
return|return
name|this
operator|.
name|totalUncompressedBytes
return|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|getStorefilesSize
parameter_list|()
block|{
name|long
name|size
init|=
literal|0
decl_stmt|;
for|for
control|(
name|StoreFile
name|s
range|:
name|this
operator|.
name|storeEngine
operator|.
name|getStoreFileManager
argument_list|()
operator|.
name|getStorefiles
argument_list|()
control|)
block|{
name|StoreFile
operator|.
name|Reader
name|r
init|=
name|s
operator|.
name|getReader
argument_list|()
decl_stmt|;
if|if
condition|(
name|r
operator|==
literal|null
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"StoreFile "
operator|+
name|s
operator|+
literal|" has a null Reader"
argument_list|)
expr_stmt|;
continue|continue;
block|}
name|size
operator|+=
name|r
operator|.
name|length
argument_list|()
expr_stmt|;
block|}
return|return
name|size
return|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|getStorefilesIndexSize
parameter_list|()
block|{
name|long
name|size
init|=
literal|0
decl_stmt|;
for|for
control|(
name|StoreFile
name|s
range|:
name|this
operator|.
name|storeEngine
operator|.
name|getStoreFileManager
argument_list|()
operator|.
name|getStorefiles
argument_list|()
control|)
block|{
name|StoreFile
operator|.
name|Reader
name|r
init|=
name|s
operator|.
name|getReader
argument_list|()
decl_stmt|;
if|if
condition|(
name|r
operator|==
literal|null
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"StoreFile "
operator|+
name|s
operator|+
literal|" has a null Reader"
argument_list|)
expr_stmt|;
continue|continue;
block|}
name|size
operator|+=
name|r
operator|.
name|indexSize
argument_list|()
expr_stmt|;
block|}
return|return
name|size
return|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|getTotalStaticIndexSize
parameter_list|()
block|{
name|long
name|size
init|=
literal|0
decl_stmt|;
for|for
control|(
name|StoreFile
name|s
range|:
name|this
operator|.
name|storeEngine
operator|.
name|getStoreFileManager
argument_list|()
operator|.
name|getStorefiles
argument_list|()
control|)
block|{
name|size
operator|+=
name|s
operator|.
name|getReader
argument_list|()
operator|.
name|getUncompressedDataIndexSize
argument_list|()
expr_stmt|;
block|}
return|return
name|size
return|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|getTotalStaticBloomSize
parameter_list|()
block|{
name|long
name|size
init|=
literal|0
decl_stmt|;
for|for
control|(
name|StoreFile
name|s
range|:
name|this
operator|.
name|storeEngine
operator|.
name|getStoreFileManager
argument_list|()
operator|.
name|getStorefiles
argument_list|()
control|)
block|{
name|StoreFile
operator|.
name|Reader
name|r
init|=
name|s
operator|.
name|getReader
argument_list|()
decl_stmt|;
name|size
operator|+=
name|r
operator|.
name|getTotalBloomSize
argument_list|()
expr_stmt|;
block|}
return|return
name|size
return|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|getMemStoreSize
parameter_list|()
block|{
return|return
name|this
operator|.
name|memstore
operator|.
name|size
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|int
name|getCompactPriority
parameter_list|()
block|{
name|int
name|priority
init|=
name|this
operator|.
name|storeEngine
operator|.
name|getStoreFileManager
argument_list|()
operator|.
name|getStoreCompactionPriority
argument_list|()
decl_stmt|;
if|if
condition|(
name|priority
operator|==
name|PRIORITY_USER
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Compaction priority is USER despite there being no user compaction"
argument_list|)
expr_stmt|;
block|}
return|return
name|priority
return|;
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|throttleCompaction
parameter_list|(
name|long
name|compactionSize
parameter_list|)
block|{
return|return
name|storeEngine
operator|.
name|getCompactionPolicy
argument_list|()
operator|.
name|throttleCompaction
argument_list|(
name|compactionSize
argument_list|)
return|;
block|}
specifier|public
name|HRegion
name|getHRegion
parameter_list|()
block|{
return|return
name|this
operator|.
name|region
return|;
block|}
annotation|@
name|Override
specifier|public
name|RegionCoprocessorHost
name|getCoprocessorHost
parameter_list|()
block|{
return|return
name|this
operator|.
name|region
operator|.
name|getCoprocessorHost
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|HRegionInfo
name|getRegionInfo
parameter_list|()
block|{
return|return
name|this
operator|.
name|fs
operator|.
name|getRegionInfo
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|areWritesEnabled
parameter_list|()
block|{
return|return
name|this
operator|.
name|region
operator|.
name|areWritesEnabled
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|getSmallestReadPoint
parameter_list|()
block|{
return|return
name|this
operator|.
name|region
operator|.
name|getSmallestReadPoint
argument_list|()
return|;
block|}
comment|/**    * Used in tests. TODO: Remove    *    * Updates the value for the given row/family/qualifier. This function will always be seen as    * atomic by other readers because it only puts a single KV to memstore. Thus no read/write    * control necessary.    * @param row row to update    * @param f family to update    * @param qualifier qualifier to update    * @param newValue the new value to set into memstore    * @return memstore size delta    * @throws IOException    */
specifier|public
name|long
name|updateColumnValue
parameter_list|(
name|byte
index|[]
name|row
parameter_list|,
name|byte
index|[]
name|f
parameter_list|,
name|byte
index|[]
name|qualifier
parameter_list|,
name|long
name|newValue
parameter_list|)
throws|throws
name|IOException
block|{
name|this
operator|.
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
name|long
name|now
init|=
name|EnvironmentEdgeManager
operator|.
name|currentTime
argument_list|()
decl_stmt|;
return|return
name|this
operator|.
name|memstore
operator|.
name|updateColumnValue
argument_list|(
name|row
argument_list|,
name|f
argument_list|,
name|qualifier
argument_list|,
name|newValue
argument_list|,
name|now
argument_list|)
return|;
block|}
finally|finally
block|{
name|this
operator|.
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|long
name|upsert
parameter_list|(
name|Iterable
argument_list|<
name|Cell
argument_list|>
name|cells
parameter_list|,
name|long
name|readpoint
parameter_list|)
throws|throws
name|IOException
block|{
name|this
operator|.
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|lock
argument_list|()
expr_stmt|;
try|try
block|{
return|return
name|this
operator|.
name|memstore
operator|.
name|upsert
argument_list|(
name|cells
argument_list|,
name|readpoint
argument_list|)
return|;
block|}
finally|finally
block|{
name|this
operator|.
name|lock
operator|.
name|readLock
argument_list|()
operator|.
name|unlock
argument_list|()
expr_stmt|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|StoreFlushContext
name|createFlushContext
parameter_list|(
name|long
name|cacheFlushId
parameter_list|)
block|{
return|return
operator|new
name|StoreFlusherImpl
argument_list|(
name|cacheFlushId
argument_list|)
return|;
block|}
specifier|private
class|class
name|StoreFlusherImpl
implements|implements
name|StoreFlushContext
block|{
specifier|private
name|long
name|cacheFlushSeqNum
decl_stmt|;
specifier|private
name|MemStoreSnapshot
name|snapshot
decl_stmt|;
specifier|private
name|List
argument_list|<
name|Path
argument_list|>
name|tempFiles
decl_stmt|;
specifier|private
name|List
argument_list|<
name|Path
argument_list|>
name|committedFiles
decl_stmt|;
specifier|private
name|long
name|cacheFlushCount
decl_stmt|;
specifier|private
name|long
name|cacheFlushSize
decl_stmt|;
specifier|private
name|StoreFlusherImpl
parameter_list|(
name|long
name|cacheFlushSeqNum
parameter_list|)
block|{
name|this
operator|.
name|cacheFlushSeqNum
operator|=
name|cacheFlushSeqNum
expr_stmt|;
block|}
comment|/**      * This is not thread safe. The caller should have a lock on the region or the store.      * If necessary, the lock can be added with the patch provided in HBASE-10087      */
annotation|@
name|Override
specifier|public
name|void
name|prepare
parameter_list|()
block|{
name|this
operator|.
name|snapshot
operator|=
name|memstore
operator|.
name|snapshot
argument_list|()
expr_stmt|;
name|this
operator|.
name|cacheFlushCount
operator|=
name|snapshot
operator|.
name|getCellsCount
argument_list|()
expr_stmt|;
name|this
operator|.
name|cacheFlushSize
operator|=
name|snapshot
operator|.
name|getSize
argument_list|()
expr_stmt|;
name|committedFiles
operator|=
operator|new
name|ArrayList
argument_list|<
name|Path
argument_list|>
argument_list|(
literal|1
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|flushCache
parameter_list|(
name|MonitoredTask
name|status
parameter_list|)
throws|throws
name|IOException
block|{
name|tempFiles
operator|=
name|HStore
operator|.
name|this
operator|.
name|flushCache
argument_list|(
name|cacheFlushSeqNum
argument_list|,
name|snapshot
argument_list|,
name|status
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|commit
parameter_list|(
name|MonitoredTask
name|status
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|this
operator|.
name|tempFiles
operator|==
literal|null
operator|||
name|this
operator|.
name|tempFiles
operator|.
name|isEmpty
argument_list|()
condition|)
block|{
return|return
literal|false
return|;
block|}
name|List
argument_list|<
name|StoreFile
argument_list|>
name|storeFiles
init|=
operator|new
name|ArrayList
argument_list|<
name|StoreFile
argument_list|>
argument_list|(
name|this
operator|.
name|tempFiles
operator|.
name|size
argument_list|()
argument_list|)
decl_stmt|;
for|for
control|(
name|Path
name|storeFilePath
range|:
name|tempFiles
control|)
block|{
try|try
block|{
name|storeFiles
operator|.
name|add
argument_list|(
name|HStore
operator|.
name|this
operator|.
name|commitFile
argument_list|(
name|storeFilePath
argument_list|,
name|cacheFlushSeqNum
argument_list|,
name|status
argument_list|)
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ex
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Failed to commit store file "
operator|+
name|storeFilePath
argument_list|,
name|ex
argument_list|)
expr_stmt|;
comment|// Try to delete the files we have committed before.
for|for
control|(
name|StoreFile
name|sf
range|:
name|storeFiles
control|)
block|{
name|Path
name|pathToDelete
init|=
name|sf
operator|.
name|getPath
argument_list|()
decl_stmt|;
try|try
block|{
name|sf
operator|.
name|deleteReader
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|deleteEx
parameter_list|)
block|{
name|LOG
operator|.
name|fatal
argument_list|(
literal|"Failed to delete store file we committed, halting "
operator|+
name|pathToDelete
argument_list|,
name|ex
argument_list|)
expr_stmt|;
name|Runtime
operator|.
name|getRuntime
argument_list|()
operator|.
name|halt
argument_list|(
literal|1
argument_list|)
expr_stmt|;
block|}
block|}
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Failed to commit the flush"
argument_list|,
name|ex
argument_list|)
throw|;
block|}
block|}
for|for
control|(
name|StoreFile
name|sf
range|:
name|storeFiles
control|)
block|{
if|if
condition|(
name|HStore
operator|.
name|this
operator|.
name|getCoprocessorHost
argument_list|()
operator|!=
literal|null
condition|)
block|{
name|HStore
operator|.
name|this
operator|.
name|getCoprocessorHost
argument_list|()
operator|.
name|postFlush
argument_list|(
name|HStore
operator|.
name|this
argument_list|,
name|sf
argument_list|)
expr_stmt|;
block|}
name|committedFiles
operator|.
name|add
argument_list|(
name|sf
operator|.
name|getPath
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|HStore
operator|.
name|this
operator|.
name|flushedCellsCount
operator|+=
name|cacheFlushCount
expr_stmt|;
name|HStore
operator|.
name|this
operator|.
name|flushedCellsSize
operator|+=
name|cacheFlushSize
expr_stmt|;
comment|// Add new file to store files.  Clear snapshot too while we have the Store write lock.
return|return
name|HStore
operator|.
name|this
operator|.
name|updateStorefiles
argument_list|(
name|storeFiles
argument_list|,
name|snapshot
operator|.
name|getId
argument_list|()
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|List
argument_list|<
name|Path
argument_list|>
name|getCommittedFiles
parameter_list|()
block|{
return|return
name|committedFiles
return|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|needsCompaction
parameter_list|()
block|{
return|return
name|this
operator|.
name|storeEngine
operator|.
name|needsCompaction
argument_list|(
name|this
operator|.
name|filesCompacting
argument_list|)
return|;
block|}
annotation|@
name|Override
specifier|public
name|CacheConfig
name|getCacheConfig
parameter_list|()
block|{
return|return
name|this
operator|.
name|cacheConf
return|;
block|}
specifier|public
specifier|static
specifier|final
name|long
name|FIXED_OVERHEAD
init|=
name|ClassSize
operator|.
name|align
argument_list|(
name|ClassSize
operator|.
name|OBJECT
operator|+
operator|(
literal|16
operator|*
name|ClassSize
operator|.
name|REFERENCE
operator|)
operator|+
operator|(
literal|10
operator|*
name|Bytes
operator|.
name|SIZEOF_LONG
operator|)
operator|+
operator|(
literal|5
operator|*
name|Bytes
operator|.
name|SIZEOF_INT
operator|)
operator|+
operator|(
literal|2
operator|*
name|Bytes
operator|.
name|SIZEOF_BOOLEAN
operator|)
argument_list|)
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|long
name|DEEP_OVERHEAD
init|=
name|ClassSize
operator|.
name|align
argument_list|(
name|FIXED_OVERHEAD
operator|+
name|ClassSize
operator|.
name|OBJECT
operator|+
name|ClassSize
operator|.
name|REENTRANT_LOCK
operator|+
name|ClassSize
operator|.
name|CONCURRENT_SKIPLISTMAP
operator|+
name|ClassSize
operator|.
name|CONCURRENT_SKIPLISTMAP_ENTRY
operator|+
name|ClassSize
operator|.
name|OBJECT
operator|+
name|ScanInfo
operator|.
name|FIXED_OVERHEAD
argument_list|)
decl_stmt|;
annotation|@
name|Override
specifier|public
name|long
name|heapSize
parameter_list|()
block|{
return|return
name|DEEP_OVERHEAD
operator|+
name|this
operator|.
name|memstore
operator|.
name|heapSize
argument_list|()
return|;
block|}
annotation|@
name|Override
specifier|public
name|KeyValue
operator|.
name|KVComparator
name|getComparator
parameter_list|()
block|{
return|return
name|comparator
return|;
block|}
annotation|@
name|Override
specifier|public
name|ScanInfo
name|getScanInfo
parameter_list|()
block|{
return|return
name|scanInfo
return|;
block|}
comment|/**    * Set scan info, used by test    * @param scanInfo new scan info to use for test    */
name|void
name|setScanInfo
parameter_list|(
name|ScanInfo
name|scanInfo
parameter_list|)
block|{
name|this
operator|.
name|scanInfo
operator|=
name|scanInfo
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|hasTooManyStoreFiles
parameter_list|()
block|{
return|return
name|getStorefilesCount
argument_list|()
operator|>
name|this
operator|.
name|blockingFileCount
return|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|getFlushedCellsCount
parameter_list|()
block|{
return|return
name|flushedCellsCount
return|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|getFlushedCellsSize
parameter_list|()
block|{
return|return
name|flushedCellsSize
return|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|getCompactedCellsCount
parameter_list|()
block|{
return|return
name|compactedCellsCount
return|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|getCompactedCellsSize
parameter_list|()
block|{
return|return
name|compactedCellsSize
return|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|getMajorCompactedCellsCount
parameter_list|()
block|{
return|return
name|majorCompactedCellsCount
return|;
block|}
annotation|@
name|Override
specifier|public
name|long
name|getMajorCompactedCellsSize
parameter_list|()
block|{
return|return
name|majorCompactedCellsSize
return|;
block|}
block|}
end_class

end_unit

