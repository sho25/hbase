begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  *  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
package|;
end_package

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|annotations
operator|.
name|VisibleForTesting
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Function
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|ImmutableList
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|Ordering
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collection
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collections
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Comparator
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|UUID
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|atomic
operator|.
name|AtomicBoolean
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|atomic
operator|.
name|AtomicInteger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|Log
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|LogFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|Cell
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|CellComparator
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|CellUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HDFSBlocksDistribution
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|classification
operator|.
name|InterfaceAudience
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|hfile
operator|.
name|BlockType
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|hfile
operator|.
name|CacheConfig
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|hfile
operator|.
name|HFile
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|BloomFilterFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|Bytes
import|;
end_import

begin_comment
comment|/**  * A Store data file.  Stores usually have one or more of these files.  They  * are produced by flushing the memstore to disk.  To  * create, instantiate a writer using {@link StoreFileWriter.Builder}  * and append data. Be sure to add any metadata before calling close on the  * Writer (Use the appendMetadata convenience methods). On close, a StoreFile  * is sitting in the Filesystem.  To refer to it, create a StoreFile instance  * passing filesystem and path.  To read, call {@link #initReader()}  *<p>StoreFiles may also reference store files in another Store.  *  * The reason for this weird pattern where you use a different instance for the  * writer and a reader is that we write once but read a lot more.  */
end_comment

begin_class
annotation|@
name|InterfaceAudience
operator|.
name|LimitedPrivate
argument_list|(
literal|"Coprocessor"
argument_list|)
specifier|public
class|class
name|StoreFile
block|{
specifier|private
specifier|static
specifier|final
name|Log
name|LOG
init|=
name|LogFactory
operator|.
name|getLog
argument_list|(
name|StoreFile
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|String
name|STORE_FILE_READER_NO_READAHEAD
init|=
literal|"hbase.store.reader.no-readahead"
decl_stmt|;
specifier|private
specifier|static
specifier|final
name|boolean
name|DEFAULT_STORE_FILE_READER_NO_READAHEAD
init|=
literal|false
decl_stmt|;
comment|// Keys for fileinfo values in HFile
comment|/** Max Sequence ID in FileInfo */
specifier|public
specifier|static
specifier|final
name|byte
index|[]
name|MAX_SEQ_ID_KEY
init|=
name|Bytes
operator|.
name|toBytes
argument_list|(
literal|"MAX_SEQ_ID_KEY"
argument_list|)
decl_stmt|;
comment|/** Major compaction flag in FileInfo */
specifier|public
specifier|static
specifier|final
name|byte
index|[]
name|MAJOR_COMPACTION_KEY
init|=
name|Bytes
operator|.
name|toBytes
argument_list|(
literal|"MAJOR_COMPACTION_KEY"
argument_list|)
decl_stmt|;
comment|/** Minor compaction flag in FileInfo */
specifier|public
specifier|static
specifier|final
name|byte
index|[]
name|EXCLUDE_FROM_MINOR_COMPACTION_KEY
init|=
name|Bytes
operator|.
name|toBytes
argument_list|(
literal|"EXCLUDE_FROM_MINOR_COMPACTION"
argument_list|)
decl_stmt|;
comment|/** Bloom filter Type in FileInfo */
specifier|public
specifier|static
specifier|final
name|byte
index|[]
name|BLOOM_FILTER_TYPE_KEY
init|=
name|Bytes
operator|.
name|toBytes
argument_list|(
literal|"BLOOM_FILTER_TYPE"
argument_list|)
decl_stmt|;
comment|/** Delete Family Count in FileInfo */
specifier|public
specifier|static
specifier|final
name|byte
index|[]
name|DELETE_FAMILY_COUNT
init|=
name|Bytes
operator|.
name|toBytes
argument_list|(
literal|"DELETE_FAMILY_COUNT"
argument_list|)
decl_stmt|;
comment|/** Last Bloom filter key in FileInfo */
specifier|public
specifier|static
specifier|final
name|byte
index|[]
name|LAST_BLOOM_KEY
init|=
name|Bytes
operator|.
name|toBytes
argument_list|(
literal|"LAST_BLOOM_KEY"
argument_list|)
decl_stmt|;
comment|/** Key for Timerange information in metadata*/
specifier|public
specifier|static
specifier|final
name|byte
index|[]
name|TIMERANGE_KEY
init|=
name|Bytes
operator|.
name|toBytes
argument_list|(
literal|"TIMERANGE"
argument_list|)
decl_stmt|;
comment|/** Key for timestamp of earliest-put in metadata*/
specifier|public
specifier|static
specifier|final
name|byte
index|[]
name|EARLIEST_PUT_TS
init|=
name|Bytes
operator|.
name|toBytes
argument_list|(
literal|"EARLIEST_PUT_TS"
argument_list|)
decl_stmt|;
comment|/** Key for the number of mob cells in metadata*/
specifier|public
specifier|static
specifier|final
name|byte
index|[]
name|MOB_CELLS_COUNT
init|=
name|Bytes
operator|.
name|toBytes
argument_list|(
literal|"MOB_CELLS_COUNT"
argument_list|)
decl_stmt|;
specifier|private
specifier|final
name|StoreFileInfo
name|fileInfo
decl_stmt|;
specifier|private
specifier|final
name|FileSystem
name|fs
decl_stmt|;
comment|// Block cache configuration and reference.
specifier|private
specifier|final
name|CacheConfig
name|cacheConf
decl_stmt|;
comment|// Counter that is incremented every time a scanner is created on the
comment|// store file. It is decremented when the scan on the store file is
comment|// done.
specifier|private
specifier|final
name|AtomicInteger
name|refCount
init|=
operator|new
name|AtomicInteger
argument_list|(
literal|0
argument_list|)
decl_stmt|;
specifier|private
specifier|final
name|boolean
name|noReadahead
decl_stmt|;
specifier|private
specifier|final
name|boolean
name|primaryReplica
decl_stmt|;
comment|// Indicates if the file got compacted
specifier|private
specifier|volatile
name|boolean
name|compactedAway
init|=
literal|false
decl_stmt|;
comment|// Keys for metadata stored in backing HFile.
comment|// Set when we obtain a Reader.
specifier|private
name|long
name|sequenceid
init|=
operator|-
literal|1
decl_stmt|;
comment|// max of the MemstoreTS in the KV's in this store
comment|// Set when we obtain a Reader.
specifier|private
name|long
name|maxMemstoreTS
init|=
operator|-
literal|1
decl_stmt|;
comment|// firstKey, lastkey and cellComparator will be set when openReader.
specifier|private
name|Cell
name|firstKey
decl_stmt|;
specifier|private
name|Cell
name|lastKey
decl_stmt|;
specifier|private
name|Comparator
argument_list|<
name|Cell
argument_list|>
name|comparator
decl_stmt|;
name|CacheConfig
name|getCacheConf
parameter_list|()
block|{
return|return
name|cacheConf
return|;
block|}
specifier|public
name|Cell
name|getFirstKey
parameter_list|()
block|{
return|return
name|firstKey
return|;
block|}
specifier|public
name|Cell
name|getLastKey
parameter_list|()
block|{
return|return
name|lastKey
return|;
block|}
specifier|public
name|Comparator
argument_list|<
name|Cell
argument_list|>
name|getComparator
parameter_list|()
block|{
return|return
name|comparator
return|;
block|}
specifier|public
name|long
name|getMaxMemstoreTS
parameter_list|()
block|{
return|return
name|maxMemstoreTS
return|;
block|}
specifier|public
name|void
name|setMaxMemstoreTS
parameter_list|(
name|long
name|maxMemstoreTS
parameter_list|)
block|{
name|this
operator|.
name|maxMemstoreTS
operator|=
name|maxMemstoreTS
expr_stmt|;
block|}
comment|// If true, this file was product of a major compaction.  Its then set
comment|// whenever you get a Reader.
specifier|private
name|AtomicBoolean
name|majorCompaction
init|=
literal|null
decl_stmt|;
comment|// If true, this file should not be included in minor compactions.
comment|// It's set whenever you get a Reader.
specifier|private
name|boolean
name|excludeFromMinorCompaction
init|=
literal|false
decl_stmt|;
comment|/** Meta key set when store file is a result of a bulk load */
specifier|public
specifier|static
specifier|final
name|byte
index|[]
name|BULKLOAD_TASK_KEY
init|=
name|Bytes
operator|.
name|toBytes
argument_list|(
literal|"BULKLOAD_SOURCE_TASK"
argument_list|)
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|byte
index|[]
name|BULKLOAD_TIME_KEY
init|=
name|Bytes
operator|.
name|toBytes
argument_list|(
literal|"BULKLOAD_TIMESTAMP"
argument_list|)
decl_stmt|;
comment|/**    * Map of the metadata entries in the corresponding HFile. Populated when Reader is opened    * after which it is not modified again.    */
specifier|private
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|byte
index|[]
argument_list|>
name|metadataMap
decl_stmt|;
comment|// StoreFile.Reader
specifier|private
specifier|volatile
name|StoreFileReader
name|reader
decl_stmt|;
comment|/**    * Bloom filter type specified in column family configuration. Does not    * necessarily correspond to the Bloom filter type present in the HFile.    */
specifier|private
specifier|final
name|BloomType
name|cfBloomType
decl_stmt|;
comment|/**    * Key for skipping resetting sequence id in metadata.    * For bulk loaded hfiles, the scanner resets the cell seqId with the latest one,    * if this metadata is set as true, the reset is skipped.    */
specifier|public
specifier|static
specifier|final
name|byte
index|[]
name|SKIP_RESET_SEQ_ID
init|=
name|Bytes
operator|.
name|toBytes
argument_list|(
literal|"SKIP_RESET_SEQ_ID"
argument_list|)
decl_stmt|;
comment|/**    * Constructor, loads a reader and it's indices, etc. May allocate a substantial amount of ram    * depending on the underlying files (10-20MB?).    * @param fs The current file system to use.    * @param p The path of the file.    * @param conf The current configuration.    * @param cacheConf The cache configuration and block cache reference.    * @param cfBloomType The bloom type to use for this store file as specified by column family    *          configuration. This may or may not be the same as the Bloom filter type actually    *          present in the HFile, because column family configuration might change. If this is    *          {@link BloomType#NONE}, the existing Bloom filter is ignored.    * @deprecated Now we will specific whether the StoreFile is for primary replica when    *             constructing, so please use    *             {@link #StoreFile(FileSystem, Path, Configuration, CacheConfig, BloomType, boolean)}    *             directly.    */
annotation|@
name|Deprecated
specifier|public
name|StoreFile
parameter_list|(
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Path
name|p
parameter_list|,
specifier|final
name|Configuration
name|conf
parameter_list|,
specifier|final
name|CacheConfig
name|cacheConf
parameter_list|,
specifier|final
name|BloomType
name|cfBloomType
parameter_list|)
throws|throws
name|IOException
block|{
name|this
argument_list|(
name|fs
argument_list|,
operator|new
name|StoreFileInfo
argument_list|(
name|conf
argument_list|,
name|fs
argument_list|,
name|p
argument_list|)
argument_list|,
name|conf
argument_list|,
name|cacheConf
argument_list|,
name|cfBloomType
argument_list|)
expr_stmt|;
block|}
comment|/**    * Constructor, loads a reader and it's indices, etc. May allocate a substantial amount of ram    * depending on the underlying files (10-20MB?).    * @param fs The current file system to use.    * @param p The path of the file.    * @param conf The current configuration.    * @param cacheConf The cache configuration and block cache reference.    * @param cfBloomType The bloom type to use for this store file as specified by column family    *          configuration. This may or may not be the same as the Bloom filter type actually    *          present in the HFile, because column family configuration might change. If this is    *          {@link BloomType#NONE}, the existing Bloom filter is ignored.    * @param primaryReplica true if this is a store file for primary replica, otherwise false.    * @throws IOException    */
specifier|public
name|StoreFile
parameter_list|(
name|FileSystem
name|fs
parameter_list|,
name|Path
name|p
parameter_list|,
name|Configuration
name|conf
parameter_list|,
name|CacheConfig
name|cacheConf
parameter_list|,
name|BloomType
name|cfBloomType
parameter_list|,
name|boolean
name|primaryReplica
parameter_list|)
throws|throws
name|IOException
block|{
name|this
argument_list|(
name|fs
argument_list|,
operator|new
name|StoreFileInfo
argument_list|(
name|conf
argument_list|,
name|fs
argument_list|,
name|p
argument_list|)
argument_list|,
name|conf
argument_list|,
name|cacheConf
argument_list|,
name|cfBloomType
argument_list|,
name|primaryReplica
argument_list|)
expr_stmt|;
block|}
comment|/**    * Constructor, loads a reader and it's indices, etc. May allocate a substantial amount of ram    * depending on the underlying files (10-20MB?).    * @param fs The current file system to use.    * @param fileInfo The store file information.    * @param conf The current configuration.    * @param cacheConf The cache configuration and block cache reference.    * @param cfBloomType The bloom type to use for this store file as specified by column family    *          configuration. This may or may not be the same as the Bloom filter type actually    *          present in the HFile, because column family configuration might change. If this is    *          {@link BloomType#NONE}, the existing Bloom filter is ignored.    * @deprecated Now we will specific whether the StoreFile is for primary replica when    *             constructing, so please use    *             {@link #StoreFile(FileSystem, StoreFileInfo, Configuration, CacheConfig, BloomType, boolean)}    *             directly.    */
annotation|@
name|Deprecated
specifier|public
name|StoreFile
parameter_list|(
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|StoreFileInfo
name|fileInfo
parameter_list|,
specifier|final
name|Configuration
name|conf
parameter_list|,
specifier|final
name|CacheConfig
name|cacheConf
parameter_list|,
specifier|final
name|BloomType
name|cfBloomType
parameter_list|)
throws|throws
name|IOException
block|{
name|this
argument_list|(
name|fs
argument_list|,
name|fileInfo
argument_list|,
name|conf
argument_list|,
name|cacheConf
argument_list|,
name|cfBloomType
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
comment|/**    * Constructor, loads a reader and it's indices, etc. May allocate a substantial amount of ram    * depending on the underlying files (10-20MB?).    * @param fs fs The current file system to use.    * @param fileInfo The store file information.    * @param conf The current configuration.    * @param cacheConf The cache configuration and block cache reference.    * @param cfBloomType cfBloomType The bloom type to use for this store file as specified by column    *          family configuration. This may or may not be the same as the Bloom filter type    *          actually present in the HFile, because column family configuration might change. If    *          this is {@link BloomType#NONE}, the existing Bloom filter is ignored.    * @param primaryReplica true if this is a store file for primary replica, otherwise false.    */
specifier|public
name|StoreFile
parameter_list|(
name|FileSystem
name|fs
parameter_list|,
name|StoreFileInfo
name|fileInfo
parameter_list|,
name|Configuration
name|conf
parameter_list|,
name|CacheConfig
name|cacheConf
parameter_list|,
name|BloomType
name|cfBloomType
parameter_list|,
name|boolean
name|primaryReplica
parameter_list|)
block|{
name|this
operator|.
name|fs
operator|=
name|fs
expr_stmt|;
name|this
operator|.
name|fileInfo
operator|=
name|fileInfo
expr_stmt|;
name|this
operator|.
name|cacheConf
operator|=
name|cacheConf
expr_stmt|;
name|this
operator|.
name|noReadahead
operator|=
name|conf
operator|.
name|getBoolean
argument_list|(
name|STORE_FILE_READER_NO_READAHEAD
argument_list|,
name|DEFAULT_STORE_FILE_READER_NO_READAHEAD
argument_list|)
expr_stmt|;
if|if
condition|(
name|BloomFilterFactory
operator|.
name|isGeneralBloomEnabled
argument_list|(
name|conf
argument_list|)
condition|)
block|{
name|this
operator|.
name|cfBloomType
operator|=
name|cfBloomType
expr_stmt|;
block|}
else|else
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Ignoring bloom filter check for file "
operator|+
name|this
operator|.
name|getPath
argument_list|()
operator|+
literal|": "
operator|+
literal|"cfBloomType="
operator|+
name|cfBloomType
operator|+
literal|" (disabled in config)"
argument_list|)
expr_stmt|;
name|this
operator|.
name|cfBloomType
operator|=
name|BloomType
operator|.
name|NONE
expr_stmt|;
block|}
name|this
operator|.
name|primaryReplica
operator|=
name|primaryReplica
expr_stmt|;
block|}
comment|/**    * @return the StoreFile object associated to this StoreFile.    *         null if the StoreFile is not a reference.    */
specifier|public
name|StoreFileInfo
name|getFileInfo
parameter_list|()
block|{
return|return
name|this
operator|.
name|fileInfo
return|;
block|}
comment|/**    * @return Path or null if this StoreFile was made with a Stream.    */
specifier|public
name|Path
name|getPath
parameter_list|()
block|{
return|return
name|this
operator|.
name|fileInfo
operator|.
name|getPath
argument_list|()
return|;
block|}
comment|/**    * @return Returns the qualified path of this StoreFile    */
specifier|public
name|Path
name|getQualifiedPath
parameter_list|()
block|{
return|return
name|this
operator|.
name|fileInfo
operator|.
name|getPath
argument_list|()
operator|.
name|makeQualified
argument_list|(
name|fs
operator|.
name|getUri
argument_list|()
argument_list|,
name|fs
operator|.
name|getWorkingDirectory
argument_list|()
argument_list|)
return|;
block|}
comment|/**    * @return True if this is a StoreFile Reference; call    * after {@link #open()} else may get wrong answer.    */
specifier|public
name|boolean
name|isReference
parameter_list|()
block|{
return|return
name|this
operator|.
name|fileInfo
operator|.
name|isReference
argument_list|()
return|;
block|}
comment|/**    * @return True if this is HFile.    */
specifier|public
name|boolean
name|isHFile
parameter_list|()
block|{
return|return
name|StoreFileInfo
operator|.
name|isHFile
argument_list|(
name|this
operator|.
name|fileInfo
operator|.
name|getPath
argument_list|()
argument_list|)
return|;
block|}
comment|/**    * @return True if this file was made by a major compaction.    */
specifier|public
name|boolean
name|isMajorCompaction
parameter_list|()
block|{
if|if
condition|(
name|this
operator|.
name|majorCompaction
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|NullPointerException
argument_list|(
literal|"This has not been set yet"
argument_list|)
throw|;
block|}
return|return
name|this
operator|.
name|majorCompaction
operator|.
name|get
argument_list|()
return|;
block|}
comment|/**    * @return True if this file should not be part of a minor compaction.    */
specifier|public
name|boolean
name|excludeFromMinorCompaction
parameter_list|()
block|{
return|return
name|this
operator|.
name|excludeFromMinorCompaction
return|;
block|}
comment|/**    * @return This files maximum edit sequence id.    */
specifier|public
name|long
name|getMaxSequenceId
parameter_list|()
block|{
return|return
name|this
operator|.
name|sequenceid
return|;
block|}
specifier|public
name|long
name|getModificationTimeStamp
parameter_list|()
throws|throws
name|IOException
block|{
return|return
operator|(
name|fileInfo
operator|==
literal|null
operator|)
condition|?
literal|0
else|:
name|fileInfo
operator|.
name|getModificationTime
argument_list|()
return|;
block|}
comment|/**    * Only used by the Striped Compaction Policy    * @param key    * @return value associated with the metadata key    */
specifier|public
name|byte
index|[]
name|getMetadataValue
parameter_list|(
name|byte
index|[]
name|key
parameter_list|)
block|{
return|return
name|metadataMap
operator|.
name|get
argument_list|(
name|key
argument_list|)
return|;
block|}
comment|/**    * Return the largest memstoreTS found across all storefiles in    * the given list. Store files that were created by a mapreduce    * bulk load are ignored, as they do not correspond to any specific    * put operation, and thus do not have a memstoreTS associated with them.    * @return 0 if no non-bulk-load files are provided or, this is Store that    * does not yet have any store files.    */
specifier|public
specifier|static
name|long
name|getMaxMemstoreTSInList
parameter_list|(
name|Collection
argument_list|<
name|StoreFile
argument_list|>
name|sfs
parameter_list|)
block|{
name|long
name|max
init|=
literal|0
decl_stmt|;
for|for
control|(
name|StoreFile
name|sf
range|:
name|sfs
control|)
block|{
if|if
condition|(
operator|!
name|sf
operator|.
name|isBulkLoadResult
argument_list|()
condition|)
block|{
name|max
operator|=
name|Math
operator|.
name|max
argument_list|(
name|max
argument_list|,
name|sf
operator|.
name|getMaxMemstoreTS
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|max
return|;
block|}
comment|/**    * Return the highest sequence ID found across all storefiles in    * the given list.    * @param sfs    * @return 0 if no non-bulk-load files are provided or, this is Store that    * does not yet have any store files.    */
specifier|public
specifier|static
name|long
name|getMaxSequenceIdInList
parameter_list|(
name|Collection
argument_list|<
name|StoreFile
argument_list|>
name|sfs
parameter_list|)
block|{
name|long
name|max
init|=
literal|0
decl_stmt|;
for|for
control|(
name|StoreFile
name|sf
range|:
name|sfs
control|)
block|{
name|max
operator|=
name|Math
operator|.
name|max
argument_list|(
name|max
argument_list|,
name|sf
operator|.
name|getMaxSequenceId
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
name|max
return|;
block|}
comment|/**    * Check if this storefile was created by bulk load.    * When a hfile is bulk loaded into HBase, we append    * {@code '_SeqId_<id-when-loaded>'} to the hfile name, unless    * "hbase.mapreduce.bulkload.assign.sequenceNumbers" is    * explicitly turned off.    * If "hbase.mapreduce.bulkload.assign.sequenceNumbers"    * is turned off, fall back to BULKLOAD_TIME_KEY.    * @return true if this storefile was created by bulk load.    */
specifier|public
name|boolean
name|isBulkLoadResult
parameter_list|()
block|{
name|boolean
name|bulkLoadedHFile
init|=
literal|false
decl_stmt|;
name|String
name|fileName
init|=
name|this
operator|.
name|getPath
argument_list|()
operator|.
name|getName
argument_list|()
decl_stmt|;
name|int
name|startPos
init|=
name|fileName
operator|.
name|indexOf
argument_list|(
literal|"SeqId_"
argument_list|)
decl_stmt|;
if|if
condition|(
name|startPos
operator|!=
operator|-
literal|1
condition|)
block|{
name|bulkLoadedHFile
operator|=
literal|true
expr_stmt|;
block|}
return|return
name|bulkLoadedHFile
operator|||
operator|(
name|metadataMap
operator|!=
literal|null
operator|&&
name|metadataMap
operator|.
name|containsKey
argument_list|(
name|BULKLOAD_TIME_KEY
argument_list|)
operator|)
return|;
block|}
annotation|@
name|VisibleForTesting
specifier|public
name|boolean
name|isCompactedAway
parameter_list|()
block|{
return|return
name|compactedAway
return|;
block|}
annotation|@
name|VisibleForTesting
specifier|public
name|int
name|getRefCount
parameter_list|()
block|{
return|return
name|refCount
operator|.
name|get
argument_list|()
return|;
block|}
comment|/**    * @return true if the file is still used in reads    */
specifier|public
name|boolean
name|isReferencedInReads
parameter_list|()
block|{
name|int
name|rc
init|=
name|refCount
operator|.
name|get
argument_list|()
decl_stmt|;
assert|assert
name|rc
operator|>=
literal|0
assert|;
comment|// we should not go negative.
return|return
name|rc
operator|>
literal|0
return|;
block|}
comment|/**    * Return the timestamp at which this bulk load file was generated.    */
specifier|public
name|long
name|getBulkLoadTimestamp
parameter_list|()
block|{
name|byte
index|[]
name|bulkLoadTimestamp
init|=
name|metadataMap
operator|.
name|get
argument_list|(
name|BULKLOAD_TIME_KEY
argument_list|)
decl_stmt|;
return|return
operator|(
name|bulkLoadTimestamp
operator|==
literal|null
operator|)
condition|?
literal|0
else|:
name|Bytes
operator|.
name|toLong
argument_list|(
name|bulkLoadTimestamp
argument_list|)
return|;
block|}
comment|/**    * @return the cached value of HDFS blocks distribution. The cached value is    * calculated when store file is opened.    */
specifier|public
name|HDFSBlocksDistribution
name|getHDFSBlockDistribution
parameter_list|()
block|{
return|return
name|this
operator|.
name|fileInfo
operator|.
name|getHDFSBlockDistribution
argument_list|()
return|;
block|}
comment|/**    * Opens reader on this store file. Called by Constructor.    * @throws IOException    * @see #closeReader(boolean)    */
specifier|private
name|void
name|open
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|this
operator|.
name|reader
operator|!=
literal|null
condition|)
block|{
throw|throw
operator|new
name|IllegalAccessError
argument_list|(
literal|"Already open"
argument_list|)
throw|;
block|}
comment|// Open the StoreFile.Reader
name|this
operator|.
name|reader
operator|=
name|fileInfo
operator|.
name|open
argument_list|(
name|this
operator|.
name|fs
argument_list|,
name|this
operator|.
name|cacheConf
argument_list|,
literal|false
argument_list|,
name|noReadahead
condition|?
literal|0L
else|:
operator|-
literal|1L
argument_list|,
name|primaryReplica
argument_list|,
name|refCount
argument_list|,
literal|true
argument_list|)
expr_stmt|;
comment|// Load up indices and fileinfo. This also loads Bloom filter type.
name|metadataMap
operator|=
name|Collections
operator|.
name|unmodifiableMap
argument_list|(
name|this
operator|.
name|reader
operator|.
name|loadFileInfo
argument_list|()
argument_list|)
expr_stmt|;
comment|// Read in our metadata.
name|byte
index|[]
name|b
init|=
name|metadataMap
operator|.
name|get
argument_list|(
name|MAX_SEQ_ID_KEY
argument_list|)
decl_stmt|;
if|if
condition|(
name|b
operator|!=
literal|null
condition|)
block|{
comment|// By convention, if halfhfile, top half has a sequence number> bottom
comment|// half. Thats why we add one in below. Its done for case the two halves
comment|// are ever merged back together --rare.  Without it, on open of store,
comment|// since store files are distinguished by sequence id, the one half would
comment|// subsume the other.
name|this
operator|.
name|sequenceid
operator|=
name|Bytes
operator|.
name|toLong
argument_list|(
name|b
argument_list|)
expr_stmt|;
if|if
condition|(
name|fileInfo
operator|.
name|isTopReference
argument_list|()
condition|)
block|{
name|this
operator|.
name|sequenceid
operator|+=
literal|1
expr_stmt|;
block|}
block|}
if|if
condition|(
name|isBulkLoadResult
argument_list|()
condition|)
block|{
comment|// generate the sequenceId from the fileName
comment|// fileName is of the form<randomName>_SeqId_<id-when-loaded>_
name|String
name|fileName
init|=
name|this
operator|.
name|getPath
argument_list|()
operator|.
name|getName
argument_list|()
decl_stmt|;
comment|// Use lastIndexOf() to get the last, most recent bulk load seqId.
name|int
name|startPos
init|=
name|fileName
operator|.
name|lastIndexOf
argument_list|(
literal|"SeqId_"
argument_list|)
decl_stmt|;
if|if
condition|(
name|startPos
operator|!=
operator|-
literal|1
condition|)
block|{
name|this
operator|.
name|sequenceid
operator|=
name|Long
operator|.
name|parseLong
argument_list|(
name|fileName
operator|.
name|substring
argument_list|(
name|startPos
operator|+
literal|6
argument_list|,
name|fileName
operator|.
name|indexOf
argument_list|(
literal|'_'
argument_list|,
name|startPos
operator|+
literal|6
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
comment|// Handle reference files as done above.
if|if
condition|(
name|fileInfo
operator|.
name|isTopReference
argument_list|()
condition|)
block|{
name|this
operator|.
name|sequenceid
operator|+=
literal|1
expr_stmt|;
block|}
block|}
comment|// SKIP_RESET_SEQ_ID only works in bulk loaded file.
comment|// In mob compaction, the hfile where the cells contain the path of a new mob file is bulk
comment|// loaded to hbase, these cells have the same seqIds with the old ones. We do not want
comment|// to reset new seqIds for them since this might make a mess of the visibility of cells that
comment|// have the same row key but different seqIds.
name|boolean
name|skipResetSeqId
init|=
name|isSkipResetSeqId
argument_list|(
name|metadataMap
operator|.
name|get
argument_list|(
name|SKIP_RESET_SEQ_ID
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|skipResetSeqId
condition|)
block|{
comment|// increase the seqId when it is a bulk loaded file from mob compaction.
name|this
operator|.
name|sequenceid
operator|+=
literal|1
expr_stmt|;
block|}
name|this
operator|.
name|reader
operator|.
name|setSkipResetSeqId
argument_list|(
name|skipResetSeqId
argument_list|)
expr_stmt|;
name|this
operator|.
name|reader
operator|.
name|setBulkLoaded
argument_list|(
literal|true
argument_list|)
expr_stmt|;
block|}
name|this
operator|.
name|reader
operator|.
name|setSequenceID
argument_list|(
name|this
operator|.
name|sequenceid
argument_list|)
expr_stmt|;
name|b
operator|=
name|metadataMap
operator|.
name|get
argument_list|(
name|HFile
operator|.
name|Writer
operator|.
name|MAX_MEMSTORE_TS_KEY
argument_list|)
expr_stmt|;
if|if
condition|(
name|b
operator|!=
literal|null
condition|)
block|{
name|this
operator|.
name|maxMemstoreTS
operator|=
name|Bytes
operator|.
name|toLong
argument_list|(
name|b
argument_list|)
expr_stmt|;
block|}
name|b
operator|=
name|metadataMap
operator|.
name|get
argument_list|(
name|MAJOR_COMPACTION_KEY
argument_list|)
expr_stmt|;
if|if
condition|(
name|b
operator|!=
literal|null
condition|)
block|{
name|boolean
name|mc
init|=
name|Bytes
operator|.
name|toBoolean
argument_list|(
name|b
argument_list|)
decl_stmt|;
if|if
condition|(
name|this
operator|.
name|majorCompaction
operator|==
literal|null
condition|)
block|{
name|this
operator|.
name|majorCompaction
operator|=
operator|new
name|AtomicBoolean
argument_list|(
name|mc
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|this
operator|.
name|majorCompaction
operator|.
name|set
argument_list|(
name|mc
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
comment|// Presume it is not major compacted if it doesn't explicity say so
comment|// HFileOutputFormat explicitly sets the major compacted key.
name|this
operator|.
name|majorCompaction
operator|=
operator|new
name|AtomicBoolean
argument_list|(
literal|false
argument_list|)
expr_stmt|;
block|}
name|b
operator|=
name|metadataMap
operator|.
name|get
argument_list|(
name|EXCLUDE_FROM_MINOR_COMPACTION_KEY
argument_list|)
expr_stmt|;
name|this
operator|.
name|excludeFromMinorCompaction
operator|=
operator|(
name|b
operator|!=
literal|null
operator|&&
name|Bytes
operator|.
name|toBoolean
argument_list|(
name|b
argument_list|)
operator|)
expr_stmt|;
name|BloomType
name|hfileBloomType
init|=
name|reader
operator|.
name|getBloomFilterType
argument_list|()
decl_stmt|;
if|if
condition|(
name|cfBloomType
operator|!=
name|BloomType
operator|.
name|NONE
condition|)
block|{
name|reader
operator|.
name|loadBloomfilter
argument_list|(
name|BlockType
operator|.
name|GENERAL_BLOOM_META
argument_list|)
expr_stmt|;
if|if
condition|(
name|hfileBloomType
operator|!=
name|cfBloomType
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"HFile Bloom filter type for "
operator|+
name|reader
operator|.
name|getHFileReader
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|": "
operator|+
name|hfileBloomType
operator|+
literal|", but "
operator|+
name|cfBloomType
operator|+
literal|" specified in column family "
operator|+
literal|"configuration"
argument_list|)
expr_stmt|;
block|}
block|}
elseif|else
if|if
condition|(
name|hfileBloomType
operator|!=
name|BloomType
operator|.
name|NONE
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Bloom filter turned off by CF config for "
operator|+
name|reader
operator|.
name|getHFileReader
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|// load delete family bloom filter
name|reader
operator|.
name|loadBloomfilter
argument_list|(
name|BlockType
operator|.
name|DELETE_FAMILY_BLOOM_META
argument_list|)
expr_stmt|;
try|try
block|{
name|this
operator|.
name|reader
operator|.
name|timeRange
operator|=
name|TimeRangeTracker
operator|.
name|getTimeRange
argument_list|(
name|metadataMap
operator|.
name|get
argument_list|(
name|TIMERANGE_KEY
argument_list|)
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IllegalArgumentException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Error reading timestamp range data from meta -- "
operator|+
literal|"proceeding without"
argument_list|,
name|e
argument_list|)
expr_stmt|;
name|this
operator|.
name|reader
operator|.
name|timeRange
operator|=
literal|null
expr_stmt|;
block|}
comment|// initialize so we can reuse them after reader closed.
name|firstKey
operator|=
name|reader
operator|.
name|getFirstKey
argument_list|()
expr_stmt|;
name|lastKey
operator|=
name|reader
operator|.
name|getLastKey
argument_list|()
expr_stmt|;
name|comparator
operator|=
name|reader
operator|.
name|getComparator
argument_list|()
expr_stmt|;
block|}
comment|/**    * Initialize the reader used for pread.    */
specifier|public
name|void
name|initReader
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|reader
operator|==
literal|null
condition|)
block|{
try|try
block|{
name|open
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|Exception
name|e
parameter_list|)
block|{
try|try
block|{
name|boolean
name|evictOnClose
init|=
name|cacheConf
operator|!=
literal|null
condition|?
name|cacheConf
operator|.
name|shouldEvictOnClose
argument_list|()
else|:
literal|true
decl_stmt|;
name|this
operator|.
name|closeReader
argument_list|(
name|evictOnClose
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ee
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"failed to close reader"
argument_list|,
name|ee
argument_list|)
expr_stmt|;
block|}
throw|throw
name|e
throw|;
block|}
block|}
block|}
specifier|private
name|StoreFileReader
name|createStreamReader
parameter_list|(
name|boolean
name|canUseDropBehind
parameter_list|)
throws|throws
name|IOException
block|{
name|initReader
argument_list|()
expr_stmt|;
name|StoreFileReader
name|reader
init|=
name|fileInfo
operator|.
name|open
argument_list|(
name|this
operator|.
name|fs
argument_list|,
name|this
operator|.
name|cacheConf
argument_list|,
name|canUseDropBehind
argument_list|,
operator|-
literal|1L
argument_list|,
name|primaryReplica
argument_list|,
name|refCount
argument_list|,
literal|false
argument_list|)
decl_stmt|;
name|reader
operator|.
name|copyFields
argument_list|(
name|this
operator|.
name|reader
argument_list|)
expr_stmt|;
return|return
name|reader
return|;
block|}
specifier|public
name|StoreFileScanner
name|getStreamScanner
parameter_list|(
name|boolean
name|canUseDropBehind
parameter_list|,
name|boolean
name|cacheBlocks
parameter_list|,
name|boolean
name|pread
parameter_list|,
name|boolean
name|isCompaction
parameter_list|,
name|long
name|readPt
parameter_list|,
name|long
name|scannerOrder
parameter_list|,
name|boolean
name|canOptimizeForNonNullColumn
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|createStreamReader
argument_list|(
name|canUseDropBehind
argument_list|)
operator|.
name|getStoreFileScanner
argument_list|(
name|cacheBlocks
argument_list|,
name|pread
argument_list|,
name|isCompaction
argument_list|,
name|readPt
argument_list|,
name|scannerOrder
argument_list|,
name|canOptimizeForNonNullColumn
argument_list|)
return|;
block|}
comment|/**    * @return Current reader.  Must call initReader first else returns null.    * @see #initReader()    */
specifier|public
name|StoreFileReader
name|getReader
parameter_list|()
block|{
return|return
name|this
operator|.
name|reader
return|;
block|}
comment|/**    * @param evictOnClose whether to evict blocks belonging to this file    * @throws IOException    */
specifier|public
specifier|synchronized
name|void
name|closeReader
parameter_list|(
name|boolean
name|evictOnClose
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|this
operator|.
name|reader
operator|!=
literal|null
condition|)
block|{
name|this
operator|.
name|reader
operator|.
name|close
argument_list|(
name|evictOnClose
argument_list|)
expr_stmt|;
name|this
operator|.
name|reader
operator|=
literal|null
expr_stmt|;
block|}
block|}
comment|/**    * Marks the status of the file as compactedAway.    */
specifier|public
name|void
name|markCompactedAway
parameter_list|()
block|{
name|this
operator|.
name|compactedAway
operator|=
literal|true
expr_stmt|;
block|}
comment|/**    * Delete this file    * @throws IOException    */
specifier|public
name|void
name|deleteReader
parameter_list|()
throws|throws
name|IOException
block|{
name|boolean
name|evictOnClose
init|=
name|cacheConf
operator|!=
literal|null
condition|?
name|cacheConf
operator|.
name|shouldEvictOnClose
argument_list|()
else|:
literal|true
decl_stmt|;
name|closeReader
argument_list|(
name|evictOnClose
argument_list|)
expr_stmt|;
name|this
operator|.
name|fs
operator|.
name|delete
argument_list|(
name|getPath
argument_list|()
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|String
name|toString
parameter_list|()
block|{
return|return
name|this
operator|.
name|fileInfo
operator|.
name|toString
argument_list|()
return|;
block|}
comment|/**    * @return a length description of this StoreFile, suitable for debug output    */
specifier|public
name|String
name|toStringDetailed
parameter_list|()
block|{
name|StringBuilder
name|sb
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
name|sb
operator|.
name|append
argument_list|(
name|this
operator|.
name|getPath
argument_list|()
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
name|sb
operator|.
name|append
argument_list|(
literal|", isReference="
argument_list|)
operator|.
name|append
argument_list|(
name|isReference
argument_list|()
argument_list|)
expr_stmt|;
name|sb
operator|.
name|append
argument_list|(
literal|", isBulkLoadResult="
argument_list|)
operator|.
name|append
argument_list|(
name|isBulkLoadResult
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|isBulkLoadResult
argument_list|()
condition|)
block|{
name|sb
operator|.
name|append
argument_list|(
literal|", bulkLoadTS="
argument_list|)
operator|.
name|append
argument_list|(
name|getBulkLoadTimestamp
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|sb
operator|.
name|append
argument_list|(
literal|", seqid="
argument_list|)
operator|.
name|append
argument_list|(
name|getMaxSequenceId
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|sb
operator|.
name|append
argument_list|(
literal|", majorCompaction="
argument_list|)
operator|.
name|append
argument_list|(
name|isMajorCompaction
argument_list|()
argument_list|)
expr_stmt|;
return|return
name|sb
operator|.
name|toString
argument_list|()
return|;
block|}
comment|/**    * Gets whether to skip resetting the sequence id for cells.    * @param skipResetSeqId The byte array of boolean.    * @return Whether to skip resetting the sequence id.    */
specifier|private
name|boolean
name|isSkipResetSeqId
parameter_list|(
name|byte
index|[]
name|skipResetSeqId
parameter_list|)
block|{
if|if
condition|(
name|skipResetSeqId
operator|!=
literal|null
operator|&&
name|skipResetSeqId
operator|.
name|length
operator|==
literal|1
condition|)
block|{
return|return
name|Bytes
operator|.
name|toBoolean
argument_list|(
name|skipResetSeqId
argument_list|)
return|;
block|}
return|return
literal|false
return|;
block|}
comment|/**    * @param fs    * @param dir Directory to create file in.    * @return random filename inside passed<code>dir</code>    */
specifier|public
specifier|static
name|Path
name|getUniqueFile
parameter_list|(
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Path
name|dir
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
operator|!
name|fs
operator|.
name|getFileStatus
argument_list|(
name|dir
argument_list|)
operator|.
name|isDirectory
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Expecting "
operator|+
name|dir
operator|.
name|toString
argument_list|()
operator|+
literal|" to be a directory"
argument_list|)
throw|;
block|}
return|return
operator|new
name|Path
argument_list|(
name|dir
argument_list|,
name|UUID
operator|.
name|randomUUID
argument_list|()
operator|.
name|toString
argument_list|()
operator|.
name|replaceAll
argument_list|(
literal|"-"
argument_list|,
literal|""
argument_list|)
argument_list|)
return|;
block|}
specifier|public
name|Long
name|getMinimumTimestamp
parameter_list|()
block|{
return|return
name|getReader
argument_list|()
operator|.
name|timeRange
operator|==
literal|null
condition|?
literal|null
else|:
name|getReader
argument_list|()
operator|.
name|timeRange
operator|.
name|getMin
argument_list|()
return|;
block|}
specifier|public
name|Long
name|getMaximumTimestamp
parameter_list|()
block|{
return|return
name|getReader
argument_list|()
operator|.
name|timeRange
operator|==
literal|null
condition|?
literal|null
else|:
name|getReader
argument_list|()
operator|.
name|timeRange
operator|.
name|getMax
argument_list|()
return|;
block|}
comment|/**    * Gets the approximate mid-point of this file that is optimal for use in splitting it.    * @param comparator Comparator used to compare KVs.    * @return The split point row, or null if splitting is not possible, or reader is null.    */
name|byte
index|[]
name|getFileSplitPoint
parameter_list|(
name|CellComparator
name|comparator
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|this
operator|.
name|reader
operator|==
literal|null
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Storefile "
operator|+
name|this
operator|+
literal|" Reader is null; cannot get split point"
argument_list|)
expr_stmt|;
return|return
literal|null
return|;
block|}
comment|// Get first, last, and mid keys.  Midkey is the key that starts block
comment|// in middle of hfile.  Has column and timestamp.  Need to return just
comment|// the row we want to split on as midkey.
name|Cell
name|midkey
init|=
name|this
operator|.
name|reader
operator|.
name|midkey
argument_list|()
decl_stmt|;
if|if
condition|(
name|midkey
operator|!=
literal|null
condition|)
block|{
name|Cell
name|firstKey
init|=
name|this
operator|.
name|reader
operator|.
name|getFirstKey
argument_list|()
decl_stmt|;
name|Cell
name|lastKey
init|=
name|this
operator|.
name|reader
operator|.
name|getLastKey
argument_list|()
decl_stmt|;
comment|// if the midkey is the same as the first or last keys, we cannot (ever) split this region.
if|if
condition|(
name|comparator
operator|.
name|compareRows
argument_list|(
name|midkey
argument_list|,
name|firstKey
argument_list|)
operator|==
literal|0
operator|||
name|comparator
operator|.
name|compareRows
argument_list|(
name|midkey
argument_list|,
name|lastKey
argument_list|)
operator|==
literal|0
condition|)
block|{
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"cannot split because midkey is the same as first or last row"
argument_list|)
expr_stmt|;
block|}
return|return
literal|null
return|;
block|}
return|return
name|CellUtil
operator|.
name|cloneRow
argument_list|(
name|midkey
argument_list|)
return|;
block|}
return|return
literal|null
return|;
block|}
comment|/**    * Useful comparators for comparing StoreFiles.    */
specifier|public
specifier|abstract
specifier|static
class|class
name|Comparators
block|{
comment|/**      * Comparator that compares based on the Sequence Ids of the      * the StoreFiles. Bulk loads that did not request a seq ID      * are given a seq id of -1; thus, they are placed before all non-      * bulk loads, and bulk loads with sequence Id. Among these files,      * the size is used to determine the ordering, then bulkLoadTime.      * If there are ties, the path name is used as a tie-breaker.      */
specifier|public
specifier|static
specifier|final
name|Comparator
argument_list|<
name|StoreFile
argument_list|>
name|SEQ_ID
init|=
name|Ordering
operator|.
name|compound
argument_list|(
name|ImmutableList
operator|.
name|of
argument_list|(
name|Ordering
operator|.
name|natural
argument_list|()
operator|.
name|onResultOf
argument_list|(
operator|new
name|GetSeqId
argument_list|()
argument_list|)
argument_list|,
name|Ordering
operator|.
name|natural
argument_list|()
operator|.
name|onResultOf
argument_list|(
operator|new
name|GetFileSize
argument_list|()
argument_list|)
operator|.
name|reverse
argument_list|()
argument_list|,
name|Ordering
operator|.
name|natural
argument_list|()
operator|.
name|onResultOf
argument_list|(
operator|new
name|GetBulkTime
argument_list|()
argument_list|)
argument_list|,
name|Ordering
operator|.
name|natural
argument_list|()
operator|.
name|onResultOf
argument_list|(
operator|new
name|GetPathName
argument_list|()
argument_list|)
argument_list|)
argument_list|)
decl_stmt|;
comment|/**      * Comparator for time-aware compaction. SeqId is still the first      *   ordering criterion to maintain MVCC.      */
specifier|public
specifier|static
specifier|final
name|Comparator
argument_list|<
name|StoreFile
argument_list|>
name|SEQ_ID_MAX_TIMESTAMP
init|=
name|Ordering
operator|.
name|compound
argument_list|(
name|ImmutableList
operator|.
name|of
argument_list|(
name|Ordering
operator|.
name|natural
argument_list|()
operator|.
name|onResultOf
argument_list|(
operator|new
name|GetSeqId
argument_list|()
argument_list|)
argument_list|,
name|Ordering
operator|.
name|natural
argument_list|()
operator|.
name|onResultOf
argument_list|(
operator|new
name|GetMaxTimestamp
argument_list|()
argument_list|)
argument_list|,
name|Ordering
operator|.
name|natural
argument_list|()
operator|.
name|onResultOf
argument_list|(
operator|new
name|GetFileSize
argument_list|()
argument_list|)
operator|.
name|reverse
argument_list|()
argument_list|,
name|Ordering
operator|.
name|natural
argument_list|()
operator|.
name|onResultOf
argument_list|(
operator|new
name|GetBulkTime
argument_list|()
argument_list|)
argument_list|,
name|Ordering
operator|.
name|natural
argument_list|()
operator|.
name|onResultOf
argument_list|(
operator|new
name|GetPathName
argument_list|()
argument_list|)
argument_list|)
argument_list|)
decl_stmt|;
specifier|private
specifier|static
class|class
name|GetSeqId
implements|implements
name|Function
argument_list|<
name|StoreFile
argument_list|,
name|Long
argument_list|>
block|{
annotation|@
name|Override
specifier|public
name|Long
name|apply
parameter_list|(
name|StoreFile
name|sf
parameter_list|)
block|{
return|return
name|sf
operator|.
name|getMaxSequenceId
argument_list|()
return|;
block|}
block|}
specifier|private
specifier|static
class|class
name|GetFileSize
implements|implements
name|Function
argument_list|<
name|StoreFile
argument_list|,
name|Long
argument_list|>
block|{
annotation|@
name|Override
specifier|public
name|Long
name|apply
parameter_list|(
name|StoreFile
name|sf
parameter_list|)
block|{
if|if
condition|(
name|sf
operator|.
name|getReader
argument_list|()
operator|!=
literal|null
condition|)
block|{
return|return
name|sf
operator|.
name|getReader
argument_list|()
operator|.
name|length
argument_list|()
return|;
block|}
else|else
block|{
comment|// the reader may be null for the compacted files and if the archiving
comment|// had failed.
return|return
operator|-
literal|1L
return|;
block|}
block|}
block|}
specifier|private
specifier|static
class|class
name|GetBulkTime
implements|implements
name|Function
argument_list|<
name|StoreFile
argument_list|,
name|Long
argument_list|>
block|{
annotation|@
name|Override
specifier|public
name|Long
name|apply
parameter_list|(
name|StoreFile
name|sf
parameter_list|)
block|{
if|if
condition|(
operator|!
name|sf
operator|.
name|isBulkLoadResult
argument_list|()
condition|)
return|return
name|Long
operator|.
name|MAX_VALUE
return|;
return|return
name|sf
operator|.
name|getBulkLoadTimestamp
argument_list|()
return|;
block|}
block|}
specifier|private
specifier|static
class|class
name|GetPathName
implements|implements
name|Function
argument_list|<
name|StoreFile
argument_list|,
name|String
argument_list|>
block|{
annotation|@
name|Override
specifier|public
name|String
name|apply
parameter_list|(
name|StoreFile
name|sf
parameter_list|)
block|{
return|return
name|sf
operator|.
name|getPath
argument_list|()
operator|.
name|getName
argument_list|()
return|;
block|}
block|}
specifier|private
specifier|static
class|class
name|GetMaxTimestamp
implements|implements
name|Function
argument_list|<
name|StoreFile
argument_list|,
name|Long
argument_list|>
block|{
annotation|@
name|Override
specifier|public
name|Long
name|apply
parameter_list|(
name|StoreFile
name|sf
parameter_list|)
block|{
return|return
name|sf
operator|.
name|getMaximumTimestamp
argument_list|()
operator|==
literal|null
condition|?
operator|(
name|Long
operator|)
name|Long
operator|.
name|MAX_VALUE
else|:
name|sf
operator|.
name|getMaximumTimestamp
argument_list|()
return|;
block|}
block|}
block|}
block|}
end_class

end_unit

