begin_unit|revision:0.9.5;language:Java;cregit-version:0.0.1
begin_comment
comment|/**  *  * Licensed to the Apache Software Foundation (ASF) under one  * or more contributor license agreements.  See the NOTICE file  * distributed with this work for additional information  * regarding copyright ownership.  The ASF licenses this file  * to you under the Apache License, Version 2.0 (the  * "License"); you may not use this file except in compliance  * with the License.  You may obtain a copy of the License at  *  *     http://www.apache.org/licenses/LICENSE-2.0  *  * Unless required by applicable law or agreed to in writing, software  * distributed under the License is distributed on an "AS IS" BASIS,  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  * See the License for the specific language governing permissions and  * limitations under the License.  */
end_comment

begin_package
package|package
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
package|;
end_package

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|DataInput
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|net
operator|.
name|InetSocketAddress
import|;
end_import

begin_import
import|import
name|java
operator|.
name|nio
operator|.
name|ByteBuffer
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Arrays
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collection
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Collections
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Comparator
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|SortedSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|UUID
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|atomic
operator|.
name|AtomicBoolean
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|Log
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|logging
operator|.
name|LogFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|classification
operator|.
name|InterfaceAudience
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|conf
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|FileSystem
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|fs
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|CellUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HConstants
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|HDFSBlocksDistribution
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|KeyValue
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|KeyValue
operator|.
name|KVComparator
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|KeyValueUtil
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|client
operator|.
name|Scan
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|FSDataInputStreamWrapper
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|hfile
operator|.
name|BlockType
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|hfile
operator|.
name|CacheConfig
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|hfile
operator|.
name|HFile
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|hfile
operator|.
name|HFileContext
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|hfile
operator|.
name|HFileScanner
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|io
operator|.
name|hfile
operator|.
name|HFileWriterV2
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|regionserver
operator|.
name|compactions
operator|.
name|Compactor
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|BloomFilter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|BloomFilterFactory
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|BloomFilterWriter
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|Bytes
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|ChecksumType
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|hbase
operator|.
name|util
operator|.
name|Writables
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|hadoop
operator|.
name|io
operator|.
name|WritableUtils
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Function
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|base
operator|.
name|Preconditions
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|ImmutableList
import|;
end_import

begin_import
import|import
name|com
operator|.
name|google
operator|.
name|common
operator|.
name|collect
operator|.
name|Ordering
import|;
end_import

begin_comment
comment|/**  * A Store data file.  Stores usually have one or more of these files.  They  * are produced by flushing the memstore to disk.  To  * create, instantiate a writer using {@link StoreFile.WriterBuilder}  * and append data. Be sure to add any metadata before calling close on the  * Writer (Use the appendMetadata convenience methods). On close, a StoreFile  * is sitting in the Filesystem.  To refer to it, create a StoreFile instance  * passing filesystem and path.  To read, call {@link #createReader()}.  *<p>StoreFiles may also reference store files in another Store.  *  * The reason for this weird pattern where you use a different instance for the  * writer and a reader is that we write once but read a lot more.  */
end_comment

begin_class
annotation|@
name|InterfaceAudience
operator|.
name|LimitedPrivate
argument_list|(
literal|"Coprocessor"
argument_list|)
specifier|public
class|class
name|StoreFile
block|{
specifier|static
specifier|final
name|Log
name|LOG
init|=
name|LogFactory
operator|.
name|getLog
argument_list|(
name|StoreFile
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
comment|// Keys for fileinfo values in HFile
comment|/** Max Sequence ID in FileInfo */
specifier|public
specifier|static
specifier|final
name|byte
index|[]
name|MAX_SEQ_ID_KEY
init|=
name|Bytes
operator|.
name|toBytes
argument_list|(
literal|"MAX_SEQ_ID_KEY"
argument_list|)
decl_stmt|;
comment|/** Major compaction flag in FileInfo */
specifier|public
specifier|static
specifier|final
name|byte
index|[]
name|MAJOR_COMPACTION_KEY
init|=
name|Bytes
operator|.
name|toBytes
argument_list|(
literal|"MAJOR_COMPACTION_KEY"
argument_list|)
decl_stmt|;
comment|/** Minor compaction flag in FileInfo */
specifier|public
specifier|static
specifier|final
name|byte
index|[]
name|EXCLUDE_FROM_MINOR_COMPACTION_KEY
init|=
name|Bytes
operator|.
name|toBytes
argument_list|(
literal|"EXCLUDE_FROM_MINOR_COMPACTION"
argument_list|)
decl_stmt|;
comment|/** Bloom filter Type in FileInfo */
specifier|public
specifier|static
specifier|final
name|byte
index|[]
name|BLOOM_FILTER_TYPE_KEY
init|=
name|Bytes
operator|.
name|toBytes
argument_list|(
literal|"BLOOM_FILTER_TYPE"
argument_list|)
decl_stmt|;
comment|/** Delete Family Count in FileInfo */
specifier|public
specifier|static
specifier|final
name|byte
index|[]
name|DELETE_FAMILY_COUNT
init|=
name|Bytes
operator|.
name|toBytes
argument_list|(
literal|"DELETE_FAMILY_COUNT"
argument_list|)
decl_stmt|;
comment|/** Last Bloom filter key in FileInfo */
specifier|private
specifier|static
specifier|final
name|byte
index|[]
name|LAST_BLOOM_KEY
init|=
name|Bytes
operator|.
name|toBytes
argument_list|(
literal|"LAST_BLOOM_KEY"
argument_list|)
decl_stmt|;
comment|/** Key for Timerange information in metadata*/
specifier|public
specifier|static
specifier|final
name|byte
index|[]
name|TIMERANGE_KEY
init|=
name|Bytes
operator|.
name|toBytes
argument_list|(
literal|"TIMERANGE"
argument_list|)
decl_stmt|;
comment|/** Key for timestamp of earliest-put in metadata*/
specifier|public
specifier|static
specifier|final
name|byte
index|[]
name|EARLIEST_PUT_TS
init|=
name|Bytes
operator|.
name|toBytes
argument_list|(
literal|"EARLIEST_PUT_TS"
argument_list|)
decl_stmt|;
specifier|private
specifier|final
name|StoreFileInfo
name|fileInfo
decl_stmt|;
specifier|private
specifier|final
name|FileSystem
name|fs
decl_stmt|;
comment|// Block cache configuration and reference.
specifier|private
specifier|final
name|CacheConfig
name|cacheConf
decl_stmt|;
comment|// Keys for metadata stored in backing HFile.
comment|// Set when we obtain a Reader.
specifier|private
name|long
name|sequenceid
init|=
operator|-
literal|1
decl_stmt|;
comment|// max of the MemstoreTS in the KV's in this store
comment|// Set when we obtain a Reader.
specifier|private
name|long
name|maxMemstoreTS
init|=
operator|-
literal|1
decl_stmt|;
specifier|public
name|long
name|getMaxMemstoreTS
parameter_list|()
block|{
return|return
name|maxMemstoreTS
return|;
block|}
specifier|public
name|void
name|setMaxMemstoreTS
parameter_list|(
name|long
name|maxMemstoreTS
parameter_list|)
block|{
name|this
operator|.
name|maxMemstoreTS
operator|=
name|maxMemstoreTS
expr_stmt|;
block|}
comment|// If true, this file was product of a major compaction.  Its then set
comment|// whenever you get a Reader.
specifier|private
name|AtomicBoolean
name|majorCompaction
init|=
literal|null
decl_stmt|;
comment|// If true, this file should not be included in minor compactions.
comment|// It's set whenever you get a Reader.
specifier|private
name|boolean
name|excludeFromMinorCompaction
init|=
literal|false
decl_stmt|;
comment|/** Meta key set when store file is a result of a bulk load */
specifier|public
specifier|static
specifier|final
name|byte
index|[]
name|BULKLOAD_TASK_KEY
init|=
name|Bytes
operator|.
name|toBytes
argument_list|(
literal|"BULKLOAD_SOURCE_TASK"
argument_list|)
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|byte
index|[]
name|BULKLOAD_TIME_KEY
init|=
name|Bytes
operator|.
name|toBytes
argument_list|(
literal|"BULKLOAD_TIMESTAMP"
argument_list|)
decl_stmt|;
comment|/**    * Map of the metadata entries in the corresponding HFile    */
specifier|private
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|byte
index|[]
argument_list|>
name|metadataMap
decl_stmt|;
comment|// StoreFile.Reader
specifier|private
specifier|volatile
name|Reader
name|reader
decl_stmt|;
comment|/**    * Bloom filter type specified in column family configuration. Does not    * necessarily correspond to the Bloom filter type present in the HFile.    */
specifier|private
specifier|final
name|BloomType
name|cfBloomType
decl_stmt|;
comment|// the last modification time stamp
specifier|private
name|long
name|modificationTimeStamp
init|=
literal|0L
decl_stmt|;
comment|/**    * Constructor, loads a reader and it's indices, etc. May allocate a    * substantial amount of ram depending on the underlying files (10-20MB?).    *    * @param fs  The current file system to use.    * @param p  The path of the file.    * @param conf  The current configuration.    * @param cacheConf  The cache configuration and block cache reference.    * @param cfBloomType The bloom type to use for this store file as specified    *          by column family configuration. This may or may not be the same    *          as the Bloom filter type actually present in the HFile, because    *          column family configuration might change. If this is    *          {@link BloomType#NONE}, the existing Bloom filter is ignored.    * @throws IOException When opening the reader fails.    */
specifier|public
name|StoreFile
parameter_list|(
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Path
name|p
parameter_list|,
specifier|final
name|Configuration
name|conf
parameter_list|,
specifier|final
name|CacheConfig
name|cacheConf
parameter_list|,
specifier|final
name|BloomType
name|cfBloomType
parameter_list|)
throws|throws
name|IOException
block|{
name|this
argument_list|(
name|fs
argument_list|,
operator|new
name|StoreFileInfo
argument_list|(
name|conf
argument_list|,
name|fs
argument_list|,
name|p
argument_list|)
argument_list|,
name|conf
argument_list|,
name|cacheConf
argument_list|,
name|cfBloomType
argument_list|)
expr_stmt|;
block|}
comment|/**    * Constructor, loads a reader and it's indices, etc. May allocate a    * substantial amount of ram depending on the underlying files (10-20MB?).    *    * @param fs  The current file system to use.    * @param fileInfo  The store file information.    * @param conf  The current configuration.    * @param cacheConf  The cache configuration and block cache reference.    * @param cfBloomType The bloom type to use for this store file as specified    *          by column family configuration. This may or may not be the same    *          as the Bloom filter type actually present in the HFile, because    *          column family configuration might change. If this is    *          {@link BloomType#NONE}, the existing Bloom filter is ignored.    * @throws IOException When opening the reader fails.    */
specifier|public
name|StoreFile
parameter_list|(
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|StoreFileInfo
name|fileInfo
parameter_list|,
specifier|final
name|Configuration
name|conf
parameter_list|,
specifier|final
name|CacheConfig
name|cacheConf
parameter_list|,
specifier|final
name|BloomType
name|cfBloomType
parameter_list|)
throws|throws
name|IOException
block|{
name|this
operator|.
name|fs
operator|=
name|fs
expr_stmt|;
name|this
operator|.
name|fileInfo
operator|=
name|fileInfo
expr_stmt|;
name|this
operator|.
name|cacheConf
operator|=
name|cacheConf
expr_stmt|;
if|if
condition|(
name|BloomFilterFactory
operator|.
name|isGeneralBloomEnabled
argument_list|(
name|conf
argument_list|)
condition|)
block|{
name|this
operator|.
name|cfBloomType
operator|=
name|cfBloomType
expr_stmt|;
block|}
else|else
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Ignoring bloom filter check for file "
operator|+
name|this
operator|.
name|getPath
argument_list|()
operator|+
literal|": "
operator|+
literal|"cfBloomType="
operator|+
name|cfBloomType
operator|+
literal|" (disabled in config)"
argument_list|)
expr_stmt|;
name|this
operator|.
name|cfBloomType
operator|=
name|BloomType
operator|.
name|NONE
expr_stmt|;
block|}
comment|// cache the modification time stamp of this store file
name|this
operator|.
name|modificationTimeStamp
operator|=
name|fileInfo
operator|.
name|getModificationTime
argument_list|()
expr_stmt|;
block|}
comment|/**    * @return the StoreFile object associated to this StoreFile.    *         null if the StoreFile is not a reference.    */
specifier|public
name|StoreFileInfo
name|getFileInfo
parameter_list|()
block|{
return|return
name|this
operator|.
name|fileInfo
return|;
block|}
comment|/**    * @return Path or null if this StoreFile was made with a Stream.    */
specifier|public
name|Path
name|getPath
parameter_list|()
block|{
return|return
name|this
operator|.
name|fileInfo
operator|.
name|getPath
argument_list|()
return|;
block|}
comment|/**    * @return Returns the qualified path of this StoreFile    */
specifier|public
name|Path
name|getQualifiedPath
parameter_list|()
block|{
return|return
name|this
operator|.
name|fileInfo
operator|.
name|getPath
argument_list|()
operator|.
name|makeQualified
argument_list|(
name|fs
argument_list|)
return|;
block|}
comment|/**    * @return True if this is a StoreFile Reference; call after {@link #open()}    * else may get wrong answer.    */
specifier|public
name|boolean
name|isReference
parameter_list|()
block|{
return|return
name|this
operator|.
name|fileInfo
operator|.
name|isReference
argument_list|()
return|;
block|}
comment|/**    * @return True if this file was made by a major compaction.    */
specifier|public
name|boolean
name|isMajorCompaction
parameter_list|()
block|{
if|if
condition|(
name|this
operator|.
name|majorCompaction
operator|==
literal|null
condition|)
block|{
throw|throw
operator|new
name|NullPointerException
argument_list|(
literal|"This has not been set yet"
argument_list|)
throw|;
block|}
return|return
name|this
operator|.
name|majorCompaction
operator|.
name|get
argument_list|()
return|;
block|}
comment|/**    * @return True if this file should not be part of a minor compaction.    */
specifier|public
name|boolean
name|excludeFromMinorCompaction
parameter_list|()
block|{
return|return
name|this
operator|.
name|excludeFromMinorCompaction
return|;
block|}
comment|/**    * @return This files maximum edit sequence id.    */
specifier|public
name|long
name|getMaxSequenceId
parameter_list|()
block|{
return|return
name|this
operator|.
name|sequenceid
return|;
block|}
specifier|public
name|long
name|getModificationTimeStamp
parameter_list|()
block|{
return|return
name|modificationTimeStamp
return|;
block|}
specifier|public
name|byte
index|[]
name|getMetadataValue
parameter_list|(
name|byte
index|[]
name|key
parameter_list|)
block|{
return|return
name|metadataMap
operator|.
name|get
argument_list|(
name|key
argument_list|)
return|;
block|}
comment|/**    * Return the largest memstoreTS found across all storefiles in    * the given list. Store files that were created by a mapreduce    * bulk load are ignored, as they do not correspond to any specific    * put operation, and thus do not have a memstoreTS associated with them.    * @return 0 if no non-bulk-load files are provided or, this is Store that    * does not yet have any store files.    */
specifier|public
specifier|static
name|long
name|getMaxMemstoreTSInList
parameter_list|(
name|Collection
argument_list|<
name|StoreFile
argument_list|>
name|sfs
parameter_list|)
block|{
name|long
name|max
init|=
literal|0
decl_stmt|;
for|for
control|(
name|StoreFile
name|sf
range|:
name|sfs
control|)
block|{
if|if
condition|(
operator|!
name|sf
operator|.
name|isBulkLoadResult
argument_list|()
condition|)
block|{
name|max
operator|=
name|Math
operator|.
name|max
argument_list|(
name|max
argument_list|,
name|sf
operator|.
name|getMaxMemstoreTS
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|max
return|;
block|}
comment|/**    * Return the highest sequence ID found across all storefiles in    * the given list.    * @param sfs    * @return 0 if no non-bulk-load files are provided or, this is Store that    * does not yet have any store files.    */
specifier|public
specifier|static
name|long
name|getMaxSequenceIdInList
parameter_list|(
name|Collection
argument_list|<
name|StoreFile
argument_list|>
name|sfs
parameter_list|)
block|{
name|long
name|max
init|=
literal|0
decl_stmt|;
for|for
control|(
name|StoreFile
name|sf
range|:
name|sfs
control|)
block|{
name|max
operator|=
name|Math
operator|.
name|max
argument_list|(
name|max
argument_list|,
name|sf
operator|.
name|getMaxSequenceId
argument_list|()
argument_list|)
expr_stmt|;
block|}
return|return
name|max
return|;
block|}
comment|/**    * @return true if this storefile was created by HFileOutputFormat    * for a bulk load.    */
name|boolean
name|isBulkLoadResult
parameter_list|()
block|{
return|return
name|metadataMap
operator|.
name|containsKey
argument_list|(
name|BULKLOAD_TIME_KEY
argument_list|)
return|;
block|}
comment|/**    * Return the timestamp at which this bulk load file was generated.    */
specifier|public
name|long
name|getBulkLoadTimestamp
parameter_list|()
block|{
return|return
name|Bytes
operator|.
name|toLong
argument_list|(
name|metadataMap
operator|.
name|get
argument_list|(
name|BULKLOAD_TIME_KEY
argument_list|)
argument_list|)
return|;
block|}
comment|/**    * @return the cached value of HDFS blocks distribution. The cached value is    * calculated when store file is opened.    */
specifier|public
name|HDFSBlocksDistribution
name|getHDFSBlockDistribution
parameter_list|()
block|{
return|return
name|this
operator|.
name|fileInfo
operator|.
name|getHDFSBlockDistribution
argument_list|()
return|;
block|}
comment|/**    * Opens reader on this store file.  Called by Constructor.    * @return Reader for the store file.    * @throws IOException    * @see #closeReader(boolean)    */
specifier|private
name|Reader
name|open
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|this
operator|.
name|reader
operator|!=
literal|null
condition|)
block|{
throw|throw
operator|new
name|IllegalAccessError
argument_list|(
literal|"Already open"
argument_list|)
throw|;
block|}
comment|// Open the StoreFile.Reader
name|this
operator|.
name|reader
operator|=
name|fileInfo
operator|.
name|open
argument_list|(
name|this
operator|.
name|fs
argument_list|,
name|this
operator|.
name|cacheConf
argument_list|)
expr_stmt|;
comment|// Load up indices and fileinfo. This also loads Bloom filter type.
name|metadataMap
operator|=
name|Collections
operator|.
name|unmodifiableMap
argument_list|(
name|this
operator|.
name|reader
operator|.
name|loadFileInfo
argument_list|()
argument_list|)
expr_stmt|;
comment|// Read in our metadata.
name|byte
index|[]
name|b
init|=
name|metadataMap
operator|.
name|get
argument_list|(
name|MAX_SEQ_ID_KEY
argument_list|)
decl_stmt|;
if|if
condition|(
name|b
operator|!=
literal|null
condition|)
block|{
comment|// By convention, if halfhfile, top half has a sequence number> bottom
comment|// half. Thats why we add one in below. Its done for case the two halves
comment|// are ever merged back together --rare.  Without it, on open of store,
comment|// since store files are distinguished by sequence id, the one half would
comment|// subsume the other.
name|this
operator|.
name|sequenceid
operator|=
name|Bytes
operator|.
name|toLong
argument_list|(
name|b
argument_list|)
expr_stmt|;
if|if
condition|(
name|fileInfo
operator|.
name|isTopReference
argument_list|()
condition|)
block|{
name|this
operator|.
name|sequenceid
operator|+=
literal|1
expr_stmt|;
block|}
block|}
if|if
condition|(
name|isBulkLoadResult
argument_list|()
condition|)
block|{
comment|// generate the sequenceId from the fileName
comment|// fileName is of the form<randomName>_SeqId_<id-when-loaded>_
name|String
name|fileName
init|=
name|this
operator|.
name|getPath
argument_list|()
operator|.
name|getName
argument_list|()
decl_stmt|;
name|int
name|startPos
init|=
name|fileName
operator|.
name|indexOf
argument_list|(
literal|"SeqId_"
argument_list|)
decl_stmt|;
if|if
condition|(
name|startPos
operator|!=
operator|-
literal|1
condition|)
block|{
name|this
operator|.
name|sequenceid
operator|=
name|Long
operator|.
name|parseLong
argument_list|(
name|fileName
operator|.
name|substring
argument_list|(
name|startPos
operator|+
literal|6
argument_list|,
name|fileName
operator|.
name|indexOf
argument_list|(
literal|'_'
argument_list|,
name|startPos
operator|+
literal|6
argument_list|)
argument_list|)
argument_list|)
expr_stmt|;
comment|// Handle reference files as done above.
if|if
condition|(
name|fileInfo
operator|.
name|isTopReference
argument_list|()
condition|)
block|{
name|this
operator|.
name|sequenceid
operator|+=
literal|1
expr_stmt|;
block|}
block|}
name|this
operator|.
name|reader
operator|.
name|setBulkLoaded
argument_list|(
literal|true
argument_list|)
expr_stmt|;
block|}
name|this
operator|.
name|reader
operator|.
name|setSequenceID
argument_list|(
name|this
operator|.
name|sequenceid
argument_list|)
expr_stmt|;
name|b
operator|=
name|metadataMap
operator|.
name|get
argument_list|(
name|HFileWriterV2
operator|.
name|MAX_MEMSTORE_TS_KEY
argument_list|)
expr_stmt|;
if|if
condition|(
name|b
operator|!=
literal|null
condition|)
block|{
name|this
operator|.
name|maxMemstoreTS
operator|=
name|Bytes
operator|.
name|toLong
argument_list|(
name|b
argument_list|)
expr_stmt|;
block|}
name|b
operator|=
name|metadataMap
operator|.
name|get
argument_list|(
name|MAJOR_COMPACTION_KEY
argument_list|)
expr_stmt|;
if|if
condition|(
name|b
operator|!=
literal|null
condition|)
block|{
name|boolean
name|mc
init|=
name|Bytes
operator|.
name|toBoolean
argument_list|(
name|b
argument_list|)
decl_stmt|;
if|if
condition|(
name|this
operator|.
name|majorCompaction
operator|==
literal|null
condition|)
block|{
name|this
operator|.
name|majorCompaction
operator|=
operator|new
name|AtomicBoolean
argument_list|(
name|mc
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|this
operator|.
name|majorCompaction
operator|.
name|set
argument_list|(
name|mc
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
comment|// Presume it is not major compacted if it doesn't explicity say so
comment|// HFileOutputFormat explicitly sets the major compacted key.
name|this
operator|.
name|majorCompaction
operator|=
operator|new
name|AtomicBoolean
argument_list|(
literal|false
argument_list|)
expr_stmt|;
block|}
name|b
operator|=
name|metadataMap
operator|.
name|get
argument_list|(
name|EXCLUDE_FROM_MINOR_COMPACTION_KEY
argument_list|)
expr_stmt|;
name|this
operator|.
name|excludeFromMinorCompaction
operator|=
operator|(
name|b
operator|!=
literal|null
operator|&&
name|Bytes
operator|.
name|toBoolean
argument_list|(
name|b
argument_list|)
operator|)
expr_stmt|;
name|BloomType
name|hfileBloomType
init|=
name|reader
operator|.
name|getBloomFilterType
argument_list|()
decl_stmt|;
if|if
condition|(
name|cfBloomType
operator|!=
name|BloomType
operator|.
name|NONE
condition|)
block|{
name|reader
operator|.
name|loadBloomfilter
argument_list|(
name|BlockType
operator|.
name|GENERAL_BLOOM_META
argument_list|)
expr_stmt|;
if|if
condition|(
name|hfileBloomType
operator|!=
name|cfBloomType
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"HFile Bloom filter type for "
operator|+
name|reader
operator|.
name|getHFileReader
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|": "
operator|+
name|hfileBloomType
operator|+
literal|", but "
operator|+
name|cfBloomType
operator|+
literal|" specified in column family "
operator|+
literal|"configuration"
argument_list|)
expr_stmt|;
block|}
block|}
elseif|else
if|if
condition|(
name|hfileBloomType
operator|!=
name|BloomType
operator|.
name|NONE
condition|)
block|{
name|LOG
operator|.
name|info
argument_list|(
literal|"Bloom filter turned off by CF config for "
operator|+
name|reader
operator|.
name|getHFileReader
argument_list|()
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
block|}
comment|// load delete family bloom filter
name|reader
operator|.
name|loadBloomfilter
argument_list|(
name|BlockType
operator|.
name|DELETE_FAMILY_BLOOM_META
argument_list|)
expr_stmt|;
try|try
block|{
name|byte
index|[]
name|timerangeBytes
init|=
name|metadataMap
operator|.
name|get
argument_list|(
name|TIMERANGE_KEY
argument_list|)
decl_stmt|;
if|if
condition|(
name|timerangeBytes
operator|!=
literal|null
condition|)
block|{
name|this
operator|.
name|reader
operator|.
name|timeRangeTracker
operator|=
operator|new
name|TimeRangeTracker
argument_list|()
expr_stmt|;
name|Writables
operator|.
name|copyWritable
argument_list|(
name|timerangeBytes
argument_list|,
name|this
operator|.
name|reader
operator|.
name|timeRangeTracker
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|IllegalArgumentException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Error reading timestamp range data from meta -- "
operator|+
literal|"proceeding without"
argument_list|,
name|e
argument_list|)
expr_stmt|;
name|this
operator|.
name|reader
operator|.
name|timeRangeTracker
operator|=
literal|null
expr_stmt|;
block|}
return|return
name|this
operator|.
name|reader
return|;
block|}
comment|/**    * @return Reader for StoreFile. creates if necessary    * @throws IOException    */
specifier|public
name|Reader
name|createReader
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|this
operator|.
name|reader
operator|==
literal|null
condition|)
block|{
try|try
block|{
name|this
operator|.
name|reader
operator|=
name|open
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
try|try
block|{
name|this
operator|.
name|closeReader
argument_list|(
literal|true
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|ee
parameter_list|)
block|{         }
throw|throw
name|e
throw|;
block|}
block|}
return|return
name|this
operator|.
name|reader
return|;
block|}
comment|/**    * @return Current reader.  Must call createReader first else returns null.    * @see #createReader()    */
specifier|public
name|Reader
name|getReader
parameter_list|()
block|{
return|return
name|this
operator|.
name|reader
return|;
block|}
comment|/**    * @param evictOnClose whether to evict blocks belonging to this file    * @throws IOException    */
specifier|public
specifier|synchronized
name|void
name|closeReader
parameter_list|(
name|boolean
name|evictOnClose
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|this
operator|.
name|reader
operator|!=
literal|null
condition|)
block|{
name|this
operator|.
name|reader
operator|.
name|close
argument_list|(
name|evictOnClose
argument_list|)
expr_stmt|;
name|this
operator|.
name|reader
operator|=
literal|null
expr_stmt|;
block|}
block|}
comment|/**    * Delete this file    * @throws IOException    */
specifier|public
name|void
name|deleteReader
parameter_list|()
throws|throws
name|IOException
block|{
name|closeReader
argument_list|(
literal|true
argument_list|)
expr_stmt|;
name|this
operator|.
name|fs
operator|.
name|delete
argument_list|(
name|getPath
argument_list|()
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|String
name|toString
parameter_list|()
block|{
return|return
name|this
operator|.
name|fileInfo
operator|.
name|toString
argument_list|()
return|;
block|}
comment|/**    * @return a length description of this StoreFile, suitable for debug output    */
specifier|public
name|String
name|toStringDetailed
parameter_list|()
block|{
name|StringBuilder
name|sb
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
name|sb
operator|.
name|append
argument_list|(
name|this
operator|.
name|getPath
argument_list|()
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
name|sb
operator|.
name|append
argument_list|(
literal|", isReference="
argument_list|)
operator|.
name|append
argument_list|(
name|isReference
argument_list|()
argument_list|)
expr_stmt|;
name|sb
operator|.
name|append
argument_list|(
literal|", isBulkLoadResult="
argument_list|)
operator|.
name|append
argument_list|(
name|isBulkLoadResult
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|isBulkLoadResult
argument_list|()
condition|)
block|{
name|sb
operator|.
name|append
argument_list|(
literal|", bulkLoadTS="
argument_list|)
operator|.
name|append
argument_list|(
name|getBulkLoadTimestamp
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|sb
operator|.
name|append
argument_list|(
literal|", seqid="
argument_list|)
operator|.
name|append
argument_list|(
name|getMaxSequenceId
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|sb
operator|.
name|append
argument_list|(
literal|", majorCompaction="
argument_list|)
operator|.
name|append
argument_list|(
name|isMajorCompaction
argument_list|()
argument_list|)
expr_stmt|;
return|return
name|sb
operator|.
name|toString
argument_list|()
return|;
block|}
specifier|public
specifier|static
class|class
name|WriterBuilder
block|{
specifier|private
specifier|final
name|Configuration
name|conf
decl_stmt|;
specifier|private
specifier|final
name|CacheConfig
name|cacheConf
decl_stmt|;
specifier|private
specifier|final
name|FileSystem
name|fs
decl_stmt|;
specifier|private
name|KeyValue
operator|.
name|KVComparator
name|comparator
init|=
name|KeyValue
operator|.
name|COMPARATOR
decl_stmt|;
specifier|private
name|BloomType
name|bloomType
init|=
name|BloomType
operator|.
name|NONE
decl_stmt|;
specifier|private
name|long
name|maxKeyCount
init|=
literal|0
decl_stmt|;
specifier|private
name|Path
name|dir
decl_stmt|;
specifier|private
name|Path
name|filePath
decl_stmt|;
specifier|private
name|InetSocketAddress
index|[]
name|favoredNodes
decl_stmt|;
specifier|private
name|HFileContext
name|fileContext
decl_stmt|;
specifier|public
name|WriterBuilder
parameter_list|(
name|Configuration
name|conf
parameter_list|,
name|CacheConfig
name|cacheConf
parameter_list|,
name|FileSystem
name|fs
parameter_list|)
block|{
name|this
operator|.
name|conf
operator|=
name|conf
expr_stmt|;
name|this
operator|.
name|cacheConf
operator|=
name|cacheConf
expr_stmt|;
name|this
operator|.
name|fs
operator|=
name|fs
expr_stmt|;
block|}
comment|/**      * Use either this method or {@link #withFilePath}, but not both.      * @param dir Path to column family directory. The directory is created if      *          does not exist. The file is given a unique name within this      *          directory.      * @return this (for chained invocation)      */
specifier|public
name|WriterBuilder
name|withOutputDir
parameter_list|(
name|Path
name|dir
parameter_list|)
block|{
name|Preconditions
operator|.
name|checkNotNull
argument_list|(
name|dir
argument_list|)
expr_stmt|;
name|this
operator|.
name|dir
operator|=
name|dir
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**      * Use either this method or {@link #withOutputDir}, but not both.      * @param filePath the StoreFile path to write      * @return this (for chained invocation)      */
specifier|public
name|WriterBuilder
name|withFilePath
parameter_list|(
name|Path
name|filePath
parameter_list|)
block|{
name|Preconditions
operator|.
name|checkNotNull
argument_list|(
name|filePath
argument_list|)
expr_stmt|;
name|this
operator|.
name|filePath
operator|=
name|filePath
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**      * @param favoredNodes an array of favored nodes or possibly null      * @return this (for chained invocation)      */
specifier|public
name|WriterBuilder
name|withFavoredNodes
parameter_list|(
name|InetSocketAddress
index|[]
name|favoredNodes
parameter_list|)
block|{
name|this
operator|.
name|favoredNodes
operator|=
name|favoredNodes
expr_stmt|;
return|return
name|this
return|;
block|}
specifier|public
name|WriterBuilder
name|withComparator
parameter_list|(
name|KeyValue
operator|.
name|KVComparator
name|comparator
parameter_list|)
block|{
name|Preconditions
operator|.
name|checkNotNull
argument_list|(
name|comparator
argument_list|)
expr_stmt|;
name|this
operator|.
name|comparator
operator|=
name|comparator
expr_stmt|;
return|return
name|this
return|;
block|}
specifier|public
name|WriterBuilder
name|withBloomType
parameter_list|(
name|BloomType
name|bloomType
parameter_list|)
block|{
name|Preconditions
operator|.
name|checkNotNull
argument_list|(
name|bloomType
argument_list|)
expr_stmt|;
name|this
operator|.
name|bloomType
operator|=
name|bloomType
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**      * @param maxKeyCount estimated maximum number of keys we expect to add      * @return this (for chained invocation)      */
specifier|public
name|WriterBuilder
name|withMaxKeyCount
parameter_list|(
name|long
name|maxKeyCount
parameter_list|)
block|{
name|this
operator|.
name|maxKeyCount
operator|=
name|maxKeyCount
expr_stmt|;
return|return
name|this
return|;
block|}
specifier|public
name|WriterBuilder
name|withFileContext
parameter_list|(
name|HFileContext
name|fileContext
parameter_list|)
block|{
name|this
operator|.
name|fileContext
operator|=
name|fileContext
expr_stmt|;
return|return
name|this
return|;
block|}
comment|/**      * Create a store file writer. Client is responsible for closing file when      * done. If metadata, add BEFORE closing using      * {@link Writer#appendMetadata}.      */
specifier|public
name|Writer
name|build
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
operator|(
name|dir
operator|==
literal|null
condition|?
literal|0
else|:
literal|1
operator|)
operator|+
operator|(
name|filePath
operator|==
literal|null
condition|?
literal|0
else|:
literal|1
operator|)
operator|!=
literal|1
condition|)
block|{
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"Either specify parent directory "
operator|+
literal|"or file path"
argument_list|)
throw|;
block|}
if|if
condition|(
name|dir
operator|==
literal|null
condition|)
block|{
name|dir
operator|=
name|filePath
operator|.
name|getParent
argument_list|()
expr_stmt|;
block|}
if|if
condition|(
operator|!
name|fs
operator|.
name|exists
argument_list|(
name|dir
argument_list|)
condition|)
block|{
name|fs
operator|.
name|mkdirs
argument_list|(
name|dir
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|filePath
operator|==
literal|null
condition|)
block|{
name|filePath
operator|=
name|getUniqueFile
argument_list|(
name|fs
argument_list|,
name|dir
argument_list|)
expr_stmt|;
if|if
condition|(
operator|!
name|BloomFilterFactory
operator|.
name|isGeneralBloomEnabled
argument_list|(
name|conf
argument_list|)
condition|)
block|{
name|bloomType
operator|=
name|BloomType
operator|.
name|NONE
expr_stmt|;
block|}
block|}
if|if
condition|(
name|comparator
operator|==
literal|null
condition|)
block|{
name|comparator
operator|=
name|KeyValue
operator|.
name|COMPARATOR
expr_stmt|;
block|}
return|return
operator|new
name|Writer
argument_list|(
name|fs
argument_list|,
name|filePath
argument_list|,
name|conf
argument_list|,
name|cacheConf
argument_list|,
name|comparator
argument_list|,
name|bloomType
argument_list|,
name|maxKeyCount
argument_list|,
name|favoredNodes
argument_list|,
name|fileContext
argument_list|)
return|;
block|}
block|}
comment|/**    * @param fs    * @param dir Directory to create file in.    * @return random filename inside passed<code>dir</code>    */
specifier|public
specifier|static
name|Path
name|getUniqueFile
parameter_list|(
specifier|final
name|FileSystem
name|fs
parameter_list|,
specifier|final
name|Path
name|dir
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
operator|!
name|fs
operator|.
name|getFileStatus
argument_list|(
name|dir
argument_list|)
operator|.
name|isDirectory
argument_list|()
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Expecting "
operator|+
name|dir
operator|.
name|toString
argument_list|()
operator|+
literal|" to be a directory"
argument_list|)
throw|;
block|}
return|return
operator|new
name|Path
argument_list|(
name|dir
argument_list|,
name|UUID
operator|.
name|randomUUID
argument_list|()
operator|.
name|toString
argument_list|()
operator|.
name|replaceAll
argument_list|(
literal|"-"
argument_list|,
literal|""
argument_list|)
argument_list|)
return|;
block|}
specifier|public
name|Long
name|getMinimumTimestamp
parameter_list|()
block|{
return|return
operator|(
name|getReader
argument_list|()
operator|.
name|timeRangeTracker
operator|==
literal|null
operator|)
condition|?
literal|null
else|:
name|getReader
argument_list|()
operator|.
name|timeRangeTracker
operator|.
name|getMinimumTimestamp
argument_list|()
return|;
block|}
comment|/**    * Gets the approximate mid-point of this file that is optimal for use in splitting it.    * @param comparator Comparator used to compare KVs.    * @return The split point row, or null if splitting is not possible, or reader is null.    */
annotation|@
name|SuppressWarnings
argument_list|(
literal|"deprecation"
argument_list|)
name|byte
index|[]
name|getFileSplitPoint
parameter_list|(
name|KVComparator
name|comparator
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|this
operator|.
name|reader
operator|==
literal|null
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Storefile "
operator|+
name|this
operator|+
literal|" Reader is null; cannot get split point"
argument_list|)
expr_stmt|;
return|return
literal|null
return|;
block|}
comment|// Get first, last, and mid keys.  Midkey is the key that starts block
comment|// in middle of hfile.  Has column and timestamp.  Need to return just
comment|// the row we want to split on as midkey.
name|byte
index|[]
name|midkey
init|=
name|this
operator|.
name|reader
operator|.
name|midkey
argument_list|()
decl_stmt|;
if|if
condition|(
name|midkey
operator|!=
literal|null
condition|)
block|{
name|KeyValue
name|mk
init|=
name|KeyValue
operator|.
name|createKeyValueFromKey
argument_list|(
name|midkey
argument_list|,
literal|0
argument_list|,
name|midkey
operator|.
name|length
argument_list|)
decl_stmt|;
name|byte
index|[]
name|fk
init|=
name|this
operator|.
name|reader
operator|.
name|getFirstKey
argument_list|()
decl_stmt|;
name|KeyValue
name|firstKey
init|=
name|KeyValue
operator|.
name|createKeyValueFromKey
argument_list|(
name|fk
argument_list|,
literal|0
argument_list|,
name|fk
operator|.
name|length
argument_list|)
decl_stmt|;
name|byte
index|[]
name|lk
init|=
name|this
operator|.
name|reader
operator|.
name|getLastKey
argument_list|()
decl_stmt|;
name|KeyValue
name|lastKey
init|=
name|KeyValue
operator|.
name|createKeyValueFromKey
argument_list|(
name|lk
argument_list|,
literal|0
argument_list|,
name|lk
operator|.
name|length
argument_list|)
decl_stmt|;
comment|// if the midkey is the same as the first or last keys, we cannot (ever) split this region.
if|if
condition|(
name|comparator
operator|.
name|compareRows
argument_list|(
name|mk
argument_list|,
name|firstKey
argument_list|)
operator|==
literal|0
operator|||
name|comparator
operator|.
name|compareRows
argument_list|(
name|mk
argument_list|,
name|lastKey
argument_list|)
operator|==
literal|0
condition|)
block|{
if|if
condition|(
name|LOG
operator|.
name|isDebugEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|debug
argument_list|(
literal|"cannot split because midkey is the same as first or last row"
argument_list|)
expr_stmt|;
block|}
return|return
literal|null
return|;
block|}
return|return
name|mk
operator|.
name|getRow
argument_list|()
return|;
block|}
return|return
literal|null
return|;
block|}
comment|/**    * A StoreFile writer.  Use this to read/write HBase Store Files. It is package    * local because it is an implementation detail of the HBase regionserver.    */
specifier|public
specifier|static
class|class
name|Writer
implements|implements
name|Compactor
operator|.
name|CellSink
block|{
specifier|private
specifier|final
name|BloomFilterWriter
name|generalBloomFilterWriter
decl_stmt|;
specifier|private
specifier|final
name|BloomFilterWriter
name|deleteFamilyBloomFilterWriter
decl_stmt|;
specifier|private
specifier|final
name|BloomType
name|bloomType
decl_stmt|;
specifier|private
name|byte
index|[]
name|lastBloomKey
decl_stmt|;
specifier|private
name|int
name|lastBloomKeyOffset
decl_stmt|,
name|lastBloomKeyLen
decl_stmt|;
specifier|private
name|KVComparator
name|kvComparator
decl_stmt|;
specifier|private
name|KeyValue
name|lastKv
init|=
literal|null
decl_stmt|;
specifier|private
name|long
name|earliestPutTs
init|=
name|HConstants
operator|.
name|LATEST_TIMESTAMP
decl_stmt|;
specifier|private
name|KeyValue
name|lastDeleteFamilyKV
init|=
literal|null
decl_stmt|;
specifier|private
name|long
name|deleteFamilyCnt
init|=
literal|0
decl_stmt|;
comment|/** Checksum type */
specifier|protected
name|ChecksumType
name|checksumType
decl_stmt|;
comment|/** Bytes per Checksum */
specifier|protected
name|int
name|bytesPerChecksum
decl_stmt|;
name|TimeRangeTracker
name|timeRangeTracker
init|=
operator|new
name|TimeRangeTracker
argument_list|()
decl_stmt|;
comment|/* isTimeRangeTrackerSet keeps track if the timeRange has already been set      * When flushing a memstore, we set TimeRange and use this variable to      * indicate that it doesn't need to be calculated again while      * appending KeyValues.      * It is not set in cases of compactions when it is recalculated using only      * the appended KeyValues*/
name|boolean
name|isTimeRangeTrackerSet
init|=
literal|false
decl_stmt|;
specifier|protected
name|HFile
operator|.
name|Writer
name|writer
decl_stmt|;
comment|/**      * Creates an HFile.Writer that also write helpful meta data.      * @param fs file system to write to      * @param path file name to create      * @param conf user configuration      * @param comparator key comparator      * @param bloomType bloom filter setting      * @param maxKeys the expected maximum number of keys to be added. Was used      *        for Bloom filter size in {@link HFile} format version 1.      * @param favoredNodes      * @param fileContext - The HFile context      * @throws IOException problem writing to FS      */
specifier|private
name|Writer
parameter_list|(
name|FileSystem
name|fs
parameter_list|,
name|Path
name|path
parameter_list|,
specifier|final
name|Configuration
name|conf
parameter_list|,
name|CacheConfig
name|cacheConf
parameter_list|,
specifier|final
name|KVComparator
name|comparator
parameter_list|,
name|BloomType
name|bloomType
parameter_list|,
name|long
name|maxKeys
parameter_list|,
name|InetSocketAddress
index|[]
name|favoredNodes
parameter_list|,
name|HFileContext
name|fileContext
parameter_list|)
throws|throws
name|IOException
block|{
name|writer
operator|=
name|HFile
operator|.
name|getWriterFactory
argument_list|(
name|conf
argument_list|,
name|cacheConf
argument_list|)
operator|.
name|withPath
argument_list|(
name|fs
argument_list|,
name|path
argument_list|)
operator|.
name|withComparator
argument_list|(
name|comparator
argument_list|)
operator|.
name|withFavoredNodes
argument_list|(
name|favoredNodes
argument_list|)
operator|.
name|withFileContext
argument_list|(
name|fileContext
argument_list|)
operator|.
name|create
argument_list|()
expr_stmt|;
name|this
operator|.
name|kvComparator
operator|=
name|comparator
expr_stmt|;
name|generalBloomFilterWriter
operator|=
name|BloomFilterFactory
operator|.
name|createGeneralBloomAtWrite
argument_list|(
name|conf
argument_list|,
name|cacheConf
argument_list|,
name|bloomType
argument_list|,
operator|(
name|int
operator|)
name|Math
operator|.
name|min
argument_list|(
name|maxKeys
argument_list|,
name|Integer
operator|.
name|MAX_VALUE
argument_list|)
argument_list|,
name|writer
argument_list|)
expr_stmt|;
if|if
condition|(
name|generalBloomFilterWriter
operator|!=
literal|null
condition|)
block|{
name|this
operator|.
name|bloomType
operator|=
name|bloomType
expr_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isTraceEnabled
argument_list|()
condition|)
name|LOG
operator|.
name|trace
argument_list|(
literal|"Bloom filter type for "
operator|+
name|path
operator|+
literal|": "
operator|+
name|this
operator|.
name|bloomType
operator|+
literal|", "
operator|+
name|generalBloomFilterWriter
operator|.
name|getClass
argument_list|()
operator|.
name|getSimpleName
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// Not using Bloom filters.
name|this
operator|.
name|bloomType
operator|=
name|BloomType
operator|.
name|NONE
expr_stmt|;
block|}
comment|// initialize delete family Bloom filter when there is NO RowCol Bloom
comment|// filter
if|if
condition|(
name|this
operator|.
name|bloomType
operator|!=
name|BloomType
operator|.
name|ROWCOL
condition|)
block|{
name|this
operator|.
name|deleteFamilyBloomFilterWriter
operator|=
name|BloomFilterFactory
operator|.
name|createDeleteBloomAtWrite
argument_list|(
name|conf
argument_list|,
name|cacheConf
argument_list|,
operator|(
name|int
operator|)
name|Math
operator|.
name|min
argument_list|(
name|maxKeys
argument_list|,
name|Integer
operator|.
name|MAX_VALUE
argument_list|)
argument_list|,
name|writer
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|deleteFamilyBloomFilterWriter
operator|=
literal|null
expr_stmt|;
block|}
if|if
condition|(
name|deleteFamilyBloomFilterWriter
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
name|LOG
operator|.
name|isTraceEnabled
argument_list|()
condition|)
name|LOG
operator|.
name|trace
argument_list|(
literal|"Delete Family Bloom filter type for "
operator|+
name|path
operator|+
literal|": "
operator|+
name|deleteFamilyBloomFilterWriter
operator|.
name|getClass
argument_list|()
operator|.
name|getSimpleName
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**      * Writes meta data.      * Call before {@link #close()} since its written as meta data to this file.      * @param maxSequenceId Maximum sequence id.      * @param majorCompaction True if this file is product of a major compaction      * @throws IOException problem writing to FS      */
specifier|public
name|void
name|appendMetadata
parameter_list|(
specifier|final
name|long
name|maxSequenceId
parameter_list|,
specifier|final
name|boolean
name|majorCompaction
parameter_list|)
throws|throws
name|IOException
block|{
name|writer
operator|.
name|appendFileInfo
argument_list|(
name|MAX_SEQ_ID_KEY
argument_list|,
name|Bytes
operator|.
name|toBytes
argument_list|(
name|maxSequenceId
argument_list|)
argument_list|)
expr_stmt|;
name|writer
operator|.
name|appendFileInfo
argument_list|(
name|MAJOR_COMPACTION_KEY
argument_list|,
name|Bytes
operator|.
name|toBytes
argument_list|(
name|majorCompaction
argument_list|)
argument_list|)
expr_stmt|;
name|appendTrackedTimestampsToMetadata
argument_list|()
expr_stmt|;
block|}
comment|/**      * Add TimestampRange and earliest put timestamp to Metadata      */
specifier|public
name|void
name|appendTrackedTimestampsToMetadata
parameter_list|()
throws|throws
name|IOException
block|{
name|appendFileInfo
argument_list|(
name|TIMERANGE_KEY
argument_list|,
name|WritableUtils
operator|.
name|toByteArray
argument_list|(
name|timeRangeTracker
argument_list|)
argument_list|)
expr_stmt|;
name|appendFileInfo
argument_list|(
name|EARLIEST_PUT_TS
argument_list|,
name|Bytes
operator|.
name|toBytes
argument_list|(
name|earliestPutTs
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|/**      * Set TimeRangeTracker      * @param trt      */
specifier|public
name|void
name|setTimeRangeTracker
parameter_list|(
specifier|final
name|TimeRangeTracker
name|trt
parameter_list|)
block|{
name|this
operator|.
name|timeRangeTracker
operator|=
name|trt
expr_stmt|;
name|isTimeRangeTrackerSet
operator|=
literal|true
expr_stmt|;
block|}
comment|/**      * Record the earlest Put timestamp.      *      * If the timeRangeTracker is not set,      * update TimeRangeTracker to include the timestamp of this key      * @param kv      */
specifier|public
name|void
name|trackTimestamps
parameter_list|(
specifier|final
name|KeyValue
name|kv
parameter_list|)
block|{
if|if
condition|(
name|KeyValue
operator|.
name|Type
operator|.
name|Put
operator|.
name|getCode
argument_list|()
operator|==
name|kv
operator|.
name|getTypeByte
argument_list|()
condition|)
block|{
name|earliestPutTs
operator|=
name|Math
operator|.
name|min
argument_list|(
name|earliestPutTs
argument_list|,
name|kv
operator|.
name|getTimestamp
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|!
name|isTimeRangeTrackerSet
condition|)
block|{
name|timeRangeTracker
operator|.
name|includeTimestamp
argument_list|(
name|kv
argument_list|)
expr_stmt|;
block|}
block|}
specifier|private
name|void
name|appendGeneralBloomfilter
parameter_list|(
specifier|final
name|KeyValue
name|kv
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|this
operator|.
name|generalBloomFilterWriter
operator|!=
literal|null
condition|)
block|{
comment|// only add to the bloom filter on a new, unique key
name|boolean
name|newKey
init|=
literal|true
decl_stmt|;
if|if
condition|(
name|this
operator|.
name|lastKv
operator|!=
literal|null
condition|)
block|{
switch|switch
condition|(
name|bloomType
condition|)
block|{
case|case
name|ROW
case|:
name|newKey
operator|=
operator|!
name|kvComparator
operator|.
name|matchingRows
argument_list|(
name|kv
argument_list|,
name|lastKv
argument_list|)
expr_stmt|;
break|break;
case|case
name|ROWCOL
case|:
name|newKey
operator|=
operator|!
name|kvComparator
operator|.
name|matchingRowColumn
argument_list|(
name|kv
argument_list|,
name|lastKv
argument_list|)
expr_stmt|;
break|break;
case|case
name|NONE
case|:
name|newKey
operator|=
literal|false
expr_stmt|;
break|break;
default|default:
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Invalid Bloom filter type: "
operator|+
name|bloomType
operator|+
literal|" (ROW or ROWCOL expected)"
argument_list|)
throw|;
block|}
block|}
if|if
condition|(
name|newKey
condition|)
block|{
comment|/*            * http://2.bp.blogspot.com/_Cib_A77V54U/StZMrzaKufI/AAAAAAAAADo/ZhK7bGoJdMQ/s400/KeyValue.png            * Key = RowLen + Row + FamilyLen + Column [Family + Qualifier] + TimeStamp            *            * 2 Types of Filtering:            *  1. Row = Row            *  2. RowCol = Row + Qualifier            */
name|byte
index|[]
name|bloomKey
decl_stmt|;
name|int
name|bloomKeyOffset
decl_stmt|,
name|bloomKeyLen
decl_stmt|;
switch|switch
condition|(
name|bloomType
condition|)
block|{
case|case
name|ROW
case|:
name|bloomKey
operator|=
name|kv
operator|.
name|getRowArray
argument_list|()
expr_stmt|;
name|bloomKeyOffset
operator|=
name|kv
operator|.
name|getRowOffset
argument_list|()
expr_stmt|;
name|bloomKeyLen
operator|=
name|kv
operator|.
name|getRowLength
argument_list|()
expr_stmt|;
break|break;
case|case
name|ROWCOL
case|:
comment|// merge(row, qualifier)
comment|// TODO: could save one buffer copy in case of compound Bloom
comment|// filters when this involves creating a KeyValue
name|bloomKey
operator|=
name|generalBloomFilterWriter
operator|.
name|createBloomKey
argument_list|(
name|kv
operator|.
name|getRowArray
argument_list|()
argument_list|,
name|kv
operator|.
name|getRowOffset
argument_list|()
argument_list|,
name|kv
operator|.
name|getRowLength
argument_list|()
argument_list|,
name|kv
operator|.
name|getQualifierArray
argument_list|()
argument_list|,
name|kv
operator|.
name|getQualifierOffset
argument_list|()
argument_list|,
name|kv
operator|.
name|getQualifierLength
argument_list|()
argument_list|)
expr_stmt|;
name|bloomKeyOffset
operator|=
literal|0
expr_stmt|;
name|bloomKeyLen
operator|=
name|bloomKey
operator|.
name|length
expr_stmt|;
break|break;
default|default:
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Invalid Bloom filter type: "
operator|+
name|bloomType
operator|+
literal|" (ROW or ROWCOL expected)"
argument_list|)
throw|;
block|}
name|generalBloomFilterWriter
operator|.
name|add
argument_list|(
name|bloomKey
argument_list|,
name|bloomKeyOffset
argument_list|,
name|bloomKeyLen
argument_list|)
expr_stmt|;
if|if
condition|(
name|lastBloomKey
operator|!=
literal|null
operator|&&
name|generalBloomFilterWriter
operator|.
name|getComparator
argument_list|()
operator|.
name|compareFlatKey
argument_list|(
name|bloomKey
argument_list|,
name|bloomKeyOffset
argument_list|,
name|bloomKeyLen
argument_list|,
name|lastBloomKey
argument_list|,
name|lastBloomKeyOffset
argument_list|,
name|lastBloomKeyLen
argument_list|)
operator|<=
literal|0
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Non-increasing Bloom keys: "
operator|+
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|bloomKey
argument_list|,
name|bloomKeyOffset
argument_list|,
name|bloomKeyLen
argument_list|)
operator|+
literal|" after "
operator|+
name|Bytes
operator|.
name|toStringBinary
argument_list|(
name|lastBloomKey
argument_list|,
name|lastBloomKeyOffset
argument_list|,
name|lastBloomKeyLen
argument_list|)
argument_list|)
throw|;
block|}
name|lastBloomKey
operator|=
name|bloomKey
expr_stmt|;
name|lastBloomKeyOffset
operator|=
name|bloomKeyOffset
expr_stmt|;
name|lastBloomKeyLen
operator|=
name|bloomKeyLen
expr_stmt|;
name|this
operator|.
name|lastKv
operator|=
name|kv
expr_stmt|;
block|}
block|}
block|}
specifier|private
name|void
name|appendDeleteFamilyBloomFilter
parameter_list|(
specifier|final
name|KeyValue
name|kv
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
operator|!
name|CellUtil
operator|.
name|isDeleteFamily
argument_list|(
name|kv
argument_list|)
operator|&&
operator|!
name|CellUtil
operator|.
name|isDeleteFamilyVersion
argument_list|(
name|kv
argument_list|)
condition|)
block|{
return|return;
block|}
comment|// increase the number of delete family in the store file
name|deleteFamilyCnt
operator|++
expr_stmt|;
if|if
condition|(
literal|null
operator|!=
name|this
operator|.
name|deleteFamilyBloomFilterWriter
condition|)
block|{
name|boolean
name|newKey
init|=
literal|true
decl_stmt|;
if|if
condition|(
name|lastDeleteFamilyKV
operator|!=
literal|null
condition|)
block|{
name|newKey
operator|=
operator|!
name|kvComparator
operator|.
name|matchingRows
argument_list|(
name|kv
argument_list|,
name|lastDeleteFamilyKV
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
name|newKey
condition|)
block|{
name|this
operator|.
name|deleteFamilyBloomFilterWriter
operator|.
name|add
argument_list|(
name|kv
operator|.
name|getRowArray
argument_list|()
argument_list|,
name|kv
operator|.
name|getRowOffset
argument_list|()
argument_list|,
name|kv
operator|.
name|getRowLength
argument_list|()
argument_list|)
expr_stmt|;
name|this
operator|.
name|lastDeleteFamilyKV
operator|=
name|kv
expr_stmt|;
block|}
block|}
block|}
specifier|public
name|void
name|append
parameter_list|(
specifier|final
name|KeyValue
name|kv
parameter_list|)
throws|throws
name|IOException
block|{
name|appendGeneralBloomfilter
argument_list|(
name|kv
argument_list|)
expr_stmt|;
name|appendDeleteFamilyBloomFilter
argument_list|(
name|kv
argument_list|)
expr_stmt|;
name|writer
operator|.
name|append
argument_list|(
name|kv
argument_list|)
expr_stmt|;
name|trackTimestamps
argument_list|(
name|kv
argument_list|)
expr_stmt|;
block|}
specifier|public
name|Path
name|getPath
parameter_list|()
block|{
return|return
name|this
operator|.
name|writer
operator|.
name|getPath
argument_list|()
return|;
block|}
specifier|public
name|boolean
name|hasGeneralBloom
parameter_list|()
block|{
return|return
name|this
operator|.
name|generalBloomFilterWriter
operator|!=
literal|null
return|;
block|}
comment|/**      * For unit testing only.      *      * @return the Bloom filter used by this writer.      */
name|BloomFilterWriter
name|getGeneralBloomWriter
parameter_list|()
block|{
return|return
name|generalBloomFilterWriter
return|;
block|}
specifier|private
name|boolean
name|closeBloomFilter
parameter_list|(
name|BloomFilterWriter
name|bfw
parameter_list|)
throws|throws
name|IOException
block|{
name|boolean
name|haveBloom
init|=
operator|(
name|bfw
operator|!=
literal|null
operator|&&
name|bfw
operator|.
name|getKeyCount
argument_list|()
operator|>
literal|0
operator|)
decl_stmt|;
if|if
condition|(
name|haveBloom
condition|)
block|{
name|bfw
operator|.
name|compactBloom
argument_list|()
expr_stmt|;
block|}
return|return
name|haveBloom
return|;
block|}
specifier|private
name|boolean
name|closeGeneralBloomFilter
parameter_list|()
throws|throws
name|IOException
block|{
name|boolean
name|hasGeneralBloom
init|=
name|closeBloomFilter
argument_list|(
name|generalBloomFilterWriter
argument_list|)
decl_stmt|;
comment|// add the general Bloom filter writer and append file info
if|if
condition|(
name|hasGeneralBloom
condition|)
block|{
name|writer
operator|.
name|addGeneralBloomFilter
argument_list|(
name|generalBloomFilterWriter
argument_list|)
expr_stmt|;
name|writer
operator|.
name|appendFileInfo
argument_list|(
name|BLOOM_FILTER_TYPE_KEY
argument_list|,
name|Bytes
operator|.
name|toBytes
argument_list|(
name|bloomType
operator|.
name|toString
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|lastBloomKey
operator|!=
literal|null
condition|)
block|{
name|writer
operator|.
name|appendFileInfo
argument_list|(
name|LAST_BLOOM_KEY
argument_list|,
name|Arrays
operator|.
name|copyOfRange
argument_list|(
name|lastBloomKey
argument_list|,
name|lastBloomKeyOffset
argument_list|,
name|lastBloomKeyOffset
operator|+
name|lastBloomKeyLen
argument_list|)
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|hasGeneralBloom
return|;
block|}
specifier|private
name|boolean
name|closeDeleteFamilyBloomFilter
parameter_list|()
throws|throws
name|IOException
block|{
name|boolean
name|hasDeleteFamilyBloom
init|=
name|closeBloomFilter
argument_list|(
name|deleteFamilyBloomFilterWriter
argument_list|)
decl_stmt|;
comment|// add the delete family Bloom filter writer
if|if
condition|(
name|hasDeleteFamilyBloom
condition|)
block|{
name|writer
operator|.
name|addDeleteFamilyBloomFilter
argument_list|(
name|deleteFamilyBloomFilterWriter
argument_list|)
expr_stmt|;
block|}
comment|// append file info about the number of delete family kvs
comment|// even if there is no delete family Bloom.
name|writer
operator|.
name|appendFileInfo
argument_list|(
name|DELETE_FAMILY_COUNT
argument_list|,
name|Bytes
operator|.
name|toBytes
argument_list|(
name|this
operator|.
name|deleteFamilyCnt
argument_list|)
argument_list|)
expr_stmt|;
return|return
name|hasDeleteFamilyBloom
return|;
block|}
specifier|public
name|void
name|close
parameter_list|()
throws|throws
name|IOException
block|{
name|boolean
name|hasGeneralBloom
init|=
name|this
operator|.
name|closeGeneralBloomFilter
argument_list|()
decl_stmt|;
name|boolean
name|hasDeleteFamilyBloom
init|=
name|this
operator|.
name|closeDeleteFamilyBloomFilter
argument_list|()
decl_stmt|;
name|writer
operator|.
name|close
argument_list|()
expr_stmt|;
comment|// Log final Bloom filter statistics. This needs to be done after close()
comment|// because compound Bloom filters might be finalized as part of closing.
if|if
condition|(
name|StoreFile
operator|.
name|LOG
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|StoreFile
operator|.
name|LOG
operator|.
name|trace
argument_list|(
operator|(
name|hasGeneralBloom
condition|?
literal|""
else|:
literal|"NO "
operator|)
operator|+
literal|"General Bloom and "
operator|+
operator|(
name|hasDeleteFamilyBloom
condition|?
literal|""
else|:
literal|"NO "
operator|)
operator|+
literal|"DeleteFamily"
operator|+
literal|" was added to HFile "
operator|+
name|getPath
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
specifier|public
name|void
name|appendFileInfo
parameter_list|(
name|byte
index|[]
name|key
parameter_list|,
name|byte
index|[]
name|value
parameter_list|)
throws|throws
name|IOException
block|{
name|writer
operator|.
name|appendFileInfo
argument_list|(
name|key
argument_list|,
name|value
argument_list|)
expr_stmt|;
block|}
comment|/** For use in testing, e.g. {@link org.apache.hadoop.hbase.regionserver.CreateRandomStoreFile}      */
name|HFile
operator|.
name|Writer
name|getHFileWriter
parameter_list|()
block|{
return|return
name|writer
return|;
block|}
block|}
comment|/**    * Reader for a StoreFile.    */
specifier|public
specifier|static
class|class
name|Reader
block|{
specifier|static
specifier|final
name|Log
name|LOG
init|=
name|LogFactory
operator|.
name|getLog
argument_list|(
name|Reader
operator|.
name|class
operator|.
name|getName
argument_list|()
argument_list|)
decl_stmt|;
specifier|protected
name|BloomFilter
name|generalBloomFilter
init|=
literal|null
decl_stmt|;
specifier|protected
name|BloomFilter
name|deleteFamilyBloomFilter
init|=
literal|null
decl_stmt|;
specifier|protected
name|BloomType
name|bloomFilterType
decl_stmt|;
specifier|private
specifier|final
name|HFile
operator|.
name|Reader
name|reader
decl_stmt|;
specifier|protected
name|TimeRangeTracker
name|timeRangeTracker
init|=
literal|null
decl_stmt|;
specifier|protected
name|long
name|sequenceID
init|=
operator|-
literal|1
decl_stmt|;
specifier|private
name|byte
index|[]
name|lastBloomKey
decl_stmt|;
specifier|private
name|long
name|deleteFamilyCnt
init|=
operator|-
literal|1
decl_stmt|;
specifier|private
name|boolean
name|bulkLoadResult
init|=
literal|false
decl_stmt|;
specifier|public
name|Reader
parameter_list|(
name|FileSystem
name|fs
parameter_list|,
name|Path
name|path
parameter_list|,
name|CacheConfig
name|cacheConf
parameter_list|,
name|Configuration
name|conf
parameter_list|)
throws|throws
name|IOException
block|{
name|reader
operator|=
name|HFile
operator|.
name|createReader
argument_list|(
name|fs
argument_list|,
name|path
argument_list|,
name|cacheConf
argument_list|,
name|conf
argument_list|)
expr_stmt|;
name|bloomFilterType
operator|=
name|BloomType
operator|.
name|NONE
expr_stmt|;
block|}
specifier|public
name|Reader
parameter_list|(
name|FileSystem
name|fs
parameter_list|,
name|Path
name|path
parameter_list|,
name|FSDataInputStreamWrapper
name|in
parameter_list|,
name|long
name|size
parameter_list|,
name|CacheConfig
name|cacheConf
parameter_list|,
name|Configuration
name|conf
parameter_list|)
throws|throws
name|IOException
block|{
name|reader
operator|=
name|HFile
operator|.
name|createReader
argument_list|(
name|fs
argument_list|,
name|path
argument_list|,
name|in
argument_list|,
name|size
argument_list|,
name|cacheConf
argument_list|,
name|conf
argument_list|)
expr_stmt|;
name|bloomFilterType
operator|=
name|BloomType
operator|.
name|NONE
expr_stmt|;
block|}
comment|/**      * ONLY USE DEFAULT CONSTRUCTOR FOR UNIT TESTS      */
name|Reader
parameter_list|()
block|{
name|this
operator|.
name|reader
operator|=
literal|null
expr_stmt|;
block|}
specifier|public
name|KVComparator
name|getComparator
parameter_list|()
block|{
return|return
name|reader
operator|.
name|getComparator
argument_list|()
return|;
block|}
comment|/**      * Get a scanner to scan over this StoreFile. Do not use      * this overload if using this scanner for compactions.      *      * @param cacheBlocks should this scanner cache blocks?      * @param pread use pread (for highly concurrent small readers)      * @return a scanner      */
specifier|public
name|StoreFileScanner
name|getStoreFileScanner
parameter_list|(
name|boolean
name|cacheBlocks
parameter_list|,
name|boolean
name|pread
parameter_list|)
block|{
return|return
name|getStoreFileScanner
argument_list|(
name|cacheBlocks
argument_list|,
name|pread
argument_list|,
literal|false
argument_list|,
comment|// 0 is passed as readpoint because this method is only used by test
comment|// where StoreFile is directly operated upon
literal|0
argument_list|)
return|;
block|}
comment|/**      * Get a scanner to scan over this StoreFile.      *      * @param cacheBlocks should this scanner cache blocks?      * @param pread use pread (for highly concurrent small readers)      * @param isCompaction is scanner being used for compaction?      * @return a scanner      */
specifier|public
name|StoreFileScanner
name|getStoreFileScanner
parameter_list|(
name|boolean
name|cacheBlocks
parameter_list|,
name|boolean
name|pread
parameter_list|,
name|boolean
name|isCompaction
parameter_list|,
name|long
name|readPt
parameter_list|)
block|{
return|return
operator|new
name|StoreFileScanner
argument_list|(
name|this
argument_list|,
name|getScanner
argument_list|(
name|cacheBlocks
argument_list|,
name|pread
argument_list|,
name|isCompaction
argument_list|)
argument_list|,
operator|!
name|isCompaction
argument_list|,
name|reader
operator|.
name|hasMVCCInfo
argument_list|()
argument_list|,
name|readPt
argument_list|)
return|;
block|}
comment|/**      * Warning: Do not write further code which depends on this call. Instead      * use getStoreFileScanner() which uses the StoreFileScanner class/interface      * which is the preferred way to scan a store with higher level concepts.      *      * @param cacheBlocks should we cache the blocks?      * @param pread use pread (for concurrent small readers)      * @return the underlying HFileScanner      */
annotation|@
name|Deprecated
specifier|public
name|HFileScanner
name|getScanner
parameter_list|(
name|boolean
name|cacheBlocks
parameter_list|,
name|boolean
name|pread
parameter_list|)
block|{
return|return
name|getScanner
argument_list|(
name|cacheBlocks
argument_list|,
name|pread
argument_list|,
literal|false
argument_list|)
return|;
block|}
comment|/**      * Warning: Do not write further code which depends on this call. Instead      * use getStoreFileScanner() which uses the StoreFileScanner class/interface      * which is the preferred way to scan a store with higher level concepts.      *      * @param cacheBlocks      *          should we cache the blocks?      * @param pread      *          use pread (for concurrent small readers)      * @param isCompaction      *          is scanner being used for compaction?      * @return the underlying HFileScanner      */
annotation|@
name|Deprecated
specifier|public
name|HFileScanner
name|getScanner
parameter_list|(
name|boolean
name|cacheBlocks
parameter_list|,
name|boolean
name|pread
parameter_list|,
name|boolean
name|isCompaction
parameter_list|)
block|{
return|return
name|reader
operator|.
name|getScanner
argument_list|(
name|cacheBlocks
argument_list|,
name|pread
argument_list|,
name|isCompaction
argument_list|)
return|;
block|}
specifier|public
name|void
name|close
parameter_list|(
name|boolean
name|evictOnClose
parameter_list|)
throws|throws
name|IOException
block|{
name|reader
operator|.
name|close
argument_list|(
name|evictOnClose
argument_list|)
expr_stmt|;
block|}
comment|/**      * Check if this storeFile may contain keys within the TimeRange that      * have not expired (i.e. not older than oldestUnexpiredTS).      * @param scan the current scan      * @param oldestUnexpiredTS the oldest timestamp that is not expired, as      *          determined by the column family's TTL      * @return false if queried keys definitely don't exist in this StoreFile      */
name|boolean
name|passesTimerangeFilter
parameter_list|(
name|Scan
name|scan
parameter_list|,
name|long
name|oldestUnexpiredTS
parameter_list|)
block|{
if|if
condition|(
name|timeRangeTracker
operator|==
literal|null
condition|)
block|{
return|return
literal|true
return|;
block|}
else|else
block|{
return|return
name|timeRangeTracker
operator|.
name|includesTimeRange
argument_list|(
name|scan
operator|.
name|getTimeRange
argument_list|()
argument_list|)
operator|&&
name|timeRangeTracker
operator|.
name|getMaximumTimestamp
argument_list|()
operator|>=
name|oldestUnexpiredTS
return|;
block|}
block|}
comment|/**      * Checks whether the given scan passes the Bloom filter (if present). Only      * checks Bloom filters for single-row or single-row-column scans. Bloom      * filter checking for multi-gets is implemented as part of the store      * scanner system (see {@link StoreFileScanner#seekExactly}) and uses      * the lower-level API {@link #passesGeneralBloomFilter(byte[], int, int, byte[],      * int, int)}.      *      * @param scan the scan specification. Used to determine the row, and to      *          check whether this is a single-row ("get") scan.      * @param columns the set of columns. Only used for row-column Bloom      *          filters.      * @return true if the scan with the given column set passes the Bloom      *         filter, or if the Bloom filter is not applicable for the scan.      *         False if the Bloom filter is applicable and the scan fails it.      */
name|boolean
name|passesBloomFilter
parameter_list|(
name|Scan
name|scan
parameter_list|,
specifier|final
name|SortedSet
argument_list|<
name|byte
index|[]
argument_list|>
name|columns
parameter_list|)
block|{
comment|// Multi-column non-get scans will use Bloom filters through the
comment|// lower-level API function that this function calls.
if|if
condition|(
operator|!
name|scan
operator|.
name|isGetScan
argument_list|()
condition|)
block|{
return|return
literal|true
return|;
block|}
name|byte
index|[]
name|row
init|=
name|scan
operator|.
name|getStartRow
argument_list|()
decl_stmt|;
switch|switch
condition|(
name|this
operator|.
name|bloomFilterType
condition|)
block|{
case|case
name|ROW
case|:
return|return
name|passesGeneralBloomFilter
argument_list|(
name|row
argument_list|,
literal|0
argument_list|,
name|row
operator|.
name|length
argument_list|,
literal|null
argument_list|,
literal|0
argument_list|,
literal|0
argument_list|)
return|;
case|case
name|ROWCOL
case|:
if|if
condition|(
name|columns
operator|!=
literal|null
operator|&&
name|columns
operator|.
name|size
argument_list|()
operator|==
literal|1
condition|)
block|{
name|byte
index|[]
name|column
init|=
name|columns
operator|.
name|first
argument_list|()
decl_stmt|;
return|return
name|passesGeneralBloomFilter
argument_list|(
name|row
argument_list|,
literal|0
argument_list|,
name|row
operator|.
name|length
argument_list|,
name|column
argument_list|,
literal|0
argument_list|,
name|column
operator|.
name|length
argument_list|)
return|;
block|}
comment|// For multi-column queries the Bloom filter is checked from the
comment|// seekExact operation.
return|return
literal|true
return|;
default|default:
return|return
literal|true
return|;
block|}
block|}
specifier|public
name|boolean
name|passesDeleteFamilyBloomFilter
parameter_list|(
name|byte
index|[]
name|row
parameter_list|,
name|int
name|rowOffset
parameter_list|,
name|int
name|rowLen
parameter_list|)
block|{
comment|// Cache Bloom filter as a local variable in case it is set to null by
comment|// another thread on an IO error.
name|BloomFilter
name|bloomFilter
init|=
name|this
operator|.
name|deleteFamilyBloomFilter
decl_stmt|;
comment|// Empty file or there is no delete family at all
if|if
condition|(
name|reader
operator|.
name|getTrailer
argument_list|()
operator|.
name|getEntryCount
argument_list|()
operator|==
literal|0
operator|||
name|deleteFamilyCnt
operator|==
literal|0
condition|)
block|{
return|return
literal|false
return|;
block|}
if|if
condition|(
name|bloomFilter
operator|==
literal|null
condition|)
block|{
return|return
literal|true
return|;
block|}
try|try
block|{
if|if
condition|(
operator|!
name|bloomFilter
operator|.
name|supportsAutoLoading
argument_list|()
condition|)
block|{
return|return
literal|true
return|;
block|}
return|return
name|bloomFilter
operator|.
name|contains
argument_list|(
name|row
argument_list|,
name|rowOffset
argument_list|,
name|rowLen
argument_list|,
literal|null
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|IllegalArgumentException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Bad Delete Family bloom filter data -- proceeding without"
argument_list|,
name|e
argument_list|)
expr_stmt|;
name|setDeleteFamilyBloomFilterFaulty
argument_list|()
expr_stmt|;
block|}
return|return
literal|true
return|;
block|}
comment|/**      * A method for checking Bloom filters. Called directly from      * StoreFileScanner in case of a multi-column query.      *      * @param row      * @param rowOffset      * @param rowLen      * @param col      * @param colOffset      * @param colLen      * @return True if passes      */
specifier|public
name|boolean
name|passesGeneralBloomFilter
parameter_list|(
name|byte
index|[]
name|row
parameter_list|,
name|int
name|rowOffset
parameter_list|,
name|int
name|rowLen
parameter_list|,
name|byte
index|[]
name|col
parameter_list|,
name|int
name|colOffset
parameter_list|,
name|int
name|colLen
parameter_list|)
block|{
comment|// Cache Bloom filter as a local variable in case it is set to null by
comment|// another thread on an IO error.
name|BloomFilter
name|bloomFilter
init|=
name|this
operator|.
name|generalBloomFilter
decl_stmt|;
if|if
condition|(
name|bloomFilter
operator|==
literal|null
condition|)
block|{
return|return
literal|true
return|;
block|}
name|byte
index|[]
name|key
decl_stmt|;
switch|switch
condition|(
name|bloomFilterType
condition|)
block|{
case|case
name|ROW
case|:
if|if
condition|(
name|col
operator|!=
literal|null
condition|)
block|{
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"Row-only Bloom filter called with "
operator|+
literal|"column specified"
argument_list|)
throw|;
block|}
if|if
condition|(
name|rowOffset
operator|!=
literal|0
operator|||
name|rowLen
operator|!=
name|row
operator|.
name|length
condition|)
block|{
throw|throw
operator|new
name|AssertionError
argument_list|(
literal|"For row-only Bloom filters the row "
operator|+
literal|"must occupy the whole array"
argument_list|)
throw|;
block|}
name|key
operator|=
name|row
expr_stmt|;
break|break;
case|case
name|ROWCOL
case|:
name|key
operator|=
name|bloomFilter
operator|.
name|createBloomKey
argument_list|(
name|row
argument_list|,
name|rowOffset
argument_list|,
name|rowLen
argument_list|,
name|col
argument_list|,
name|colOffset
argument_list|,
name|colLen
argument_list|)
expr_stmt|;
break|break;
default|default:
return|return
literal|true
return|;
block|}
comment|// Empty file
if|if
condition|(
name|reader
operator|.
name|getTrailer
argument_list|()
operator|.
name|getEntryCount
argument_list|()
operator|==
literal|0
condition|)
return|return
literal|false
return|;
try|try
block|{
name|boolean
name|shouldCheckBloom
decl_stmt|;
name|ByteBuffer
name|bloom
decl_stmt|;
if|if
condition|(
name|bloomFilter
operator|.
name|supportsAutoLoading
argument_list|()
condition|)
block|{
name|bloom
operator|=
literal|null
expr_stmt|;
name|shouldCheckBloom
operator|=
literal|true
expr_stmt|;
block|}
else|else
block|{
name|bloom
operator|=
name|reader
operator|.
name|getMetaBlock
argument_list|(
name|HFile
operator|.
name|BLOOM_FILTER_DATA_KEY
argument_list|,
literal|true
argument_list|)
expr_stmt|;
name|shouldCheckBloom
operator|=
name|bloom
operator|!=
literal|null
expr_stmt|;
block|}
if|if
condition|(
name|shouldCheckBloom
condition|)
block|{
name|boolean
name|exists
decl_stmt|;
comment|// Whether the primary Bloom key is greater than the last Bloom key
comment|// from the file info. For row-column Bloom filters this is not yet
comment|// a sufficient condition to return false.
name|boolean
name|keyIsAfterLast
init|=
name|lastBloomKey
operator|!=
literal|null
operator|&&
name|bloomFilter
operator|.
name|getComparator
argument_list|()
operator|.
name|compareFlatKey
argument_list|(
name|key
argument_list|,
name|lastBloomKey
argument_list|)
operator|>
literal|0
decl_stmt|;
if|if
condition|(
name|bloomFilterType
operator|==
name|BloomType
operator|.
name|ROWCOL
condition|)
block|{
comment|// Since a Row Delete is essentially a DeleteFamily applied to all
comment|// columns, a file might be skipped if using row+col Bloom filter.
comment|// In order to ensure this file is included an additional check is
comment|// required looking only for a row bloom.
name|byte
index|[]
name|rowBloomKey
init|=
name|bloomFilter
operator|.
name|createBloomKey
argument_list|(
name|row
argument_list|,
literal|0
argument_list|,
name|row
operator|.
name|length
argument_list|,
literal|null
argument_list|,
literal|0
argument_list|,
literal|0
argument_list|)
decl_stmt|;
if|if
condition|(
name|keyIsAfterLast
operator|&&
name|bloomFilter
operator|.
name|getComparator
argument_list|()
operator|.
name|compareFlatKey
argument_list|(
name|rowBloomKey
argument_list|,
name|lastBloomKey
argument_list|)
operator|>
literal|0
condition|)
block|{
name|exists
operator|=
literal|false
expr_stmt|;
block|}
else|else
block|{
name|exists
operator|=
name|bloomFilter
operator|.
name|contains
argument_list|(
name|key
argument_list|,
literal|0
argument_list|,
name|key
operator|.
name|length
argument_list|,
name|bloom
argument_list|)
operator|||
name|bloomFilter
operator|.
name|contains
argument_list|(
name|rowBloomKey
argument_list|,
literal|0
argument_list|,
name|rowBloomKey
operator|.
name|length
argument_list|,
name|bloom
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
name|exists
operator|=
operator|!
name|keyIsAfterLast
operator|&&
name|bloomFilter
operator|.
name|contains
argument_list|(
name|key
argument_list|,
literal|0
argument_list|,
name|key
operator|.
name|length
argument_list|,
name|bloom
argument_list|)
expr_stmt|;
block|}
return|return
name|exists
return|;
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Error reading bloom filter data -- proceeding without"
argument_list|,
name|e
argument_list|)
expr_stmt|;
name|setGeneralBloomFilterFaulty
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IllegalArgumentException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Bad bloom filter data -- proceeding without"
argument_list|,
name|e
argument_list|)
expr_stmt|;
name|setGeneralBloomFilterFaulty
argument_list|()
expr_stmt|;
block|}
return|return
literal|true
return|;
block|}
comment|/**      * Checks whether the given scan rowkey range overlaps with the current storefile's      * @param scan the scan specification. Used to determine the rowkey range.      * @return true if there is overlap, false otherwise      */
specifier|public
name|boolean
name|passesKeyRangeFilter
parameter_list|(
name|Scan
name|scan
parameter_list|)
block|{
if|if
condition|(
name|this
operator|.
name|getFirstKey
argument_list|()
operator|==
literal|null
operator|||
name|this
operator|.
name|getLastKey
argument_list|()
operator|==
literal|null
condition|)
block|{
comment|// the file is empty
return|return
literal|false
return|;
block|}
if|if
condition|(
name|Bytes
operator|.
name|equals
argument_list|(
name|scan
operator|.
name|getStartRow
argument_list|()
argument_list|,
name|HConstants
operator|.
name|EMPTY_START_ROW
argument_list|)
operator|&&
name|Bytes
operator|.
name|equals
argument_list|(
name|scan
operator|.
name|getStopRow
argument_list|()
argument_list|,
name|HConstants
operator|.
name|EMPTY_END_ROW
argument_list|)
condition|)
block|{
return|return
literal|true
return|;
block|}
name|KeyValue
name|smallestScanKeyValue
init|=
name|scan
operator|.
name|isReversed
argument_list|()
condition|?
name|KeyValueUtil
operator|.
name|createFirstOnRow
argument_list|(
name|scan
operator|.
name|getStopRow
argument_list|()
argument_list|)
else|:
name|KeyValueUtil
operator|.
name|createFirstOnRow
argument_list|(
name|scan
operator|.
name|getStartRow
argument_list|()
argument_list|)
decl_stmt|;
name|KeyValue
name|largestScanKeyValue
init|=
name|scan
operator|.
name|isReversed
argument_list|()
condition|?
name|KeyValueUtil
operator|.
name|createLastOnRow
argument_list|(
name|scan
operator|.
name|getStartRow
argument_list|()
argument_list|)
else|:
name|KeyValueUtil
operator|.
name|createLastOnRow
argument_list|(
name|scan
operator|.
name|getStopRow
argument_list|()
argument_list|)
decl_stmt|;
name|boolean
name|nonOverLapping
init|=
operator|(
name|getComparator
argument_list|()
operator|.
name|compareFlatKey
argument_list|(
name|this
operator|.
name|getFirstKey
argument_list|()
argument_list|,
name|largestScanKeyValue
operator|.
name|getKey
argument_list|()
argument_list|)
operator|>
literal|0
operator|&&
operator|!
name|Bytes
operator|.
name|equals
argument_list|(
name|scan
operator|.
name|isReversed
argument_list|()
condition|?
name|scan
operator|.
name|getStartRow
argument_list|()
else|:
name|scan
operator|.
name|getStopRow
argument_list|()
argument_list|,
name|HConstants
operator|.
name|EMPTY_END_ROW
argument_list|)
operator|)
operator|||
name|getComparator
argument_list|()
operator|.
name|compareFlatKey
argument_list|(
name|this
operator|.
name|getLastKey
argument_list|()
argument_list|,
name|smallestScanKeyValue
operator|.
name|getKey
argument_list|()
argument_list|)
operator|<
literal|0
decl_stmt|;
return|return
operator|!
name|nonOverLapping
return|;
block|}
specifier|public
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|byte
index|[]
argument_list|>
name|loadFileInfo
parameter_list|()
throws|throws
name|IOException
block|{
name|Map
argument_list|<
name|byte
index|[]
argument_list|,
name|byte
index|[]
argument_list|>
name|fi
init|=
name|reader
operator|.
name|loadFileInfo
argument_list|()
decl_stmt|;
name|byte
index|[]
name|b
init|=
name|fi
operator|.
name|get
argument_list|(
name|BLOOM_FILTER_TYPE_KEY
argument_list|)
decl_stmt|;
if|if
condition|(
name|b
operator|!=
literal|null
condition|)
block|{
name|bloomFilterType
operator|=
name|BloomType
operator|.
name|valueOf
argument_list|(
name|Bytes
operator|.
name|toString
argument_list|(
name|b
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|lastBloomKey
operator|=
name|fi
operator|.
name|get
argument_list|(
name|LAST_BLOOM_KEY
argument_list|)
expr_stmt|;
name|byte
index|[]
name|cnt
init|=
name|fi
operator|.
name|get
argument_list|(
name|DELETE_FAMILY_COUNT
argument_list|)
decl_stmt|;
if|if
condition|(
name|cnt
operator|!=
literal|null
condition|)
block|{
name|deleteFamilyCnt
operator|=
name|Bytes
operator|.
name|toLong
argument_list|(
name|cnt
argument_list|)
expr_stmt|;
block|}
return|return
name|fi
return|;
block|}
specifier|public
name|void
name|loadBloomfilter
parameter_list|()
block|{
name|this
operator|.
name|loadBloomfilter
argument_list|(
name|BlockType
operator|.
name|GENERAL_BLOOM_META
argument_list|)
expr_stmt|;
name|this
operator|.
name|loadBloomfilter
argument_list|(
name|BlockType
operator|.
name|DELETE_FAMILY_BLOOM_META
argument_list|)
expr_stmt|;
block|}
specifier|private
name|void
name|loadBloomfilter
parameter_list|(
name|BlockType
name|blockType
parameter_list|)
block|{
try|try
block|{
if|if
condition|(
name|blockType
operator|==
name|BlockType
operator|.
name|GENERAL_BLOOM_META
condition|)
block|{
if|if
condition|(
name|this
operator|.
name|generalBloomFilter
operator|!=
literal|null
condition|)
return|return;
comment|// Bloom has been loaded
name|DataInput
name|bloomMeta
init|=
name|reader
operator|.
name|getGeneralBloomFilterMetadata
argument_list|()
decl_stmt|;
if|if
condition|(
name|bloomMeta
operator|!=
literal|null
condition|)
block|{
comment|// sanity check for NONE Bloom filter
if|if
condition|(
name|bloomFilterType
operator|==
name|BloomType
operator|.
name|NONE
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"valid bloom filter type not found in FileInfo"
argument_list|)
throw|;
block|}
else|else
block|{
name|generalBloomFilter
operator|=
name|BloomFilterFactory
operator|.
name|createFromMeta
argument_list|(
name|bloomMeta
argument_list|,
name|reader
argument_list|)
expr_stmt|;
if|if
condition|(
name|LOG
operator|.
name|isTraceEnabled
argument_list|()
condition|)
block|{
name|LOG
operator|.
name|trace
argument_list|(
literal|"Loaded "
operator|+
name|bloomFilterType
operator|.
name|toString
argument_list|()
operator|+
literal|" "
operator|+
name|generalBloomFilter
operator|.
name|getClass
argument_list|()
operator|.
name|getSimpleName
argument_list|()
operator|+
literal|" metadata for "
operator|+
name|reader
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
elseif|else
if|if
condition|(
name|blockType
operator|==
name|BlockType
operator|.
name|DELETE_FAMILY_BLOOM_META
condition|)
block|{
if|if
condition|(
name|this
operator|.
name|deleteFamilyBloomFilter
operator|!=
literal|null
condition|)
return|return;
comment|// Bloom has been loaded
name|DataInput
name|bloomMeta
init|=
name|reader
operator|.
name|getDeleteBloomFilterMetadata
argument_list|()
decl_stmt|;
if|if
condition|(
name|bloomMeta
operator|!=
literal|null
condition|)
block|{
name|deleteFamilyBloomFilter
operator|=
name|BloomFilterFactory
operator|.
name|createFromMeta
argument_list|(
name|bloomMeta
argument_list|,
name|reader
argument_list|)
expr_stmt|;
name|LOG
operator|.
name|info
argument_list|(
literal|"Loaded Delete Family Bloom ("
operator|+
name|deleteFamilyBloomFilter
operator|.
name|getClass
argument_list|()
operator|.
name|getSimpleName
argument_list|()
operator|+
literal|") metadata for "
operator|+
name|reader
operator|.
name|getName
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
throw|throw
operator|new
name|RuntimeException
argument_list|(
literal|"Block Type: "
operator|+
name|blockType
operator|.
name|toString
argument_list|()
operator|+
literal|"is not supported for Bloom filter"
argument_list|)
throw|;
block|}
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Error reading bloom filter meta for "
operator|+
name|blockType
operator|+
literal|" -- proceeding without"
argument_list|,
name|e
argument_list|)
expr_stmt|;
name|setBloomFilterFaulty
argument_list|(
name|blockType
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IllegalArgumentException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Bad bloom filter meta "
operator|+
name|blockType
operator|+
literal|" -- proceeding without"
argument_list|,
name|e
argument_list|)
expr_stmt|;
name|setBloomFilterFaulty
argument_list|(
name|blockType
argument_list|)
expr_stmt|;
block|}
block|}
specifier|private
name|void
name|setBloomFilterFaulty
parameter_list|(
name|BlockType
name|blockType
parameter_list|)
block|{
if|if
condition|(
name|blockType
operator|==
name|BlockType
operator|.
name|GENERAL_BLOOM_META
condition|)
block|{
name|setGeneralBloomFilterFaulty
argument_list|()
expr_stmt|;
block|}
elseif|else
if|if
condition|(
name|blockType
operator|==
name|BlockType
operator|.
name|DELETE_FAMILY_BLOOM_META
condition|)
block|{
name|setDeleteFamilyBloomFilterFaulty
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**      * The number of Bloom filter entries in this store file, or an estimate      * thereof, if the Bloom filter is not loaded. This always returns an upper      * bound of the number of Bloom filter entries.      *      * @return an estimate of the number of Bloom filter entries in this file      */
specifier|public
name|long
name|getFilterEntries
parameter_list|()
block|{
return|return
name|generalBloomFilter
operator|!=
literal|null
condition|?
name|generalBloomFilter
operator|.
name|getKeyCount
argument_list|()
else|:
name|reader
operator|.
name|getEntries
argument_list|()
return|;
block|}
specifier|public
name|void
name|setGeneralBloomFilterFaulty
parameter_list|()
block|{
name|generalBloomFilter
operator|=
literal|null
expr_stmt|;
block|}
specifier|public
name|void
name|setDeleteFamilyBloomFilterFaulty
parameter_list|()
block|{
name|this
operator|.
name|deleteFamilyBloomFilter
operator|=
literal|null
expr_stmt|;
block|}
specifier|public
name|byte
index|[]
name|getLastKey
parameter_list|()
block|{
return|return
name|reader
operator|.
name|getLastKey
argument_list|()
return|;
block|}
specifier|public
name|byte
index|[]
name|getLastRowKey
parameter_list|()
block|{
return|return
name|reader
operator|.
name|getLastRowKey
argument_list|()
return|;
block|}
specifier|public
name|byte
index|[]
name|midkey
parameter_list|()
throws|throws
name|IOException
block|{
return|return
name|reader
operator|.
name|midkey
argument_list|()
return|;
block|}
specifier|public
name|long
name|length
parameter_list|()
block|{
return|return
name|reader
operator|.
name|length
argument_list|()
return|;
block|}
specifier|public
name|long
name|getTotalUncompressedBytes
parameter_list|()
block|{
return|return
name|reader
operator|.
name|getTrailer
argument_list|()
operator|.
name|getTotalUncompressedBytes
argument_list|()
return|;
block|}
specifier|public
name|long
name|getEntries
parameter_list|()
block|{
return|return
name|reader
operator|.
name|getEntries
argument_list|()
return|;
block|}
specifier|public
name|long
name|getDeleteFamilyCnt
parameter_list|()
block|{
return|return
name|deleteFamilyCnt
return|;
block|}
specifier|public
name|byte
index|[]
name|getFirstKey
parameter_list|()
block|{
return|return
name|reader
operator|.
name|getFirstKey
argument_list|()
return|;
block|}
specifier|public
name|long
name|indexSize
parameter_list|()
block|{
return|return
name|reader
operator|.
name|indexSize
argument_list|()
return|;
block|}
specifier|public
name|BloomType
name|getBloomFilterType
parameter_list|()
block|{
return|return
name|this
operator|.
name|bloomFilterType
return|;
block|}
specifier|public
name|long
name|getSequenceID
parameter_list|()
block|{
return|return
name|sequenceID
return|;
block|}
specifier|public
name|void
name|setSequenceID
parameter_list|(
name|long
name|sequenceID
parameter_list|)
block|{
name|this
operator|.
name|sequenceID
operator|=
name|sequenceID
expr_stmt|;
block|}
specifier|public
name|void
name|setBulkLoaded
parameter_list|(
name|boolean
name|bulkLoadResult
parameter_list|)
block|{
name|this
operator|.
name|bulkLoadResult
operator|=
name|bulkLoadResult
expr_stmt|;
block|}
specifier|public
name|boolean
name|isBulkLoaded
parameter_list|()
block|{
return|return
name|this
operator|.
name|bulkLoadResult
return|;
block|}
name|BloomFilter
name|getGeneralBloomFilter
parameter_list|()
block|{
return|return
name|generalBloomFilter
return|;
block|}
name|long
name|getUncompressedDataIndexSize
parameter_list|()
block|{
return|return
name|reader
operator|.
name|getTrailer
argument_list|()
operator|.
name|getUncompressedDataIndexSize
argument_list|()
return|;
block|}
specifier|public
name|long
name|getTotalBloomSize
parameter_list|()
block|{
if|if
condition|(
name|generalBloomFilter
operator|==
literal|null
condition|)
return|return
literal|0
return|;
return|return
name|generalBloomFilter
operator|.
name|getByteSize
argument_list|()
return|;
block|}
specifier|public
name|int
name|getHFileVersion
parameter_list|()
block|{
return|return
name|reader
operator|.
name|getTrailer
argument_list|()
operator|.
name|getMajorVersion
argument_list|()
return|;
block|}
specifier|public
name|int
name|getHFileMinorVersion
parameter_list|()
block|{
return|return
name|reader
operator|.
name|getTrailer
argument_list|()
operator|.
name|getMinorVersion
argument_list|()
return|;
block|}
specifier|public
name|HFile
operator|.
name|Reader
name|getHFileReader
parameter_list|()
block|{
return|return
name|reader
return|;
block|}
name|void
name|disableBloomFilterForTesting
parameter_list|()
block|{
name|generalBloomFilter
operator|=
literal|null
expr_stmt|;
name|this
operator|.
name|deleteFamilyBloomFilter
operator|=
literal|null
expr_stmt|;
block|}
specifier|public
name|long
name|getMaxTimestamp
parameter_list|()
block|{
return|return
name|timeRangeTracker
operator|==
literal|null
condition|?
name|Long
operator|.
name|MAX_VALUE
else|:
name|timeRangeTracker
operator|.
name|getMaximumTimestamp
argument_list|()
return|;
block|}
block|}
comment|/**    * Useful comparators for comparing StoreFiles.    */
specifier|public
specifier|abstract
specifier|static
class|class
name|Comparators
block|{
comment|/**      * Comparator that compares based on the Sequence Ids of the      * the StoreFiles. Bulk loads that did not request a seq ID      * are given a seq id of -1; thus, they are placed before all non-      * bulk loads, and bulk loads with sequence Id. Among these files,      * the size is used to determine the ordering, then bulkLoadTime.      * If there are ties, the path name is used as a tie-breaker.      */
specifier|public
specifier|static
specifier|final
name|Comparator
argument_list|<
name|StoreFile
argument_list|>
name|SEQ_ID
init|=
name|Ordering
operator|.
name|compound
argument_list|(
name|ImmutableList
operator|.
name|of
argument_list|(
name|Ordering
operator|.
name|natural
argument_list|()
operator|.
name|onResultOf
argument_list|(
operator|new
name|GetSeqId
argument_list|()
argument_list|)
argument_list|,
name|Ordering
operator|.
name|natural
argument_list|()
operator|.
name|onResultOf
argument_list|(
operator|new
name|GetFileSize
argument_list|()
argument_list|)
operator|.
name|reverse
argument_list|()
argument_list|,
name|Ordering
operator|.
name|natural
argument_list|()
operator|.
name|onResultOf
argument_list|(
operator|new
name|GetBulkTime
argument_list|()
argument_list|)
argument_list|,
name|Ordering
operator|.
name|natural
argument_list|()
operator|.
name|onResultOf
argument_list|(
operator|new
name|GetPathName
argument_list|()
argument_list|)
argument_list|)
argument_list|)
decl_stmt|;
specifier|private
specifier|static
class|class
name|GetSeqId
implements|implements
name|Function
argument_list|<
name|StoreFile
argument_list|,
name|Long
argument_list|>
block|{
annotation|@
name|Override
specifier|public
name|Long
name|apply
parameter_list|(
name|StoreFile
name|sf
parameter_list|)
block|{
return|return
name|sf
operator|.
name|getMaxSequenceId
argument_list|()
return|;
block|}
block|}
specifier|private
specifier|static
class|class
name|GetFileSize
implements|implements
name|Function
argument_list|<
name|StoreFile
argument_list|,
name|Long
argument_list|>
block|{
annotation|@
name|Override
specifier|public
name|Long
name|apply
parameter_list|(
name|StoreFile
name|sf
parameter_list|)
block|{
return|return
name|sf
operator|.
name|getReader
argument_list|()
operator|.
name|length
argument_list|()
return|;
block|}
block|}
specifier|private
specifier|static
class|class
name|GetBulkTime
implements|implements
name|Function
argument_list|<
name|StoreFile
argument_list|,
name|Long
argument_list|>
block|{
annotation|@
name|Override
specifier|public
name|Long
name|apply
parameter_list|(
name|StoreFile
name|sf
parameter_list|)
block|{
if|if
condition|(
operator|!
name|sf
operator|.
name|isBulkLoadResult
argument_list|()
condition|)
return|return
name|Long
operator|.
name|MAX_VALUE
return|;
return|return
name|sf
operator|.
name|getBulkLoadTimestamp
argument_list|()
return|;
block|}
block|}
specifier|private
specifier|static
class|class
name|GetPathName
implements|implements
name|Function
argument_list|<
name|StoreFile
argument_list|,
name|String
argument_list|>
block|{
annotation|@
name|Override
specifier|public
name|String
name|apply
parameter_list|(
name|StoreFile
name|sf
parameter_list|)
block|{
return|return
name|sf
operator|.
name|getPath
argument_list|()
operator|.
name|getName
argument_list|()
return|;
block|}
block|}
block|}
block|}
end_class

end_unit

